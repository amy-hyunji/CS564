,Unnamed: 0,Unnamed: 0.1,title,abstract,affiliation_code,affiliation_name,affiliation_city,affiliation_country,category,average_length,polarity,subjectivity,passive_active,verb_ratio,noun_ratio,prof_ratio
0,0,0,Fabrication and characterization of 3D printing induced orthotropic functional ceramics,"The orthotropic functional properties of additively manufactured ceramics due to the fabrication process was characterized in this study. Spherical, environmentally benign barium titanate (BaTiO3) powders were fabricated using binder jetting 3D printing. Dielectric and piezoelectric properties of these ceramics were characterized as a function of the printing orientation. The dielectric constant of the samples tested normal to the printing layers was observed to be 20% higher than those tested in the parallel fashion. Similarly, the piezoelectric response was found to be over 35% in the normal orientation. With these results, it was shown that the electroding orientation has a direct influence on the functional properties of additively manufactured ceramics. Overall, with less than 37% of the theoretical density, the average piezoelectric coefficient for the perpendicularly tested ceramics was found to be 152.7 pC N-1, which is 80% of the theoretical value. The high piezoelectric response obtained with such low densities can lead to the development of more mass efficient, and cost-effective sensing and energy harvesting devices, as well as structures that can be tuned to respond based on the direction of the loads applied.",60007801,The University of Texas at El Paso,El Paso,United States,['1711'],23.0,0.04824074074074074,0.36472222222222217,1,0.1201923076923077,0.019230769230769232,0.2961165048543689
1,1,1,A piecewise controllable tunable lens with large aperture for eyewear application,"Here, we present a piecewise controllable tunable lens with large aperture which is composed of a soft polymer lens, an shape memory alloy (SMA) driven iris diaphragm and an SMA driven latch. The SMA driven diaphragm expands the soft polymer lens in the radial direction, thereby varying the focal length. The soft lens has the large aperture of 35 mm in diameter and shows focal length tunability of 31.7% (175-230 mm) under current signal control. The solid characteristics of the polymer lens assure robustness against gravitational force. In addition, the locking mechanism enables the tunable lens to be piecewise controllable and provides high energy efficiency. Due to these advantages, the fabricated tunable lens module can be implemented in various eyewear applications.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,['1711'],20.166666666666668,0.06363095238095239,0.3810119047619048,1,0.09352517985611511,0.04316546762589928,0.2846715328467153
2,2,2,Building blocks of negotiating agents for healthcare data,"The healthcare market demands advanced, flexible, and secure solutions for personal health data sharing. In our paper, we present preliminary work that proposes a distributed infrastructure of negotiating agents for the healthcare domain. This infrastructure will support healthcare stakeholders to share and access patient health data in a secure way, thus providing benefits for patients and their treatment. Distributed ledger technologies and smart contracts can be considered as a basis for negotiations between distributed agents that carry health-related data. We present an overview of related work and outline the research methodology.",60004490,Norsk Regnesentral,Oslo,Norway,"['1712', '1709', '1707', '1705']",18.2,0.1767857142857143,0.3928571428571429,1,0.16666666666666666,0.0,0.3
3,3,3,A real-time detection drone algorithm based on instance semantic segmentation,"With the rapid development of drones, drones are widely used in various fields and bring convenience to people's production and life. However, they also bring security problems to society and the country. Especially in airports or military areas, the flight of drones can cause some problems. In order to effectively supervise the drone, this paper proposes a real-time detection drone algorithm HR-YOLACT which is based on instance semantic segmentation, and designed a new drone data set. The proposed algorithm combines the real-time instance semantic segmentation algorithm YOLACT with the deep high-resolution representation classification network HRNet. Firstly, feature maps are extracted by HRNet's backbone network. Secondly, the feature pyramid network is used to further extract image features, so that the network has better classification ability. Finally, the improved prediction head is utilized to detect the boxes of drones. In addition, this paper uses cross entropy instead of focal loss as the loss function to obtain better network training speed and quality. The experimental results show that HR-YOLACT has faster detection speed and higher detection precision than existing popular real-time object detection and real-time instance semantic segmentation algorithms.",60092530,"Huawei Technologies Co., Ltd.",Shenzhen,China,"['1712', '1709', '1707', '1705']",18.6,0.1609625668449198,0.4875222816399288,1,0.0945945945945946,0.02252252252252252,0.30288461538461536
4,4,4,Fast image dehazing based on guided filter and look-up-table,"Video surveillance has been applied to all aspects of daily life such as security surveillance and driving records. However, it is inevitable that bad weather such as fog and haze will greatly reduce the visibility of the image, and make it impossible to record valuable data. In order to solve this problem, we propose in this paper a fast image dehazing algorithm based on dark channel prior and guiding filter. In addition, we further improve the processing speed by using look-up-table. Based on the prior theory of dark channel, this algorithm first extracts coarser transmission in blocks, then joint bilateral filtering is applied to refine the details. Finally, clear images are recovered with the refined dark channel map and the transmission map. In addition, in order to reduce the computation load in joint bilateral filtering and accelerate the algorithm, we use a two-dimensional look-uptable to avoid the cumbersome computation in weight calculation. Experimental results show that the proposed algorithm can improve the image quality, especially it removes halos on the edges at object boundaries. In addition, the method has low computation and can be applied in practice.",60014643,Wuhan University of Science and Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",20.777777777777782,-0.023333333333333317,0.4616666666666667,1,0.13488372093023257,0.013953488372093023,0.25120772946859904
5,5,5,Application of improved LeNet-5 network in traffic sign recognition,"Considering that most convolutional neural network (CNN) models designed for traffic sign recognition (TSR) have sacrificed more resources and complicated network model development while pursuing higher performance, LeNet-5 shallow CNN with low complexity has been selected for improvement. Increasing the number of convolution kernel in the first convolution layer (C1 layer) and the third convolution layer (C3 layer) while reducing the size of the convolution kernel in C3 layer. Introducing Rectified Linear Unit (ReLU) function with better performance. The maximum pooling is introduced instead of mean pooling. Besides, the output layer employs support vector machine (SVM) to shorten the operation time. The research results demonstrate that the improved LeNet-5 network has an identification accuracy rate of 98.12% and the identification time is 0.154s for traffic signs in German Traffic Sign Recognition Benchmark (GTSRB), which could guarantee the real-time performance of the system and effectively reduce the complexity of the system on the basis of a high recognition rate.",60010955,Changchun University of Science and Technology,Changchun,China,"['1712', '1709', '1707', '1705']",26.33333333333333,0.12416666666666665,0.4739102564102564,1,0.09782608695652174,0.07065217391304347,0.34065934065934067
6,6,6,Improving findability of open data beyond data catalogs,"There is a vast amount of datasets available as Open Data on the Web. However, it is challenging for consumers to find datasets relevant to their goals. This is because the available metadata in catalogs is not descriptive enough. Nevertheless, datasets exist in various types of contexts not expressed in the metadata. These may include information about the data publisher, the legislation related to dataset publication, etc. In this paper we describe an idea of a data model that enables consumers to better understand the data. We propose to define a formal model for representation of the datasets and their contexts, and we propose to apply existing similarity techniques, adjust them to fit each identified dataset context type and combine them together to measure similarity of datasets in new ways, improving their findability.",60016605,Charles University,Prague Praha,Czech Republic,"['1712', '1709', '1707', '1705']",19.0,0.22803030303030306,0.5795454545454546,1,0.14285714285714285,0.02040816326530612,0.3129251700680272
7,7,7,"Analysis of forensic fingerprints in facebook images, the universal antiforensic attack","Now days Facebook is used as one of the most effective communication media. Cheaper digital devices have made it easy, to capture, edit and share images on Facebook. Consequently, image integrity is often an issue for these images. Most of the internet images do not use any embedded active security mechanism, such as watermarking and steganography. Hence, passive digital image forensic techniques are often used to investigate these images. These techniques analyze various fingerprints introduced during tampering attacks, e.g. Noise, JPEG fingerprints, resampling artefacts, etc. Anitforensic attacks searches techniques to hide these forensic fingerprints. Most of the antiforensic techniques target a single forensic fingerprint. In this paper, we have investigated some of the very common forensic techniques on Facebook images. We found that JPEG fingerprints fail on Facebook images. In addition, the common resampling detector and noise inconsistency also fail on these images. Hence, Facebook can be considered as the universal antiforensic attack without degrading visual quality of an image.",60114821,Terna Engineering College,Navi Mumbai,India,"['1712', '1709', '1707', '1705']",12.307692307692307,0.037563025210084006,0.39397759103641455,1,0.125,0.043478260869565216,0.42162162162162165
8,8,8,Bayesian learning of latent representations of language structures,"We borrow the concept of representation learning from deep learning research, and we argue that the quest for Greenbergian implicational universals can be reformulated as the learning of good latent representations of languages, or sequences of surface typological features. By projecting languages into latent representations and performing inference in the latent space, we can handle complex dependencies among features in an implicit manner. The most challenging problem in turning the idea into a concrete computational model is the alarmingly large number of missing values in existing typological databases. To address this problem, we keep the number of model parameters relatively small to avoid overfitting, adopt the Bayesian learning framework for its robustness, and exploit phylogenetically and/or spatially related languages as additional clues. Experiments show that the proposed model recovers missing values more accurately than others and that some latent variables exhibit phylogenetic and spatial signals comparable to those of surface features.",60011001,Kyoto University,Kyoto,Japan,"['1706', '1702']",30.2,0.15494505494505495,0.4355311355311355,1,0.13580246913580246,0.0,0.2716049382716049
9,9,9,Active suppression of the backward motion in a parasitic motion principle (PMP) piezoelectric actuator,"In the piezoelectric driving field, backward motion commonly exists in output displacement curves of the actuators designed by various driving principles, which deteriorates the output performances and increases difficulty in subsequent control. To suppress the backward motion, a synergic motion principle (SMP) was proposed in this paper, which employed two piezoelectric stacks (PESs), one for driving and the other for lifting. By synergic driving of these two PESs, the contact force during the driving process could be effectively controlled and thus the backward motion could be actively suppressed. To verify the feasibility, an actuator prototype was designed and fabricated, and an experimental system was established to test its output performances. By theoretical analysis and experiments, the relationship of the driving voltages for these two PESs was determined. Under the optimized experimental conditions, it showed that the actuator could output stepping displacement without backward motion when working under the SMP. By comparing the results with those obtained when the actuator worked under the parasitic motion principle (PMP), the feasibility and validity of the proposed SMP for suppressing the backward motion were further confirmed.",60007711,Jilin University,Changchun,China,['1711'],26.0,0.053472222222222233,0.4979166666666667,1,0.13592233009708737,0.024271844660194174,0.2912621359223301
10,10,10,Detection of behavioral facilitation information in disaster situation,"Disasters of many types have occurred in recent years, such as strong earthquakes, heavy rain, and typhoons. In such disaster situations, people often use social network services (SNS) and exchange information of all types to help each other. Especially, people exchange information using Twit-ter during disasters. Such tweet messages include much in-formation that promotes people's behaviors. We designate such tweets as behavioral facilitation tweets. When psycho-logically unstable in the aftermath of a disaster, behavioral facilitation tweets can strongly affect people, irrespective of a message's authenticity. We regard the extraction of the be-havioral facilitation tweets automatically as important. In this paper, we propose a method that extracts behavioral facilitation tweets in disaster situations. Specifically, we pro-pose and compare three methods to extract behavioral facil-itation tweets in disaster situations: Rule-based, support vec-tor machine (SVM) and long short-term memory (LSTM). Furthermore, we conducted experiments to assess the bene- ts of our proposed method.",60029341,Konan University,Kobe,Japan,"['1712', '1709', '1707', '1705']",15.0,0.10833333333333336,0.5172222222222224,1,0.10606060606060606,0.020202020202020204,0.4444444444444444
11,11,11,Attentional Bi-directional LSTM for Semantic Attribute Prediction,"Attribute prediction is a basic task in CV field, and it belongs to a multi-label prediction problem in practical terms. Most studies using deep features to handle the problem while ignoring the potential dependencies that exist within attributes and images. Differ from previous work, we propose a novel deep architecture named ABLSTM, which not only taking advantage of CNN and Bi-LSTM, but also utilizing a multi-task-multi-loss design for attribute detection. Based on ABLSTM, we further construct a simple but extremely effective regression module to improve the accuracy of high-level abstract semantic attributes. Extensive experiments on the largest attribute prediction dataset of DeepFashion show the consistency superiority and efficiency of the proposed model.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,"['1712', '1709', '1707', '1705']",22.4,0.08484848484848485,0.5074675324675324,1,0.11194029850746269,0.05223880597014925,0.32786885245901637
12,12,12,Multiple ship targets association method of remote sensing images based on SIFT and bags of visual words model,"Ships with unique moving and group activity characteristics can be considered as a type of very important military targets in marine situation awareness. We propose a novel method for multiple ship targets association with utilizing multi-temporal optical satellite images. First, a large number of local invariant features are extracted from the region of the optical satellite imagery containing the ship targets. Second, we present a weighted Bag of Visual Words model to perform transforming the 128-dim features to high-order semantic features. Finally, the optimization model based on the Associated Cost Matrix is constructed to solve the target optimal correlation matching. The experimental results clearly demonstrate that the proposed method is robust to multi-target association ambiguity and produces good matching accuracy with low computational effort.",60088576,Jiangsu Automation Research Institute,Lianyungang,China,"['1712', '1709', '1707', '1705']",20.666666666666668,0.14395238095238094,0.3696825396825397,1,0.12949640287769784,0.050359712230215826,0.2857142857142857
13,13,13,3D saliva ferning images to determine the women's fertility rates,"In this paper we will discuss the process of processing salivary images which will be represented by salivary fern patterns into 3D shapes and determine the level of fertility visually with existing theories. The author raises this theme because it can make it easier to recognize the pattern of ferns in saliva in determining the level of female fertility in the health field. The work stages in this paper start from the study of literature, data collection, designing 3D applications, making 3D applications and testing. The stages of processing the saliva image used by the author's computer in the process of image improvement, edge detection, cropping and masking, segmentation and 3-dimensional image representation.",60105733,Gunadarma University,Depok,Indonesia,"['1712', '1709', '1707', '1705']",28.25,0.0,0.08333333333333333,1,0.13709677419354838,0.0,0.2661290322580645
14,14,14,Combining a gamified civic engagement platform with a digital game in a loosely way to increase retention,"In this article we discuss an innovative approach to tackle the retention problem in civic engagement systems, more in particular in the context of care taking of elderly. The proposed solution is to complement a gamified civic engagement platform with an entertainment game but in such a way that the two are only loosely coupled. The civic engagement platform is a location-based card environment that allows to connect people who might be in need of assistance (i.e. elderly) with people willing to spend their time to help (i.e. volunteers). By helping people the volunteers collect cards, which can be used in the game to play. Special is that we do not expect that the volunteers will be the one playing the game. On the contrary, the aim is to create a self-feeding network between two groups of users: On the one hand the volunteers and on the other hand gamers. We hope that the gamers will stimulate the volunteers to collect cards and that in this way we can retain the volunteers for longer periods. Currently, the approach is being implemented for the case of assisting elderly, but the principle is also applicable in other domains of civic engagement. The paper discusses the research goals and problems, the research approach, as well as the current state and future work.",60026810,Vrije Universiteit Brussel,Brussels,Belgium,"['1712', '1709', '1707', '1705']",19.90909090909091,0.015430402930402924,0.4874370421245422,1,0.12295081967213115,0.004098360655737705,0.2396694214876033
15,15,15,Uniform access to multiform data lakes using semantic technologies,"Increasing data volumes have extensively increased application possibilities. However, accessing this data in an ad hoc manner remains an unsolved problem due to the diversity of data management approaches, formats and storage frameworks, resulting in the need to effectively access and process distributed heterogeneous data at scale. For years, SemanticWeb techniques have addressed data integration challenges with practical knowledge representation models and ontology-based mappings. Leveraging these techniques, we provide a solution enabling uniform access to large, heterogeneous data sources, without enforcing centralization; thus realizing the vision of a Semantic Data Lake. In this paper, we define the core concepts underlying this vision and the architectural requirements that systems implementing it need to fulfill. Squerall, an example of such a system, is an extensible framework built on top of state-ofthe- A rt Big Data technologies. We focus on Squerall's distributed query execution techniques and strategies, empirically evaluating its performance throughout its various sub-phases.",60007493,Universität Bonn,Bonn,Germany,"['1712', '1709', '1707', '1705']",21.714285714285715,0.14325396825396827,0.40410052910052907,1,0.12359550561797752,0.0449438202247191,0.37209302325581395
16,16,16,ToT for CSV: Accessing open data CSV files through SQL,"Recently, the push for open data has been very strong, and more and more sources, such as governments are sharing data such as weather records or demographic statistics. The Remote Table Access (RTA) system allows the easy publication of data from a relational database, and its use through SQL-like queries by remote users. Still, the data currently being shared as open data comes in many formats, not always directly integrable with relational databases, and many sources publish data as raw CSV, XML or even PDF files. These files then need to be downloaded, parsed, and integrated with the final user's data, often in a relational database. In this work, we present Table on Top (ToT) for CSV, an extension of the RTA system that allows the easy publication and access of data contained in CSV files through RTA.",60025997,Keio University,Tokyo,Japan,"['1712', '1709', '1707', '1705']",27.6,0.17996153846153845,0.5015769230769231,1,0.0736196319018405,0.05521472392638037,0.39751552795031053
17,17,17,Sketch based image retrieval with adversarial network,"Sketch retrieval is a specific cross-domain retrieval task. The core of sketch retrieval is to learn a common feature subspace, where the features of sketches and natural images can be both discriminative and domain-invariant. However, similarity constraints can impair the performance of the feature extractor, resulting in unsatisfactory retrieval accuracy. For this problem, we propose a novel sketch based image retrieval method based on adversarial network. Our method is demonstrated as follows: Firstly, we train the sketch image network and natural image network to improve the ability of classification; secondly, we train the adversarial network to promote the feature fusion of sketches ,of which the network is constituted by feature extractor and domain classifier; thirdly, we use the deep convolutional neural network to extract the deep feature to achieve retrieval. Experiments on retrieval show positive results.",60001298,Northwest University,Xi'an,China,"['1712', '1709', '1707', '1705']",22.66666666666667,0.037727272727272734,0.3103787878787879,1,0.11464968152866242,0.0,0.22875816993464052
18,18,18,Automated detection of steel defects via machine learning based on real-time semantic segmentation,"To improve automation, increase efficiency, and maintain high quality in the production of steel, applying modern machine learning techniques to help detect steel defects has been the research focus in the steel industry, since an unprecedented revolution in image semantic segmentation has been witnessed in the past few years. In the traditional production process of steel materials, localizing and classifying surface defects manually on a steel sheet is inefficient and error-prone. Therefore, it's a key challenge to achieve automated detection of steel surface defects in image pixel level, leaving an urgent and critical issue to be addressed. In this paper, to accomplish this crucial task, we apply a series of machine learning algorithms of real-time semantic segmentation, utilizing neural networks with encoder-decoder architectures based on Unet and feature pyramid network (FPN). The image dataset of steel defects is provided by Severstal, the largest steel company in Russia, through a featured code competition in the Kaggle community. The results show that the ensemble algorithm of several neural networks with encoderdecoder architectures has a decent performance regarding both time cost and segmentation accuracy. Our machine learning algorithms achieve dice coefficients over 0.915 and 0.905 at a speed of over 1.5 images per second on the public test set and private test set on the Kaggle platform, respectively, which locates at the top 2% among all teams in the competition.",60025761,Huazhong University of Science and Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",32.42857142857143,0.07354166666666667,0.4592708333333333,1,0.10077519379844961,0.023255813953488372,0.2976190476190476
19,19,19,A web service architecture for social micro-learning,"In knowledge organizations or a knowledge society learning processes are inherently social and distributed. To enable these processes knowledge artifacts need to be created, updated, and consumed decentralized. Social Micro-Learning is an example for an approach following that paradigm. By proposing a flexible service architecture, this paper addresses the diverse demands that Social Micro-Learners have throughout their learning process. It allows integrating information retrieval, recommender systems, workflow engines and spaced repetition algorithms through a single stream data model. Consequently, we can reuse user interface implementations and provide a consistent, recognizable view. Our evaluations show a good system usability, and stable results across different services. We conclude that our service design can serve as a blueprint for social e-learning systems.",60021931,Johannes Kepler Universitat Linz,Linz,Austria,"['1712', '1709', '1707', '1705']",14.875,0.1261904761904762,0.2280952380952381,1,0.14893617021276595,0.0425531914893617,0.37037037037037035
20,20,20,Mining stock price changes for profitable trade using candlestick chart patterns,"One major technical analysis of stock price fluctuation is the use of candlestick charts. This paper proposes a model with six parameters to retrieve similar candlestick patters to improve accuracy of stock price predictions. Because criteria that trigger reversing trade largely affect gains and losses, we examine two criteria; one based on sum of negative stock price changes and the other on sum of negative 5-day average differences. The proposed retrieval algorithm and criteria are evaluated through simulations in terms of gains and losses using NASDAQ's daily stock data. The results of simulations indicate that the proposed method leads to a trade decision that opportunities of successful stock trades are effectively above that of failure ones with several percentage of gains. Simulations also show that high risks deliver high returns. The results are examined statistically by the regression analysis suggesting the significant capabilities of the proposed method to predict stock price fluctuations.",60007578,Tokyo University of Information Sciences,Chiba,Japan,"['1712', '1709', '1707', '1705']",21.714285714285715,0.033132440476190475,0.39428571428571424,1,0.11728395061728394,0.018518518518518517,0.2716049382716049
21,21,21,A study on characterizing the ecosystem of monetizing video spams on youtube platform,"In this work, we specifically study YouTube videos promoting easy money gaining tricks. We observe a noticeable presence of such videos on YouTube that are being used to-1) mislead users into sharing their personal identifiable information, i.e., phone numbers publically or 2) direct users away from YouTube on sites causing negative user experience. For our study, we call them-phone spam and link spam based videos respectively. We provide a detailed analysis of the behavioral characteristics of these two categories of videos based on metadata content and graph based features. For our study, a total of 80 phone spam videos and 2000 link spam videos were collected and analyzed. Our analysis shows that such videos are highly related to each other, and specific motifs discriminating such videos exist. To our knowledge this is the first attempt towards characterizing such types of videos on YouTube.",60093232,"Pandit Dwarka Prasad Mishra Indian Institute of Information Technology, Design &amp; Manufacturing Jabalpur",Jabalpur,India,"['1712', '1709', '1707', '1705']",20.428571428571427,0.05364583333333334,0.4541666666666666,1,0.11875,0.0375,0.379746835443038
22,22,22,Effects of mining parameters on the performance of the sequence pattern variants analyzing method applied to electronic medical record systems,"Sequential pattern mining (SPM) is widely used for data mining and knowledge discovery in various application domains. Recently, we have proposed an analyzing method to evaluate the sequence pattern variant (SPV) that is the original sequence containing frequent patterns including variants. Such a study is meaningful for medical tasks such as improving the quality of a disease's treatment method. This paper aims to evaluate the effectiveness of the proposed analyzing method in more detail when it was applied to Electronic Medical Record Systems. Using a real dataset, it is observed that the analyzing method is successful in statistically discovering the meaningful indicators that are leading to the difference between comparative SPVs, such as complicated risk, severity risk of the disease, the length of stay in the hospital and the total medical cost. Moreover, it is observed that the length of stay and the medical cost can gain more benefit from increasing the significance level parameter used in comparing the SPVs.",60031126,Tokyo Institute of Technology,Tokyo,Japan,"['1712', '1709', '1707', '1705']",26.66666666666667,0.14125,0.435,1,0.12429378531073447,0.03389830508474576,0.2768361581920904
23,23,23,On the Support Splitting Algorithm for Induced Codes,"Abstract—: As shown by N. Sendrier in 2000, if a [n,k,d]-linear code C(⊆Fn q) with length n, dimensionality k and code distance d has a trivial group of automorphisms PAut(C), it allows one to construct a determined support splitting algorithm in order to find a permutation σ for a code D, being permutation-equivalent to the code C, such that σ(C) = D. This algorithm can be used for attacking the McEliece cryptosystem based on the codeC. This work aims the construction and analysis of the support splitting algorithm for the code Fl q⊗C, induced by the code C, l ϵ N. Since the group of automorphisms PAutFl q⊗C is nontrivial even in the case of that trivial for the base code C, it enables one to assume a potentially high resistance of the McEliece cryptosystem on the code Fl q⊗C to the attack based on a carrier split. The support splitting algorithm is being constructed for the code Fl q⊗C and its efficiency is compared with the attack to a McEliece cryptosystem based on the code Fl q⊗C",60025383,Southern Federal University,Rostov-on-Don,Russian Federation,"['1712', '1711']",29.66666666666667,-0.21333333333333332,0.68,1,0.08040201005025126,0.1407035175879397,0.3170731707317073
24,24,24,Security issues in mobile healthcare applications,"Mobile healthcare applications, in short mHealth apps, are an effiicient and more affordable way for patients to communicate with medical doctors and receive treatment using their mobile devices. However, the security of mHealth apps has become obstacle because many of mHealth apps deal with sensitive personal information including health-related data. To promote the developments of secure and trustworthy mHealth apps, in this paper, we survey mHealth-related security issues, not only general security issues but also mHealth-specific issues, and explore potential solutions to each issue.",60002227,Virginia Military Institute,Lexington,United States,"['1712', '1709', '1707', '1705']",28.0,0.155,0.5599999999999999,1,0.11,0.07,0.40425531914893614
25,25,25,Unsupervised single image dehazing via disentangled representation,"Image dehazing aims to recover the latent clear content from the corresponding degraded hazy image. In this paper, we propose an unsupervised method for single image dehazing based on disentangled representation. Our proposed method does not rely on the physical scattering model and does not need paired of training data. We propose a content encoder and a haze encoder to disentangle the content and hazy information from a hazy image respectively. We propose a latent regression loss to encourage the generated image to preserve haze information and to force the haze encoder to extract haze information from the haze image. The cycle-consistency loss are introduced to ensure that the dehazed images have the same content structures with the original images. We also use an adversarial loss on the dehazed images to guarantee haze free and visually realistic. Extensive experiment results on the public dehazing dataset RESIDE demonstrate that the proposed method outperforms state-of-the-art unsupervised methods, and can achieve comparable performance with the stateof-the- A rt supervised methods.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1709', '1707', '1705']",20.875,0.09702380952380953,0.3248809523809525,1,0.1711229946524064,0.0,0.2655367231638418
26,26,26,Events insights extraction from twitter using LDA and day-hashtag pooling,"News extraction from Twitter data is a hot topic. But can we extract much more than just news? The purpose of this research is to find, either news is the only information which can be extracted from Twitter data or it contains much more insights about real life events. So, we introduce a technique for analysis of Twitter's raw content. After pre-processing of tweets data, we apply hashtag pooling and extract topics using available topic modeling algorithm Latent Dirichlet Allocation (LDA) without modifying its core machinery. In the second part, estimated number of tweets per day and correlated top hashtags for each topic are calculated using dayhashtag pooling. Finally, the continues time series graph is constructed for topic analysis. Our findings show interesting results of bursty news detection, topic popularity, people's way to perceiving an event, real-life event's transition over time and before & after affects of a specific event.",60014256,University of Tsukuba,Tsukuba,Japan,"['1712', '1709', '1707', '1705']",21.428571428571427,0.2182692307692308,0.5113782051282052,1,0.10857142857142857,0.05142857142857143,0.34502923976608185
27,27,27,Tourism application with CNN-based classification specialized for cultural information,"Over-tourism has become an important difficulty in Japan because the number of visiting international tourists has increased in recent years. This intensive tourism leads to sightseeing problems because opportunities to inform tourists about culture and rules in tourist areas are few. Some system is needed to convey correct cultural aspects of tourist areas. This paper proposes a system to present a user with useful information such as area-specic culture from photographs taken with a convolutional neural network (CNN). Tourists can gain information by associating the contents with the real world by browsing useful information while viewing photographs. After we constructed the prototype system to present 30 types of useful information in English, we evaluated our system quantitatively. We also administered a questionnaire survey for Japanese and foreign residents. The results demonstrate that our system is effective to facilitate foreign tourists' understanding Japanese culture and norms.",60028385,Okayama University of Science,Okayama,Japan,"['1712', '1709', '1707', '1705']",18.125,0.09722222222222222,0.18333333333333326,1,0.13664596273291926,0.018633540372670808,0.3184713375796178
28,28,28,Investigation on frequency-dependent hysteresis loops of ferroelectric materials,"In this paper, a frequency-dependent theory is developed to study the polarization hysteresis loops of ferroelectric materials. From experimental observations, the polarization hysteresis loops strongly depend on the electric field loading frequency. When the frequency increases both remanent polarization and coercive electric field are increasing, while the dielectric constant remains unchanged at the given range of the frequency. An exponential function is introduced to express such frequency-dependent changes of the remanent polarization and the coercive field. Then a micromechanics-based approach can be applied to study hysteresis loops of ferroelectrics. To verify the developed theory, we first compare the results between the theoretical calculations and experimental data of PZT. Then we applied the model to study the frequency effects on hysteresis loops of a complex ceramic BaMn3Ti4O14.25 (BMT-134) under the electric field.",60028458,City College of New York,New York,United States,['1711'],18.714285714285715,0.07833333333333332,0.38,1,0.12,0.006666666666666667,0.2847222222222222
29,29,29,View resistant gait recognition,"Human gait is one of the biometric characteristics that a person can be identified by. However, the wide applicability of gait recognition in real life is prevented by a great variety of conditions that affect the gait representation, such as different viewpoints. In this work, we present a novel view resistant approach to overcome the multi-view recognition challenge. The new loss function is proposed to increase the stability of the model to view changes. Besides this, the cross-view embedding of the gait features is made to enhance their discriminant ability which improves the recognition accuracy as well. The proposed approaches show a significant gain in quality and allow to achieve the state-of-the-art accuracy on the most common benchmark and outperform the most successful model on the majority of the views and on average.",60020513,National Research University Higher School of Economics,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",22.16666666666667,0.1936688311688312,0.4878246753246754,1,0.10457516339869281,0.0,0.21678321678321677
30,30,30,A method to estimate entity performance from mentions to related entities in texts on the web,"Publications on the Web can influence the public opinion about certain entities (e.g., politicians, institutions). At the same time, a variety of indicators can be extracted from these publications and used to estimate entity performance (e.g., popularity, votes share). This work proposes an automatic method that employs state-of-theart natural language processing tools to extract indicators about entities mentioned in texts, for estimating the performance of these entities or semantically related ones. Our method calculates performance metrics from performance indicators consolidated for semantically related entities, assess correlations of these consolidated metrics with ground true performance, and uses these metrics to predict certain fluctuations in entity performance. Experimental results in a case study on politics show that consolidated metrics for several interrelated entities are better correlated to observed real performance measures of some target entities and lead to better predictions, than metrics for just one entity.",60017609,Universidade Federal de Santa Catarina,Florianopolis,Brazil,"['1712', '1709', '1707', '1705']",28.8,0.1675824175824176,0.3757326007326007,1,0.14457831325301204,0.0,0.345679012345679
31,31,31,Secure naïve bayes classification protocol over encrypted data using fully homomorphic encryption,"Machine learning classification has a wide range of applications. In the big data era, a client may want to outsource classification tasks to reduce the computational burden at the client. Meanwhile, an entity may want to provide a classification model and classification services to such clients. However, applications such as medical diagnosis require sensitive data that both parties may not want to reveal. Fully homomorphic encryption (FHE) enables secure computation over encrypted data without decryption. By applying FHE, classification can be outsourced to a cloud without revealing any data. However, existing studies on classification over FHE do not achieve the scenario of outsourcing classification to a cloud while preserving the privacy of the classification model, client's data and result. In this work, we apply FHE to a naïve Bayes classifier and, to the best of our knowledge, propose the first concrete secure classification protocol that satisfies the above scenario.",60023462,Waseda University,Tokyo,Japan,"['1712', '1709', '1707', '1705']",18.625,0.18333333333333326,0.3861111111111111,1,0.14792899408284024,0.029585798816568046,0.3076923076923077
32,32,32,Captioning images on mobile devices using semi-statistical extraction,"In this work, we propose a semi-statistical Image Extracting Image Semantic Framework using TensorFlow for Mobile Devices. We used datasets for training and generate extraction from other datasets of sentences using the N-Best algorithm selecting the closest sentence associated to images. In addition, we test our experiment with two models of Object Recognition and make comparisons between the different datasets of images and sentences.",60012392,National Taipei University of Technology,Taipei,Taiwan,"['1712', '1709', '1707', '1705']",21.33333333333333,-0.0625,0.4875,1,0.1232876712328767,0.1232876712328767,0.4782608695652174
33,33,33,Generation of test cases for testing superSQL,"SuperSQL is an extension of SQL which generates data in various formats like HTML, PDF, XML, among many others. The same data is represented in different forms according to the user, due to which it is called a data representation and publishing language. This research is to provide help in testing the SuperSQL processor. In this study, possible test cases that are used for testing the SuperSQL system are generated using a combinatorial algorithm that was constructed. This algorithm generated a combinatorially explosive number of test cases that are required for testing the SuperSQL system. A software tool called SStest was made to exhibit these test cases for use and also to manage (execute, add, delete) these test cases.",60025997,Keio University,Tokyo,Japan,"['1712', '1709', '1707', '1705']",19.83333333333333,0.0625,0.5166666666666667,1,0.14925373134328357,0.03731343283582089,0.34328358208955223
34,34,34,Weighted load balancing in distributed hash tables,"The rising amount of data in Internet of Things (IoT) and Wireless Sensor Network (WSN) scenarios motivates new computing paradigms like fog or edge computing. To reduce the amount of data sent upstream, in-network (pre-)processing is widely used, which demands for both compute and distributed storage capacities in highly constrained environments. This paper introduces a new way of using Distributed Hash Tables (DHTs) to create a distributed storage in P2P-networks. The main design goals are to introduce the lowest overheads possible and allowing for fair load balancing, even if nodes contributing storage capacities of arbitrary/different sizes form the network. A combination of an optimized bootstrap mechanism and a virtual node scheme that deploys a variable number of virtual nodes depending on a node's storage capacity yields success. An evaluation and comparison with state of the art work shows that the new method performs well in terms of load balancing while minimizing overheads introduced by newly introduced virtual nodes.",60028717,Ludwig-Maximilians-Universität München,Munich,Germany,"['1712', '1709', '1707', '1705']",26.33333333333333,0.1772121212121212,0.4991515151515151,1,0.14917127071823205,0.04419889502762431,0.3728813559322034
35,35,35,What do language representations really represent?,"A neural language model trained on a text corpus can be used to induce distributed representations of words, such that similar words end up with similar representations. If the corpus is multilingual, the same model can be used to learn distributed representations of languages, such that similar languages end up with similar representations. We show that this holds even when the multilingual corpus has been translated into English, by picking up the faint signal left by the source languages. However, just as it is a thorny problem to separate semantic from syntactic similarity in word representations, it is not obvious what type of similarity is captured by language representations. We investigate correlations and causal relationships between language representations learned from translations on one hand, and genetic, geographical, and several levels of structural similarity between languages on the other. Of these, structural similarity is found to correlate most strongly with language representation similarity, whereas genetic relationships—a convenient benchmark used for evaluation in previous work—appears to be a confounding factor. Apart from implications about translation effects, we see this more generally as a case where NLP and linguistic typology can interact and benefit one another.",60030840,Københavns Universitet,Copenhagen,Denmark,"['1706', '1702']",27.57142857142857,0.04166666666666666,0.3736842105263158,1,0.12962962962962962,0.018518518518518517,0.24528301886792453
36,36,36,Building a web-based federated toolchain: Lessons learned from a four-year industrial project,"Big companies use many tools, jointly referred to as the toolchain, to manage vast amounts of engineering data being generated across an application lifecycle. Individual tools are typically designed to perform specific engineering tasks, and rely on specific data formats. This leads to problems when attempting to automate engineering tasks that are not supported by a particular tool, and which require data from multiple tools. This paper presents the experiences and lessons learned from an industrial research-project within the heavy vehicle manufacturer Scania, where the project goal was to identify and industrialize technologies and principles that solve the above problem. The presented lessons cover architectural, technological, and organizational aspects of a toolchain development-process. In addition, as a consequence of the lessons learned, the toolchain architecture and tool-interface architecture is also presented.",60031824,Scania AB,Sodertalje,Sweden,"['1712', '1709', '1707', '1705']",21.83333333333333,0.027272727272727268,0.3348484848484849,1,0.13815789473684212,0.006578947368421052,0.3561643835616438
37,37,37,Deep CNN: A machine learning approach for driver drowsiness detection based on eye state," All rights reserved.Driver drowsiness is one of the reasons for large number of road accidents these days. With the advancement in Computer Vision technologies, smart/intelligent cameras are developed to identify drowsiness in drivers, thereby alerting drivers which in turn reduce accidents when they are in fatigue. In this work, a new framework is proposed using deep learning to detect driver drowsiness based on Eye state while driving the vehicle. To detect the face and extract the eye region from the face images, Viola-Jones face detection algorithm is used in this work. Stacked deep convolution neural network is developed to extract features from dynamically identified key frames from camera sequences and used for learning phase. A SoftMax layer in CNN classifier is used to classify the driver as sleep or non-sleep. This system alerts driver with an alarm when the driver is in sleepy mood. The proposed work is evaluated on a collected dataset and shows better accuracy with 96.42% when compared with traditional CNN. The limitation of traditional CNN such as pose accuracy in regression is overcome with the proposed Staked Deep CNN.",60005630,"National Institute of Technology, Tiruchirappalli",Tiruchirappalli,India,"['1712', '1702']",20.444444444444443,0.08755411255411255,0.5152597402597402,0,0.1407766990291262,0.06310679611650485,0.3096446700507614
38,38,38,Lossless compression algorithm based on context tree,"In order to deal with the context dilution problem introduced in the lossless compression of M-ary sources, a lossless compression algorithm based on a context tree model is proposed. By making use of the principle that conditioning reduces entropy, the algorithm constructs a context tree model to make use of the correlation among adjacent image pixels. Meanwhile, the M-ary tree is transformed into a binary tree to analyze the statistical information of the source in more details. In addition, the escape symbol is introduced to deal with the zero-frequency symbol problem when the model is used by an arithmetic encoder. The increment of the description length is introduced for the merging of tree nodes. The experimental results show that the proposed algorithm can achieve better compression results.",60028009,Yunnan University,Kunming,China,"['1712', '1709', '1707', '1705']",21.166666666666668,0.3666666666666667,0.4666666666666666,1,0.11888111888111888,0.03496503496503497,0.24817518248175183
39,39,39,A museum information system for sustaining and analyzing national cultural expressions,"Culture is an integral part of the social and economic development of a nation. In the Philippines, The National Commission for Culture and the Arts (NCCA) is the overall policy-making body for culture and arts development. NCCA has been experiencing difficulty in collecting and organizing large cultural data sets, which are vital in their decisions concerning culture and arts reforms. We propose a sustainable data collection and analysis method for NCCA, using the museum cultural domain as case study. With the museum-centric information system, valuable information across the museum cultural domain can be obtained, and later translated to information visualization with resulting correlation statistics and reports, showing variables that give context to the performance of a museum, museums in an area, and museums in the country. The museum information system may serve as the information system framework for other cultural domains.",60071464,De La Salle University-Manila,Manila,Philippines,"['1712', '1709', '1707', '1705']",23.5,0.07478354978354977,0.17002164502164505,1,0.09316770186335403,0.037267080745341616,0.2929936305732484
40,40,40,Fake news classification based on subjective language,"While many works investigate spread patterns of fake news in social networks, we focus on the textual content. Instead of relying on syntactic representations of documents (aka Bag ofWords) as many works do, we seek more robust representations that may better differentiate fake from legitimate news. We propose to consider the subjectivity of news under the assumption that the subjectivity levels of legitimate and fake news are significantly different. For computing the subjectivity level of news, we rely on a set subjectivity lexicons built by Brazilian linguists. We then build subjectivity feature vectors for each news article by calculating the Word Mover?fs Distance (WMD) between the news and these lexicons considering the embedding the news words lie in, in order to classify the documents. The results demonstrate that our method is more robust than classical text classification approaches, especially in scenarios where training and test domains are different.",60030074,Universidade Federal de Minas Gerais,Belo Horizonte,Brazil,"['1712', '1709', '1707', '1705']",24.66666666666667,0.07948717948717947,0.5974358974358973,1,0.1165644171779141,0.03067484662576687,0.28484848484848485
41,41,41,Pose estimation of complex human motion,"In this paper, a human body pose estimation method based on skeleton matching is proposed. In the process of human body pose skeleton matching, we obtain the key point feature information of the human body by performing CNN operation on the input image: The joint point heat map, and the joint point according to the specific connection rules are connected to form a human skeleton. This method is not only suitable for image data, but the accuracy of human skeleton matching after inputting video data is also verified.",60022281,Beijing University of Technology,Beijing,China,"['1712', '1709', '1707', '1705']",29.33333333333333,0.06111111111111112,0.3750000000000001,1,0.10416666666666667,0.020833333333333332,0.17708333333333334
42,42,42,Knowledge graph of university campus issues and application of completion methods,"Contemporary societies face many urban issues. To address these issues, governments, corporations and individuals should disclose and share their related statistical and sensory data. However, existing published data appear in various formats and contain defects. Therefore, few problems have been solved using these data. In this research, we sought to address this problem, by considering a university campus as a microcosm of society, designed data integration schema, and consolidated data into a knowledge graph.We then, applied and modified existing completion methods. In particular, regarding the bicycle environment,we trained our knowledge graph and evaluated it with the conventional method and our proposed derivative method, respectively. Using approximately 650 parking data with various dates and times, our method correctly estimated 54.5 more bicycles than the conventional method by comparing each time's mean absolute error.",60032315,University of Electro-Communications,Chofu,Japan,"['1712', '1709', '1707', '1705']",18.857142857142858,0.02234126984126984,0.4001190476190476,1,0.16666666666666666,0.0,0.34415584415584416
43,43,43,Exploiting blockchain and smart contracts for data exploration as a service,"Digital transformation and the adoption of ICT technologies in the factory of the future are growing faster and faster. In particular, data exploration methods and techniques are enabling the development of data-intensive Remote Monitoring Services for anomaly detection and predictive maintenance purposes. Remote Monitoring Services involve different actors across organizations. The Original Equipment Manufacturer explores high volume of data collected by sensors on the monitored machines to provide anomaly detection and predictive maintenance services. Insurance agencies may provide support to sustain maintenance costs. Spare parts suppliers can schedule the delivery of mechanical parts required for maintenance interventions. In this scenario, trust among participants becomes a critical issue. On the one hand, providers of anomaly detection and predictive maintenance services as well as insurance agencies must trust the way machines have been used by collecting and analysing sensors data. On the other hand, owners of monitored machines must trust the use of collected data to implement services, based on which maintenance costs are calculated. The goal of this paper is to leverage blockchain and smart contracts to ensure the required level of trust when implementing data exploration for Remote Monitoring Services. Events occurring on the monitored machines are stored as transactions in a blockchain-based system, to ensure non repudiation. Moreover, trust-demanding services are implemented as smart contracts, to guarantee the required level of trustworthiness among participants. The approach is integrated with a tool for data exploration in the digital factory, and has been validated taking into account performances and cost requirements.",60015300,Università degli Studi di Brescia,Brescia,Italy,"['1712', '1709', '1707', '1705']",19.23076923076923,0.05037414965986396,0.3863605442176872,1,0.1510791366906475,0.04316546762589928,0.3602941176470588
44,44,44,Target-topic aware Doc2Vec for short sentence retrieval from user generated content,"This paper proposes a new method of supplementing the context of short sentences for the training phase of Doc2Vec. Since CGM (Consumer Generated Media) sites and SNS sites become widespread, the importance of similarity calculation between a given query and a short sentence is increasing. As an example, a search by the query ""sad"" should find actual expressions such as ""I needed a handkerchief"" on a movie review site. Doc2Vec is one of the most widely used methods for vectorization of queries and sentences. However, Doc2Vec often exhibits low accuracy if the training data consists of short sentences, because they lack context. We modified Doc2Vec with the hypothesis that other posts for the same topic (i.e. reviews for the same movie in online movie review sites) may share the same background. Our method uses target-topic IDs instead of sentence IDs as the context in the training phase of the Doc2Vec with the PV-DM model; this model estimates the next term from a few previous terms and context. The model trained with item IDs vectorizes a sentence more accurately than a model trained with sentence IDs. We conducted a large-scale experiment using 1.2 million movie review posts and a crowdsourcing-based evaluation. The experimental result demonstrates that our new method achieves higher precision and nDCG than previous Doc2Vec variants and traditional topic modeling methods.",60012461,Aoyama Gakuin University,Tokyo,Japan,"['1712', '1709', '1707', '1705']",20.181818181818183,0.03184974747474748,0.3573232323232323,1,0.10276679841897234,0.05533596837944664,0.32926829268292684
45,45,45,On efficiently storing huge property graphs in relational database management systems,"Graph structured data can be found in an increasing amount of use-cases. While there exists a considerable number of solutions to store graphs in NoSQL databases, the combined storage of relationally stored data with huge graph structured data within the same relational database system is not well researched.We present a relational approach for storing and querying huge property graphs by combining NoSQL features, provided by nearly any state-of-the- A rt database system, and an adjacency table approach. Our approach is optimized for read-only queries but also performs well on update queries. Through an empirical evaluation we show that we achieve a 10 times higher throughput than previous works on a graph with up to 650 million edges. This way, we can use all the advantages of full-fledged relational database systems and seamlessly integrate classical relational data with graph-structured data in an efficient way.",60014151,Universität Passau,Passau,Germany,"['1712', '1709', '1707', '1705']",28.6,0.15694444444444447,0.37847222222222215,1,0.14457831325301204,0.030120481927710843,0.28289473684210525
46,46,46,Ordered tree decomposition for HRG rule extraction,"We present algorithms for extracting Hyperedge Replacement Grammar (HRG) rules from a graph along with a vertex order. Our algorithms are based on finding a tree decomposition of smallest width, relative to the vertex order, and then extracting one rule for each node in this structure. The assumption of a fixed order for the vertices of the input graph makes it possible to solve the problem in polynomial time, in contrast to the fact that the problem of finding optimal tree decompositions for a graph is NP-hard. We also present polynomial-time algorithms for parsing based on our HRGs, where the input is a vertex sequence and the output is a graph structure. The intended application of our algorithms is grammar extraction and parsing for semantic representation of natural language. We apply our algorithms to data annotated with Abstract Meaning Representations and report on the characteristics of the resulting grammars.",60027165,University of Rochester,Rochester,United States,"['1706', '1702']",24.83333333333333,0.03333333333333333,0.26666666666666666,1,0.10303030303030303,0.048484848484848485,0.2608695652173913
47,47,47,Estimating the Probability of a Checksum Error in a Message,"Abstract: In this paper, we consider some probability-theoretical models of information distortion at the message level. The checksum (CS) distributions typical of TCP-type protocols are investigated. As an addition operator in the CS, bitwise coordinate addition and binary addition with carryover are considered. For the distortion models described, asymptotic estimates of CS error probabilities are obtained at a small distortion probability. These asymptotic estimates can be useful for messages with long segments.",60020513,National Research University Higher School of Economics,Moscow,Russian Federation,"['1712', '1711']",14.4,-0.041666666666666664,0.325,1,0.06896551724137931,0.04597701149425287,0.40963855421686746
48,48,48,Multi-level up-sampling network for infrared ship saliency object detection,"Deep convolutional neural networks have been widely used for saliency detection. However, most of the previous works focus on the visible light image. In this paper, there are mainly two contributions. First, we propose a new architecture named Multilevel Up-sampling Network (MLUNet) for infrared (IR) ship object saliency detection. Specifically, the architecture of MLUNet is an Encoder-Decoder like network embedded with subtraction feature filtering module (SFFM). The encoder uses the DenseNet like architecture, and the decoder part use two upsampling methods, which are deconvolution and sub-pixel convolution. SFFM is a feature subtraction module which is in charge of feature filtering. In our proposed MLUNet, SFFM is embedded after each convolution and deconvolution block. Secondly, we construct an IR ship object image dataset for saliency detection. This dataset includes 3845 IR images and ground-truth images with different backgrounds and different objects. Experimental results show that our method outperforms the state-of-the-art methods in terms of regional evaluation measures.",60022281,Beijing University of Technology,Beijing,China,"['1712', '1709', '1707', '1705']",14.181818181818182,0.10719696969696972,0.4073232323232324,1,0.07179487179487179,0.07179487179487179,0.4419889502762431
49,49,49,Artificial musculoskeletal actuation module driven by twisted and coiled soft actuators,"Skeletal muscles produce contractile motions and a couple of skeletal muscles antagonistically arranged are required to create bidirectional active movements. The musculoskeletal system is mainly composed of two skeletal muscles, joint, bones and tendons, and thus, a joint performs active bidirectional rotations. Likewise, twisted and coiled soft actuator (called TCA in this study) exhibits only unidirectional actuation, and two TCAs in antagonistic structure can produce bidirectional active motions. However, the TCA exhibits characteristics similar to that of tension coil spring, and it diminishes the available force and displacement from two TCAs in the antagonistic structure. In this study, a dual spiral pulley is proposed to overcome the limitations of TCAs. In the first, the artificial musculoskeletal actuation module (AMAM) is fabricated by integrating two spandex-based TCA (called STCA in this paper) bundles with the dual spiral pulley. The AMAM is experimentally tested, and its feasibility is validated. In addition, a robotic arm was developed with the AMAM, and successfully demonstrated full biceps curl and triceps kickback motions.",60007511,Sungkyunkwan University,Jongno-gu,South Korea,['1711'],20.875,0.03627450980392157,0.5745098039215687,1,0.12755102040816327,0.04591836734693878,0.38144329896907214
50,50,50,Prevention of DoS Attacks by Predicting the Values of Correlation Network Traffic Parameters,"Abstract: The authors propose an approach for the prevention of network denial of service attacks, which is based on predicting the values of the multiple correlation coefficients of the detail coefficients of the discrete wavelet transform of network traffic parameters.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1711']",40.0,0.0,0.0,1,0.06976744186046512,0.023255813953488372,0.2558139534883721
51,51,51,Named entity recognition using point prediction and active learning,"Named entity recognition (NER) research has been spreading into specialty domains. A specialty domain corpus is smaller than a general domain corpus. Moreover, annotating a specialty domain corpus is more expensive than annotating a general corpus. Therefore, in this paper, we introduce a model that uses point-wise prediction and active learning to achieve a high extraction performance even in a small annotation corpus. We demonstrate the effectiveness of our approach through a simulation of active learning.",60014256,University of Tsukuba,Tsukuba,Japan,"['1712', '1709', '1707', '1705']",15.2,-0.028518518518518512,0.5377777777777778,1,0.09090909090909091,0.03409090909090909,0.2441860465116279
52,52,52,A simulation model demonstrating the impact of social aspects on social internet of things,"In addition to seamless connectivity and smartness, the objects in the Internet of Things (IoT) are expected to have the social capabilities-these objects are termed as ""social objects"". In this paper, an intuitive paradigm of social interactions between these objects are argued and modeled. The impact of social behavior on the interaction pattern of social objects is studied taking Peer-to-Peer (P2P) resource sharing as an example application. The model proposed in this paper studies the implications of competitive vs. cooperative social paradigm, while peers attempt to attain the shared resources/services. The simulation results divulge that the social capabilities of the peers impart a significant increase in the quality of interactions between social objects. Through an agent-based simulation study, it is proved that cooperative strategy is more efficient than competitive strategy. Moreover, cooperation with an underpinning on real-life networking structure and mobility does not negatively impact the efficiency of the system at all; rather it helps.",60078194,"City University of Science &amp; Information Technology, Peshawar",Peshawar,Pakistan,"['1712', '1709', '1707', '1705']",19.375,0.09935897435897437,0.21602564102564104,1,0.08602150537634409,0.016129032258064516,0.3390804597701149
53,53,53,The synergy of simulation and time series forecasting for live performance testing of smart buildings,"Differences in requirements for reliability in buildings imply the different needs for calculation of expected building behaviour. In this paper we examine four techniques for calculating expected behaviour of buildings. Two of them are simulation techniques, namely, a white box EnergyPlus model and a æ static tool as per the requirements of the Danish government. The other two are machine learning techniques, namely an ARIMA model, and an long short-term memory artificial recurrent neural network, used in deep learning. We compare and contrast these four techniques based on their accuracy of forecast, as well as execution time to forecast a new data point. Furthermore, we provide an algorithm for selection of forecasting technique based on terms such as availability, accuracy, and execution time requirements, to facilitate real time threshold generation in light of building performance testing.",60019160,Syddansk Universitet,Odense,Denmark,"['1712', '1709', '1707', '1705']",22.66666666666667,0.02010489510489511,0.4945804195804195,1,0.09090909090909091,0.006493506493506494,0.24342105263157895
54,54,54,Pulmonary tuberculosis detection using deep learning convolutional neural networks,"Tuberculosis (TB) is classified as one of the top ten reasons for death from an infectious agent. This paper is to investigate the accuracy of two methods to detect Pulmonary Tuberculosis based on the patient chest X-ray images using Convolutional Neural Networks (CNN). Various image preprocessing methods are tested to find the combination that yields the highest accuracy. Moreover, a hybrid approach using the original statistical computer-aided detection method combined with Neural Networks was also investigated. Simulations have been carried out based on 406 normal images & 394 abnormal images. The simulations show that a cropped region of interest coupled with contrast enhancement yields excellent results. When further enhancing the images with the hybrid method even better results are achieved.",60002397,University of South Africa,Pretoria,South Africa,"['1712', '1709', '1707', '1705']",17.142857142857142,0.315625,0.55,1,0.13970588235294118,0.07352941176470588,0.38636363636363635
55,55,55,Analysis of high-value reviews based on sentiment,"When people use online shopping, they often refer reviews which are written about the products. They can understand the product more deeply by reading the reviews. The review has a star rating that shows what other people think about the product. The star rating is not always appropriate for the evaluation of the product. There are so many reviews and it is difficult to find the review that affects the users' willingness to buy. We call such review ""high-value review"". Our proposed high-value review does not depend on the number of star ratings. The high-value review is that people find useful information when they read the review and they think it is a good review. In this paper, we investigate the relation between high-value reviews and their sentiment of clause based on four hypotheses. Our analyzing sentiment is three- A xis which are positive/negative/neutral. Finally, we extract the characteristics of high-value reviews from the results of our investigate.",60032407,Chiba Institute of Technology,Narashino,Japan,"['1712', '1709', '1707', '1705']",14.363636363636365,0.1875,0.5375,1,0.1111111111111111,0.005291005291005291,0.28
56,56,56,Development of IoT monitoring device and prediction of daily life behavior,"In this study, we developed an Internet of Things (IoT) monitoring device to monitor over the people inside a room.We collected sen-sor data at a specific location using the device. Based on the data, we tried to predict the behavior of the person at that location. Mon-itoring and predicting human daily behavior is trivial task. Most of the research on monitoring and predicting daily life behavior are based on the data available from smart home [7] [16] [17]. But smart home is expensive compare to normal home, as different kind of sensor are attached in the room and have more facilities. So, we developed a low cost IoT monitoring device and predict the daily life behavior of human from the sensor data taken from the device.We can extract information from the daily life behavior and share it with the family living in distant places.",60023499,"University of Hyogo, Kobe",Kobe,Japan,"['1712', '1709', '1707', '1705']",24.0,0.10892857142857143,0.3555357142857142,1,0.12941176470588237,0.01764705882352941,0.2716049382716049
57,57,57,Remote sensing and time series data fused multimodal prediction model based on interaction analysis,"With the rapid development of the times, human's life is becoming more and more modern, helping people experience surrounding environment better. People can see attractive scenery, hear marvelous voice, smell fragrant flavor, touch soft objects and taste delicious food. All these feelings can be generalized by 'Modality'. As there are heterogeneous modalities, the way to learning from multiple such modalities become an emerging research topic. Multimodal machine learning has a wide range of applications while it still has many challenges. Challenges can be included in five categories: Representation, Translation, Alignment, Fusion, Co-learning. In this paper, we focus on the representation and fusion problem of multimodal and solve a practical problem of urban functional area classification. In this paper, we propose a scalable interaction model based on Squeezeand-Excitation block to fuse image modality from remote sensing images and temporal modality from user visit sequence. Crucially, our model produces improvements over typical multimodal methods.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1709', '1707', '1705']",16.88888888888889,0.28796296296296303,0.5111111111111111,1,0.12637362637362637,0.04395604395604396,0.3107344632768362
58,58,58,A crawling method with no parameters for geo-social data based on road maps,"Researchers must crawl geo-social data to analyze and visualize geo-social data. A conventional method to exhaustively crawl geosocial data is based on a grid. The crawler divides a specified area into a grid and uses the center coordinates of each cell to query databases using APIs. However, there is a difficult problem when using the grid-based method. It is that researchers cannot estimate the optimized grid size to exhaustively crawl geo-social data in advance because the optimized grid size depends on data density owing to geographical characteristics of an area. We focus on the fact that geo-social data are dense along roads. Thus, we propose a method based on road maps to exhaustively crawl geo-social data. We demonstrated that our method can crawl geo-social data by using almost the same number of queries compared to the crawler with an optimized grid size.",60028385,Okayama University of Science,Okayama,Japan,"['1712', '1709', '1707', '1705']",17.75,-0.18571428571428567,0.3955357142857143,1,0.15568862275449102,0.04790419161676647,0.2875816993464052
59,59,59,Your body signals expose your fall,"Fall is a common cause of severe injuries that may lead to irreversible body damage and even death. A real-time fall monitoring system can reveal a fall in time for timely medical aid to a victim. This is particularly important in the context of mobile healthcare. Fall detection with most contemporary wearable devices relied solely on acceleration signals, often not flexible and robust enough. In this paper, we propose to deploy body signals in a multi-modality approach. Besides the common acceleration signals, we also make use of physiological signals returned by wearable devices for multiple modalities. Fall detectionwould not fail easily even if some acceleration signals become ineffective. Our experiment results indicate that we are able to attain an accuracy of more than 96%. An in-depth evaluation demonstrates that physiological signals can contribute in distinguishing falls from actions generating similar acceleration signals, such as jumps, sit-downs and walking-downstairs.",60008928,Hong Kong Polytechnic University,Kowloon,Hong Kong,"['1712', '1709', '1707', '1705']",16.444444444444443,0.13833333333333336,0.425,1,0.12138728323699421,0.005780346820809248,0.3006134969325153
60,60,60,"Fully informed vulnerable road users: Simpler, maybe better","Vulnerable Road Users (VRUs) are all those with an increased vulnerability on the road, in particular non-motorised ones. Until now, the emphasis has been in politics more focused on drivers, vehicles and infrastructures. However, recent developments show a shift in other directions, with researchers now devoting efforts to improve VRUs' safety. Hence, this work focuses on pedestrian walking and crossing behaviour, attitudes, motivations and habits, being grounded on an approach to Knowledge Representation and Reasoning centred on logic programming, which establishes a formal logical inference engine that is complemented with an Artificial Neural Network line to computation.",60029257,University of Évora,Evora,Portugal,"['1712', '1709', '1707', '1705']",24.25,-0.04404761904761905,0.4583333333333333,1,0.10344827586206896,0.06896551724137931,0.45614035087719296
61,61,61,Model for Identifying Cyber Threats to Internet Information Resources,"Abstract: In this paper, we discuss the construction of a model for protecting information resources based on new approaches to active search, unified investigation, and response to cyber threats. The process of identifying cyber threats is based on search prediction methods interconnected with the cyclic nature of the behavioral activity of users of network resources.",60108589,"A.F. Mozhaisky Military Space Engineering Academy, Saint Petersburg",Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1711']",27.5,0.001515151515151511,0.5272727272727272,1,0.09836065573770492,0.03278688524590164,0.3114754098360656
62,62,62,Improving precision in IR considering dynamic environments,"Much of the research in Information Retrieval (IR) is devoted to studying the improvement of personalized results for specific users in a static environment. Nevertheless, few approaches take advantage of collective past searches in a dynamic context where the number of documents is increased according with the passage of time. In this paper, we present an on-line probabilistic algorithm, which uses the collective past searches in a dynamic context to answer static and dynamic queries. Several experiments were carried out with the aim of evaluating the effectiveness of our algorithm. The algorithm's results were compared with the cosine measure. Following the Cranfield paradigm, simulated datasets were used in the experiments. Final results show that it is possible to improve effectiveness in a dynamic context.",60023195,Universidad del Bio Bio,Concepcin,Chile,"['1712', '1709', '1707', '1705']",17.714285714285715,0.03125,0.3432291666666667,1,0.12142857142857143,0.03571428571428571,0.3188405797101449
63,63,63,Reverse-transliteration of Hebrew script for entity disambiguation,"JudaicaLink is a novel domain-specific knowledge base for Jewish culture, history, and studies. JudaicaLink is built by extracting structured, multilingual knowledge from different sources and it is mainly used for contextualization and entity linking. One of the main challenges in the process of aggregating Jewish digital resources is the use of the Hebrew script. The proof of materials in German central cataloging systems is based on the conversion of the original script of the publication into the Latin script, known as Romanization. Many of our datasets, especially those from library catalogs, contain Hebrew authors' names and titles which are only in Latin script without their Hebrew script. Therefore, it is not possible to identify them in and link them to other corresponding Hebrew resources. To overcome this problem, we designed a reverse-transliteration model which reconstructs the Hebrew script from the Romanization and consequently makes the entities more accessible.",60003027,Hochschule der Medien,Stuttgart,Germany,"['1712', '1709', '1707', '1705']",21.142857142857142,0.06813725490196078,0.4715686274509803,1,0.08333333333333333,0.02976190476190476,0.2621951219512195
64,64,64,A privacy-preserving similarity search scheme over encryptedword embeddings,"Recent evolution in cloud computing platforms have attracted the largest amount of data than ever before. Today, even the most sensitive data are being outsourced, thus, protection is essential to ensure that privacy is not traded for the convenience provided by cloud platforms. Traditional symmetric encryption schemes provide good protection; however, they ruin the merits of cloud computing. Attempts have been made to obtain a scheme where both functionality and protection can be achieved. However, features provided in existing searchable encryption schemes tend to be left behind the latest findings in the information retrieval (IR) area. In this study, we propose a privacy-preserving similar document search system based on Simhash. Our scheme is open to the latest machine-learning based IR schemes, and performance has been tuned utilizing a VP-tree based index, which is optimized for security. Analysis and various tests on real-world datasets demonstrate the scheme's security and efficiency on real-world datasets.",60014256,University of Tsukuba,Tsukuba,Japan,"['1712', '1709', '1707', '1705']",19.0,0.14615384615384613,0.5538461538461539,1,0.13186813186813187,0.016483516483516484,0.3372093023255814
65,65,65,Measuring impact of macro economic variable on capital market: Comparative modelling approach,"The study focussed in Asian country using the extensive data set on capital market index and macroeconomic variables in India from 1999 to 2018 we examined the impact of selected macroeconomic variable on Nifty 50. During the past twenty years, there occur lot many changes in Asia and so as in Indian stock market has observed many incidence changes due to various reasons in Indian economy. The market index indicates the share market as for the macro-economic variables GDP, Bank Rate, Inflation, Industrial Production Growth Rate, Fiscal Deficit, Exports, Imports and Trade balance was used. Linear regression test was carried out, and six models were developed in which linear, synthesised and log value of Nifty 50 and selected macro-economic variables were considered and the result and analysis showed that GDP and exports are the factors which have impact on the stock market index nifty 50.",60009689,Jiwaji University,Gwalior,India,['1700'],36.25,0.090625,0.3447916666666666,1,0.09876543209876543,0.06790123456790123,0.379746835443038
66,66,66,The web-based processing speed training and remediation in psychosis,"Computerised cognitive remediation (CR) has become progressively essential to ameliorate the cognitive deficits in schizophrenia. The study aims to determine whether targeted processing speed training generalised to enhancements on global cognition, comparable, and untrained tasks for real world applications. 30 participants of young adults with first episode psychosis aged between 18 and 40 years, engaged in 15 sessions of treatment arm or general CR in a single-blinded randomised controlled trial. The Remediation of Mind (ReMind)intervention is focusing on processing speed exercises using commercial training from Lumosity, Fit Brains and other recognised exercises based on the previous software task analysis findings while the active control group received standard exercises of CR. The main outcome was cognition and the secondary outcomes were functional and clinical measures which were measured using Brief Assessment of Cognition Schizophrenia (BACS), the Positive and Negative Syndrome Scale (PANSS), and Social Functioning Scale (SFS) at baseline (T1) and post-test at week 8 (T2). Results revealed that participants who were assigned to web-based processing speed training showed a significant improvement in cognitive functioning and psychosocial including social functioning negative symptoms reduction which beneficial for recovery in processing speed and untrained skills. Targeted processing speed exercises in ReMind was feasible and promising to be implemented in Malaysia as a tool for CR in young adults to enhance cognitive performance and functionality in real-world. The selected computerised exercises with proper strategies were possibly the active ingredients that accounted for effective intervention in accelerating the functioning and generalisation in cognitive health efficiently.",60090667,"Management &amp; Science University, Malaysia",Shah Alam,Malaysia,['1700'],31.25,0.04204545454545455,0.3748376623376624,1,0.11228070175438597,0.08421052631578947,0.4121863799283154
67,67,67,Cross cultural validation and adaptation of the parsimonious version of motivated learning strategies questionnaire in the Indian context,"The present study tried to validate and adapt the 44-items parsimonious version of the Motivated Learning Strategies Questionnaire (MSLQ) developed by Jackson (2018), in the Indian Context, by comparing it with the original 81-items questionnaire prepared by Pintrich et al. (1991). The subjects of the study comprised of 1424 students belonging to the disciplines of Sciences, Commerce, Business Administration and Computer Applications (605 boys and 819 girls) at undergraduate and post graduate levels, from universities located in the three regions of the Indian state of Punjab. The goodness of fit indices used in the study are CMIN/DF, GFI, TLI, CFI, RMR, RMSEA, and lower AIC and BIC are used as the estimates of parsimony with the help of SPSS AMOS Ver.23.0. The study found that the sub-scales test anxiety, effort regulation peer learning and help seeking could not display satisfactory psychometrics and hence were eliminated. A total of 52 items from 11 sub-scales are part of the newly validated tool in the Indian context after comparing the original and parsimonious scales of MSLQ in their entirety. The shortcomings of the Cronbach’s alpha as a poor estimator of reliability are discussed and compared with the less known and more reliable greatest lower bound reliability. The implications of the research are discussed.",60094571,Lovely Professional University,Phagwara,India,['1700'],26.25,0.21088154269972448,0.5064738292011021,1,0.09795918367346938,0.11428571428571428,0.375
68,68,68,The effects of social influence factors on income tax evasion among the palestinian SMEs,"The phenomenon of tax evasion has proved to be a common challenge across both the developing and developed countries. This may be considered a vital threat to national revenue of any government, and results in fiscal deficits. In the case of the developing countries, Palestine depends heavily on the revenue from tax and funds coming from international aids in financing the national growth plan. Hence, this study aims at examining the interrelationships among tax fairness, peer influence, corruption, and income tax evasion based on the theory of Social Influence. The procedure involved a proportionate sampling of the targeted respondents, and the data collection was achieved quantitatively by means of appropriate questionnaires. The returned questionnaires were screened and only 184 were useful for analysis. The analysis of the data was done by means of Partial Least Square (PLS) software. The outcome of the data analyses revealed that both peer influence and tax fairness had a negative but significant influence. Regarding corruption, it was insignificant though was positive in relation to the evasion of the income tax. This finding implies that the income tax administration efficiency can make a maximum gain from tax collections as well as discourages tax evasion.",109178307,Palestine Ahliya University,Bethlehem,Palestine,['1700'],19.8,0.03111471861471862,0.4133658008658009,1,0.0963302752293578,0.03669724770642202,0.25688073394495414
69,69,69,"A study review on mobile ad-hoc network: Characteristics, applications, challenges and routing protocols classification","Nowadays, the innovation is growing quickly. especially gadgets like laptop, cell phone and remote sensorMobile due to its features like lightweight and mobility. Ad-hoc network is a self-configuring network that allows nodes to communicate with each other. MANET is a dynamic topology that changes when nodes move in different speed to communicate with another node. Those nodes in MANET can join and leave the network at any time. Since MANET is decentralized base, routing is considered the major issue that accrues in MANET. In this paper, a study review on MANET and its proactive, reactive and hybrid routing protocols are presented. This paper also includes the challenges of MANET and its applications.",60116157,Al-Maarif University College,Ramadi,Iraq,['1700'],14.0,-0.1359375,0.5270833333333333,1,0.11627906976744186,0.046511627906976744,0.336
70,70,70,Almost automorphic mild solutions for abstract differential equations with iterated deviating arguments,"In this paper, we shall deal the existence and uniqueness of compact almost automorphic solutions to some classes of functional differential equations in a Banach space. The sufficient conditions for existence and uniqueness of compact almost automorphic mild solutions are obtained by semigroup theory and Banach contraction principle.",60031818,Indian Institute of Technology Roorkee,Roorkee,India,['1700'],24.0,0.3333333333333333,0.5,1,0.058823529411764705,0.0392156862745098,0.23529411764705882
71,71,71,Adoption model of electronic human resource management (E-hrm) based cloud computing system for healthcare organizations,"The main thrust of this study is identifying most influential determinants that are related to managerial decision for adapting E-HRM based cloud computing system for healthcare organization. The aim of the study is to develop E-HRM adoption model based cloud computing for healthcare organizations. The model E-HRM based cloud computing system includes cloud healthcare applications, cloud services, cloud deployment, controls and solutions, and E-HRM. The proposed a conceptual model is an iterative approach and method that can help identify critical factors leading to adopt EHRM and cloud system, and control factors for mitigating EHRM and cloud system issues. There are four stages for EHRM issues based cloud computing such as electronic Human Resource Management activities, the level awareness of EHRM and cloud computing system, IT and cloud computing infrastructure, and management support system and quality for HRM. Futher, the EHRM issues related to control andsolutions methods such as technological, organizational, legal, and environmental dimension. Finally, Cloud computing areincreasingly influencingelectronic human resource management (EHRM) practices for healthcare organizations.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],23.857142857142854,0.0787878787878788,0.4393939393939394,1,0.116751269035533,0.07106598984771574,0.4021164021164021
72,72,72,On sequences of diophantine 3-tuples generated through bernoulli polynomials,"This paper deals with the study of constructing sequences of diophantine triples (a, b, c) such that the product of any two elements of the set added by a polynomial with integer coefficient is a perfect square.",60069532,"Nehru Memorial College, Puthanampatti",Puthanampatti,India,['1700'],37.0,0.5,0.75,1,0.07142857142857142,0.0,0.2857142857142857
73,73,73,Shard mapping manager for database sharing to provide high availability and fault tolerance on the cloud,"The logical split of entities or tables into an independent small portion that can be manageable with better performance and availability is high during the process which has been done appropriately. However, the strategy of portioning is made for distributing database components are made-up conceptual to perform from logical perspective and its utilization through physical and logical that is through software. One of the major developments in partitioning is sharding that act as horizontal portioning which is traditional but until it performs to be challenging during implementation due to frequent need of customer code and enhancing complexness for the application layer. The availability of elastic database tools for simplifying the shared application to create and manage over SQL database using elastic database client library. Moreover this tool is utilized for distributing database for both one shard per customer and multi shard. This paper discuss about architecture of multi-shard mapping manager and its implementation on cloud environment utilized for distributing database system to various vendors and also provide better scalability to large database, high availability and fault tolerance. Multi shard plays a major role in scattering the data among data node presented over redundant server for efficient management of Microsoft Azure cloud SQL.",60114563,"Government Arts College, Salem",Salem,India,['1700'],28.857142857142854,0.14671428571428574,0.4275714285714285,1,0.10697674418604651,0.013953488372093023,0.25118483412322273
74,74,74,An innovative green material for reducing the urban heat island surrounding PMU towards smart low carbon building and city,"In this study, a new innovative green material using waste material especially vegetable waste and their combination was developed to be used as PMU streetscape furniture. It is has been tested based on the international green material standard. In line with the deliverable of new material to be used as PMU streetscape furniture, exploratory study of combination used of waste material using vegetable waste or name as Vege-grout coating give a good promise and comply with the standard for improvement of streetscape surrounding the PMU facades. Based on the results, it is found that the best way to reduce the surface temperature of the paver block is by immersing the paver block in Vege-grout and paint mixture. Using this method, heat is reduced up to 7°C. Building information modeling (BIM) result shows reducing of heat up to 12°C from the facades of surrounding streetscape material used. The results showed an improvement in the thermal conductivity test for pavement coating based on The American Society for Testing and Materials (ASTM) describes methods for determining solar reflectance in the following standards; ASTM E 903, ASTM E 1175, ASTM C 1549 and ASTM E 1918.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],27.42857142857143,0.07626262626262625,0.2671717171717172,1,0.11926605504587157,0.08256880733944955,0.3
75,76,76,Design and development of information system for SMB II museum collection management,"This paper discusses the design and development of an information System for museum collections management to improve its performance for preserving Palembang cultural artifacts stored in Sultan Mahmud Badaruddin II (SMB II) Museum. This developed information system effectiveness to manage the museum collections where the information can be saved and retrieved by user efficiently Therefore the information can be access and utilized for service quality improvement of the museum. Hopefully, it can protect, improve understanding, and dissemination of cultural heritage as the identity of the Palembang Society.",118104248,Indo Global Mandiri University,Palembang,Indonesia,['1700'],29.0,0.10000000000000002,0.16666666666666666,1,0.14736842105263157,0.10526315789473684,0.3368421052631579
76,77,77,Electronic personalized health records [E-Phr] issues towards acceptance and adoption,"Patients self-management considered an efficient and important tool for continuous monitoring and manage health especially those with chronic disease through Electronic Personalized Health Records (e-PHR). e-PHR presenting the patient's personalized records by providing an excellent software tool for patients to monitor and manage their health care. e-PHR contain various benefits such as allowing patients to access their personalized health records at any time and anywhere via online and offline, enabling them to monitors like their blood pressure or blood glucose, manage their health and many more. However, even e-PHR contains a lot of benefits but the level of acceptance and adoption still remains medium over the world. This paper is presenting the current e-PHR issues towards acceptance and adoption.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],23.8,0.3,0.675,1,0.1056338028169014,0.09154929577464789,0.33076923076923076
77,78,78,"Comparison of vehicle detection using haar-like feature, LBP and HOG technique for feature extraction in cascade classifier","Transportation continues to increase every year. Recorded in 2018, the number of vehicles registered in Indonesia is more than 111 million. Problems such as traffic congestion and traffic accidents need to be resolved. One of the solutions implements intelligent transportation systems (ITS). ITS plays a very important role in the suitability of the traffic conditions of the vehicle. Many researchers apply the Haar-like feature, Histogram of Oriented Gradients (HOG) and Local Binary Pattern (LBP) to detect objects and vehicles. This paper describes the comparison of the applicability of the Haar-like Feature, the LBP Feature and the HOG Feature on vehicle detection. The results of the comparison of the three features are Haar-like features for vehicle detection system proves better than of using HOG features and LBP feature for vehicle detection. Its detection rate is higher than HOG and LBP where it detected 40 vehicles from the total of 42 vehicles rather by HOG and LBP with only 36 and 35 vehicles detected. In the execution process, the haar-like detection feature is faster at execution time of 14.56 s rather by HOG and LBP with the execution time only 21.36 s and 19.41 s. Haar-like features faster by 46.7% times more than HOG feature detector and Haar-like features faster 33.3% times more than LBP. Haar-like feature based detector system is the best technique for vehicle detection using cascade classifier.",60104628,State Polytechnic of Malang,Malang,Indonesia,['1700'],19.0,0.358,0.5633333333333334,1,0.06037735849056604,0.10943396226415095,0.4063745019920319
78,79,79,Life-cycle assessment (LCA) of plastic bag: Current status of product impact,"An initial research of plastic bag has been established by adopting the life-cycle assessment (LCA) method. The parameters were developed for measuring the standard plastic bag in order to identify the plastic bag impacts towards environment. The development of measurement parameters was referred to the literature review related to the life-cycle assessment method and comparisons of harmfulness of plastic bags. The FTIR analysis and OpenLCA software were applied for analysing the results. The results of this study indicated that the plastic bags manufactured by the local industries are eco-unfriendly, which the production process can jeopardise natural environment and human health system. Furthermore, some recommendations for possible improvement were made based on the findings.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],18.83333333333333,0.025,0.275,1,0.11627906976744186,0.023255813953488372,0.3089430894308943
79,80,80,Power efficient control unit design using 40nm field programmable gate array,"In today’s modern generation, people are living in a digital world where each and every thing is interconnected and communicating. This generation is living in a technology dependent world. With the enlargement of population, the resources of energy are reducing. Therefore, there is a demand of developing efficient systems. Energy efficiency is a major concern and an active research area now a day. Therefore, this paper introduces an energy efficient Control Unit Circuit implemented with Field Programmable Gate Array (FPGA) Virtex-6 and Input/output Standard This research work has not only considered the transmitted power at every transmission node but also examined the consumed processing power on every reception node to analyze the overall performance of the circuit. This CU circuit is capable enough to perform its fundamental task with low power consumption. This research work has utilized FPGA, along with the I/O Standard and found that the power consumption level for the CU of a computer's Central Processing Unit (CPU) has reduced significantly and furthermore, Stub Series Terminated Logic (SSTL) I/O Standard has been used for input and output power matching. FPGA is known for itshigh cost but based on the previous research work, it is also observed to be an efficient circuit. This work used a complete family of I/O Standard and each member’sperformance has been observed very carefully. For the coding purpose Very High Speed Integrated Circuit Hardware Description Language (VHDL) is used which is also an easy language and widely used. Simulation is performed on Xilinx ISE Design Suite and performance of the complete circuit is analyzed on X-power analyzer tool. After implementation, it is observed that the CU circuit using SSTL15 I/O Standard has consumed the least input power while on the contrary the circuit using SSTL2_II_DCI I/O Standard has utilized the highest power consumption.",60113205,"Chitkara University, Punjab",Rajpura,India,['1700'],23.0,0.03395333333333333,0.3610800000000001,1,0.09302325581395349,0.11627906976744186,0.37537537537537535
80,81,81,Physical unclonable function based design for customized digital logic circuit,"Security, area and energy efficient primitives are the fundamental blocks for empowering end-to-end contented protection in Integrated circuits (ICs). PUF is similar physical security effervescent, which uses in-deterministic dissimilarities in the course of manufacturing process, to produce a distinctive and an unclonable IC. In this paper, a digital real time delay based Intrinsic RO-PUF has been proposed to design and detect an input challenge to authenticate and to generate a response. RO-PUF design is implemented on DigilentNexys 2 FPGA and Spartan-3E FPGA boards. The PUF design is validated by means of external evaluation on FPGA by interfacing peripherals like VGA, LCD and SSD to external GPIO modules.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],21.4,0.03333333333333333,0.17380952380952386,1,0.09302325581395349,0.12403100775193798,0.42857142857142855
81,82,82,Research impediments and challenges in Indian academia: Conquering them ethically,"Research has a paramount importance in the expansion and dissemination of knowledge. In the present Indian context the academic fraternity be it the research scholars, the supervisors, the teachers-all face numerous impediments and challenges in the process of conducting and publishing a good research study. This paper throws light on the various barriers and challenges encountered by the academicians during the process of research and how these can be overcome. The paper also highlights the ethical dilemmas in research along with the problem of plagiarism and also suggests solutions with specific reference to the Indian context. The paper also discusses the Indian policy perspectives on curbing plagiarism. The present paper describes the results of the study conducted on 50 research scholars and 15 supervisors in order to find out the various challenges encountered in conducting and publishing a research study and what impact it had on the required research output. The descriptive survey method was utilized in this study. The researcher – made instrument comprising the questionnaire containing both open and closed ended questions was administered to the academicians. The study established that various impediments such as lack of competence in academic writing skills, lack of funds and many others that hinder the conduction and publication of a good research study. The study recommends solutions and measures that can be taken up in an endeavour to overcome the challenges and conduct good quality research.",60076774,"Amity University, Noida",Noida,India,['1700'],23.4,0.1722222222222222,0.37916666666666665,1,0.1285140562248996,0.0,0.25101214574898784
82,83,83,Design guidelines of tangible interaction learning model for children with dyslexia,"Children with dyslexia are synonymous with having difficulties in learning to read. Dyslexic children commonly encounter visual, auditory and kinesthetic deficits which cause an inability to process the information in their brain despite no visual, hearing and motor impairments. The current teaching approach used is through traditional instruction such as books, flashcards, boards and many more. However, children with dyslexia require a multisensory approach which allows them to utilize all their senses, be it eyes, ears, voice, and tactile, in learning. Tangible interaction has gained a reputation as an alternative approach to bring richness and intuitiveness of a multimodal using physical tangible objects while interacting with a digital space. In order to provide the appropriate tools for dyslexic children in learning, design guidelines of tangible interaction learning model are established and supported by theories and other related works in the dyslexia domain. In regards to the design guidelines, an initial tangible interaction prototype called DisleksiaBelajar 3dT is going to be developed for children with dyslexia. The prototype may serve as an interactive and supportive tool for dyslexic children to learn Malay language.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],22.75,0.1046875,0.3667410714285714,1,0.11386138613861387,0.024752475247524754,0.297029702970297
83,84,84,Constructing a model of risk mitigation for anti software ageing during software maintenance,"Software will normally undergo an inevitable ageing process during its lifecycle. Most often, software rejuvenation is mainly proposed by past researchers to delay software ageing caused by errors accumulation from long running software execution. This method addresses software ageing from software dependability perspective.However little attention has been paid to address software ageing from software engineering perspective, which caused by failures to modify the software or from the results of software changes.Changes are vital to enable software accommodating new functions, ensuring its survivability towards new environment but pioneer in software ageing field argued that the results of software changes could influence software ageing. Hence, this motivate the study to develop a method to tackle software ageing from software engineering perspective to reduce risks impact before it become apparent. This paper discusses on the development of conceptual model of risk mitigation for anti software ageing during software maintenance through concepts gained from literature study. The design of the conceptual model illustrates the relationships between related concepts through concept mapping. It is significant to portray preliminary work in the study thus provide direction for further work to examine the relationships between concepts.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],27.0,0.08049242424242424,0.5048160173160172,1,0.1715686274509804,0.0,0.35
84,85,85,The intellectual concept and aesthetical values of recycled furniture design (Using pallets wood remnants and glazed ceramics decorated with islamic ornaments as a model),"The idea of recycling various materials and industrial wastes, especially the ""pallet"" for the manufacture of furniture comes within the modern design trends that seek to achieve sustainability in the design and manufacture of furniture. Therefore, the problem of research is not to shed light on the technical and aesthetic values of the design results that depend on the recycling of various materials, especially ""pallet"" that decorate the glazed ceramic tiles with Islamic decoration units, as they reinforce the intellectual direction of modern design which aims to achieve sustainability by design results. The research aims to highlight the artistic and aesthetic values enjoyed by furniture manufactured from industrial waste ""pallet"", by decorating them with Islamic decoration units implemented on glazed porcelain pieces that have been combined with furniture pieces. The most important results of the research, the pieces of furniture that were designed and manufactured from industrial waste and various materials enjoy a unique distinction from other pieces of furniture manufactured from new materials and wood, because it combines the modernity of the present and the ancient past and sustainability design.",60072733,An-Najah National University,Nablus,Palestine,['1700'],45.25,0.1204216073781291,0.4817193675889328,1,0.12121212121212122,0.0,0.25252525252525254
85,86,86,Role of procedural justice and organizational trust on organizational citizenship behavior among IT employees,"The purpose of this research is to find the influence of Procedural Justice (PJ) and Organizational Trust (OT) on Organizational Citizenship behaviour (OCB). The organizational citizenship behaviour has three sub-components such as Helping Behavior (HB), Sportsmanship and Civic Virtue (CV). Procedural justice is considered as a mode to gain the trust between the organization and the employees by stepping towards the approaches that help to build and maintain trust. From the literature, it is inferred that both sales representatives and sales managers the cooperation among organizational trust, Procedural Justice and Organizational Citizenship Behavior is highly related. In the present study, there are a total 185 respondents from the various retail sector and the researcher mainly focused on to find out the relationship between Procedural Justice, Trust and Organizational Citizenship Behavior of Sales managers of the various retail sector. From the regression test it can be inferred that there is a high correlation between Procedural justices and Organizational Citizenship Behavior, and between the Organizational trust and Organizational Citizenship Behavior. Also, Regression test was done to check the relationship of procedural justice and organizational trust with the three elements of the organizational Citizenship behaviour individually. The result obtained from the regression test explains that there is a high correlation between the Procedural justice and helping behaviour, moderate correlation between the Procedural justice and sportsmanship and finally, good correlation between the Procedural justice and Civic virtue. Also, from the test, it is inferred that there is a good correlation between the Trust and helping behaviour, moderate correlation between the Trust and sportsmanship and a good correlation between the Trust and Civic virtue.",60080427,Manipal Institute of Management,Manipal,India,['1700'],29.88888888888889,0.17244444444444446,0.510888888888889,1,0.06291390728476821,0.1291390728476821,0.3433333333333333
86,87,87,Artificial neural networks and backward propagation model for weather forecasting and monitoring in real-time environment - A review,"Weather Forecasting rather than a binary decision is a statistical measure. In this paper, the authors have studied towards proposing a smart weather-monitoring model as it has become a necessity in today’s scenario. The proposed model checks the parameters such as max and min temperature and precipitation for a designated period of time and is monitored. An accurate and smart approximation based on the available data is accomplished using machine learning paradigms. A measure of more than 89% accuracy is obtained, depending upon the quality of data values. Weather Monitoring and Forecasting helps to determine the future conditions of the atmosphere. We have studies and prepared this paper on weather forecasting and monitoring by making use of ANN (Artificial Neural Network) methodology. We are focusing and concentrating on the implementation of a data-centric model using the various data mining methods and techniques available. Weather represents a process of constant changing and non-linear process and advanced methods of artificial neural network (ANN) can take care of such processes. The data mining methodology in collaboration with upcoming network of neurons which gives meaningful information for weather monitoring and forecasting which further reduces its cost as compared to other monitoring and prediction models.",114207552,CGC College of Engineering,Mohali,India,['1700'],20.0,0.10575396825396824,0.5362433862433862,1,0.12946428571428573,0.03125,0.319634703196347
87,88,88,Intrude buzzer system for trees in forest using wireless sensor network based on IOT,"Numerous days we are perusing in the daily papers about pirating of the trees like sandal, Sagwan and so on. These trees are expensive and in addition less accessible on the planet. These are use in the restorative sciences and beautifying agents. In light of immense measure of cash engaged with offering of such tree woods heaps of episodes are going on of cutting of trees and their pirating. To confine such carrying and to spare the woods around the world some preventive measures should be conveyed. We are growing such a framework which can be utilized to limit this carrying.",60112727,"Sri Venkateshwara College of Engineering, Bengaluru",Bengaluru,India,['1700'],16.833333333333336,-0.044696969696969686,0.5219696969696971,1,0.12962962962962962,0.009259259259259259,0.2777777777777778
88,89,89,Image restoration on fusion of mammographs and MRI breast images using dual tree complex wavelet transform,"The developments in the medical field is remarkable in recent days due to the innovation in medicines, diagnosis of diseases at an early stage and computer aided applications for identifying the exact location of the affected part. The disease is also increasing day by day along with the medical developments. In those diseases, the most life threatening diseases is the cancer. In olden days, the cancer is mostly of blood cancer but there are different types of cancers like blood, stomach, colon, cervical and breast cancer. Among these cancers, the less life threatening is the breast cancer, which can be cured by medicine at early stage and surgery in the final stage of the cancer. This work is to improve the diagnosis of breast cancer by fusion method. The breast cancer is diagnosed using MRI scan and X-ray. These image modalities have different information of the breast. The previous work used the registration approach on these modalities to improve the information of the cancer from the images using intensity gradient approach and scalar gradient approach. In this proposed work, the images will be fuse to extract both the lesion and inter bone of the breast. The fusion process will perform by pre-processing steps like gray-scale conversion, and noise removal process. The pre-processed image will be fuse by using the dual tree complex wavelet transform. It has both the MRI and X-ray information of the breast. The geometric correction is applied to the fused image for restoration. This fused image is extracted with more information/property. The fused image will be evaluated with the help of following metrics like entropy, mean and variance to ensure the information and image quality is preserved in the fusion approach.",102030704,R.V.S. College of Arts and Science,Coimbatore,India,['1700'],17.75,0.08574561403508772,0.3866228070175439,1,0.09597523219814241,0.01238390092879257,0.22186495176848875
89,90,90,Detect the phishing websites in the contex of internet security by using machine learning approach,"For malicious use to get the sensitive and private information like detail of credit card, username, detail of bank account, password the fraudulent attempt is known as phishing. It can say that in of phishing can be consider as the today's most popular cybercrime. Many areas like financial institution, cloud storage, webmail, online payment sector, file hosting etc. where phishing attack can happen. More than any other is the phishing attacker mainly targeted the online payment sector and webmail sector. Machine learning, heuristic, visual similarity and blacklist are known as some anti-phishing techniques. Among these anti phishing techniques the blacklist is very easy to implement but some time for new phishing attacks it may fail to detect. This paper studies the effect of phishing and detects the phishing attack using machine learning algorithm [1].",60007998,"Maulana Azad National Urdu University, Hyderabad",Hyderabad,India,['1700'],16.75,0.1877972027972028,0.4721445221445221,1,0.14743589743589744,0.00641025641025641,0.33766233766233766
90,91,91,Deployment of gross profit loss for attenuating time loss impact in automotive industries,"Time Loss (TL) occurs along the production processes that have a significant effect on productivity and able to influence the monetary loss in the manufacturing industry. TL becomes critical when an assembly process involves a high product variety in the same production line. The aim of this study is to provide a measure for Gross Profit Loss (GPL)based on Production Capacity Loss (PCL) result. Then, the equation for Production Capacity Loss (PCL) was derived based on the structure of Time Loss Measures (TLM) components known as: (i) Non-valued Changeover Time (NVCOT), (ii) Inefficient Processing Time (IPT), (iii) Unnecessary Overtime (UOT), and (iv) Non-conformance Time (NCT). The TLM had been developed through a thorough literature study on manufacturing operations. In economic view, PCL can be converted into Gross Profit Loss (GPL). Finally, the GPL equation were validated by using case study at five automotive manufacturing companies in Malaysia. The results of the case study show that GPL did occur through the four TLM components that caused an amount of PCL. In conclusion, GPL can be used as a measuring tool for the manufacturing companies to monitor continuously the operational performance of the manual assembly process and semi-auto assembly process in monetary unit.",124036336,Chancellory,Malacca,Malaysia,['1700'],22.33333333333333,0.01541666666666666,0.5304166666666666,1,0.09163346613545817,0.16334661354581673,0.46963562753036436
91,92,92,"Ground water impact on the building materials of the king Seti I funerary temple in the west bank of Luxor, Egypt","The funerary temple of King Seti I in Qurna is located at the west bank of Luxor, the temple is affected by both external and internal Deterioration Factors. Scientific tests and analysis were carried out on samples of salts and building materials of the temple, including optical microscopy, which showed the dissociation between the mineral grains of the stones building, as well as the erosion in the surface layers, gaps and losses in mineral components and fine cracks. Polarized microscope (PM), scanning electron microscope which is equipped with Energy Dispersive X-rays Unit (EDX), X-ray diffraction analysis (XRD) showed sandstone in this temple is Nubian sandstone consists of quartz (SiO2 Iron oxides as a cement, clay minerals, Mica of the type of biotite K (Mg, Fe)3 (AlSi3O10) (OH)2 and Halite (NaCl). Field studies have shown that the environmental factors of dwelling houses are adjacent to the temple, as well as the agricultural lands adjacent to the temple, also the temple built of sandstone porous sedimentary rocks. Temperature and humidity changes led to the melting and re-crystallization of salts in frequent continuous cycles.",60107271,Aswan University,Aswan,Egypt,['1700'],36.2,0.12916666666666668,0.225,1,0.059907834101382486,0.11981566820276497,0.40930232558139534
92,93,93,Impact of social compliance on employee motivation: An empirical study,"The primary purpose of this study is to observe the relationship between important social compliance variables (wages & benefits, discrimination, harassment & abuse, leave & holidays, welfare facilities) and employee motivation. The present study was conducted through positivism philosophy, and by employing Herzberg Two Factor Theory for framing the hypotheses. Furthermore, the study also employed a deductive approach, explanatory research design, and a quantitative methodology. In all, 500 samples were collected from Bangladesh ready-made garment industry through self-administrated scheduled questionnaire method. In addition, the used of Smart-PLS and SPSS was used in analysing and developing the model of the present study. As such, the outcome of the analysis revealed that all five hypotheses were supported. Based on this, it is hoped that this finding will assist the policymakers, government of Bangladesh, factory owners, managers, as well as other stakeholders to formulate the succeeding policy and practice. Finally, it is recommended for further research to employ other social compliance variables, which are not included in this study.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],20.75,0.05606060606060606,0.3984848484848485,1,0.115,0.06,0.32989690721649484
93,94,94,Autonomous vehicle drive through advanced navigation marker identification and categorization system: ANMIC,"The ANMIC is a context dependent, multi perspective multilevel concept based on image capturing. The field related to autonomous vehicle among map navigation has historically been informed by knowledge from narrow functional areas. While some effort towards producing a broader perspective of the concept has been made, nonetheless, autonomous vehicle in navigation continues to be largely eclectic with little development of concept within the consensus on its conceptualization and research methodological bases. The paper proposed the method of image capturing, its categorization for run time video. MATLAB has been used to implement the concept. The paper proposes an algorithm which creates image categorization mechanism leads to detection of landmarks from run time video; vehicle navigation is further facilitated by the detected markers using optical flow approach; categorization mechanism detects the non-trivial markers by removing triviality step by step. The paper has attempted to identify categorization technique of images by proposing various trivial levels.",60094571,Lovely Professional University,Phagwara,India,['1700'],21.857142857142854,0.06964285714285716,0.4587301587301586,1,0.11904761904761904,0.011904761904761904,0.26506024096385544
94,95,95,A theoretical framework of factors contributing towards the talent management practices and employee retention in contemporary organization,This Paper deals with an appraisal of the various dimensions of talent management practices contributing towards the retention of the employees in contemporary organization. The objective of the review is to present various dimensions related to talent management practices and it relation with employee retention. Various databases are used to review the literature; 121 research papers out of 430 are thoroughly discussed in the paper to assess the contemporary meaning and relationship of various dimensions of talent management leading to sustainability. Inclusion criteria of literature are the papers showing the relationship of at least two variables; rest all were excluded from the literature. The finding of the paper clearly identifies the strong positive relationship between these variables of talent management and employee retention and its direct positive relation to effectiveness of the organization was also clearly visible. This paper shall be helpful in understanding the importance of various components of talent management from future’s point of view and for the betterment of the performance of organizations in The results of this study present a meaningful insight the information in the area of improving talent management at the workplace that increases the organizational performance.,60111704,Chandigarh University,Mohali,India,['1700'],32.16666666666667,0.08606060606060606,0.3674621212121211,1,0.09405940594059406,0.0049504950495049506,0.18226600985221675
95,96,96,Intelligent smart city enabled environmental monitoring system using internet of things,"Now-a-days Smart City enabled services are growing vastly due to its necessity and provides good quality of service to the people. A well-known and most important need of Smart City management is to maintain the environmental conditions in clean manner such as monitoring the Pollutions such as air and weather conditions as well as the most important need is to automate the home and commercial/non-commercial buildings. In the proposed system of Internet of Things (IoT) enabled environmental monitoring scheme handle all these circumstances with the help of intelligent sensors such as Temperature Monitoring Sensor, Humidity level Monitoring Sensor and CO2 Sensor. The temperature sensor is used to analyze the present temperature of an environment, in this proposed approach the temperature is monitored by using LM35 Sensor and the humidity level is monitored by using SY-HS220, which can be used in well in weather monitoring application as well and the Carbon Monoxide (CO) gas sensor detects the concentrations of CO in the air and outputs its reading as an analog voltage. These sensors are integrated working together to provide efficient environmental monitoring system in hands with Internet of Things (IoT). In this paper, a new monitoring strategy is used to prove our proposed system is better compare to all other past approaches, which is the addition of IoT over present environmental monitoring applications. By using this IoT enabled service, the sensor details can be monitored from anywhere in the world without any interruptions. This service enable the sensors to pass the data to the remote server and that can be viewed from anywhere in the world by using respective WebPages or else android applications associated with it. The proposed model is designed based on Self-Alert strategies such as: once the sensors identify any abnormal condition, which is immediately passed as an alert via SMS by using GSM module. The main concentration of this proposed system is to monitoring the pollution ratio and the appropriate actions need to taken for that as well as the data accumulated from sensors are visible to all people in the environment.",60115557,Vivekanandha College of Engineering for Women,Tiruchengode,India,['1700'],34.5,0.19992784992784995,0.4822330447330448,1,0.1279373368146214,0.07049608355091384,0.3116531165311653
96,97,97,An investigation into multi-spinning process with telescopic mandrel,"Conventional multi-stage spinning is a process used widely in manufacturing to obtain cup shape products. A proposed compound tool with telescopic mandrel was developed before to achieve the process of multi spinning at one pass, this technique still needs investigation in the area of optimization. In this research, an investigation into the effect of process parameters of the compound multi-spinning tool with telescopic mandrel was conducted. The experimental work was carried out on the center lathe machine using spinning rollers installed on a dynamometer replaced the tool post while the telescopic mandrel was mounted on the lathe chuck. The process parameters such as the rotational speed of telescopic mandrel and the feed rate of the spinning roller effect on the spinning ratio, process load, and the product quality were investigated. The experimental results showed that mandrel rotational speed and axial feed affected the process load, the spinning ratio, and the product quality.",60007948,Beni-Suef University,Beni Suef,Egypt,['1700'],25.33333333333333,-0.0061224489795918356,0.3510204081632653,1,0.1130952380952381,0.023809523809523808,0.18902439024390244
97,98,98,"An inventory model for deteriorating products under trade credit, with life time and time discounting",An inventory model has been discussed for deteriorating products under trade credit and time discounting for finite time. The deterioration rate has the form αβtß−1. Demand rate is cubic function of time. Deterioration of products is with life time.,60004880,Maharshi Dayanand University,Rohtak,India,['1700'],9.75,0.0,0.0,1,0.06976744186046512,0.0,0.3488372093023256
98,99,99,Influence of entrepreneurial creativity on competitive advantage in automobile engineering and technologies industries,"Entrepreneurial creativity is highlighted in the method in which entrepreneurs’ judgment and reacts to their industry. Minimally as, how the entrepreneurs resolve their business problems and manage them in marketplace as competitive. The importance of the research was to identify the Influence of entrepreneurial creativity on competitive advantagein automobile engineering and technologies industries. The sample frame of the study is Chennai district alone. Convenience sampling technique was adopted. The analysis found that there is influence of Knowledge spillover and technology spillover on entrepreneurial creativity in automobile industries and technologies in Chennai. There is influence of Knowledge spillover and entrepreneurial creativity on competitive advantagein automobile industries and technologies in Chennai. The analysis also found that there is positive relationship between Knowledge spillover and technology spillover. Hence it is concluded that contributed to the competitive advantage to the automobile industries and technologies. Hence, automobile industries and technologies should concentrate more on mounting these four factors encouraging to entrepreneurs.",60027171,Annamalai University,Chidambaram,India,['1700'],15.6,0.20909090909090908,0.5484848484848485,1,0.08284023668639054,0.029585798816568046,0.3136094674556213
99,100,100,Properties of fine dust adsorption matrix using rutile type of TiO2,"Background/Objectives: Air pollution by fine dust is getting worse. As the occurrence of fine dust increases, it is affecting environmental pollution and the human body. Methods/Statistical analysis: In this study, photocatalyst was used for fine dust adsorption. TiO2 was used as a photocatalyst and the mechanism of TiO2 was analyzed. Using the rutile type of TiO2 was carried out for the comparison with the anatase used in the past. The test items were strength, density, water absorption, thermal conductivity, and adsorption experiment. Findings: In this study, photocatalyst TiO2 was used for fine dust adsorption. The hardened body was manufactured using the rutile type of TiO2, The results are as follows. As the rutile increases, the density and the absorption rate decrease and the absorption rate increases. The fluidity decreases as the rutile absorbs the compounding water. As the substitution ratio of rutile increases, the strength tends to decrease. The thermal conductivity decreases as the replacement rate increases due to the occurrence of pores as the hardening progresses. As the curing progresses, the thermal conductivity decreases. When rutile was used, the catalytic action occurred while decreasing the fine dust concentration. Improvements/Applications: As a result of using TiO2 rutile, it was confirmed that the performance is lower than that of anatase. You'll have to come up with a way to outperform anatase.",60068689,Hanbat National University,Yusong,South Korea,['1700'],13.75,0.16439393939393945,0.4477272727272728,1,0.10384615384615385,0.03461538461538462,0.28346456692913385
100,101,101,Tribological and mechanical properties of hdpe reinforced by Al2O3 nanoparticles for bearing materials,"The current work focuses on improvingthe tribological and mechanical properties of high density polyethylene (HDPE) reinforced by 0.1– 0.5 wt. % of Al2O3 nanoparticles.The nano-composite specimens were prepared to the cylindrical shape and subjected to friction and wear tests using pin on disc tribometer.The specimenswere tested as counterpart and the diskwere emery paper with grit size of 1200 μm. Wear tests were done each exactly 120 sec., and the weight lossis calculated by weighing the specimens before and after the test.The hardness test was obtained by utilizing the Durometer, Shore D, hardness analyzer according to the ASTM standard D2240.It is very well noticed from the experiments that the HDPE nano-composite specimen of 0.5% wt of Al2O3gives the best tribological properties so that the friction coefficient is reduced by 11.1%.The wear rate has characterized a declining trend with increase in Al2O3.It is obvious that adding of aluminum oxide contents may be the main reason for significant improvement of hardness that reaches 9.1%.Thus, there are irrefutable improvement observed in respect of the HDPE/Al2O3 matrix.",60009750,Minia University,Minia,Egypt,['1700'],57.33333333333334,0.20516666666666666,0.4098333333333333,1,0.10204081632653061,0.0663265306122449,0.3602150537634409
101,102,102,An empirical study on consumer awareness on digital footprints,"Background: Data is the heart of any new technology, when it comes to online marketing platform, its contribution is incredible. With technology up-gradation, there is an intensive data exploitation and manipulation. The root of this data monitoring, acquiring of personal data and the online activities is through a process called data veillance. Data veillance is the base for consumer surveillance and consumer profiling, which ultimately end up with new intrusive marketing strategies. One such intrusive marketing strategy is accessing the digital footprints of the digital consumers. This paper is an attempt to highlight the level of consumer awareness based on the intrusive marketing strategy. Methodology: This empirical study focuses on the internet user who can be placed in social techno-graphic ladder for the study because only digitally literate respondent can understand the seriousness of information tracked by the marketers. A structured questionnaire was given purposively to the respondents, through both online and manual platforms. The data was analyzed through SPSS 23 version to derive further conclusions. Findings: The data collected is analyzed and projected on the multidimensional matrix. The findings of this study would help in identifying the perception of consumerunderstanding of digital footprints ensuring security in using online platforms and to protect the misuse of digital footprints. Originality and practical implication: This paper spotlights the tracking techniques through digital footprints amongst the digital users and the consumer awareness. In addition, it would enable the policy makers in framing new law for digital marketer against their intrusive strategies and implementing new law for the digital marketers.",60008648,University of Madras,Chennai,India,['1700'],19.69230769230769,0.035399449035812665,0.3265840220385674,1,0.10915492957746478,0.007042253521126761,0.29285714285714287
102,103,103,Access and authentication of IOT nodes with optimization of energy for longitivity,"Internet of Things paradigm the existence of many battery sensors on the Internet requires the design of energy efficient protocols. Source code technology saves some energy by compressing packets sent over the network, but saves money in return for less accurate representation of the data. It deals with the problem of designing effective policies for performing transport operations. In particular, extending the lifetime of the network and lowering the overall distortion of transmitted data is a matter of defining a dual purpose scheduling strategy. The communication policy of both cases is derived by considering the total and statistical knowledge of the wireless channel.",60097266,P.D.A. College of Engineering,Gulbarga,India,['1700'],20.6,0.21428571428571436,0.4404761904761905,1,0.14545454545454545,0.0,0.2545454545454545
103,104,104,The association between intranet quality and organizational performance,"Purpose The aim of this paper is to discuss on the concept of Intranet quality and organizational performance and further investigating the relationship between Intranet quality and organizational performance particularly in higher education institutions. Design/Methodology/Approach The work methodology of this paper is a discussion of the issues from a several of past literature review. Findings The relationship of Intranet quality and performance of higher education that discussed in this paper will contribute to the knowledge that is certainly limited in the literature and organizations will better understanding on how to improve their Intranet quality, thus lead to improving their performance. Originality/Value This paper adapts the System Theory by Ludwig (1956) and Knowledge Management components by Rodriguez and Edwards (2014) and will be proposed in the context of public higher education institutions in Malaysia. This proposed framework can be used as a benchmark for quality accreditation in the future.",122243993,Universiti Teknikal,Malacca,Malaysia,['1700'],29.6,0.09285714285714286,0.30845238095238103,1,0.0975609756097561,0.0975609756097561,0.2468354430379747
104,105,105,Transformational leadership and development of marketing capabilities: Mediating role of market and entrepreneurship orientation,"Failure to adapt to the rapid and broad changes in the current business environment, can negatively impact the performance of organizations. As such, organizational capabilities and processes need to be developed, extended and/or renewed. Meanwhile, marketing capabilities play a vital role in the superior performance of organizations, and their development is significantly influenced by strategic orientations as a combination of resources, behavioral patterns and value points of a business in the market. On the other hand, the necessity of continuous organizational changes in a dynamic and changing environment today is the presence of transformational leaders. Therefore, the present study tries to examine the relationship between transformational leadership, marketing capabilities and organizational performance by mediating the strategic orientations of entrepreneurship and market orientation, from the perspective of senior executives of small & medium enterprises in the food industry of Kerman Province in the first six months of 2017. The data gathering tool was questionnaire & data analysis was done by using LISREL and PLS softwares. In this regard, 200 senior executives in the studied population were selected by multistage cluster sampling. The results show that transformational leadership has significant effect on both market and entrepreneurial tendencies; but evidence suggests a lack of support for themediating role of market orientation in the relationship between transformational leadership & marketing capabilities; and confirming the indirect impact of transformational leadership on developing marketing capabilities & performance improvement merely through the entrepreneurship orientation in our studied businesses.",60027546,Payame Noor University,Tehran,Iran,['1700'],30.125,0.021813725490196074,0.4375,1,0.08396946564885496,0.022900763358778626,0.2900763358778626
105,106,106,The antecedent of customer satisfaction and its impact on customer retention in tourism as hospitality industry,"Taking a case study of tourism as hospitality industry in Lampung Province in Indonesia, we analyze the antecedent of customer satisfaction and its impact on customer retention. Using Structural Equation Model (SEM), we find that customer relationship management has a significant impact on service quality, customer satisfaction and customer retention. Moreover, the impact of service quality on customer satisfaction and the one of customer satisfaction on customer retention are aslo significant. Relying on the findings, we recommend some strategies for the government of Lampung Province, e.g. training local people to behave more friendly in welcoming domestic or international tourists, fixing all lodging facilities, creating more souvenirs with Lampung’s ornaments and developing management system adopting global changes in technology, communication and trend.",60069401,Universitas Lampung,Bandar Lampung,Indonesia,['1700'],24.2,0.2361111111111111,0.37222222222222223,1,0.0948905109489051,0.072992700729927,0.31654676258992803
106,107,107,Character transformation through sports achievement: A naturalistic study of athletes in South Kalimantan,"This research focuses on the development of sport achievement which will develop strong character in athletes. It uses qualitative approach and grounded theory as the method of the research. The findingsand results of the research are: (1) Strong character comes from five universal values; discipline, truth, individuality and self-esteem, determination, and caring. (2) Sport, as a medium to develop character, integrates character education values in the process of sport achievement development; therefore, strong character is an inclusive aspect of personality, not a secondary effect of values. (3) Transformation of strong character takes a long time; and can be done through habituation, encouraging motivation and rulereinforcement, in sport development.(4) Understanding the values of sport not only offers the value of competitive and winning spirit but also brings the value of friendship, peaceful, truth, integrity and strength; nevertheless, the lack of such understanding will weaken these values. (5) There seems to be a very close relationship between the sport achievement in wrestling with competitive and local wisdom of Banjar people. (6) Most Banjar wrestlers tend to come from families with similar background.",122684557,Universitas Lambung Mangkurat,Banjarbaru,Indonesia,['1700'],25.714285714285715,0.15490196078431373,0.5049019607843137,1,0.1004566210045662,0.0182648401826484,0.3409090909090909
107,108,108,Dual property of tamarind seed polysaccharide aid wound healing,"Amongst several wound natural wound healers, Xyloglucan (XG) are being extensively studied for their healing property. XG, proved to enhance cell viability, proliferation and migration in human skin cells, cure wounds individually or in combination. Together with its property of hydrogel production and film formation, it aids slow drug delivery, acting as a wound enhancer, meanwhile. Tamarind seed polysaccharide (TSP) was extracted from Tamarind seed kernel powder, using a protocol involving consecutive, boiling, centrifuging and precipitation steps. Identification of XG from Tamarind seed polysaccharide (TSP) was performed using Liquid chromatography-Mass spectrometer (LC-MS/MS), Fourier transform infrared spectroscopy (FT-IR) and Nuclear magnetic resonance (NMR) studies. Scratch assay conducted on TSP treated human fibroblast cells at 0 hr., 5 hr. and 24 hr. time period, reveal significant differences in scratch area due to migration of skin fibroblast cells, in comparison with non-treated and fetal bovine serum (positive control), confirming its potency in In-vitro wound healing.",60104599,Sree Balaji Dental College &amp; Hospital (SBDCH),Chennai,India,['1700'],19.0,0.025206611570247933,0.32079889807162537,1,0.0891089108910891,0.08415841584158416,0.42857142857142855
108,109,109,Improved convolutional neural network based sign language recognition,"Hand gestures offer a natural manner for humans to act with computers to perform a spread of various applications. However, factors like the quality of hand gesture structures, variations in hand size, hand posture, and environmental illumination will influence the performance of linguistic communication recognition algorithms. Recent advances in Deep Learning have considerably advanced the performance of image recognition systems. particularly, the Improved Convolutional Neural Network has incontestable superior performance in image illustration and classification, compared to standard machine learning approaches. This paper proposes AN Improved Convolutional Neural Network (ICNN) appropriate for linguistic communication recognition tasks. information augmentation is at the start applied that shifts pictures each horizontally and vertically to an extent of 200th of the first dimensions every which way, in order to numerically increase the scale of the dataset and to feature the lustiness required for a deep learning approach. These pictures area unit input into the projected ICNN model that is authorised by the presence of network low-level formatting (ReLU and Softmax) and L2 Regularization to eliminate the matter of information overfitting. With these modifications, the experimental results mistreatment the ICNN model demonstrate that it's a good methodology of accelerating the performance of CNN for linguistic communication recognition. The model was trained and tested mistreatment 105600 static hand gesture pictures, that incorporate variations in options like scale, rotation, translation, illumination and noise. The projected ICNN was compared to a baseline Convolutional Neural Network and also the results show that the projected ICNN achieved a classification recognition accuracy of 99.96.",118580534,Kalinga University,Raipur,India,['1700'],25.3,0.21862745098039216,0.4009803921568627,1,0.09219858156028368,0.07801418439716312,0.35
109,110,110,Multi-level authentication (MLA) for wireless sensor networks using artificial intelligence,"Wireless sensor applications deployed in different types of domains due to its vast applications such as the medical field, metering system, research and development area, industrial machinery monitoring, etc. One of the big problem and challenge with this network is intrusion detection. whenever sensor nodes are communicating with each other they don’t know either its conjugative node is authorized node or not if node authorized node there is no problem in the exchange of sensitive data if it is not then the problem will arise. In this case, it is essential to find out the type of intruder; in this Manuscript, the proposed algorithm can quickly solve this problem by using the multilevel authentication using Artificial Intelligence. If any sensor node wants to join in the network, it must authenticate itself with the nearest server with the multilevel authentication mechanism; once the authentication is successful, then only it can get the permissions to exchange the sensitive data with its conjugative node.",60114412,Dadi Institute of Engineering &amp; Technology,Visakhapatnam,India,['1700'],32.2,0.04222222222222223,0.5733333333333334,1,0.10734463276836158,0.01694915254237288,0.21910112359550563
110,111,111,Influence of CEO characteristics of SMEs on technological innovation and management performance,"Background/Objectives: CEOs of SMEs are highly influential and have a high concentration of decision-making power. Therefore, it can be said that the characteristics of CEO of SMEs have a great influence on corporate innovation activities. The purpose of this study is to investigate the effect of technological innovation on the characteristics of SME CEO and management performance, and to help survival and growth of SMEs facing difficulties in rapid environmental change. Methods/Statistical analysis: In this study, CEOs and executives of SMEs were selected as research subjects, and interviews and e-mails were used to conduct surveys. The questionnaire consisted of 42 items including 6 items of demographics. Likert 5point scale was used for all items except for the question about the general characteristics of the respondents in the questionnaire.Statistical analysis, reliability analysis, and exploratory factor analysis were performed using IBM SPSS Statistics 22, and AMOS 22.0 was used for confirmatory factor analysis, structural model analysis, and mediating effect test. Findings:Summarizing the results of the study, First, the research hypothesis that analyzed the influence of the psychological characteristics of CEO of SMEs on technology innovation led to the conclusion that CEO 's attitude to challenge and enjoy new business has a significant influence on technological innovation. Second, the hypothesis to analyze the significant influence relationship of CEO 's competence characteristics on technological innovation led to the conclusion that CEO' s risk coping ability and external organization 's sense have a significant influence on technological innovation capacity.Third, the hypothesis test that analyzed the effect of technological innovation on business performance showed that efforts to introduce innovative products at a higher level than existing products in terms of product performance and quality affected the operating profit and net profit and it was concluded that. Fourth, the degree of technological innovation has a direct or indirect influence on the relationship between CEO characteristics of SMEs and business performance of SMEs. Improvements/Applications: Because the analysis method of this study used only the structural model analysis and the mediating effect test, it could not analyze the group such as the growth stage of the company, the manager 's age, and the size of the company. Therefore, we can obtain better research results by subdividing the research subjects, separating the groups based on various characteristics, and analyzing the cluster analysis or the control effect.",60006504,Hansung University,Seoul,South Korea,['1700'],35.09090909090909,0.19266798418972333,0.4714295125164691,1,0.09153318077803203,0.036613272311212815,0.2860520094562648
111,112,112,Analysis of main actors’beauty image in korean tv drama “dokebi”,"Background/Objectives: The beauty image studies in Korean TV dramas have been conducted around actresses.While this study aims to provide the basic data for the production of dramas, analyzing two main actors, Gong Yoo and Lee Dong-wook in “Dokebi,” which has been a fever in the U.S. and Europe as well as Asian countries, such as Taiwan and Japan, of the Korean TV dramas in 2017. Methods/Statistical analysis: This study would understand the beauty images centering around the capture images of the main actors in the drama, “Dokebi,” focusing on clothes, hairstyles, and accessories. In addition, this study would analyze somatotypes and face shapes, using an indirect measurement method and conduct a comparative study of somatotypes with Korean body measurements provided by the National Institute of Technology. Andit also conduct forface shapes with a 30-year-old man’s face shapes on culturecontent.com operated by the Korea Creative Content Agency. For personal colors, this study would analyze two actors’ skin colors, based on a third party, using Pantone’s Formula Guide and DIC Color Guide and look for colors complement them, using Adobe Photoshop CS5. Findings: It was found that Gong Yoo and Lee Dong-wook were taller and weighed less as compared to the standard somatotype, and as a result of a measurement of the ratio of their bodies with the head height, Gong Yoo was about 8.1 head figure, and Lee Dong-wook, about 7.5 head figure. For face shape, Gong Yoo’s face was smaller than Lee Dong-wook’s, and Gong Yoo’s face shape was an inverted triangle while Lee Dong-wook’s was a rectangle. For the beauty image, the number of clothes differed depending on the importance in the synopsis, and especially, since Gong Yoo symbolized a god of wealth, he put on expensive clothes of famous brands. Hairstyle did not change less than clothes, and the synopsis affected accessories the most. Through this study, it was found that somatotype or face shape had bigger impacts on the determination of the beauty image, rather than skin color, and also, for the color guides, an Asian, that is, Japanese color guide was applied better in finding Korean’s personal color rather than American products. Improvements/Applications: Studies of the beauty image have been conducted around women and people in their 20s, and celebrities’ the beauty images have also been investigated around actresses or idol groups. Thus, it is judged that this study has a value as a study of the beauty images of actors in their 30s. In addition, hopefully, this study will become the basic data for the production of dramas and a content material that promote Korea to the world.",60094949,Joongbu University,Kumsan,South Korea,['1700'],30.92857142857143,0.06521739130434782,0.3413043478260869,1,0.07692307692307693,0.10576923076923077,0.3510848126232742
112,113,113,Desing and implementation of MQTT protocol analyzer,"Background/Objectives: In this paper, we design and implementan MQTT protocol analyzerto monitor the data exchange between MQTT broker and clients. The implemented protocol analyzer does not affect the performance of the broker because it uses packet sniffering method and has functions, such as MQTT Topic status, that conventional protocol analyzers can not show. Methods: The MQTT analyzer was developed using the Java language and the Jpcap library. We developed a GUI version protocol analyzer similar to the general protocol analyzer, and also developed a console mode analyzer that can simply check the number of messages per sec. Findings: Since the MqttAnalyzer implemented in this research uses Jpcap packet capturelibaray, the MQTT protocol can be monitored with minimal performance degradation of the broker even they are running in a same computer. When operating in GUI mode, it displays packet-level analysis, including TCP/IP information, statistics based on MQTT protocol, and real-time message exchange performance. In case of console mode monitoring, with little overhead, itdisplaysMQTT PUBLISH message so that it can monitor real time message traffic more efficiently. Applications: The MqttAnalyzer can be used for monitoring and debuggingan MQTT application system. In particular, it is useful for evaluating performance of high speed MQTT appliance where MQTT Broker is embedded.",60006504,Hansung University,Seoul,South Korea,['1700'],22.88888888888889,0.06742997198879552,0.3830952380952381,1,0.11715481171548117,0.13807531380753138,0.354978354978355
113,114,114,Word sense disambiguation using unsupervised approach applied on Punjabi language,"Research is being carried out for machines to be able to better decipher an ambiguous word. The majority of work done in Punjabi, a regional language of India and one among the 10 most spoken languages of the world, is limited to supervised techniques. The primary limitation of which is that it requires a sense-tagged corpus and in case an ambiguous word is not listed, the technique will not be able to decipher its meaning. The unsupervised techniques on the other hand uses an untagged corpus and from the instances available with it, it deciphers the correct meaning of the unlisted ambiguous word. This could be either done by clustering instances of the target word or clustering the context of the target word. Using the metrics like precision, recall and f-measure, the results obtained from token based unsupervised methodology were analyzed and compared with decision tree, which showed better outcome than decision tree.",60097632,"Institute of Engineering &amp; Technology, Lucknow",Lucknow,India,['1700'],25.5,0.34484126984126984,0.4630952380952381,1,0.13529411764705881,0.011764705882352941,0.20481927710843373
114,115,115,Multi-criteria optimization of a hybrid renewable energy for standalone electrification,"In developing countries, designing a sustainable electrification system for remote places is very complex. Recently published research papers in the hybrid renewable field have not considered various factors such as technical, economic, environmental, and social (TEES), without which achievement of the goal of the sustainable energy system for rural places is not feasible. In the presented paper, a methodological framework based on decision analysis is designed with locally available renewable energy sources considering various TEES factors. Initially, suitable energy alternatives selected by considering different criteria with multiple scenarios for decision analysis. Further optimal combination of energy sources evaluated for different possibilities. The case study with real metrological data of a remote place in Himanchal Pradesh carried out, and the result shows that new methodology gave an optimized real-time system with multiple system combinations and configuration with the use of multitasking decisions algorithm and found very impactful on its TEES factor for the considered location.",118435169,RRSIMT,Amethi,India,['1700'],25.66666666666667,0.053795093795093785,0.3305339105339105,1,0.11046511627906977,0.029069767441860465,0.2823529411764706
115,116,116,Modelling of population density in urban cities using VIIRS night time light data,"The changes in the number of population are one of the important measures for several activities such as land-use planning, environmental monitoring, construction design, soil, water and air quality observation. Urbanization accelerates the development of city and residential expansion. Proper planning of urban city needsa thorough observation to maintain good environmental and economic growth. This study was conducted to estimate and model urban population in five cities in Peninsular Malaysia (Ipoh, Johor Bahru, Klang Valley, Kuantan and Pulau Pinang) from night time light images. This image records the light intensity and helped in derive gridded urban population estimation from the number of light radiance acquired by Day/Night band of VIIRS sensor. The results show that the number of population estimation highly correlates to light intensity (R2>0.7). Validation of the polynomial model shows that the population density of estimated and actual population derived by censuses have high similarities and close into each other.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],21.714285714285715,0.18205882352941175,0.3973529411764706,1,0.07471264367816093,0.08620689655172414,0.3430232558139535
116,117,117,The bluetooth and GPS tracking system: Comparison and analysis of technique,"In recent years, tracking system is a popular approach to detect misplaced objects due to the availability of related systems in the market. The common technologies used are RIFD, Bluetooth, WIFI and GPS. Following framework more often than not consolidates the utilization of an electronic gadget (equipment) with portable application (programming) that tracks the missing objects. Numerous structures likewise join verbal trade parts together with satellite TV for pc transmitters to communicatewith equipment's for a distant client. Google maps are utilized to observe the equipment's region. This examination is centered around two administrations in following lost question. The first one is GPS and the second one is Bluetooth. The ascent of Bluetooth Low Energy (known as BLE or Bluetooth 4.0) opens up to unlimited potential outcomes of Bluetooth following applications. On the other hand, GPS is a service that communicates with satellites, provides location on the globe, and gives coordinates of the location tracker.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],17.11111111111111,0.016666666666666663,0.3518518518518518,1,0.10734463276836158,0.07909604519774012,0.3954802259887006
117,118,118,A resource optimize split bit multiplier for high order computation,"Computation of arithmetic and logical operation involve multipliers as the basic unit. In the designing operation of multiplier operation, among different optimization approach, divide and conquer approach has a greater efficiency. The split operation of a partial operand in multiplication operation result in faster computation and lower resource overhead. However a lower radix operation leads to larger processing iterations, resulting in increase of resource utilization and increases the latency of the system. In improving the multiplication performance a resource optimization by resource reutilization and higher level coding is proposed. This approach illustrates a significant improvement in the resource optimization and speed of computing in multiplication operation.",60115132,Guru Nanak Institute of Technology,Ibrahimpatnam,India,['1700'],17.666666666666668,0.159375,0.45625,1,0.06956521739130435,0.034782608695652174,0.21739130434782608
118,119,119,A study on user authentication method using EEG biometric information in the fast identity online system,"Recently, the world started to use biometrics with the convergence of information technology and financial systems. Using such biometrics FIDO (Fast Identity Online), Samsung and Apple launched Samsung Pay and Apple Pay respectively. The FIDO authentication technology has substituted conventional authentication methods such as password. Among these biometric technologies, fingerprint recognition has drawn an attention from the world in that it can minimize user denial, and the device is relatively cheap. In fingerprint data, however, the amount of information a user can get is limited. In addition, if they are leaked by a hacker, they cannot be reused. Therefore, this study proposes a way to authenticate users using an EEG signal, one of biometric technologies. It increased convenience, using a single-channel EEG device instead of conventional multi-channel EEG devices. Furthermore, this study suggested a method to use EEG signals in the FIDO system. More precisely, it explains how to utilize EEG signals as a means of user authentication when a user recognizes a specific object.",60092867,Korea Institute of Science and Technology Information,Yusong,South Korea,['1700'],16.5,0.0879120879120879,0.3793956043956044,1,0.11794871794871795,0.07179487179487179,0.39267015706806285
119,120,120,"An analytic research on the damage of plankjoined with CFRP, Mg, AI and aifoam under torsional load","Background/Objectives: As lightweight materials,most of the studies have been focused on the destruction characteristics of a single material.Butthose materials as composites were examined in this study. Methods/Statistical Analysis: Most of the studies in this field have been usedwith opening mode under a tensile load. On the other hand, this research was utilized with tearing mode under the anti-planar shear load to examine the destruction characteristics of specimens under torsional load. The specimen designswere conformed with the standard of ISO15310 to describe the experiments with specimens of each material combination under a torsional load. Findings: In terms ofequivalent stresses on the specimens with each material combination, the maximum value was shown for the plank with CFRP and AIfoam combination. As other combinations, the specimen with Mg had higher equivalent stress. The equivalent stress as specific strength also demonstrated higher strength for the specimen with Mg than AI. The graph of reaction to displacement showed that the damage of CFRP’s fibrous layer caused the numerous amplitudeson the latter part of graph. Moreover, though the maximum reactions at specimens with Mg and AI seemed to be similar, the plankjoined with Mg and AIfoam had lighter weight and higher strength. As shown bythe adhesive damage trend, the displacement over 3mm reduced the adhesive strength by causing the plankto separations, and the separation occurred firstly at the parts against a jig. As seen by the maximum shear stress on the top of specimen, theplank with Mg and AIfoam combination were shown to have higher values than the otherplanks. Improvements/Applications: This research was investigated on the damagesof lightweight composite materials. This study result can be applied for the improvements on the parts of automobiles, airplanesand ships.",60103616,Kongju National University,Gongju,South Korea,['1700'],21.538461538461537,0.1285714285714286,0.35484126984126985,1,0.06875,0.059375,0.3225806451612903
120,121,121,Performance analysis of multipath routing protocols for disaster response networks,"Multipath routing protocols improve the load balancing and quality of service in WSN and also provide reliable communication, they allow building and use of multiple paths for routing between a source destination pair. they exploits the resource redundancy and diversity in the underlying network to provide benefits such as fault tolerance, load balancing, bandwidth aggregation, and improvement in QoS metrics such as delay, in this paper, we present a selection of multipath routing protocols and give a discussion on how multipath techniques can be extended to disaster response networks, the paper also investigates various multipath routing protocols from the perspective of disaster response networks DRNs through an in-depth analysis of these protocols and compares their performance to a number of DRNs routing requirements, the paper also helps to understand the properties and limitations of existing multipath routing solutions from the perspective of DRNs and suggests enhancements of these solutions to cope with routing requirements in DRNs.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],78.0,0.0,0.3,1,0.13690476190476192,0.023809523809523808,0.2710843373493976
121,122,122,Ceramic proppants for hydraulic fracturing treatments,"The results of studies to create magnesium-silicate proppants based on the raw materials of Kazakhstan are presented herein. Serpentinites from chromite ores from the Kempirsai region were used as the main component of the charge. Serpentine as chrysotile and antigorite is the main mineral of serpentinite rock. Impurity minerals of the rock are olivine, carbonates, chromospinelide and hematite. The laws of structural and phase transformations occurring during the heat treatment of serpentinite raw materials in the range of 400-1400°C were studied. It was revealed that the formation of equilibrium phases (forsterite and clinoenstatite) in magnesium silicate ceramics occurs through the formation of metaserpentine, an intermediate metastable compound, which exists at 600-900°C. Magnesium-silicate proppants based on serpentinite with the addition of 10-20% silica sand or refractory clay, were obtained. Proppants were obtained with a bulk density of 1.60-1.65 g/cm3, crush resistance at 34.5 MPa of 10-15%, and roundness and sphericity of 0.8. Properties of the proppants obtained meet the requirements of the API standard.",60122628,Institute of Metallurgy and Ore Beneficiation,Almaty,Kazakhstan,['1700'],18.11111111111111,-0.02564102564102565,0.31794871794871804,1,0.07881773399014778,0.04433497536945813,0.36065573770491804
122,123,123,The mediating effect of knowledge management on the relation between tqm and banking service performance: a review,"Several different banking systems face challenges because of the fast growth of technology. Practitioners of management have supported more innovation and creativity in procedures, management applications and lines of production. Though, total quality management systems have long been a main management performance. Knowledge management procedures obtain currently an acceptance incorporations. Moreover, service/product performance additionally gains significant interest and it could be considered as a critical point to keep sustainable benefit in the market. Such this research investigates the relation between service performance KM procedures and TQM systems.",60076016,"Sam Higginbottom University of Agriculture, Technology and Sciences",Allahabad,India,['1700'],14.5,0.10833333333333332,0.5234848484848486,1,0.08163265306122448,0.02040816326530612,0.3125
123,124,124,A review on durability and degradation of glass fiber reinforced polymer structures,"This paper reviews the literature available on glass fiber reinforced polymer (GFRP) and its applications as outdoor structure or component. The current trends on the usage of GFRP have been reviewed and various properties of GFRP are presented and discussed. Durability and degradation of GFRP performance in certain application have shown that mechanical strength behaviour decreases when GFRP structure or component was exposed to outdoor environment. Hence, GFRP structure are capable of withstanding extreme environmental condition with modification of GFRP composition. The review literature show GFRP composite material are more resilient in terms of strength, corrosion resistance, sustain capability in harsh nature and long life serviceability with performing as a good insulator in lightning impulse strength. It is concluded that application of GFRP in various application has contribute to the development of significant properties of high performance GFRP and also application of GFRP as high durability crossarm in transmission tower with prolong lifespan.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],25.5,0.16673469387755105,0.5661734693877551,1,0.08536585365853659,0.07926829268292683,0.25609756097560976
124,125,125,Visual similarity using convolution neural network over textual similarity in content-based recommender system,"In today’s digital era recommendation system is widely used applications from Netflix to Amazon, from Google to Goodreads, etc. Amazon estimated about 35% incremental revenue from product recommendations every year. Majority of e-commerce companies provides a recommendation system for purchasing product. The most search engine uses text-based search criteria for finding similar products. In this article, a comprehensive study of research contents related to text and image-based recommendation system is mentioned. First, we presented various text pre-processing techniques are used to clean dataset. Second, we described various techniques used for finding textual based similarity. Third, an advanced technique likeConvolution Neural Network(ConvNets) is used for computing image-based similarity of product. Cosine similarity is calculated when word occurrence is important in textual input whereas Euclidean distance is measured when an image or semantic-based text is considered as input. Experimental results depict how recommendations using ConvNets is more exciting than usual classical techniques.",60115150,"Government College of Engineering &amp; Research, Avasari Khurd",Ambegaon,India,['1700'],15.0,0.13703703703703699,0.4046296296296297,1,0.143646408839779,0.03867403314917127,0.36627906976744184
125,126,126,Gaussian YOLOv3: An accurate and fast object detector using localization uncertainty for autonomous driving,"The use of object detection algorithms is becoming increasingly important in autonomous vehicles, and object detection at high accuracy and a fast inference speed is essential for safe autonomous driving. A false positive (FP) from a false localization during autonomous driving can lead to fatal accidents and hinder safe and efficient driving. Therefore, a detection algorithm that can cope with mislocalizations is required in autonomous driving applications. This paper proposes a method for improving the detection accuracy while supporting a real-time operation by modeling the bounding box (bbox) of YOLOv3, which is the most representative of one-stage detectors, with a Gaussian parameter and redesigning the loss function. In addition, this paper proposes a method for predicting the localization uncertainty that indicates the reliability of bbox. By using the predicted localization uncertainty during the detection process, the proposed schemes can significantly reduce the FP and increase the true positive (TP), thereby improving the accuracy. Compared to a conventional YOLOv3, the proposed algorithm, Gaussian YOLOv3, improves the mean average precision (mAP) by 3.09 and 3.5 on the KITTI and Berkeley deep drive (BDD) datasets, respectively. Nevertheless, the proposed algorithm is capable of real-time detection at faster than 42 frames per second (fps) and shows a higher accuracy than previous approaches with a similar fps. Therefore, the proposed algorithm is the most suitable for autonomous driving applications.",60026263,Seoul National University of Science and Technology (SNUST),Seoul,South Korea,"['1712', '1707']",24.88888888888889,0.1896100514069264,0.5317880817099567,1,0.10984848484848485,0.05303030303030303,0.3333333333333333
126,127,127,Fabric design identity: Implementation of pattern formation into Kain punca potong (KPP) weaving design,"Kain punca potong (KPP) is a long fabric generally crafted via the ikat technique resulting in square patterns with striped motifs consisting of a decorative limar pattern. Instead of decorative motifs and KPP design, this paper will embark on a discourse on pattern formation style specific to the design style and pattern composition of KPP motifs, design and use in Malay society. The paper shows that this textile provided some valuable insights into Malay culture and fabric identity. Regarding the Malay textile context, the main issue revolves around local textile‟s Malay fabric identity pattern formation. This issue came to be when it was discovered that other communities lack awareness when it comes to understanding the fabric identity of Malay textiles, let alone its fabric design identity. This paper also provides enhanced deliberation on the use of pattern formation basis inspired by design style consisting of selected motifs and pattern composition to identify the identity of fabric design. The researcher used qualitative approach to identify the attributes of fabric design identity, which included pattern formation and style process. This paper will therefore seek to uncover viable concepts and techniques that passed as feasible guidelines for new designers when incorporating a ""distinctive"" national identity in their design. For this study, in addition to interviews, fieldwork notes, photography and video documentation, participant observation in the form of a master weaver apprenticeship will aid better understanding of weaving design learning process while participation in design education will provide insights on how design knowledge is transmitted. It also explores the potential of pattern formation style to further develop the identity of fabric design in various design forms, particularly in the field of textile weaving design.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],28.0,0.07039141414141413,0.4184343434343434,1,0.11842105263157894,0.019736842105263157,0.21052631578947367
127,128,128,Frequency control operation of essto improve the power system reliability,"Background/Objectives: The Battery Energy Storage System(BESS) has been maintained power voltage value to rapidly response speed for steady state in the power system. It is operating the BESS to securing the reactive power. Methods/Statistical analysis: It has been investigated the output control result of large capacity ESS due to the failure of the nuclear power generators. The power system would be operated to maintain the voltage level by Governor Free Control(GFC) and Automation Generation Control(AGC). The BESS is evaluated to compare the real power system with simulation power system in fault state. The BESS has been rapidly responded speed in steady state, and recovered frequency in transient state. The control methods are classified the steady state, transient state, and change from normal to transient state operation. Findings: The steady state output was proportional to frequency error and system constant. The transient state was operated when the rate of charge of frequency was less than-0.0306[Hz/s], and the system would be fully discharged. It was stopped the operation when the frequency would be recovered to 59.9[Hz] within the system error of ± 0.01[Hz]. Recovery from transient state to steady state has been restored to linear slop for 0~10[s] until transient discharge power. Improvements/Applications: It should be used for expended application of the BESS in the power system as stable power supply. It would be expected that the reliability of the power system by fast response speed for spinning reserve power.",60033270,Wonkwang University,Iksan,South Korea,['1700'],18.30769230769231,0.08595238095238095,0.4502380952380952,1,0.09854014598540146,0.06204379562043796,0.32142857142857145
128,129,129,Practical investigation of tool wear mechanism of PCBN material by using FSP,"The goal of this experimental evaluation was to observe the actions of a polycrystalline cubic boron nitride (PCBN) device throughout hard turning of chromium-molybdenum alloy solidified steel. Individual cutting parameter affects on the basic tool wear patterns were quantitatively evaluated on the basis of appropriate physical as well as mathematical modeling strategies. Friction stir processing (FSP) of ferrous alloys is possible using polycrystalline cubic boron nitride as the device product. FSP device wear attributes hinge on the quality of PCBN and the ferrous alloy being processed. A number of qualities of PCBN were examined in machining wear examinations using 304L and also AL-6XN stainless-steels. Friction Stir Handling has actually exposed to be viable device for enhancing the mechanical residential or commercial properties of materials like micro firmness, great grain structures, high tensile strength, enhanced return toughness, improvement in elongation, and increased corrosion resistance. The wore down size of device, volume measurements as well as the tool wear price is computed for a variety of combinations of elements and degrees. The results of experiments methodically gone over and also to achieve procedure criteria on device wear rate are identified.",60114430,"Malla Reddy Engineering College, Secunderabad",Secunderabad,India,['1700'],23.5,0.03662698412698413,0.40631519274376415,1,0.11904761904761904,0.04285714285714286,0.30097087378640774
129,130,130,An experimental approach for prediction of disease in smart health system using data mining technique,"It can happen sometime that there is an urgent need of doctors but due to any reason they are not available. An online consultation project and an end user support system are known as Health Prediction system. By using online an intelligent health care system in this research paper a system is introduced. For better coordinate of Healthcare the smart health informatics system consider as an important component. This system based on proper transmission, retrieval, generation and storage of health data.",60007998,"Maulana Azad National Urdu University, Hyderabad",Hyderabad,India,['1700'],16.2,0.22704081632653064,0.5596938775510204,1,0.07954545454545454,0.03409090909090909,0.23863636363636365
130,131,131,Developing a vocational engineering word list: Bridging the gaps of secondary and tertiary education,"There is a meaningful need to have an engineering corpus in Malaysia to bridge the vocabulary gap from secondary to tertiary engineering education. Thus, using the prescribed Malaysian KBSM vocational engineering textbooks, the development of Malaysia's very own vocational syllabus engineering corpus was facilitated which gave way to the creation of Engineering Word List (EngWL). The word list consists of the properties those of technical and semi-technical engineering lexis. The objectives of the study were summarized as(1) To develop a pedagogic engineering corpus; (2) To create a specific Engineering Word List (EngWL) from the developed corpus. Content analysis (corpus linguistics approach) was used as the research design for the word list creation process. For the purpose of text analysis and concordance, WordSmith Tools Version 5.0 and RANGE were used. As a result, a corpus with the size of 391,505 words (15,619 types) and the EngWL with 841 word families (1,704 types) were created. Hence, lexical products can be utilized by other researchers in the effort of bridging the gaps of secondary and tertiary education.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],21.75,0.1255,0.38,1,0.07352941176470588,0.08333333333333333,0.37254901960784315
131,132,132,Natural radionuclide of 230th in Malaysian harbor sediments,"The activities of detrital230Th (230Thdet) and excess230Th (230Thex) were determined in surface sediment (0-20 cm) collected at eight harbors areas covering the Malacca Straits, southern South China Sea (SCS) and southeast SCS to calculate unsupported inventory and flux of230Th. The average inventories and fluxes of230Thex ranged from 1.10 x 103 Bq/cm2 to 1.66 x 103 Bq/cm2 and 10.50 x 10-3 Bq/cm2/yr to 15.84 x 10-3 Bq/cm2/yr, respectively. Highest average inventories and fluxes of unsupported230Th have been detected at southeast SCS, follow by southern SCS and Malacca Straits might be due to much water containing huge suspended particles rich with230Th flow at southeast SCS from western Pacific. Southeast SCS harbor was also classified as high productivity area of230Th, whereas southern SCS and Malacca Straits harbors were classified moderate and low productivity areas, respectively.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],33.0,0.04733333333333334,0.31766666666666665,1,0.07784431137724551,0.17964071856287425,0.44966442953020136
132,133,133,Ceramic proppants based on high-ferrous bauxite,"The possibility of obtaining ceramic proppants from high-ferrous bauxite of Kazakhstan with properties that meet the requirements of American Petroleum Institute standards was studied. High-ferrous bauxite content in mixtures with refractory clay provides a hardening effect by increasing the content of the crystalline phase in the firing products. This is due to the binding of free silica and other impurities to alumina into secondary mullite and spinel compounds. Proppants with a bulk density of 1.65-1.69 g/cm3, roundness of 0.7, sphericity of 0.9 and crush resistance at 52 MPa of 9.8% were obtained from high-ferrous bauxite and refractory clay mixtures.",60122628,Institute of Metallurgy and Ore Beneficiation,Almaty,Kazakhstan,['1700'],24.75,-0.029999999999999995,0.37,1,0.0603448275862069,0.04310344827586207,0.32075471698113206
133,134,134,Assessment of the place attachment of residents to residential spaces in new urban fabric case study: Jahad Township-Zahedan City,"Aim and Background: Lack of attachment to new townships and cities is a hidden problem that in the long run impels the feelings of anomie in the inhabitants of these environments, and the sense of attachment stimulates the city development and improves the living environment. The purpose of the research is to know the status of attachment among the citizens living inJihad Townshipand identify the effective factors on residents' attachment to their residential space. Materials and Method: The present research is applied in terms of purpose and survey in terms of methodology. The research instrument is a researcher-built questionnaire whose validity was confirmed through face validity and its reliability coefficient was 0.78 usingCronbach's alpha test. The statistical population of the study includedall residents of the Jihad Township. The sample size is 332, by whom the questionnaires were completed. Results and Conclusion: The hypothesis test has shown that there is a significant and positive relationship between the duration of stay, social activities, quality of service, sense of security and emotional attachment with the level of residents' place attachment. Also, it was found that the average level of attachment to their living space was 5 <2.17> 1, which was lower than average. Regression analysis of the four criteria of attachment to parks explains 77% of the variations of the dependent variable (residents' attachment). The results indicate that the quality of services variable has the highest impact, then social activities, sense of security and emotionalattachmentin the next priorities, have increasing influence on the place attachment of residents in the Jihad Township of Zhehadan.",60012835,Iran University of Science and Technology,Tehran,Iran,['1700'],26.0,0.09204545454545457,0.4279761904761905,1,0.05102040816326531,0.04081632653061224,0.3013698630136986
134,135,135,Method for providing efficient real-time multimedia communication using VoIP over communication channels,"The Voice packets and the Video packet are transmitted in the existing infrastructure using the Voice Over Internet Protocol (VoIP). VoIP (Voice over IP, VoIP and IP telephony) has become more popular in the recent years due to its advantage of low-priced calls than to the existing Public Switch Telephone Network. The significant objective of this research work is to improve the performance of multimedia service in the wireless telecommunication through the mobile VoIP. This paper explains the modulation scheme based approach for improving the performance of voice over the IP telephony. The proposed modulation selection method selects the modulation for the real time multimedia traffic based on the channel condition. The algorithm in the proposed system reduces the modulation switching time and increases the throughput. The performance metrics taken to ensure the quality are throughput and Mean Opinion Score.",60113205,"Chitkara University, Punjab",Rajpura,India,['1700'],20.0,0.1375,0.450462962962963,1,0.12337662337662338,0.11688311688311688,0.3355263157894737
135,136,136,Segmenting medical image data set with inhomogeneous intensities by using level sets,"The images obtained during the medical procedure have inhomogeneous intensity properties which cause the difficulty in image segmentation. The globally accepted region-based algorithm relies on the homogenous intensity in interest regions. So, the expected result cannot be obtained for medical images. In this research work, we induce a functionality criterion (FC) to cluster the locals (CL) according to the intensity of medical images. The FC is merged with the mid of neighbor to provide an accepted criterion for image segmenting. By formulating level sets, the functionality level set criteria (FLSC) has an energy that represents the domain portion of the image. By reducing this energy, the medical images can be consecutively segmented. The validation of our method has been done on 100 datasets of endoscopic medical images with inhomogeneous intensities. The results show that the proposed technique provides promising results and high performance than well-known algorithms.",60097734,Jeppiaar Engineering College,Chennai,India,['1700'],16.22222222222222,0.026,0.14400000000000002,1,0.14705882352941177,0.029411764705882353,0.3373493975903614
136,137,137,The statistical analysis and E-risks of major E-commerce systems in India,"Online shopping made so natural for everybody with their item varieties and basic approach to purchase things. An endeavor has been made to fundamentally inspect different corporate and business level methodologies of major e-commerce systems. Correlation have been finished considering web based business challenges, their plan of action, subsidizing, income age, development, survival procedures, Shoppers' internet shopping background, esteem included separation, and item contributions. These enormous players made their own check in India, however who will be extreme champ or be the best one will be. A near investigation of Flipkart with one of the nearby competitor Amazon conveys the data about the distinctive systems to prevail in web based business advertise and diverse open doors accessible in India. Online business is a doorstep of a typical individual in India it tends to be viewed as an eventual fate of trade. The internet business has broken the innovative and topographical hindrances throughout the years and has colossal measure of progress which numerous practical examiner and specialists never anticipated and still it needs to proceed in India. In this paper, we presented a brief overview of the statistical analysis of e-commerce system in India. Further, we narrow down to the top major e-commerce platforms i.e. Flipkart and Amazon. We also addressed the risks encountered at most of the e-commerce systems.",105606837,Siddharth Institute of Engineering and Technology,Puttur,India,['1700'],19.90909090909091,0.12126068376068375,0.4931623931623933,1,0.10040160642570281,0.060240963855421686,0.2809917355371901
137,138,138,Intelligent information technology-based ICT education and creativity education develop core competencies,"Background/Objectives: For the prosperity in the 21st century that is evolving rapidly, students need more than what they have learned. In the future society, students must get used to cease-less cooperation, communication and problem solving, and it can be developed through social and emotional learning(SEL). Methods/Statistical analysis: This paper investigates today’s teaching of creativity and the importance of school teachers in such teaching and accordingly proposes a new model for training the teachers on creativity-teaching. Findings: Intelligent Information Technology is applied to a wide range of industries such as intelligent robotics, smart manufacturing and blockchain, and is giving rise to massive innovation in economy and society as a whole. Improvements/Applications: Viewed in the context of such significance, ICT competencies and IIT are the subjects that should henceforth be addressed with importance in school education.",60117634,Jeju National University,Jeju,South Korea,['1700'],26.8,0.16774891774891776,0.4899418290043291,1,0.10493827160493827,0.043209876543209874,0.33548387096774196
138,139,139,Analysis of globalization and its effect on different arenas of indian society,"Globalization broadly refers to the expansion of the global linkages, the organization of the social life on the global scaleThis paper is analysing and summarising the concept and impact of globalisation on Indiansocial and cultural values with the help of secondary data analysis method .With the help of different textual material in hand researcher tried to touch the various arena of Indian society getting affected with the existence and power of globalization. In this paper social and cultural issues like gender inequality, equal opportunities, family structure and values, social, festivals, language, music, literature, cinema, television discussed on the basis of prior research works. The finding reflected that globalization put effects on the above explored areas.",60032618,Kurukshetra University,Kurukshetra,India,['1700'],38.333333333333336,0.004464285714285714,0.17589285714285713,1,0.0859375,0.0078125,0.2578125
139,140,140,The design and development of semi-automated paste filling machine for spicy shrimp paste,"The main objective of the development of semi-automated paste filling machine was to provide the simple filling mechanism into pouch pack for spicy shrimp paste (sambal belacan). The spicy shrimp paste contains chilly seed and flakes often stuck during filling process whilst using the current and normal filling machine. Hence, semi-automated paste filling machine for spicy shrimp paste was developed and customized for Dapur Ibu Food Industry. The machine is 70cm height X 35cm width X 83cm length. The development of this machine attached with volume sensor, speed sensor and extruder (co-injection) to push the spicy shrimp paste through the special fabricated nozzle and avoid clotting during the process of filling into the pouch pack. The co-extrusion could create the outer envelope and an auxiliary system for injection a filling. The machine also has sensor for speed depends on the speed of the operator holding the pouch pack. Quality control for food hygienic whilst the operation is ongoing is being controlled and monitored.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1700'],20.375,0.019312169312169315,0.4846560846560846,1,0.09574468085106383,0.047872340425531915,0.22033898305084745
140,141,141,An overview of simulation of biodiesel production using reactive distillation,"Biodiesel fuel is a renewable substitute for petroleum diesel. Biodiesel production from conventional feedstocks leads to high energy consumptions and high cost of production that resulted from the bottlenecks of reaction and separation processes. In this respect, reactive distillation technology is a key player that can reduce energy requirement. This work overviews the simulation of biodiesel production using intensified process, namely, reactive distillation. Moreover, the usage trend of the reactive distillation is also highlighted.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],14.8,0.04428571428571429,0.6092857142857142,1,0.0963855421686747,0.0,0.30120481927710846
141,142,142,The relationship of corporate governance and environmental performance towards environmental disclosure of oil and gas companies operating in Malaysia upstream projects,"In recent years, the environmental disclosures have increased as the concerns on global environmental issues are growing.Oil and gas industry deals with destructive operations and is considered as the most exposed industry which owes its effort to be responsible in disclosing the information about the activities and maintaining sustainable developments. The purpose of this research is to analyze the relationship between environmental performance and corporate governance towards Environmental Disclosure of oil and gas companies operating in Malaysia upstream projects by adopting the Global Reporting Initiative (GRI) index as benchmark. This research is a quantitative study using content analysis based on the secondary data extracted from the annual reports of oil and gas companies. Descriptive statistics, Spearman's Rho test and logistic regression were conducted to examine the relationship between the variables of this study which revealed the positive relationship. This research used combination of theories which are voluntarily disclosure theory, stakeholder's theory and agency theory.",60101841,UCSI University,Kuala Lumpur,Malaysia,['1700'],30.8,0.0030303030303030338,0.3050505050505051,1,0.10119047619047619,0.05357142857142857,0.2891566265060241
142,143,143,A study of factors affecting career choice,"The study sought to carry out research of the factors that influence the career choice of students with reference to Defence services as a career. The investigation sets up the means to identify the factors that would assist the policy makers that endeavor to provide guidance to students about career choices. A descriptive survey method was used in this study. A self-developed questionnaire was used to collect the data from the students. Eight hundred and ninety-nine senior secondary students participated in the study. The study revealed that parental career, peers, and some more factors influence on students’ choice of Defence services as career. The parental career and parental choice were found to have a positive impact on students’ choice of Defence as a career. The study mainly recommended training of students’ parents as well as their teachers for enhancement of students’ choice of career. The study also recommended a guidance workshop for career choice to assist in helping students choose Defence as a career.",60076774,"Amity University, Noida",Noida,India,['1700'],18.222222222222218,0.14848484848484847,0.4196969696969697,1,0.12021857923497267,0.02185792349726776,0.2569832402234637
143,145,145,Music onset detection using convolutional neural network,Onset detection is a primary task in audio processing for any higher-level audio processing such as music information retrieval (MIR) or automatic speech recognition (ASR). Onset detection using data driven approach is hard due to labeled data scarcity. In this work we use some in build dataset for training our convolutional neural network (CNN) work and make some test data for Nepalese traditional music. The CNN with raw waveform of input audio signal performs well in this study for onset detection. This network performs well in diversified audio type where 50 millisecond windows are set in each audio file to identify the presence or absence of onset.,60114276,"Government College of Engineering, Karad",Karad,India,['1700'],21.4,-0.037133699633699634,0.4468864468864469,1,0.09166666666666666,0.03333333333333333,0.2542372881355932
144,146,146,Binomial distribution series connected with certain subclasses of analytic functions,"The purpose of present paper is to obtain the necessary and sufficient conditions and inclusion (m−1)! relations for Binomial distribution series k(m, p, z) = z + ∑∞n=2 (m−n)!(n−1)! pn−1 (1 − p)m−nzn belonging to the subclasses T(δ, λ) and C(δ, λ) of analytic functions with negative coefficients. z Further the integral operator H(m, p, z) = ∫F(m,p,t) dt is related to this series is also considered. 0t 2010 Mathematics Subject Classification: 30C45, 30C55.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],24.66666666666667,-0.07777777777777778,0.4388888888888889,1,0.0392156862745098,0.16666666666666666,0.5555555555555556
145,147,147,Determinants of petroleum profit tax compliance among oil companies: A proposed model,"Energy sector contribute immensely to the economic development of more than 98 countries around the globe. One of the popular energy sectors is oil and gas industry. Oil and gas companies paid huge amount of percentage as tax revenue to the host oil and gas producing countries. Despite the enormous contribution of this sector to the economic growth of virtually most of the oil and gas producing countries, standard tax compliance model relevant to the industry are yet to be developed. To address this issue the current study tent to expand the tax compliance models of Allingham and Sandmo (1972) to incorporate additional two predictor variables relevant to oil and gas industry, these variables are; environmental regulations and royalty rates as well as the moderating effect of tax administration efficiency. The model once validated could be a robust model that accounts for the situational and environmental peculiarity of the oil and gas industry for better understanding of oil companies’ tax compliance behaviors. If validated, the model would have a significant policy implication to the host oil and gas countries, relevant tax authorities and academia at large.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1700'],26.57142857142857,0.28172268907563025,0.60609243697479,1,0.06965174129353234,0.009950248756218905,0.23880597014925373
146,148,148,Cognitive strategy in second language learning: Understanding how learners transfer from English to Malay,"Language transfer is a common phenomenon in a second language (L2) learning environment. This cognitive process involves the use of different methods known as “transfer strategies” in the production of a target language structure. It very much depends on the linguistic element being transferred as different element requires different strategy. However, strategies in the production of noun phrases (NPs) has not gained much attention thus far. Hence, this study investigates how L2 learners produce Malay NPs via transfer from English. Framed within a qualitative case study design, 4 university students were chosen as participants. The methods used in this study are document analysis and interview. The findings indicate that students have used all the 3 types of transfer strategies namely Substitution, Literal translation and Alteration of structure. However, they resulted in erroneous NPs. This information reveals that students must be cautious in using transfer as a learning strategy to avoid unwanted results.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],15.2,-0.012727272727272728,0.4054545454545455,1,0.10404624277456648,0.017341040462427744,0.3583815028901734
147,149,149,Inventory model for deteriorating products with life time and demand depending on price,"In this paper, an inventory model has been developed in which deterioration rate is of Weibull distribution form, demand rate is a function of selling price, inventory holding cost and ordering cost are functions of time. Life time is taken into consideration. Shortages are allowed during lead time and are fully backlogged.",60004880,Maharshi Dayanand University,Rohtak,India,['1700'],17.333333333333332,0.1,0.3,1,0.1206896551724138,0.0,0.27586206896551724
148,150,150,Evaluation of target tracking approaches using infrared imagery,"In this modern world, security is one of the crucial aspects of life either from cross border security or in house security. To secure from the unwanted access, several target detections and tracking algorithms have been proposed and found in the literature for visual imaging. There is number of fields where target tracking or moving object tracking is concerned such as medical, ATM surveillance, border security, quality checking, weather forecasting, defence-security, sea shore security and many more. However, visual imaging is not well capable of dealing with all type of target tracking, thermal imaging or infrared imaging is one of the great options to handle effectively those object where lights are low or near to zero. In this paper, we are focussing on evaluating some of the popular target detection algorithms with the Kalman filter which were mostly used for tracking the object and compared with mean shift filter and blob analysis with Gaussian mixture model on infrared video sequences. We also performed statistical analysis with all five algorithms for real-world benchmark datasets. This analysis will provide great exposure to develop a practical algorithm to achieve tracking the target.",60107380,"National Institute of Technology, Arunachal Pradesh",Yupia,India,['1700'],27.0,0.244375,0.444375,1,0.10426540284360189,0.009478672985781991,0.27053140096618356
149,151,151,Preliminary studies on the acceptance of virtual learning module (VLM)for school's ICT coordinator using UTAUT2,"This study aimed at acceptance ofVirtual Learning Module under the computer network management in the ICT Lab School using UTAUT2 acceptance model. Fourty schools in the districts of Batu Pahat were selectedas a case study by focusing onVirtual Learning Modulefor the management of the computer network in the ICT Lab School. Findings of training needs analysis, computer network requirements on issues andskills are required. In summary, all test results have a high degree of reliability and validity of what reflects the consistency of these variables used for ICT coordinator requirement to manage computer network in ICT LaboratorySchool.The result also show that the ICT Coordinator have increased the level of motivation and habits to use VLM to improve their skills.",60105342,Kolej Poly-Tech MARA,Kuala Lumpur,Malaysia,['1700'],29.75,0.16,0.5399999999999999,1,0.10236220472440945,0.15748031496062992,0.368
150,152,152,Neck circumference: A reliable indicator of the percent body fat in young male and female adults,"Background: There are several methods which are being used for the assessment of body fat. The neck circumference measurement has recently become a new method of estimating the body fat. It is also used as an indicator of the body mass index. Several researchers have used this assessment method in their studies as a measure of estimating the adiposity and cardiovascular risk factors. The body mass index is a general indicator of the body weight and a rough indicator of fat-mass and fat-free mass. Whereas the percent body fat is the estimation of only the fat-mass in the body. The objective of the present study was to find out the association between the neck circumference and the percent body fat in order to find out if the neck circumference measurement is a reliable method of estimating the body fat. Materials and Methods: For the present study, normal healthy adult subjects with age group of 18-26 years were selected purposively from Amritsar, India. The sample size was 816 subjects which included 483 males and 333 females. The subjects underwent assessment for the neck circumference and percent body fat. For the body fat percentage calculation, measurements were taken for the triceps and subscapular skinfolds. From these measurements, percent body fat was calculated using gender specific formulas. Results: The results of inter-correlation matrix of the studied variables showed a significant (p<0.001) positive correlation of the neck circumference with percent body fat in both males and females. It was also observed that the males had significantly (p<0.001) higher mean values for the neck circumference than the females (38.43±2.62 cm and 32.81±2.15 cm respectively). However, the values of percent body fat were significantly (p<0.001) higher in females than in the males (21.53±6.42 % and 15.38±6.70 % respectively). Conclusion: The neck circumference can be considered as an important and reliable method of assessing the percent body fat which is a measure of health in young male and female adults.",60000078,Guru Nanak Dev University,Amritsar,India,['1700'],20.1875,0.10652356902356902,0.4075617283950617,1,0.057065217391304345,0.01358695652173913,0.2802197802197802
151,153,153,Synthesis of palladium nanoparticles in SiO2 matrix,"Palladium nanoparticles in SiO2 matrix have been deposited by atom beam sputtering technique (ABS) using a gun as atom beam source. The concentration of Palladium in nanocomposite system has been varied from 10 at. % to 40 at.%. Structural characterizations Transmission electron microscopy (TEM) confirms the formation of spherical nanoparticles size varying from 2.2 Å to 3.8 Å. Structural characterizations Glancing Angle X-ray Diffraction (GAXRD) Studies & Selected Area Electron Diffraction(SAED) study confirms the crystallite nature of palladium nanoparticles. Energy Dispersive X-ray spectroscopy (EDX) technique confirms the presence of Palladium, silicon and oxygen.",60020898,Sant Longowal Institute of Engineering and Technology,Longowal,India,['1700'],15.5,0.0,0.0,1,0.08035714285714286,0.14285714285714285,0.5446428571428571
152,154,154,"The development of typologies, design patterns and scaled models bio-inspired by mangrove species","Mangrove is unique type of plants with distinctive roots that inhabit rivers or beaches. It is estimated that more than 36 species of mangroves have been identified in Sungai Merbok, Kedah, Malaysia alone and it is considered to be one of the largest collections of mangrove species in the world. Analogy is a process where the ideas are depicted or illustrated from a subject matter is a common process for designers and artists whom using nature as source of inspirations. Every part of the plant shown a different variation of roots, fruits, flowers, leaves and other physical parts according to the species or family name. The aim of this study is to observe, identify, and translate the common physical forms of the mangroves into series of patterns and to record the findings on the preferences of the potential consumers towards the scaled models developed. This study can be divided into two phases and it is estimated that 265 basic design patterns were sketched and developed in the first phase. Then the design patterns where chosen to be developed as 4 scaled models and it was showcased publicly in the art exhibition. To find out more on the preferences of potential consumers, a survey was performed for three months. About 494 responses received and the findings were analysed and discuss on which scaled models is preferred the most. This study is also done to explore potential of mangroves to be developed further in different forms of design, especially in industrial design field.",60104069,Royal College of Art,London,United Kingdom,['1700'],25.1,0.06805555555555556,0.4966269841269842,1,0.1259259259259259,0.018518518518518517,0.3074074074074074
153,155,155,Adoption of cloud computing model for managing e-banking system in banking organizations,"Cloud computing offers a lot of benefits, but today, cloud computing is suffering from safety hazards. Security is the client's most significant problem these days. This aim of this study is to propose adoption of cloud computing model for managing e-banking system. There are 4 stages for success adoption of cloud computing model for managing e-banking system. The cloud service models include Cloud Banking as a Service, cloud software as a service, cloud platform as a service, cloud infrastructure as a service. The cloud deployment models include four items as public cloud, community cloud, private cloud and hybrid cloud. Cloud computing issues and risks models are classified to technological factors, organizational factors, environmental factors, and operational factors. Finally, security control methods are classified to network security controls, data and storage security controls, application security control and physical security controls. Furthermore, successful adoption of cloud computing model for managing e-banking system will greatly improve the probability of cloud e-banking success in banking organizations.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],18.0,0.2840909090909091,0.4235930735930735,1,0.10309278350515463,0.02577319587628866,0.3655913978494624
154,156,156,Experimental investigation of damping enhancement and low cycle fatigue characteristics of CNT-reinforced hybrid polymer composite curved beam structure,"This research discusses the influence of the weight percentage of carbon nanotubes (CNT) in the curved composite beam structure through vibration testing. GFRP composite curved structured beams are fabricated with weight percentages 1, 2, 3, 4 and 5 wt. % of CNT with support of vacuum helped hand layup system. Structural vibration response of the CNT reinforced curved composite beam are studied in terms of natural frequencies and damping ratio. The natural frequencies and damping ratio of the curved composite beams are determined. It is observed that the higher values of natural frequencies are obtained at the 3 wt. % CNT-GFRP hybrid composite curved beam. Its value increases 44.31% and 36.26% higher than that of GFRP composite beams under clamped-clamped condition and clamped-free boundary conditions, respectively. Also, the increase in the damping factor is observed concerning the weight percentage of the CNT. The forced vibration analysis is performed with (3 wt. %) and without CNT and it is observed that the fundamental natural frequency of 3% CNT-GFRP composite curved beam decreased by 12.6% and 6.6%, under the condition of low cycle fatigue experimentation of 12500 cycles.",60018623,South Valley University,Qena,Egypt,['1700'],16.909090909090907,0.01597222222222221,0.3875,1,0.09545454545454546,0.06363636363636363,0.4009433962264151
155,157,157,"Performance improvement in 100KW photovoltaic grid connected system with firefly intelligent method under constant, different irradiation and temperature conditions","Solar PV cells have remained an active area of research over the past decade and more, with diminishing supplies of fossil fuels and the increasing necessity of renewable energy resources have attracted new path to be explored in the domain of Photo Voltaic cells. Considering the high initial capital cost of a Solar Photovoltaic (SPV) source and its low energy conversion efficiency, it is essential to operate the SPV source at Maximum Power Point (MPP) to extract maximum power under varying solar irradiance and temperatures. In view of the above an attempt has been made in the present work to develop proper algorithm for extraction of maximum power from the solar photovoltaic system (SPV). The scope of the paper includes tracking of Maximum power within less time and oscillations for this a meta-heuristic algorithm Firefly with ANN is utilized to track the maximum power in 100KW Grid connected PV System due to its good features and performance, the firefly algorithm is trained by the ANN technique to get the better power, less power fluctuations, no steady state oscillations, high tracking speed and better working in the change in environmental conditions. Moreover it is compared and showed as better one when compared to the other MPPT algorithms like P&O, PSO, PSO with P&O, P&O, PSO with ABC, Firefly which is implemented in this work.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],44.6,0.10030303030303032,0.3413275613275613,1,0.08097165991902834,0.11336032388663968,0.32669322709163345
156,158,158,"A study on the influence of mobile accessories purchased impulsively, with special reference to chennai city","Earlier were the days when it was difficult to find out a cellular phone with any one person among the 100. But, today it is difficult to find a person without the cellular phone or a smart phone. Not, only a Smartphone nowadays we can see n number of accessories tied up to a particular Smartphone or a cellular phone. The R & D in the accessories market is so vigilant in order to change according to the consumers wants. Perhaps we can say that the Mobile Accessories market rolls out a new accessory every month creating a wow factor. The wow factor created by the Smartphone’s is in the maturity stage whereas the accessories market is growing in an upward trend. A study which was conducted recently stated that the accessories market is growing directly proportional to that of the Smartphone market. The unplanned purchases made by an individual due to the influences of various factors can be termed as Impulsive Buying. The effect of impulsive buying exists in almost all the areas of the business irrespective of the industries. This paper aims to study whether there is an impulsive purchase in the mobile accessories market, if sowhat are the factors which influence the impulsive purchase whether it is internal factors or it is external factors. A sample of 250 respondents was collected across the Chennai city for the study. The responses collected from the respondents were analyzed using ANOVA with the help of SPSS.",60014340,SRM Institute of Science and Technology,Chennai,India,['1700'],20.5,-0.006334351922587217,0.5326903488668194,1,0.10687022900763359,0.04580152671755725,0.24334600760456274
157,159,159,Politics of law enforcing death sentence based on the benefit of law,"The application of death sentence still creates problems due to the ineffectiveness of deterrent effects in raising fear amidst the society so that people will not do the same crime. The practice of death sentence does not lower the number of extraordinary crimes that threaten the instability of a country and human safety, such as corruption, narcotics, and terrorism. Death sentence is enforced to fight crime against humanity or extraordinary crime. The enforcement of death sentence is also related to the effectiveness of law enforcement. In order to build a model of death sentence system, Islamic law becomes the reference to realize the principle of law utility. The essential purpose of Islamic sharia is benefit. There is no single rule in the Quran or Sunnah that does not bring benefit.",60069439,Universitas Sebelas Maret,Surakarta,Indonesia,['1700'],18.571428571428573,0.06415343915343914,0.44603174603174606,1,0.07801418439716312,0.02127659574468085,0.14893617021276595
158,160,160,To analyse the cost of sterilisation in central sterile supply department (CSSD) of a tertiary care corporate hospital,"The central sterile supply department is said to be a significant cost center in the hospital. Understanding various activities of CSSD in detail, managers can identify the required areas for cost management and improve the efficiency of the department. By analyzing costs, hospital management can ensure that the costs do not surpass the available revenues and subsidies. The objective of the study is to analyze the cost of sterilization of CSSD sets per unit in a 350 bedded tertiary care corporate hospital.An observational study was conducted to identify various cost elements involved and the workload on sterilizers. The cost was calculated under fixed and variable costs, using the average costing method. On an average 4723 were sterilized by autoclave and 1867 items by ETO per month in the CSSD. The average cost incurred per month for steam sterilization was Rs.2,15,767 and for EO gas sterilization is Rs.1,00,424, while the average cost incurred for sterilizing a set by autoclave and ETO was calculated to be Rs.45.68 and Rs.53.78 respectively.The findings of the study provided essential data on the utilization of resources and the amount incurred on the provision of the services, aiding in the optimization of the costs on resources and pricing to the patients.",60016524,Manipal Academy of Higher Education,Manipal,India,['1700'],29.142857142857146,0.012499999999999995,0.34464285714285714,1,0.11818181818181818,0.05,0.2777777777777778
159,161,161,Feasibility for adopting feedback-based adaptive speedy TCP to real-world deployment scenarios,"The transmission control protocol (TCP) is one of the tools that are being used to enhance communications between individuals particularly in this era of technology and digitalization. TCP is used to perform a number of functions such as flow control, traffic congestion, and rate control that facilitate the flow of communications over internet networks. However, factors like node mobility, delays, as well as node and route failures have greatly affected the performance of TCP over network systems. As such, Feedback-based Adaptive Speedy Transmission Control Protocol (FAS-TCP) has been proposed as a tool that is aimed at enhancing performance of TCP over network systems. Most significantly, FAS-TCP offers a merit of addressing the aforementioned challenges so as to enhance performance of TCP in network systems. This paper discusses a few use cases for implementing FAS-TCP in real world scenarios like IoT.",60121757,Mewar University,Chittorgarh,India,['1700'],23.33333333333333,0.19416666666666668,0.38583333333333336,1,0.09146341463414634,0.10365853658536585,0.3821656050955414
160,162,162,Status and challenges of integrated water resources management (IWRM) in Brunei Darussalam,"Integrated Water Resources Management (IWRM) has drawn worldwide attention as the endorsed approach by many international agencies help countries achieve better solutions to water management. To determine the worldwide status of implementation of IWRM, United Nation Environment Programme (UNEP) conducted a global survey in 2011 among 134 countries. However, data on the progress of Brunei Darussalam is not available. The current progress of IWRM in Brunei Darussalam is constrained due to lack of adequate information available on the water resources management. To close the research gap, a questionnaire survey was conducted to four government departments related to water management. We compared the primary data from the survey with existing IWRM progress in ASEAN countries. Constraints and challenges of implementing IWRM in Brunei Darussalam were also investigated. The study recommends appropriate tools that would be suited for Brunei Darussalam based on the analysis of tools from successful IWRM cases in ASEAN countries. In analysing the questionnaire against the performance of ASEAN countries, the study finds that there is still space for further improvement on the three pillars of IWRM. The performance of Brunei Darussalam is below the average status in comparison to other ASEAN countries except for component, Management Instrument. It is important that, for a successful implementation of IWRM, focus should be given in terms of Enabling Environment and the Institutional Roles.",60110791,Ove Arup dan Rakan-Rakan,Bandar Seri Begawan,Brunei Darussalam,['1700'],20.181818181818183,0.2185185185185185,0.4712962962962963,1,0.09016393442622951,0.14344262295081966,0.3975409836065574
161,163,163,Implementation of artificial neural networks to predict void content,"Void content is one of the governing factors to determine the properties of concrete. Basically determination of void content is a tough job. This paper deals with the usage of neural network to predict void content. It also eradicates the hectic work and consumes less amount of cement, which also saves time. The aim is to identify the suitable number of hidden neurons that minimizes the error with minimum void content. Void content of the aggregate mixture is determined by using four networks with different number of hidden neurons. These are optimized with levenberg-marquadt algorithm and then compared with each other. Different volume proportions of river sand, intermediate aggregate (maximum size of 10mm (I.A)) and coarse aggregate (maximum size of 20mm (C.A)) are used as inputs. Experimental void content is used as target. The network which has N3 number of neuron in hidden layer shows good results when compared with other networks.",60106974,"JNTUA College of Engineering, Ananthapuramu",Anantapur,India,['1700'],15.2,0.013888888888888892,0.4571428571428572,1,0.11363636363636363,0.028409090909090908,0.313953488372093
162,164,164,An improved LEACH algorithm based on fuzzy C-means algorithm and distributed cluster head selection mechanism,"The beneficial capability of Wireless Sensor Networks (WSNs) to check numerous types of environmental settings via detection mechanisms on the physical state of matters discovered through researches, has attracted great interest in many quarters. Significant necessities in a majority of applications related to sensor networks are the extensive duration of network lifespan. Towards the fulfillment of such requirements, the clustering sensor nodes is an efficient method for the purpose of achieving these ends. The fundamental goal of WSN routing protocol are in maintaining the equilibrium of network energy usage, and in stretching the total network lifespan. The most famous protocol that utilized clustering technique is Low Energy Adaptive Clustering Hierarchy (LEACH). In LEACH algorithm, the random manner is used to select specific nodes as a cluster heads. In addition, the resulting clusters suffer from an imbalance in cluster size. In this study, the LEACH issues are solved by utilizing Fuzzy C-means algorithm (FCM) to form balanced clusters,which is followed by the selection of the cluster head in each cluster according to the energy of nodes and distance to the cluster centroid. The comparison of therecommended algorithm with LEACH algorithm is conducted, in relations to energy consumption and network lifetime. The result showed that our proposed algorithm has further advantage over LEACH.",60107657,University of Kerbala,Karbala,Iraq,['1700'],21.1,0.145,0.5117460317460317,1,0.10084033613445378,0.08823529411764706,0.3432203389830508
163,165,165,Analysis of active suspension control policies for vehicle using robust controllers,"Better ride comfort and controllability of vehicles are pursued by automotive industries by considering the use of suspension system which plays a very important role in handling and ride comfort characteristics. This paper presents the design of an active suspension of quarter car system using Robust H-infinity, Robust H2, Robust Mu-synthesis controllers with passive suspension technique. Parametric uncertainties were also considered to model the non linearities associated in the system. Numerical simulation was performed to the designed controller. Results shows that inspite of introducing uncertainties, the designed active controller improves ride comfort and road holding of the car when compared to the traditional passive suspension system.",60095150,C. Abdul Hakeem College of Engineering &amp; Technology,Melvisharam,India,['1700'],21.2,0.15066666666666667,0.6900000000000001,1,0.15254237288135594,0.05084745762711865,0.3157894736842105
164,166,166,Improved coverage area based on boundary coverage technique for wireless sensor network,"Today in a modernize era of computer technology wireless network plays a significant role. Wireless sensor Networks are a fast growing area of research and business development. The task of Wireless sensor Networks are to monitor a given region of interest for changes in environment, intruder detection, providing coverage and so on. It is very successful for military environmental and scientific application purposes. One of most popular area of research in wireless sensor network is Coverage. Coverage in Wireless Sensor Network is denoted as a measure of how well and how long the sensors are able to observe particular region. In this paper, it has been proposed a better area coverage algorithm in which the deployment of sensor nodes are random.",60018003,Assam University,Silchar,India,['1700'],17.285714285714285,0.28787878787878785,0.5757575757575757,1,0.061068702290076333,0.04580152671755725,0.2366412213740458
165,167,167,Image encryption management mechanism based onvisual cryptography for enhancing video security,"Background/Objectives: This paper proposes a new mechanism to solve problems arising from the leakage of personal identification information by unnecessary leakage of image information. Methods/Statistical analysis: As the threat of privacy intrusion increases, it becomes important to protect the identification information of the subject. The proposed mechanism makes it impossible to identify a subject existing in a photographed image, and it can be restored step by step according to the authority of the user in the restoration process, thereby minimizing the possibility of privacy leakage. Findings: In this paper, we have studied a method of minimizing the leakage of identification information by applying image restoration according to access authority. Improvements/Applications: The technique to prevent the privacy violation of the subject by the image should be studied continuously.",60117634,Jeju National University,Jeju,South Korea,['1700'],25.4,-0.12878787878787878,0.5818181818181818,1,0.14383561643835616,0.02054794520547945,0.22142857142857142
166,168,168,A brief survey of asthma classification using classifiers,"Asthma diseases are the disorder, issues that affect the lungs, the body organs that allow us to take a breath as well as it is the most regular medical conditions around the world specifically in India. In this job, the trouble of lung diseases like the trouble encountered while identifying the condition in radiography can be fixed. There are numerous techniques found in literary works for the detection of asthma condition discovery. Numerous investigators have actually contributed their facts for Bronchial asthma condition forecast. The demand for determining bronchial asthma disease at a beginning is really essential and also is an energetic research study area in the field of medical image processing. For this, we have testimonial several regression designs, k-means clustering, ordered algorithm, classifications as well as deep learning techniques to find the best classifier for lung disease discovery. These papers mostly pact about prevailing lung cancer cell discovery methods that are obtainable in the literature. Spotting and after that treating, that condition in the preliminary phases uses the patients with a greater opportunity of survival. There are various kinds of classifiers like support vector machine (SVM), Random woodland, Choice tree and K-Nearest Neighbor (KNN) are made use of for the lung mass discovery. A character of methodologies has actually been come from cancer cell discovery approaches to proceed to the effectiveness of their discovery. Diverse applications like as assistance vector makers, neural networks, image processing methods are extensively made use of in for asthma condition discovery which is elaborated in this work.",60114867,"SR Engineering College, Warangal",Warangal,India,['1700'],23.09090909090909,0.10454545454545454,0.2868298368298368,1,0.08070175438596491,0.028070175438596492,0.2704626334519573
167,169,169,Strategic design management capability framework for Bumiputera SME furniture manufacturer,"The study attempts to identify the factors that affect the unsuccessful participation of Bumiputera furniture manufacturers in the export market through the industry indicators evaluation and also to examines the landscape of the Malaysia furniture industry. This study uses a literature review and structured interview to document the current scenarios of Malaysia furniture industry. Then, it uses a data analysis to determine the appropriate components as industry indicators in developing the framework. In addition, this study also is to enhance the understanding of the Bumiputera manufacturers and strengthen the evidence base for the policy developers. As a result of this study, it will provide solutions that will regenerate the economic importance of furniture classes in the years to come. By resolving the common concern, it is possible to escalate the Bumiputera manufacturing companies to be ahead not only for the domestic market but also for the global market.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],24.66666666666667,-0.04444444444444445,0.5222222222222221,1,0.12025316455696203,0.03164556962025317,0.23417721518987342
168,170,170,Low power high speed robust sram cells,"This paper presents two unique topologies of 11T SRAM cells with. The proposed 11T-A and 11T-B cells effectively reduce power consumption and also decrease delay time of input to be propagated to the output and furthermore improve the Write-capacity by utilizing power-cutoff and compose '0'/'1' just procedures. The 11T-A and 11T-B cells expend low power contrasted with proposed 11T-A SRAM cell. The proposed 11T-A cell likewise shows low power utilization contrasted and existing 11T cell. And 11T-B shows ground cut-off with floating node avoidance assist. Both the proposed cells effectively dispense with coasting hub condition experienced in before power cut-off cells. We additionally present a near investigation of Bias Temperature Instability (BTI) unwavering quality affecting the SRAM execution in a prescient 130nm high-k metal entryway CMOS innovation. 11T-A and 11T-B cells improve postpone all the more effectively. In addition, the proposed 11T-A (11T-B) show less postponement contrasted with proposed 11t SRAM cell. Subsequently, the proposed 11T cells are an astounding decision for dependable SRAM structure at nanoscale in the midst of procedure varieties and transistor maturing impact and can likewise be utilized in bit-interleaving design to accomplish multi-cell upset (MCU) insusceptibility.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],19.1,0.3083333333333333,0.532051282051282,1,0.13095238095238096,0.07142857142857142,0.4272300469483568
169,171,171,A detailed evaluation of the impact of learning & development on employee performance & productivity in IT sector in Pune,"Learning and Development is a process which helps the employee to enhance their knowledge and able to perform well as expected by the organization. Perhaps the industry expectations and the innovations in technology call for skill and knowledge of the employee to perform, and its objectives are to reach in a certain goal in a limited period of times. In this case learning and development has the crucial role to perform. This is well revealed and explained through the vision and mission statements. Training is an organizational activity which aims to enhance the employee’s current performance. Performance of employees is a prerequisite for any training programme and output in the form of overall growth for the organization is the aim of the management. It also helps to develop the productivity, revenue and profit of the company. Continuous improvement is highly effective on the performance of the employee. On the job training is the old trusted concept in Indian industry, accordingly majority of the training programs are well structured with the aim to acquire knowledge and enhance skill of an individual. It has been well documented and experienced out of the routine affairs of majority of the leading Indian nationals and multinational’s along with the no of the MNC’S that the learning and development can help enormously to boost and develop employee’s knowledge, skill, attitude and behavior while improving the brand of the organization. This is one of the reason why majority of them are totally committed to learning programs and spends their efforts, precious time and resources on these learning and development programs. Now a day’s learning and development program are becoming an increasingly important functions of HR Department as they help the organization to enhance human capital and compete in a rapidly changing business world. Despite the potential drawbacks, training program provides both the company as a whole and the individual employees with benefits that make the cost and time a worthwhile investment and develop the performance and productivity as well. This research paper is basically focused on evaluation of the impact of learning program which helps to develop the better performance and productivity. It provides about training effectiveness and how it contributes in enhancing the skill sets of an employee. The primary data is used for this study. The data was collected through a structured questionnaire from different IT companies in Pune. The analysis was done by using the “t” Test and Anova through SPSS and some of the analysis was done with the help of Excel.",60107570,"Narsee Monjee Institute of Management Studies University, Shirpur",Shirpur,India,['1700'],23.277777777777782,0.20803571428571432,0.5808035714285714,1,0.10864745011086474,0.024390243902439025,0.21052631578947367
170,172,172,The influence of service quality on customer satisfaction: Evidence from public sector and private sector banks in kurdistan/iraq,"The purpose of this research study is to determine the satisfaction level of banking clients with respect to the quality of the various services supplied by their bank and their satisfaction with the bank. The service quality is researched in a variety of aspects. There is also an attempt to find out which dimension of service quality can improve customer satisfaction. Respondents are selected using stratified random sampling from a range of different demographic features. Banks are chosen for sampling from both the government and private sectors. Using a convenience sampling technique, the required data were gathered from 384 participants using a structured questionnaire. Findings show that the service quality and all its’ dimensions are associated with customer satisfaction significantly and positively. The banking sector is an important industry in the economy of Kurdistan and in the last century has seen unprecedented development and raging competition. Therefore, this study was specifically carried out to explore this phenomenon and to seek empirical justification in this regard by considering the quality of service as the main contributing factor to the satisfaction of customers.",60116094,Erbil Polytechnic University,Erbil,Iraq,['1700'],20.11111111111111,0.1244490358126722,0.5268595041322314,1,0.12435233160621761,0.0051813471502590676,0.18134715025906736
171,173,173,"Knowledge, skills and professional development of special education teachers to handle assistive technology for students with disabilities","This research paper focuses on knowledge, skills and professional development to handle assistive technology of special education teachers. Assistive technology is enormous balancing in a classroom with diverse learners. Students with disabilities face many challenges in learning and assistive technology can be a potential aid for compensating for their educational needs. The purpose of this research was to explore the knowledge, skills and professional development of special education teachers on assistive technology for students with disabilities. Data were collected from eighty seven participants via a self reporting questionnaire. Quantitative data was analyzed using descriptive statistics. Descriptive statistics makes use of summary measures such as means and standard deviations. This helps in understanding the data, show the patterns and relationships and therefore, very important in reporting the outcomes. Results revealed that special education teachers do not have adequate level of knowledge and skills in using assistive technology. Special education teachers are in need of training programmes to increase their overall knowledge and skill in implementing assistive technology in their classrooms effective while teaching students with disabilities.",60016712,Alagappa University,Karaikudi,India,['1700'],17.5,0.2394940476190477,0.4855654761904761,1,0.10582010582010581,0.0,0.291005291005291
172,174,174,Enhanced noise removal technique based on window size for SAR data,"Manufactured gap radar (SAR) picture include extraction is turning into an imperative procedure for remote detecting, and for this, numerous apparatuses are accessible. In this exploration work the specialist proposes another procedure called an 'Improve Gamma Map' (EGM) system. In this system (which relies on the window size) a subset from the SAR picture is gathered and this gathered subset picture ought to be changed over from Slant Range (SR) to the Ground Range (GR). This SR to GR transformation figures adjust qualities and furthermore to discover the sigma nothing (σ0) esteem from every pixel. Thereafter, in light of sigma nothing esteem, the Land use and Land Cover (LULC) realities can be distinguished. Henceforth, the EGM strategy expels the clamor and it ascertains the histogram and disperse plots. At that point, this determined (histogram and disperse plots) values viably recognize the SAR picture with 72% enhancement for ground truth.",60014273,B.S.Abdur Rahman University,Chennai,India,['1700'],21.285714285714285,0.16875,0.44375,1,0.10497237569060773,0.13259668508287292,0.43333333333333335
173,175,175,Development of multilingual social media data corpus: Development and evaluation,"The purpose of this study is manual annotating,a corpus for Bahasa Indonesia and Bahasa Melayu. Corpus for both languages has been made by many researchers before, but the focus of this research is only on words with the same vocabulary but which have very different meanings. The data used is obtained from social media, so informal words are found. As many as 2100 words for each language which were then randomly selected so that it found 300 words with the same vocabulary but had different meanings. The objective of this study is to confirm that this condition can influence the results of polarity sentiment. At the end of this paper, we will show the results of the influence of the conditions of the two languages on the polarity of sentiments. From the manual annotation, an annotation agreement test is made bythreeBahasa Indonesia annotators and threeBahasa Melayu annotators. The results of the annotation found that there are 63 out of 300 words experience different polarity. Results of score agreement among annotations for each language show that there are good agreement among the annotators during annotation process.",60106643,Universitas Widyatama,Bandung,Indonesia,['1700'],20.555555555555557,0.10277777777777776,0.4580555555555555,1,0.08,0.03,0.26
174,176,176,"Isolation, screening and production of alkaline protease from by nocardiopsis synnematoformans and nocardiopsis dassonvilleivar. BSRMJY-2019 and SRMJY-2019","Microbial natural products have been one of the major resources for discovery of novel drugs. With the help of microorganisms to produce proteases source as they can be cultured in large quantities in a relatively short time by established fermentation methods, and they produce an abundant, regular supply of the desired product. The antimicrobial activity was studied preliminarily by cup plate method. The test organism E.Coli (Atcc 9837), Straphylococcus aureus (ATCC 9027).",60097740,J.K.C. College,Guntur,India,['1700'],18.0,0.16279761904761905,0.4425824175824176,1,0.08433734939759036,0.060240963855421686,0.3253012048192771
175,177,177,Appreciation and visual semiotic evaluation in bilingual tourism information media,"In bilingual tourism information media, linguistic and visual information are deemed necessary. The purpose of the article is to analyze the syntagmatic and paradigmatic relationships between them. Departing from this point of argumentation, we aim to recognize the coherence of linguistic and visual features in bilingual tourism brochure. This research employs descriptive qualitative approach. Meanwhile, the bilingual brochure data is analyzed using five phases of data analysis. The finding shows that appreciation is rarely used to give positive evaluation to the tourism destination described in the bilingual brochure. Aggravating the finding, it is pitiful to see that the disharmony between linguistic and visual information data also appears frequently. We claim that the harmony between linguistic and visual aspects in the brochure cannot be neglected since it carries the function to convince brochure readers to the information shown in the bilingual brochure. Therefore, to create greater convincing effect, we recommend tourist brochure makers to integrate the harmony of linguistic information and visual portrayal.",60108631,Universitas Dian Nuswantoro,Semarang,Indonesia,['1700'],18.0,0.13295454545454544,0.2965909090909091,1,0.1348314606741573,0.0056179775280898875,0.20786516853932585
176,178,178,The relationship between workforce diversity practices and productivity: Mediating role of conflict,"The primary objective of this paper is to study the impact of diversity practices on productivity and mediating role of conflict between diversity practices and productivity. A structured questionnaire and face to face interaction method are used to collect the primary data (five-point Likert scale) from the employees. Secondary data is received from various journals, textbooks, internet, newspapers, and magazines. Convenience sampling from nonprobability sampling method is used to avail the data from respondents who are conveniently available to participate in this study. Six Hundred (600) railway employees are chosen as respondents working in Southwestern railway. To satisfy the research objectives, respondents were selected because they were in the position to provide the best information. Correlation matrix, Regression (Process Macro), Mean and Standard deviation are utilized to calculate the results. To test the validity and reliability, we are using the Cronbach alpha by using the SPSS (22nd Version). Authors' findings are unique and clearly, indicate that effective diversity practices give positive results in the workplace.",60111840,Davangere University,Davangere,India,['1700'],18.33333333333333,0.22229020979020975,0.4627913752913753,1,0.1134020618556701,0.041237113402061855,0.359375
177,179,179,Reliability assessment on assembly line due to random failure of mechanical component: A case study in an automotive ancillary unit,"This paper presents reliability and availability analysis of a mechanical component which is a part of an assembly line. Mechanical component failed due to deterioration or poor operating condition, so scheduled as well as preventive maintenance policy is adopted. A scheduled maintenance and preventive maintenance is to improve the degraded components life. Degraded life of component is modelled by a reliability equation. While doing the preventive maintenance of an assembly line first component within the line identified. Also deteriorated components is to replace by new one as per preventive maintenance process suggested. A genetic algorithm has been used to investigate the failure data and down times. An assembly line reliability and availability has been estimated from the actual failure data collected.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],15.125,-0.1586139169472503,0.3390852974186307,1,0.11538461538461539,0.0,0.2153846153846154
178,180,180,Sustainability of micro entrepreneurs and empowerment perception: An empirical study in Indonesia,"This study aims to identify factors that support the sustainability of micro entrepreneurs and perceptions of entrepreneurs on economic empowerment, individual empowerment, family empowerment, and social empowerment. This study includes 294 micro entrepreneurs in Indonesia. The results show that there are 5 main factors for the sustainability of micro entrepreneurs: capital, place/location, family support, regular customers, and trading skills. As for respondents' perceptions of empowerment carried out by microfinance institutions where they become members can be differentiated into individual empowerment, empowerment for families, and empowerment for the social.",60070441,Universitas Pelita Harapan,Tangerang,Indonesia,['1700'],22.0,0.061904761904761914,0.22051282051282053,1,0.08571428571428572,0.01904761904761905,0.4077669902912621
179,181,181,"Critical success factors for e-learning in vocational training: A comparative analysis between ICT experts, trainer and faculty","This study identifies multiple factors that influence the success of e-learning systems from the literature and compares the relative importance among three stakeholder groups in developing countries, ICT experts, trainer and faculty. This study collected usable responses using the Delphi method and Analytic Hierarchy Process (AHP) approach. Data collection techniques used questionnaires, direct observation and interviews. The results reveal 2 categories and 13 critical success factors for e-learning systems in vocational training. Findings illustrate the importance of learning objectives for learning performance. Technical concept, media concept, and concept for media and interaction design are prerequisites for successful e-learning implementations. Several recommendations are provided to aid the implementation of e-learning systems for stakeholder which have relevance for researchers and practitioners.",60087601,Universitas Negeri Yogyakarta,Yogyakarta,Indonesia,['1700'],17.0,0.175,0.265,1,0.1276595744680851,0.03546099290780142,0.42105263157894735
180,182,182,A fused extractive summarization approach for kannada text documents,"Text summarization is an application of natural language processing in the field of data mining, used to generate the summary of document. Summarization can be defined as a procedure which reduces the contents of the given input text into shorter structure that contains significant data which is useful for the user in different real-life applications. A lot of methods have been developed to summarize the English text documents yet only a small number of methods have been developed for Kannada text because of lack of resources and tools available for Kannada language. This paper discusses the fused technique for extractive text summarization which selects main sentences from the Kannada document. The proposed approach uses the combination of results of two methods to generate the final extractive summary of Kannada document. The two different methodologies used for Kannada text document extractive summarization are: (a) Summarization based on Clustering (b) Summarization based on the Latent Semantic Analysis. In the clustering approach, Term-Frequency/Inverse Sentence Frequency (TF/ISF) is used to compute the sentence score first and then sentences are grouped by means of clustering algorithm called K-means to produce the extractive summary. In the second approach, latent semantic analysis based on singular value decomposition is used to generate the summary of the document. The consequences of the proposed model are assessed utilizing ROUGE toolkit to measure the performance dependent on three evaluation metrics – Precision, Recall and F-score. The experimentation is performed on the custom-built dataset containing fifty text documents (Kannada) to generate the extractive summaries. The extractive summaries produced by the system are acceptable when compared to reference summaries.",60038307,JSS Science and Technology University,Mysore,India,['1700'],24.181818181818183,0.04947916666666667,0.4713541666666666,1,0.12828947368421054,0.0756578947368421,0.3
181,183,183,Economics of vulnerabilities and security issues of social networking,"Social media and networks provide enormous facilities and conveniences to the registered users but not free from various threats and attacks. Huge information is produced and posted on social network sites by the large intentionally. The posted information encompassed large vulnerabilities[1] that leads to cyber-attacks by the social enemies over the Internet for social exploitation or business deeds. This paper focuses on various unattended and unaware user behavior that leads to vulnerabilities and attacks. Paper also explores various defensive measures to safeguard from social network attacks that are based on user behavior parameters. Further it is also suggested to implement appropriate user behavior model from various model techniques like Classification, Random Forest, Decision Tree and Support Vector Machine for attack detection on social media and networks. Performance of different models is evaluated further by using evaluation metrics that will determine the accuracy of different model(s) to be applied finally.",100340138,Lyallpur Khalsa College,Jalandhar,India,['1700'],21.285714285714285,0.0360248447204969,0.4590062111801242,1,0.1111111111111111,0.043209876543209874,0.34146341463414637
182,184,184,Potential use of fuel cell as electricity generation in malysia: A review*,"The world is in the exploration for new energy resources that can substitute the dominion of fossil fuel in electricity generation. Recently, fuel cell has been addressed as a solution. Currently, an increasing number of studies are focusing on fuel cell as a source to generate electricity. In Malaysia, an average of 86% of electricity is generated from fossil fuel. Therefore, there is a need to explore a variety of alternative energy resources that can generate electricity by decreasing the nation’s dependence on conventional ways. As a tropical country, Malaysia is rich in biomass resources that can be combined with fuel cell for electricity generation. This paper aimed to explore the potential use of fuel cell in the electricity generation sector. Hopefully, the outcome of this paper could serve as a guideline for the development of fuel cell in electricity generation in Malaysia.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1700'],17.875,0.031215213358070506,0.5159554730983302,1,0.1069182389937107,0.018867924528301886,0.225
183,185,185,Electronic tax filing adoption in Jordan: The tax employees’ perspectives,"Electronic Tax Filing (ETF) in Jordan is implemented as part of e-government initiatives to enhance efficiency of Income and Sales Tax Department (ISTD). However, being among users, tax employees’ acceptance and use of technology are interesting concerns. Using the Unified Theory of Acceptance and Use of Technology (UTAUT) framework, this study investigates the effect of four determinants of ETF adoption, namely performance expectancy, effort expectancy, social influence, and facilitating conditions. Through questionnaire survey, data was collected from 204 employees of ISTD. Partial Least Squares Method algorithm was used to test the four hypotheses. The findings signify positive relationship among performance expectancy and facilitating conditions on ETF adoption. While effort expectancy and social influence have no influence on ETF adoption by tax employees. Nonetheless, the overall findings are consistent with the majority of previous studies that user acceptance and use of technology are important in the success of technology adoption.",60070289,Irbid National University,Irbid,Jordan,['1700'],18.625,0.10702479338842977,0.2995867768595041,1,0.06285714285714286,0.11428571428571428,0.4046242774566474
184,186,186,Robust framework based on machine learning and knowledge graph for disease detection,"As Noncommunicable Diseases (NCDs) are influenced or constrained by assorted factors, for example, age, regionalism, practicality or regularity, they are continually testing to be dealt with precisely, which has affected on every day life and work of patients. Sadly, albeit various specialists have just made a few accomplishments (counting clinical or even PC based) on specific ailments, current circumstance is anxious to be improved through PC innovations, for example, information mining and Deep Learning. Likewise, the advancement of NCD inquire about has been hampered by protection of wellbeing and medicinal information. In this paper, a progressive thought has been proposed to contemplate the impacts of different factors on illnesses, and an information driven system named d-DC with great extensibility is introduced. d-DC can group the malady as indicated by the occupation on the reason where the sickness is happening in a specific district. During gathering information, we utilized a mix of individual or family medicinal records and conventional strategies to manufacture an information obtaining model. Not exclusively would it be able to acknowledge programmed assortment and renewal of information, yet it can likewise viably handle the virus start issue of the model with generally not many information adequately. The decent variety of data gathering incorporates organized information and unstructured information, (for example, plain messages, pictures or recordings), which adds to improve the arrangement exactness and new information securing. Aside from embracing AI techniques, d-DC has utilized information chart (KG) to group infections just because. The vectorization of restorative messages by utilizing information inserting is a novel thought in the arrangement of illnesses. At the point when results are solitary, the restorative master framework was proposed to address irregularities through information bases or online specialists. The consequences of d-DC are shown by utilizing a mix of KG and conventional strategies, which instinctively gives a sensible understanding to the outcomes (exceptionally clear). Tests show that d-DC accomplished the improved precision than the different past strategies. Particularly, a combination technique called RKRE dependent on both ResNet and the master framework accomplished a normal right extent of 86.95%, which is a decent possibility study in the field of illness arrangement.",60114276,"Government College of Engineering, Karad",Karad,India,['1700'],25.42857142857143,0.05708314673831915,0.4920697118972982,1,0.1108433734939759,0.03614457831325301,0.32592592592592595
185,187,187,Religious freedom in islam its dimensions and conditions,"Some Qur’anic verses differ from others that they form great Islamic bases, on which certain principles were built and developed. Among such verses we have those verses talking about religious freedom in Islam, which was discussed in the Qur'an under the concept of (compulsion), particularly verse 2/256 which declares that there is no compulsion in religion, a principle which gives the base of human rights, the real dignity of mankind, and the respect of human will. In fact, such verses open the door to understand righteously the issue of freedom in a wide concept, a matter which was declared and practiced during the Islamic reign. On the other hand, some people-whether Muslims or non-Muslims, blame Islam in having compulsion in its legislations and applications: in faith matters, worship matters, criminal law, and interactions, a matter which insists that there is a kind of inconsistency in Islamic rules. May the study can clarify any misunderstanding arises in these applications, particularly the concept and the rules of Turncoat-apostasy, this concept dominates a great attention of scholars and were claimed to oppose the concept of freedom in religion.",60064180,The University of Jordan,Amman,Jordan,['1700'],37.0,0.09014550264550264,0.4729497354497355,1,0.09767441860465116,0.023255813953488372,0.2938388625592417
186,188,188,Design and control of a single phase synchronous inverter for microgrid,"Microgrid power system is becoming popular for utilizing renewable energy. This energy should invert to supply AC for microgrid, but inversion of the renewable energy has suffered some issues; inferior quality of waveform, large phase difference, high switching loss and poor power quality. A new scheme of phase synchronous inverter (PSI) has outline in the microgrid system which improve the quality of the power supply. A pulse width modulation (PWM) signal is generated for PSI to precisely synchronize with the grid line frequency. A lowpass LC filter is utilized to reduce the higher harmonics frequency in the inverter. In this research a resistive load of 40 Ω and input DC voltage ± 35 V has been considered. A PWM of 1600 Hz carrier frequency and 95% modulation index with 50 Hz fundamental frequency has been examined in this project. The simulated results show that the proposed PSI overall efficiency is 96%, total harmonic distortion (THD) is 3.9% and phase distortion is about 4 degrees. Therefore, it is highly appreciated that proposed design will improve the microgrid power supply system.",60016775,International Islamic University Malaysia,Kuala Lumpur,Malaysia,['1700'],19.88888888888889,0.1827863046044864,0.5384651711924439,1,0.09852216748768473,0.07389162561576355,0.3448275862068966
187,189,189,Assets misappropriation awareness in the Malaysian public and private sectors,"Asset misappropriation is becoming one of the major issues in many organizations. It is an occupational fraud which is continuously committed by employees in both public and private sectors even though prevention mechanisms and awareness programs exist. This paper examines the relationships between the four scenarios and asset misappropriation awareness in the public and private sectors. Data for this study is collected through a questionnaire survey and out of 200 distributed, 173 are usable. In addition, four interviews were conducted to enrich the quantitative results. Based on the t-test analysis, a higher mean score is evidenced for private as compared to public sectors employees on the usage of the official vehicle, office’s computer, printer and stationeries, and office utilities. However, a greater mean difference on the usage of office equipment and materials is identified from public sector employees. In addition, regression results reveal a significant positive relationship between Scenario 2 and 3, and asset misappropriation awareness. It shows that both public and private sectors employees are very much aware of asset misappropriation but still continuously committing it. As a conclusion, preventing the act of asset misappropriation is trivial and organizations are facing difficulties in addressing this issue. Yet, neglecting it would create unnecessary financial waste that will have an impact on the organization as a whole. Thus, enhancing asset misappropriate awareness is vital to all employees in the public and private sectors.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1700'],19.33333333333333,0.06499125874125875,0.3796328671328672,1,0.0888030888030888,0.0,0.3023255813953488
188,190,190,"The relationship between human resource development, intrapreneurial competencies and innovative work behaviour","This paper is aimed at examining the connection between human resource development, intrapreneurial competencies and innovative work behaviour. By issuing 284 sample questionnaires to executives at one public organization, this analysis utilized quantitative approach. Partial Least Square (PLS) was used to analyse the collected data. The findings show that the intrapreneurial competencies influences the innovative work behaviour of 53.6%, human resource development influences the intrapreneurial competencies of 32%, human resource development influences the innovative work behaviour of 14.4% and innovative work behaviour model is affected 35% by human resource development and intrapreneurial competencies. This model can be used to further develop the intrapreneurial competencies that most relevant for employees of public sector in order to exhibit innovative work behaviour which be able to integrated into the human resource development of respective organization via training and development. Previously, researchers recognized employees as a major cause of development. Systemic empirical study, however, was not completely implemented to investigate the connection between human resource development, intrapreneurial competencies and innovative work behaviour.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1700'],24.0,0.15783333333333335,0.4489999999999999,1,0.10582010582010581,0.021164021164021163,0.32275132275132273
189,191,191,Slope stability evaluations using limit equilibrium and finite element methods,"Landslide occurrences in Malaysia cause huge economic losses each year and have resulted in over 600 recorded casualties from 1961 to 2011. It is therefore overdue for practitioners and researchers alike in Malaysia to re-evaluate slope stability in high-risk areas prior to any mitigation work. In this study, the case study is focused on one such slope stability evaluation that was conducted at a landslide-prone location, i.e., Maktab Rendah Sains MARA (MRSM), Bentong, Pahang. The evaluation uses limit equilibrium and finite element methods; more specifically, SLOPE/W software for the limit equilibrium method and PLAXIS software for the finite element method. The primary distinction between these two analytical approaches is that finite element methods are based on the stress–strain relationship of the soil whereas limit equilibrium methods are based on static equilibrium that divide sliding mass into smaller slices. Here limit equilibrium methods collectively represent a conventional approach in which the fundamental principles of static equilibrium and interslice forces are used in the past. Conversely, finite element approaches serve as a more realistic indicator for the factor of safety in the absence of stress distribution data. The simulations showed that both methods produce results that are not significantly different, but the use of the finite element method proves to be best-suited for complicated geometries, as those experienced in Malaysia.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],27.25,0.186739417989418,0.4911375661375661,1,0.096,0.056,0.31512605042016806
190,192,192,The relationship of second language communication problems with oral language communication strategies,"This study intended to investigate the effects of communication problems faced by non-native speakers to utilise Oral Communication Strategy (SKBL) while speaking in a second language (Malay). The research instrument consisted of a written test (questionnaire) and oral test (storytelling and dialogue) administered to collect essential data. The study method is a union of quantitative and qualitative. A sum of 130 respondents, including five Chinese students in 16 Chinese National Primary Schools (SRJKC) in Hulu Langat district, were directly affected in this research. As a result of the analysis of transcribed sentence data, it was found that 986 sentences were delivered through storytelling instruments (443 sentences) and dialogues (543 sentences). During the hearing, a total of 525 cases of Oral Language Communication Strategy (SKBL) were used. The application of SPSS through the Cramer V test revealed that Chinese students‟ communication problems with the Oral Language Communication Strategy (SKBL) were interpreted as firmly based on the Cramer V value = 0.364. The conclusions note that second language communication problems faced by non-native speakers have inspired the use of the Oral Language Communication Strategy (SKBL).",60001821,Universiti Kebangsaan Malaysia,Bangi,Malaysia,['1700'],22.875,0.03,0.235,1,0.0958904109589041,0.1552511415525114,0.4372093023255814
191,193,193,The role of biometric technology to protect consumer in online banking transaction,"The development of information technology (IT) in online banking model provides an efficiency and effectively for account holder to conduct online transaction. In this situation, technology and financial services law plays an important role in providing protection of financial identity. Nowadays, the most of online banks offer transaction safety when consumer access to login page of websites to warn users about the existence of such scams. However, the cases of online banking scams have been increasing from time to time. Perpetrator can access to the consumer’s account and do online transaction illegally. Identity theft is one of the fastest growing types of consumer fraud. In this regards, using biometric technology, such as fingerprint technology is very important to protect the consumer identity during online transaction in over the world. It is a form of innovation technology through biometric technology can be used for real evidence in law enforcement at cyberspace. This paper uses qualitative empirical legal research with multidisciplinary research approach through the analysis of legal rules under Indonesian Law on Information and Transaction Electronic. The objective of this paper is examined consumer identity theft protection in online banking transaction through biometric technology application. This paper identified that banking security through biometric application is very important. The biometrics technology can be applied for e-verification as real evidence in detecting authorized user. It will support banking security as an effort for consumer protection.",60112575,Universitas Islam Nusantara,Bandung,Indonesia,['1700'],17.846153846153847,0.18375,0.4375,1,0.09019607843137255,0.0196078431372549,0.25196850393700787
192,194,194,Future fuels for environmental sustainability: Roles of computing,"In this review paper, a number of research studies related to future fuels have been analysed. There have been several studies introduced in order to highlight hazards of fuels produced by different types of transportation and their effects for the environment. Transportation is a vital enabler of human civilizations. Currently, the main fuel source use to power these various modes of transportation is fossil fuel. Two third of anthropogenic greenhouse gases (GHGs) emission originates from fossil fuel combustion in transportation and industrial sector. These GHGs particles are pollutants which have negative impact on the climate and the environment. To reduce these environmentally-harmful pollutants, people are looking into the use of alternative and renewable fuels. Information and Communication Technology (ICT) is regarded as a key instrument to create an efficient transportation system and networks. Therefore, resulting in less fossil fuel combustion. This in turn will curb climate change and reduce carbon footprints. This paper will also review the various roles of ICT in managing sustainability, environmental issues, and their impact on future fuels. This include technologies such as Artificial Intelligence, block chain, internet of things (IoT) and cloud computing. ICT solutions also enable the establishment of intelligent transportation systems and traffic networks.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],15.461538461538463,6.167905692361981e-18,0.4083333333333333,1,0.08695652173913043,0.030434782608695653,0.35526315789473684
193,195,195,Novel tree based efficient data aggregation and dissemination protocol for iot enabled wireless sensor networks,"In recent past, the use of Internet of Things (IoT) enabled Wireless Sensor Networks (WSNs) is significantly increasing in wide range of real time applications like weather monitoring, farm monitoring, security monitoring, military etc. The sensor networks consist of tiny and small energy constrained device called sensor node. As the sensor nodes are energy constrained, short network lifetime is key research problem. The IoT enabled sensor networks may fail early due to energy expiration of sensor nodes. To improve the energy efficiency of such network, various solutions proposed by researchers such as clustering, energy efficient self-organization and deployment of sensor nodes, data aggregation, data dissemination, efficient MAC protocol etc. Data aggregation and dissemination is vital phase of IoT enabled WSNs on which the energy consumption is mainly depends. Thus the efficient design of data aggregation and dissemination improves the energy efficiency of WSNs. In this paper, we proposed the Efficient Data aggregation an dissemination using Optimized Tree based clustering (EDOT) for IoT enabled WSNs. As the name indicates the aim of EDOT is to improve the process of data aggregation and transmission. The main properties of EDOT protocol is build routing tree with less number of messages, increased number of overlapping paths, improved aggregation rate, reliable data aggregation, and reliable data dissemination according to shortest path tree (SPT) and reliable data fusion solution. The main aim of the EDOT is build energy efficient and reliable tree with shortest paths which connect all the source sensor nodes to the intended sink to improve data aggregation and dissemination performance. The simulation results claimed that EDOT improves the performance compared to state-of-art protocols.",60114325,P.E.S. Modern College of Engineering,Pune,India,['1700'],22.5,-0.010317460317460322,0.39603174603174607,1,0.10610932475884244,0.05787781350482315,0.3442622950819672
194,196,196,A random key generation methodology based light weight security model for data-mining based healthcare applications (Dmha),"Data-Mining applications deployed in different types of domains due to its vastapplications such as the medical field, metering system, research and development area, e-commerce,etc.One of the big problems and challenges with these mining applications while retrieving data from the mining servers is data security. Whenever clients are retrieving the sensitive data from the mining servers, there is a chance to hack these sensitive data by the intruders,so it is always a challenging thing to transmit and receive the data between the mining server and clients. It is still suggestible that to overcome this problem, it is mandatory to retrieve the data from the mining servers with the encryption format. The proposed Manuscript was overcomesuch type of issues by the implementation of encryption and decryptiontechniques and applied for the health care applications.",60017411,Acharya Nagarjuna University,Guntur,India,['1700'],32.75,0.071875,0.546875,1,0.06666666666666667,0.02666666666666667,0.2777777777777778
195,197,197,The communication strategies relationship of non-native speakers with extra linguistics factors in target language: A case study,"The study was administered to find the types and frequency of communication strategies used by students of various levels (excellent, moderate and weak) in second language expression. Besides, this study also analyzed the extent to which extra linguistics influenced non-native speaker communication strategies. This study considered oral error as a communication strategy that could benefit non-native speakers. Therefore, the researcher conducted a study at a school called SRJKC Onn Pong 2. A total of 30 students of different competency levels (ten excellent, ten moderate and ten weak) from standard five batches were involved in this study. The findings showed that all levels of students used the non-verbal communication strategy (SKBBL) as much as 173 cases in comparison with 96-language oral communication strategy (SKBL). The types and frequency of communication strategies vary by student level. A total of 269 cases were used by excellent students (77 cases), moderate students (82 cases), and primary students used the most communication strategies, which were 110 cases. Also, the findings of the analysis indicate that the extra-linguistic for non-native speakers play an important role in determining the type and frequency of communication strategies that should be used during speech with interlocutors.",60001821,Universiti Kebangsaan Malaysia,Bangi,Malaysia,['1700'],21.777777777777782,0.17045454545454544,0.5113636363636364,1,0.08936170212765958,0.02127659574468085,0.37777777777777777
196,198,198,Seasonal wind pattern model development for coral reef monitoring,"Wind pattern model development is vital for coral reef monitoring due to its dependency on sea surface wind. Wind in Malaysia is influenced primarily by four monsoon season; Northeast and Southwest monsoon with two transition period; April and October inter monsoon and categorized as low wind with annual mean speed of 3-5 m/s. Current wind study utilized limited wind data hence neglects the seasonal characteristics of wind behaviour in wind pattern model simulation. In this study, the Mixed-Layer Conveyor (MLC) model was adopted to simulate wind parameters such as wind speed distribution, direction, days in distinct monsoon to derive cumulative wind of distinct season. This can be used to describe wind behaviour of distinct monsoon season on coral reef growth. Result shows that the derived cumulative wind fit with an actual wind data (0.89). The model developed has an ability to derive seasonal wind cumulative productivity data to be used in estimation of the highest wind and lowest wind production.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],22.857142857142854,0.0993622448979592,0.3575255102040816,1,0.08791208791208792,0.04945054945054945,0.22727272727272727
197,200,200,A deep-dive into information retrieval systems: Statistical perspective,"Evaluation of user queries in order to provide highly-accurate search results within a time limited window has been the pillar-stone formula for designing any information retrieval system. In order to perform this task, various retrieval models like Boolean-model, vector-space model, languageprocessing model, etc. have been proposed by researchers over the years. The major challenge for any information retrieval system designer is to select the best model suited for the application under development. Selection of this model requires an algorithm which can fulfill the constraints of query processing delay, retrieval accuracy, and the desired level of precision and recall values. In order to assist such researchers, in this paper we have analyzed and evaluated the recent state-of-the-art retrieval systems, and compared them in terms of general precision, recall, accuracy and delay metrics. Based on this review, researchers can select algorithms which are most suited for their system, and also improve on them based on the recommendations which are mentioned about these algorithms in this text.",60036724,Shri Shivaji Science College Amravati,Amravati,India,['1700'],23.42857142857143,0.19263392857142855,0.3991071428571429,1,0.10152284263959391,0.01015228426395939,0.3005464480874317
198,201,201,Selection of input data of artificial neural network to improve performance for long-term load forecasting,"The paper describes a method to select input data of artificial neural network (ANN) to improve performances of training and prediction for long-term load pattern. The paper focuses on forecasting weekly peak load during a year. Generally, the ANN has been used to forecast short-term load because the training data can be less and the data with high correlation can be easily obtained. However, it is difficult to decide the ANN structure and to select proper input for long-term load forecasting via the ANN. In the paper, the effect of several input data is investigated and the smoothing method is applied to improve the training performance. The results of the paper are obtained by applying the proposed ANN model to forecast load data in South Korea.",60103616,Kongju National University,Gongju,South Korea,['1700'],21.0,-0.07791666666666665,0.505,1,0.13286713286713286,0.04895104895104895,0.24087591240875914
199,202,202,Factors affecting client’s involvement in construction projects,"The client has a great influence on construction activities, which will decide the success or failure of a particular project. Hence, the client's goal is to attain the desired outcome through good design, good planning, and good construction. It has been suggested that success in construction projects is attributed to the knowledge and skills of the client. The client’s perception of their role affects their decisions making capabilities in the early project phases. Furthermore, clients needed to understand the entire desired quality requirements to ensure full satisfaction. The client, as project owner has to ensure that the project is undertaken in a manner such that all risks are minimized. When clients are close and frequently participating in managing a project they are mostly pleased with the outcomes. Therefore, clients are considered to be the energetic force in the construction sectors as well as a central to the construction projects. The improvement in low client participation in construction sectors is necessary to enhance the client findingthe ideal blend of performance. Therefore, it is significant to recognize the attributeswhich reduces the client participation in the construction sector so that efforts can be taken to mitigate this important concern. Hence, this paper presents a systematic review to gain a better picture of the factors affecting client involvement in the construction sector in Sultanate of Omanand thereafter proposing the appropriate recommendations for active engagement of clients in projects.",60071776,Dhofar University,Salalah,Oman,['1700'],21.272727272727273,0.31006944444444445,0.5409722222222222,1,0.109375,0.0078125,0.26459143968871596
200,203,203,Preschool teachers’ professionalism through developmentally appropriate practices (Dap) curriculum,"When discussing the education system quality of a country, the main focus points to teachers’ professionalism. Teachers are the foundation to the education system as they are the implementors to the policy, curriculum goal and the government’s desires. Professional teachers will always perform the duties and responsibilities assigned to them with full dedication. In formal education in Malaysia, preschool is the most critical period to prepare children with various skills, self-esteem and positive attitudes for the next phase of learning. Even though many efforts have been implemented by the ministry to increase teachers’ professionalism, there still 9exists preschool teachers who failed to implement the curriculum as expected. Thus, this concept paper discusses the concept of Developmentally Appropriate Practices (DAP) to build the professionalism of preschool teachers. DAP is the basic knowledge that needs to be mastered by preschool teachers regarding appropriate teaching and learning strategies for children.",60103633,Universiti Pendidikan Sultan Idris,Tanjong Malim,Malaysia,['1700'],21.0,0.1602813852813853,0.4038419913419914,1,0.09580838323353294,0.029940119760479042,0.3313253012048193
201,204,204,Emotional intelligence and doctor’s counterproductive work behavior: The mediating role of leader member exchange quality,"We investigated the moderating function of the Leader-Member Exchange Quality (LMXQ) in the relationship of Emotional Intelligence and Doctor’s Counterproductive Behaviour. Accordingly, the purpose of this research is to examine the immediate influence of leader-member exchange quality and emotional intelligence on counterproductive work performance. This analysis was administered by employing data collected from 408 Indonesians’ doctors of a government hospital. Measuring tools adopted from the Counterproductive Work Behavior-Checklist (CWB-C) including of 45 items, Emotional Competency Inventory (ECI) consisting of 50 items and Multidimensional Instrumental Leader-Member Exchange (MDM-LMX), data were investigated applying Confirmatory Factor Analysis (CFA) and Structural Equation Modelling (SEM) with SPSS version 22 and AMOS version 23. The results revealed that the hypothesized model has the best-fit standards, with the specification model presenting a more reliable goodness-of-fit. Mainly, the outcomes confirmed that leader-member exchange quality, together with emotional wit, carries a direct negative and vital impression on counterproductive work performance. This investigation further supported that there is a negative indirect and notable effect factor of emotional intelligence on counterproductive work behaviour through leader-member exchange quality as mediators. Further, predictor factors namely emotional intelligence, added 23%, and leader-member exchange quality gave 23% on variance counterproductive work behaviour. In conclusion, emotional intelligence and leader-member exchange quality was the deciding constituent for counterproductive work practice. The value of counterproductive work behaviour in this research offers to supplement the theories of organizational behaviour and adds to the execution of human resource development and administration within the company.",60110631,Universitas Islam Negeri Raden Fatah Palembang,Palembang,Indonesia,['1700'],24.4,0.06666666666666668,0.5043859649122808,1,0.0749185667752443,0.12052117263843648,0.4397163120567376
202,205,205,Assessing environmental education through KBSM social sciences subjects: Three case studies,"The issue of flood disaster is becoming more prevalent in the present days of Malaysia. Flood is an annual recurring problem and it causes issues of discomfort, economic loss, health and the social well-being of Malaysians. To cope with this hydrometeorological disaster, the authoritative Sendai Framework for Disaster Risk Reduction 2015-2030 (2015) (Hereafter Sendai Framework) identified education as one of the best avenues to cope with flood disaster. This paper focuses on the 4th priority area in the Sendai Framework which aims is enhancing disaster preparedness for effective response and to “Build Back Better” in recovery, rehabilitation and reconstruction. Hence, this paper examines flood education through KBSM social sciences subjects with the idea that the Malaysian secondary school curriculum can help to enhance the preparedness among the students. The social sciences subjects chosen are Geography, English and Moral studies in Malaysian school system. The aim of this paper is to examine the coverage of flood related issues in the KBSM textbooks as well as the ways in which the issues are being discussed and manifested. The methodology used is qualitative content analysis. The findings indicate that in the Malaysian secondary school curriculum, English textbooks have more flood related topics than Moral studies and Geography. The issues discussed in the English textbooks are very current, varied and able to elucidate the synergy of knowledge.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],22.3,0.16875000000000004,0.32479166666666665,1,0.09561752988047809,0.07171314741035857,0.3157894736842105
203,206,206,Challenges and survival of households with deficient income,"The research is conducted in surburban area of Selangor, Malaysia, focusing on B40 group of people. B40 is a classification of bottom 40% consisting of citizens who incomes below than RM3,000 per month. The objective of the study is to explore the B40’s household survival with insuficient income. B40 is the lowest category of income group in Malaysia. The study employed qualitative method and twenty participants were inerviewed. The result shows that B40 group of people is struggling for basic necessities due to low income, low education level, high risk in job loss, inability to work and lack of retirement plan.",60012005,Multimedia University,Malacca Town,Malaysia,['1700'],16.833333333333336,0.0058333333333333345,0.29,1,0.07894736842105263,0.07017543859649122,0.30434782608695654
204,207,207,Three level cloud storage scheme for providing privacy preserving using edge computing,"With the rapid growth of unstructured data, cloud storage gets more and more attention for the advanced development. Inprimitive cloud storage schema, the entireuser’s data is totally stored into the centralized cloud servers. In other words, users lose their right of control on data and face privacy leakage risk. In this proposed thesis we developed a multi-layer approach in order to store the sensitive data in a secure manner from the cloud server. Here we have integrated edge computing concept for the current cloud in which the data can be stored on a multiple edges rather than all the data in a centralized server. Here we try to divide the original data into multiple edges or blocks in which each and every block is encrypted by the data owner. We try to apply Hash Message Authentication Code (HMAC) Algorithm for generating hash codes for individual blocks. The data user tries to access the fileby sending request to the all individual edge nodes controlled by cloud server. The cloud server and its associate edges need to give access permissions to the requested users in order to view the file in a decrypted manner. Those who don’t have access permission from multi level cannot be viewed in a plain text manner.",60115565,Vignan's Nirula Institute of Technology and Science for Women,Guntur,India,['1700'],20.9,0.130672268907563,0.4569327731092437,1,0.11353711790393013,0.03056768558951965,0.27074235807860264
205,208,208,A pilot study of an improved agile hybrid model in managing software projects success,"Managing software projects successfully requires the use of effective and robust methodologies. The Agile Manifesto in 2001 introduced 4 values and 12 principles as a set of development and management criteria to provide a more suitable and effective way to design and use agile methods in software projects. The agile management methods have improvedthe success rates of software projects, but the increase is not significant. Agile hybrid management methodshave shown more promise when compared to pure agile methods with an overall increase of 16%. A review of the current hybrid models have identified some gaps to be addressed and improved for the hybrid approaches.This paper presents a pilot study analysis of an initial model development for an improved agile hybrid model with experts in the software industry.The findings support the model based on the questionnaire review and a pilottest analysis.",60105696,Asia Pacific University of Technology and Innovation,Kuala Lumpur,Malaysia,['1700'],28.0,0.379265873015873,0.5875,1,0.09933774834437085,0.013245033112582781,0.3129251700680272
206,209,209,Design of metamaterial-based bandstop filters using complementary split ring resonators,"In this study, a miniaturized metamaterial bandstop filter (BSF) based on complementary split ring resonators (CSRRs) is presented. The filter is constructed on low dielectric constant substrate, which combines the conventional filter characteristics and the negative permittivity properties of the metamaterials to establish a metamaterial filter. The negative permittivity metamaterial is produced by CSRRs, which are etched in the ground plane. Two and three CSRR unit cells are cascaded in a periodic manner to design a high performance BSF. The frequency characteristics of the proposed filters are successfully designed and optimized using numerical experimentation techniques. The major parameters affect the filter performance is being investigated. The results show that the compact SBF has an insertion loss less than 0.5 dB and easily adjustable rejection bands of about 3.2 and 4.6 GHz widths using cascaded CSRRs cells periodic structures. Simulation results based on a 3D full-wave EM simulator are presented in this paper.",60018623,South Valley University,Qena,Egypt,['1700'],19.0,0.04963095238095239,0.4680476190476191,1,0.1242603550295858,0.029585798816568046,0.39520958083832336
207,210,210,E-service quality-impact on customer satisfaction,The paper aims to determine the impact of e-service quality on customer satisfaction. The study utilised data from 252 customers of private and public banks in India through questionnaires. It was found that the e-service quality has significant impact on customer satisfaction in public sector banks as well as private sector banks.,124036331,Centre for Management Development,Ghaziabad,India,['1700'],17.333333333333332,0.075,0.3516666666666667,1,0.06779661016949153,0.03389830508474576,0.2727272727272727
208,211,211,Complications with routing in manet’s and proposed framework for effectively improving classification accuracy,"In Wireless mobile ad-hoc networks, there is no preset topology as a result of the wheelchair of nodules, disturbance, multipath propagation, and also pathway loss. For this reason, a robust routing procedure is required for these networks to work correctly. A lot of Routing protocols have been established for completing this job. This paper delivers idea into the several attacks as well as discusses the technological challenges that process professionals, as well as network designers, are dealt with as well as goes over the formula for computing manet reliability. This paper can be used to evaluate the reliability of mobile ad hoc networks under different conditions and also proposed a framework for improving classification accuracy.",60104126,Jouf University,Sakakah,Saudi Arabia,['1700'],23.0,0.0,0.3,1,0.11627906976744186,0.0,0.2992125984251969
209,212,212,Performance enhancement of a squashed mender antenna for wireless sensor network applications operating in ISM band,"Immense achievements have been reached in antenna engineering since the pioneer work of Hertz and Marconi in demonstrating the existence of radio waves. An uninterrupted development and state of art designs of patch antennas leads a significant enhancement in the performance of wireless sensor network (WSN). The deployment of patch antenna in WSN significantly reduces the size of the sensor node and provided better impedance matching and hence better power transfer. With a patch antenna by means of optimized geometry and matching structure, a size optimization and better power transfer is possible in WSN. In this paper a very basic traditional shape of mender antenna is considered which on modification results in better return loss and size reduction in comparison with some existing work. The proposed work presents a low profiles & better return loss mender antenna designs operating on 2.4GHz, ISM band with fabrication results proposing that the projected designs contribute for performance improvement of WSN and provides good impedance matching.",124036326,Gondavana University,Gadchiroli district,India,['1700'],27.0,0.28214285714285714,0.5758928571428571,1,0.0872093023255814,0.046511627906976744,0.25
210,213,213,"Issuance of units in rights offerings, agency cost and signaling theory","We examine the issuance choice of unit offerings made by Malaysian publicly listed firms. Our results show that smaller and riskier firms with less earnings, lower ownership concentration and lower liquidity tend to choose unit offerings than equity rights offerings. We also find that the market reacts more negatively to the unit offerings during the subscription period indicating that the market prefers equity rights offerings rather than units to raise capital in Malaysia.",60006925,La Trobe University,Melbourne,Australia,['1700'],24.33333333333333,0.0066666666666666775,0.30666666666666664,1,0.14285714285714285,0.025974025974025976,0.2987012987012987
211,214,214,Looking into “awéwé” and “lalaki” in the sundanese magazine manglé local wisdom and a corpus analysis of the linguistic construction of gender,"This study uses methods in corpus linguistics to examine the construction of gender, based on word usage patterns of awéwé ‘woman’ and lalaki ‘man’ in a 2.9 million-word corpus of Sundanese magazine Manglé. The linguistic construction of gender is discussed as empirical evidence of how Sundanese local wisdoms may give an impact on ways of speaking about man and woman. Using the corpus software WordSmith Tools, frequency analysis demonstrates that woman was more popular to talk about than man that is indicated by the higher frequency of awéwé than of lalaki. Following this, an analysis of the top 30 significant collocates of awéwé and lalaki discovers that the following semantic categories were referenced: kin, people, relationship, body and physical appeareance and age. Other semantic categories, however, were specific to particular gender terms, i.e. general ethics found only in collocates of awéwé, while personal traits and power solely found in lalaki. A close examination of the concordances reveals that the usages of awéwé seem to represent that woman is weak and dependent on man, while the usages of lalaki tend to signify that man is strong and powerful. The result of corpus analyses is apparently in line with the Sundanese traditional knowledge that expects woman to be submissive to man. Thus, the present paper argues that corpus-based analysis can be used to investigate the manifestation of local wisdoms in language use.",60069388,Universitas Padjadjaran,Bandung,Indonesia,['1700'],25.555555555555557,0.12187499999999996,0.41289682539682543,1,0.11196911196911197,0.023166023166023165,0.28515625
212,215,215,Landslide occurrences in Malaysia based on soil series and lithology factors,"Past researchers have created various techniques to analyse landslide occurrences. Those techniques utilize qualitative, quantitative or semi-quantitative approaches. Each technique poses advantages and disadvantages depending on the available information, landslide inventory or area of interest. In Malaysia, landslides have become an alarming issue and fatalities are increasing in every event. These fatalities can be reduced if the landslide prone areas are mapped using zonation techniques. The main aim of this research is to produce a hazard risk map using the susceptibility index based on soil series and strata lithology in the state of Selangor, Malaysia. Over the past 20 years, this state has developed rapidly, and many housing schemes have been developed to accommodate high market demand. Moreover, this state has contributed the largest number of landslide tragedies in the past compared to the other states. Susceptibility index based on soil series and strata lithology provides high reliability after validation with past tragedies. Analytical Hierarchal Index (AHP) has been deployed to find the ranking and susceptibility index for those two factors. It was found that urban land soil series and acid intrusive lithology provide higher weightage of landslide susceptibility compared to other series or lithology. Any locations with those series and lithology will pose a critical level of landslide vulnerability. The overlaying of various series and lithology on the state of Selangor map reveals that three provinces, namely Gombak, Petaling and Hulu Langat should be given special attention should future development is to be carried out in these territories.",60107670,Nilai University,Nilai,Malaysia,['1700'],19.153846153846157,0.040181405895691615,0.3933219954648526,1,0.12363636363636364,0.05818181818181818,0.32234432234432236
213,216,216,Investigating factors of service quality influencing patient satisfaction towards patient loyalty,"The main purpose of the paper is to recognize the service quality factors impact on patient satisfaction in health clinic towards patient loyalty. The study is based on surrey approaches for the preliminary pilot test of 50 respondents. This study was fully conducted in quantitate study and implementation of research was conducted in Melaka, Malaysia. The research model included four dimensions which ate infrastructure quality, procedural quality, interaction quality and personnel quality. The results are based on descriptive analysis and reliability tests and all dimensions are significant when testing reliability. The research provided further research and pilot-based data.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],16.333333333333336,0.18055555555555555,0.5694444444444444,1,0.09174311926605505,0.027522935779816515,0.21495327102803738
214,217,217,The implementation of age-friendly services for the elderly living alone,"Recently in Korea, with the transition to a rapidly aging society and nuclear family, the number of old people suffering from chronic diseases and loneliness has also increased. Thus, there is a great need for providing convenience and safety support services, especially for the elderly living alone. In this paper, we propose an age-friendly service that locates belongings in the home and protects the elderly from danger outside the home. First, for the elderly living alone who often lose their important belongings due to forgetfulness, we provide the convenience service of finding the lost items through the smartphone. Second, the safety support service is implemented to protect the elderly from sudden traffic accidents and dangers when going outside. We have developed an application that finds the location of personal belongings through Bluetooth communication with smartphones by attaching small beacons to wallets and car keys that older people with forgetfulness or dementia often lose in the house. On the other hand, when an elderly person with poor hearing ability fail to hear warning sounds or vehicle closures on the road, a neck pillow which can sensitize these sounds and warn the elderly avoid accident using vibrations is implemented. While the existing elderly support system is mainly aimed at providing living convenience, health care and emergency response for the elderly, the proposed system is focused on assisting elderly people with forgetfulness and preventing traffic accidents. If the proposed system is distributed countrywide, the elderly living alone will be able to live independently and safely at low cost, either at home and outside the home.",60031231,Semyung University,Jecheon,South Korea,['1700'],29.11111111111111,0.05082070707070707,0.3770833333333334,1,0.13240418118466898,0.003484320557491289,0.24912280701754386
215,218,218,A study on the improvement of spatial awareness and the appropriate service distribution of examination centers using pedestrian-based discrete event simulations,"Background/Objectives: In an aging society and while economic conditions improve, the general public’s interest in health is increasing, and the concept of medical care is shifting from treatment to proactive management. Therefore, the health examination center is emerging from a medical auxiliary facility to a key and independent medical facility. However, medical facilities are not easy to design and improve because of the complex relationship between humans and space and the variable characteristics of humans. Methods/Statistical analysis: This study used a medical examination center currently in operation as an example to analyze the issues and develop improved methods of applying a pedestrian-based discrete event simulation. Four evaluation and verification indicators were presented for the evaluation and a simulation analysis tool was developed to derive the indicators. After identifying the examination time and the number of people to be accommodated through the simulation, the problems were derived based on the flow of human traffic and cause of queues. After resolving the problems by reducing the waiting time through adjusting the number of services and improving the spatial awareness by rearranging the space, the effects of reducing the waiting time, increasing the number of people accommodated, and shortening the moving distance were demonstrated through verification analysis. Findings: As a result of the study, the main reasons that extend the overall examination time was due to the increase and concentration of queues, which means that adjusting the number of services and the distribution of the queues to the services greatly helped to reduce the overall examination time. Improvements/Applications: This study is a basic research intended to develop a program for analyzing the spatial environment of examination centers. Further studies will be performed to complement tasks such as improving spatial recognition by analyzing the examination sequence and improving data reliability through repeated simulations.",60015143,Inje University,Gimhae,South Korea,['1700'],29.9,0.019,0.2683333333333333,1,0.14457831325301204,0.009036144578313253,0.24615384615384617
216,219,219,A novel approach for segmentation of typewritten gurmukhi script,"Demand of OCR (Optical Character Recognition) based frameworks have expanded definitely because of their noteworthy focal points into continuous applications. Segmentation assumes a significant job in optical character recognition of typewritten Gurmukhi script. Segmentation of typewritten documents is a challenging task due to the presence of skewness, overlapping, and degraded characters. Improper segmentation can hamper accuracy of character recognition. In this paper, we are proposed a new technique for line segmentation by modifying A-star algorithm and combining it with strip-based projection. Character segmentation technique is also proposed on the basis of horizontal and vertical projections combining with the aspect ratio of characters. We have accomplished accuracy of 94.28% and 99.78% with pixel count for line segmentation and 95.70% for character segmentation.",60016760,Punjab Technical University,Jalandhar,India,['1700'],17.285714285714285,0.1810606060606061,0.6174242424242424,1,0.09285714285714286,0.06428571428571428,0.34558823529411764
217,220,220,Software engineering for distributed systems security: A practical approach based on problem-oriented language paradigm,"Securing distributed systems remains a significant challenge for several reasons. First, the security features required in an application may depend on the environment in which the application is operating, the type of data exchanged, and the capability of the end-points of communication. Second, the security mechanisms deployed could apply to both communication and application layers in the system, making it difficult to understand and manage overall system security. This paper presents a policy-based approach to meeting these needs. We propose a framework based on a Domain-Specific Language for the specification, verification and implementation of security policies for distributed systems. Based on a set of abstractions, this framework allows to develop modular security policies and independent of the underlying system. Thus, security policies can be developed by a developer who is not necessarily computer security expert.",60070316,Université de la Manouba,Manouba,Tunisia,['1700'],19.285714285714285,0.025,0.4037037037037037,1,0.16666666666666666,0.019230769230769232,0.28
218,221,221,Enhanced security of public integrity auditing for outsourced data in cloud storage,"Cloud storage is now being used for storing all types of data like financial, medical, legal, technical, etc. and offers significant benefits over local storage. In addition, data access needs to be controlled and regularly audited to prevent unlawful access. The objective of this paper is to offer a secure and efficient public integrity auditing method for dynamic data in a cloud storage with dynamic data operations. In this scheme, the file-sharing and dynamic operations like append, insert, delete, and update uses algebraic signature properties. To minimize the auditing cost, an index table has been used with less difficult operations in contrast to bilinear pairing. This is poised to incur minimum computation overhead at the data owner side. Finally, the performance evaluation shows that the proposed scheme is more secure and efficient in comparison to other presented schemes.",60093099,KIET Group of Institutions,Ghaziabad,India,['1700'],17.25,0.05916666666666667,0.3030128205128205,1,0.11949685534591195,0.0,0.2929936305732484
219,222,222,Performance characteristics of a single cylinder diesel engine fueled with blends of sal seed oil and diesel,"The present work deals with an underutilized vegetable oil; Shorea Robusta (Sal) belongs to the family of Dipterocarpaceae. Sal has an important role in the economics of central states of India (i.e. Orissa, Jharkhand and Madhya Pradesh). These states cover about 45 % of forest area. Sal is a deciduous tree that reaches up to 50 m height. The pressure filtered Sal seed oil was transesterified into Sal seed oil Methyl Ester (SOME). The kinematic viscosity (5.85cSt), density (865 kg/m3) and calorific value (38349 KJ/kg) of the SOME were well within the ASTM/EN standard limits. Various test fuels were prepared for the engine trials by blending 10%, 20% and 30% of SOME in diesel on volumetric basis and designated as SOME10, SOME20 and SOME30 respectively. The BTE, in general, was found to be decreased with increased volume fraction of SOME in the blends. At full load, BSFC for SOME10, SOME20 and SOME30 were 0.18kg/kWh, 0.17kg/kWh and 0.15kg/kWh respectively as compared to 0.19kg/kWh in case of diesel. It may be concluded from the experimental investigations that Sal seed biodiesel is a potential alternative to diesel fuel for reducing dependence on crude petroleum derived fuels and also to reduce pollution significantly.",109492163,S. G. Balekundri Institute of Technology,Belgaum,India,['1700'],18.09090909090909,0.012500000000000002,0.4982142857142857,1,0.07258064516129033,0.13709677419354838,0.4127659574468085
220,223,223,Csr policy towards promoting societal benefits: An analysis on criticism and favourable arguments,"As all businesses try to inline with laws and regulations on social, environmental and economic objectives set by the legislations and legal institutions, CSR is often understood as involving the private sector commitments and activities those extend beyond this foundation of compliance with laws. In fact the key features of the concept is the way businesses engage or involve the shareholders, employees, customers, suppliers, governments, nongovernmental organizations, international organizations and other into the organization. Corporate Social Responsibility means, giving back to society what it gets from society. Corporate Social Responsibility is about capacity building for sustainable livelihoods. CSR means the obligation of companies to stress on their social, ethical and environmental performance as on their financial performance. After globalization of world economies most of the companies and business firms in India either already have a CSR practices initiatives or are in process of taking the initiatives. The study is to attempt the CSR principles, criticism and favoritism to the society. The results will be the identified by the major CSR initiatives taken up by the companies’ promoting social activities in India.",60016712,Alagappa University,Karaikudi,India,['1700'],22.625,0.06689814814814815,0.2268518518518519,1,0.09950248756218906,0.05472636815920398,0.3582089552238806
221,224,224,Sponge function based authentication encryption technique (SAFE) using robust initialization vector and ChaCha stream cipher,"In current times there are various categories of encryption algorithms which work on different structure; like AES, TDES and DES works on symmetric key cryptography, RSA works on Asymmetric key cryptography; another technique which aims at increasing security of algorithm is authenticated encryption. It is difficult to compare algorithms of different category but there are some factors in which encryption algorithms of every category can be compared; namely, time to encrypt, time to decrypt, frequency table and mainly security. This paper aims at comparing one algorithm of each category and check which one is best. SAFE is taken from authenticated encryption, which is claimed to be better than AES when implemented on software. RSA is taken from asymmetric key cryptography, which is first of its kind and still considered as one of the best encryption algorithm. All these algorithms are first implemented using GO language and results are compared to find best results in time and security.",60076774,"Amity University, Noida",Noida,India,['1700'],26.16666666666667,0.2803921568627451,0.5823529411764707,1,0.12716763005780346,0.05202312138728324,0.28901734104046245
222,225,225,Willingness of women in engineering towards the purchase of green smartphone in Delhi NCR (India),"Purpose: The present research paper is worked out with a purpose to find out if there exists any relevant difference in the willingness of working and non-working women in engineering towards the purchase of green Smartphone. Design/ Methodology/ Approach: The research was conducted though a survey in order to develop an understanding about the willingness of women in engineering (both working and non-working women) towards the purchase of green Smartphone in Delhi NCR region of India. The data was collected from five major cities of National capital region viz. Gurgaon, Noida, Delhi, Ghaziabad and Meerut with the help of Questionnaire as a research tool. Further, the data was analyzed and the hypothesis were tested using the two independent samples Mann-Whitney U test. Findings: The findings of the study revealed that though there may be lot of difference in working and non-working women in engineering with regards to various parameters such as income, working status, etc. but there is no relevant difference in the women’s willingness to purchase green smartphone. Limitations: The main limitation of the study is that the women respondents chosen for the study belongs to selected cities of Delhi National capital region and therefore, the geographical coverage is restricted to NCR. Practical Implications: The outcomes of the research study will enable marketers to have a better understanding of the women’s willingness to purchase green smartphone. The study will enable marketers to understand the willingness of women to purchase green smartphone in nearby future, willingness to purchase green smartphone despite of low budget, willingness to purchase green smartphone though it is complicated, willingness to purchase smartphone though already possessing one and willingness to purchase green smartphone for replacing the existing one. This will enable the marketers to understand the difference if any in working & non-working women’s buying behavior with regards to willingness to purchase green smartphone. The better understanding of the buying behavior enables marketers in formulation of right set of market strategies for grabbing a competitive position in the chosen target market. Originality/ Value: The present research work is the original work of the authors and the data collected for the study provides understanding about willingness of women in engineering towards purchase of green smartphone which enhances the understanding of organizations marketing smartphones and considering women as an important segment of the market. The research provides valuable insights that may enable marketers to focus on women consumers and frame right set of strategies. Article Type: Research Paper.",60093099,KIET Group of Institutions,Ghaziabad,India,['1700'],27.33333333333333,0.009503284072249587,0.4311986863711002,1,0.11159737417943107,0.045951859956236324,0.28444444444444444
223,226,226,The components which affect the adoption of e-government applications in Jordan,"The goal of the following paper will be to analyze the reasons which affect the adoption of citizens in Jordan of the e-government. The model of research was improved relying on the collaboration of the diffusion of innovative and technological approved model in addition to the examination of the mediating effect of perceived usefulness and perceived trust on the relationships among the adoption of e-government in Jordan and perceived ease of use. In order to examine the relationships which are empirically hypothesized among numerals a replica consisting of the variables mentioned earlier was improved relying on the review of literature. Utilizing AMOS program 22 and using Structural Equation Modeling (SEM), this model was analyzed. A descriptive, quantitative explanation of a self-administered built questionnaire which was created to analyze the relationships of models and distributed on. The information was gathered using a questionnaire of Likert-scale from poor, urban citizens 416 who are Jordanian. Empirical resolutions show that Image had a greatly positive effect on adopting e-governments, perceiving usefulness and adopting e-government findings also revealed that perceived trust impacts greatly on the perceived ease of utilization and the adoption of e-government in Jordan. The outcomes can be helpful for the companies to improve their service for their consumers by the strategies of the online buzz marketing.",60070289,Irbid National University,Irbid,Jordan,['1700'],26.75,0.14747474747474745,0.41060606060606064,1,0.15289256198347106,0.049586776859504134,0.31140350877192985
224,227,227,A framework for implementing blockchain with enhanced e2e encryption on ethereum 2.0,"Blockchain is technological platform having distributed ledger which is shared by all the participants in the blockchain and each participant have its own replica of shared ledger, Blockchain is Best Suitable for the Application where Trust is an issue as Blockchain Provide Trust in an untrusted Environment because of its Immutable Nature.E2E Encryption Algorithm is another way to build and convince Users for secure messaging over chat such as WhatsApp claim that they are using E2E encryption to provide trust to the users, it provides secure way of communication between the End 2 End nodes over the network. This paper proposes a framework for Implementation of Enhanced E2E Encryption Algorithm over social Network by using Ethereum 2.0.",60113718,"Teerthanker Mahaveer University, Moradabad",Moradabad,India,['1700'],58.5,0.4261904761904762,0.5452380952380953,1,0.08943089430894309,0.14634146341463414,0.371900826446281
225,228,228,Ad hoc on-demand distance vector (AODV)routing protocol invehicular ad hoc network (VANET): An analysis study,"One ofvariation Mobile Ad-hoc Network(MANET) is a Vehicular Ad Hoc Network (VANET). Vanet also part of Intelligent Transportation Systems (ITS) that uses cars as nodes of a network of a mobile network. The communication types in VANET are categorized into three types which are vehicle-to-vehicle communication (V2V), vehicle-to-roadside communication (V2R) and vehicle-to-infrastructure communication (V2I) [2].The routing protocol investigated in this research is topology-based ad hoc routing protocol that is Ad hoc On-Demand Distance Vector (AODV). The routing analysis of this protocol is evaluated based on throughput and packet drop. This research investigates the latest trend of routing protocol used in VANET, evaluate the routing protocol in VANET using TWO (2) performance parameters and to implement the routing protocol in VANET in network simulator. This research was conducted using Network Simulator (NS-3) simulation.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],22.0,0.65,0.9,1,0.10795454545454546,0.14204545454545456,0.5185185185185185
226,229,229,A comprehensive study on traditional AI and ANN architecture,"A computer unit is able to perform jobs that typically call for individual intelligence, including visual belief, speech recognition, decision-making, and interpretation between languages. Artificial Intelligence has made it possible. Deep discovering is actually a part of machine learning, as well as artificial intelligence is a part of AI, which is a sunshade phrase for any type of computer program that performs one thing wisely. In short, all artificial intelligence is actually AI[1], yet not all AI is actually artificial intelligence, and so forth. Machine Learning represents a crucial evolution in the business of computer science, information review, software program engineering, and also artificial intelligence. This paper provides an assessment on machine learning, deep discovering, traditional AI and also ANN architecture.",107147343,S R Engineering College,Warangal,India,['1700'],20.166666666666668,-0.1568627450980392,0.6220588235294118,1,0.04861111111111111,0.0625,0.3194444444444444
227,230,230,A study on the effect of quality management activities on business performance-focusing on small and medium-sized manufacturing business,"Background/Objectives: This study is designed to identify key elements of small businesses through enterprise-wide quality management and establish a direction of consulting to improve management performance Methods/Statistical analysis: The subjects of the study were small and medium-sized manufacturing business and surveyed by survey method. From October to November 2017, 208 questionnaires were collected and examined, and 179 copies were analyzed excluding 29 copies not belonging to small and medium-sized manufacturing business. validity Analysis and Reliability analysis, regression analysis were performed using SPSS 22.0. Findings: Factor analysis was performed on six independent variables and two dependent variables. The results were fit to factor analysis with KMO (.864 or higher) and Bartlett (.000).Factor load was removed from 34 factors among 61 factors and loaded with 27 factors. Reliability analysis showed that the reliability of Cronbach's Alpha was over .814.Correlation was significant in the p-value <.01 and correlated in the positive direction. In financial performance, leadership, strategy, customer, measurement/analysis/knowledge management were rejected as t value smaller than ±1.96 and significance level> .05. And, workforce and operations have t value greater than ± 1.96 and adopted as significance level <.05.For small and medium-sized manufacturing business, it can be seen that workforce and operations have a significant impact on profitability, sales and cost competitiveness. Non-financial performance strategy, measurement/analysis/knowledge management was rejected and leadership, customer, workforce, operations was adopted. The results show that leadership, customer, workforce, and operations affect corporate image, work efficiency and employee satisfaction. Improvements/Applications: Future research will require a study of quality management methods and tools that can reflect the realities of small and medium-sized manufacturing industries.",60006504,Hansung University,Seoul,South Korea,['1700'],24.0,0.05160427807486632,0.4379679144385027,1,0.09036144578313253,0.0391566265060241,0.40522875816993464
228,231,231,Reliable and energy efficient wban through on-demand handover protocol,"In recent years, innovation in technological development makes human work easy. More specifically the development in the field of medical is unimaginable. Nowadays medical treatments were enhanced and more medical equipments were developed to detect the disease and also to monitor the human health. But the patient needs to be stayed in the hospital until they recover from the ill. Some health issues may take even couple of months to few years. In that case Wireless Body Area Networks provide facility to make the patient stay in the home by using wearable body sensors. These sensors can be fixed inside the human body or outer surface of the body to observe the body conditions. These wearable sensors are small in size and they were designed to carry easily. Since the body sensor node is small, the battery capacity is also very less. So, the effective utilization of the energy is much important for avoiding the replacement of battery very often. At the same time patients can move freely inside their home, during that time there may be chance for obstacles like wall and furniture that act as a barrier for the communication between the sensor node and access point. Therefore the data from the sensor node is being transmitted through other access point to increase the reliability. But the number of times handover the signal from one access point to other access point is also consumes more energy. So the proposed On-Demand Handover Protocol will establish the connection with new access point only if the data is very much essential. Otherwise sensor will omit the data and continue to sense the value without considering the signal strength of the existing connection. This proposed On-Demand Handover Protocol endow with energy efficient and reliable network.",123457022,SPIHER,Chennai,India,['1700'],18.3125,0.08621212121212121,0.3910959595959597,1,0.1167192429022082,0.031545741324921134,0.21725239616613418
229,232,232,Service quality measure and customer satisfaction towards prepaid meter in facilities management at Malaysia,"Prepaid meters have being wide adopted by utilities in numerous countries. The research disclosed that consistent service quality is the most efficient way to maintain customer satisfaction, which reduces the price of attracting different clients and increases revenues and market share. The aim of this paper is to measure the service quality on customer satisfaction of prepaid energy meter system among facility management in Malaysia. To fulfill the needs of end user, developing a model to assess the extent to that service quality indicators and different instructive attributes could also be wont to forecast customer satisfaction.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],24.0,0.10833333333333334,0.475,1,0.1262135922330097,0.009708737864077669,0.20588235294117646
230,233,233,Unstructured data learning using relation pattern knowledge for efficient classification through probabilistic approach,"The web is a huge source of information that makes it complicated for humans to choose significant information without knowledge. However, traditional classification methods face significant challenges due to the complex and unregulated distribution of data from large, heterogeneous sources. In such a case, current classification methods or methods of computational complexity and high time to process such large text data. Therefore, it is necessary to develop effective classification methods that can regulate real-time information requirements for different fields. This paper proposed classification by Relation Pattern Knowledge (RPK) and building an FP-Tree for data functions, and applying it to the Probabilistic Relation Pattern Approach (PRPA) to data correlation and classification. FP-Tree uses feature reduction based on covariance deviation deviations and feature relationship trees to provide robust relationship patterns between feature patterns used to efficiently classifies data. The approach is evaluated in comparison with the existing feature reduction and classification approaches measure to evaluate the accuracy to show the improvisation of the proposed approach in various classification.",60021891,Jawaharlal Nehru Technological University Hyderabad,Hyderabad,India,['1700'],23.714285714285715,0.08315126050420169,0.6395378151260506,1,0.11170212765957446,0.05851063829787234,0.3021978021978022
231,234,234,The use of the interactive whiteboard in mathematics lessons towards the achievement and motivation of year five students in the topic of space,"The purpose of this research was to determine the use of interactive board in students’ achievement and motivation in the topics of space. The research methodology is based on an quasi experiment whereby two different teaching techniques were applied, which were traditional technique for the controlled group and teaching by using interactive board for the treatment group. The data were students’ scores on their performance on the pre-test and post-test while the data on students’ level of motivation was collected using a questionnaire: Motivated Strategies for Learning Questionnaire (MSLQ). 60 students were selected as samples and they were divided into two groups of 30 students in the controlled group and 30 students in the treatment group. The difference of students’ scores was then analyzed using t-test. The results of this study indicated that the mean score of post-test for the treatment group is significantly higher. In conclusion, the treatment group who had undergone the lesson using interactive whiteboard performed better with a positive motivation level towards learning material compared to the controlled group with the traditional method. The implication of this study shows the use of interactive boards showed positive impact on students’ achievement and is suitable for an alternative to existing methods.",60103633,Universiti Pendidikan Sultan Idris,Tanjong Malim,Malaysia,['1700'],25.375,0.16022727272727275,0.625378787878788,1,0.08296943231441048,0.013100436681222707,0.2895927601809955
232,235,235,Impact of social media on reading comprehension among undergraduates,"This study aims to investigate the perceptions of undergraduates regarding the relevance of social media, WeChat application platform towards improving reading comprehension skills of English as a Second Language. At the same time the study wants to find out the influence of the social media platform usage on language learning towards improving students’ critical thinking skills in view of its association with the reading comprehension skill. The results show significant information on students’ use of WeChat for ESL learning intentions. The ease of use and the structural characteristics of these tools engage students in critical thinking; enhance communication, reading and writing skills while sharing information, and modification. As for educators, it is to be noted that students prefer their presence in an online learning community. They need a teacher to guide and provide useful feedback related to learning. It is concluded that although using the social media provides students with an enriched learning experience, students shared that they need a teacher to plan and execute teaching and learning activities effectively. Consequently, teachers can opt for more reference sources to consider when they design curricula.",60090712,Wawasan Open University,Penang,Malaysia,['1700'],23.0,0.14821428571428572,0.32857142857142857,1,0.15920398009950248,0.01990049751243781,0.2736318407960199
233,236,236,Water resources availability and management policy in himachal pradesh:- A survey,"Water is a natural resource and a basic necessity for sustaining life on earth. Himachal Pradesh is a state which is having enormous volume of water from the catchment areas of Satluj, Beas, Ravi and Chenab rives which are a part of Indus system. Most of the surface water resources of H.P. comes from the rivers which originates form the glaciers. However, ground water resources are limited. Water availability in Himachal Pradesh depends directly on its physiographic conditions including relief, drainage, climate and geology. Only one third area of cultivated land is irrigated due to its physiological conditions. Water requirements for both the domestic and industrial purposes are increasing linearly with the increase of population in the state. Himachal Pradesh is one of the few states, which has come out with their state water policy, as early as in 2005. It presents a set of general guidelines towards the planning and management of water resources. The State took the first steps by formulating its own Hydropower Policy in 2006. The HP State government is targeting to tap over 70% of the hydropower potential of the State by 2020, essentially adding 10 GW to the current potential. This study presents the details about the available natural water resources and the water requirements in Himachal Pradesh. It also gives the brief about the initiatives taken by Himachal Government for the planning and management of available water resources.",60109643,Eternal University,Baru sahib,India,['1700'],16.785714285714285,0.09580745341614907,0.4525879917184266,1,0.07782101167315175,0.08560311284046693,0.3449612403100775
234,237,237,Evolution of data analytics techniques: From data mining to big data mining,"Data mining is one of the most significant techniques for researchers, business organizations and decision analyst. It has helped data analyst in improving business model, healthcare, weather forecasting, e-mail spam filtering, social networks and many other domains. It has evolved in recent years at a very high pace. The motive of this paper is to highlight different phases of data mining evolution in frequently changing requirements. Specifically, ten algorithms which are identified as most prevalent by researchers are studied and observed in this paper. K-means, SVM and Naïve Bayes are compared based on several characteristics. Moreover, Big data mining, machine learning and deep learning techniques which are advanced form of data analytics are observed with their specific applications. Graphics Processors (GPU) which is essential for deep learning techniques are analyzed in detail in this paper. Several research works have discussed the advantages and limitations of these data analytics techniques. However, to the best of our knowledge very few works have provided comprehensive analysis of these techniques. Readers can identify limitations and advantages of these techniques which are evolved over the time and select the best technique which is most suitable for their research or applications.",60001166,Thapar Institute of Engineering &amp; Technology,Patiala,India,['1700'],17.727272727272727,0.22005555555555556,0.3572361111111111,1,0.08108108108108109,0.03153153153153153,0.3440366972477064
235,238,238,Role of information technology (IT) @ system management in district central co-operative banks (DCCBs) in Tamil Nadu,"Information Technology (IT) and system is a basic resource in today’s society. Without system or ITs people cannot live in the society. Today most of the people are sending and receiving the messages through electronic way. At present day world is passing through the era of computer or ITs and small enterprises and petty shops also apply system or IT. IT is used in DCCBs and its branches to increasing productivity, profitability, banks process time, quick services to the customers etc. The co-operative movement in India has a long history of more than one century with more than 5.49 lakhs total co-operatives, but throughout India have 372 DCCBs. In that we have 23 total numbers of DCCBs in Tamilnadu we have 749 branches of DCCBs throughout Tamilnadu. DCCBs are located at the district headquarters or some well-known town of the district. This study was mainly focused on new technology services related to DCCBs and its branches such as NEFT, SEFT, RTGS, Debit Card, Credit Card, touch facilities, Telebanking, Mobile Banking, personal computer banking, Automated Teller Machine, Internet Banking and Core Banking etc,. The study was empirical research based on survey method. The main purpose of the study is the measurement of the abstract variable “use of IT @ system management” and the benefits and satisfaction level with of use of IT in DCCBs and its branches through statistical treatment. We have selected DCCBs and its branches in Salem District and simple random technique was applied selecting employees for the study. Total branches of DCCBs in Salem District 72 branches including head office. We have selected 70 branches for performance of DCCBs and its branches. 5 employees from each branch and head office have been collected at random using lots from the list of employees provided by the DCCB. The DCCBs must be provides computer or IT literacy awareness, IT training programme to the employees. The study highlights the benefits and satisfaction level with use of IT and system derived by the DCCBs and its branches of employees. The study will help to improve the performance of their DCCBs and its branches through IT.",60012959,Periyar University,Salem,India,['1700'],19.61111111111111,0.056336088154269964,0.42969795356158985,1,0.07017543859649122,0.07017543859649122,0.3756345177664975
236,239,239,Lowlatency semi-systolic array for computing themodular ab2multiplication based on shifted polynomial basis over finite fields,"Arithmetic operations in finite fields have been adopted in a variety of fields such as cryptographic algorithms and error correction codes.Especially, it is necessary to compute exponentiation over finite fields in cryptosystems and exponentiation is a time-consuming operation.This paper focuses on a modular AB^2 multiplication for being used to perform exponentiation over GF(2^n).Various architectures for computing the modular AB^2 multiplication has been developed. Since the existing modular AB^2 multipliers have high time and area complexities, we need to develop a modular AB^2 multiplier with lower time and area than existing multipliers.In this paper, a modular AB^2 multiplier using the semi-systolic architecture in finite fields based on the shifted polynomial basis. The proposed modular AB^2architecture has the low area and time complexities as compared to other modular AB^2multipliers.",60002877,Dankook University,Seoul,South Korea,['1700'],42.333333333333336,0.022500000000000003,0.5025,1,0.11188811188811189,0.027972027972027972,0.34306569343065696
237,240,240,"Smart controller placement for uninterrupted software defined networking service under DDoS attack in RF, data center and telecom industries","In software defined networks (SDN) controller placement is essential and it’s a critical issue. Existing research works address the primary factors, such as reliability, latency, capacity of controllers, propagation delay of control paths and energy consumption etc. In this paper, we propose an integer linear programming (ILP) scientific model for the controller position in SDN due to DDoS attack. More unerringly, conferred a set of switches that must be overseen by the controller(s), our proposed model can decides the ideal number, node, and kind of unique and smart controller(s) just as the interconnections between all the system components under DDoS attack simultaneously. The objective of the model is to limit the absolute expense without compromising the continuous service of SDN while considering different scenarios of DDoS attack .The simulated results obtained demonstrate that the ILP scientific model can be utilized to design and plan small and medium scale SDN.",60012005,Multimedia University,Malacca Town,Malaysia,['1700'],29.8,0.20102040816326533,0.6084183673469389,1,0.12941176470588237,0.047058823529411764,0.3142857142857143
238,241,241,An hybrid algorithm to currency recognition using digital image processing and feature extraction,"The digital image processing is used to manage and building up an advanced framework to perform digital image with the utilization of algorithms on computer. Digital image processing handling alludes to the control of a picture by methods for processor. An image is nothing but a mathematical function 2D f (x, y) where x and y are two horizontal and vertical coordinates[1]. In this thesis we work on currency recognition system by using Digital Image processing. Currency recognition the standout amongst the most critical applications in image processing. By contemplating the case of a bank, each now acknowledgment of the group is required where utilization of the device which comprise of ultraviolet light. The cash note to the device gives by the banker and endeavor to see if the serial numbers, watermark images and the notes various different qualities of are pertinent to get the money and check denomination validness[2] . This process increases the work of the banker. In its place if the our framework utilizes by the banker and automate his work, significantly more precise outcome will be get, for example, investment firms, shopping centers where this sorts of framework can be utilized. Simpler method for perceive the currency notes is required. The fundamental rule of this approach is to plan a programmed framework which can without much of a stretch perceive the currency and give a precise outcome. The outcome demonstrates that the expected framework gives the precise outcome when it is connected on given info images.",107119881,Government Engineering College,Bikaner,India,['1700'],20.83333333333333,0.1823529411764706,0.4235294117647059,1,0.11397058823529412,0.029411764705882353,0.2572463768115942
239,242,242,"The influence of campus environment, curriculum and extracurricular activity on employability","The issue of graduates’ unemployabilityprevails till today. Despite having completed higher education, some graduates still experience unemployment. Employability is a complex topic, as there are many contributing factors. This study considers the effect of campus environment, curriculum, and extra-curricular activity on graduates’ employability amongst graduates of a private university in Klang Valley, Malaysia.85 respondents participated in this study, via data collected through online questionnaire.Data was inspected using normality test to ascertain the common method variance. In addition, descriptive statistics, frequency and Pearson correlation analysis were conducted to investigate the relationship between predictors and dependent variable. The findings revealed that of the three, the strongest factor affecting employability is Campus Environment. This preliminary study provides stakeholders, including Higher Education Institutions, policy makers, and employers, with a preview of factors that potentially affect graduates’ employability.",60105696,Asia Pacific University of Technology and Innovation,Kuala Lumpur,Malaysia,['1700'],19.0,0.05714285714285715,0.5392857142857143,1,0.1,0.04375,0.4166666666666667
240,243,243,Energy and exergy analysis of wet ethanol-based HCCI engine combined cycle cogeneration system,"Homogeneous Charge Compression Ignition (HCCI) engine uses an advance combustion process with a lean premixed air-fuel mixture, and it works with a high compression ratio like a diesel engine. The charge is compression ignited, and ignition occurs throughout the combustion chamber. The present system is proposed to meet the simultaneous demand of power and thermal energy from a sustainable fuel in an efficient and environmentally friendly manner. The paper describes the computational analysis of first and second law efficiencies of wet ethanol-based HCCI engine with a combined cycle cogeneration system by varying its turbocharger efficiency and pinch point. It further describes the exergy destruction in each component and its variation with turbocharger compressor efficiency, pinch point, turbocharger pressure ratio, ambient temperature and effectiveness of regenerator. The cogeneration cycle has a good thermal performance with first and second law efficiencies of 46.47% and 38.5% respectively for the mean operating conditions of T0=300K, Pr=3, ηT=80% ε=79%. An examination of results indicates that the first and second law efficiencies are increasing function with pinch point of the evaporator of organic Rankine cycle (ORC) as it provides higher exhaust gas temperature at the inlet of HRSG of cogeneration which further results in increasing the quantity of process heat for steam generation. These efficiencies are also increasing with an increase in efficiency of turbocharger compressor because it leads to higher HCCI engine work output due to efficient turbocharger. This study evaluated the thermodynamic losses in terms of exergy destruction, and the same is presented in this paper to answer the reason for deviation on the actual and ideal performance of the system. This paper briefly states the variation in performance of the system due to varying considered parameters. Thus the suitable selection of optimum parameters could yield better performance.",60020458,Jamia Millia Islamia,New Delhi,India,['1700'],26.72727272727273,0.1720192307692308,0.3956089743589744,1,0.07975460122699386,0.03987730061349693,0.27414330218068533
241,244,244,The application of the shifting burden of proof principles as an alternative consumer protection effort due to unfair property advertising,"In the business world, advertising becomes an important factor in marketing a product. Advertising is identified as a promotional media and introduction to products to be produced or sold to the public. The people must be careful in buying and selling transactions for housing or property. The problem in this study is how is the legal politics of the shifting burden of proof principle in an effort to provide fair consumer protection due to fair property advertising? Research Methods, normative research is research by directing research into positive law and written norms, thus the analysis in this study refers to the applicable laws and regulations namely the Consumer Protection Act No.8 of 1999. The typology includes descriptive research, this study uses literature study, the type of data used is secondary data obtained from literature, primary data through interviews. Conclusion of consumer protection against misleading property advertisements can be preventive by establishing a legal rule that will ensure that consumers can receive legal protection by conducting shifting burden of proof.",60069439,Universitas Sebelas Maret,Surakarta,Indonesia,['1700'],28.16666666666667,0.20852272727272728,0.5155934343434343,1,0.14285714285714285,0.02197802197802198,0.21978021978021978
242,245,245,An optimal topology selection for power recharging model in wireless sensor networks),"WSNs repeatedly face errors because of energy discharge, software, or hardware errors in the network, environmental occurrences, and various attacks. It is essential to make sure that WSNs application system is present throughout the event of fault or interruption happens. Recent work in topology control has shown that a reasonable topology can improve the robustness of WSN. However, there is a need for a reliable and suitable type of topology to be appropriate for SenCar technique. This paper explores an optimal network topology for WSNs when a concept of SenCar merges with load balancing. Therefore, investigating a robust system with varying data rate assess the impact of the type of topology on distinct parameters. Further, the proposed work analyzes its performance for randomly distributed nodes, which can be taken to calculate the results at fluctuating data rate.",60113584,"Khalsa College, Amritsar",Amritsar,India,['1700'],19.571428571428573,0.1409090909090909,0.4626262626262626,1,0.1118421052631579,0.019736842105263157,0.28289473684210525
243,246,246,EFL learners communicative competence in undergraduate programmes in pakistan: A case of two universities in Pakistan,"Nowadays the English language is considered a language of education, business and research. Since English is medium of learning at tertiary level and learners’ competence in English language decides their academic success. The aim of this study was to explore the undergraduate programmes students and teachers’ beliefs about communicative competence and its need for language learning at tertiary level. This study used a descriptive survey method to collect the data from teachers and students of the National College of Business Administration and Economics University and University of Central Punjab Lahore. 300 students and 25 teachers from the English Language faculties were selected using random convenient sampling method. The results of the study have shown that teachers and students have clarity about the concept of communicative competence and believe it is important for job and academic success. Teachers’ low proficiency, lack of interest in speaking in English, outdated syllabus, traditional teaching methods and not training the students “How to learn” are the main difficulties in developing communicative abilities of the students. Students believe they need to be self-reliant, responsible and use new strategies for their learning. On the other hand teachers believe training, authentic material, oral practice of English and new methods are indispensible for the development of communicative competence of the students. The findings of the study are significant for the English language teachers, trainers and policy makers in order to focus the communicative needs of the students at tertiary level in Pakistan.",60103633,Universiti Pendidikan Sultan Idris,Tanjong Malim,Malaysia,['1700'],24.3,0.06205808080808081,0.3010732323232323,1,0.08208955223880597,0.05970149253731343,0.2857142857142857
244,247,247,Feature extraction and elimination using machine learning algorithm for breast cancer biological datasets,"Cancer is a non-curable disease if diagnosed at last stage. It is not easy to diagnose cancer at an early stage. Cancer stage is divided into four stages. First two stages are known as early stage and last two stages as last stage. In order to diagnose at an early stage, Machine Learning is applied. Machine Learning is a field of computer science and Machine Learning algorithm is effective in the operation on biological data. Machine Learning is the technology that can be used to predict the accuracy of cancerous tumor of a human body. Too many features might pose some issues of overfitting the model. In that case, less important features have to be eliminated. Elimination of less important features and including important features create less computational complexity. In this paper, it is marked that with the smaller number of effective features, cancer prediction can be more accurate.",60113890,DIT University,Dehradun,India,['1700'],13.545454545454545,0.1696969696969697,0.45,1,0.10240963855421686,0.04819277108433735,0.2804878048780488
245,248,248,Tracying for power representation through the use of directive acts speech between the teacher and the student: A communication and pragmatic study,"This article presents the results of research on the representation of power in the speech directive of teachers and students in high school. The study uses the communication and pragmatic ethnographyapproach. The results of this study indicate that the use of directive acts by teachers and students represents power. Teachers and students in classroom discourse use four types of directives, namely command, request, prohibition, politeness, and suggestions. The use of the directive type of command and the prohibition has a high restriction content that tends to represent dominative power. In contrast, the use of demand, politeness, and suggestion, has a low restriction level that represents humanist power. The degree of dominance of teacher and student directive action is related to the use of modality types including the directness of the directive, the greeting used, and the type of speech acting diathesis. The power representation is influenced by the socio-cultural dimension that builds class discourse, especially the difference in institutional role between teacher and student, the purpose of speech to be achieved from the learning process, and the topic of speech controlling the learning activity.",122684557,Universitas Lambung Mangkurat,Banjarbaru,Indonesia,['1700'],23.0,0.06000000000000001,0.4114285714285714,1,0.07692307692307693,0.004807692307692308,0.24757281553398058
246,249,249,Impact of virtual learning enviroments on students mathematical performance,"The study aims to measure the impact of virtual learning environment on mathematical performance in higher education institutions in Kurdistan Region of Iraq from the faculty members and students viewpoints, and to indicate if there are significant differences between the studies variables. Descriptive analytical approach is adopted; a questionnaire for collecting datais designed, distributed among three dimensions i.e. teaching, learning and evaluation. The questionnaire met the requirements of validity, reliability and consistency.The study showed that the degree of the impact of virtual learning environment VLE on student’s mathematical performance in the overall the three dimensions is above than the theoretical mean.The study went out with a set of recommendations to those in charge of mathematics education in universities, to initiate training the faculty members of mathematics in education technology through organizing workshops, scientific symposia, and through exploits advantages provided by e-learning in connecting the theories in mathematics with its practical applications.",60121882,Lebanese French University,Erbil,Iraq,['1700'],37.75,0.08928571428571429,0.22500000000000006,1,0.09467455621301775,0.01775147928994083,0.26666666666666666
247,250,250,A study on performance indicator of university students’ career information management system using block chain technology,"Testing of software is a time-consuming activity which requires a great deal of planning and resources. Blockchain based testing is gaining importance as a research issue. In scenario-based testing, test scenarios are used for generating test cases and to prove performance indicators to describe analysis and design specifications of software development. In this paper, we generate test scenarios from activity diagrams, which achieve test adequacy criteria perfectly. Finally we generate test cases by analyzing the respective sequence and class diagrams of each scenario, which achieves maximum path coverage criteria.We suggest the feature of the block chain technology that is impossible to correct or deleted the recorded facts to gain greater efficiency in University Student’s Career Management System. University Students’ Career Information Management System has dual aims to increase competency and stimulate adoption of long-term career counselling, career design, and career management for students to enter the target company after entering the university. Whilst it has generally achieved its first aim, its issues are hindering the accomplishment of the second. Several solutions have been proposed to improve Students’ Career Information Management System, yet none of them have considered the revolutionary advancement to prevent fraud and falsification issues. In this paper, We propose deployment of Students’ Career Information Management System using block chain technology to provide trustworthy data and information. Key to the success of this research is a scalable and distributed block chain technology, which has been applied as a distributed transaction book and smart contract[1].",60006504,Hansung University,Seoul,South Korea,['1700'],24.5,0.12063492063492065,0.485515873015873,1,0.1223021582733813,0.06474820143884892,0.34065934065934067
248,251,251,"The effect of sales-marketing collaboration, market-oriented product development, and nimble network structure on organizational agility","The study aims to comprehensively understand how organizational agility in telecommunication equipment companies affects organizations’ business performance. Furthermore, it also elaborates how organizational agility is shaped by the interdependence of the main antecedents―sales-marketing interdepartmental collaboration, complete market-oriented integrated product development (IPD) strategy, and nimble network structure. Exploratory case study and literature review are used to examine the interrelationship of organizational agility antecedents and to develop the conceptual framework. The study identifies that in highly dynamic, rapidly changing, and complex digitized business environments of Telecommunication 4.0 era, to achieve competitive advantage, organizations are required to become agile, which is becoming responsive and flexible in delivering continuous innovation and customer-focused solution through rapid experimentation and decisiveness. To fully gain organizational agility, the collaborative role of sales and marketing in guiding and supporting research and development (R&D) is crucial for product development success. Further, the whole organization needs to embrace an agile mindset and working under a nimble network structure and project management arrangement. Derived from resource dependence theory, the originality of this study lies on the elucidation of collaboration and integration among functional specialists working under nimble project-based network structure that bring positive impact on the accomplishment of product development collective task and responsiveness in satisfying customer’s requirement. This study is expected to enrich prior studies on organizational agility from a different perspective.",60103610,Bina Nusantara University,Jakarta,Indonesia,['1700'],27.625,0.164349376114082,0.4909090909090909,1,0.12992125984251968,0.003937007874015748,0.24096385542168675
249,253,253,Strategies to improve financial technology product innovation,"This research is the result of a research strategy to improve marketing performance through innovation, which is conducted at fin tech service providers in Indonesia. The purpose of this study is to look at the effects of information technology, technology capability, intellectual capital, marketing capability, social environment, and innovation, as an integrated strategy model in improving marketing performance in fin tech service providers in Indonesia. This research was conducted by distributing questionnaires to 72 fin tech companies in various regions in Indonesia, who are members of the Indonesian fin tech association using simple random sampling technique. To analyze the relationship in this study used Partial Least Square path analysis technique. The findings prove that there is a significant influence of information technology capability, marketing capability, intellectual capital and social environment on innovation.",60103797,Universitas Pendidikan Indonesia,Bandung,Indonesia,['1700'],26.4,0.014166666666666666,0.38654761904761903,1,0.06802721088435375,0.07482993197278912,0.25170068027210885
250,254,254,Is B2B marketing enable in value-in-use? The co-creation perspective,"The current era change of traditional industries, if it is impossible to change the marketing model or industrial upgrading, traditional industries will tend to sunset industry, but most of them do not mention how comprehensive integration methods and systematic data analysis. How to use the issues of co-creation economy and cultural marketing is the development trend of the traditional cake industry. The cooperative modes that can participate together can not be eliminated by the times and continue to be sustainable. They use the analytic network process (ANP) as a decision-making tool to find out the relative importance weights among various goals, sub-goals and criteria. Super Decision software analyzes the data collected to find out the direction of change, so based on the results of this study, we explored the practical advice between the co-creation and cake industry.",60025502,Chaoyang University of Technology,Taichung,Taiwan,['1700'],27.4,0.026666666666666672,0.5416666666666667,1,0.12025316455696203,0.0189873417721519,0.24
251,255,255,Consensus pattern selection from structured profile using multiobjective algorithm,"Consensus are also referred as motif. Motif detection is a demanding task in bioinformatics and the broad variance of protein motifs make it challenging. Imprinting gapped motifs is very important but tedious because of feasible combinatorial representations caused by considering long gaps.Detection of planted (l, d) motif is an NP complete problem. We propose a new method to identify motif by Markov clustering of the Augmented Emerging Substrings (MAES). In this, we generate augmented bucket with pareto optimization by considering the multiplicity and weight of each node and detail the emerging substrings.Experimental outcome on simulated data exhibits that i) MAES is able to identify(l,d) motifs effectively and is absolutely faster than contemporary state of art (l,d) motif uncovering algorithm like F-motif and MEME-ChIP ii) MAES is able to identify subtle patterns that are concealed by stronger pattern in data.",60114052,REVA University,Bengaluru,India,['1700'],27.8,0.18478438228438224,0.629516317016317,1,0.10179640718562874,0.0658682634730539,0.33540372670807456
252,256,256,Impact of packaging materials and different chemicals on storage and shelf life of pear cv. Punjab beauty,"The present investigations entitled Impact of packaging materials and different chemicals on storage and shelf life of pear cv. Punjab Beauty were carried out in the laboratory of Department of Horticulture Khalsa College, Amritsar during the year 2017-18. The fruits were harvested from healthy trees of a well maintained Govt. Orchard and Nursery, Attari Distt, Amritsar. The study comprised of seven treatments as CaCl 2 (2.5, 3.5 and 7.5%), GA 3 (25, 40 and 50ppm) and control. 2 Kg of fruits were selected for laboratory analysis for each treatment and these fruits were dipped for a period of five minutes in different concentrations of CaCl 2and GA 3, however, fruits were dipped in plain water under control. Then the fruits were packed in Corrugated fibre boxes and wooden boxes and kept under cold storage. The fruits from each treatment were analysed for physico-chemical characteristics after 0, 20, 40 and 60 days of cold storage period. The results revealed that CaCl2-7.5 per cent (T3) was found to be significant in prolonging the shelf life of soft pear fruits than all other treatments. The fruits under treatment T3 maintained the marketable acceptability upto 40 days of storage under CFB by retaining the fruit firmness, reducing PLW and spoilage losses than control.",60113584,"Khalsa College, Amritsar",Amritsar,India,['1700'],20.9,-0.051298701298701295,0.5142857142857142,1,0.07407407407407407,0.0823045267489712,0.43037974683544306
253,257,257,Potential recycling of brewed tea leaf (Camellia sinensis) waste as natural reinforcement in unsaturated polyester (upe) bio-composite,"This study presents the preparation of a bio composite made from unsaturated polyester (UPE) matrix filled with brewed tea waste (TW) as natural fibre by applying compression moulding principle. Composite of different filler loading ranging from 0 wt.%, 10 wt.%, 20 wt.%, 30 wt.% and 40 wt.% were prepared. The microstructural characteristics and functional group as well as mechanical properties namely tensile and flexural test were investigated. Results show that the mechanical properties of biocomposites decreased as the weight percentage of tea waste content increased. The optimum tea waste content for the bio-composites was found to be 10 wt.% that shows the highest value of tensile and flexural strength which are 15.757 MPa and 24.417 MPa respectively. Surface morphology was evaluated by using scanning electron microscope (SEM) and functional group identification was investigated by using Fourier Transformation Infra-red (FTIR) analysis.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],23.33333333333333,0.022222222222222216,0.4,1,0.11801242236024845,0.07453416149068323,0.4233128834355828
254,258,258,Monitoring your fleets on the go with RTDFMS [real time distributed fleet monitoring system],"Fleets are an indispensable part of human life starting from an early phase. There was always the need for a good carrier whether it was Stone Age or the age of modernized advanced technology of today. Sheep’s and mules are still the means of transportation in the remote hilly areas where there is no facilitation of good transportation by roads. However, in recent the means of transportation and communication has been evolved so abruptly that almost none of the area is left where we do not have vehicles.Vehicles have touched every part of life. Whether it is the school bus which drops or carries your children or your daily schedule of life-going to Office, visiting relatives or buying goods for daily usages, no part of life is left untouched of it. All because of this, the number of means of transportation are increasing day by day. More than 1.2 billion vehicles are running currently on the road at a time and so as the minimum number of peoples riding the vehicle. So in this contrast, for a public fleet servicing organization or any corporate organization, it has become mandatory to keep concern for the safety of peoples and their lives. For private organizations and companies, tracking of fleets have become mandatory in order to make the productivity of workers smoother and trustworthy..",60114276,"Government College of Engineering, Karad",Karad,India,['1700'],24.66666666666667,0.1355263157894737,0.3153508771929825,1,0.07407407407407407,0.01646090534979424,0.23333333333333334
255,259,259,"Feminist rebellions: Lessing, Munro and Lahiri in the quest of self identity","Women, who in the most of the culture worshiped some or other way as goddesses, anyhow cannot be regarded as equal in the society. Although her place which varies from one culture to other and from this age to that age and also from literature to literature. The present perspective of relating the thought to portrayal and depiction of „objective reality‟ in narration, the present study has subsequently explored a sense of „ethics‟ among numerous voices and situations like feminism, self-identity, regionalism and subjectivity in the stories of these writers. Study has explored the feminist-relational psychoanalysis of identity that how self –identity is socialized by stating that relationship and community is a part of self identity. The focus of these award winning authors was the identity in relation to community that the characters in so many of their stories struggle to achieve.",113130720,Swami Keshwanand Institute of Technology,Jaipur,India,['1700'],28.4,0.125,0.33,1,0.075,0.0,0.24516129032258063
256,260,260,Study on characteristics and energy content’s optimization of torrefied oil palm empty fruit bunch biochar,"Malaysia has enormous biomass resources especially in agricultural field and the most outstanding coming from oil palm plantation. By taking oil palm empty fruit bunch (OPEFB) into consideration, this research was conducted to characterize the torrefied OPEFB biochar from torrefaction process as a potential renewable energy sources based on the influence of parameters particle size, holding temperature and residence time on energy content. By using response surface method (RSM), box-Benhken model has been applied for generating shortest experiment run, and analysis of variance (ANOVA) has been utilized for the optimization. The surface morphology as well as bonding behavior of the torrefied OPEFB biochar have been investigated using scanning electron microscope (SEM) and Fourier transformation infrared spectroscopy (FTIR) respectively. The thermal behavior of torrefied OPEFB biochar has been identified using thermogravimetric analysis (TGA-DSC), meanwhile characterization of ultimate elements has been running by CHNS analyser and crystallinity index (CI) has been conducted using X-ray diffractometer (XRD). From ANOVA, in case to obtain the highest of energy content, the suggested optimized parameters for torrefaction was at 300°C of holding temperature and 90 minutes of residence time, meanwhile particle size did not perform as significant factor for the optimization torrefaction. As the higher holding temperature and longer residence time was applied, the darker color of OPEFB was obtained resulting from carbon content increment. Moreover, both surface morphology and bonding behavior of the torrefied OPEFB biochar was influenced by the degradation of the lignocellulose, hemicellulose, cellulose and lignin. Biochar start to rupture as the longer torrefaction time was applied due to longer period of thermochemical reaction. FTIR spectrum proved that the weak bonds had diminished at this condition. For thermal behavior, the degradation started from the removal of moisture content, proceeded by removal of hemicellulose, cellulose and lignin was decompositions of biochar to completely degrade. From CHNS results, the carbon in raw and torrefied OPEFB biochar was increased while the amount of oxygen is decreasing as holding temperature and residence time increased. This is due to occurrence of decomposition of hemicellulose in this region. For XRD, the decrement of CI is observed as the holding temperature and residence time increased from 200-300°C and 30-90 minutes respectively. This is because the cellulose become completely amorphous as the high temperature and longer time of torrefaction applied.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],25.266666666666666,0.057179487179487176,0.5848076923076923,1,0.11337868480725624,0.06802721088435375,0.3161592505854801
257,261,261,Non functional requirements analysis using data analytics,"Requirements play a significant part in Software Development Life Cycle. The Functional and Non Functional Requirements are both similarly significant in development of software. Mostly Requirements are written in Natural Language. The extraction of Requirements from the Software Requirement report is a difficult assignment. The different Machine Learning techniques like Supervised, Semi-Supervised and Unsupervised are used for extracting the NFRs. The presentation of the distinctive methodology is estimated as far as Precision, Recall and F-measure. Furthermore, the researcher have explored the diverse datasets like User Reviews, Health related data, Open Source Software Data and Promise Repository. The different Natural Language Processing and Machine Learning techniques have explored by researchers for efficient NFRs extraction.",60094571,Lovely Professional University,Phagwara,India,['1700'],14.125,0.09545454545454546,0.65,1,0.07692307692307693,0.2230769230769231,0.5
258,263,263,In-vitro cytotoxic and anti-angiogenesis studies of polyvinyl alcohol mediated 5fluorouracil conjugated iron oxide nanoparticles,"The objective of the researchis toevaluate the in-vitro cytotoxic and anti angiogenesisactivity of 5-fluorouracil conjugatedironoxidenanoparticlesmediatedwithPolyvinylalcohol. Ironoxide Nano particleswerechemicallysynthesised and conjugatedwith 5 –Fluorouracildrug. This mixture wasthenadded to Polyvinylalcohol. This PVA isact as a drug carrier vehicle. Characterization of this compound werecharacterizedusing UV, FTIR, Thermo-Gravimetric/Differential Thermal Analysis (TG/DTA), Raman Spectroscopy, Field Emission Scanning Electron Microscope (FESEM) and X-ray powder diffraction (XRD). 5-Fluorouracil drug is Nano conjugated with these synthesized PVA coated iron oxide nanoparticles.When a drug is bound to iron –oxide nanoparticles, their tolerance can be overcome due to a reduction of the efflux pumps that transport the drug to the outside of the cell and promotes an increase in drug concentration in cancerous tissues.The result shows the effectiveness of the sample in increasing the angiogenesisactivity (i.e) formation of new bloodvesselscompared to the standard pyruvicacid. The resultsclearly show the effectiveness of the drug in treatingcancerouscells by deprivingcells of nutrients and oxygenbecause cancer cellsrequireaccess to bloodvessels for growth and metastasis.This non-toxicity effect of this drug also makes it more effective for the treatment of various types of cancer and reduces the mortality and morbidity from carcinoma. The increased anticancer activity was found even at lower concentration of the drug. Thus, synthesized nanoparticles were more efficient in the biomedical applications in cancer treatment for their high anticancer activity.",60114919,"Vivekananda College, Agastheeswaram",Kanyakumari,India,['1700'],23.777777777777782,0.17713636363636362,0.38195454545454544,1,0.07782101167315175,0.10505836575875487,0.38396624472573837
259,264,264,Classification accuracy improvement using wavelet-pca image fusion technique and change detection in land cover/land use,"In general, to detect land use land cover (LULC) changes, LULC features are extracted independently using multi-temporal remote sensing data, then analyzed and compared to detect their changes. This study introduces a new classification method that integrates PCA-Wavelet fusion technique and Maximum likelihood classifier (MLC). PCA-wavelet fusion technique was used to extract the quality information about the targets whereas MLC was applied for the purpose of image classification. The quality of fused image was evaluated by the existing fusion methods. MLC classification was applied to extract four classes; settlement land, vegetation, water and soil, for the proposed and existing fusion techniques. Experimental results show that the wavelet-PCA fusion technique improves classification accuracy better than the other existing fusion methods. The overall accuracy and kappa coefficient for the proposed is 0.91 and 0.86. The performance of proposed method was evaluated using Landsat 8 data set. Furthermore, change in each class, in the interval 1978-2018, was evaluated with post classification comparison method. Changes were observed in all classes; the results demonstrate that during the forty years period, area under settlements and soil/bare land increased and the area under water bodies and vegetation decreased. In the future, these changes may have a significant influence on the ecosystem.",60008424,Sri Venkateswara University,Tirupati,India,['1700'],18.545454545454547,0.0487603305785124,0.38677685950413226,1,0.12704918032786885,0.04918032786885246,0.3577586206896552
260,265,265,Classification of thalassemia data using K-nearest neighbor and Naïve Bayes,"Thalassemia is an abnormal blood disorder. Research on thalassemia has been done a lot, such as testing on beta-thalassemia data using a decision tree, K-Nearest Neighbor, and Multi-Layer Perceptron classifier. In this study, we will discuss the comparative performance of classification of thalassemia data using K-Nearest Neighbor and Naïve Bayes which are very popular in the field of classification. The author uses thalassemia data from Harapan Kita Hospital, West Jakarta. While the training data used ranges from 10 to 90, the results of the Naïve Bayes classification are higher than the classification results using K-Nearest Neighbor with an average of 99.78% with an average running time of 0.06 seconds, while the KNN is 97.14% with the average running time 0.081 seconds.",60069377,Universitas Indonesia,Depok,Indonesia,['1700'],24.2,0.09666666666666666,0.5333333333333333,1,0.05517241379310345,0.15862068965517243,0.4148148148148148
261,266,266,Long-term social issue analysis using news articles for more than 10 years’social issuein South Korea,"Background/Objectives:The existing social issueresearch focuses on each problem, so wewill look at thefeatures of longterm social issue based on the social issue itself. Methods/Statisticalanalysis:In order to examine the features of social issue, select threesocial issues. Examples youth unemployment, poverty of the elderly people, Low birth rate that lasted for0more than 10 years. First, crawl the news articles of Naver portal only 100 titles per month. After the crawl, analyze it using sentimental analysis. Findings:With the exception of some periods, the negative rates higher than positive rates. Specifically, all three keywords showed a positive sign of less than 65 percent of the total period on a negative basis. Improvements/Applications:Unlike traditional long-term social issue research, there is a difference in identifying and defining the features of new social issue as graphs.",60080750,Namseoul University,Cheonan,South Korea,['1700'],16.125,0.014433811802232853,0.3918660287081339,1,0.08024691358024691,0.04938271604938271,0.4025974025974026
262,267,267,Methodology for probabilistic assessment of attack vectorfor cyber threat scenario,"Background/Objectives: This paper propose to establish a comprehensive attack vector evaluation scale for cyber threat scenarios and to suggest a method for calculating probability values for deriving standardized results. Methods/Statistical analysis: In general, the qualitative method of threat assessment is expressed by technical variables rather than numerical values due to the qualitative nature of the elements analyzed in the evaluation. Quantitative methods can compare the effect of threat levels and countermeasures through objective figures, which helps in decision making when establishing security measures. It is difficult to have statistical data on past cybersecurity-related cases because of the work required. Findings: In this paper, we study a method to derive the quantitative level of qualitative attributes by matching the evaluation elements in the physical environment with those in the cybersecurity environment. Through detailed analysis of the attack route included in the attack base of the threat scenario, the evaluation scale of the essential elements constituting the established attack vector was established. Applying the proposed evaluation scale, we derive a method of calculating probability values for standardized results. Improvements/Applications: The method complements the limitations of the existing quantitative methods by calculating the attack vector level as a probability value for the probability of threat success, and can compare the standardized threat levels through the proposed method. The proposed threat assessment model is expected to be useful for determining security action priorities.",60117634,Jeju National University,Jeju,South Korea,['1700'],25.444444444444446,-0.04464285714285715,0.3584183673469388,1,0.125,0.015625,0.2701612903225806
263,268,268,"Assessment of urban heat Islands in Rawang small cities, Malaysia","Early studies of UHIs focused almost exclusively on large cities or metropolitan regions, owing to the greater importance placed on air circulation and pollution. However, a number of studies for small-and medium-sized cities have described problems in the air and temperature of these cities that are unique; however, their effects are becoming a common concern in smaller cities as well. This study was conducted in to examine the relevance of the level of urbanization in the city of Rawang and investigate the factors that contribute to the cause heat islands in Rawang either in city center area and the rural. As a result of the impact of urbanization, the temperature pattern in the city center area and rural should be evaluated. Data gathering involved mobile surveys across Rawang City centre to rural area, during arternoon 1400 to 1800 and 2000 to 2200 night times (9 and 10 April 2018). Urban Heat Island Pattern shown the temperature distribution is high in central area of Rawang which categorized as urban. Variability in Maximum temperature on working days during noon were recorded at 34.8°C while at night is 32°C while the minimum temperature is 30.2°C at noon and 27.9°C. Industrial areas mostly influenced the highest temperature and the lowest temperature recorded in Station 12 that is Sungai Kanching Tropical Forest. The results showed that in the center city area seen temperatures higher than the rural area and rural area.",60103633,Universiti Pendidikan Sultan Idris,Tanjong Malim,Malaysia,['1700'],26.222222222222218,0.09282312925170066,0.29374149659863946,1,0.07547169811320754,0.09811320754716982,0.31225296442687744
264,269,269,Spatial regression analysis in determining the influencing factors on poverty in West Java,"Poverty is still a very important issue in Indonesia, hence needs government's concern to overcome it. Handling this problem can be considered as modelling the poverty based on the factors that cause it. According to the law of geography proposed by Tobler, to overcome poverty in a region, the government must also consider the situation of its neighbours. Tob-ler's law is used as a pillar of study in spatial data analysis. If an observation in a location has spatial elements, then the data analysis using a simple regression model, will not as accurate as that which pays attention to spatial element. Therefore, we use a regression analysis that takes into account the existence of spatial influences, called spatial regression analysis. The models formed in spatial regression analysis are spatial lag model or spatial autoregressive model (SAR), spatial error model (SEM), and general spatial model. In this research we use spatial autoregressive model (SAR).",60069388,Universitas Padjadjaran,Bandung,Indonesia,['1700'],19.125,0.24250000000000005,0.6226190476190476,1,0.12222222222222222,0.03888888888888889,0.28651685393258425
265,270,270,Determinants of millennial online consumer behavior and prospective purchase decisions,"As per an ongoing study led by Sheer-ID (An American eligibility verification services company), web-based shopping is up 13% year over year among millennial. Owing to this tremendous growth, the given study focuses on identifying and analyzing different attributes affecting the millennial perception towards internet shopping. The data for this study was gathered using direct overview with the help of an organized poll.The survey was done on the millennial of Uttrakhand. All factors were distinguished utilizing the writing on web-based shopping. The data were analyzed using SPSS. Factor analysis identified the factors.. The consequences of this investigation offer a valuable reference to the e-advertisers to comprehend the variables affecting buyer conduct and with the help of these components they can additionally hone their showcasing systems to draw in and hold clients.",60103785,Graphic Era Deemed to be University,Dehradun,India,['1700'],18.714285714285715,0.10833333333333334,0.5,1,0.16339869281045752,0.026143790849673203,0.3076923076923077
266,271,271,Songket as a Malay heritage craft: Exploring the weavers’ information behaviour,"Until present, little attention has been given in the study of heritage crafters’ information behavior. In Malaysia, none of the user studies have been conducted in the last decade focusing solely on songket weavers. This paper provides the results of a study involving in-depth interviews with nine weavers. This study is an attempt to explain how the weavers search for information, the access tools they use, and the barriers they face. The findings informed the information seeking, selecting, organizing and maintaining in the process of weaving the songket. The findings of this study can be used to develop a proper songket design data repository systems that will facilitate access for this significant group of crafters or weavers.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1700'],19.5,0.0375,0.3083333333333333,1,0.13636363636363635,0.007575757575757576,0.3384615384615385
267,272,272,Microbial profile of bacteriuria in pregnant women and their antibiogram,"Bacteriuria refers to the presence of bacterial contaminants in urine when bacterial load is above 105 CFU/ml. In the present study routine microbial investigation was carried out on 450 urine samples of pregnant women collected from Patna Medical College, Bihar, India. 350 cases of asymptomatic and 100 of symptomatic bacteriuria infections were identified though routine microbial investigation. The bacteriuria was found to be also influenced by the socio-economic status of the population with prevalence among population living under compromised sanitation. Isolated bacterial cultures were identified using different biochemical test in accordance to the Bergey's manual for microbial identification. E. coli (56.6%), Klebsiella pneumoniae (15.09%), Staphylococcus (Coagulase '-') (9.43%), Proteus mirabilis (7.54%), Staphylococcus aureus (5.66%), Pseudomonas aeruginosa (3.77%) and others were isolated. Antibiotic sensitivity tests were carried out for all bacterial isolates using standard disc diffusion (Kibry Bauer) method. The sensitivity of different antibiotics varied against the test microorganisms with 81.35% of amikacin (10 mcg) against E. coli; 12% nitrofurantoin (10 mcg) against Klebsiella pneumoniae. Meropenem (10 mcg) displayed effective antibacterial activity against Staphylococcus (coagulase '-'), S. aureus, Pseudomonas spp. and Proteus spp. with sensitivity of 72.72%, 57.14%, 66.66% and 25% respectively. In contact to the individual antibiotic activity, synergistic effect of antibiotics especially cefoperazone and sulbactum (10 mcg each) was found to be highest. Study indicates that antibiotics displaying synergistic action must be employed for the early treatment and recovery from UTI infection minimizing the chances of abortions.",60114077,"GLA University, Mathura",Mathura,India,['1700'],14.875,0.08717948717948719,0.3461538461538461,1,0.07395498392282958,0.09646302250803858,0.4885245901639344
268,273,273,Investigating factors influencing consumer adoption of nanofood towards purchase intention,"P3 Sweetener Liquid Drop is one instance of a nanofood product, which can enhance nutritional value, food quality, and taste of product. The main objective of this research is to define the influencing factors affecting consumer adoption of nanofood towards purchase intention, thus determining the most influencing factor affecting on this research. The main sample from 365 of respondents were obtained from the survey carried out in Johor, Malaysia based upon stratified random sampling plan. The model tested in this research elicits 4 influencing factors affecting on consumer adoption, namely: knowledge, trust, perceived benefit and psychological factor. Multi-Regression Analysis (MRA) has shown that trust, perceived benefit and psychological factor have positive significance effects on consumer adoption of nanofood towards purchase intention, while knowledge has insignificant effect on this research. The findings of this analysis can help to enhance consumer understanding towards purchase intention and help to address the gap for future studies.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],25.33333333333333,0.06228956228956229,0.293013468013468,1,0.10982658959537572,0.057803468208092484,0.2807017543859649
269,274,274,A privacy protection technique for users using probabilistic attributes of multilevel hierarchy in cloud environment,"Background/Objectives: Over the past few years, cloud services have made many changes in the evolution of mobile phones. Recently, cloud services are providing various services according to the needs of users. However, as the cloud service model becomes more diverse, various risks related to privacy protection occur in cloud users, enterprise customers, cloud service providers, and data stored in the cloud, but specific countermeasures to prevent them are not yet clear. In particular, attacks that exploit the privacy of cloud users have not yet achieved significant results other than data governance and standardization activities. Methods/Statistical analysis: As a result of the performance evaluation, the efficiency of the proposed method improved by 21.4% on the number of attributes and the authentication delay time of the server decreased by 14.2% on average. The overhead change of the authentication server according to the change of the number of attributes of the users is 11.5% lower than that of the conventional method. Findings: In this paper, we propose the user's privacy protection technique using layered learning-based multistage attribute information stochistically to prevent third parties from maliciously stealing the user's privacy. The proposed method improves the convenience of cloud service by extending the proxy signature used for user authentication in the existing cloud computing environment. Improvements/Applications: In order to efficiently protect the privacy of the user, the proposed method registers the information to minimize the third party identification process of abusing the privacy of the user in different types of mobile devices and processes the information necessary for the authentication procedure in the server. In the proposed method, the attributes of n-bit mobile devices are hierarchically distributed according to a certain rule for each type, so that k attribute values are selected in a part of the attribute information of the user. Since the proposed method distributes the user 's privacy according to the user attribute value of the multi-level hierarchy, it has cost efficiency as well as server efficiency.",60095591,TongMyong University,Busan,South Korea,['1700'],29.54545454545455,0.028004535147392286,0.415249433106576,1,0.10215053763440861,0.010752688172043012,0.2722222222222222
270,275,275,Preliminary assessment of utilizing treated arabica coffee waste as adsorbent material for heavy metals removal from aqueous solution,"In this study, treated coffee waste was used to remove heavy metals (Cd, Cr and Pb) from synthetic water. For the adsorption studies, operational parameters such as adsorbent dosage and contact time were studied. For the characterization, Fourier-transform infrared spectroscopy (FT-IR) and Scanning electron microscope (SEM) were used to identify functional group and observed the surface of treated coffee waste. Removal of heavy metals were studied using 100 ml of synthetic water contained 7.5 ppm (Pb), 4.8 ppm (Cr) and 0.9 ppm (Cd) at room temperature. All adsorption processes were carried out for different dosage and contact time to identify the optimum condition for adsorption. Concentrations of synthetic water were measured using atomic adsorption spectroscopy (AAS). The results were analysed using removal percentage of heavy metals and adsorption capacity. The highest removal percentage for 0.5g of adsorbent content were 74.4 % (Pb), 50% (Cr) and 44% (Cd) respectively. For 0.7 g, the removal percentage was Pb (84%) followed by Cd (35%) and Cr (30%). For 1 g and 3 g, the removal percentage were Pb (85%), Cd (40%), Cr (-33%) and 75.5 % (Pb), 50.5 % (Cd) and 20% (Cr) Every dosage was observed with different contact time of 30 minutes, 1 hour and 2 hours. The best contact time for 0.5 g, 0.7 g, 1 g, and 3 of dosage was 1 hour to reach equilibrium state. In conclusion, this study indicates that treated coffee waste could be employed as a potential adsorbent for heavy metals removal from synthetic water and could perform better than untreated coffee waste.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],21.58333333333333,0.037499999999999985,0.40625,1,0.07964601769911504,0.07079646017699115,0.4820359281437126
271,276,276,"Plants compatible with islamic values in the Malay landscape at city of Kota Bharu, Kelantan, Malaysia","This study was accomplished to delve the compatibility of Malay landscape with the Islamic values for landscape in city of Kota Bharu, Kelantan, Malaysia. Islamic religion has expended to Tanah Melayu since long ago had conquered Malay society’s culture and surrounding. The characteristic in Islam that can tolerate with many kind of culture make it easily to accept this religion through culture assimilation among Malay society. The occurrence of assimilation of Islamic values has changed many aspects of their way of life either directly or indirectly, including the landscape surrounding. In Kota Bharu city, the Islamic values is eagerly developed by Kota Bharu Municipal Council-Islamic City, including the progressing attempting by inserting Islamic motif in their city landscape. However, this attempt has much or less eroded the local Malay landscape. For example, the application of flora species mostly from the Middle East did change the environment of Malay landscape. As such, this study has been undertaken to unearth the compatibility of plants application with Islamic values in the Malay landscape. Interviews were conducted with few group of respondent to get information and identify people skills with regards to plants and Islam religion. Consequently, identifying functional of plant that compatible with Islamic values helps to preserve the Malay landscape and meanwhile protecting the natural heritage and its knowledge.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],21.7,0.15937500000000002,0.39791666666666653,1,0.10460251046025104,0.0794979079497908,0.2689075630252101
272,277,277,"The practice of professional learning community in trust schools, transformation schools and high performing schools in Selangor Malaysia","This study aims to identify the level of Professional Learning Community (PLC) in 3 different types of school namely in Selangor. A total of 450 Malay language teachers from 42 schools in Selangor were involved as respondents in this study. This quantitative study uses survey methods for the purpose of data collection. Data were collected through a set of questionnaires which was developed through Fuzzy Delphi method based on the consensus of 12 experts. The quantitative data collected were analyzed using SPSS version 23.0 and SEM PLS 3.0. This study conveys the level of PLC practice of Malay language teachers in Selangor and the outcome is high for each PLC dimension through overall average score (Min = 3.92, SP = 0.509). In addition, the findings also show that there is a substantial relationship across dimensions of PLC. Finally, it is hoped that the findings of this study will have a positive impact on the implementation of PLC in Malaysian schools as well as for the improvement of student learning outcome.",60029157,University of Malaya,Kuala Lumpur,Malaysia,['1700'],21.25,0.04858585858585858,0.4706060606060606,1,0.08108108108108109,0.0972972972972973,0.3621621621621622
273,278,278,The study on impact of national rural health mission in child health indicator of sourthern satate of India with special refence to infant mortality rate male & female,"NRHM launched by Government of India holds great hopes and promises to the need of the people. Especially, NRHM has been implementing so many projects exclusively to reduce gender (male & female) inequality large disparity in India. The paper intends to study the impact of NRHM in the southern States of India in term of IMR of male and female. This present study is based on the available secondary data. The data has collected from various government reports. This study has employed various statistical and econometric tools like table; graph and paired sample T test in order to analysis and interpretation of data. Thepaired samples T test result indicating thatAfter NRHM in the southern States of India IMR of male and female is significant reduction. But, reduction of IMR in male is much faster and much higher than IMR in female.This paper suggested that to further reduction of IMR of male & female, the Government should be continuous effectively this programme like HBNBC in all regions in India. Then only, its Infant Mortality can reduce as per the requirements of Millennium Development Goals.",60015418,Manonmaniam Sundaranar University,Tirunelveli,India,['1700'],20.33333333333333,0.1168956043956044,0.36231684981684975,1,0.07960199004975124,0.1044776119402985,0.3165829145728643
274,280,280,Experimental investigation on performance of multiwalled carbon nano tubes grafted carbon fiber reinforced friction material,"The present research work was prompted to study the actual performance of carbon fiber reinforced friction material using a two wheeler brake test rig. In this work, carbon fiber (CF) content after three surface treatment methods oxidation (CF1), nitric acid (CF2), and multi walled carbon nano tubes functionalized (MWCNT-F) grafted on CF (CF3), is mixed with phenol polymer matrix and other remaining ingredients. Friction materials are developed by considering surface treated CF content as (5 wt %) using injection moulding method by using a standard die. After fabrication, friction materials are machined to remove unwanted edges to meet with the standard dimensions of friction materials having outer radius 75mm, inner radius 55 mm and thickness 6 mm. Three slotted friction materials are obtained at equal distance of 20mm for each slot and with a depth of 4mm. The performance of surface treated friction materials with three slot condition are evaluated using a test rig at varying speeds and pressures applied on the friction material. These materials are compared with the existing standard asbestos fiber friction material (AF). The test was performed based on few assumptions. All friction materials are characterized for their physical, mechanical, chemical and tribological performance. Scanning electron microscope images (SEM), Atomic force microscope images (AFM) and energy dispersive X-Ray spectroscopy (EDS) are observed for all the samples before and after performing the test, to identify uniform distribution of all the ingredients and worn surface analysis of the materials. The results reveal that, (MWCNT-F grafted on CF three slotted condition friction material), CF3 exhibits good overall performance interms of fade, recovery, weight loss and uniform distribution of all the ingredients compared to other formulations of friction materials.",60076888,Anil Neerukonda Institute of Technology &amp; Sciences,Bheemunipatnam,India,['1700'],25.363636363636363,0.02333333333333333,0.17730158730158732,1,0.10746268656716418,0.06567164179104477,0.40797546012269936
275,281,281,Optimization of extraction methods and detectors for heavy metal analysis in sediment,"The optimization analysis, extractions of metals (Zinc, Cadmium, Lead, and Coppe r) content in Certified Reference Material, BCR®-667 of estuarine sediment was carried out by different procedures of acid digestion such hydrochloric acid-nitric acid-hydrofluoric acid, nitric acid-perchloric acid, and sulphuric acid-hydrogen peroxide mixtures. These metals concentrations were determined by using Differential Pulse Stripping Voltammetry (DPSV) and Inductive Coupled Plasma-Mass Spectrometry (ICP-MS). The purpose was to determine these metals (Zn, Cd, Pb, Cu) concentration in sediment sampl es simultaneously in good precision and accuracy measurement. The results showed both have small standard deviation indicates good precision of metals determinations in both detectors. The accuracy for DPSV ranged from 18.85-154.38% and ICP-MS ranged from 75.28-90.13%. Zn, Cd, Pb, and Cu were simultaneously measured in BCR®-667. When the optimized method was applied into real sediment samples, both determinations showed a good precision in analysis but ICP-MS was selected as the detector. It measured all the metals of interest (Zn, Cd, Pb, Cu) in the real sediment sample simultaneously.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],20.625,0.25,0.43333333333333335,1,0.0752212389380531,0.17699115044247787,0.4900990099009901
276,282,282,Performance and emission analysis of waste cooking oil biodiesel added with AL2O3 nanoadditive using VCR engine,"This research work reveals the effect of biodiesel Unsaturation on its fuel properties and thereby on combustion, performance and emissions characteristics. Major part is focused on keeping the compression ration constant at 18 and analyzing different parameters of compression ignition engine. Also added the Al2O3 Nanoadditive in the produced biodiesel.",60023330,Sathyabama Institute of Science and Technology,Chennai,India,['1700'],16.666666666666664,0.02083333333333333,0.4777777777777777,1,0.1111111111111111,0.05555555555555555,0.35185185185185186
277,283,283,"Face spoofing detection using hybrid kernel approach with CNN, SVM classifiers","Face antispoofing methods has been built up quite a while since the face affirmation frameworks were satisfactorily related. The standard methods in this subject simply utilize the whole area of person face. Regardless, uncommon facial parts continually have different structures and the full-face model possibly debilitate the error of the particular parts. Thusly, setting up the particular model for every facial part can improve the execution of against spoofing. Here, we propose another procedure of face against spoofing utilizing half and half CNN for facial parts. We separate the face into a couple of areas and dependent on different parts, applying the CNN representation for it, which will set up the crossover DCT-CNN. Moreover, we connect on the cross breed model to prepare a SVM classifier. Utilizing SVM, The face picture is portioned into number of various squares and LBP Features are taken, at that point SVM is utilized for deciding if the information picture relates to live or counterfeit face. We tried the proficiency of our procedure on open available databases, picture, video, mask attacks and the investigations exhibit our proposed methodology can secure acceptable results with respect to the top class methodologies.",60021176,Anna University,Chennai,India,['1700'],21.555555555555557,0.0986824769433465,0.3778467908902691,1,0.13761467889908258,0.045871559633027525,0.29439252336448596
278,284,284,A systematic review of knowledge management in competency development,"In this paper, we undertake a systematic mapping review to present a review on knowledge management practice and its relation to competency development. It explores the research methodologies used, its findings and results, as well as the research contributions in these two domains. Thirty four articles in various sectors were identified. We concluded that various research methodologies were used for researches on KM and competency development. The paper is intended to practitioners and academics investigating the field of KM and competency development. Specifically, it contributes to direct efforts for future research in knowledge management and competency development.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],16.166666666666664,0.02,0.305,1,0.102803738317757,0.018691588785046728,0.3177570093457944
279,285,285,"Organic produce and millennials: Motives, attitudes and purchase intention","In this paper, we focus and discuss the factors, which motivates and influence consumer behavior towards organic produce. We extract findings from the Bengaluru city and target population of the study is the millennials i.e…people who belongs to the age group of 23-38. The shift in the attitude and preference of the modern consumers is greatly influenced by the proliferation of various health problems. This study provides a framework for organic industry to understand consumer’s demand and preferences and provides a perspective of Indian organic produce industry from consumers perspective which might serve as a basis for the future development of organic produce market.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],26.0,0.25,0.41875,1,0.08695652173913043,0.017391304347826087,0.22321428571428573
280,286,286,Protecting the pawners: Appraising the role of ministry of housing and local government,"The role of consumer credit in modern society is vital particularly when poor economic conditions prevail and cost of living soars. It is prevalent that low and middle-income earners pledge their valuable in exchange for cash by resorting to pawnshops which are often labeled as a bank for poor. Being on the disadvantage side of having low bargaining power, the role of a regulator is indispensable. Therefore, this study examines the role of Ministry of Housing and Local Government which has been mandated to safeguard the interest of pawners under conventional pawnbroking transaction in Malaysia. The scope of discussion covers its institutional set-up, organisational structure while regulatory powers concentrate on licensing and enforcement based on the relevant statutory provisions. The discussion identifies several shortcomings in respect of licensing requirements, enforcement powers and human resources. Overall, the study finds that entrusting this ministry with consumer protection function is inappropriate. Recommendations to enhance protection for this class of consumer are proposed.",60111124,"International Islamic University Malaysia, Institute of Islamic Banking and Finance",Kuala Lumpur,Malaysia,['1700'],19.875,0.03492063492063492,0.3526984126984127,1,0.10227272727272728,0.028409090909090908,0.29651162790697677
281,287,287,Multistage hybrid median filter (MHMF) design for stereo matching algorithms,"In this paper, a Multistage Hybrid Median Filter (MHMF) of the stereo matching algorithm is proposed with high capability of providing a high performance and high accuracy of disparity depth map to be embedded in numerous stereo matching applications. The significant contribution of this approach is to solve multiple drawbacks and inherent issues that make stereo difficult and unresolved including noises, horizontal stripes, depth map non-edge preserving, and removing the unwanted regions that affect the quality of the disparity depth map. A new post-processing algorithm is developed which occupied multiple stages including a new segment-based, multiple filtering processes, and merging approaches in order to achieve our targets. The structure of MHMF is consisting of several parts including Basic Block Matching (BBM), Dynamic Programming (DP), segmentation, Hybrid Median Filtering (MHF), and merging processes toward the achievement of high disparity depth map. The paper will also provide the performance of MHMF with some existing algorithms, which they all will be evaluated using several stereo functions including PSNR, MSE, and SSIM. Based on the evaluation, the proposed approach can achieve high accuracy of disparity depth map with less algorithm complexity and computational efficiency among other algorithms. Thus, the Multistage Hybrid Median Filter (MHMF) can be a unique approach for efficient performance of stereo vision and 3D applications.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],30.57142857142857,0.05386002886002885,0.3817821067821067,1,0.11904761904761904,0.10317460317460317,0.3821138211382114
282,288,288,Evaluation and comparison of job prediction model,"There is a huge amount of data available over the internet which needs to be mined in order to make that data useful and also there is a need of predictive analytics in order to make the predictions for future outcomes. Artificial neural network plays the crucial part in this scenario as it’s one of promising techniques that can be used to analyze the data with greater accuracy as it has the capability to do complex calculation with ease. This technique makes use of some learning algorithms to train the network. We have proposed and developed a model for job prediction using one input layer, two hidden layers and one output layer using artificial neural network and back propagation algorithm. So, in this paper, some of the learning algorithms have been discussed as well as a comparison is made between the existing model and proposed model for job prediction based on some parameters. This paper also includes the result of the model for predicting the jobs of applicants.",60104778,Central University of Jammu,Bagla,India,['1700'],28.0,0.017948717948717968,0.4967948717948718,1,0.1404494382022472,0.0,0.21787709497206703
283,289,289,Comparative analysis of rural consumer’s purchase behavior towards mobile phone in Karnataka,"Indian urban market is getting saturated for many products. Thus, due to success of brands like Chik shampoo, Project Shakti, LG, Dabur, HLL (then…2005), many marketers are now expanding their product offerings to rural markets as well. Also, since major part of India living in villages (around 70%) are now more improved due to increased literacy, TV penetration and improved affordability is a reason for marketers to expand. Of the research conducted on rural India, majority was either on understanding rural consumers on price, quality, brand, function and style or comparing rural consumers over urban consumers on buying behavior. This research focused on comparing rural consumers of two different districts on age, brand and opinion leaders’ role on influencing the rural preference towards mobile phone. The research focused on understanding the buying behavior of two villages, Keelara and Alekere of Mandya and two villages, Araleri and medahatti of Kolar with reference to mobile phone.",60115161,"Prin. L. N. Welingkar Institute of Management Development &amp; Research, Bengaluru",Bengaluru,India,['1700'],25.66666666666667,0.10078125,0.209375,1,0.08743169398907104,0.07103825136612021,0.39779005524861877
284,290,290,Control of active suspension system using robust H∞ control with genetic algorithm,"Better ride comfort and controllability of vehicles are pursued by automotive industries by considering the use of suspension system which plays a very important role in handling and ride comfort characteristics. Comprehensive comparison on half car model was conducted to analyze the effect of active suspension system, using Robust H-infinity on the model. Passive suspension system is also compared with active suspension technique for the purpose of benchmarking. Parametric uncertainties are used to model the non-linearities associated in the system. Genetic Algorithm is used to develop weighting function for robust control design purpose. Comparison of all models also shows that in spite of adding uncertainties in the system, the designed Robust H-infinity controller achieved better settling time than the traditional passive suspension system.",60095150,C. Abdul Hakeem College of Engineering &amp; Technology,Melvisharam,India,['1700'],20.5,0.15523809523809526,0.5880952380952381,1,0.13138686131386862,0.029197080291970802,0.26717557251908397
285,291,291,Investigation and analysis of technostress among teacher at higher secondary level,"The technology has played major roles in all fields especially in education. The information and communication technology (ICT) in education is to enhance, support and delivered the information in worldwide.. The technology has develop into a integral part in teaching and learning practices. Now-a-days, many schools are replacing with interactive digital board, whiteboard, and they use smartboard for developing or creating good learning environment for students. Some of them feel stress or feel depression when they are using technology overtime. The technostress is the negative psychological effects between the person and introduction of innovative technology. The individual or people are experienced technostress since they can't ready to regulate the technology overtime. The main objective of this study was to find out the level of technostress among teachers. This paper is to analyze the factors of causing technostress among teacher in schools. The data was collected from 200 teachers from Madurai District. The descriptive survey method was adopted for this present study. Further, this paper also discussed about the various coping strategies of reducing stress, how to promote positive outlook about technology and also to give strategies to use it user friendly.",60016712,Alagappa University,Karaikudi,India,['1700'],15.916666666666664,0.17952441077441078,0.4654882154882155,1,0.11574074074074074,0.023148148148148147,0.2641509433962264
286,292,292,Factors affecting innovative work behavior: A case of manufacturing company in Malaysia,"Innovative Work Behaviour (IWB) among employees is very important as it could affects the work performance and sustainability of organizations. This study aims to investigate the impacts of training and development, personality, and organizational culture on IWB. Quantitative method was used where a set of questionnaire was distributed among 200 employees at one manufacturing company located in Kedah, Malaysia. The results presented significant relationships between training and development and IWB (r=0.65, p<0.01); personality and IWB (r=0.64, p<0.01); and organizational culture and IWB (r=0.70, p<0.01). Thus, the appropriate activities should be designed to enhance IWB of employees in the aspects of training and development, personality and organizational culture. Several suggestions for the future study has also been discussed.",60090652,Universiti Malaysia Perlis,Arau,Malaysia,['1700'],19.5,0.3158333333333333,0.5833333333333334,1,0.09219858156028368,0.06382978723404255,0.4557823129251701
287,293,293,Evaluation the importance of readability to assess the quality of software product line orthogonal variability model,Because of the complexity of the systems of software the quality assessment in Software Product Line is very complex task. With reference to software product line orthogonal variability model the concept of the evaluation of quality attribute is very necessary. To implement a successful product line it is helpful to identifying that OVM is easily readable or not. Readability is one of the important features of maintainability. How anyone can easily understand a text or a product is known as readability. For successful implementation of a product line the readability plays a major role. Study the connection of product line of orthogonal variability model with the attribute of readability quality is the main objective of this paper.,60121757,Mewar University,Chittorgarh,India,['1700'],16.714285714285715,0.2605833333333333,0.7019999999999998,1,0.056451612903225805,0.03225806451612903,0.1935483870967742
288,295,295,Sustainbale innovation competency among supervisors in textile mills in Erode,"In a past decade of innovation, companies have come to understand that innovation is an important issue in sustainable business management, as it helps improve capabilities and competencies of their company. Because of the fiercely competitive environment in the textile industry, the need of innovation among the supervisors has become a critical factor in the process of productivity differentiation, leading to sustainable business success.In particularly textile industry need skilled supervisors for managing competitive market. In this research, Amarjothi Spinning Mills is selected, it is one of the major textile mill in Erode District. From the company, 48 supervisors have selected for examining their competency performance. Questionnaire is the main tool for data collection. The collected data were subdued into tables and charts with the help of SPSS 22.0. Statistical tools like Percentage Analysis, Mean Score Analysis andAnovaAnalysis. The results showed that 36-45 years aged supervisors have more productivity with innovation that leads to sustainable business development of the textile mills.",60027171,Annamalai University,Chidambaram,India,['1700'],20.0,0.11333333333333333,0.5304166666666668,1,0.08888888888888889,0.06666666666666667,0.3125
289,296,296,An applied study of the effect of air pollution on non-environmentally friendly colors of archaeological oil paintings in the vicinity of the nubia museum in aswan,"Aswan government in south Egypt is famous with its monuments, so there must be measurement and detailed characterization of pollutant present in it and its effect on colures for perfect conservation to ancient paintings and archaeologies. The study carried out in Aswan city, one of the most polluted areas with gases and particulates (it is characterized by the presence of large industrial centers such as the Kima Aswan plant which cause high levels of pollutants). The study carried out by measuring atmospheric pollutants (RH%, Temperature, TSP and Smoke) during exposure of colored materials consisting of earth pigments mixed with oil medium (linseed oil) applied on canvas and measure the impact of inappropriate environmental conditions on them. The study was done using modern methods of testing and analyzes such as EDX-SEM, XRD,FTIR and Spectrophotometer. The results indicate the discoloration of the colors and the presence of a black layer of different thickness on the surface of the samples consisting mainly of dust and a calcified white layer of mineral soap.",60107271,Aswan University,Aswan,Egypt,['1700'],33.8,0.1858928571428572,0.4459523809523809,1,0.07936507936507936,0.06349206349206349,0.2765957446808511
290,297,297,Security key provided for group data sharing in cloud computing,"Data sharing in cloud computing enables multiple participants to freely share the group data, which improves the efficiency of work in cooperative environments and has widespread potential applications. Nonetheless, how to guarantee security of information sharing inside a gathering and how to productively share information redistributing such that difficulties the weight gathering. Note that the key understanding convention has assumed a significant job in the protected and proficient sharing of information in a distributed computing gathering. In this paper, by exploiting symmetric balanced incomplete block design (SBIBD), [2] Our present understanding of the key square structure that supports the convention based on the novel of different members, who deftly able to expand the number of members in the cloud conditions as indicated by the structure of a square plan. Based collect the proposed information sharing model, we present a general equation for creating a K key meeting open to specific members. Note that with the benefit of (v; k + 1; 1)-a square structure, uncertainty computation of the increase in the proposed convention directly with the quantity of members and correspondence complexity greatly decreased.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],30.66666666666667,0.060294117647058824,0.5661764705882352,1,0.11274509803921569,0.004901960784313725,0.3058252427184466
291,298,298,A literature review on energy value stream mapping (EVSM),"This paper presents a review of literature on extended VSM to enhance Energy Value stream mapping. The increase in the price of energy due to the scarcity of energy resources has imposed enormous pressure on the industries to reduce the consumption of these resources and is forcing them to invest in techniques that contribute to the improvement of their energy efficiency. The application of methods such as Energy Value Stream Mapping (EVSM) has been promising in reducing energy consumption and is being one of the methods widely used by industry professionals to eliminate inefficiencies in processes. Based on this information, the objective of this work is to present an analysis of the literature on EVSM addressing the modes of implementation, advantages and disadvantages, the applied industrial context and the complementary methods. By means of the results it was verified that its use allows the reduction of energy consumption, but is limited to a static representation and allows the analysis of only one product.Though some researches had proposed how to increase sustainability, none of those researches showed the effect of the increase of performance metrics to the level of energy. Finally, suggestions are made for methods to complement its use and to assist future research in this area.",60026714,"Birla Institute of Technology, Mesra",Ranchi,India,['1700'],34.5,0.03363095238095238,0.4952380952380953,1,0.11210762331838565,0.03587443946188341,0.2669683257918552
292,299,299,Teachers’ perspectives of college english in institutions of higher learning in central China,"English is taught as a foreign language at all education levels ranging from the primary schools to the graduate schools in China. College English is taught to non-English majors in all institutions of higher learning (IHL) in China. Since the implementation of the 2016 College English Teaching Reform, all IHL in China have witnessed a shift from a traditional teacher-centered approach to a more learner-centered communicative approach in the teaching and learning of English as a Foreign Language (EFL). This paper presents the perspectives of 62 university EFL teachers on College English from two IHL located in Central China. Data were collected via a questionnaire and interviews. The findings revealed that teachers have moderately positive perceptions of College English in terms of its teaching objectives, language skills, teaching methods and teaching resources. The findings also recorded no significant difference in teachers’ perceptions based on gender but a significant difference was observed based on age on two aspects, namely teaching objectives and language skills. Meanwhile, a significant difference was also seen based on teaching experience in terms of teaching objectives. This study has helped to provide some feedback on the implementation of the 2016 College English Teaching Reform so that necessary steps can be taken for further enhancement of its implementation in all IHL in China.",60104896,SEGi University,Petaling Jaya,Malaysia,['1700'],23.88888888888889,0.08448863636363636,0.3710227272727272,1,0.09583333333333334,0.1125,0.36324786324786323
293,300,300,Automated pest detection and control using acoustic signal in wireless sensor network,"Agriculture is the heart of our civilization, but farmers are facing many problems for good yield because of pest infestation. To control the growth of pests, pesticides are sprayed in large quantities through the cultivation land. Due to this, humans consume only inorganic food which leads to serious health issues. Moreover manual inspection by the farmers is not possible during the different stages of growth of the plant. This necessitates the development of a novel technique which detects the presence of the pests and intimates the farmer to spray the pesticides to the particular area. In this project work, the acoustic signal of the pests which affect a particular plant will be captured, processed and detected. Once it has been detected, it will be initiated to the farmer to control the infestation. A real time hardware setup will be developed to detect and control the pest.",60023330,Sathyabama Institute of Science and Technology,Chennai,India,['1700'],18.25,0.1324404761904762,0.53640873015873,1,0.1375,0.0,0.28125
294,301,301,Profile of students’ argumentation: A case study on human cloning,"Skills argue is one of the crucial role in developing the science. Extensive knowledge not only presents the facts, but more than that. Broadly science can construct an argument and have consideration and debate something obvious about the phenomenon that occurs. This research conducted to capture the profiles of students' argumentation on issues of human cloning. Students were chosen purposively with the subject of 170 high school students from three high schools in Bandung City, West Java, Indonesia. A case study approach with a descriptive analysis to analyze student test results of argumentation is used in this research. Instruments given are questions context of human cloning. The argumentation is adapted from Toulmin’s argumentation pattern, which contains the structured argument by Claim, Grounds, Warrant, Backing, Qualifier, and Rebuttal. The result shows the general pattern of students’ argumentation skills is the Claim only as much as 8,82%, Claim-Data-Warrant argument 81,76 % and the remaining 9,42% is a combination pattern of the six argumentation components. The percentage of higher coherence of students' arguments is 49% in the lower public school, better than the medium private school (33%) and medium public schools (21%). The interview of the teacher due to confirm the teaching-learning process on facilitating students' argumentation skills.",60103797,Universitas Pendidikan Indonesia,Bandung,Indonesia,['1700'],18.63636363636364,0.07954166666666668,0.442125,1,0.0728744939271255,0.05668016194331984,0.3760330578512397
295,302,302,The implementations and applications of ampere’s law to the theory of electromagnetic fields,"Many efforts are made in order to link the Ampere’s Law to the theory of electromagnetic fields and waves especially the topic of magnetostatics. In this paper, the implementations and the applications of Ampere’s Law are determined, studied and analyzed based on the journals that are related to Ampere’s Law. Initially, eight related journals are picked and chosen as our references and subsequently, one journal out of these that we understand the most and most complete and informative will be our main reference and we basically prepare and write this paper based on this main reference by comparing the main reference with the rest of the journals in terms of the performance, methods, results, discussions and so on. As a result, we understand that the Ampere’s Law can be implemented and applied in many ways and applications in order to solveproblems.",124036320,Atmospheric and Lightning Research Lab Centre for Telecommunication Research and Innovation (CeTRI),Malacca,Malaysia,['1700'],35.25,0.2,0.4038461538461538,1,0.12101910828025478,0.07643312101910828,0.2857142857142857
296,303,303,Expert review analysis on knowledge integration model in business organization,"Knowledge Integration (KI) has been significant concern in analyzing the organization performance. Social media also are widely adopted by organizations to enhance the effectiveness of KI practices. The purpose of this paper is to present the findings of expert opinion in verifying the KI and social media factors in developing of proposed model. The study approach was conducting to verify from 3 academicians and 2 industry experts who has experienced in knowledge integration and social media. The findings from expert has verified the content of 12 factors include technology dimension (social network, IT capability, media interactive, media richness) organization dimension (credibility, specialization, coordination, inter-learning organization) Environment dimension (technology turbulence and market turbulence) were suitable for proposed KI model. Descriptive analysis has been used to interpret the frequency, mean, and standard deviation which represent the factors. The proposed model will be validated and conduct through survey in the future work.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],21.285714285714285,0.12048611111111113,0.3336805555555556,1,0.10919540229885058,0.034482758620689655,0.3488372093023256
297,304,304,Internet of things-based services implementation and challenges in malaysia: A review,"The fields of electronics and computer science have merged to form one of the most significant technological advances; the Internet of Things (IoT). IoT has become a key trend all over the world. Although still in its early stage of development, the impact of IoT in Malaysia has been significant. However, there exist particular challenges in achieving successful implementation of IoT-based services. This paper aims to review and understand the implementation status of IoT-based services in Malaysia. The challenges, as well as suggestions for future research trends, are discussed.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],14.833333333333336,0.2833333333333333,0.6197916666666666,1,0.10377358490566038,0.04716981132075472,0.38235294117647056
298,305,305,Enhanced ODR reflection by using Sio2 exponentially graded materials for 1D photonic crystals,"An exponentially graded index material for one dimensional structure of binary & ternary photonic crystal has been proposed. It works as a perfect mirror at third transmission window (1550 nm).A transfer matrix method has been used to estimate the reflection properties of semiconductor materials. An enhanced ODR range is obtained by using both binary and ternary photonic crystal in which Ge as exponentially graded material. In the proposed structure when a third semiconductor layer (GaAs) is introduced between SiO2 and Ge semiconductor photonic crystals the ODR range is increased. This property shows that one dimensional graded index ternary photonic crystal structures have widened ODR than Binary photonic crystals. Therefore broadband omnidirectional photonic bandgap is applicable for many prospects such as omnidirectional mirrors, optical switches, filters, WDM etc. for optical fiber communications.",60097517,G.L.Bajaj Institute of Technology And Management,Greater Noida,India,['1700'],18.714285714285715,0.3,0.4,1,0.09722222222222222,0.09027777777777778,0.4246575342465753
299,306,306,Architecturally inspired furniture: Creating furniture inspired by masterpieces in architecture. Application in advanced furniture course,"Architecture is one of humanity's most visible and long-lasting forms of expression, spanning the entire length of humanity. Most historic civilizations are even identified by their surviving architectural relics: The Pyramids of Giza in Egypt, The Golden Pavilion in Japan, or The Taj Mahal in India. Here, the research focuses on a few of the icons of modern architecture, utilizing masterpiece examples of masters of architecture that are true masters of their craft. We employ some of the icons of modern architecture as key elements for analyzing, developing, and evaluating the advanced furniture design we will work on. This research explores the possibility of producing a line of furniture design inspired by the icons of modern architecture, masterpieces of architectural design by famous pioneers in the classroom environment. Borrowing the architectural language to produce furniture is an experimental technique which expects to find inspiration from other designers work. In the advanced furniture design course, which is offered as an elective in the interior design program, the students were asked to produce original designs of furniture pieces that reflect the design language of a particular building of a famous architect. The goal is for the students to be able to analyze the style elements, find the defining lines, and eventually producing their own designs based on their finding. The exercise as successful as it was did not finish as desired, producing physical furniture pieces, but only settled for scale models which the students were able to produce in the allocated time and resources. This research would like to expand that opportunity to detail and build some of the resultant ideas in order to close the design process circle by producing the expected final product.",60074315,Abu Dhabi University,Abu Dhabi,United Arab Emirates,['1700'],28.3,0.2450617283950617,0.5768959435626102,1,0.1382636655948553,0.02572347266881029,0.27184466019417475
300,307,307,21st century skills and sustainability,"Sustainability has been interpreted in many ways based on requirements from different aspects, application domains and objectives. Sustainability as a whole stand on three pillars as environmental sustainability, economic sustainability and social sustainability. Sustainable Development (SD) is the outcome of sustainability in its all the three pillars. Education is considered as most important and fundamental domain to achieve sustainable development, as has been proposed andreflectedby the new 2030 agenda for sustainable development (as adopted on 25 September 2015 by the UN General Assembly). 21st century skills are the skills that are basic requirement for overall development of the students in their K-12 stage and are helpful in leading a successfullife. The basic educational skills like learning skills, literary skills and life skills are required to be instilled in a blended form of learning in school curriculum. Such kind of blended learning focused on development of these skills provide support and act as a means and tool for Education for Sustainable Development (ESD).",60076774,"Amity University, Noida",Noida,India,['1700'],23.142857142857146,0.17468805704099818,0.36595365418894826,1,0.0782122905027933,0.07262569832402235,0.3575418994413408
301,308,308,Improved canny edge detection method for affected leaves,"Edge Detection technique is applied commonly in several fields and also agricultural field. This technique used in agricultural for plant disease identification and also identifying leaves common characteristics that’s why it’s will be prove whenever it’s useful technique for farmers and will be alert them at the correct time before escalating of the disease over large area. Compared with various Edge finds out Methods, Improved Canny Edge Detection method provide higher accuracy of following datasets such as hibiscus dataset accuracy is 0.86, Swedish dataset accuracy is 0.96 and Betel Leaf dataset accuracy is 0.98.",60114470,Erode Arts and Science College,Erode,India,['1700'],31.33333333333333,0.05803571428571429,0.31607142857142856,1,0.14705882352941177,0.08823529411764706,0.3238095238095238
302,309,309,A reference model for semantic enabled services library system,"Background/Objectives: This study proposes functional requirements and an architectural reference model of Semantic Library, recognized as a prototype of nextgeneration library information systems. Methods/Statistical analysis: Semantic Library can realize semantic interoperability and integration based on ontology and metadata, and also renovate information services for users with openness, sharing, participation and collaboration. Semantic Library will be effectively implemented by means of service-oriented architecture and the logical structure of FRBR. In this study, a reference model of Semantic Library at cloud computing environment emerging is presented as a next-generation model of library information systems. Findings: The LOD form evolves into an open library framework, and the detailed technology can be categorized into six categories. First is LOD converting technology, which can publish structured database like non-structured data into RDF triples by rule-based mechanism. Second is to develop an ontology language to specify LOD data at web service and distributed processing system, and is about technology for registering LOD information resources which is possible to register LOD specification. Third is LOD data retrieving parts for LOD data set and semantic retrieving system which are used to search ontology, semantic web and semantic retrieving field. Fourth is knowledge service specification and registration enabled field. Fifth is about discovery of semantic based knowledge service used for semantic based matching system which discovers most optimized services to coup with user requirements and service profile for ontology, semantic web and inferences. Six is LOD based service development parts, which is an integrated development environment (IDE). Improvements/Applications: This study combines libraries, information technology, and nextgeneration Internet technologies, including the concept of semantic libraries and functional requirements.",60033270,Wonkwang University,Iksan,South Korea,['1700'],22.33333333333333,0.2,0.4133333333333333,1,0.10828025477707007,0.0732484076433121,0.37333333333333335
303,310,310,Child custody disputes: An analysis of circumstances in which the court awards custody of children to non-parents in malaysia,"One important issue in a divorce where great importance need to be given is the issue on child custody disputes. A marriage may come to an end but the ties between the parent and the children are never severed. When there is an action for primary custody, the courts presume that the custody should be given to the parent unless there are evidence to show that the parents should not be given the custody. Immediate family members, including grandparents, aunts, uncles, or older siblings, are some of the common suitable third-party custodians. This article examines the child custody disputes by analysing the circumstances in which the court awards the right of custody of a child to a non-parent in Malaysia. Several cases and statutory provisions will be examined in this article. A comparative legal research methodology is employed in comparing the positions in Indiana. The findings of this paper suggest some comprehensive policy and guidelines which can assist the courts in giving rights to third-party caregivers who played a significant role in raising the children while the biological parent was absent.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1700'],22.625,0.2706709956709957,0.504004329004329,1,0.12437810945273632,0.009950248756218905,0.2717948717948718
304,311,311,Automated early detection of multiple diseases from retinal fundus images: A review,"Now a days there are large number of disease such as cardiovascular, diabetic retinopathy and lung diseases which will damage the optic nerve head that results in the loss of vision. Manually it is not possible to find the disease at earlier stages The diagnoses require regular monitoring of retinal fundus images that consumes more time and costlier. The accuracy and reliability of the diagnosis depends upon the ophthalmologist’s domain knowledge. Therefore the requirement for automatic diagnosis of multiple eye diseases is needed. This paper surveys automatic extraction of multiple diseases from the retinal fundus images. This paper evaluates the existing automated early detection of multiple eye disease extraction methods based on Convolution neural network, multi-sieving Convolutional neural network and back propagation network.",60109336,Saveetha School of Engineering,Chennai,India,['1700'],20.5,0.07402597402597402,0.3004995004995005,1,0.09701492537313433,0.007462686567164179,0.2706766917293233
305,312,312,Design and analysis of IOT/WSN compatible low power symmetrical cryptography algorithm for data security,"Internet of Things (IoT) is promising future technology is relied upon to interface billions of gadgets. Many rounds of encryption are essentially a misuse of requirements Gadget vitality. Less convoluted calculation, be that as it may, conceivable compromise required uprightness. It is a 64-bit square secret key that requires a 64-bit key to encrypt information. The engineering of the calculation is a blend of feistel and a uniform substitution-to supplant the system Simulation. The outcomes demonstrate that the calculation gives only a considerable security five rounds of encryption. The proposed work demonstrates the implementation of symmetric key lightweight algorithm for secured data transmission of images and text using image encryption system as well as reversible data hiding system. Proposed research have demonstrated faster computation, less complexity and higher PSNR as compared to existing algorithms. In the proposed work we have implemented symmetric key cryptography for various format of images, as well as real time image acquisition system has been designed in the form of graphical user interface.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],18.555555555555557,0.03627450980392157,0.5475490196078432,1,0.08695652173913043,0.016304347826086956,0.2967032967032967
306,313,313,Application of design thinking in designing history instructional media for high school students,"Design thinking as a mindset, methodology, and work tools has given a new color in the world of education, especially in the innovation of instructional media development. An application of 5 stages in the design thinking that consists of empathizing, define, ideate, prototype, and test is able to identify the learning problems experienced by high school students so that the development of instructional media is relevant to the learning problems. This study aims to design a prototype of instructional media especially on historical subjects that are designed relevant to various problems experienced by high school students when learning history. From the problem identification to the process of obtaining the right solution that can be solved with the use of instructional media entirely done with design thinking. The end result of this research is a prototype of history instructional media which is tested by the Guerrilla method as the solution of various learning problems experienced by high school students when learning the history.",60087601,Universitas Negeri Yogyakarta,Yogyakarta,Indonesia,['1700'],32.4,0.2876298701298701,0.6475162337662338,1,0.09770114942528736,0.011494252873563218,0.20114942528735633
307,314,314,Smart health care system using wireless body area network,"As is aware, there is a rapid progress in health care technology, day by day. With the advancement in technology, newer and newer diagnostic and therapeutic systems are being developed, for better health care. Ubiquitous systems are very effective and useful, these days, particularly for maintaining the health, anywhere, anytime, for any one. Wireless sensor networking (WSN) technology is applied easily for health care in various harsh environments. This technology is very useful to monitor, in particular, the health of old age patients, living in isolated areas like hills. Medical abnormalities are sensed and transmitted with sensors to main city hospital. After proper analysis by the doctor, appropriate advice/precaution is telemeter back to the patient before shifting to a hospital. Examples of some diseases are Strokes are more serious to be dealt with. Cancer nanotechnology and high intensity focal ultrasound system for the treatment of deep seated brain tumors.The advanced health care systems are thus very effective and useful for better health care, in a reliable manner, at low cost.",60097266,P.D.A. College of Engineering,Gulbarga,India,['1700'],18.88888888888889,0.22923076923076924,0.3996153846153847,1,0.04,0.0,0.29081632653061223
308,315,315,"Databases, classifiers for speech emotion recognition: A review","Over the past decades, a lot of research was done in the field of speech emotion recognition using machine learning and deep neural network learning. However, in past few years, researchers are focused on exploring and utilizing deep neural network for speech emotion recognition over machine learning. DNN attracts the interest of researchers as it yields better results than machine learning. This paper aims to explore various existing models, methods and techniques for speech emotion recognition based on machine and deep neural network learning. The goal of this paper is to find out the deficiencies in current literature and also to analyze various existing methods. This research will be helpful for the researchers those who will aim to work and improve the existing literature of speech emotion recognition.",60113453,"Multani Mal Modi College, Patiala",Patiala,India,['1700'],21.33333333333333,-0.02,0.37,1,0.13768115942028986,0.007246376811594203,0.2536231884057971
309,316,316,"Evaluation of isolated gut probiotic bacillus subtilis on haematological parameters of Indian major carp Labeo Rohita (Hamilton, 1822)","The research study followed out to determine the influence of isolated single gut probiotic bacteria Bacillus subtilis (SUB 3845847 SeqJP2 MH128358) on the haematological parameters of freshwater carp Labeo rohita. After acclimatization, fish (5.00 cm ± 4.5 gm) were allocated into the tubs such as a control tub (feed without B. subtilis) and an experimental tub (feed fed with B. subtilis) was continued, 30 fingerlings fish brought together keen on the separate tub. The formulated diet such as ricebran 40%, groundnut oil cake 20%, dry fishmeal 15%, soyameal 15%, maize 9%, vitamins and minerals mix 1% were analyzed for the proximate composition. The formulated diet was given each day morning at 6 am and evening at 6 pm usually at the ratio of three percent of body weight. The water was to exchange each day with a pump and every treatment had triplicates. The blood samples were collected on fifteen days intervals of the experimental period in 60 days. The results exposed that the haematological parameters were insignificantly (P<0.05) increased in the experimental group than the control group. The isolated gut probiotic B. subtilis with formulated diet increased the haematological values of the haemopoietic stimulation in fresh water fish Labeo rohita.",60114470,Erode Arts and Science College,Erode,India,['1700'],18.272727272727273,0.02354497354497355,0.41825396825396827,1,0.07327586206896551,0.0603448275862069,0.405982905982906
310,317,317,Measuring consumers’ perception and determinants of green purchase,"In the late 20th century ecological issues have emerged as a serious concern among corporate world.Simultaneously consumers also become environmentally conscious and want to buy eco-friendly products, which compelled to businesses to address these concerns in the light of sustainability and economic growth. Green marketingwhich also sometimes known as sustainability marketing, environmental marketing or ecological marketing is an opportunity to build innovative products and technologies that meet customer needs in the market. It has also received a tremendous boost with the revival of environmental consciousness among consumers. The study examines consumers' perception towards green products and factors which influence the green purchase. Information was obtained from 600 consumers resides in two cosmopolitan cities (Chennai and Hyderabad) on justified sampling method. Multiple Regression techniquewas used to know the consumers perception and Exploratory Factor Analysis (EFA) was used to identify the influencing factors for green products. The findings reveal that consumers have positive perception for green products and most influencing factor is eco-labels followed by promotion, price, availability and quality for green purchase.",60069550,H.N.B.Garhwal University,Srinagar,India,['1700'],24.42857142857143,0.07396694214876033,0.4414600550964188,1,0.11398963730569948,0.04145077720207254,0.35294117647058826
311,318,318,Factors influencing the adoption of mobile banking service among cihan bank customers in the kurdistan region of iraq,"Few banks ofIraq’s Kurdistan Regionhave started providing banking services over smartphones. In addition, not many papers find the factors that influence users’ intention to adopt mobile banking services among bank customers in Iraq’s Kurdistan Region. The main focus of this research is to fill the gap also, analyzes various variables impact of mobile banking adoption.The theories of Diffusion of Innovation (DOI) and Technology Acceptance Model (TAM) have been chosen by the researchers as the baseline theories.It is discovered that relative advantage, trust, and subjective norms have a constructive impact on adoption. Conflicting to the unearthing in the extant writings, compatibility and perceived value have no critical impact on adoption. Complexitynegatively affects appropriation. The discoveries of this examination will have viable ramifications for the financial business in Iraq’s Kurdistan Region.",60121882,Lebanese French University,Erbil,Iraq,['1700'],21.5,-0.04047619047619048,0.3190476190476191,1,0.08552631578947369,0.09868421052631579,0.37748344370860926
312,319,319,Gamical: Simulating medical module using gamification approach,"Medical curricula in the foundation years in King Abdulaziz University, Jeddah, Saudi Arabia, focus on teaching students' symptoms and diseases. Medical students acquire their knowledge and skills by exploring the clinical environment and interacting with clinicians and patients in various contexts. The paper presents an e-learning approach to assist medical students in acquiring knowledge and skills by interacting with virtual patients in preset scenarios. The e-learning systems currently in use offer materials targeted to one audience, regardless of differences in students’ backgrounds, interests, and goals. These platforms are also usually centered around a single learning method, which may adversely affect the achievement of learning outcomes. Therefore, this paper proposes an adaptive e-learning system, ""GAMICAL,"" which can adapt to and control medical students’ learning in their endocrine physiology module, with the goal of improving their diagnostic skills. GAMICAL uses animation and images to present medical cases, symptoms, and situations visually. The integration of gamification features into the academic material may enhance the learning process by boosting student engagement and motivation.",60004582,King Abdulaziz University,Jeddah,Saudi Arabia,['1700'],21.125,-0.026785714285714284,0.11369047619047618,1,0.13930348258706468,0.03482587064676617,0.39487179487179486
313,320,320,Micro franchising for B40 societies in Malaysia: Are we there yet?,"Franchise business system has been regarded as one of the tool that can stimulate the economy of the B40 societies. Therefore, this paper contained one major objective, which is to compare the practice of micro franchise in Malaysia with selected micro franchise businesses in Ghana and India.To accomplish the objective of this research, qualitative method were employed. In-depth interviews were conducted with the selected micro franchise businesses in Malaysia. The findings of this research revealed majority of the micro franchise businesses in Malaysia are yet to benefits B40 societies and even not affordable for them to venture. Further analysis also revealed that micro franchise busineses in Malaysia tend to have different objectives, business format, target group, distribution network and even business model as compared to selected micro franchise businesses in Malaysia. In addition, majority of the micro franchise businesses in Malaysia is a scale down franchise businesses rather than scale up businesses.",60012005,Multimedia University,Malacca Town,Malaysia,['1700'],25.33333333333333,-0.015509259259259263,0.3481481481481481,1,0.10650887573964497,0.05325443786982249,0.28484848484848485
314,321,321,Landslides susceptibility assessment and risk mapping using logistic regression and geographical information system,"Rapid development in the agriculture sector, land clearing, and construction have a great impact on the surface and soils structure especially in the mountainous area, for example, Cameron Highlands. These activities coupled with natural triggering factors like aspect of slope, elevation,geology, angle of slope, curvature, and rainfall may lead to serious geological hazard such as landslides. Cameron Highlands is one of the regions that is known to be susceptible to landslides. A study was carried out to classifysusceptible areas and guide tothe risk management. In this study, Logistics Regression (LR) using Geographical Information System (GIS) was applied to assess the susceptibility oflandslidesat Cameron Highlands. Ten (10) landslide contributing factors are taking into consideration including elevation, aspect, geology, slope, curvature,land use, distance from the fault, distance from drainage and road as well as rainfall. Based on the result, the LR approach obtained 82.5% landslides prediction accuracy and considered as a good result for the prediction. With the right information and updates from the landslides susceptibility map, it will assist the local authority in mitigating, treating and controlling this natural hazard at an early stage before any landslide happen.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],23.375,0.15930735930735931,0.4683982683982684,1,0.09375,0.05803571428571429,0.3482142857142857
315,322,322,A study on the development and effect of survival swimming standard curriculum,"Survival swimming standard curriculum was developed and its efficacy was examined 23 3rd grade elementary school student participated in the survival swimming standard curriculum, and 48 3rd grade elementary school student participated in the leaf float(n=24) and general swimming(n=24) curriculum. Their scores on various variables were compared with those of the non-treatment control group. For the self-compassion enhancement program group, basic psychological needs and performance assessment significantly increased, respectively. These findings indicated that the survival swimming standard curriculum exhibited relative benefits of its effects compared to the other curriculum. Lastly, contributions of this study to an integrative understanding of the process of survival swimming are discussed. Limitations and suggestions for future research are also discussed.",60024495,Catholic Kwandong University,Gangneung,South Korea,['1700'],19.166666666666668,0.05555555555555555,0.2703703703703704,1,0.08396946564885496,0.03816793893129771,0.33587786259541985
316,323,323,A proposal of automatic identity fingerprint authentication system using matching algorithm for improvement of fingerprint authentication,"Human fingerprint is the most suitable biometric identification means because of their unique nature, difficult to alter, and durable over the entire life time of an individual, and making them suitable as long-term markers of human identity. The paper aims to develop a proposal of automatic identity fingerprint authentication system using matching algorithm to verify fingerprint for testing people based on the concept of data analysis and classification of dataset. The research contributions involve full knowledge of data analysis to find out optimal solution for the components in automated fingerprint identification system. In experimental results, the proposed system was obtained and extracted images in automated fingerprint identification system. As compared with other current approachesthe proposed matching algorithm performs the best output in analyzingfingerprint authentication.",60071354,Hanoi University of Science and Technology,Hanoi,Viet Nam,['1700'],24.8,0.2,0.5178571428571429,1,0.16296296296296298,0.007407407407407408,0.22556390977443608
317,324,324,Analysis of designed power system with the real power system,"This Research deals with the investigation of designed power system with the real power system of 11 KV substation at Sahnewal. It used an optimization technique to reduce the fault in voltage and current. The collapse of the voltage and the swelling of the current constitute the main problem of nonlinear loads.Thus, by study Grey wolf optimization technique we have to reduce the difficulty of sag / swell of the voltage and current by using the static distribution compensator (D-STATCOM). The result of optimization technique in mitigating voltage sag/ swell is find out with the help of MATLAB simulation.This paper presents the 3 phase fault of voltage and current that occur in 11kv substation at Sahnewal are removed by using Grey wolf optimization technique, and also compared the results with real Power system.",60016760,Punjab Technical University,Jalandhar,India,['1700'],33.25,0.09666666666666664,0.3633333333333334,1,0.08843537414965986,0.07482993197278912,0.23404255319148937
318,325,325,Netflix and dilemma of content regulation in Malaysia,"This study represents the dilemma encountered by Malaysian audiences on the issue of Netflix content through Internet streaming. Malaysia has various laws that regulate the functioning of media in the areas of printing, broadcasting and telecommunications. However, the government‟s assurance through the Communications and Multimedia Act 1998 will not impose any filter on the Internet has opened the democratic space to the new media world. This freedom has triggered a public outcry over content streamed through the Netflix platform. Netflix, as one of the leading global media overthe-top (OTT) provider, provides its published material as well as aggregated content from publishers from various countries that are not in line with the practice of content regulation in Malaysia. The findings of this study revealed the experiences and views of adults on Netflix‟s subscription motives, the relationship between the Internet and Netflix‟s programmes as well as discovered audiences understanding on the regulatory and censorship concepts in Malaysia. In conclusion, this would lead to some suggestions for further consideration.",60001821,Universiti Kebangsaan Malaysia,Bangi,Malaysia,['1700'],23.714285714285715,0.022727272727272724,0.3368686868686869,1,0.08743169398907104,0.060109289617486336,0.35359116022099446
319,327,327,Cache supported efficient path planning technique in VANET,"In mobile road navigation, an important aspect is one that finds consistency between source and destination. Transport Special Network called Vehicular Ad-hoc Network (VANET) is a modern technology that combines the capabilities of next-generation wireless networks in vehicles. The skill of the path planning function is censored due to various scenarios, such as sudden change of direction, unexpected traffic conditions, lack of GPS signals, etc. Another important technology called Intelligent Transport System (ITS) which play an essential role in VANET. In particular, an efficient cache path planning method using the OCVRP (Vehicle Routing Protocol) algorithm with optimal cache support responds to another route planning request. In real time by properly organizing caching and reusing old polled paths. Unlike the traditional cache, where the polled path is used only when the request matches the most recent one. As a result, the server only calculates unmatched paths, which minimizes load of system.",60097266,P.D.A. College of Engineering,Gulbarga,India,['1700'],18.75,0.15494047619047618,0.5689880952380952,1,0.0847457627118644,0.096045197740113,0.41040462427745666
320,328,328,Design of the goat/sheep holding cage slaughtering system (Cage for animal slaughter): Innovations and prospect,"The main objective of inventing the goat/sheep holding cage-slaughtering mechanism or cage for animal slaughter was to seek solutions for the slaughtering mechanism from the traditional operation with four to five persons manning it to a one-person operation. The development of this innovation is for Chak Chee Bor Enterprise. This mechanism consists of a goat/sheep holding cage of 1.23m (height) X 1.60m (length) X 0.97m (width). The overall purpose of using this goat/sheep holding cage is to keep the goat/sheep calm, whilst minimizing the danger of unnecessary injury to both the animal and worker. The goat/sheep holding cage-slaughtering mechanism consists of a head latch (neck yoke or head gate) to hold the animal‘s neck and head, and two wooden boards to hold or gently clamp the body of the animal, with the purpose to calm the animal and ensure that it does not move. The round-shaped iron pieces at the end of both sides of the holding cage enable the mechanism to be swung aside or tilted at a 45o angle before the final stage of the ritual. This holding cage-slaughtering mechanism that comes with an adjustable head latch is able to accommodate different sizes of animals.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1700'],28.142857142857146,0.08888888888888889,0.5506944444444445,1,0.10504201680672269,0.02100840336134454,0.2350230414746544
321,329,329,Analysis of solar energy potential to construct a solar community in North Korea,"Background/Objectives: North Korea’s residential environment is poor because housing has hardly been developed since 1953. This study aims to analyze the solar energy potential to construct community in North Korea. Methods/Statistical analysis: As a fundamental study, this paper focuses on selecting optimal regions for such a project in North Korea, considering solar energy and accessibility to South Korea by railway. The Inter-Korean railways were used to calculate the solar energy by the region by dividing North Korea, and the Hottel’s clean sky model was introduced as a methodology to derive the solar energy. Findings: For this study, specific regions in North Korea must first be determined, and two important elements must be examined. First, the transportation networks of the two Koreas are analyzed, and second, the available solar energy is calculated. For the former, the project region must have excellent accessibility to South Korea because massive South Korean resources, e.g., materials, technicians, and maintenance resources, must be transported to North Korea for the project. This study used railways as a transportation network for the project because the Trans-Korean Railway (TKR) between South and North Korea is currently being actively discussed. For the latter, regions in North Korea with abundant solar energy should first be identified. Moreover, for the project to be effective, regions with excellent accessibility to South Korea must be selected. The analysis results revealed that three regions in western North Korea, namely, Haeju, Chonju, and Changyon, had the highest solar energy. Furthermore, although the Kumgangsan region in eastern North Korea had less solar energy than the western regions, it was the most accessible. Improvements/Applications: This study could significantly contribute to the improving the North Korean sustainable development as well as to promoting the peace and the prosperity between South and North Koreas.",60073748,Hankyong National University,Anseong,South Korea,['1700'],22.615384615384613,0.1955357142857143,0.4904761904761905,1,0.09169054441260745,0.1174785100286533,0.3489736070381232
322,330,330,Studies on the distribution of 210pb in surface sediments of peninsular malaysia during monsoonal season,"Thirty-three surface sediments samples were collected from the East and West coasts of Peninsular Malaysia by using the Van Veen Grab during Universiti Kebangsaan Malaysia – First Institute of Oceanography, China (UKM-FIO) Scientific Cruise. Samples were collected during Southwest Monsoon events (August 2017) and Northeast Monsoon events (March 2018). The analysis of chemical and physical of the homogenised sediment sample, including sediment textural, loss of ignition, and210Pb concentration have been determined to investigate the effect of monsoonal changes to the physical and chemical characteristic of sediments in marginal sea area. The concentration of210Pb in surface sediment ranged from 80.33 ± 11.81 Bq/kg to 231.52 ± 25.95 Bq/kg. The result of statistical analysis shows significant negative correlation between organic matter (OM) and the content of silt (r =-0.519, p < 0.05) and positive correlation between OM and sand (r = 0.507, p < 0.05) during Southwest monsoon. However, no significant correlations detected between210Pb with the OM and sediments textural during both monsoons. Since the location of the sampling stations are located in the marginal sea area, it’s may suggest that the exposure to the boundary scavenging might leads to the fluctuated activity of210Pb and organic content in surface sediment, which occurred due to high particle flux within the water column.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],29.857142857142854,0.03331060606060606,0.4696168831168831,1,0.06477732793522267,0.14979757085020243,0.41422594142259417
323,331,331,A review on flood modelling tools for transformation of spatial and non-spatial data to 3d geo visualization,"Flood is a natural disaster caused directly by excessive amount of rain water, or indirectly by the global warming. Flood information can be disseminated using visual media such as 3D flood modelling. This study uses qualitative methods to review frequently used computer tools in 3D flood modelling. Currently, the generated 3D geovisualization results produced by the 3D modelling tools are lacking in terms of their aesthetics value. The purpose of this study is to analyse and select effective 3D geovisualization tools that could be merged with multimedia tools to create better aesthetics images. This study can offer insights into creating future 3D geovisualization based on spatial and non-spatial data that are more realistic and rich with aesthetics value. The analysis was conducted using SWOT analysis in order to find out strengths, weaknesses, opportunities and threats of each tools. Result shows that some commonly used 3D geovisualization tools such as ArcGIS and FME can be combined with multimedia tools such as 3ds Max and Blender to create 3D geovisualsization for flood modelling with applied aesthetics value.",60069394,Lembaga Ilmu Pengetahuan Indonesia,Jakarta,Indonesia,['1700'],21.875,0.11197916666666667,0.4442708333333333,1,0.14285714285714285,0.037037037037037035,0.37433155080213903
324,332,332,"Privacy preserving data mining: Approaches, applications and research directions","Large amount of data is generated nowadays from different fields and domains such as healthcare, retail, finance, social media etc. Data mining is used to extract and discover information or knowledge from this data. Important results can be obtained through mining process but it can lead to disclosure of sensitive data which has to be protected. Mining which allows useful knowledge to be discovered while preserving the privacy of an individual is Privacy Preserving Data Mining (PPDM). In this paper, role and scheme of Privacy Preserving Data mining is discussed with the help of different approaches to it. Application domains in which privacy is necessary are surveyed. Also, existing techniques of PPDM given by different authors are presented. Research findings are described in conclusion part of the paper to guide further research in this area.",60000690,Punjabi University,Patiala,India,['1700'],16.875,0.08730158730158731,0.5496031746031745,1,0.12666666666666668,0.04666666666666667,0.35333333333333333
325,333,333,Vision based gesture recognition from rgb video frames using morphological image processing techniques,"with the large number of population in all over the world nowadays, novel human computer interaction systems and techniques can be used to help improve our way of life. A vision based gesture recognition technology can help to maintain the safety and needs of the disable as well as others. Gesture recognition from video frames is a challenging task due to the high changeability in the features of each gesture with respect to different person. In this work, we propose a vision-based hand gesture recognition algorithm where the image frames are from RGB video data. Gesture-based systems are more natural, spontaneous, and straightforward. Previous works attempted to recognize hand gesture for different kind of scenarios. According to our studies, gesture recognition system can be based on wearable sensor or it can be vision based. Our proposed method is applied on a vision based gesture recognition system. In our proposed system image acquisition starts from RGB videos capture using Kinect sensor. We convert the image frames one after another from videos to blur for background noise removal. Then, we convert the images of a whole video into HSV color mode. After that, we do the dilation, erosion, filtering, and thresholding operations on the images. We use these morphological image processing techniques for converting the images to black and white format. Finally, using the prominent classification algorithm SVM we recognize the hand gestures with a higher accuracy 91.01 percent compared to the state of the art. In conclusion, the proposed algorithm aims to create a better vision-based hand gesture recognition system with a unique solution in this domain.",60012005,Multimedia University,Malacca Town,Malaysia,['1700'],17.733333333333334,0.21028344671201815,0.5580272108843538,1,0.12709030100334448,0.020066889632107024,0.26621160409556316
326,334,334,Refusal strategies in english used by malay and chinese undergraduates,"Exchanges and encounters among people of different cultures have increased rapidly since the last decade due to factors such as globalization, tourism and academic exchanges. Such encounters are obvious especially in multi-cultural societies where the population is made up of different ethnic groups, like Malaysia. A refusal is a negative response to an offer, request, invitation and suggestion. Refusals are important because they take a central place in everyday communication. It is difficult to reject requests. It is even harder to refuse in a foreign language, where one risks offending the interlocutor. This study aimed to identify refusal strategies used by Malay and Chinese undergraduates towards a person of higher and equal status. The research used qualitative and quantitative approach as a research design. 10 Malay undergraduates and 10 Chinese undergraduates of engineering students from University Technical Malaysia Melaka participated in this study. Based on the refusal taxonomy adapted and adopted by Beebe et al. (1990), five situations on refusals to request and suggestion were analyzed. The usage of Indirect-Statement of Regret (IR) is only evident for interlocutor with higher power. They normally continue with indirect refusal, while Adjuncts-Pause Filler (APF), Indirect Attempt to dissuade the interlocutor (IDI) and Indirect-Provides Rhetorical Question (IRQ) are meant for interlocutor of equal power. This study is important in revealing how Malaysian students, especially Chinese and Malay uses English as their second language to refuse and add more insight the pragmatics research area of refusal strategies.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],17.285714285714285,0.02741935483870968,0.40376344086021504,1,0.0812720848056537,0.08833922261484099,0.33454545454545453
327,335,335,D2MM-CNN: Difference depth motion map and convolutional neural networks for human action recognition,"Human Action Recognition has become the most significant research area for several applications like robotics, healthcare, gaming, smart houses, etc. However, in computer vision, action recognition from videos is one of the most challenging issues, due to some extraneous aspects like Occlusions, backgrounds, noises and so on. One solution to overcome the above-mentioned problems is acquiring only motion and shape cues form depth action video sequences. With this objective, in this paper, a new action representation approach is proposed based on Depth Motion Map (DMM), called as Difference Depth Motion Map (D2MM). Next, a well-designed CNN is trained especially to extract the features from two actions with a similar structure. The CNN model introduced in this paper involves five convolutional layers, three pooling layers, and one fully connected layer. The experimental results of the proposed method are compared with conventional methods on the publicly available dataset, MSR Action 3D. The comparative analysis proves that the proposed approach outperforms the state-of-art techniques.",60021891,Jawaharlal Nehru Technological University Hyderabad,Hyderabad,India,['1700'],20.125,0.14164313946922644,0.3741106719367589,1,0.09693877551020408,0.08673469387755102,0.4603174603174603
328,336,336,The role of the law on electronic information and transactions in overcoming challenges of democracy in Indonesia,"Democracy is idealized as a government system that provides space for citizens to be freely involved in the governance process. This space can be in the form of freedom of opinion and expression. However, the concept of freedom found in democracy often gives birth to a number of issues and paradoxes that have the potential to threaten the sustainability of democracy itself, such as the potential for the emergence of social conflict, social disintegration, segregation politics, and negative excesses as the result of the strong identity politics. The presence of the Law on Electronic Information and Transactions (EIT Law) has a strategic role in safeguarding the future and to face challenges of democracy in Indonesia by applying restrictions to the concept of freedom. This is in line with efforts to realize the principle of democratize rechstaat (democracy within the state of law) that seeks to implement democracy on the social order for the citizens. This article focuses on the analysis of the role of Law No.11 of 2008 concerning Electronic Information and Transactions as one of the legal instruments that strives for the realization of social order in the implementation of democracy to minimize the emergence of democratic paradoxes by analyzing the application of the law as this paper’s research method. This article is expected to provide a new perspective on the importance of implementing the legal instrument in the form of EIT Law to realize the concept of democratize rechstaat in Indonesia.",60106037,Universitas Islam Negeri Syarif Hidayatullah Jakarta,Jakarta,Indonesia,['1700'],34.714285714285715,0.07353535353535354,0.4053030303030303,1,0.08461538461538462,0.046153846153846156,0.24521072796934865
329,337,337,Protecting iot based transmitted data security using tokenized multiple layered encryption techniques,"Now-a-days the development of Internet of Things (IoT) is increased rapidly in different applications. The created IoT consists of several connected devices which are used to transmit the information from one device to another device. During the data transmission process, security and privacy is one of the serious issues. The security issue creating more vulnerabilities and difficulties while accessing the data. There are several traditional techniques are used to manage the data security but they are failing to maintain the information. Most of the information is maintained by creating the password which used for long time that also creating the security problem. So, in this system uses the tokenized multiple layered encryption technique to creating the security to transmitted information. The created system uses the three layer of encryption technique along with tokenized process, which successfully ensures the protection to data in every layer. In addition to this, each layer uses the specific encryption technique, which creates the difficulties while guessing key value. This created IoT based secure data transmission process efficiency is evaluated using experimental results.",122229462,Faculty of Information and Communication Technology,Malacca,Malaysia,['1700'],17.7,0.13333333333333333,0.4636904761904762,1,0.14646464646464646,0.010101010101010102,0.29896907216494845
330,339,339,Predictive modeling for bank direct marketing: A SEM based approach on select attributes,"Banking is a critical for the development of any economy. The banking sector is also the subject of several studies especially those related with data mining and predictive analytics. This study is based on a predictive structural model and uses select parameters (behavioral and demographics) extracted from the classic bank marketing dataset available in the UCI depository. The study assesses the relationship among age, bank balance and call duration. The mediation effect of bank balance is also assessed within the relationship between age and call duration. Marital status and education levels have been included to check their moderation effect on the proposed model.",60113205,"Chitkara University, Punjab",Rajpura,India,['1700'],17.166666666666668,0.05714285714285715,0.4428571428571428,1,0.09821428571428571,0.008928571428571428,0.1875
331,340,340,Improvement of deep cross-modal retrieval system through semantic preserving binary hash code generation,"The amount of data which is semantically consistent with distinct statistical properties is called multi-modal data and combine them in one space is crucial task. In addition, to retrieve information of interest based on need and demand from multi-modal data is one of the open research challenge which gives birth to cross-modal retrieval. In this paper, various approaches for cross-modal retrieval is discussed where hashing is used for faster retrieval. But there is no dependency between feature generation and hash code generation which degrades the performance of the system. So to make retrieval process efficient, deep networks are used to generate features as well as hash code. In this paper, such deep based cross-modal retrieval methods are discussed. But existing deep based cross-modal system has used bag-of-word (BoW) model to map words into vector which is sparse in nature and does not preserve the semantic similarity between words. To resolve this problem, a predictive based model called word2vec is used. In addition, existing work has assumed that the generated binary code for each modality has the equal length but it is not always possible. So cosine similarity is used which normalize vectors. In this paper, experiment is performed on improved deep cross-modal retrieval (IDCMR) using MIRFLICKR-25K, NUS-WIDE-10k and XMediaNet dataset which contains image and text modality. This result is compared with state-of-the-art methods which proves that there is an improvement in image query → text database and vice versa.",60110157,Chandubhai S Patel Institute of Technology,Changa,India,['1700'],19.916666666666668,0.06538461538461539,0.4538461538461539,1,0.1103448275862069,0.027586206896551724,0.311787072243346
332,341,341,On sequences of diophantine 3-tuples generated through euler polynomials," All rights reserved.This paper deals with the study of constructing sequences of diophantine triples (a, b, c) such that the product of any two elements of the set added by a polynomial with integer coefficient is a perfect square.",122274087,Shrimati Indira Gandhi College,Tiruchirappalli,India,['1700'],40.0,0.5,0.75,0,0.0851063829787234,0.0,0.3181818181818182
333,342,342,NOx reduction of CI engine operated with flaxseed oil biodiesel emulsions with water,"The objective of this research is to reduce NOx emissions from engines operated with flaxseed oil biodiesel by emulsifying it with water. The percentage of water in pure flaxseed oil biodiesel was varied from 0%, 5% and 10% respectively with the help of surfactants tween 80 and span 80. The performance and emission results were then compared with standard diesel fuel. It was observed that the NOx emissions were reduced for all emulsions of flaxseed oil biodiesel and were lowest with 10% water concentration. HC, CO emissions and BTE were better for fuel emulsions. However, the BSFC increases as the concentration of water was increased in the fuel emulsion and was found to be maximum for 10% water emulsion. The temperature of exhaust gases was reduced when water content was increased in the fuel. Hence, it is concluded that emulsification of flaxseed oil biodiesel is beneficial for using it as a substitute fuel in CI engines.",60021318,Maulana Azad National Institute of Technology,Bhopal,India,['1700'],19.5,0.14285714285714285,0.24,1,0.08670520231213873,0.046242774566473986,0.3352601156069364
334,343,343,Analyzing the linkedin content and its effect on organizational successof start-ups,The businesses are transforming with the constantly changing technology and the customers preferences and specifications irrespective of B2B or B2C transactions. One of the vitalplatform is Linkedin in the current scenario which is used by numerous companies to promote their business and services whichcomprises early stage startups to very large organizations. There are convincedindications of successful social media marketing strategies across the world from the available literature. Here is a necessity to personalize the Content marketing strategy for each organization depending on the nature and commercial transactions followed by their business.The study was directed to find out the usage of Linkedn by the start-ups as a social network. It also gives us the ways and means of managing online practices and identification of various factors influencing the audience.,60105126,Dayananda Sagar University,Bengaluru,India,['1700'],25.6,0.14502164502164505,0.3703463203463204,1,0.0948905109489051,0.021897810218978103,0.2932330827067669
335,344,344,"Design of sensing device for detection of disease in bovine, avian and caprine","A low cost hand-held ZnO based sensing device has been successfully designed for testing blood serum of bovine (cow), avian (poultry) and caprine (goat) to diagnose their health of liver and kidney by detecting four biological parameters in-situ. Nanostructured Zinc oxide (ZnO) solution is synthesized using the chemical bath deposition method. Using transmission electron microscopy (TEM) and X-ray diffraction (XRD), the size of ZnO nanoparticles were determined. It shows a hexagonal wurtzite structure with an orientation along the direction (101).The size of ZnO nanoparticle is 0.004nm as obtained from XRD. ZnO based sensing device is designed with the help of Arduino and Microsoft visual basic 6.0 version software. The resistance of blood serum is taken into consideration for carrying out the experiment. It has been measured after adding (1µl) ZnO to (1ml) of blood serum to detect four biological parameters – Serum glutamate pyruvate transaminase (SGPT), Serum glutamic-oxaloacetic transaminase (SGOT), Blood urea nitrogen (BUN) and creatinine of bovine, avian and caprine more precisely. The device can indicate whether the blood serum of bovine, avian and caprine have normal/diseased parameters. This device will also help the veterinarians in the field.",60016850,Gauhati University,Guwahati,India,['1700'],21.0,0.18958333333333333,0.3552083333333333,1,0.1134453781512605,0.07563025210084033,0.4104803493449782
336,346,346,Smart drill load balancing protocol: Wise exploration and reacting,"Load balancing at data centers is an active research area. The literature contains various load balancing protocols. DRILL is one recognized load balancing algorithm. DRILL is inspired by concept of “the power of two choices” through enabling forwarding packets based on two factors: past experience through selecting least loaded ports and exploring new choices through random selection of new ports. This article proposes a newer variant of DRILL named smart DRILL or SDRILL. It balances between relying on the last ports or exploring new ports through using the buffer status as indicator to the need of exploring more new ports. Also, SDRILL reacts faster when the congestion is increasing and slower when the congestion is not increasing highly. Experimental results show that SDRILL was superior in terms of flow completion time for the most used flows in datacenters: data mining and web-search while it was in the average for general flows. Also, SDRILL was superior in terms of both tail latency and throughput.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],18.11111111111111,0.1098003848003848,0.4932058682058682,1,0.1,0.044444444444444446,0.33146067415730335
337,348,348,An advanced keyword attacks over encrypted data in cloud,"Exploration of encipher is currently developing enthusiasm for assure the information aloofness in defended hunt cloud storage. Safety of cryptographic natives, ie, the public key encryption with key-word are search (PEKS) this is quite treasured in severe applications the allocated storage. Shockingly, it's far been examined that conventional PEKS gadget revel in the ill effects of frailty characteristic in the meant keyword guessing attack (KGA) end up propelled with the aid of manner of a pernicious server. To cope with this protection helplessness, the nowadays named skeleton PEKS dual-server PEKS (DS-PEKS). As a few other sizeable self-discipline, some special version of the easy projective hash capabilities (SPHFs) referred to as linear and homomorphic SPHF (LH-SPHF). To reveal the conventional relaxed development DS-PEKS of LH-SPHF. To delineate the achievability of the state-of-the-art tool, giving efficient release of the general form of preference Diffie-Hellman based completely truely LH-SPHF and display that it could accomplish strong protection from the KGA.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],22.428571428571423,0.036428571428571435,0.5607142857142856,1,0.07804878048780488,0.1024390243902439,0.3425414364640884
338,349,349,I/o performance analysis of enterprise server using flash-based ssds,"Background/Objectives: Recently, enterprise computing environments require high performance storage to provide various services. For this reason, we analyze the performance of server storage used by enterprises. Methods/Statistical analysis: HDD and SDD were used for the experiments to analyze the performance of the enterprise storage server. In addition, performance was analyzed by applying RAID technology used in storage server. We used a validated benchmark program to analyze the exact performance of the experiment. Findings: Experimental results show that the performance of RAID configuration using SSD is about 5 times better than RAID server which is composed of HDD in read / write. This result means that the performance of SSD-based RAID is higher than that of existing HDD-based RAID when a storage server is applied to servers providing various services recently. In addition, when SSD is added to a RAID server configured as an existing HDD, the read performance rises about 4 to 5 times like a RAID configured as an SSD. Based on these results, SSDs can be cached on the primary storage server to improve performance at the lowest cost of servers with many read I/Os. Finally, RAID systems that consist solely of SSDs can be guaranteed to use the latest RAID controllers that support SSDs. Improvements/Applications: Based on the experimental results, there is a lot of performance improvement when applying SSD-only RAID storage to a server with a lot of read/write.",60027090,Virginia Polytechnic Institute and State University,Blacksburg,United States,['1700'],21.181818181818183,0.19714285714285715,0.4992857142857143,1,0.15073529411764705,0.06985294117647059,0.36328125
339,350,350,Hybrid CPU–GPU execution support in the skeleton programming framework SkePU,"In this paper, we present a hybrid execution backend for the skeleton programming framework SkePU. The backend is capable of automatically dividing the workload and simultaneously executing the computation on a multi-core CPU and any number of accelerators, such as GPUs. We show how to efficiently partition the workload of skeletons such as Map, MapReduce, and Scan to allow hybrid execution on heterogeneous computer systems. We also show a unified way of predicting how the workload should be partitioned based on performance modeling. With experiments on typical skeleton instances, we show the speedup for all skeletons when using the new hybrid backend. We also evaluate the performance on some real-world applications. Finally, we show that the new implementation gives higher and more reliable performance compared to an old hybrid execution implementation based on dynamic scheduling.",60009358,Linköpings universitet,Linkoping,Sweden,"['1712', '1710', '1708']",19.285714285714285,0.09633838383838383,0.4313131313131313,1,0.11842105263157894,0.03289473684210526,0.32432432432432434
340,351,351,Otranto treasures in 3D,"Otranto is an Italian city located on the Adriatic coast of the Salento peninsula, on the easternmost stretch of Italy. Always considered one of the pearls of the Mediterranean, Otranto exudes a timeless charm, with its countless historical, artistic and naturalistic beauties. ""Otranto Treasures in 3D"" is a video-documentary that tells the millennial charm of Otranto's, landscape, culture and nature through video footage and 3D reconstructions. The video allows a guided virtual tour of the wonders of Otranto, to discover this ancient town, to know and admire its churches and its splendid monuments and some ancient settlements and archaeological sites of remarkable relevance, such as the Grotta dei Cervi in Porto Badisco, and to dive into a crystal blue sea, a realm of enchanting habitats rich in biodiversity and spectacular backdrops.",60024353,Universita del Salento,Lecce,Italy,"['1710', '1706', '1705']",32.75,0.2743055555555556,0.5083333333333333,1,0.06622516556291391,0.09271523178807947,0.348993288590604
341,352,352,Lighting design for monumental complex: A case study,"8As part of the restoration of the Neptune Fountain in Bologna, research was carried out, and certain design proposals were formulated which offer food for thought and give new light to the monumental complex within the context in which it is located, in the system of squares Maggiore and Neptune. The activity was divided into two distinct phases, the first was concerned with surveying the current state of lighting of the fountain and the adjacent spaces; the second focused on drafting proposals for a new lighting system, based on new LED technologies, of the fountain of Neptune and the areas immediately surrounding which was presented by means of synthetic images derived from the digital reconstruction of the site. This article presents the working method applied and the results achieved.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1710', '1706', '1705']",43.0,0.11576151121605666,0.3698543880362062,1,0.1223021582733813,0.050359712230215826,0.2158273381294964
342,353,353,Limitations of difference-in-difference for measuring convergence," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.Linguistic convergence is the phenomenon in which interlocutors' speech characteristics become more similar to each other's. One of the methods frequently used to measure convergence is the difference-in-difference (DID) approach, comparing change in absolute distance between a subject and an interlocutor or model talker. We show that this approach is not a reliable measure of convergence when the starting values of the subject and the interlocutor or model talker are close, which can result in the measurement of apparent divergence, while extreme starting points can result in overestimation of convergence. These biases are of particular concern in studies that look for individual differences in convergence. We propose an alternative approach, linear combination, which does not have the same biases, and demonstrate the advantages of this method using data from convergence studies of four linguistic characteristics and simulated data.",60011460,Brown University,Providence,United States,['1706'],29.5,0.07824074074074075,0.41111111111111104,0,0.10144927536231885,0.033816425120772944,0.3
343,354,354,Exploring the subconscious decision making in neuromarketing research using eye tracking technique,"This manuscript investigates the relationship of the effects and cognitive consumer purchase behaviors when making decisions. The study of consumer purchase behavior, which is known today as Neuromarketing, is one of the emerging multidisciplinary fields that link studies such as psychology, cognitive science, business planning, marketing and electronics systems. In contrast, traditional marketing business only based consumers' responses on surveys with no direct quantification of their behavior. Hence, the study objectively focused on tracking the gazing behavior to measure and analyze its correlation to the behavior of the mind. We further investigate to determine the subconscious of consumer behavior in decision making and their purchasing process. In this experiment, the Tobii TX300 eye tracker was used to track and record the eye gaze. Sixteen mentally and physically healthy participants took part in this experiment. Men and women clothes collections from online shopping were chosen as the stimuli. The gaze behavior of each individual was observed and analyzed. A post experiment questionnaire was given to the participants to confirm their subconscious' decision. The results showed that the gazing behavior of participants were significantly and subconsciously influenced by the bold, highlighted, and big elements of each stimulus. Hence, most of the respondents have their own decision when purchasing a product which does not depend on the amount of their eyefixation on a product.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",18.416666666666668,0.12696078431372548,0.5377450980392157,1,0.11788617886178862,0.012195121951219513,0.27235772357723576
344,355,355,A process capability index for normal random variable with intuitionistic fuzzy information,"In this study, a process control criterion was extended based on intuitionistic fuzzy information in cases where the underlying population is normal with intuitionistic fuzzy mean and exact variance. The proposed process control criterion was constructed based on the arithmetic operations and a common distance measure in the space of intuitionistic fuzzy numbers. For this purpose, one of the most popular process capability indices and its corresponding estimator were extended based on intuitionistic fuzzy specific limits and intuitionistic fuzzy target when the intuitionistic fuzzy mean and/or variance are unknown. A criterion was also proposed to investigate the level of process condition. The effectiveness of the proposed method was also examined by a practical example.",60030265,University of Birjand,Birjand,Iran,['1703'],22.8,0.052777777777777785,0.5444444444444444,1,0.09917355371900827,0.0,0.1487603305785124
345,356,356,Predictive controller with Kalman filter for Intelligence Pneumatic Actuator (IPA),"This paper discusses and analyzes the performances of an Intelligence Pneumatic Actuator (IPA) positioning system using Predictive Functional Controller (PFC) with Kalman filter Design. The uncertainties in the pneumatic system are undesirable. Kalman filter is useful in vast areas due to the prediction assets. The system models are designed based on previous research on the predictive controller and focused on position tracking. The transfer function for the pneumatic actuator is obtained by using system identification (SI) techniques. The initial covariance values of the Kalman filter system are determined according to the plant system. The performances of the proposed system are performed in MATLAB, Simulink and validated with IPA plant. The validation process of the IPA plant is run through real-time experiments using National Instrument (NI) devices. The Result showed the system is stable with Kalman filter is new implementation on both simulations and experiment process.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",16.11111111111111,0.024116161616161612,0.3327020202020202,1,0.10909090909090909,0.12121212121212122,0.3987730061349693
346,357,357,A multiscale method for data assimilation,"In data assimilation problems, various types of data are naturally linked to different spatial resolutions (e.g., seismic and electromagnetic data), and these scales are usually not coincident to the subsurface simulation model scale. Alternatives like upscaling/downscaling of the data and/or the simulation model can be used, but with potential loss of important information. Such alternatives introduce additional uncertainties which are not in the nature of the problem description, but the result of the post processing of the data or the geo-model. To address this issue, a novel multiscale (MS) data assimilation method is introduced. The overall idea of the method is to keep uncertain parameters and observed data at their original representation scale, avoiding upscaling/downscaling of any quantity. The method relies on a recently developed mathematical framework to compute adjoint gradients via a MS strategy in an algebraic framework. The fine-scale uncertain parameters are directly updated and the MS grid is constructed in a resolution that meets the observed data resolution. This formulation therefore enables a consistent assimilation of data represented at a coarser scale than the simulation model. The misfit objective function is constructed to keep the MS nature of the problem. The regularization term is represented at the simulation model (fine) scale, whereas the data misfit term is represented at the observed data (coarse) scale. The computational aspects of the method are investigated in a simple synthetic model, including an elaborate uncertainty quantification step, and compared to upscaling/downscaling strategies. The experiment shows that the MS strategy provides several potential advantages compared to more traditional scale conciliation strategies: (1) expensive operations are only performed at the coarse scale; (2) the matched uncertain parameter distribution is closer to the “truth”; (3) faster convergence behavior occurs due to faster gradient computation; and (4) better uncertainty quantification results are obtained. The proof-of-concept example considered in this paper sheds new lights on how one can reduce uncertainty within fine-scale geo-model parameters with coarse-scale data, without the necessity of upscaling/downscaling the data nor the geo-model. The developments demonstrate how to consistently formulate such a gradient-based MS data assimilation strategy in an algebraic framework which allows for implementation in available computational platforms.",60118023,"Department of Geoscience &amp; Engineering, TU Delft",Delft,Netherlands,"['1706', '1703']",25.5,0.08681344696969698,0.5105215097402597,1,0.1,0.018604651162790697,0.3069306930693069
347,358,358,Connect resound: Using online technology to deliver music education to remote communities,"This article describes an action research project that aimed to widen participation for music education in schools in England (United Kingdom). The Connect Resound project involved a pilot stage in North Yorkshire (England, United Kingdom) followed by a roll-out to four further geographical regions of England: Cumbria; Durham/Darlington; East Riding of Yorkshire; and Cornwall. The project involved testing a technological framework created to bring music education to schools with little or no music instrumental lessons within primary schools at key stage 2 (pupils aged 7–11 years). The pilot and roll-out phases refined the approach and established a business case for a grant to roll out the project nationally in 2017. The approach used in the study provided not only the instrumental lessons but also continuing professional development for teachers, on-demand technical support, and access to music performances and masterclasses. The research team designed and tested several scenarios for using technology in this environment some of which were using single cameras and others that used a multi-camera set-up. One of the approaches used technology to allow the teachers and pupils access to different camera angles and high-quality audio to deliver the lessons which proved beneficial. The project team captured both video data as well as interviews and questionnaires with participants in order to better understand and refine the approach developed. This article reports upon the challenges and opportunities provided by the project in terms of the technology and environment, an evaluation using a case study approach of how the teachers used the technology, and feedback in the form of questionnaires from pupils and parents/carers concerning the lessons. Issues around the technology concerned time lag, initial technical problems, and background noise in the teaching environment amplified by the technology. The different camera angles adopted in the project proved valuable for teachers, potential issues with assembling and tuning instruments were considered, and beginner technique could be demonstrated using this approach.",60030469,University of Hull,Hull,United Kingdom,['1706'],28.818181818181817,0.046726190476190484,0.41746031746031736,1,0.12121212121212122,0.049586776859504134,0.3112391930835735
348,359,359,Templaticity effects on differential processing of consonants and vowels," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.The aim of this study is to investigate the role of morphophonology and written representations in speech processing. Results are presented from an immediate serial recall (ISR) study, designed to determine the relative effects of L1 morphology and orthography on the recall of consonants versus vowels. Forty-five speakers of English, Amharic, and Arabic completed an ISR experiment testing the differential recall of these two segment types. English speakers remembered sequences of syllables in which the consonant is held constant and the vowel changes (e.g., “ma mi mu …”) better than sequences in which the vowel is held constant and the consonant changes (e.g., “ka ma za …”), whereas Arabic speakers remembered both types of sequences equally well, replicating findings from Kissling (2012). Crucially, Amharic speakers in this study performed similarly to Arabic speakers, remembering both sequence types with equal accuracy. Given that Amharic and Arabic share a templatic morphological system, this new result suggests that the morphophonology of a listener's L1 impacts ISR. English and Amharic share similar orthographic systems; the mean accuracies of English and Amharic speakers were significantly different, and it therefore appears that orthography of the L1 does not affect recall accuracy. The results have implications for the role of the morphophonology of a given speaker's L1 in ISR and in speech processing more generally.",60023927,Georgetown University,"Washington, D.C.",United States,['1706'],28.555555555555557,0.08327922077922077,0.3789862914862915,0,0.08881578947368421,0.10855263157894737,0.4080267558528428
349,360,360,Adoption of halal standard in Malaysian food industry: A case of small and medium enterprises,"The Halal industry has now expanded well beyond the food sector, further widening the economic potentials for Halal products. However, most of the SMEs are still reluctant to apply Halal standard (HS) and not seriously picture significance the power of Halal to gain competitive in the market. Thus, the aim of this study is to identify and analyse the adoption factors that motivate food manufacturers to adopt HS. A total 183 food manufactures certified by Halal take the survey of the study. The survey data were recorded using 5-points questionnaire. By conducting exploratory factor analysis, the findings yield that compatibility and perceived benefits are two factors grouped by technological factor. Halal integrity, Halal awareness, top management support, expected business benefits, understanding the practices and organisation readiness are six factors grouped by organisational factor. Lastly, Halal market demand, consumer pressure, competitive pressure and government support are four factors grouped by environmental factors. The paper includes implications for the halal food industry, whereby the adoption of HS will contribute to the business benefits to create a more competitive advantage to the industry.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",20.0,0.17666666666666667,0.4083333333333334,1,0.11822660098522167,0.04926108374384237,0.3251231527093596
350,361,361,Thermal and mechanical behaviour of recycled polypropylene/polyethylene blends of rejected-unused disposable diapers,"This paper presents the characterization of recycled plastic that derived from the rejected-unused disposable diapers containing polypropylene (PP) and polyethylene (PE), noted as r-PP/PE. The blends were tested for thermal, mechanical and morphological properties. Tensile test showed that the r-PP/PE is lower in strength and strain but higher for modulus in comparison to the v-PP/PE by 56%, 55%, and 2% respectively. For the flexural properties, the r-PP/PE also has lower in strength, strain, and modulus as 67%, 13%, and 77% respectively. Lower absorbed energy and impact strength was observed in r-PP/PE, 36% and 24% respectively compared to v-PP/PE. Thermal analysis revealed that the degree of crystallinity of recycled PP and PE was 19% and 20% lower than the virgin possibly due to thermal degradation during the process. Morphological examination revealed the present of impurity, phase separations and inhomogeneity were found in the r-PP/PE as compared to v-PP/PE that might contribute to their lower strength.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",22.0,0.06071428571428573,0.29642857142857143,1,0.09090909090909091,0.1318181818181818,0.4032258064516129
351,362,362,Transforming powerlist-based divide-and-conquer programs for an improved execution model,"Powerlists are data structures that can be successfully used for defining parallel programs based on divide-and-conquer paradigm. These parallel recursive data structures and their algebraic theories offer both a methodology to design parallel algorithms and parallel programming abstractions to ease the development of parallel applications. The paper presents a technique for speeding up the parallel recursive programs defined based on powerlists. The improvements are achieved by applying transformation rules that introduce tuple functions and prefix operators, for which a more efficient execution model is defined. Together with the execution model, a cost model is also defined in order to allow a proper evaluation. The treated examples emphasise the fact that the transformation leads to important improvements of the programs. The speeding up is achieved by reducing the number of recursive calls, and also by enable the fusion of splitting/combining operations on different data structures. In addition, enhancing the function that has to be computed to other useful functions using a tuple, could improved the cost reduction even more.",60024417,Universitatea Babes-Bolyai din Cluj-Napoca,Cluj Napoca,Romania,"['1712', '1710', '1708']",21.0,0.1660714285714286,0.28750000000000003,1,0.15508021390374332,0.0,0.30386740331491713
352,363,363,The Social Pragmatics of Communication with Social Robots: Effects of Robot Message Design Logic in a Regulative Context,"V.When social robots are used in communicative contexts, the norms, values, and expectations associated with the process of communication itself are important considerations. Message design logics (MDL) are working models of communication that lead to distinct ways of thinking about communication situations and reasoning from goals to messages. The three MDLs are expressive, conventional, and rhetorical. Respectively, they treat communication as a vehicle for the transmission of information, a game to be played cooperatively according to social norms, and the creation and negotiation of social selves and situations. In human communication, there is an observed preference for partners and messages that display the most sophisticated rhetorical MDL. The purpose of this study was to test/extend the theory of MDL and communication pragmatics in HRI. An online between-subjects experiment of 511 U.S. American adults was conducted to determine the effects of a social robot’s MDL and goal structure on people’s evaluations of the message and its source in a hypothetical regulative context, or a situation in which one individual is faced with the need to control or correct the behavior of another. Results demonstrated that rhetorical message designs led to the most positive impressions of the robot in terms of predicted communication success, goal-relevant attributes (ability to motivate and provide face support), competence, credibility, and attractiveness. Findings mirror results in earlier studies of human communication establishing an MDL sophistication advantage in communication dilemmas. Analysis of qualitative responses showed that participants understood the robot’s overall communication pragmatic differently on the basis of the MDL it demonstrated.",60001439,Pennsylvania State University,University Park,United States,['1700'],23.09090909090909,0.14171585989767807,0.3486029122392758,1,0.09278350515463918,0.030927835051546393,0.3125
353,364,364,Epenthetic vowel production of unfamiliar medial consonant clusters by Japanese speakers," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.Existing nativized loanword studies have traditionally suggested that there are three epenthetic vowels in Japanese, which reflect both phonotactic restrictions and articulatory properties of certain consonant-vowel sequences in the language. Recent findings, however, call this tri-partite epenthesis pattern into question: First, several studies suggest that this epenthesis pattern is not true in the realm of perception and is not completely regular in production, and second, the relevant phonotactic restrictions seem to be weakening even outside of epenthesis contexts. This paper therefore investigates the extent to which the spontaneous choice of epenthetic vowels in the production of Japanese conforms to the traditional tri-partite pattern. Epenthesis was induced by presenting pseudo-word stimuli of the form of [aCCa] (C = a voiced consonant) to subjects orthographically. The findings suggest that indeed, the production pattern does not fully conform to what is generally reported for nativized loanwords; in particular, the traditionally “default” vowel [M] is used by our participants frequently in all contexts, including the two where [o] or [i] is usually reported. That said, we also show that there is considerable variability across speakers as to which vowel is epenthesized, especially in the palatal context, and this variability includes tokens of vowels similar to all possible lexical vowels of Japanese.",60020585,University of Canterbury,Christchurch,New Zealand,['1706'],35.142857142857146,0.08633156966490299,0.4431488264821598,0,0.09090909090909091,0.04040404040404041,0.34615384615384615
354,366,366,Electroencephalography (EEG) application in neuromarketing-exploring the subconscious mind,"This article presents how the human brain makes a decision and the influence of subconscious mind when observing different brands in advertisement. The study of the human brain using EEG is related to electronics, psychology, and cognitive neuroscience to study the human behavior on problem solving and decision making. In this paper, we particularly investigate the decision making of the human brain in a short period of time. The study is focused on which band wave is dominant when use for decision making and subconscious mind. The EEG was used to study the cognition in different states of mind because EEG can analyze the brain activity directly from the scalp. Experiments were conducted to examine the wave of the brain by using the 14-channel EEG Emotiv Epoch device. The brain memory recalls and makes a decision of what they want or experience. The result shows that the human brain can recall a product by experience and beneficial to their understanding. This proves that subconscious mind and decision making has always been and existing in our daily lives. The result from the experiment showed that theta band wave was dominant during subconscious mind and decision making.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",19.5,0.03333333333333333,0.3137254901960784,1,0.12980769230769232,0.028846153846153848,0.20192307692307693
355,367,367,The role of vowel length and glottalization in German learners' perception of the English coda stop voicing contrast," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.In German, the voicing contrast in word-final stops is neutralized towards the voiceless sound. We tested how German learners of English use in perception two phonetic cues to this contrast in English: the duration of the vowel preceding the stop and the partial glottalization of this vowel. While a longer vowel cues the voiced sound of the contrast, glottalization enhances the voiceless sound, which should be 'easy' for learners as word-finally it is the default in German. We asked whether cueing the 'easy' sound would nevertheless affect learners' word identification. Learners categorized two English minimal pairs along vowel duration continua with either a fully modal vowel or the last 25% of the vowel glottalized. Learners gave more voiced-stop responses as vowel duration increased. They also used glottalization by giving fewer voiced-stop responses for the glottalized continua. A second experiment demonstrated that the glottalization was not merely perceived as a change in the vowel+closure duration ratio. When the glottalized portion of the vowels was set to silence learners gave even fewer voiced-stop responses than in the glottalized condition. Results suggest that learners can use a phonetic cue to a second language sound contrast even if it enhances the familiar 'easy' sound.",60028717,Ludwig-Maximilians-Universität München,Munich,Germany,['1706'],21.727272727272727,0.2115384615384616,0.3506410256410257,0,0.1347517730496454,0.0425531914893617,0.35714285714285715
356,368,368,Global/local model order reduction in coupled flow and linear thermal-poroelasticity,"Coupled flow and geomechanics computations are very complex and require solving large nonlinear systems. Such simulations are intense from both runtime and memory standpoint, which strongly hints at employing model order reduction (MOR) techniques to speed them up. Different types of Reduced-Order Models (ROM) have been proposed to alleviate this computational burden. MOR approaches rely on projection operators to decrease the dimensionality of the problem. We first execute a computationally expensive “offline” stage, during which we carefully study the full order model (FOM). Upon creating a ROM basis, we then perform the cheap “online” stage. Our reduction strategy estimates a ROM using proper orthogonal decomposition (POD). We determine a family of solutions to the problem, for a suitable sample of input conditions, where every single realization is so-called a “snapshot.” We then ensemble all snapshots to determine a compressed subspace that spans the solution. Usually, POD employs a fixed reduced subspace of global basis vectors. The usage of a global basis is not convenient to tackle problems characterized by different physical regimes, parameter changes, or high-frequency features. Having many snapshots to capture all these variations is unfeasible, which suggests seeking adaptive approaches based on the closest regional basis. We thus develop such a strategy based on local POD basis to reduce one-way coupled flow and geomechanics computations. We partition the time window to adequately capture regimes such as depletion/build-up and decreasing the number of snapshots per basis. We focus on linear elasticity and consider factors such as the role of the heterogeneity. We also assess how to tackle different degrees of freedom, such as the displacements (intercalated and coupled), pressure, and temperature, with MOR. Preliminary 2- and 3-D results show significant compression ratios up to 99.9% for the mechanics part. We formally compare FOM and ROM and provide time data to demonstrate the speedup of the procedure. Examples focus on linear and nonlinear poroelasticity. We employ continuous Galerkin finite elements for all of the discretizations.",60020547,Texas A&amp;M University,College Station,United States,"['1706', '1703']",17.105263157894736,0.08256978653530378,0.4700246305418718,1,0.1421188630490956,0.03359173126614987,0.3716577540106952
357,369,369,Load and Price Forecasting in Smart Grids Using Enhanced Support Vector Machine,"In this paper, an enhanced model for electricity load and price forecasting is proposed. This model consists of feature engineering and classification. Feature engineering consists of feature selection and extraction. For feature selection a hybrid feature selector is used which consists of Decision Tree (DT) and Recursive Feature Elimination (RFE) to remove redundancy. Furthermore, Singular Value Decomposition (SVD) is used for feature extraction to reduce the dimensionality of features. To forecast load and price, two classifiers Stochastic Gradient Descent (SGD) and Support Vector Machine (SVM) is used and for better accuracy an enhanced framework of SVM is proposed. Dataset is taken from NYISO and month wise forecasting is being conducted by proposed classifiers. To evaluate performance RMSE, MAPE, MAE, MSE is used.",60089631,COMSATS University Islamabad,Islamabad,Pakistan,"['1706', '1705', '1710']",15.25,0.6,0.7,1,0.11643835616438356,0.1643835616438356,0.4520547945205479
358,370,370,Tracking the eye-mind relationship of positive emotion using eye tracking technique,"This article presents an exploration and investigation of the eye movement features to track the eye-mind relationship through eye tracking device during video clips of positive emotional stimulation. The relationship of eyes gazing behavior with human mind is a challenging topic. Many parameters of the eyes gazing behavior is yet to be explored namely pupil size and pupil dilation. Since pupil size is one of the indicators of the brain's activity studies on eye-mind relationship can be beneficial and added value in learning human behavior. Prior studies have suggested that the cognitive processing and affective information affect the size of pupils in humans. Significantly, this study focus on the behavior of positive emotion by using eye tracking technique to observe the eye-mind relation. It is hypothesized from this observation that the visual attention of the gazing behavior will affect the pupil dilation and will further provide evidence of the human mind triggered emotion. Ten subjects' pupil responses were measured while watching interesting and amusing emotional clips. The results showed that the fixation duration and pupil dilation significantly different between each video stimulation. These results suggest that the measurement of eye fixation is a potential computer input for detecting emotional state.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",20.0,0.1541866028708134,0.490311004784689,1,0.1232876712328767,0.0045662100456621,0.22535211267605634
359,371,371,On the development of a relative permeability equation of state,"Standard compositional simulators use composition-dependent cubic equations of state (EoS), but saturation-dependent relative permeability and capillary pressure. This discrepancy causes discontinuities, increasing computational time and reducing accuracy. In addition, commonly used empirical correlations, such as the Corey relative permeability model, show a sole dependence of relative permeability on phase saturation, lumping the effect of other pore-scale phenomena into one tuning exponent. To rectify this problem, relative permeability has been recently defined as a state function, so that it becomes compositional dependent and single valued. Such a form of the relative permeability EoS can significantly improve the convergence in compositional simulation for both two- and three-phase flows. This paper revisits the recently developed EoS for relative permeability by defining relevant state variables and deriving functional forms of the partial derivatives in the state function. The state variables include phase saturation, phase connectivity, wettability index, capillary number, and pore topology. The developed EoS is constrained to key physical boundary conditions. The model coefficients are estimated through linear regression on data collected from a pore-scale simulation study that estimates relative permeability based on micro-CT image analysis. The results show that a simple quadratic expression with few calibration coefficients gives an excellent match to two-phase flow simulation measurements from the literature. The goodness of fit, represented by the coefficient of determination (R2) value, is 0.97 for relative permeability at variable phase saturation and phase connectivity, and constant wettability, pore structure, and capillary number (∼ 10− 4). The quadratic response for relative permeability also shows excellent predictive capabilities.",60001439,Pennsylvania State University,University Park,United States,"['1706', '1703']",21.08333333333333,0.08640552995391708,0.31282642089093704,1,0.09271523178807947,0.023178807947019868,0.2951388888888889
360,372,372,Database secure manipulation based on paillier's homomorphic encryption (DSM-PHE),"The objective of this research was to suggest some simple solution to increase database manipulation security. Based on advantage of Homomorphic encryption, user's data in database is always encrypted by Homomorphic encryption algorithm such as Paillier. User's data is manipulated or processed on many times such as addition, subtraction, multiplication and division. By the advantage of Homomorphic encryption algorithm, user's data will not be decrypted while manipulated. Therefore, secrecy of data is still kept. Unfortunately, Paillier's Homomorphic encryption normally covers only addition and multiplication operation on numerical data. This paper suggests simple technique to enhance Pailler's encryption algorithm to perform data operation as well in subtraction and division operation. Evaluation in suggested database manipulation, DSM-PHE, indicates that its operation tasks take five operation times more than ordinary data base manipulation operation tasks, without any encryption. Therefore DSM-PHE shall be especially used in more sensitive data.",60103462,King Mongkut's University of Technology North Bangkok,Bangkok,Thailand,"['1706', '1705']",16.11111111111111,0.01333333333333333,0.6242857142857143,1,0.11627906976744186,0.046511627906976744,0.32142857142857145
361,373,373,An effective approach to enhancing a focused crawler using Google,"In this paper, we share our experience in augmenting a focused crawler of our vertical search engine designed to work with academic slides. The goal of the focused crawler was to collect Microsoft PowerPoint files from academic institutions. A previous approach based on a general web crawler can fail to collect a sufficient number of files mainly because of the robots exclusion protocol and missing hyperlinks. As a remedy to these problems, we propose a combinatory approach in which the indexing information maintained by a general web search engine such as Google is utilized for target URL list generation through our query generator, further then complemented by our URL extractor and file downloader. Because Google has already crawled billions of web pages, it will be more cost-efficient and potentially effective to systematically retrieve the desired information from Google than to redo crawling from scratch by ourselves. Our focused crawler, which we call SlideCrawler, has been used for our vertical search engine CourseShare since the fall of 2011. The capability of SlideCrawler was verified for the top-500 world wide universities. SlideCrawler collected about one million files from the top-500 universities. Further, the study results show that SlideCrawler outperforms Nutch, collecting 3.7 times more slide files.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1710', '1708']",22.66666666666667,0.05999999999999999,0.37,1,0.1210762331838565,0.05829596412556054,0.3031674208144796
362,374,374,A DSL for graph parallel programming with vertex subsets,"The vertex-centric (VC) computation model has emerged as a promising approach for easy parallel programming and massive parallel execution for big graph processing. A simple graph computation can easily be implemented in the VC model, but some algorithms cannot easily be implemented in the VC model. Examples of the latter algorithms are those that use vertex subsets or subgraphs as a manipulation unit. Such a “global view style” is natural for programmers to design graph algorithms, but the VC model requires us to redesign algorithms in the “local view style” focusing on a vertex. The gap between these styles prevents us from writing parallel programs for useful graph computations. In this paper, we propose a novel DSL for graph processing that can be used to write parallel programs for big graph processing in the “global view style”. It is compiled into the VC model so that it can enjoy massive parallelism in various parallel computing environments including commercial cloud services like Amazon EC2. We show non-trivial examples in our DSL, and our experimental results show that the compiled program achieves good scalability.",60031838,Kyushu Institute of Technology,Kitakyushu,Japan,"['1712', '1710', '1708']",22.75,0.11923076923076925,0.3252747252747253,1,0.11594202898550725,0.03864734299516908,0.33004926108374383
363,375,375,Factors affecting user's intention to adopt smart home in Malaysia,"Nowadays, the advancement of technology makes life easier and convenient. The smart home is one of the technology provides a better living environment for the residents. The purpose of this study is to make a systematic and empirical study on the factors and model that influencing the intention to adopt smart home in Malaysia. Clear interface, consistency, attractiveness, information accuracy, information completeness, perceived security and perceived privacy used as the variables to investigate the intention to adopt the smart home. The quantitative method was used in this research. The sample size of this research is 102 respondents. The questionnaire was used for data collection. From the statistical analysis, the result verifies that clear interface, consistency, attractiveness, information accuracy, perceived security, and perceived privacy have positive impact on the Malaysia householder's intention to adopt the smart home. By referring to this, the practitioner can refer and focus on those variables to develop the smart home that suitable for Malaysian.",60000906,Universiti Sains Malaysia,Gelugor,Malaysia,"['1706', '1705']",17.555555555555557,0.2407910271546635,0.5342188114915388,1,0.11049723756906077,0.016574585635359115,0.2430939226519337
364,376,376,Work posture improvement at plastic printing process in plastic manufacturing industry,"Plastic printing workstations in the plastic manufacturing industry are still semi-automated exposing operators to various ergonomics risk factors. This study aims to redesign the existing plastic printing workstation for improving work posture to prevent the occurrence of workrelated musculoskeletal disorders (WMSD). The ergonomics risk factors faced by ten plastic printing workstation operators were assessed using workplace observation, questionnaire survey and Rapid Upper Limb Assessment (RULA). The results showed the operators were subjected to frequent bending posture which may cause WMSD on the back, shoulder, and legs. A new workstation design concept was constructed and finalized using the House of Quality (HOQ). This study concluded that the new design of the workstation has improved the RULA score from 7 to 3. Further investigation is recommended on the productivity and product quality analysis, and muscle activity of the operators in the future study.",60120897,President University,Bekasi,Indonesia,"['1712', '1708', '1705']",20.142857142857142,0.04141414141414141,0.2593434343434343,1,0.1375,0.075,0.41139240506329117
365,377,377,A research of Monte Carlo optimized neural network for electricity load forecast,"In this paper, we apply the Monte Carlo neural network (MCNN), a type of neural network optimized by Monte Carlo algorithm, to electricity load forecast. Meanwhile, deep MCNNs with one, two and three hidden layers are designed. Results have demonstrated that three-layer MCNN improves 70.35% accuracy for 7-week electricity load forecast, compared with traditional neural network. And five-layer MCNN improves 17.24% accuracy for 7-week forecast. This proves that MCNN has great potential in electricity load forecast.",60028265,Lanzhou University,Lanzhou,China,"['1712', '1710', '1708']",15.2,0.15555555555555556,0.5388888888888889,1,0.09473684210526316,0.06315789473684211,0.45054945054945056
366,378,378,The javanese letters classifier with mobile client-server architecture and convolution neural network method,"The rapid development of mobile technologies allows platform devices to perform sophisticated tasks, including character recognition. These identification systems are notable techniques that required high computation cost, in order to achieve acceptable accuracy resulting from diversity in alphabet shape and method of writing, especially for the non-Latin alphabet, e.g., Javanese letter. In addition, numerous studies have attempted to address these issues by employing a Convolution Neural Network (CNN) due to its ability to provide high accuracy in character detection. However, the performance on mobile devices is possibly faced with problems resulting from the limitation of computation resource on the platform that also affect computation cost. This study, therefore, proposes a 2-tier architecture by placing the mobile app as a client that invokes a Javanese letters classifier service, which is based on CNN, and implemented in the web-server through the Application Program Interface (API). The results show that the letter classification was successfully implemented in a mobile platform, with an accuracy rate of 86.68%, utilizing training for 50 epochs, and an average time of 1935 ms.",60104977,Universitas Atma Jaya Yogyakarta,Yogyakarta,Indonesia,"['1706', '1705']",29.16666666666667,0.1795,0.6805000000000001,1,0.10294117647058823,0.058823529411764705,0.35
367,379,379,Detecting semantic violations of lock-free data structures through C++ contracts,"The use of synchronization mechanisms in multithreaded applications is essential on shared-memory multi-core architectures. However, debugging parallel applications to avoid potential failures, such as data races or deadlocks, can be challenging. Race detectors are key to spot such concurrency bugs; nevertheless, if lock-free data structures are used, these may emit a significant number of false positives. In this paper, we present a framework for semantic violation detection of lock-free data structures which makes use of contracts, a novel feature of the upcoming C++20, and a customized version of the ThreadSanitizer race detector. We evaluate the detection accuracy of the framework in terms of false positives and false negatives leveraging some synthetic benchmarks which make use of the SPSC and MPMC lock-free queue structures from the Boost C++ library. Thanks to this framework, we are able to check the correct use of lock-free data structures, thus reducing the number of false positives.",60002676,Universidad Jaume I,Castellon de la Plana,Spain,"['1712', '1710', '1708']",25.16666666666667,-0.0016666666666666867,0.5599999999999999,1,0.09444444444444444,0.03333333333333333,0.35119047619047616
368,380,380,EEG imaging application on positive emotion of affective neuroscience,"This research paper explored the brain electrical activities of human positive emotions through Electroencephalography (EEG) device. Modern day EEG device has made it possible to record and analyze the electrophysiological pattern of the brainwaves. Brain reactions to certain situation and environment affect human physical body and produce physiological or emotions effects. However, the correlation of human emotion and its electrophysiological is still poorly understood. Although many scientific research has been carried out, it is still remain a big challenge as the physiology and psychology of human and living being cannot be quantify directly. The previous study investigated the positive emotion of the affective neuroscience. Despite being important for many functioning in humans, it is far less researched compared to negative emotions. This study elaborates its findings by investigating the relation between positive emotion with EEG frequency and its cognitive relation to the brain lobes. Human subjects participated for this experiment and were assigned to watch several stimulus videos while wearing the Emotiv Epoch to record their brainwaves. The results show that different positive emotions generate different spatial patterns. The spatial patterns and frequency bands for joy, inspiration and serenity particularly shows distinguishable difference compared to other positive emotions.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",18.0,0.09863275613275613,0.4027741702741702,1,0.11574074074074074,0.027777777777777776,0.2777777777777778
369,381,381,A device control method based on worker's device usage history,". All rights reserved.Unlike in the past, the 4th Industrial Revolution is proceeding at a very rapid pace and affects society as a whole. Humans can be provided with the necessary information anytime, anywhere with the help of high-speed communication networks and artificial intelligence, and thus they can work more conveniently and quickly on a given problem. In this study, we will study ways to effectively coordinate various devices in connected space based on IoT (Internet of Things) technology.Due to the recent development of hardware technology, the use of fast processing speed and high-speed communication network can solve the problem more precisely and faster than humans in problem solving or decision making. We investigate the platform technologies of the 4th industrial revolution such as artificial intelligence, big data, internet of things, cloud computing and 3D printing. Based on this technologies, we would like to prepare a way to promote the convenience of life by utilizing the intelligent system by the Internet of Things, automation and artificial intelligence.With the recent development of IoT technology and high-speed wireless communication network, smart home automation system is becoming more convenient than the past and evolving into a smart system without delay. These systems are being developed into a system that promptly responds to user's command and learns user's life pattern by linking with AI speaker that supports high recognition rate. In this study, we propose a framework to effectively control various devices in home, university classrooms and company conference rooms. The proposed framework consists of spaces such as homes, universities and offices, classrooms, conference rooms, devices that can be installed and operated in each space, and a control server to manage them.Using the framework-based system proposed in this study, the user enters the room, accesses the smart room system, selects the device, and starts the device. In addition, the administrator can automatically operate the devices at specific times by inputting the weekly and monthly plans written for each space into the smart room system. As such, by storing and managing the usage history of devices installed in a specific space, it is possible to guide the operation of the devices installed in the space by referring to the program registered for each space as well as analyzing the behavior patterns of the worker in the space.",60000872,Kangwon National University,Chuncheon,South Korea,['1700'],34.72727272727273,0.11715646258503402,0.5631836734693877,1,0.12814645308924486,0.011441647597254004,0.28978622327790976
370,382,382,An empirical study on smartphone addiction of the university students,Smartphones have become an import part of the human life from the beginning of the 21st century. Most of the people of different ages are using most modern smartphones. The present study is an attempt to examine the university students' smartphone addiction and their perception on its usefulness for the academic purposes. The study employed quantitative method to measure the smartphones addiction. Two questionnaires were used to gather the data for the present attempt. One questionnaire was used to gather the data for smartphone addition and the second questionnaire was used to attain learners' perception on the smartphone addiction for the learning purposes. The participants of the present attempt were (N=174) undergraduate students of a public university. The finding of the study displayed that university students spend more than 8 hours in a day on their smartphones. Findings also indicate that participants are aware of the positive aspects of smartphones. The study also recommends suggestion on the future research.,60110525,Majmaah University,Al-Majmaah,Saudi Arabia,"['1706', '1705']",15.9,0.13607954545454545,0.21794507575757574,1,0.09248554913294797,0.005780346820809248,0.24855491329479767
371,383,383,New efficient caching strategy based on clustering in named data networking,"The Named Data Networking NDN is one of the most proposed architecture for the new model of Internet communications based on contents distribution, called Information-Centric Network ICN. It is widely accepted by the research community since it has become dominant in ICN design that resolves TCP-IP based Internet problems such as bandwidth, delay, location dependent and congestion. Based on location host IP addresses, TCP-IP designed for Peer-to-Peer communication P2P. NDN architecture is oriented Content Centric Networking CCN, where the data is stored on routers and distributed to users from the nearest router. Cache capacities of routers are limited compared to forwarded contents. To move from TCP-IP model to CCN model, many papers propose several new contents distribution based architecture ICN. In this paper, we propose a novel strategy to optimize the use of network resources inspired from Network clustering and cluster head selection in MANETs. Specifically, the improved K-medoids cluster algorithm is used to divide the global network in clusters, where for each cluster; three routers are selected as content routers. The first is the main caching router as well as the second and the third are the secondary caching router. The caching router selection process relies on three relevant criteria consisting of the distance between a node and its cluster centroid, the number of neighbors, and the congestion level. Two Multi Attribute Decision-Making methods MADM are applied, namely TOPSIS and AHP. Performance analysis of our proposed strategy with the established criteria showed its effectiveness and strong potential.",60068758,Université des Sciences et de la Technologie d'Oran Mohamed Boudiaf,Oran,Algeria,"['1706', '1705']",20.666666666666668,0.11396103896103894,0.3695526695526696,1,0.1111111111111111,0.13194444444444445,0.3516483516483517
372,384,384,Applying eye tracking device on the gazing behaviour and its effects on emotions attributes,"Recent eye-tracking technology has grown popularity in various field of research and industry. However, it has been a challenge to identify human emotional states using eye tracking method. The purpose of this study is an empirical attempt to apply the eye tracking device and method to investigate the relationship between human emotions and eye-gaze behaviors. In order to achieve this purpose, nine emotional video stimuli such as Amusement, Joy, Neutral, Sad and Fear are used to stimulate two types of emotions which are positive and negative. These stimuli are displayed and emotions are measured using eye-tracker, Tobii TX 300. Fifteen students from Malaysian-Japan International Institute of Technology (MJIIT) are randomly chosen for the study. The results obtained are in the form of fixation duration and pupil dilation. The results are filtered and tabulated to analyze the related behavior. Mean fixation duration and pupil dilation are calculated to identify the video stimuli with the highest count. ANOVA analysis shows that the significance, p-value is 0.43 for fixation duration. Whereas, p-value 0.003 for pupil dilation indicating there is a significant relationship between eye-gaze behavior and emotion. This study might be favorable in usability issues in human-computer interaction (HCI) contexts.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",16.416666666666664,-0.006483957219251334,0.4387032085561498,1,0.10548523206751055,0.06329113924050633,0.34841628959276016
373,385,385,Neuroimaging electroencephahlography (EEG) application on human electrical brain activities during meditation and music listening,"Meditation has a positive impact on the life of human beings. Researchers have scientifically measured and reported the positive impact of meditation from various neuroscience and neuroimaging technology such as encephalogram, fMRI, ECG, etc. Therefore, the neurophysiological EEG was used to identify the brain activities after listening to Zikr and compared it to music listening. Five healthy students as subjects were instructed to listen to the Zikr meditation from Asma Ul-Husna and slow rock music. A lowcost 16 electrodes of Emotiv Epoc was used to record the brain waves activities and determined its location in the brain lobes. Statistical analysis by using FFT from the MATLAB EEGLAB Toolbox software was performed to obtain and analyzed the data. The analysis result showed that the right frontal F8 give out high alpha and beta value thus proving that it involves focus and attention. 85% of the lobes involved give out low beta band during listening to Zikr meditation which indicates the person to focus more during Zikr listening session. Hence, Zikr meditation can lead a person into a calmer state when compared to music listening.",60009885,Tokai University,Hiratsuka,Japan,"['1712', '1708', '1705']",20.33333333333333,0.14547815820543095,0.4515112160566706,1,0.14,0.095,0.32323232323232326
374,386,386,Decision making model of introducing energy-saving technologies based on the analytic hierarchy process,"A hierarchical tree of the levels of choosing the optimal information and communication means for promoting energy-saving technologies based on the hierarchy analysis method was built, including 4 levels of criteria: type of consumer; economic indicators of consumer opportunities; means of promotion available for perception; tools that have a direct impact on the consumer. This hierarchical system allows the selection of the optimal communication means of promoting energy-saving technologies. The communication system for promoting energy-saving measures was formalized as a set of real and potential threats to the choice of management decisions to ensure an adequate level of support for energy saving measures.",60111496,Tashkent Institute of Irrigation and Agricultural Mechanization Engineers,Tashkent,Uzbekistan,['1710'],34.333333333333336,0.2055555555555556,0.4388888888888889,1,0.11965811965811966,0.008547008547008548,0.2972972972972973
375,387,387,Designing a theoretical integration framework for mobile learning,"New technologies are rapidly changing mobile learning and making it difficult to control. In addition to educational factors and learning content, a modern mobile learning system must take into account the technical and personal aspects of learning, the devices and aspects related to its evolution and interoperability. Teaching on the other hand has also evolved involving more flexibility in tasks and learning stages, thus using modern technologies that offer more alternatives now. In addition, such tasks may be specific to the learning content as well as the learning context or furthermore the learner's environment. Traditionally, mobile platform design relies on the skills of a mobile developer whose knowledge allows him to design mobile applications that are useful to users. But with mobile learning, the design phase involves more than just mobile development skills. For example, if you are designing a platform for practical work, the instructors responsible for the training should be involved. However, the empirical results show that educators do not integrate technology effectively into their curricula. To enable these instructors to develop mobile learning platforms, it is important to facilitate their integration through a theoretical model that will take into account all the ingredients necessary to complete this learning and to balance them in order to ensure its efficiency. In this study authors used a thematic synthesis methodology to present a framework for mobile devices integration in learning. They focused on three models that they think are the most cited in the field of ICT (information and communication technologies) integration in learning. The five-axis framework consists of enriching the TPACK framework (Technological Pedagogical Content Knowledge model in order to more precisely address mobile learning by covering the following parts: pedagogy, content, mobile technology, learning environment and learner's profile. It describes relatively in depth the various factors involved as well as the effective interconnection to be ensured to achieve an optimal and efficient integration of m-learning. Balancing those five parts will be a matter of plural reflection when designing or consulting on a mobile learning platform.",60025457,Hassan II University of Casablanca,Casablanca,Morocco,"['1706', '1705']",24.07142857142857,0.16754261363636366,0.42201704545454544,1,0.13368983957219252,0.013368983957219251,0.25405405405405407
376,388,388,Understanding the design intent through the analysis of renaissance drawings the digital reconstruction of an unbuilt mausoleum by Giuliano da Sangallo,"Giuliano da Sangallo is one of the paramount figure emerging from the Italian architecture during the Renaissance. He was commissioned to build many buildings, leaving also an ample documentary corpus, made of sketches and more technical drawings. On some pages in the Codice Barberiniano, a rich collection of drawings stored at the Vatican Apostolic Library, Giuliano drafted a plan and a section view of a building that recent studies speculate to be a conceptual proposal for the Pope Julius II's mausoleum. Beginning from these graphical representations, and taking into account many coeval paintings illustrating architectural details, several digital reconstructions were proposed and compared in two master thesis works, ending in a virtual computer model whose shape and proportions are expression of a plausible constructive hypothesis. Many analysis were also carried out on the model, in order to better understand the original Sangallo's design intent.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1710', '1706', '1705']",28.8,0.26785714285714285,0.3464285714285714,1,0.10062893081761007,0.09433962264150944,0.2893081761006289
377,389,389,Evaluating neuromarketing technique on consumer satisfaction using EEG imaging,"This article presents an evaluation of consumer satisfaction using the EEG brain imaging technique. Involvement of brain science into marketing research has sparked great interest recently since traditional marketing solely dependent on questionnaires. Consumers are normally less cooperative with marketers when they made an unexplained decision by answering the questionnaires. In response to this problem, the EEG imaging technique could be used to identify the consumer response by analyzing their brain activities. A low-cost Emotiv EPOC EEG Neuroheadset was used in this experiment. Theta (ϑ) 4-8 Hz, Alpha (α) 8 to 12 Hz and Beta (β) 12-25 Hz waves are the basis for determining the brain activation. Popular shoes product advertisement on price reduction were displayed on the computer screen to observe the subject's responses. The topographic maps result of the brain showed that the frontal lobe and the right part of the brain activated the most which indicates the contentment or satisfaction behaviour. Further analysis on the power spectral density showed that higher synchronization of Theta (ϑ), Alpha (α) and Beta (β) bands were more apparent in the right frontal lobe which thus confirmed a significant correlation of marketing decisions with the brain activities.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",21.66666666666667,0.22894345238095234,0.5216517857142857,1,0.084070796460177,0.0752212389380531,0.35909090909090907
378,390,390,Dual band printed bow-tie antenna for WLAN/WiMAX application,"In this paper a dual band printed bow-tie antenna for WLAN and WiMAX application has been presented. A planar bow tie antenna consists of defected ground and symmetrical shape split ring resonator (SRR) is presented to apply to the dual band application. A triangular microstrip patch with the defected ground is used as initial bow tie antenna which worked on WiMAX Band. Further initial design (primary antenna) added with SRR to operate over 2.4-2.8 GHz for Bluetooth, Wi-Fi, ZigBee, WLAN Applications and 3.4-4.2 GHz which includes Worldwide Interoperability for Microwave Access (WiMAX) and C-band down link frequency band for satellite communications. The proposed antenna has been made on 1.6 mm thick FR-4 substrate with a size of 50x28 mm2. The proposed antenna has very wide bandwidth with the value of VSWR less than 2.",60105058,"Amity University, Rajasthan",Jaipur,India,"['1712', '1708', '1705']",22.33333333333333,-0.04402777777777778,0.2938194444444445,1,0.09433962264150944,0.11320754716981132,0.40268456375838924
379,391,391,"Scires-it, a well established open acces journal",This short Editorial focuses on the pioneering features of the well established open acces Journal SCIRES-IT - SCIentific RESearch and Information Technology. It also makes a review of SCIRES-IT achievements in the past year.,60024353,Universita del Salento,Lecce,Italy,"['1710', '1706', '1705']",17.0,-0.08333333333333333,0.35000000000000003,1,0.1,0.15,0.5277777777777778
380,392,392,Integration of contextual-pragmatic and phonetic information in speech perception: An eye-tracking study," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.Pragmatic information, such as inferences regarding upcoming coreference, has been shown to influence phonetic perception (Rohde & Ettlinger, 2012). Pragmatic information, however, comes in many forms. Using a Visual World Paradigm, tracking listeners' categorical responses and the time-course of information integration via eye movements, we investigated whether and how a different kind of pragmatic information, the contrastive function of prenominal adjectives (Sedivy, Tanenhaus, Chambers, & Carlson, 1999), can affect listeners' perception of voicing in initial plosives. Our results suggest that the pragmatic contrast inference did not affect the behavioral judgments on phonetic categorization, but it did have an (albeit limited) influence during the online processing of voice onset time (VOT). Our findings suggest that different kinds of higher-level pragmatic inferences are not uniform in how (successfully) they are integrated with low-level phonetic properties in real-time comprehension.",60029278,The University of Chicago,Chicago,United States,['1706'],29.16666666666667,0.2211309523809524,0.4952380952380953,0,0.08444444444444445,0.06666666666666667,0.45794392523364486
381,393,393,Heterogeneity in IoT-based smart city designs,"Smart city is a strategy of supporting a new way of living using data collected from different types of electronic devices. Subsequently, such data are analyzed and utilized to enable efficient resource usability and service optimization. Various applications, such as traffic planning, crowd monitoring, public health care, security, economy, and urban planning, are elaborated in smart cities. Thus, various requirements are needed to incorporate and facilitate efficient development of these applications in the smart city design. Smart cities can be distinguished via the requirements supporting these applications. This study establishes the requirements of smart cities in relation to the involved applications and their influence on the smart city design. Moreover, this research provides a list of smart city requirements and discusses the potentials of various network architectures to facilitate such requirements. The existing smart city designs are evaluated and compared on the basis of the requirements and architectures.",60064180,The University of Jordan,Amman,Jordan,"['1706', '1705']",18.5,0.11753246753246753,0.4882034632034633,1,0.12650602409638553,0.0,0.3493975903614458
382,394,394,Mobile learning application design to promote youth financial management competency in Thailand,"Financial knowledge is an important factor in a country's economic and financial security and its citizens' lives and there is much related research indicating that technology will help, especially in the case for the mobile learning application model. This has the potential to educate and for the knowledge to be shared via the social network and social share and for the student to access vast learning sources to cultivate appropriate habits in financial management as they grow up. The purpose of the study was to design and develop a mobile application, including confirmatory factor analysis to learn and promote youth's financial management competency. This study used mixed methods in research both quantitative and qualitative approaches to explore research by collecting the comments from 5 regions in Thailand totaling 957 students and the qualitative data of 10 teachers by interviews. The results found that 98.75% of students had a smart mobile phone and that the students need a mobile application which can be used for learning everywhere (64.89%), supporting smart mobile phones both iOS system (Apple) and Android (66.04%), mobile learning design consisting of infographics, animation, sound and video (65.41%), The respondents needed the scaffolding application that is both flexible and fixed at the highest level (67.50%) and scenario-based learning in daily life at the (84.64%) and a financial pretest which motivated mobile application learning.",60028190,Chulalongkorn University,Bangkok,Thailand,"['1706', '1705']",44.8,0.1116780045351474,0.3628117913832201,1,0.11583011583011583,0.015444015444015444,0.29571984435797666
383,395,395,Puncalc: task-based parallelism and speculative reevaluation in spreadsheets,"Spreadsheets are commonly declarative, first-order functional programs and are used as organizational tools, for end-user development and for educational purposes. Spreadsheet end users are usually domain experts who use spreadsheets as their main computational model, but are seldom trained IT professionals who can leverage today’s abundant multicore processors for spreadsheet computation. In this paper, we present an algorithm for automatic, parallel evaluation of spreadsheets targeting shared-memory multicore architectures, which lets end users transparently make use of their multicore processors. We evaluate our algorithm on a set of synthetic and real-world spreadsheets and obtain up to 16 times speedup on 48 cores.",60018567,IT-Universitetet i København,Copenhagen,Denmark,"['1712', '1710', '1708']",25.25,0.06666666666666668,0.3261904761904762,1,0.125,0.008333333333333333,0.35398230088495575
384,396,396,Effect of heating temperature on brookite TIO2 sol-gel coating for photo-induced hydrophilicity,"Brookite has been rarely used and always exits as a by-product of TiO2. Until recently, there are limited studied concerned with the preparation of brookite coating. In this paper, the main objective of producing pure brookite coating from a specially synthesized sol without using solvent for photo-induced hydrophilicity is reported. The TiO2 coatings were deposited on a glass substrate via a spin coating method at various temperatures (200C, 300C, and 400C) and soaked for 3 hours. Coatings characteristic were evaluated using XRD and Raman spectroscopy. For the photocatalytic and photo-induced hydrophilicity performance, a color degradation technique of methylene blue (MB) and water contact angle measurement (CA) was utilized respectively. The test was done under UV light irradiation for 5 hours. The XRD results revealed a single peak denoted to brookite, B (111) with an orthorhombic structure was formed at 31.9° throughout all temperatures with an average crystallite size of 41 nm to 58nm. Further analysis using Raman spectroscopy also indicated that the deposited TiO2 coatings are brookite. Results of the band gap analysis also proved that the obtained values are in agreement with the value of brookite phase. Thus, it can be confirmed that the TiO2 coatings deposited from the synthesized sol are brookite coatings. It is found that the brookite TiO2 coating deposited at 400°C is the best to possess well-balanced properties for self-cleaning application.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",18.83333333333333,0.1457983193277311,0.4163865546218488,1,0.1198501872659176,0.04868913857677903,0.36363636363636365
385,397,397,Development of augmented reality (AR) based gamelan simulation with leap motion control,"One of the traditional musical instrument from Indonesia is gamelan, that is now less desirable because people nowadays prefer to play modern musical instruments, or because of its expensive price. This study combines the modern technology of AR and Leap Motion and also utilizes the sophisticated smartphone to develop a gamelan simulation that is presentable to the user. There are two kinds of an experiment performed in this research. The first is Augmented Reality (AR) experiment which authenticates that the distance and the height parameters are the keys to get a 100% success in running the gamelan simulation. The distance is ranged from 45 cm to 65 cm and the height is ranged from 25 cm to 30 cm. And the second one is the usability evaluation to five users, who resolves the completion task very well, acquires the result of 86.48%.",60069392,Brawijaya University,Malang,Indonesia,"['1706', '1705']",23.66666666666667,0.08194444444444443,0.3125,1,0.08333333333333333,0.04487179487179487,0.32051282051282054
386,398,398,Metaheuristic approaches to a vehicle scheduling problem in sugar beet transportation,"A variant of vehicle scheduling problem (VSP) arising from the sugar beet transportation in a sugar factory in Serbia is introduced. The objective of the considered VSP is to minimize the required transportation time under problem-specific constraints. The problem is formulated as a mixed integer linear program (MILP). Within the framework of commercial CPLEX solver the proposed MILP model was able to produce optimal solutions for small size problem instances. Therefore, two metaheuristic methods, variable neighborhood search (VNS) and greedy randomized adaptive search procedure (GRASP), are designed to solve problem instances of larger dimensions. The proposed GRASP and VNS are evaluated and compared against CPLEX and each other on the set of real-life and generated problem instances. Computational results show that VNS is superior method with respect to the solution quality, while GRASP is able to find high quality solutions within very short running times.",60068815,University of Belgrade,Belgrade,Serbia,['1703'],20.714285714285715,0.13499999999999998,0.4277272727272727,1,0.09523809523809523,0.07738095238095238,0.3597560975609756
387,399,399,Animation of two-dimensional pictorial works into multipurpose three-dimensional objects. The atlas of the ships of the known world depicted in the 1460 Fra Mauro's mappa mundi as a showcase,"This paper reports the preliminary results of an ongoing interdisciplinary research in digital humanities and animation that the authors are undertaking to explore how a new generation of three-dimensional (3D) non-photorealistic animated visualisations can improve upon two-dimensional (2D) visualisation methods. The atlas of the world's ships depicted in the Fra Mauro's mappa mundi (Venice, Marciana National Library, dated 1460) has been used to: 1) showcase the design process and techniques of an innovative method through the prototyping of a 3D non-photorealistic-rendering (NPR) model of one ship, and 2) demonstrate the effectiveness of this method through the 3D NPR animation of all Fra Mauro's ships as a contribution to both the advancement of learning in pre-modern maritime history (with a focus on shipping), and the implementation of NPR for the creative industry.",60118482,"School of Art, Design and Media",Singapore City,Singapore,"['1710', '1706', '1705']",65.5,0.20727272727272728,0.510909090909091,1,0.07272727272727272,0.06666666666666667,0.40522875816993464
388,400,400,Comparison of MATLAB Simulink application with PLC application of real-time classical PID controllers in laboratory,"Process control is a common area of study for different engineering disciplines. Controllers working with the proportional-integral-derivative (PID) method are generally used in process control. Parameters like level, flow, position, pressure, and temperature are controlled in-process control. PID algorithm can be formed with different microprocessor-based devices. Process control is implemented by using analog input and outputs terminals of PLCs (Programmable logic controller) which is recently the most commonly used in industries. Also, a real-time PID method can be implemented by using a computer-based MATLAB program in the laboratory. The liquid level and flow control in the laboratory has been done by using PID algorithms and PLC device and MATLAB real-time interface by using an experimental set. Necessary connections and configurations have been prepared to perform process control. (SIMATIC Manager Step7) is used for programming in PLC. Besides, the MATLAB simulation program is configured to implement real-time control to be compatible with the MF624 data acquisition card. Liquid level and fluid flow control experiments were performed separately for the same PID algorithms formed on two different devices, then liquid level detection and liquid flow control results have been collected and investigated. Based on these results, a total of four experiments were compared with both devices considering the ease and difficulties of using PLC and MATLAB.",60108465,Northern Technical University,Kirkuk,Iraq,['1700'],17.833333333333332,0.003846153846153847,0.4942307692307691,1,0.11328125,0.0625,0.37916666666666665
389,401,401,Deep learning with word embedding modeling for a sentiment analysis of online reviews,"Recently, online buyers have been able to express their opinions about a variety of products, restaurants and services by writing online reviews. Opinions have subsequently become a new, important, and influential source of information for decision-making. This paper implements binary and multiclass sentiment classifications on a dataset of online reviews. The experiments are performed using restaurant reviews from Yelp to predict ratings based on the content of the reviews. This paper investigates various structures of neural networks on restaurant reviews, such as recurrent neural networks (RNNs) with long short-term memory (LSTM), RNNs with bidirectional LSTM (Bi-LSTM) and convolutional neural networks (CNNs). The reviews were first converted into vectors during preprocessing using various features: pretrained word2vec and global vector (GloVe) embedding. The efficacy of these text classification techniques was examined and compared. The classification performance was evaluated using different metrics: the accuracy, confusion matrix, recall, specificity, precision, F1 score, receiver-operating characteristic (ROC) curve, and the area under the curve (AUC). The results showed that the RNN model achieved a better accuracy score with Bi-LSTM for both binary and multiple sentiment classification tasks.",60105146,Princess Nourah bint Abdulrahman University,Riyadh,Saudi Arabia,"['1711', '1710', '1707', '1702']",20.11111111111111,0.11131313131313132,0.41196969696969704,1,0.07423580786026202,0.05240174672489083,0.4611872146118721
390,402,402,Performance enhancement of Gauss-Newton trust-region solver for distributed Gauss-Newton optimization method,"Distributed Gauss-Newton (DGN) optimization method has been proved very efficient and robust for history matching and uncertainty quantification (HM&UQ). The major bottleneck for performance enhancement is the expensive computational cost of solving hundreds of Gauss-Newton trust-region (GNTR) subproblems in each iteration. The original GNTR solver applies the less efficient iterative Newton-Raphson (NR) method using a derivative which requires solving a large-scale linear system twice in each NR iteration. Instead of using a less accurate linear proxy as in the iterative NR method, the nonlinear GNTR equation is first approximated with an inverse-quadratic (IQ) or a cubic-spline (CS) model, by fitting points generated in previous iterations without using any derivative. Then, the analytical (or numerical) solution of the IQ (or CS) model is used as the new proposal for the next iteration. The performances of the two new GNTR solvers are benchmarked against different methods on different sets of test problems with different numbers of uncertain parameters (ranging from 500 to 100,000) and different numbers of observed data (ranging from 100 to 100,000). In terms of efficiency and robustness, the two new GNTR solvers have comparable performance, and they outperform other methods we tested, including the well-known direct and iterative trust-region solvers of the GALAHAD optimization library. Finally, the proposed GNTR solvers have been implemented in our in-house distributed HM&UQ system. Our numerical experiments indicate that the DGN optimizer using the newly proposed GNTR solver performs quite stable and is effective when applied to real-field history matching problems.",60030496,Royal Dutch Shell,Den Haag,Netherlands,"['1706', '1703']",27.444444444444446,0.08295454545454546,0.4699934123847167,1,0.08852459016393442,0.07540983606557378,0.41114982578397213
391,403,403,Investigation of wear and corrosion characteristics of short heat treated thixoformed aluminium alloy,"The thixoformed Al-Si-Cu alloys play an important role in automotive and engineering industries due to their wear resistance properties. This investigation looks into the wear and corrosion behaviors of thixoformed Al-Si-Cu alloy. Attempt has been made to relate the coefficient of friction (CoF) and corrosion rate on the short series of T6-heat treatment of thixoformed LM4 aluminium alloy. The short T6 heat treatment involves the application of solute solutioning, quenching and artificial ageing. Dry sliding condition using a pin-on-disc configuration against the SKD II steel disk under a constant load, distance and speed of 10 N, 1000 m and 0.1 m/s respectively was conducted to investigate the wear. The CoF of thixoformed shows an improvement of 5% where the T6 treated alloy is 0.4299 as compared to the 0.4537 untreated LM4 alloy. Furthermore, a significant reduction of 54% from 2.5459x10-4 mmpy to 1.1697x10-4 mmpy corrosion rate was also noted between the untreated and treated thixoformed alloy. Therefore, the alloys that undergone the short T6 heat treatment cycle generally improved the wear and corrosion resistant as compared to the alloys without heat treatment.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",22.75,0.0030303030303030372,0.5166666666666667,1,0.10138248847926268,0.07373271889400922,0.36683417085427134
392,404,404,Evaluation of user interface performing a DVZ-fuzzy logic pilot for powered wheelchair, All rights reserved.This paper presents the preliminary tests of an adapted user interface that performs an hybrid fuzzy-Deformable Virtual Zone(DVZ) pilot. The proposed concept uses a safely guidance algorithm for the powered wheelchair user and a laser range sensor to avoid collision. An adapted user interface is developed so that the accessibility and the mobility of disable or aged people especially those suffering from low cognitive abilities will be enhanced. Trials with the proposed algorithm detected obstacles and avoid them in 80% of trials with different objects and generated safe paths for the interface user.,60064746,University of Sfax,Sfax,Tunisia,"['1711', '1702']",24.0,0.11875,0.45,0,0.16037735849056603,0.0,0.3300970873786408
393,405,405,Exploring the eye tracking data of human behaviour on consumer merchandise product,"This article presents an exploration of the human eye tracking data towards consumer products. The study aim to investigate the data attributes of the cognitive processes and focused on the visual attention of the participants when choosing a shampoo brand which is commonly available in Malaysia. However, eye tracking datasets has a wealth of data on the eyes visual attention, fixation, saccade and scan path gaze. Therefore, this paper aims to solve this problem to minimize the datasets by using clustering machine learning approach. This is to observe the relation of these data attributes and possibly predict the possible solution contributing to cognitive processing. Tobii TX300 Eye-tracker was used in this experiment and the eyes tracking data were gathered particularly related to the eyes fixation and saccades by using the Tobii I-VT filter. Sixty subjects participated in this study. K-means clustering was used as statistical analysis to cluster the huge datasets from the eye tracking data. The relationship of the consumer cognitive processes with visual attention was understood when most of the participants chose the most popular shampoo brand such as Head & Shoulder. Further visual analysis on the data attributes results showed that K-means clustering has the potential to cluster and minimize the huge datasets and predicts consumer preferences.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,"['1712', '1708', '1705']",21.0,0.16470588235294115,0.5058823529411764,1,0.11637931034482758,0.06465517241379311,0.29910714285714285
394,406,406,Optimal dynamic auditing based on game theory,"A dynamic model based on game-theory is proposed to address the problem of fraud detection in auditing under non-linear payoff functions. Non-linearity is introduced by incorporating learning and sympathy effects in the audit process. It is proven that the audit/fraud detection game between two new engagement parties has a unique mixed strategy equilibrium, between an experienced auditor and a client has a unique pure strategy equilibrium, whereas in the long-run the game converges to a pure strategy equilibrium. In addition to this, to ensure an acceptable level of quality in the audit process, a closed form formula used to estimate the optimal auditor’s replacement time is extracted. The validity of the proposed scheme is tested on empirical data and modeling results comply with the International Standard of Auditing that requires the key audit partner to be rotated after a predefined period.",60067711,Hellenic Open University,Patra,Greece,['1703'],28.2,0.08766233766233765,0.4514141414141414,1,0.11180124223602485,0.018633540372670808,0.21710526315789475
395,407,407,Generation of high-performance code based on a domain-specific language for algorithmic skeletons,"Parallel programming can be difficult and error prone, in particular if low-level optimizations are required in order to reach high performance in complex environments such as multi-core clusters using MPI and OpenMP. One approach to overcome these issues is based on algorithmic skeletons. These are predefined patterns which are implemented in parallel and can be composed by application programmers without taking care of low-level programming aspects. Support for algorithmic skeletons is typically provided as a library. However, optimizations are hard to implement in this setting and programming might still be tedious because of required boiler plate code. Thus, we propose a domain-specific language for algorithmic skeletons that performs optimizations and generates low-level C++ code. Our experimental results on four benchmarks show that the models are significantly shorter and that the execution time and speedup of the generated code often outperform equivalent library implementations using the Muenster Skeleton Library.",60000401,Westfälische Wilhelms-Universität Münster,Munster,Germany,"['1712', '1710', '1708']",21.142857142857142,-0.07972222222222221,0.5075,1,0.13690476190476192,0.03571428571428571,0.36075949367088606
396,408,408,A joint chance-constrained data envelopment analysis model with random output data,"Data envelopment analysis (DEA) is a mathematical programming approach for evaluating the technical efficiency performances of a set of comparable decision-making units that transform multiple inputs into multiple outputs. The conventional DEA models are based on crisp input and output data, but real-world problems often involve random output data. The main purpose of the paper is to propose a joint chance-constrained DEA model for analyzing a real-world situation characterized by random outputs and crisp inputs. After developing the model, we carry out the following: First, we obtain an upper bound of this stochastic non-linear model deterministically by applying a piecewise linear approximation algorithm based on second-order cone programming; Second, we obtain a lower bound with use of a piecewise tangent approximation algorithm, which is also based on second-order cone programming; and then we use a numerical example to demonstrate the applicability of the proposed joint chance-constrained DEA framework.",60031014,"La Salle University, Philadelphia",Philadelphia,United States,['1703'],37.0,-0.01615646258503401,0.21836734693877552,1,0.12359550561797752,0.033707865168539325,0.2962962962962963
397,409,409,A bargaining approach to determine common weights in DEA,"In this paper Data Envelopment Analysis (DEA) is used to assess the relative efficiency of a set of decision-making units (DMUs). Each DMU is evaluated on the basis of the ratio of its weighted output (i.e. virtual output) over its weighted input (i.e. virtual input). Conventional DEA models allow each DMU to select the weighting scheme which optimizes its own evaluation. However, this total flexibility has drawbacks and in certain contexts may not be desirable. In such cases, it may be more appropriate to consider a common set of weights to benchmark and rank the alternatives using a common platform. In this paper, bargaining theory is used to determine a common set of weights in DEA. The advantage of using a bargaining approach is that the weights emerge bottom-up as the result of an agreement between the DMUs, instead of using an exogenous criterion imposed from above. The novelty of the proposed approach is that we consider two players per DMU, one whose utility function corresponds to its virtual input, and another whose utility is the negative of the virtual input. Thus, each DMU wants to choose the output weights so as to maximize its virtual output, and the input weights so as to minimize its virtual input. In this way, all DMU try to appear under the best possible light but the input and output weights are common and agreed. Models based on the Nash and the Kalai–Smorodinsky solutions are formulated and an application to a supplier selection problem is presented.",60033284,University of Seville,Sevilla,Spain,['1703'],19.384615384615387,0.051127819548872175,0.5093984962406014,1,0.11188811188811189,0.045454545454545456,0.30851063829787234
398,410,410,Effect of stitching on tensile properties of kenaf fabric reinforced polypropylene,"Nowadays, an increased interest in environmental awareness and use of eco-friendly composites towards the natural fibre such as kenaf fibre usage as reinforcement in composites have been shown by the researchers and industry. In this study, an experimental investigation was conducted to discover the effect of stitching patterns on woven kenaf fabric. The woven kenaf fibre and epoxy resin was used as a reinforcement and matrix. The composite samples was prepared by using hot press technique. It was found that the V and T60 samples was improved the tensile performance about 69.91% and 41.37%, respectively. It was also shown that the highest specific strength is V stitch pattern with the increment of 34.60% compared to unstitched sample. This can be concluded that, the angle of stitch direction gave significant effect on specific strength performance. Implications of the results and future research directions are also presented.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",18.125,0.09166666666666666,0.38888888888888895,1,0.11728395061728394,0.037037037037037035,0.28125
399,411,411,A compromise solution method for the multiobjective minimum risk problem,We develop an approach which enables the decision maker to search for a compromise solution to a multiobjective stochastic linear programming (MOSLP) problem where the objective functions depend on parameters which are continuous random variables with normal multivariate distributions. The minimum-risk criterion is used to transform the MOSLP problem into its corresponding deterministic equivalent which in turn is reduced to a Chebyshev problem. An algorithm based on the combined use of the bisection method and the probabilities of achieving goals is developed to obtain the optimal or epsilon optimal solution of this specific problem. An illustrated example is included in this paper to clarify the developed theory.,60068750,Université Mouloud Mammeri de Tizi Ouzou,Tizi Ouzou,Algeria,['1703'],26.75,-0.024999999999999998,0.32916666666666666,1,0.1391304347826087,0.02608695652173913,0.23893805309734514
400,412,412,Same value analysis on Edwards curves,"Recently, several research groups in cryptography have presented new elliptic curve models based on Edwards curves. These new curves were selected for their good performance and security perspectives. Cryptosystems based on elliptic curves in embedded devices can be vulnerable to side-channel attacks (SCA), such as simple power analysis (SPA) or differential power analysis. In this paper, we analyze the existence of special points—whose use in SCA is known as same value analysis (SVA)—in the case of Edwards elliptic curves. These special points can be identified through a power analysis of the scalar multiplication. We show that all Edwards curves recently proposed for standardization contain some of these points and are therefore unsafe against SVA. As a countermeasure, we use the isogeny volcano approach to find SVA-secure isogenous curves to those proposed for standardization.",60032717,Universitat de Lleida,Lleida,Spain,"['1712', '1705']",19.0,0.10791027154663517,0.3985537190082644,1,0.1032258064516129,0.05161290322580645,0.3509933774834437
401,413,413,Synergy in the composition classroom: Powerful learning through technology and instructional design,"To provide insight into structural, technological and environmental factors that contribute to powerful learning experiences in composition tasks, this instrumental case study offers an examination of the interactions of various elements evident in a music composition class. Data were collected via classroom observations, participant interviews and miscellaneous documents. The synergistic relationship between instructional design components and classroom supports, mediated through the use of technology, served to transform the human–computer interface from problem-solving to possibility-driven action. Instructional design elements that contributed to student engagement were choice in assignment completion, a self-paced work environment and musical preference. Instructional supports facilitated a core student learning process that expanded foundational knowledge and skill through active engagement in exploration, identification of musical elements and decision-making; and through interaction with an expert instructor, reflection through peer engagement, technology affordances and autonomy.",60000221,University of Colorado Boulder,Boulder,United States,['1706'],27.0,0.07708333333333334,0.30625,1,0.08125,0.0,0.2866666666666667
402,414,414,"A gamified mobile-based approach with web monitoring for a crowdsourcing framework designed for urban problems related smart government: A case study of Chiang Mai, Thailand",Crowdsourcing in smart cities has rapidly grown with the buildup of the internet of things which has enabled citizens who are similarity thinking in the society to become increasingly connected with one another delivering information to the government in order to plan the city. This article proposes a gamified crowdsourcing framework for smart governments to solve urban problems. It could help government officers to organize the deliveries regarding the city's characteristics. We applied game elements from the Gamification Concept in a mobile application in order to engage the citizens in our framework. We evaluated the framework for 2 months which had 548 citizens according to system data. According to our crowd sourcing project the most important issues that Chiang Mai is facing are pollution and traffic jams.,60000881,Chiang Mai University,Chiang Mai,Thailand,"['1706', '1705']",21.166666666666668,0.15476190476190474,0.5309523809523811,1,0.14925373134328357,0.029850746268656716,0.3208955223880597
403,415,415,2.45 GHZ rectenna design for RF energy harvesting,"A high conversion efficiency rectenna at 2.45 GHz is proposed in this paper. Two layers low cost FR-4 substrate has been used to fabricate the rectenna. The proposed designs contain patch antenna and open stub rectifying circuits. The dimension for the proposed rectenna design is 100 × 100 × 5 mm3. The technique of air gap approach has been used in order to increase gain of the antenna. The ground plane is added with the triangular slot has eliminate second and third harmonics which results enhancement of the conversion efficiency. The measured conversion efficiency reaches 79.29% when the input power at 17 dBm. This rectenna takes advantages of low profile, easy integration, high gain and high power conversion efficiency from previous proposals.",60110529,Saudi Electronic University,Riyadh,Saudi Arabia,"['1712', '1708', '1705']",15.25,0.07466666666666669,0.37200000000000005,1,0.10526315789473684,0.03007518796992481,0.3308270676691729
404,416,416,Interactive digital observatory on the cultural identity of italo-argentine heritage,"The contribution discusses the little-known topic of Italo-Argentine cultural heritage. The data gathered during the numerous studies performed so far have served as the basis for a Scientific Observatory. Its goal is to promote knowledge of the material and immaterial assets testifying to an integrated cultural process between the two countries as well as to highlight the relationship between Italian and Argentine culture during late twentieth-century mass immigration when Italians actively participated as designers, builders, entrepreneurs, businessmen, and teachers. All the data has been classified and is now being disseminated using a new archival and distribution medium: a visual, participatory experience present in public areas and the urban landscape.",60032350,Università degli Studi di Roma La Sapienza,Rome,Italy,"['1710', '1706', '1705']",27.25,0.0002525252525252565,0.2851010101010101,1,0.104,0.032,0.3025210084033613
405,417,417,Gaussian mixture model fitting method for uncertainty quantification by conditioning to production data,"For most history matching problems, the posterior probability density function (PDF) may have multiple local maxima, and it is extremely challenging to quantify uncertainty of model parameters and production forecasts by conditioning to production data. In this paper, a novel method is proposed to improve the accuracy of Gaussian mixture model (GMM) approximation of the complex posterior PDF by adding more Gaussian components. Simulation results of all reservoir models generated during the history matching process, e.g., using the distributed Gauss-Newton (DGN) optimizer, are used as training data points for GMM fitting. The distance between the GMM approximation and the actual posterior PDF is estimated by summing up the errors calculated at all training data points. The distance is an analytical function of unknown GMM parameters such as covariance matrix and weighting factor for each Gaussian component. These unknown GMM parameters are determined by minimizing the distance function. A GMM is accepted if the distance is reasonably small. Otherwise, new Gaussian components will be added iteratively to further reduce the distance until convergence. Finally, high-quality conditional realizations are generated by sampling from each Gaussian component in the mixture, with the appropriate relative probability. The proposed method is first validated using nonlinear toy problems and then applied to a history-matching example. GMM generates better samples with a computational cost comparable to or less than other methods we tested. GMM samples yield production forecasts that match production data reasonably well in the history-matching period and are consistent with production data observed in the blind test period.",60030496,Royal Dutch Shell,Den Haag,Netherlands,"['1706', '1703']",21.08333333333333,0.09561237373737376,0.4310921717171716,1,0.11458333333333333,0.04861111111111111,0.29642857142857143
406,418,418,Quickest flow over time network interdiction: mathematical formulation and a solution method,"This paper proposes a new problem entitled as “the quickest flow over time network interdiction problem”. This problem stands for removing some of network links using a limited interdiction resource with the aim of maximizing the minimum time required to transfer a predefined flow value through a given network. We formulate the quickest flow problem as a linear fractional programming problem and then, we transform it to a linear formulation. Using the linear formulation of the quickest flow problem we formulate the quickest flow network interdiction problem as a mixed integer linear programming problem. We also provide an improved formulation for the quickest flow network interdiction problem which is computationally more efficient than basic linear formulation. Finally, we apply the basic and improved formulations of the quickest flow network interdiction problem on a real world network and several grid networks.",60006622,University of Tabriz,Tabriz,Iran,['1703'],23.33333333333333,0.08499278499278501,0.3219336219336219,1,0.10666666666666667,0.0,0.24
407,419,419,International price comparisons: An area of further research," These rankings, so they claim, are the Swiss Army knife of competition analysis. A country that ranks lower on a list is declared a laggard or noncompetitive and thus supposedly is in need of regulatory intervention. Such claims require scrutiny and further analysis. An accurate price comparison should follow the scientific method and include a testable hypothesis, a properly designed study methodology, and accurate data collection and interpretation. One such ranking exercise is produced biannually by Finnish management consultancy Rewheel. The present review fills a void with its analysis of the Rewheel study and suggests that it is a highly simplistic international price comparison exercise. The methodology of Rewheel assumes an unrealistic world where consumers only care about how much data they can get for a certain budget (i.e., price), and all other competitive differentiators (i.e., plan and quality differences) and costs differences (e.g., size of network built) are irrelevant.",60098792,"National Economic Research Associates, Inc.",New York,United States,['1710'],21.571428571428577,-0.02738095238095237,0.5008730158730159,0,0.09302325581395349,0.029069767441860465,0.2631578947368421
408,420,420,Enzyme immobilization on polymer membranes: A quantum and molecular mechanics study,"Adsorption of the phosphotriesterase on a polysulfone membrane surface was investigated in this paper through a double-scale computational approach. Surface charges of the enzyme, as well as membrane, were calculated at sub and nanoscale while protein adsorption was simulated at larger scale. Adsorption energies were calculated as a function of the enzyme-surface distance, and for each distance, several protein rotations were tested to find the most stable orientations of the macromolecule. The results of this model were useful in obtaining information about the adhesion of the enzyme and to give indications on the orientations of its binding site. Adsorption energies agreed with the literature data. Furthermore, the binding site of the immobilized phosphotriesterase was less accessible with respect to native enzymes due to the steric hindrance of the polymer surface; thus, a reduction of its eciency is expected. The proposed methodology made use of fundamental quantities, calculated without resorting to adjustable or empirical parameters, providing basic outputs useful for ascertaining enzymatic catalysis rate.",60112436,CNR- Istituto per la Tecnologia delle Membrane,Rende,Italy,['1700'],23.285714285714285,0.10757575757575756,0.22196969696969696,1,0.09836065573770492,0.0,0.2737430167597765
409,421,421,Improving side-channel attacks against pairing-based cryptography,"Side-channel attacks are a serious threat against secret data involved in cryptographic calculations, as, for instance, pairing-based cryptography which is a promising tool for the IoT. We focus our work on correlation power analysis (CPA) attack against a pairing implementation. We improve a vertical side-channel analysis attack and propose the first horizontal attack against a pairing implementation. First, we present a characterization of the multiplication that allows us to reduce by a factor of ten the number of side-channel traces required in order to perform a CPA attack against an implementation of Ate pairing. Secondly, we successfully attack the same implementation with only one trace by using the first horizontal attack path against pairing-based cryptography.",60106179,Laboratoire de Mathématiques de Versailles,Versailles,France,"['1712', '1705']",23.0,0.08787878787878788,0.4492424242424242,1,0.11764705882352941,0.014705882352941176,0.2677165354330709
410,422,422,Three New Structures for Reactive Power Market by Considering Reactive Losses Caused by the Active Power Flow,"In this paper, three new reactive power market structures are studied and presented. Active power flow by itself causes active and reactive losses. Considering such losses in the reactive power market without making additional payments to producers is the main purpose of this paper. Therefore, this study attempts to improve the reactive power market and promote fair competition in reactive power generation by improving the market structure. The advantage of these methods is determining the mandatory region of units based on both active power output and its distance from the load. This novel structure leads to a reduction in system costs in the deregulated power system, which is one of the main policies of this paper. In order to simulate and describe the proposed methods in the implementation of the reactive power market, the IEEE 24- and 118-bus test system is applied and the proposed methods are compared with each other and the conventional reactive power market structure. Finally, findings show that the total payment by independent system operator will be reduced via application of the proposed methods.",60012835,Iran University of Science and Technology,Tehran,Iran,"['1711', '1707', '1705']",22.25,0.0386030636030636,0.5329503829503829,1,0.11518324607329843,0.010471204188481676,0.24083769633507854
411,423,423,Prosodic features of stances in conversation," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.Stance-attitudes and opinions about the topic of discussion-has been investigated textually in conversation analysis, discourse analysis, and computational models, but little attention has focused on its acoustic-phonetic properties. It is a challenge, given the complexity of stance and the many other types of meaning that share the same acoustic channels, all overlaid on the lexical and syntactic material of the message. With the goal of identifying automatically-extractable, acoustically-measurable correlates of stance-taking, this work identified signals of stance in prosodic measures of fundamental frequency, intensity, and duration in an audio corpus of dyads engaged in collaborative conversational tasks designed to elicit frequent changes in stance at varying levels of involvement. The study examined over 32,000 stressed vowels in content words spoken by 40 American English-speakers and found that f0 and intensity increased with stance strength, longer vowel duration signaled positive polarity, and a combination of measures distinguished several stance-act types, including: general agreement, weak-positive agreement, rapport-building agreement, reluctance to accept a stance, stance-softening, and backchannels. These results contribute to the understanding of the acoustic-phonetic properties of the social and attitudinal messages conveyed in natural speech.",60006514,Oklahoma State University - Stillwater,Stillwater,United States,['1706'],37.16666666666666,0.11236471861471864,0.3615800865800866,0,0.08960573476702509,0.03225806451612903,0.3779527559055118
412,424,424,A mechanism for the storage and retrieval of passwords using cloud,". All rights reserved.Every aspect in the present world has been rationalized. Each task that takes place in day to day life such as net-banking, online shopping entail password to form a nuisance free environment. The file access systems and mail conversations in business environment also require passwords. Some sites require a separate password exclusively whereas many applications connect their passwords with social networking companies. Comprising the same passwords for storing data and using the same passwords for many applications has become human proclivity. Therefore securing passwords has become a major provocation in today’s world. Thus as a motivating technology Cloud computing with wide availability, it makes the work efficient and ease. As users since we have many passwords we use for many applications it has become necessary to secure our passwords. Some inferences have been done in order to bring assurance to people of securing passwords. In this paper, on comparing various models with Cloud infrastructure, we aim in developing a biometric based authentication system for securing and maintaining passwords. It is two step authentication system which reduces the difficulties of users to manage and recollect passwords.",60103989,"Sri Krishna College of Engineering and Technology, Coimbatore",Coimbatore,India,['1700'],15.666666666666664,0.1747395833333333,0.4197916666666667,1,0.14903846153846154,0.009615384615384616,0.36097560975609755
413,425,425,Dragonfly Algorithm for solving probabilistic Economic Load Dispatch problems,", part of Springer Nature.Economic Load Dispatch problem in power system is solved by different methods to run the generating station in an economic way for different loading conditions. A combination of thermal power plant and renewable plant of wind and solar photovoltaic is considered for optimal solution at minimal cost using Dragonfly Algorithm. Swarming behaviour of dragonfly is used for optimization of the present Economic Load Dispatch problem. The modelling of solar and wind power plant is done using 2-m point estimation technique to consider the uncertainties in power generation from such renewable sources. The solution of objective function is found using the proposed method (Dragonfly Algorithm), and the same is compared with that obtained using other well-known algorithms such as Crow Search Algorithm, Ant Lion Optimizer, Oppositional Real-Coded Chemical Reaction Optimization, Biogeography-Based Optimization, Particle Swarm Optimization and Genetic Algorithm. It is found that the proposed method gives better solution in terms of execution time and cost effectiveness. To validate the performance of Dragonfly Algorithm, four test systems have been considered. It is observed that the total generation cost obtained by Dragonfly Algorithm for each test system is less (10,049.1948 $/h for test system I, 2018.0762 $/h for test system II, 15,268.8325 $/h for test system III and 32,310.2922 $/h for test system IV) as compared to other well-known optimization methods. It is also found that the time required to reach minimum solution is lesser in case of Dragonfly Algorithm (8 s for test system I, 12 s for test system II, 15 s for test system III and 20 s for test system IV) as compared to other optimization techniques.",60104582,"National Institute of Technology, Agartala",Agartala,India,"['1712', '1702']",30.222222222222218,0.015196078431372552,0.37450980392156863,1,0.09967845659163987,0.13504823151125403,0.3853820598006645
414,426,426,The interaction of knowledge as though field experimentation of the integrated survey. The case of sacristy of Francesco Solimena in the church of san Paolo Maggiore in Naples,"The use of advanced integrated survey techniques has allowed the acquisition of morphometric and colorimetric information to render three-dimensionally the frescoes by Francesco Solimena in the sacristy of san Paolo Maggiore in Naples. The research has explored different levels of knowledge by applying the necessary integration between consolidated knowledge and innovative technologies: combining innovative aspects of range-based modeling method and image-based modeling method, we created returnable models that can also be questioned remotely. The outcome is a contribution aimed at protection and enhancement of the cultural heritage, favoring conservation and restoration interventions as well as providing a permanent query of data and their complete use.",60017293,Università degli Studi di Napoli Federico II,Naples,Italy,"['1710', '1706', '1705']",35.0,0.1875,0.6125,1,0.1111111111111111,0.05982905982905983,0.27927927927927926
415,427,427,Equilibrium strategies of the fluid queue with working vacation,"The paper considers a fluid model with a working vacation strategy, in which the working vacation period and the busy period appear alternately. When the fluid reaches the system, the net benefits is calculated based on the state of the buffer observed at this time, and then fluid determines whether to enter the buffer. In addition, according to the applicability of the model, the benefit utility function of this paper adopts the exponential form of sojourn time and average queue length. Based on the above conditions, the equilibrium strategies are discussed in both fully observable case and almost observable case considering fluid individual benefit and maximum social benefits per unit time. This paper attempts to make a reasonable proposal for individual and policy makers to realize the optimal benefit through the correlation analysis of the fluid queue model under the working vacation strategy.",60018465,Yanshan University,Qinhuangdao,China,['1703'],28.6,0.013095238095238096,0.1976190476190476,1,0.12337662337662338,0.0,0.17532467532467533
416,428,428,Engine performance comparison between various RON97 gasoline brands available in Malaysian market,"Disparities towards engine performance by various gasolines from different fuel producers have constantly been a discussion among road users and available information regarding it are still not conclusive. Thus, this paper centres upon examining several Research Octane Number (RON) 97 fuel products sold in Malaysia and determining the key variation among them towards engine outputs. Specific energy was firstly collected using an oxygen bomb calorimeter since it was identified as a main petrol component that could affect overall engine performance. In terms of engine outputs, power break specific fuel consumption (BSFC), and engine efficiency were gathered by experimenting RON97 gasolines with a test engine connected to an engine dynamometer. Outcomes had depicted engine performance from utilizing various petrol products to be dissimilar even though all fuels were evaluated in similar octane rating. It was also found that gasoline specific energy values played a major role towards improving overall engine performance output especially in terms of BSFC (up to 18.47% difference) and engine efficiency (up to 11.67% difference). Therefore, despite fuel calorific value only differs among one and another by a margin lesser than 1%, it had shown towards reducing petrol consumption with up to more than ten times the impact.",60104064,Universitas Nasional,Jakarta,Indonesia,"['1712', '1708', '1705']",28.57142857142857,0.06567460317460318,0.3940476190476191,1,0.1031390134529148,0.03139013452914798,0.2914798206278027
417,429,429,Milling of titanium alloy using hexagonal boron nitride (hBN) nanofluid as a coolant,"Titanium has been used for many areas, such as aircraft turbine blade, fuel tanks, marine hardware and surgical implant. Due to its high hardness and high temperature when machining, the conventional method such as dry machining leads to rough surface roughness, high cutting force and short tool life. This study aims to evaluate the effect of different concentrations of hexagonal boron nitride (hBN) nanofluid on the cutting force, tool wear and surface roughness of titanium alloy using milling process. In this research, three different concentrations, namely 0.02, 0.06 and 0.1 wt% of hBN nanofluid were used, and their performance was compared with that of pure deionised (DI) water. The nanofluid was prepared by mixing the hBN nanoparticles with DI water and polyvinylpyrrolidone K30 as surfactant. The experimental results indicate that the machining performance of titanium alloy is better by using hBN nanofluid than by using pure DI water. Cutting force, tool wear and surface roughness are approximately reduced by 16.1%, 63.9% and 33.3% respectively by using 0.1wt% of hBN nanofluid compared to pure deionised water.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,"['1712', '1708', '1705']",25.0,-0.01789855072463767,0.5283540372670807,1,0.1044776119402985,0.05472636815920398,0.3793103448275862
418,430,430,The effectiveness of mobile learning based android in learning english vocabularies,"This research aims to examine the effectiveness of android-based mobile learning in learning vocabulary among SMP Batara Gowa's seventh grade students. Pre-experimental research design was used, namely one group pre-test post-test design. The populations in this study were all seventh-grade students of SMP Batara Gowa, and the sample was class VII.1 as the experimental class, which was chosen by using purposive sampling. The results of the data analysis show that the mean score of post-test (70.55) was higher than the mean score of pre-test (34.65). The result of the t-test was 30.117 and t-table 2.093. It could be indicated that the null hypothesis (H0) was rejected and the alternative hypothesis (H1) was accepted. Based on the effectiveness criteria, generally using mobile learning based android was effective in learning vocabulary at the seventh-grade students of SMP Batara Gowa.",122295373,STKIP YPUP Makassar,Makassar,Indonesia,"['1706', '1705']",19.571428571428573,0.0625,0.5958333333333333,1,0.10734463276836158,0.07344632768361582,0.37579617834394907
419,431,431,Multi-level Hybridized Optimization Methods Coupling Local Search Deterministic and Global Search Evolutionary Algorithms,"Efficient optimization methods coupling a stochastic evolutionary algorithm with a gradient based deterministic method are presented in this paper. Two kinds of hybridization are compared: one is a stochastic/deterministic alternate algorithm, the other is a stochastic/deterministic embedded algorithm. In the alternating algorithm, stochastic and deterministic optimizers are performed alternately as follows: some individuals are selected from the previous population, and sent to the deterministic algorithms for further optimization, then the improved individuals are inserted into the above population to form a new one for the stochastic algorithm. In the embedded hybridized algorithm, stochastic and deterministic optimization software are run in parallel and independently, the coupling between them is that the deterministic optimizer operates on a randomly selected individual (or the best individual) from the non evaluated population of the stochastic algorithm, then its outcome (new individual) is re-injected into the evaluated population. Moreover, a multilevel approximation (e.g. variable fidelity modeling, analysis and hierarchical approximated parameterization) is introduced in the algorithm, via a low fidelity modeling and rough parameterization to perform a search on large population at lower level, and a high fidelity modeling with detailed parameterization used at higher level. After a theoretical validation of the methods on mathematical test cases, the hybridized methods are successfully applied to the aerodynamic shape optimization of a fore-body of an hypersonic air breathing vehicle, providing both a significant acceleration in terms of parallel HPC performance and improved quality of the design.",60104172,Centre Internacional de Mètodes Numèrics en Enginyeria(CIMNE),Barcelona,Spain,['1706'],34.0,0.09732101232101233,0.3468972693972694,1,0.10256410256410256,0.01098901098901099,0.2669172932330827
420,432,432,Generating evacuation task plans for community typhoon emergencies: an integration of case-driven and model-driven approaches,"In community emergency management, it is crucial to generate evacuation task plans (ETPs) to help reduce risks in complex disaster situations. Case-driven and model-driven approaches have their respective advantages in generating ETPs, which can complement each other. With case-driven approach, historical experience can be fully used to establish the relationship between typhoon scenarios and historical ETPs. Through model-driven approach, the continuity of ETPs can be guaranteed when required information to operate the plans is missing. This study aims at proposing an integrated approach that can combine the benefits of both case-driven approaches and model-driven approaches. Based on the structural modeling of evacuation tasks, this paper proposes an integrated approach to generate ETPs for community typhoon emergencies. Finally, a case that is based on actual problems is provided to verify the reasonability and effectiveness of the proposed method.",60019616,Harbin Institute of Technology,Harbin,China,['1703'],19.571428571428573,-0.06944444444444445,0.3361111111111111,1,0.18902439024390244,0.0,0.34868421052631576
421,433,433,Assessing the operational and economic efficiency benefits of dynamic manufacturing networks through fuzzy cognitive maps: a case study,"The formation and effective end-to-end management of manufacturing networks is touted as a top priority for manufacturing enterprises that strive to improve the efficiency, adaptability and sustainability of their production systems. Due to their potential benefits, Dynamic Manufacturing Networks (DMNs), a knowledge-enhanced, model-based production management approach enabling seamless communication and cooperation among individual network members’ manufacturing systems, are gradually becoming a focal point of attention. Nevertheless, current understanding around the DMN concept remains fuzzy, whereas the way in which it can benefit manufacturing enterprises lacks proper articulation. This paper clarifies the management approach of Dynamic Manufacturing Networks on the basis of the DMN lifecycle and the respective information model used, while it further develops a model for their evaluation. In this respect, it employs the soft computing methodology of Fuzzy Cognitive Maps to capture industry laypeople perceptions on the factors that affect their operation, and to reveal insights on prospective benefits. Application of this model in a real-world, multi-site, single factory context in the semi-conductor industry provides good approximations of the experts’ estimations. The results, found in the directions of reduced cycle times, decreased costs and improved quality are quite promising and highlight the key role of the DMN information model. The assessment model designed enables to reason on and identify DMN gains. Thereby, it provides a basis for communication as well as a decision aid that offers evidence on the outcomes of establishing DMNs, ultimately creating a sense of confidence, before an enterprise commits its resources to it.",60002947,National Technical University of Athens,Athens,Greece,['1703'],27.66666666666667,0.1025510204081633,0.4677437641723355,1,0.10580204778156997,0.04436860068259386,0.35842293906810035
422,434,434,Efficient cascading of multi-domain image Gaussian noise filters,"Image denoising is a well explored but still an active research topic. The focus is usually on achieving higher numerical quality which is theoretically interesting, however, often the factor of computation cost is not considered. Our idea is to employ different image Gaussian noise filters to construct an effective image denoiser, where the deficiency of each filter is compensated with others, while a wide variation of quality versus speed can be achieved. We integrate filters using different cascaded forms and show that if two filters use uncorrelated features, their cascaded form provides a higher quality than each separately. We start with easy-to-implement filters employing pixel- and frequency-domain with different kernel size to construct a fast yet high-quality multi-domain denoiser. Then, we propose more complex denoisers by integrating our cascaded multi-domain denoiser to other state-of-the-art denoising methods. Simulations show that the quality of proposed multi-domain denoiser is significantly higher than its building-blocks. We also show that the proposed multi-domain denoiser can be integrated to state-of-the-art denoisers to from a more effective denoiser, while adding negligible complexity.",60033154,Concordia University,Montreal,Canada,['1710'],21.875,0.16127450980392158,0.5308823529411765,1,0.1318181818181818,0.0,0.3473684210526316
423,435,435,Perceptual deep depth super-resolution,"RGBD images, combining high-resolution color and lower-resolution depth from various types of depth sensors, are increasingly common. One can significantly improve the resolution of depth maps by taking advantage of color information; deep learning methods make combining color and depth information particularly easy. However, fusing these two sources of data may lead to a variety of artifacts. If depth maps are used to reconstruct 3D shapes, e.g., for virtual reality applications, the visual quality of upsampled images is particularly important. The main idea of our approach is to measure the quality of depth map upsampling using renderings of resulting 3D surfaces. We demonstrate that a simple visual appearance-based loss, when used with either a trained CNN or simply a deep prior, yields significantly improved 3D shapes, as measured by a number of existing perceptual metrics. We compare this approach with a number of existing optimization and learning-based techniques.",60107405,Skolkovo Institute of Science and Technology,Moscow,Russian Federation,"['1712', '1707']",21.142857142857142,0.11153846153846153,0.4672161172161172,1,0.13872832369942195,0.023121387283236993,0.3333333333333333
424,436,436,"More comprehension, more protection: Non-destructive techniques in the survey of the former S. Salvatore hospital in l'aquila, Italy","Non-destructive techniques are fundamental tools for a thorough knowledge of the construction aspects, structural conditions and pathologies of buildings. These tools become indispensable in the investigation of the Architectural Heritage subject to protection, guaranteeing the minimum invasiveness of the surveys in compliance with the architectural constraints. This paper shows the contribution that thermographer and thermofluometry have given in the knowledge and communication of the Former S. Salvatore Hospital in L'Aquila, Italy. The building, following the damage suffered by the 2009 earthquake, has been the subject of numerous studies but the analyses presented in this work represent an element of novelty and a fundamental step for the upcoming restoration interventions.",60018783,Università degli Studi dell'Aquila,L'Aquila,Italy,"['1710', '1706', '1705']",21.8,0.011111111111111118,0.3611111111111112,1,0.06666666666666667,0.06666666666666667,0.3389830508474576
425,437,437,Augmented reality storytelling: Narrative design and reconstruction of a historical event in situ,"How may we best utilize mobile augmented reality for storytelling when reconstructing historical events on location? In this article we present a series of narrative design considerations when developing an augmented reality application recreating the assault on Omaha Beach in the early morning on DDay. To what extent may we select existing genre conventions from, for example, documentary film, and adapt them to a location-based audio-visual medium like AR? How can we best combine sequence and access, the narrative flow of an unfolding historical event with the availability of background information, in order to enrich the experience of the story, but without distorting its coherence? To what extent may we draw from existing and well known media representations of the Omaha Beach landing? How was the battle documented with contemporary means? We present the rich documentation of photos, films, drawings, paintings, maps, action reports, official reports, etc., and discuss how these have been employed to create the published AR situated simulation. We also describe and discuss the testing and evaluation of the application on location with visitors, as well as online tracking of its current use.",60010348,Universitetet i Oslo,Oslo,Norway,"['1706', '1705']",62.0,0.22847222222222224,0.1930555555555556,1,0.14485981308411214,0.03271028037383177,0.2966507177033493
426,438,438,Embedded block residual network: A recursive restoration model for single-image super-resolution,"Single-image super-resolution restores the lost structures and textures from low-resolved images, which has achieved extensive attention from the research community. The top performers in this field include deep or wide convolutional neural networks, or recurrent neural networks. However, the methods enforce a single model to process all kinds of textures and structures. A typical operation is that a certain layer restores the textures based on the ones recovered by the preceding layers, ignoring the characteristics of image textures. In this paper, we believe that the lower-frequency and higher-frequency information in images have different levels of complexity and should be restored by models of different representational capacity. Inspired by this, we propose a novel embedded block residual network (EBRN) which is an incremental recovering progress for texture super-resolution. Specifically, different modules in the model restores information of different frequencies. For lower-frequency information, we use shallower modules of the network to recover; for higher-frequency information, we use deeper modules to restore. Extensive experiments indicate that the proposed EBRN model achieves superior performance and visual improvements against the state-of-the-arts.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",19.555555555555557,0.07687074829931972,0.4680272108843537,1,0.1187214611872146,0.0091324200913242,0.38071065989847713
427,439,439,An overview on robotic applications for cultural heritage and built cultural heritage,"Focus is an overview on Robotics application for Cultural heritage and Built Cultural Heritage (a term that includes all the Architectural, Archaeological, and generally constructed artifacts). In the field of analysis and restoration of Cultural Heritage and Built Cultural Heritage it is interesting to have accurate and efficient operating methodologies. Indeed, robots and robotic systems can be designed and used for these applications. The join between DART (Laboratory of Documentation, Analysis, Survey of Architecture and Territory), LARM (Laboratory of Robotics and Mechatronics) of Cassino University and the LAREA (LAboratorio di Rilievo E Architettura) of Tor Vergata University, it was an example in sharing different knowledges and competences and in developing innovative robotic applications, which are able to operate in Cultural Heritage and Built Cultural Heritage.",60032350,Università degli Studi di Roma La Sapienza,Rome,Italy,"['1710', '1706', '1705']",31.25,0.15666666666666668,0.32388888888888884,1,0.05517241379310345,0.2413793103448276,0.503448275862069
428,440,440,Explicit flow-risk allocation for cooperative maximum flow problems under interval uncertainty,"Many decision-making problems in transportation networks can be defined as maximum flow problems. During the last five decades, several efficient solution approaches have been proposed for the deterministic maximum flow problems. On the other hand, arc capacities of networks cannot be precisely defined in many real life settings. These networks are called uncertain. In this case, it becomes challenging to maintain a stable flow on the network. This paper presents a new approach based on the framework of interval analysis for the solution of maximum flow problems. We address a multiple-owners network problem by presenting a risk explicit interval linear programming model for the desired value of the system aspiration level. Afterwards, we employ a well-known collaborative game theoretic approach (the Shapley value) in a multiple-owners network under interval uncertainty in order to solve the maximum flow problem. A detailed numerical example is provided to present the suitability of the proposed approach in devising a stable network flow. The obtained numerical results and the trade-offs between decision risk and network flow information would be very valuable for supporting decision makers in resolving maximum flow problems when facing uncertainty.",60014930,Dokuz Eylül Üniversitesi,Izmir,Turkey,['1703'],18.8,0.18295454545454545,0.4068722943722944,1,0.12558139534883722,0.009302325581395349,0.2634146341463415
429,441,441,Programming bsp and multi-bsp algorithms in ml,"The bsml and multi-ml languages have been designed for programming, à laml, algorithms of the respectively bsp and multi-bsp bridging models. multi-bsp is an extension of the well-know bsp model by taking into account the different levels of networks and memories of modern hierarchical architectures. This is a rather new model, as well as multi-ml is a new language, while bsp and bsml have been used for a long time in many different domains. Intuitively, designing and programming multi-bsp algorithms seems more complex than with bsp, and one can ask whether it is beneficial to rewrite bsp algorithms using the multi-bsp model. In this paper, we thus investigate the pro and cons of the aforementioned models and languages by experimenting with them on different typical applications. For this, we use a methodology to measure the level of difficulty of writing code and we also benchmark them in order to show whether writing multi-ml code is worth the effort.",60029689,Universite d'Orleans,Orleans,France,"['1712', '1710', '1708']",26.33333333333333,0.08971861471861473,0.3935064935064935,1,0.09574468085106383,0.047872340425531915,0.31976744186046513
430,442,442,"A casestudy on the use of an innovative, technical, musical instrument, skoog, in a special needs education setting with a child with autism and its effects on social skills","The aim of the study was to explore the use of a unique musical instrument called Skoog in a special needs education setting with a child with autism. A case-study approach was adopted. Emphasis was placed on the potential of Skoog, which increases the participant’s initiation to make eye-contact and to initiate a conversation or other forms of communication. The participant was a 4-year-old boy with autism. The participant received 21 sessions of therapy, with outcomes from the sessions utilizing Skoog being compared to the outcomes from sessions not utilizing Skoog. The sessions were filmed, and pre-and post-intervention evaluations were carried out. The results did not yield any statistically significant difference between Skoog and non-Skoog sessions. A greater amount of verbal communication was recorded during the non-Skoog sessions. This might be because the participant used music, instead of language, to communicate when using Skoog. These results contradict findings from previous studies. A large-scale study with a greater number of participants is needed to further evaluate the use of Skoog in special needs education setting.",60006242,UCL Institute of Education,London,United Kingdom,['1706'],15.818181818181818,0.1975108225108225,0.5508658008658008,1,0.11594202898550725,0.033816425120772944,0.2864583333333333
431,443,443,"Introducing abstraction, diversity, and speech dynamics"," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.The editorial provides an overview of the main themes that are covered by the seven papers that form part of the special collection.",60028717,Ludwig-Maximilians-Universität München,Munich,Germany,['1706'],31.0,0.2797619047619048,0.5309523809523811,0,0.10810810810810811,0.0945945945945946,0.39436619718309857
432,444,444,Partial transmit sequence and selected mapping schemes for PAPR Reduction in GFDM systems,"Generalized Frequency Division Multiplexing (GFDM) is one of the 5G candidates to overcome the shortcomings of Orthogonal Frequency Division Multiplexing (OFDM), high peak rating power ratio (PAPR), and high Out of Band (OOB) radiation. GFDM has a low PAPR due to the use of a number of subcarriers. The purpose of this paper is to compare the two algorithms to reduce PAPR if applied to the non-linear distortion-affected GFDM system. Partial Transmit Sequence (PTS) and Selected Mapping (SLM) are selected because these techniques do not distort the signal, so they do not change the spectrum of the signal. The simulation result shows PAPR GFDM is not significantly affected by nonlinear distortion. After being given the PTS technique, the PAPR value on GFDM dropped to 5 dB. Meanwhile, after being given a selective mapping technique, the PAPR value in GFDM dropped to 6.2 dB.. However, for a 5G application with thousands of devices, this value should still be reduced. After being given a PTS, the PAPR value drops to the value according to the 5G criterion. Better PTS performance decreases PAPR for GFDM systems that are given nonlinear distortion when compared to SLM.",60114085,Universitas Semarang,Semarang,Indonesia,['1700'],19.2,0.05821428571428571,0.49,1,0.09606986899563319,0.1615720524017467,0.4439461883408072
433,445,445,Inductive learning of locality relations in segmental phonology," This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (CC-BY 4.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. See http://creativecommons.org/licenses/by/4.0/.This paper reports on a series of artificial grammar learning experiments focused on locality relations in patterns of long-distance consonant agreement (harmony) and disagreement (dissimilation). Participants in experimental conditions were exposed to dependencies affecting stem-suffix pairs of liquids at either a short-range (transvocalic, CVCVLV-LV) or medium-range (beyond-transvocalic, CVLVCV-LV) distance. Two experiments used a poverty of stimulus paradigm, offering no information about the other distance level; participants interpreted short-range interaction as a strictly transvocalic dependency but medium-range interaction as unbounded, generalizing to other distances. Two experiments employed a 'rich stimulus' paradigm, where training data unambiguously indicated the absence of any dependency at the other distance; this enabled probing of specific locality patterns, in particular strictly beyond-transvocalic dependencies. The constraint-based Agreement by Correspondence model of non-adjacent consonant interactions predicts such patterns to be possible for dissimilation but not harmony. The results do not support this hypothesis: Participants seem to have serious difficulty learning strictly beyond-transvocalic dependencies of either kind. Our findings are more consistent with recent proposals that the space of learnable phonotactic restrictions is delimited by the Tier-based Strictly 2-Local class of formal languages. Strictly transvocalic and unbounded dependencies lie within this region, whereas strictly beyond-transvocalic dependencies are more complex, falling outside the learner's hypothesis space.",60028897,"University of Ottawa, Canada",Ottawa,Canada,['1706'],27.11111111111111,0.07935606060606061,0.4772727272727274,0,0.07936507936507936,0.044444444444444446,0.4092526690391459
434,446,446,The digital competence of future teachers: Self-assessment in the context of their development,"In the context of a transforming school of the 21st century and in the context of the digital transformation of the economy and education globally, the digital competence of pedagogical specialists is crucial for the implementation of the new professional roles of the teacher in response to the ever-increasing requirements for it. This article examines the framework of teachers' digital competency by specifying the main competencies that guarantee their full practical experience. The empirical study presents a selfassessment of the digital competence of future pedagogical specialists trained in the professional field of pedagogy, as well as highlights from their real possibilities of solving specific practical tasks based on the application of information and communication technologies. Some recommendations have been made to rethink the education of future pedagogical specialists and the professional qualification of current teachers in the context of the formation and development of their digital competence.",60070358,South-West University Neofit Rilski,Blagoevgrad,Bulgaria,"['1706', '1705']",36.75,0.06265151515151515,0.19064393939393945,1,0.07051282051282051,0.0,0.19480519480519481
435,447,447,Multiobjective memetic algorithm based on adaptive local search chains for vehicle routing problem with time windows,"This paper presents a multiobjective memetic algorithm based on adaptive local search chains (MMA-ALSC) for vehicle routing problem with time window (VRPTW) which is an important research area in logistics. As shown in most previous studies, VRPTW is essentially a multiobjective optimization problem and can be solved effectively by the multiobjective algorithms with various local search operators. We have observed, however, that the promising solutions obtained during the process of evolution are not fully utilized to guide the search together with different local search operators. This will lead to the discontinuous and insufficient search in the regions showing promise. To alleviate this drawback, MMA-ALSC is proposed and characterized by combining a multi-directional local search strategy (MD-LS) with an enhanced local search chain technique (eLS-Chain). In MMA-ALSC, on the one hand, with MD-LS, different local search operators are designed to perform the search towards multiple directions with distinct problem-specific knowledge of multiobjective VRPTW (MOVRPTW). On the other hand, with eLS-Chain, the promising solutions obtained during the process of evolution are adaptively selected for the subsequent local search operators. In this way, MMA-ALSC can not only effectively explore the search space in multiple directions, but also fully exploit the promising solutions in a chain-based way. Experimental results on two suites of benchmark instances have demonstrated the competitive performance of MMA-ALSC when compared with other representative algorithms.",60006106,Huaqiao University,Quanzhou,China,"['1707', '1702']",24.88888888888889,0.09938271604938273,0.34320987654320984,1,0.09712230215827339,0.07194244604316546,0.3425196850393701
436,448,448,Talk for collaborative learning in computer-based music production,"This article presents a case study exploring the interrelationship between talk and learning in collaborative computer-based music production. Framed by Neil Mercer and Karen Littleton’s Sociocultural perspective on collaborative learning, research on talk and ‘thinking together’ for learning, this study observed two undergraduate composers as they co-produced a contemporary dance film soundtrack across one academic term. The composers recorded their collaboration, providing data for a systematic moment-by-moment micro-analysis focusing on the audio-visual aspects of this project over twelve weeks. Sociocultural discourse analysis methods were used to explore how social, cultural and concrete situations shaped the students’ developing common knowledge. Interaction analysis has been used to code turn functions and display talk characteristics and patterns. This research found that collaborative computer music production is a ‘cumulative conversation’, comprised of many ‘thinking spaces’ that foster ‘post-dialogic’ activ-ity’ and ‘connection building’. In this case the students developed new ‘tools for progressive discourse’ providing them access to the remote and private ‘thinking spaces’ that are characteristic of longer-term co-creating. This research argues for the development of new pedagogies that focus on understanding how talk shapes collaborative learning within music technology.",60032343,University of Huddersfield,Huddersfield,United Kingdom,['1706'],23.25,0.06585081585081587,0.2987762237762238,1,0.11864406779661017,0.01694915254237288,0.34101382488479265
437,449,449,Energy sustainability: a definition and assessment model,"Energy is the fundamental component of all economic activity and a central ingredient of international politics. Energy is finite and often creates externalities. A fundamental question then arises about its sustainability. Assessing energy sustainability is important since energy is a key factor of all economies. However, energy generation imposes large pressures on the environment and is mostly based on limited resources. Energy sustainability is related with the provision of adequate, reliable, and affordable energy, in conformity with social and environmental requirements. In this paper we develop a mathematical model that defines and measures energy sustainability for a given region or country. It is based on a number of indicators that cover such aspects as environmental impact, access, health, economy, generation, consumption, and security. Statistical methods and fuzzy logic reasoning lead to an index in [0, 1] and a subsequent ranking. A sensitivity analysis discovers those aspects of an economy that have the highest potential for improving energy sustainability. The model, unlike most existing ones, is nonlinear and uncovers some counterintuitive results such as the higher rankings of Brazil over the USA and Canada. Such results are explained by the high performance of Brazil in the area of energy security and the low scores of the USA and Canada in generation, consumption, and environmental aspects of energy.",60022461,Technical University of Crete,Chania,Greece,['1703'],18.0,0.11997732426303855,0.4148299319727891,1,0.061224489795918366,0.024489795918367346,0.30612244897959184
438,450,450,‘Waiting for the wow factor’: Perspectives on computer technology in classroom composing,"Due to advancements, affordability and increased accessibility of technology, composing using computer technology has become prevalent in English secondary music classrooms. Despite this, there is still little research investigating the use of technology in music classrooms, resulting in teaching and learning approaches going unchallenged. This article explores how and why computer technology is being used for composing in upper secondary school music classrooms in England. Data were collected through a mixed-methodology approach involving five case-study schools and a survey of 112 classroom music teachers in England. Findings outline both positive and negative aspects of using computer technology to compose, such as how it was often perceived as a shortcut; however it can be argued that the computer software encourages a linear approach to composing, and the unrealistic Musical Instrument Digital Interface (MIDI) sounds can be a demoralising factor for students’ creativity.",60100434,Birmingham City University,Birmingham,United Kingdom,['1706'],28.2,-0.1237689393939394,0.3267045454545455,1,0.1375,0.04375,0.358974358974359
439,451,451,Using multiobjective optimization models to establish healthy diets in Spain following Mediterranean standards,"Last reviews show how the Spanish consumption patterns have become away from the Mediterranean diet, traditionally consumed in Spain and widely supported by the nutritional expert community. Hence, the aim of this study is to explore and provide different alternatives to the current Spanish diet. The idea is to obtain a set of palatable diets fulfilling the nutritional requirements and conform the Mediterranean standards, while staying as close as possible to the current population pattern, under a budget constraint. In this context, different models are developed using multiobjective techniques. Additionally, this work defines an alternative diet more stable in comparison with the diets on the boundary of the feasible set. The consumption data used in this study is taken from Ministerio de Agricultura y Pesca, Alimentación y Medio Ambiente (in Spanish MAPAMA) that contains relevant information about the foods consumed in Spain. Using this data, each model has been solved with Matlab Software, obtaining different feasible diets, whose composition corresponds to the suggested daily intake for a Spanish adult. In any case, the budget constraint reduces the current cost and fulfills the nutritional requirements, attending to the Mediterranean standards. Results show different food baskets to guide the current Spanish diet towards the consumption of healthy foods in the appropriate proportions, going back to the diet traditionally consumed.",60003662,Universidad de Malaga,Malaga,Spain,['1703'],24.11111111111111,0.07692307692307693,0.38333333333333336,1,0.12033195020746888,0.07468879668049792,0.33195020746887965
440,452,452,Efficient similarity join for certain graphs,"Graphs have been widely applied in many real applications like knowledge mining of social networks, pattern recognition, biological analysis, etc. However, precise matching for large graphs has been proven to be a NP-hard problem. In the context, an efficient similarity join method is proposed to quickly seek similar candidate graph pairs from a large number of graphs in the paper. It is a new method, where local sensitive hash (LSH) and Minhash are used to sharply reduce the time needed to compare candidate graph pairs as well as improve the quality of similarity matching through graph associated vertex degree matrix. Furthermore, the bound filtering strategy is adopted to avoid invalid comparing between graph pairs, which can improve graph similarity join efficiency. To test the advantages of our method, various experiments on synthetic data and real data were conducted. The results of these experiments illustrate that the method in this paper has both good efficiency and effectiveness. In terms of the running time and the precision of the algorithm, the new method yields better results than the other similar methods.",60108788,Ningde Normal University,Nongde,China,['1708'],22.375,0.1658982683982684,0.4528950216450217,1,0.0945273631840796,0.04975124378109453,0.2613065326633166
441,453,453,Artifacts analysis in EEG signal with data driven parameters,"Electroencephalography (EEG) data are utilized to structure helpful markers that go about as intermediaries for identifying human’s psychological exercises. In any case, these electrical signals are powerless to various types of interferences known as artifacts from willfully and automatically muscle developments that incredibly dark the information in the signal. It is relevant to plan powerful artifact expulsion techniques (ARTs) fit for expelling or decreasing the effect of these artifacts. In any case, most ARTs have been concentrating on dealing with a couple of explicit types, or a solitary type, of EEG artifacts. EEG handling that sums up to various types of artifacts stays a significant test. EEG is an aggregate of short transient pulse containing critical obsessive information, and interference. There are fundamentally two points of interest of EEG over different techniques. Right off the bat since it is non-obtrusive and simple to look at the regular human articles. Furthermore it has great time goals which contribute better transient elements of brain mechanisms.",101741144,Sri Satya Sai University,Puttaparthi,India,['1700'],18.11111111111111,0.14553571428571427,0.509739010989011,1,0.10326086956521739,0.02717391304347826,0.3333333333333333
442,454,454,A contemporary interior design inspired from Al qatt Al asiri heritage art in Saudi Arabia residential spaces,"Arts and crafts are a mirror of nations and their heritage, reflecting a part of their culture and distinct local character. Saudi Arabia has an authentic artistic heritage stemming from its cultural and environmental diversely. The Asir region is rich in its various decorative arts. AL qatt Al asiri art is one of the ancient heritage arts in Asir region in Saudi Arabia. In 2017, this heritage has been recognized by the UNESCO (The National World Heritage).This paper discusses how to prevent the extinction of Al qatt Al asiri art heritage, and the way of developing it through contemporary designs and its application in interior residential spaces.The main target of the study is reinterpreting Al qatt Al asiri art. While emphasizing the interior designers' role in preserving the national Saudi heritage ant art. The research methodology is based on an analytical and experimental approach.The researcher implemented AL qatt Al asiri art within Saudi Residential unit in contemporary manner. The study concluded that Al qatt Al asiri art is rich in its aesthetic values and qualities. Providing the designers generally and the interior designers particularly with creative inspirations and new design solution. The study highlighted the benefits of preserving Saudi Arabia cultural heritage and reflected its identity in novel interior design projects.",60030736,King Faisal University,Al-Ahsa,Saudi Arabia,['1700'],21.1,0.20802139037433154,0.4473262032085561,1,0.06956521739130435,0.12608695652173912,0.3333333333333333
443,455,455,Characterization of the set of all k-g inverses of k-regular intuitionistic fuzzy matrices,"In this paper, we discuss the characterization of the set of all k-g inverses of k-regular intuitionistic fuzzy matrix and characterized the set of various k-g inverses associated with an intuitionistic fuzzy matrix.",60114598,"Government Arts College, Coimbatore",Coimbatore,India,['1700'],33.0,0.0,0.5,1,0.07317073170731707,0.0,0.2571428571428571
444,456,456,Effectiveness of Microbial (Entomopathogenic) agents and botanical extracts against small rice grasshoppers (oxya hyla hyla),"The use of agro-chemicals and bio-pesticides are the most important and effective tool available to the rice farmer to eradicate the pest problem. Excessive dependence on synthetic chemicals has created various problems including pest resistance and environmental pollution leading to health hazards. Hence, it was necessary to evaluate the insecticidal properties of biological products which are comparatively safe, effective and easily available. In this study,five microbial organisms and four botanical extracts were evaluated against O. hyla hyla in the crop field. Among the microbial agents, maximum (95.83%) mortality was recorded by Penicillium citrinum with both the concentrations (0.4 and 0.8%) and Trichoderma viride with higher concentration (1.0%) after a week. As the period of treatment increases the performance of these agents effectiveness were also increased and vice-versa. Among the botanical extracts, E. odoratum proved better performance over other plant leaf extracts as their residual life persists up to a week. Among the two solvents (Methanol, Petro-benzene), methanol proved to be the best against the O. hyla hyla pest species. ANOVA indicated significant different performances among all the treatments in both the biological products.",60113433,"Science College, Kokrajhar",Kokrajhar,India,['1700'],15.25,0.321875,0.6281249999999999,1,0.0593607305936073,0.0639269406392694,0.3744075829383886
445,457,457,Developing FIA5 to FSTPR25 for modeling spatio-temporal relevancy in context-aware wayfinding systems,"Wayfinding or leading a moving user from an origin to a target is one of the main research focuses in urban context-aware systems. Space and time are two dominant properties of the context-aware wayfinding process and spatio-temporal relevancy between the fixed urban entities and the moving users determine whether an entity is related to the moving user or not. This paper specifically concentrates on the development of customized fuzzy interval algebra (FIA5) for detecting spatio-temporally relevant contexts to the user. This paper integrates fuzzy spatial and temporal intervals and customizes the spatio-temporal relations between the new data models—called fuzzy spatio temporal prism relevancy (FSTPR25) model-based on Allen’s fuzzy multi interval algebra. In this implementation, the FSTPR25 helps the tourist to find his/her preferred areas that are spatio-temporally relevant with two optimistic and pessimistic strategies. The experimental results in a scenario of tourist navigation are evaluated with respect to the accuracy of the model in 450 iterations of the algorithm in 15 different routes based on the statistical quantifiers in Tehran, Iran. The evaluation process demonstrated the high accuracy and user satisfaction of the optimistic strategy in real-world applications.",60022927,University of Tehran,Tehran,Iran,['1700'],26.857142857142854,0.13300275482093665,0.4298071625344352,1,0.0990990990990991,0.03153153153153153,0.2955665024630542
446,458,458,"A comprehensive survey on computer-vision object detection, segmentation, tracking, and feature extraction","Computer-Vision [CV] applications like surveillance, autonomous vehicle navigation involves object detection and tracking using multiple features[1]–[4]. Video surveillance technology can be effectively implemented in a real-time application like public security, logistics management, and others, which involves continuous monitoring of the environment. In a video sequence, moving object detection from a video is the primary step which helps in object tracking and behavior understanding. Video surveillance in a dynamic scene with objects like vehicles and humans is a challenging task in the CV. Moving object detection involves designing efficient video surveillance algorithms for complex environments like the variation in illumination, brightness and environmental effects. Capturing and studying the moving object segmentation is an important task in vision-based object movements. Monitoring human behavior is an important task in a security surveillance system, hence it has become an active research area due to the need for such systems in civic areas. Object tracking based algorithms such as point tracking, Kernel tracking, and Silhouette tracking detect immobile background objects when the camera is fixed and the change in illumination condition is sluggish, and they separate foreground objects from the present frame. Static background surveillance systems are monitored by individuals, viewing several screen display through various camera feeds. Dynamic background detection is very difficult. Manual detection of the dynamic scene is very less effective. Hence leads to automating the entire process. Processing of a large amount of data in a video sequence which makes manual initialization cost-prohibitive. Research in CV has addressed semi-automatic and automatic methods to automate the contents of video data, to aid human operators. Advances in computation and communication techniques have increased the research interest in automating video content analysis. Research interest in Object detection, segmentation, tracking, and feature extraction areas have grown vastly over the years and hence this paper presents a summary of these fields. It analyses the literature according to various CV disciplines, the successes demonstrated, and the applicability of the research to real-world problems.",60070217,R.V.College of Engineering,Bengaluru,India,['1700'],19.176470588235293,0.08964285714285715,0.4727301587301586,1,0.096,0.010666666666666666,0.34688346883468835
447,459,459,Robust metamodels for accurate quantitative estimation of turbulent flow in pipe bends,", part of Springer Nature.Pipe bends are inevitable in industrial piping systems, turbomachinery, heat exchangers, etc. Computational fluid dynamics (CFD), which is commonly employed to understand the flow behavior in such systems has very accurate estimation but is computationally cost intensive. Thus, in this paper, an efficient computational approach for such computationally expensive problems is presented. Using genetic programming (GP), metamodels are built using a small number of samples points from the CFD data. These GP metamodels are then shown to be able to replace the actual CFD models with considerable accuracy. The applicability and suitability of the GP metamodels are validated using a variety of statistical metrics on the training as well as independent test data. It is shown that the use of metamodels leads to significant savings in computational cost.",60107570,"Narsee Monjee Institute of Management Studies University, Shirpur",Shirpur,India,"['1712', '1706']",18.857142857142858,0.034230769230769245,0.5152564102564103,1,0.07894736842105263,0.05263157894736842,0.37333333333333335
448,460,460,Temperature dependence of dielectric conductivity in KTaxNb1-xO3 system for x ≤ 0.5,"Pellet samples of mixed potassium tantalate niobate (KTax Nb1-xO3), for compositions x = 0, 0.1, 0.2, 0.3, 0.4 and 0.5 were prepared by solid-state reaction method. The calcined mixture was pressed at 0.2 GPa and sintered in a closed furnace to form 8 mm diameter pellets. Temperature variation of dielectric conductivity of the prepared samples has been studied in the frequency range from 0.1 KHz to 1 MHz. Dielectric conductivity has been observed increasing with increasing frequency and with increasing x values, for x ≤ 0.4; for x = 0.5, conductivity decreases at 0.1, 1 and 10 KHz. At 100 and 1000 KHz conductivity decreases for x = 0.3, showing the MPT region. Anomalies have been observed near the transition temperatures of the samples in temperature-dielectric conductivity curves.",60069550,H.N.B.Garhwal University,Srinagar,India,['1700'],21.33333333333333,0.0,0.25,1,0.09333333333333334,0.04,0.4931506849315068
449,461,461,"Gender Politics and Discourses of #mansplaining, #manspreading, and #manterruption on Twitter","This article presents the findings of a corpus linguistic analysis of the hashtags #mansplaining, #manspreading, and #manterruption, three lexical blends which have recently found widespread use across a variety of online media platforms. Focusing on the social media and microblogging site Twitter, we analyze a corpus of over 20,000 tweets containing these hashtags to examine how discourses of gender politics and gender relations are represented on the site. More specifically, our analysis suggests that users include these hashtags in tweets to index their individual evaluations of, and assumptions about, “proper” gendered behavior. Consequently, their metadiscursive references to the respective phenomena reflect their beliefs of what constitutes appropriate (verbal) behavior and the extent to which gender is appropriated as a variable dictating this behavior. As such, this article adds to our knowledge of the ways in which gendered social practices become sites of contestation and how contemporary gender politics play out in social media sites.",60100434,Birmingham City University,Birmingham,United Kingdom,['1706'],30.8,0.11388888888888893,0.23472222222222225,1,0.10285714285714286,0.011428571428571429,0.3485714285714286
450,462,462,An overview on trend of border trade between India and Myanmar,"The north east region of India shares huge border with neighbour countries like Bhutan, Bangladesh, Nepal, Myanmar and China. The region has the potential to transform into a principal gateway of international trade. Myanmar could be the bridge in connection with other south Asian countries. Indian states Manipur and Mizoram shares border with Myanmar. Government of India collaborating with the government of Myanmar has established two land custom stations in Moreh (Manipur) and Zowkhathar (Mizoram). The border trade through Moreh is found in fluctuation. In initial period (1995-96 to 1997-98) the trend of border trade had increased but later on it found declining.",60016850,Gauhati University,Guwahati,India,['1700'],14.714285714285715,0.0392857142857143,0.325,1,0.06504065040650407,0.15447154471544716,0.3865546218487395
451,463,463,Formulation and evaluation of sustained release matirx tablet of vildagliptin using natural and synthetic polymers,"The aim of this paper was to evulate vidagliptin matrix tablet of 50 mg. Vildagliptin is an anti diabetic drug of new dipeptidylpeptidase – 4 (DPP-4) inhibitor class of drug Vildagliptin is one of the best passed relefing and short acting drug. Medication is developed in such a way that will provide the full advantage of SR formulations. The natural polymer like pectin was utilized in the formulation of the matrix tablet with the help of wet granulation technique we can find out the characteristics and evaluation of drug containing vildagliptin. Pectin is one of the hydrophilic polymer was utilized in the formulation of these tablets and all the formulation showed the pharmacopeian standard. There are six different types of formulation of drugs with polymer concentration, first three drugs contain pectin polysaccharide and the other three contain polymers combination of pectin HPMC K100M-F1 (1:1), F2 (1:2), F3 (1:3) F4 (1:1), F5 (1:2) and F6 (1:3). Some all the above formulation F6 is the best and show best result up to 12 hrs. It is also absorbed that F6 with pectin combination shows better sustain effect. These result shows that drug release kinetic was absorbed by increasing their polymer concentration. The data which was collected was fitted to various models (mathematical model) like higuchi, first-order and zero order, to find out the mechanism of drug release. F6 shows higuchi model. So the present study evaluate the drug release (vitro) by interchanging are changing the amount of polymer according to patient compliance and improvement.",107592597,NKBR College of Pharmacy and Research Centre,Meerut,India,['1700'],21.0,0.218698347107438,0.3642217630853994,1,0.09931506849315068,0.06164383561643835,0.3344947735191638
452,464,464,Columbus sustainable energy converter,"Now-a-days “Energy Conservation” is the word on which the world is focusing its vision. Electric energy has become the most prominent source of energy for driving any device. Most of the mechanical devices run with the help of electrical energy. The production of electric energy is expensive. In developing countries like India, electric power is generated economically from thermal power plants. The methods of producing electric power in these countries is enormously polluting the atmosphere leading to adverse problems like global warming, green house effects etc., So, reducing the use of electric power wherever possible can reduce our dependency on electric power there by reducing air pollution. Conservation and reutilization of energy can be done by effective usage of sustainable energy sources. Finding suitable energy sources and extracting specific work output from them plays a prominent role in energy conservation. One among them is “Columbus Sustainable Energy Converter”. In the present work, a cotter reciprocating pump horizontally is fitted suitably for a cradle. When the cradle oscillates to and fro it is converted into reciprocating motion of the pump by means of fulcrum. This type of conversion mechanism can be used for cradles in public gardens, schools for pumping water, and sprinkling through sprayer. The working mechanism and construction details of the pump are clearly discussed in the work.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],16.846153846153847,0.2,0.5691176470588235,1,0.11693548387096774,0.04032258064516129,0.2757201646090535
453,465,465,Accelerating innovation and problem solving in engineering by design thinking,"The most demanded skills by various studies and bodies including World Economic Forum calls upon compound problem-solving, critical thinking, creative mind set, emotional intelligence, and decision-making in employable graduates [1]. The importance of higher order thinking and innovative solution skills are required in entrepreneurship as well as in intrapreneurship. More and more employers want employees that can innovate and create products which are more cost-effective, user-friendly and financially viable. The onus to deliver such skills is now on education bodies. The need for the course which judiciously balances and supplies the demand of the industry from the campus spurred the designing of the course Design Thinking. This paper will be exploratory in nature and will also present a case study of one of the premier institute of western region which is teaching Design Thinking course to its B.Tech students. The author has devised such a course and has used a scaffolding approach to include cognitive skills in the future innovators and creators. Understanding that product, idea or process will be developed by these engineers which will impact the society in problem-solving. The paper will showcase the pragmatic approaches taken and transferring experience into design thinking-an empathy-based, human-centered, and solution-driven methodology for innovation. Design thinking also helps to tackle challenges such as the creation of new products, technological innovation, processes and/or systems. This paper will expound upon the content, pedagogy and assessment. Since this is one of the types, of course, running in an engineering college, it becomes urgent to validate the curse and its intended outcome.",60115002,"Nirma University, Institute of Technology",Ahmedabad,India,['1700'],21.33333333333333,0.18431818181818185,0.4514772727272728,1,0.1390728476821192,0.029801324503311258,0.3028169014084507
454,466,466,Identification and classification of defects at different leather processing stages using vision based system,"Leather is a natural material with varying texture as in case of raw leather as well as processed one. The leather at any stage of processing may prone to various defects. Leather inspection has been recognized as a very complex problem on the area of texture classification. Like most of the natural surface, values have a high variation, framing a pseudo-arbitrary structure, with an analytical distribution. Leather deformities can have numerous shapes and sizes relying upon the imperfection. Identifying all these defects at various leather processing stages were a major challenge in leather industries. In this proposed method, a novel methodology has been developed that automatically and efficiently inspects various leather defects that occur at various leather processing stages. Further based on some of the first and second order statistical features, the common type of defects occurring in leather such as defect due to insects, scar, stain, cut and crack and can also be classified by using the proposed method and the results obtained were plotted in Graphical User Interface (GUI).",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],21.375,0.0119331983805668,0.4384143049932523,1,0.11518324607329843,0.020942408376963352,0.31216931216931215
455,467,467,Role of entrepreneurship in empowering women-an empirical study in Rayalaseema Region,"The study was limited to women entrepreneurs and confined to four selected places of Rayalaseema region. The present study is confined to assess the role of entrepreneurship in empowering women. The paper aims outlining and functioning of 240 women entrepreneurs selected based on Stratified Random sampling method in Rayalaseema region (Anantapur, Chittoor, Kadapa & Kurnool) of Andhra Pradesh. Especially discussions and individual interaction have been conducted with 240 women for collection of relevant data in the preparation of this study. The data were collected through questionnaire method and subsequently arranged in tabular forms to infer conclusions. The study has been made on the basis of secondary and primary data. An Empirical Research design has been used in this study. It is a way of gaining knowledge by means of direct and indirect observations or experience. It is a measurable phenomenon and derives knowledge from actual experience. The information thus collected from various sources have been processed, tabulated, analyzed and interpreted with the help of computer software Microsoft Excel, SPSS and statistical tools. Mathematical and statistical techniques like percentages, averages, chi-square test and ANOVA to reach logical conclusions.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],17.0,0.025238095238095243,0.3428571428571428,1,0.11961722488038277,0.08133971291866028,0.36231884057971014
456,468,468,To study AC electrical conductivity of TiO2 doped polyaniline,In the present research work we make a pallet of PANI+TiO2 and then we determined the AC electrical conductivity of polyaniline and polyaniline doped TiO2. Effect of Temperature on A.C. conductivity at varying frequency is also studied.,124041499,M.F. Arts Commerce and S.C Science College,Amravati,India,['1700'],12.333333333333336,0.0,0.0,1,0.1282051282051282,0.05128205128205128,0.3333333333333333
457,469,469,Fast Internet Packet and Flow Classification Based on Artificial Neural Networks,"Internet traffic classification is an increasingly important task for enhancing security, quality of service and management. However, there are challenges to accurate classification, tool selection/configuration and leveraging available information. This paper presents the study and design of neural network structures for the classification of Internet packet and flow traffic. The usually challenging task of determining an effective architecture for artificial neural networks is exacerbated in this case by the fact that traditionally relied upon techniques such as principal component analysis show reduced effectiveness. Presented here are the techniques and experimentation for preprocessing datasets and selecting input traffic features for the multi-layer perceptron architecture. The neural network architecture is also determined via experimentation. We show that this methodology can achieve aggregate traffic classification accuracy above 99% and individual protocol and flow recognition above 98%. Significantly, these recognition rates are for contemporary traffic types tested on several recently constructed datasets. We also compare the results for manual feature selection against principal component analysis.",60001777,Rochester Institute of Technology,Rochester,United States,"['1705', '1712', '1711']",17.88888888888889,0.14944444444444446,0.5316666666666666,1,0.09444444444444444,0.0,0.2784090909090909
458,470,470,Multi-hop communications inside cellular networks: A survey and analysis," J. Elec. & Elecn. Eng. & Telcomm.The access part of all cellular networks generation suffers from common issues related to dead spots (parts that are not covered by the network) and hot spots (parts where the number of users is huge compared to network resources). During the last eighteen years, lots of research proposals have tried to overcome cellular problems through MCN (multi-hop cellular networks) architectures which is a new paradigm allowing the extension of cellular access part via ad-hoc networks. In this paper, we propose a survey of different MCN architectures. We identify the key MCN classification factors, we compare the proposed architectures with advantages and drawbacks of each one, and then we discuss some open issues related to this subject.",60107436,Université Bourgogne Franche-Comté,Besancon,France,['1705'],15.375,-0.03694638694638693,0.5465034965034965,0,0.0821917808219178,0.0547945205479452,0.4028776978417266
459,471,471,Features of the freedom issues in the plot's philosophy,"The article detailed Plotin's philosophical views, the various analysis of the concept of freedom, his interpretation of human, oneness, and intellectual freedom in the light of contemporary philosophers, and their criticisms of some flaws in Plotin's teachings. It was shown that the role of human freedom in the creation of Plotin and the issue of eternal freedom of singularity was very important. Our goal is to rely on sources and analyze Plotin's philosophical views and ideas on freedom. Plotin's Enneadas reveals a multidimensional approach to freedom.",60071655,National University of Uzbekistan named after Mirzo Ulugbek,Tashkent,Uzbekistan,['1700'],21.5,0.1786666666666667,0.3716666666666667,1,0.050505050505050504,0.06060606060606061,0.30303030303030304
460,472,472,"Evolution, transformation and biological activity of degraded soils","The features of morphogenetic characteristics, degree of gypsation and salinization, humus state, total chemical composition, time history (over the years) of gray-brown, desert-meadow, meadow-alluvial, marsh-meadow soils of the territory are considered in the paper; the formation of a new genetic group of soils as a result of ecological-genetic aspects, transformation and evolutionary changes in the soil processes occurring under anthropogenic factors are determined; the formation of prairiefication processes as a result of soil transition from the automorphic to the semi-hydromorphic and hydromorphic regimes under the influence of the Tuyamuyun reservoir is determined; soil fertility of the territory is estimated according to their current state and properties; soil and soil-assessment maps, as well as the maps of crops distribution are developed. Determination of the influence of gypsum content and degree of salinization on enzymatic activity (catalase, peroxidase, polyphenol oxidase) and “soil respiration”, as well as on their alterations over the seasons of year; indicators of biological activity (BA), total relative biological activity (TBA) of soils, indicators on soil degradation have been developed. The aim of research is to determine the current state of the Tashsaka Plateau soils, their evolution and climatic conditions, fertility assessment and the development of measures aimed at distribution of agricultural crops, is a comprehensive study of the seasonal dynamics of the basic properties and biological activity of gypsum soils, development of criteria for the indicator of their degradation. The objects of study are the virgin and irrigated gray-brown, gray-brown-meadow, desert-meadow, meadow and marsh-meadow soils spread in the Tashsaka Plateau and adjacent territories of the Khazarasp region of Khorezm district, are gypsiferous and saline gray soils, meadow-gray soils, gray soils-meadow, meadow, meadow-marsh soils, as well as salt marshes soils, common in Zarbdar district of Jizzakh region.",60112778,Tashkent State Agrarian University,Tashkent,Uzbekistan,['1700'],72.0,0.0036363636363636377,0.3979545454545454,1,0.038356164383561646,0.06027397260273973,0.3492537313432836
461,473,473,"A Safe, Secure, and Predictable Software Architecture for Deep Learning in Safety-Critical Systems","IEEEIn the last decade, deep learning techniques reached human-level performance in several specific tasks, as image recognition, object detection, and adaptive control. For this reason, deep learning is being seriously considered by the industry to address difficult perceptual and control problems in several safety-critical applications (e.g., autonomous driving, robotics, and space missions). However, at the moment, deep learning software poses a number of issues related to safety, security, and predictability, which prevent its usage in safety-critical systems. This work proposes a visionary software architecture that allows embracing deep learning while guaranteeing safety, security, and predictability by design. To achieve this goal, the architecture integrates multiple and diverse technologies, as hypervisors, run-time monitoring, redundancy with diversity, predictive fault detection, fault recovery, and predictable resource management. Open challenges that stems from the proposed architecture are finally discussed.",60028039,Scuola Superiore Sant'Anna di Studi Universitari e di Perfezionamento,Pisa,Italy,['1700'],22.5,-0.03958333333333333,0.40989583333333335,1,0.09826589595375723,0.0,0.38181818181818183
462,474,474,Holiday brides marriages vis-a-vis NIR bill 2019-issues and challenges in India,"This Article is to pendown the marital problems of middle class women/girls married huriedly to NRIs on vacations and labelled as ‘holiday brides’. Further this article focuses on the issues and challenges faced by the abandoned brides as to their stridhan, stigmatization in society, orders from foreign courts and there implementations, passive approach of foreign embassies and police in India and upbringing of kids. This article also emphasises on the Non –Resident Indian Bill, 2019 introduced in Rajya Sabha on legal method for booking the absconding NRI grooms who have mercilessly desserted the innocent wives/brides. A concern has been raised for applying rules of Private International law [PIL] in these cases involving NRIs on vacations deciving Indian girls.",60116871,Bharati Vidyapeeth New Law College,Pune,India,['1700'],29.5,5.551115123125783e-18,0.3275,1,0.1111111111111111,0.06666666666666667,0.4461538461538462
463,475,475,Experimental investigation to obtain the PV module true performance and emphasis on application of soft computing,"With the increasing interest in generation of electricity from Solar Photovoltaic systems, it has become important to evaluate true performance. One of the advantages of renewable energy system that these are distributed in nature and can generate near the load thus almost negligible transmission and distribution losses but another side they suffer from other types of losses so the performance is yet questionable. It is well proven that Solar PV system performance deteriorates, when deployed in natural conditions although manufacturer indicate the efficiency behind the module in STC (1000 W/m2, 250C and A.M. 1.5) but it is difficult to operate at standard efficiency. In this paper attempts are made to observe the natural wind effect on temperature of PV module and to evaluate the module performance by comparing different methods with experimental and simulated values. In order to predict the performance near true value, a neural network based back propagation method is used. This paper will be helpful for project planners to estimate accurate size and performance; with the help of neural network, they can estimate true potential before actual installation. It is noted that considering natural wind cooling effect net energy gain is about 25 Wh and various types of errors like mean square error(MSE), root mean square error (RMSE), Mean bias error (MBE) and Standard deviation error (SDE) are less for cooled module than not cooled module.",60114077,"GLA University, Mathura",Mathura,India,['1700'],28.625,-0.0066358024691358045,0.4958333333333334,1,0.10196078431372549,0.06274509803921569,0.27450980392156865
464,476,476,Role of Hadoop in Big Data Handling,"In this paper big data meaning, big data analytics and big data technologies are discussed. Hadoop ecosystem consisting of many supporting tools for data acquisition, data storage, computation model, query and analysis are also presented. For our experiment in Hadoop environment, Sample data set of temperature analysis has been taken and analyzed the role of combiner in mapper nodes towards reducing network traffic. There is a brief comparison of two leading technologies Hadoop and Spark.",60114322,Nitte Meenakshi Institute of Technology,Bengaluru,India,"['1706', '1705', '1710']",18.75,0.125,0.23055555555555554,1,0.10714285714285714,0.05952380952380952,0.2976190476190476
465,477,477,Controlling a Quadrotor Carrying a Cable-Suspended Load to Pass Through a Window,"V.In this paper, we design an optimal control system for a quadrotor to carry a cable-suspended load flying through a window. As the window is narrower than the length of the cable, it is very challenging to design a practical control system to pass through it. Our solution includes a system identification component, a trajectory generation component, and a trajectory tracking control component. The exact dynamic model that usually derived from the first principles is assumed to be unavailable. Instead, a model identification approach is adopted, which relies on a simple but effective low order equivalent system (LOES) to describe the core dynamical characteristics of the system. After being excited by some specifically designed manoeuvres, the unknown parameters in the LOES are obtained by using a frequency based least square estimation algorithm. Based on the estimated LOES, a numerical optimization algorithm is then utilized for aggressive trajectory generation when relevant constraints are given. The generated trajectory can lead to the quadrotor and load system passing through a narrow window with a cascade PD trajectory tracking controller. Finally, a practical flight test based on an Astec Hummingbird quadrotor is demonstrated and the result validates the proposed approach.",60104676,Suzhou Vocational University,Suzhou,China,"['1712', '1702']",21.777777777777782,0.11964285714285715,0.5362244897959184,1,0.13302752293577982,0.027522935779816515,0.25
466,478,478,Spatial shape feature descriptors in classification of engineered objects using high spatial resolution remote sensing data,"Spatial and spectral features are two important attributes that form the knowledge based database, useful in classification of engineered objects, using remote sensing data. Spectral features alone may be insufficient to identify buildings and roads in urban areas due to spectral homogeneity and similarity exhibited by them. This has led researchers to explore the spatial features described in terms of shape descriptors to improve accuracy of classification of engineered objects. This paper discusses the parameters of spatial shape features and the method for implementing these features for improving the extraction of engineered objects, using the support vector machine (SVM). SVM classified results obtained using spatial shape features is compared with gray level co-occurrence statistical features in which the former has shown better classification accuracy for buildings and roads. The classification accuracy is also calculated using spectral features of buildings and roads by classifiers such as spectral angle mapper and spectral information divergence. The analysis shows that spatial shape features improve the classification results of buildings and roads in urban areas.",60002874,Delhi Technological University,New Delhi,India,['1706'],24.285714285714285,0.10833333333333334,0.28611111111111115,1,0.125,0.021739130434782608,0.36813186813186816
467,479,479,Implementation of low-power built in test compression capabilities in programmable PRPG,"This paper describes a low-power (LP) programmable generator capable of producing pseudorandom test patterns with desired toggling levels and enhanced fault coverage gradient compared with the best-to-date built-in self-test (BIST)-based pseudorandom test pattern generators. It is comprised of a linear finite state machine (a linear feedback shift register or a ring generator) driving an appropriate phase shifter, and it comes with a number of features allowing this device to produce binary sequences with preselected toggling (PRESTO) activity. We introduce a method to automatically select several controls of the generator offering easy and precise tuning. The same technique is subsequently employed to deterministically guide the generator toward test sequences with improved fault-coverage-to pattern-count ratios. Furthermore, this paper proposes an LP test compression method that allows shaping the test power envelope in a fully predictable, accurate, and flexible fashion by adapting the PRESTO-based logic BIST (LBIST) infrastructure. The proposed hybrid scheme efficiently combines test compression with LBIST, where both techniques can work synergistically to deliver high quality tests. Experimental results obtained for industrial designs illustrate the feasibility of the proposed test schemes and are reported herein.",110075219,Vishnu Institute of Technology,Bhimavaram,India,['1700'],26.285714285714285,0.1812121212121212,0.4346969696969696,1,0.14798206278026907,0.03587443946188341,0.36231884057971014
468,481,481,Role of women self-help groups (SHGs) in rural development of India,"Microfinance is one of the most powerful tool contains provisions of savings, credit, insurances and mobilization of fund resources on economic activities among SHGs women. Finance is ensuring poverty alleviation mainly contribute promote the socio-economic empowerment of rural women SHGs in India. SHG–Bank Linkage Programme launched by NABARD way back in 1992 envisaging synthesis of formal financial system and informal sector has become a movement throughout the country. Self Help Groups (SHGs) have become the common vehicle of development process to converge all development programmes. It is considered as the largest microfinance programme in terms of outreach in the world. The commercial banks provide certain help to encouraging and motivation of financial assistance to develop uneducated women creativity of employment opportunities among women SHGs. The present study depends on secondary data. In this study gives a clear picture about the role of women SHGs in rural development, analyze the progress of women SHGs and also identifies challenges faced by the women SHGs. It found that, women SHGs play a vital role in rural development as well as employment generation and eradicate rural poverty. It is necessary to address the challenges faced by the women SHGs and take strategic steps for effective functioning SHGs for improving their standard of living. Hence this leads to improve the financial access among women’s and access timely credit for their empowerment as well as strengthen socio-economically.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],21.0,0.07186147186147185,0.27218614718614714,1,0.11372549019607843,0.027450980392156862,0.32
469,482,482,Energy absorption of thin-walled cylinders under impact load,"This paper aims to numerical study the impact behavior of steel thin-walled tubes with circular cross section. Finite element method (FEM) analysis is used to investigate the deformation behaviors under impact load. Here, ABAQUS/Explicit is applied to study mainly the effect of side wall curvature on the resistance strength of thin wall tube. In addition to, the effect tube wall thickness on the crushing behaviors are studied for different geometric patterns. The results shows the increase of tube side wall curvature tends to decrease the values of first peak loads, which help to control the crushing behaviors of the corrugated tubes in a good manner.",60007948,Beni-Suef University,Beni Suef,Egypt,['1700'],21.0,0.18958333333333333,0.5645833333333334,1,0.11764705882352941,0.025210084033613446,0.25217391304347825
470,483,483,Statistical process control-based inventory policy,"Supply chain is a network of business entities like supplier, wholesaler, distributor, retailer etc. to perform various business functions to meet the needs of an end customer. An effective inventory policy maximizes the customer service level and keeps the total inventory at minimum. Improper inventory policy used generates the bullwhip effect which degrades the performance of a supply chain. In the present work, Statistical Process Control (SPC) based inventory policy is proposed. It’s performance is evaluated in terms of variance of orders, fill rate and total inventory at each stage of a serial supply chain and compared with the performance of order up-to level and moving average demand policies by simulation. Three sets of inventory Decision Rules namely DR1, DR2 & DR3 were developed under SPC policy to optimize future orders and inventory levels. It is found that performance of DR3 is better than other inventory policies.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],18.375,0.0925,0.45,1,0.10240963855421686,0.060240963855421686,0.3333333333333333
471,484,484,Modelling and recreation of semi conducting metal oxide (SMO) gas sensor,"The work is focused on the design of the semiconducting metal oxide gas sensor. This sensor is used for detection and analysis of different type of gases. These gas sensors are of different shape and size, and each metal oxide is used for detecting different types of gases. No two gas sensors are alike. According to the substrate that is being doped on to the sensor, each sensor detects different gases. We will then design the gas sensor in COMSOL software and simulate it. These gas sensors are highly sensitive and hence effect different factors related to surface reactions such as temperature, humidity, chemical components, and structure of sensing layer.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],15.714285714285715,0.0125,0.6,1,0.09836065573770492,0.00819672131147541,0.2786885245901639
472,485,485,Bus tracking system using RFID information over internet of things (IoT),"The Interconnection of physical devices to internet is possible only through IoT (Internet of things).City bus transportation is core part of the public way of transport in urban areas. In this fast life, everyone is hurry to reach their destinations; waiting for buses in bus stops is not reliable. As people wait for long time in bus stops because there is no schedule of buses arrival time, with the bus arrives it travels with over crowed and sometimes it may also lead to travel on footboards and theft is the another possibility of risk in over-crowed buses. To overcome this, “Bus tracking system using RFID information over IoT ” is used, it helps the people to travel more safer and efficient way and also permits to back the current location of the arriving or next arrivin g bus to the bus stop by integrating G SM module, RFID technology by android application and the cloud as server. The reduce in waiting time and overcrowding are the major advantages.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],33.6,0.059375,0.38412698412698415,1,0.11475409836065574,0.02185792349726776,0.2786885245901639
473,486,486,A comparison of lifestyle in employed women and housewives and the factors affecting it,"The present study compares lifestyle in employed women and housewives and its effective factors in Andimeshk city. The statistical population of the study was based on 63082 employed women and housewives, of which 380 women were selected as equal to 190 employed women and 190 housewives. The causal-comparative research method and the lifestyle questionnaire from Kern’s Life Style Scale (1982) were used. The research results indicated that there was a significant difference in lifestyle between the employed and unemployed women; there was a significant difference between the dimensions of lifestyle of both employed and unemployed women;. Finally, the results of the tests indicated that employed women had a higher frequency in modern life than unemployed women. Although these differences were small, they were statistically significant.",60031777,Islamic Azad University,Tehran,Iran,['1700'],20.83333333333333,0.1925,0.5875,1,0.06382978723404255,0.0425531914893617,0.36428571428571427
474,487,487,"Making Affordances Real: Socio-Material Prefiguration, Performed Agency, and Coordinated Activities in Human–Robot Communication","Usually, the alluring notion of “affordances” comes with the idea that technology makes some activities possible while constraining others. Our article departs from this dichotomic view and seeks to appreciate the multiplicity of socio-material prefiguration. Discussing three empirical examples from human–robot communication, we show that the affordances of “smart” technologies are not acted out in a smooth, planned process or through rational action alone. Rather, affordances are collective achievements that emerge within the interplay of humans and machines. This challenges the separation into active use and passive usability. It also demands us that we think through what types of agency are associated with these kinds of agents and what we take to define agency at all. Agency rests, we argue, on the capability to engage in intelligible encounters; it builds on purposive activities even though they might only realize a limited repertoire of tasks.",60008293,University of Bremen,Bremen,Germany,['1706'],20.571428571428573,0.03994708994708995,0.4817460317460318,1,0.13253012048192772,0.0,0.32098765432098764
475,488,488,Domination in hesitancy fuzzy graphs,"In this paper we introduce the domination concept in Hesitancy fuzzy graph and investigate some properties of domination in hesitancy fuzzy graphs and domination in products of hesitancy fuzzy graphs like union, join, cartesian product and composition are investigated.",60114563,"Government Arts College, Salem",Salem,India,['1700'],39.0,0.0,0.0,1,0.07142857142857142,0.07142857142857142,0.2619047619047619
476,489,489,Analysis of perforated steel unequal angle members by using abaqus,"Hot-rolled steel angle sections has many structural applications in industrial plants and lattice power transmission towers. In industries they are used as supporting structures to pipes and elevators, shelves, roof trusses, chimneys, silos, overhead tanks, bunkers and storage pallet racks etc. They are frequently used in roof and lateral braces in industrial structures. Previously for the performance assessment of angle members under compression researchers developed many analytical and experimental methods. The design of angle members are difficult to understand even they have simple structural shape and used in a variety of applications, so they should be examined thoroughly from the designer’s point of view as there is no sufficient experimental data available for angle members in comparison with other standard structural shapes. This paper is concerned with the ultimate load capacity of non-perforated and perforated equal & unequal-angle hot rolled steel columns. A finite element analysis has been undertaken to investigate the behaviour of such members. The software used for finite element analysis in this work is ABAQUS.",60106974,"JNTUA College of Engineering, Ananthapuramu",Anantapur,India,['1700'],21.0,0.08872549019607844,0.4440476190476191,1,0.07894736842105263,0.005263157894736842,0.3081081081081081
477,490,490,A direct proof of convergence of Euler product for Ld(1),A simple proof is given for the convergence of the Euler product (formula presented) discriminant of a quadratic field. The argument holds also for s = 1 + it. The mean of {formula presented} is deduced to be 0.,60017870,Institute of Chartered Financial Analysts of India,Hyderabad,India,['1700'],13.0,-0.15625,0.5223214285714286,1,0.10869565217391304,0.021739130434782608,0.34782608695652173
478,491,491,Performance assessment of feature extraction and classification algorithm using opinion mining," All rights reserved.In the arena of information-gathering, the importance lies in getting to know “what other people think?” The explosion of opinion rich contents sourced from personal web blogs and review sites generates vast research prospects, that to identify and understand people’s opinion based on the information gathered over a product or service. Opinion Mining (OM) is a key field under text mining, helps an organisation to understand consumer attitude, to handle customer relationship, to manage product positioning and branding and in market research. This paper presents an investigative study of the performance of various feature extraction methods and classification algorithms for opinion mining. For the evaluation, opinion datasets about camera product are sourced from amazon website and evaluated. Information Gain based feature selection algorithm is used to extract the features and k-NN Boosting algorithm is used for opinion classification.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],28.2,0.04166666666666666,0.6541666666666667,0,0.14634146341463414,0.04878048780487805,0.310126582278481
479,492,492,A fuzzy logic based pico serving node placement for 5G ultra dense networks,"Ultra dense networks (UDN) are one of the key components of 5G, which can address the coverage and quality of service (QoS) related issues of the user equipments (UE) in dead zones. In this work, a fuzzy based pico evolved node base station (eNB) placement method is proposed to meet the coverage demands, while not disturbing the existing macro eNBs. The simulation results show that the proposed scheme maximizes the coverage, while satisfying budget and interference constraints.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],25.66666666666667,-0.04166666666666666,0.7666666666666666,1,0.13978494623655913,0.043010752688172046,0.391304347826087
480,493,493,Analytical evaluation of the wing box splice joint for static & fatigue loading,"Aircraft is symbol of a high performance mechanical structure with high structural safety record. Safety and the structural weight are important parameters to be considered during the design phase. Analysis is carried out to find all of the theoretical stresses within and predict failure due to unknown stresses by showing stress concentrated areas in the material. Further, fatigue life to crack initiation can also be estimated by local stress strain approach. Based on the analysis the structural design, sizing and optimization is performed to meet the best feasible design. This ensures the safety of an aircraft keeping in account its structural weight. Analysis of the wing box is carried out for static and fatigue loading using finite element analysis.",60107090,Hindustan Institute of Technology and Science,Chennai,India,['1700'],17.0,0.15257575757575756,0.4686363636363637,1,0.1171875,0.0,0.1875
481,494,494,Optimization of hole taper in machining of SS316L alloy sheet using laser beam drilling,"SS316L is a most popular super alloy engineering metal having wide applications in medical implants and aerospace fasteners. Mostly, this alloy has been used in aerospace and medical industries. In laser beam machining (LBM) is used thermal energy for machining process. There is very difficult to machining operation like drilling, cutting etc. on this alloy through laser beam. In present research work, laser drilling has been used to create a precise hole of 2mm diameter on SS316L sheet. Aim of this work is to optimize (minimize) taperness of a drilled hole. Experimental models have been prepared in central composite design with 31 experiments. Response surface methodology (RSM) has been used to validate experimental model. Optimization technique genetic algorithm (GA) has been used to minimize hole taper (HT). Significance of input parameters also discussed for hole taper. Hole taper is reduced (improved) by 16.1% from experimental value while using GA.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],12.416666666666664,0.08555555555555558,0.4744444444444445,1,0.10112359550561797,0.0449438202247191,0.3954802259887006
482,495,495,Parameter identification of nonlinear system using an improved Lozi map based chaotic optimization algorithm (ILCOA),"In this paper, an efficient stochastic optimization algorithm is presented for parameter identification of nonlinear systems. Due to its robust performance, short running time and desirable potency to find local minimums the Lozi map-based chaotic optimization algorithm is an appropriate choice to estimate unknown parameters of nonlinear dynamic systems. To enhance the identification efficacy and in order to escape local minimum, a modified version of this algorithm with higher stability and better performance is rendered in this paper. An Improved Lozi map-based chaotic optimization algorithm (ILCOA) is employed to identify three nonlinear systems and the performance of the proposed algorithm is compared with other optimization algorithms. The simulation results of identification endorse the effectiveness of the proposed method.",60118242,"Department of Precision and Microsystems Engineering, TU Delft",Delft,Netherlands,['1706'],23.6,0.09,0.3316666666666667,1,0.11363636363636363,0.030303030303030304,0.2578125
483,496,496,"Don&#x2019;t Trust, Verify: A Verifiable Hardware Accelerator for Matrix Multiplication","IEEEIn this paper, we propose , a novel application that enables secure integration of an untrusted third-party matrix multiplication hardware accelerator in a system-on-chip containing a trusted general purpose processor. Our solution builds upon the theory of interactive proof (IP) protocols to enable run-time verification of each computation executed on the untrusted accelerator and formally guarantees that any incorrect results are detected with high probability. Our novel optimizations in hardware implementation reduces area and performance overhead of . We show that an FPGA prototype of introduces less than 6.25% DSP area overhead compared to a baseline untrusted matrix multiplication accelerator while enabling 11x-69x speed-ups compared to software execution.",60021784,New York University,New York,United States,['1700'],27.0,0.11083333333333337,0.4266666666666667,1,0.12,0.056,0.33043478260869563
484,497,497,Algorithmic approach for network measurements,"Estimated limit points are large enough for the tendency of appliance companies, for which cables change weight, make arrangements, sensibility, and intrusion of men or women. The limit that requires the goliath counter recommends finding website visitors from all tool streams. While recollections of SRAM items can take a walk to the beat, it's too small even to remember the night considering the night time remember the big hotel's cons of social events. They do establish by the works of the pastStimulator, who trades precision for cloudy areas. To be able, to not forget the essential counters, the systems beautifully buy the accuracy of the second, more famous stand. In this paper, we give prizes to illustrate the exact depiction of estimates. We, at that stage, present a loosened view of the estimation booth, a chosen pointer relationship that increases the accuracy of the forecast for all counters, which held made through the structure to the system. To place separating flow into pressing chambers and sorting out the maximum satisfying estimation symbolizes as indicated by using the respective counter scale manage. We show a remarkable and positive increase in relative failure and an increase in accuracy of fifty-seven exercises at the actual web agency.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],22.66666666666667,0.1879112554112554,0.39828463203463205,1,0.12554112554112554,0.012987012987012988,0.28820960698689957
485,498,498,A secure cloud storage retrieval using cost based iterative deepening depth-first search algorithm,"Nowadays, cloud storage is a popular service for many data owners due to its advantage of high scalability and large-scale storing ability. Data users can utilize its open and highly scalable application interface to store files, pictures, videos, etc. But the data security includes integrity, availability and confidentiality of data has been found to be a major challenge in cloud systems and also it is a main reason why companies avoid cloud service usage. Researchers have been studying the authentication mechanisms for cloud data integrity. This research work focuses on efficient search on the encrypted data so that the cloud auditor does not have knowledge of any query information. An efficient cryptographic algorithm is developed in this study to secure the owner’s data. Then, Cost based Iterative Deepening Depth-First Search (CIDDFS) algorithm is designed to reduce the searching time of the keyword in encrypted data. The usage of the cosine similarity of the text reduced the cost of searching time. The experimental analysis stated that when the file size is 512kB, the proposed method achieved 93ms encryption time, 68ms decryption time and 62ms searching time while comparing with existing techniques: Depth First Search (DFS) and Breadth First Search Algorithm (BFS).",60002978,Visvesvaraya Technological University,Belgaum,India,['1700'],22.222222222222218,0.2018589743589744,0.4734615384615384,1,0.1091703056768559,0.06986899563318777,0.3407079646017699
486,499,499,An access control-based distributed cloud big data file using an XACML framework,"A cloud is a definite IT environment that is designed for the aim of remotely provisioning scalable and measured IT resources. Big data is a manner of describing data issues that are unsolvable using traditional tools. Volumes of big data are starting from dozens of terabytes and petabytes. As a result, it is impossible to store them in local storage and analyze them with traditional tools. The cloud storage is a promoting solution to store the big data files. However, single cloud storage may cause threats for the stored big data. In this paper, an access control approach based on the XACML framework is proposed to guarantee data security and privacy. The access control of the big data file is ensured by using the XACML framework and proof of ownership (POW) methodology. In the proposed approach, the big data file is stripped into parts which are encrypted and distributed over multiple cloud storage devices.The metadata file that contains the locations of the stripped parts, can access paths using private keys of each stripped file. The metadata file is encrypted and stored in different cloud storage. For maintaining the protection and performance of stripped files, a mirror copy of the stripped files is generated and distributed across several cloud disks. Moreover, the access of the metadata file is controlled through the XACML framework by generating a security token for sending responses and receiving user requests for decrypting data based on the previously stored attributes in the XACML policy. The security mechanism will be strengthened by deploying a fingerprint biometric authentication parameter. There-fore, the metadata will be accessed only by authorized users through XACML framework. Moreover, if cloud storage, containing a part file, is breached, the intruder gets only a part of the big data file, hence, he cannot get the whole file. Therefore, the proposed approach ensures the security of a big data file in cloud storage devices.",60104126,Jouf University,Sakakah,Saudi Arabia,['1700'],19.8125,-0.03353174603174603,0.32733134920634915,1,0.14647887323943662,0.01971830985915493,0.29914529914529914
487,500,500,"Comparative analysis of reservoir sediment inflow forecasting using RUSLE-SDR, rainfall – runoff-sediment discharge rating curve (RR-SRC) and SWAT","Sediment inflow prediction is needed for the development of sediment management strategies to ensure the sustainability of hydropower. There are many methods to predict and forecast reservoir sedimentation, focusing on the sediment yield catchment, sediment transport along the river network and sediment deposition inside the reservoir. This study compare three main methods in predicting the sediment inflow into Ringlet Reservoir, a hydropower reservoir located in active agricultural highland area in Cameron Highlands, Pahang. It compares sediment inflow prediction using 1) soil loss and sediment delivery ratio (RUSLE-SDR); 2) integration of rainfall runoff and sediment discharge rating curves (RR-SRC) and 3) processed based sediment yield model using SWAT. Accuracy of the annual prediction from each method is assessed based on the available bathymetry survey results, proving that SWAT performs the best.",60109258,Tenaga Nasional Berhad,Kuala Lumpur,Malaysia,['1700'],26.0,0.38666666666666666,0.4266666666666666,1,0.1118421052631579,0.07236842105263158,0.35135135135135137
488,501,501,Load balanced cross layer based multipath routing in mobile adhoc network,"Multipath routing in Mobile Ad-Hoc Network (MANET) usually results in end to end delay and overload in nodes. It is quite difficult to resolve these issues, but it can be reduced by implementing the cross-layered multi-path routing technique we propose in this paper. The initial step involves setting the optimal or better route using the cross-layer metric parameter, followed by sorting the cross-layered metric in descending order. The cross-layer metric is calculated using Expected Transmission Time, residual energy and the load balancing factor of the network. To balance the load, the primary and secondary paths are assessed by calculating the bandwidth that is available. This allows the network to split the data into parts and transmit these parts over the primary and secondary paths. Apart from this being a superior load balancing procedure, this technique avoids congestion during transmission. The success of this technique has been further validated by the findings of the simulation results.",60100946,St. Joseph's College of Engineering,Chennai,India,['1700'],19.375,0.09615384615384616,0.4269230769230769,1,0.13736263736263737,0.04395604395604396,0.3058823529411765
489,502,502,Prioritization index of soil erosion intensity for management practices within mountainous river using geomatics,"Mountainous rivers are always prone to severe soil erosion. Streams runoff from steep slope carriying heavy sediment yield to the plain. In the present study an attempt has been made to prioritize the microwatershed (MWS) for management practices within a subwatershed (SWS) Priority index was made based upon the intensity of soil erosion zone in MWS. This study identified and statistically ranked the MWS in order to do further analyses for protection measures. The main elements of soil erosion intensity assessment in this study are land cover, slope and forest density.",60015601,Indian Council of Forestry Research and Education,Dehradun,India,['1700'],18.2,-0.04952380952380952,0.3380952380952381,1,0.06930693069306931,0.0594059405940594,0.2871287128712871
490,503,503,A note on nano g#α regular space,In this paper we display strongly nano g# α closed maps in nano topological space. We also introduce nano g#α regular and nano g#α normal to consider their properties.,60072225,Kongunadu Arts and Science College,Coimbatore,India,['1700'],14.5,0.12083333333333332,0.3900641025641025,1,0.15625,0.15625,0.4444444444444444
491,504,504,Right to privacy between husband and wife: Many marriages would be better if the husband and the wife clearly understood that they are on the same side. Zig Ziglar,"Indian society still is a male dominating society, where in a marriage a wife still doesn’t have that equal rights or have even her say. Though Indian constitution guarantees right to life and liberty under Art 21 still that right is infringed as far as marital nuptial is concern. On the other hand even husband has a right of privacy if he is always been checked by his wife, like where he goes, his phone etc. In this paper the researcher has gone through various judgments of the honorable courts on highlighting the marital right to privacy.",60006074,Bharati Vidyapeeth (Deemed to be University),Pune,India,['1700'],24.25,0.1242063492063492,0.4853174603174603,1,0.05714285714285714,0.0,0.2169811320754717
492,505,505,Sound learning–based event detection for acoustic surveillance sensors,"This study proposes an event detection technique for acoustic surveillance that detects emergency situations by using acoustic sensors. Most surveillance systems have widely depended on visual data recorded by closed-circuit television (CCTV) cameras, but more intelligent systems are now beginning to use audio information for more reliable detection of emergency situations. Most of the conventional studies on acoustic event detection adopt limited types of acoustic data and are based on simple algorithms, such as energy-based determination. Thus, these approaches are easily realized, but may induce serious detection errors in real-world applications. In this study, we propose an event detection technique based on a sound-learning algorithm to be adopted by real-time acoustic surveillance systems. One main process of this technique is to construct acoustic models via learning algorithms from sound data collected according to types of acoustic events. The models are used to determine whether audio streams entering an acoustic sensor refer to the events or not. In event detection experiments performed in an outdoor environment, the proposed approach outperformed conventional approaches in the real-time detection of acoustic events.",60026109,Paichai University,Daejeon,South Korea,"['1712', '1708', '1705']",22.25,0.1880952380952381,0.4529761904761904,1,0.13106796116504854,0.0048543689320388345,0.31958762886597936
493,506,506,Study of the importance of digital forensics and deep learning tools,"In today’s advanced age the reliable towards picture is twisting a direct result of malicious forgery images. The issues identified with the security have prompted the examination center towards tampering detection. As the source image also, the objective locales are from a similar picture so that copy move forgery is very effective in image manipulation due to its same properties such as temperature, color, noise and illumination conditions. Resizing images, changing brightness or applying some image transformations, copying someone's head and pasting into other's body, bill forgery also a kind of digital image forgery. Digital forensics tools in the sense, it`s normally image, audio, video or VoIP based areas. And moreover many methods used for the detection of digital forensics especially machine learning and deep learning. In machine learning, there are supervised and unsupervised methods are the common. There are many deep learning methods available for analysis, compared some deep learning based tools, concepts regarding image forgery block based methods and machine learning algorithms.",60104130,Velammal College of Engineering and Technology,Madurai,India,['1700'],20.5,0.1208695652173913,0.4184782608695653,1,0.09090909090909091,0.0106951871657754,0.3
494,507,507,Study on actuarial science and actuaries-the pioneer of insurance,"The insurance sector plays an indispensable role in economic development of a country through mobilization of savings and development of funds to the productive sectors. The sector has been playing a dominant role in the financial system in the country and also has a significant socio-economic function making inroads into the interiors of the economy. Insurance is a concept of prediction of risk and uncertainties of future at present. Hence, there is a tendency of changes in insurance sector and insurance companies, requires statistical and mathematical models to mitigate these risks/changes. For this purpose, it requires necessary mathematical and statistical calculation based on various risk assessing factors of both insurer and insured. So the Statistical and Probabilistic techniques play an important role in a wide variety of practical situations in Actuarial Science. An actuary by profession is a business expert proficient in financial security systems who deals with a focus on complex financial evaluation and deal effectively in cases of unforeseeable events to curb losses. These professional viewed as creator of insurance business and their importance can be witnessed in many of the people-oriented financial and insurance plans viz. life and non-life insurance, pension plans, retirement benefits, unemployment insurance through their mathematics, statistics, economics, finance and modelling skills in evaluating and projecting the risks involved in futuristic uncertain events. Actuarial profession is more than 400 years old but still relevant in today's real world problems. The present research study makes an attempt to find out the importance of Actuarial science and actuarial professionals in insurance business and study found that their importance is measured in higher degree and they are the pioneers in establishing a proper insurance business in the market and actuarial science is master of all sciences of risk management.",60003082,Kuvempu University,Shimoga,India,['1700'],26.54545454545455,0.13942307692307693,0.3576923076923077,1,0.0778816199376947,0.009345794392523364,0.24920127795527156
495,508,508,Influence of anthropometric dimensions on pedals activation force and on H-point position,"Besides the design, nowadays buyers are very demanding when comfort is taken into question; all commands must be reachable and adapted to their physics. During the development of new vehicles, manufacturers must take into the consideration many factors to be competitive on the market. The anthropometric dimensions of the driver are playing very important role in the vehicle development. So car manufacturers have tendency to make the vehicle that is convenient for wide people population. The acting force on the vehicle commands depends from the user physics; also the vehicle must have the possibility to increase this force as many times is necessary, to maintain safe vehicle control, as well as to not disturb the safety of other traffic participants. The analysis is conducted for wide American male population (1 – 99%), by the application of the RAMSIS software package. It is found that by increasing the anthropometric dimensions the clutch pedal acting force decreases while joint loads are growing. Besides that the H-point determination is conducted in respect to the foot commands while the comfort is not disturbed.",60068809,University of Kragujevac,Kragujevac,Serbia,['1700'],22.375,0.1450974025974026,0.3949675324675325,1,0.10552763819095477,0.005025125628140704,0.23857868020304568
496,509,509,Bibliometric analysis on tendency and topics of artificial intelligence over last decade,"Artificial intelligence (AI), together with its applications, has received world-wide attentions and is expected to exert force on the development of global economy and society in the future. By means of bibliometric method, the study aims at providing an overview on the research tendency and the most concerned topics of AI during the past decade. The database of Web of Science was chosen and the articles published in AI journals were retrieved. Top 10% of the yearly high-citation articles (12,301 articles) published since the year of 2008 were selected as sampling articles for the analysis. The bibliographic records were used for the overall analysis, and the core keywords were studied and classified into three categories (algorithm, general technology and application technology) for topics analysis. As results, number of articles in AI by year and country, the country collaboration and well-known institutes and researchers in AI were presented. Also we proposed and concluded the five most concerned topics, which are perception intelligence (1st), human mind simulated intelligence (2nd), classical model based machine learning (3rd), bio-inspired intelligence (4th), and big-data based intelligence (5th). It is the authors’ wish that the study were helpful for researchers to have an overall grasp of the recent status of AI development.",60122349,Ministry of Science and Technology of the People´s Republic of China,Beijing,China,['1708'],25.625,0.037500000000000006,0.2578125,1,0.08695652173913043,0.05533596837944664,0.3950617283950617
497,510,510,The impact of the injection of wind power plant on the steady state condition and the dynamics of SULSELBAR power system," J. Elec. & Elecn. Eng. & Telcomm.An Injection of a renewable energy generator will cause a change in power flow in the existing system and can affect the overall system stability. With the injection of new generator, an evaluation of the power system needs to be done to update data in relation to the condition of power system. In this study, simulations of steady state analysis and dynamic stability were carried out which included rotor angle stability, frequency stability and voltage stability, as well as critical clearing time to evaluate the impact of Jeneponto Wind Power Plant (WPP) injection on SULSELBAR power system performance in Indonesia. The steady state analysis results show that voltage profile of the system has improved and reduced active power losses of 0.11%, reactive power of 0.12% after injection of the WPP. Next, dynamic stability analysis shows recovery time of the rotor angle, frequency and voltage can return to the steady state condition after experiencing interference with duration of 0.823 sec. The critical clearing time after the WPP injection is longer the duration of the interruption, i.e. the duration of the interruption time 0.1889 sec the rotor angle experienced synchronous release.",60069390,Hasanuddin University,Makassar,Indonesia,['1705'],17.818181818181817,0.07878787878787878,0.4705627705627706,0,0.0867579908675799,0.0730593607305936,0.2488479262672811
498,511,511,Erratum: Generalized linear sampling method for the inverse elastic scattering of fractures in finite bodies (Inverse Problems (2019) 35 (104002) DOI: 10.1088/1361-6420/ab2b18),The following algebraic corrections deal with tensorial form of the integral representation of elastodynamic fields generated by displacement discontinuity. These corrections are inconsequential to the rest of the article; however they are required for correct numerical implementations of the proposed inverse solution. (Formula Presented). Author to whom any correspondence should be addressed.,60029445,University of Minnesota,Minneapolis,United States,"['1711', '1706']",13.0,0.0,0.1,1,0.11864406779661017,0.03389830508474576,0.3559322033898305
499,512,512,Repairing Alignments of Process Models,"Process mining represents a collection of data driven techniques that support the analysis, understanding and improvement of business processes. A core branch of process mining is conformance checking, i.e., assessing to what extent a business process model conforms to observed business process execution data. Alignments are the de facto standard instrument to compute such conformance statistics. However, computing alignments is a combinatorial problem and hence extremely costly. At the same time, many process models share a similar structure and/or a great deal of behavior. For collections of such models, computing alignments from scratch is inefficient, since large parts of the alignments are likely to be the same. This paper presents a technique that exploits process model similarity and repairs existing alignments by updating those parts that do not fit a given process model. The technique effectively reduces the size of the combinatorial alignment problem, and hence decreases computation time significantly. Moreover, the potential loss of optimality is limited and stays within acceptable bounds.",60032882,Technische Universiteit Eindhoven,Eindhoven,Netherlands,['1710'],18.11111111111111,0.1308035714285714,0.5341517857142857,1,0.09392265193370165,0.0,0.2983425414364641
500,513,513,A Revised Projectivity Calculus for Inclusion and Exclusion Reasoning,"V.We present a Revised Projectivity Calculus (denoted RC) that extends the scope of inclusion and exclusion inferences derivable under the Projectivity Calculus (denoted C) developed by Icard (Stud Log 100(4):705–725, 2012). After pointing out the inadequacies of C, we introduce four opposition properties (OPs) which have been studied by Chow (in: Aloni et al (eds) Proceedings of the 18th Amsterdam Colloquium, Springer, Berlin, 2012; Beziau, Georgiorgakis (eds) New dimensions of the square of opposition, Philosophia Verlag GmbH, München, 2017) and are more appropriate for the study of exclusion reasoning. Together with the monotonicity properties (MPs), the OPs will form the basis of RC instead of the additive/multiplicative properties used in C. We also prove some important results of the OPs and their relation with the MPs. We then introduce a set of projectivity signatures together with the associated operations and conditions for valid inferences, and develop RC by inheriting the key features of C. We then show that under RC, we can derive some inferences that are not derivable under C. We finally discuss some properties of RC and point to possible directions of further studies.",60008928,Hong Kong Polytechnic University,Kowloon,Hong Kong,['1701'],26.57142857142857,0.16363636363636366,0.6254545454545454,1,0.0990990990990991,0.12612612612612611,0.49107142857142855
501,514,514,The Benefits of Enterprise Architecture in Organizational Transformation,"Today, as organizations constantly adjust their activities to meet ever-changing circumstances, continuous business transformation is taking place. However, planning and steering this transformation can be a daunting task as complexity has been built into the organization over the years. Enterprise Architecture (EA) has been widely adapted as a planning and governance approach to manage the complexity and constant change, and to align the organization toward a common goal. This article studies the EA benefit-realization process by clarifying how EA benefits are realized. Specifically, the focus is on the strategies, resources, and practices which the EA benefits stem from. The findings, derived from an in-depth case study, show that the EA benefit-realization process constitutes a long, intertwined chain of activities. Organizations benefit from EA through various means: from the initiation, when comprehensive understanding starts to form, until years later, when measurable outcomes such as cost savings materialize. Suggestions on what to incorporate into EA programs are presented.",60011170,Tampereen Yliopisto,Tampere,Finland,['1710'],19.5,-0.05625,0.37083333333333335,1,0.1276595744680851,0.047872340425531915,0.39444444444444443
502,515,515,Collaborative filtering web based service recommender system,"As numerous web services are increasing, selecting and recommending a web serviceto a user(handler)has become vital. Using collaborative filtering technique, we propose a system that can find optimal web service list for the service users based on their history. Collaborative filtering (CF) filters informationby means of the recommendations of other users who share same interests of the target user. Cosine similarity approach is used for selection of better web service. It uses similarity measure algorithm in order to compute web services similarity that enables web service recommendations. In this proposed system, to improve prediction precisionHybrid Clustering technique is used. For estimating the system’s performance, experiments are conducted on Cosine using Hybrid clustering technique.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],16.142857142857142,0.095,0.38,1,0.16535433070866143,0.015748031496062992,0.3560606060606061
503,516,516,Estimation of isobaric vapour-liquid equilibria of THF/acetic acid system using UNIFAC method,"It is highly recommended that the solvents which are used to recover useful chemical compounds should be less harmful to health, safety and environment. The use of green solvents, particularly the solvents which are produced from renewable resources, is preferable. Furfural is produced from renewable raw material such as agricultural waste. Tetrahydrofuran (THF) which can be produced from furfural can potentially be used as a solvent to recover acetic acid. A separation system is required for the recovery of the solvent for reuse. The separation system design requires vapour-liquid equilibrium (VLE) data of the THF/Acetic acid binary system. The isobaric VLE data for THF/Acetic acid system are not available in the literature. The prediction of VLE data using group contribution methods can be preferred over experimental methods due to certain advantages for the preliminary design of the separation system. In this work, the binary VLE data for THF/Acetic acid system were estimated using the UNIFAC method. The thermodynamic consistency of the estimated data was checked by Herington’s area test and point-to-point test of VanNess. The data reduction was carried out by Wilson, NRTL and UNIQUAC models. The deviation between calculated and predicted values in vapour phase composition and temperature has been reported.",60111820,Gujarat Technological University,Ahmedabad,India,['1700'],16.833333333333336,-0.013960270498732035,0.3806128486897717,1,0.1016949152542373,0.06779661016949153,0.27555555555555555
504,517,517,Multidimensional urban segregation: toward a neural network measure,", part of Springer Nature.We introduce a multidimensional, neural network approach to reveal and measure urban segregation phenomena, based on the self-organizing map algorithm (SOM). The multidimensionality of SOM allows one to apprehend a large number of variables simultaneously, defined on census blocks or other types of statistical blocks, and to perform clustering along them. Levels of segregation are then measured through correlations between distances on the neural network and distances on the actual geographical map. Further, the stochasticity of SOM enables one to quantify levels of heterogeneity across census blocks. We illustrate this new method on data available for the city of Paris.",60106017,Universite Paris-Saclay,Saint-Aubin,France,"['1712', '1702']",20.8,0.08937847866419295,0.32258812615955473,1,0.11666666666666667,0.05,0.3017241379310345
505,518,518,The State System for Scientific and Technical Information within the Objectives of the Digital Economy,Abstract: An overview is given of the scope of the National Digital Economy of the Russian Federation Program for the development of the information and innovation infrastructure in Russia. Insight is provided into the factors that influence the pace of innovative development of the Russian economy. The current status of the State System for Scientific and Technical Information is analyzed to establish the most relevant and promising areas for modernization. A macrostructure is provided for a set of activities to modernize the information support system for science and industry and ensure the development of a national information system. The areas are outlined for the development and implementation of a new scientific and information policy for the All-Russian Institute for Scientific and Technical Information (VINITI). It is recognized that the reconstruction of the national information infrastructure is a major issue of an interdisciplinary and supradepartmental nature.,60014602,All-Russian Institute for Scientific and Technical Information of Russian Academy of Sciences,Moscow,Russian Federation,['1700'],24.16666666666667,0.14990530303030306,0.3712121212121213,1,0.0641025641025641,0.1346153846153846,0.23376623376623376
506,519,519,"Application of smart nano-composite for consolidation of plaster in roman period at the Dendera Temple, Egypt","The temple Dendera is considered one of the famous and important archaeological temples not only in Upper Egypt but also all over Egypt. This paper aim to a consolidation and protection of the plaster dating to the 5th century AD(Roman era).Most of the layers have suffered severe damage, because of the harsh weather conditions in the upper region of Egypt and affected by a different kinds of decay. In this study the smart Nano-composite based on pure tetraethoxysilane (TEOS) and addition of Nano silica to TEOS polymer were used to improvement the capability of TEOS polymer to consolidate plaster. The collected samples were in cross section identified by using Binocular and SEM-EDX in order to identify the Layers, while the ELISA analysis was used to identify the organic binders. On the other hand, the investigation of cross section and EDS analysis of the Coptic church at the Dendera temple show the structures consist of two layers: the first is coarse plaster “arriccio” composed mainly of quartz and calcium carbonate, and the second layer is fine plaster “intonaco” composed of calcite, quartz and traces of gypsum. The mixture was evaluated by SEM-EDX to invesitgation the surface morphology for the consolidation of the roman plaster. The result of ELISA showed that no organic binders from the samples collected from Dendera temple.",60107271,Aswan University,Aswan,Egypt,['1700'],31.285714285714285,0.10205026455026456,0.4158068783068783,1,0.0942622950819672,0.09016393442622951,0.2644628099173554
507,520,520,Disease predicting infectious using machine learning and big data,"Nowadays, the use of Big Data is growing in bioscience and human organizations, social events, early infection revelation, Patient care, communal services. Partitioned therapeutic facts reduce examination exactness. The Machine learning tests are proposed for compelling need for endless infection. The Korea Center for Disease Control (KCDC) works a scrutiny device towards constrain overwhelming infections. This examination predicts overwhelming illnesses by way of improving the parameters of massive studying computations at the same time as considering wonderful records which includes web based lifestyles records. To pound the hassle of lacking statistics, inherent estimation can be utilized to recollect misplaced data. In a proposed structure, it gives Machine learning figuring’s to convincing gauge of various infectious diseases such as of the deep neural framework (DNN) and Ordinary least Square technique.It is used for classifying the high risk disease predictions.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],19.714285714285715,0.10591666666666666,0.5090833333333333,1,0.14465408805031446,0.050314465408805034,0.41139240506329117
508,521,521,A review on different optimization techniques for selecting optimal parameters in microstrip bandpass filter design,"There has been growing attention recently among organic process improvement algorithms such as Ant Colony improvement (ACO), biogeography primarily based Optimization (BBO), Differential Evolution (DE), Population-Based progressive Learning (PBIL) and Stud Genetic Algorithm (SGA) to some new techniques, here, taking into consideration completely different newly developed biological process improvement algorithms, the design of a microwave microstrip passband filter is mentioned in order to match their performance on a composite index EM improvement problem. Certain techniques (DE, BBO, SGA) are effectively cope up with this kind of complicated EM problem as shown by the results.",60094076,Sir Padampat Singhania University,Udaipur,India,['1700'],47.0,0.15506493506493507,0.5875974025974026,1,0.07627118644067797,0.17796610169491525,0.46551724137931033
509,522,522,"“Oh, She’s a Tumblr Feminist”: Exploring the Platform Vernacular of Girls’ Social Media Feminisms","As avid social media users, it is perhaps unsurprising that feminist teenage girls use their favorite platforms to engage in various forms of feminist activism. Yet, existing research has not explored how a growing number of social media platforms and their technological affordances uniquely shape how girls engage in online activism. I address this oversight by asking the following: Why are girls using particular platforms for feminist activism? How do certain platforms facilitate distinctive opportunities for youth engagement with feminist politics? and How might this shape the types of feminist issues and politics both made possible and foreclosed by some social media platforms? To answer these questions, I draw on ethnographic data gathered from a group of American, Canadian, and British teenage girls involved in various forms of online feminist activism on Twitter, Facebook, and Tumblr. These data were collected as part of two UK-based team research projects. Using the concept of “platform vernacular,” I analyze how these girls do feminism across these different platforms, based on discursive textual analysis of their social media postings and interview reflections. I argue that teenage girls strategically choose how to engage with feminist politics online, carefully weighing issues like privacy, community, and peer support as determining factors in which platform they choose to engage. These decisions are often related to distinctive platform vernaculars, in which the girls have a keen understanding. Nonetheless, these strategic choices shape the kinds of feminisms we see across various social media platforms, a result that necessitates some attention and critical reflection from social media scholars.",60002306,University of Calgary,Calgary,Canada,['1706'],32.125,0.06423809523809525,0.38819047619047614,1,0.13194444444444445,0.017361111111111112,0.3041958041958042
510,523,523,An Optimal Polling Point Selection and Channel Allotment Scheme for Clustered WSN,"Wireless Sensor Networks are constructed to manage the environment surveillance operations. The sensor devices are deployed with its resource details. The sensing coverage, transmission coverage, battery power and bandwidth levels are considered as resource information. The clusters are formed with bandwidth and coverage details. The cluster head is selected with its capacity levels. The cluster head manage all the nodes comes under the coverage levels. All the data forwarding operations are carried out through the cluster head nodes. The data collection for the sensor networks is carried out with three elements. They are Mobile Collector, cluster heads and the sensor nodes. The elements are considered as individual layers. The data forwarding operations are performed with the distributed load balanced clustering and dual data uploading (LBC-DDU) method. Cluster construction and data transmission are the main tasks of the scheme. The cluster heads are paired with communication ranges. The mobile collector performs the data collection operations at the polling points. The polling point selection is carried out with the cluster head pair details. Optimal polling point selection scheme is constructed in the Enhanced Distributed Load Balanced Clustering with Dual Data Upload (ELBC-DDU) method. The bandwidth assignment tasks are managed with the channel allotment scheme. Network area verification and rescheduling process is called to manage the spatial coverage optimization for the data collection process. The data gathering scheme increases the network lifetime with minimum query response delay. Network traffic levels are minimized in the data collection framework.",60114357,Vivekanandha College of Arts &amp; Science for Women,Tiruchengode,India,['1700'],12.2,0.08333333333333333,0.3666666666666667,1,0.09090909090909091,0.05818181818181818,0.3284132841328413
511,524,524,Low noise amplifier for LTE application using high-performance low noise pseudomorphic high electron mobility transistor (PHEMT),"A growing communications technology along with modern technology, from time to time. Developments in the wireless industry, internet access without borders and increasing demand for high data rate wireless digital communication moving us toward the optimal development of communication technology. Wireless communication is a technology that plays an important role in the development of the current transformation. Long Term Evolution (LTE) is a type of wireless communication that available for transmitting the large amounts of data, voice and video over long distance using a different frequency band. Low Noise Amplifier is located at the first block of the receiver system, which makes it one of the important parts to transmit the signal. This project is to design a Low Noise Amplifier for LTE Application that will work at 6 GHz using high-performance low noise Pseudomorphic High Electron Mobility Transistor (PHEMT) ATF36163 manufactured by Avago Technologies. The overall goal of this research is to study, design and analyze the Low Noise Amplifier at 6 GHz in communication aspects of low noise amplifier must be less than 3 dB and the gain more than 15 dB is based mainly upon the s-parameter of a transistor.",60103633,Universiti Pendidikan Sultan Idris,Tanjong Malim,Malaysia,['1700'],27.57142857142857,0.11746753246753246,0.39735930735930736,1,0.0892018779342723,0.1267605633802817,0.3157894736842105
512,525,525,Usability testing for OOP visual: A 3D interactive programming learning tool,"The paper presents the design and implementation of 3D interactive software to help university students understand and visualize Object Oriented Programming-and specifically the polymorphism concept-in an effective way, using animation, visual, sounds, and interactivity. The proposed solution consists of an animated environment with an editor that allows drag and drop methods.It will be demonstrated that the developed software can assist students in understanding programming without dealing with syntax errors and complex design techniques, and can allow them to focus on programming concepts rather than the tedium of debugging code.",60004582,King Abdulaziz University,Jeddah,Saudi Arabia,['1700'],44.5,0.06,0.31416666666666665,1,0.21568627450980393,0.029411764705882353,0.3229166666666667
513,526,526,A study with reference to educational sector: VUCA and talent management practices,"In the changing world of globalization and liberalization it is become important for the organization to adapt the changes of business environment and transform them radically. Earlier the business focused only on profit making but as the trend change customer become the king of the market. Now organizations need to focus on societal development as well with concept boundaries of corporate social responsibility and corporate governance. In the changing VUCA (volatile, uncertain, complex, and ambiguous) world it is become difficult for the organization to sustain, attract, develop and engage the right talent among the fittest. Individuals those who are working with any organizations in any way are the students of an Institute/College/University. If the education sector recruits highly efficient and effective faculties, they will produce better professional for the industries. This paper is an attempt to understand how education sector can use practices to sustain faculties in the VUCA world.",60028153,Banasthali Vidyapith,Vanasthali,India,['1700'],21.428571428571427,0.0983882783882784,0.4955677655677656,1,0.1301775147928994,0.029585798816568046,0.24242424242424243
514,527,527,"Examination of causes and effects of accident on construction sites: (case study of Lagos, Lagos state, Nigeria)","The construction industry is assumed to be the most risky and hazardous of all industries due to the frequent high rates of accidents, ill-health and safety risks involving on construction sites. This becomes a perpetual concern to all the stakeholders in the construction industry. Therefore, this study investigates the various causes and effects of accidents on construction sites in Lagos State, Nigeria. Structured questionnaire was used to source the industry stakeholder’s opinions and unstructured interview were used to consolidate their opinions for the data collection. Responses were analyzed and ranked using Likert scaling method. In attempt to reduce the occurrence and severity of construction site accidents to the minimum, findings from the study identify the critical causes of accidents on construction sites and its effects in Lagos State, Nigeria. This paper therefore concludes and recommends amongst others, training and education regarding health and safety, the use of Personal Protective Equipment’s (PPE) by construction workers, ensuring safe working environment and enforcing effective and stricter safety rules against defaulters.",60018623,South Valley University,Qena,Egypt,['1700'],23.857142857142854,0.2335,0.5515,1,0.09574468085106383,0.05851063829787234,0.34574468085106386
515,528,528,"Green marketing and the perceived satisfaction of consumers in Coimbatore City of Tamilnadu, India","Global environmental consciousnesses alongside sustainable development, recycling, ecology have become buzzword for a healthy life style. As society becomes more concerned with the natural environment, businesses have begun to modify their practices in an attempt to address society's new concerns in the name of green marketing. Recently green marketing has drawn the attention of government too in this regard and paved the way for introducing many environment friendly policies. Today, manufacturers are challenged with three cardinal issues which include electricity consumption efficiency, curbing greenhouse gas emissions and reducing disposal hazards. The present study has been made in the purview of examining into the consumers’ intuition over the sustaining green marketing practices and elastic consumer preferences. Valuable suggestions based on analysis at the end would surely effective for the learners and the budding scholars and whoever in need.",60117285,"SRM Institute of Science and Technology, Ramapuram Campus",Chennai,India,['1700'],22.83333333333333,0.1701048951048951,0.3657342657342657,1,0.12666666666666668,0.0,0.26
516,529,529,A novel adaptive output feedback control for DC–DC boost converter using immersion and invariance observer,"This paper presents a class of novel adaptive output feedback controller for DC–DC boost converter with global exponential stability. In addition, the control input constraint is considered in stability analysis. The proposed adaptive control scheme is constructed to estimate input voltage and inductor current using output voltage and control signal information. In order to estimate unavailable state and parameter, immersion and invariance technique is employed. The effectiveness of the proposed method is investigated via experimental test and the practical results endorse the efficiency of this adaptive controller.",60089290,Babol Noshirvani University of Technology,Babol,Iran,['1706'],17.4,0.03333333333333333,0.26666666666666666,1,0.13541666666666666,0.020833333333333332,0.19148936170212766
517,530,530,Triangular fuzzy antimagic labeling on some special graphs,"In this paper, we prove that Y-tree graph and Kite graph KTm,n admits triangular fuzzy labeling by providing algorithms. Also we show that the said graphs admits antimagic labeling.",60117285,"SRM Institute of Science and Technology, Ramapuram Campus",Chennai,India,['1700'],14.5,0.0,0.0,1,0.16666666666666666,0.1388888888888889,0.47058823529411764
518,531,531,Experimental investigation for workability and compressive properties of high strength concrete with Al2 O3,"Concrete in construction is classified as ordinary concrete or high strength concrete. This variation is determined by the strength of concrete. Usually high strength concrete shows the strength up to 100MPa where as for normal concrete itis not more than 50MPa. The present study deals with flow and strength properties of M60 grade concrete containinga constant proportion of Al2O3 and varying proportions of silica fume. Nano-sized particles of Al2O3 are used with 0.25% by weight of cement. Silica fumes are used in the proportions of 0, 5, 10, 15, 20 and 25% by weight of cement. Cube specimens with the dimensions of 150×150×150 are casted and tested for 3, 7 and 28 days compressive strength. It is observed that the Workability of concrete is decreased by increasing the quantity of silica fume. Compressive strength of hardened concrete started increasing and maximum attained at 15% of silica fume by weight of cement and again decreased. The cement particles when replaced with nano Al2O3 and silica fume performs better when compared with conventional concrete.",60116779,"Rajiv Gandhi University of Knowledge Technologies, Andhra Pradesh",Kunchanapalli,India,['1700'],17.2,0.048911564625850334,0.3962131519274377,1,0.09895833333333333,0.046875,0.3631578947368421
519,532,532,On βwg-closed sets in nano topological spaces,"Lellis Thivagar.M introduced the concept of nano topology which is based on the approximations and boundary regions. The purpose of this paper is to define βwg-closed set in Nano topological spaces. We discuss its properties and relationship among other closed sets. Further we introduce the notion of βwg-open sets in nano topological spaces and explore its properties, also its characterizations are touched upon.",60114457,Sri Krishna Arts and Science College,Coimbatore,India,['1700'],15.75,-0.075,0.325,1,0.10810810810810811,0.08108108108108109,0.35294117647058826
520,533,533,Analytical applications of in-situ generated potassium trithiocarbonate in DMSO: Determination of tetraethyl thiuram disulfide in commercial drugs,"A simple and rapid method has been described for determination of tetraethyl thiuram disulfide in commercial drug formulations with Potassium trithiocarbonate (K2CS3). The reagent is generated in-situ in dimethly sulphoxide (DMSO) quantitatively by just adding 3-4 drops of carbon disulfide to a known amount of potassium hydroxide. The determination has been carried out visually (to the appearance of red colour), potentiometrically (using Pt-SCE assembly) and photometrically (440 nm being analytical wavelength). The method has successfully been applied to the assay of Antabuse tablets containing tetraethyl thiuram disulfide.",60075937,"ICAR - Central Institute of Post-Harvest Engineering and Technology, Ludhiana",Ludhiana,India,['1700'],21.75,0.15,0.26142857142857145,1,0.07407407407407407,0.08333333333333333,0.4215686274509804
521,534,534,Neural network approach based on a bilevel optimization for the prediction of underground blast-induced ground vibration amplitudes,", part of Springer Nature.Due to its technical and economic advantages, the use of explosives in underground rock excavation is widely adopted. However, some safety and, especially, environmental issues arise when using this technique, mainly concerning ground vibrations induced by blasts. Thus, to minimize dynamic environmental impacts, prediction of blast-induced vibrations is imperative. In the last few years, artificial neural networks (ANNs) have been applied to model blast-induced ground vibrations. Nevertheless, ANN’s architecture, mainly the number of neurons in the hidden layer, has been selected manually concerning ANN’s performance parameters. To avoid over-fitting and reduce model’s complexity, this paper presents a bilevel optimization of ANN architecture, considering two transfer functions, based on the maximization of quality of the adjustment and model’s complexity, this last one as a penalty criterion. An ANN approach based on this bilevel optimization was successfully applied on a database of 1188 samples obtained from underground blast-induced ground vibration monitoring in a granitic rock mass. A residual analysis of the best-fitted model is performed to ensure the quality of the adjustment. It is demonstrated that the determined ANN model offers much higher generalization ability than the traditional prediction models usually used for blast-induced ground vibration amplitude predictions and other ANN architectures applied to ground vibration prediction.",60004956,Instituto Superior Técnico,Lisbon,Portugal,"['1712', '1702']",23.222222222222218,0.010648148148148148,0.38472222222222224,1,0.11857707509881422,0.03162055335968379,0.3374485596707819
522,535,535,On quasi n – power – hyponormal operators,In this paper we introduce the new class of quasi n power – hyponormal operators acting on a Complex Hilbert Space H. We give some basic properties of these operators.,60114912,JCT College of Engineering and Technology,Coimbatore,India,['1700'],15.0,-0.040909090909090916,0.2448863636363636,1,0.0967741935483871,0.16129032258064516,0.3548387096774194
523,536,536,A fast algorithm on generating concept lattice for symmetry formal context constructed from social networks,"Formal concept analysis has been witnessed to be an effective soft computing methodology for data analysis, rule extraction and clustering, but how to build a formal concept lattice efficiently is always a challenge issue. Recent years, several deformation formal contexts are emerging for addressing current important research problems, such as virtual machines scheduling in mobile cloud computing and topological structure analysis in social networks. In this paper, we focus on the symmetry formal context where the objects and attributes are identical, and its formal concept lattice construction. Firstly, we explore the properties of symmetry formal context and discover a symmetry line which must appear in the expected formal concept lattice. Further, a fast algorithm for building concept lattice for symmetry formal context is presented. Then, five social network datasets are utilized for evaluating our proposed algorithm. Experimental results show that our algorithm can speed up 1.2 times and 3.45 times compared to the concept-matrix based concepts generation algorithm and incremental algorithm, respectively.",60031404,The University of Aizu,Aizuwakamatsu,Japan,['1700'],23.142857142857146,0.1077777777777778,0.3844444444444444,1,0.12154696132596685,0.016574585635359115,0.2849162011173184
524,537,537,A comparative study between breathing control and pursed lip breathing among bronchial asthma patients,"Background: Asthma is a condition that affects many individuals in Malaysia. Pursed-lip breathing and breathing control appear to be effective in improving the expiratory flow rate in bronchial asthma patients. Objective: To find out the effect of breathing control and pursed-lip breathing on expiratory flow rate among patient with bronchial asthma. Methodology: A quantitative research model in the form of a Quasi-Experimental type Study design was carried out in this study. A convenient sampling of 30 participants among the bronchial asthma patient was collected from clinics and hospitals around Kedah, Malaysia. Subjects were randomly assigned into 2 groups with each group of 15 subjects equally. Group A was given pursed lip breathing exercise as part of treatment while group B was given breathing control as treatment. Descriptive statistic was used for data analysis. Tabulation and computation of frequencies and percentages were calculated on selected variables. Result: The study shows group a (pursed lip breathing) has greater improvement compares to group B (breathing control). The mean of difference in peak flow expiratory flow rate before and after the treatment between group A and B are 43.333±16.220 and 25.289±18.002 respectively. The p-value was 0.007 which showed statistical significance in the result (p<0.05). Conclusion: The result shows both pursed lip breathing and breathing control is effective in improving the expiratory flow rate of bronchial asthma patients. However, when comparing between both groups, pursed lip breathing appears to demonstrate greater improvement in the expiratory flow rate among patient with bronchial asthma. In shorts, pursed lip breathing is one of the easiest ways to allow patients with bronchial asthma to make effective breath. This is because of the improvement in oxygenation in the lungs which helps patients to achieve the highest functioning of the lungs.",60078092,"Asian Institute of Medicine, Science &amp; Technology",Bedong,Malaysia,['1700'],18.125,0.2261363636363637,0.5034090909090909,1,0.0972644376899696,0.03951367781155015,0.2693498452012384
525,538,538,On Gd-distance of a graph,"The concept of Gd-distance between any two vertices in a graph is introduced by V.Maheswari and M.Joice Mabel in [4]. In this paper, we introduce Gd-distance of a graph. We compute the Gd-distance of a path, cycle, complete graph, complete bipartite graph, grid graph, sun, star, wheel and line graph. Also we determine the Gd-distance for some shadow graphs.",124036322,Kamaraj College,Thoothukudi,India,['1700'],14.75,0.1,0.4,1,0.04938271604938271,0.12345679012345678,0.3561643835616438
526,539,539,Recognition fraud scheme applied to rotating machine learning algorithm,"Given small earnings margins, by yourself owned or operated consuming locations are fairly sensitive to insider fraud and but have scant resources to fight the trouble. This paper is the number one open studies to use Machine Learning (ML) techniques to detect insider fraud in issue-of-income transaction information in the restaurant business enterprise. We display that after applying under-sampling strategies and punctiliously engineering functions, ML can supply very excessive fraud-detection overall performance. Understanding approximately engineered capabilities, algorithm preference, performance, and tuning received from these studies can be applied in future studies on fraud detection of restaurant records.",60023544,Andhra University,Visakhapatnam,India,['1700'],24.25,-0.13437500000000002,0.465625,1,0.15517241379310345,0.05172413793103448,0.3425925925925926
527,540,540,"Comparative view of return loss, VSWR, gain, and efficiency of cylindrical surrounding patch antenna with frequency shift"," J. Elec. & Elecn. Eng. & Telcomm.In this research work, the return loss (S-parameter, S11), Voltage Standing Wave Ratio (VSWR), gain, and efficiency of a compact and flexible Cylindrical Surrounding Patch Antenna (CSPA) have been derived from Rectangular Planar Patch Antenna (RPPA) for applications in the Industrial, Scientific and Medical (ISM) frequency band. For ease of bending, the radiating patch was stablished on surface of the cylindrical substrate (ploymide) of thickness 1.2 mm. It is flexible and has permittivity (er) 3.5, permeability (μr) 1, and loss tangent (tanz1 ) 0.0027. The RPPA was made conformal into cylindrical shapes at an angle of 90° and radius of curvature (r) ranging from 10 mm to 35 mm in steps of 5 mm to achieve the best return loss and gain. Results for the optimal performance parameters have been presented for CSPA and RPPA at 2.371 GHz and 2.4 GHz, respectively. Results show that for the CSPA S11, VSWR, and gain are -17.734 dB, 1.2984, and 4.52 dBi, respectively (with better angular coverage) compared to RPPA which has -11.969 dB, 1.6741, and 5.74 dBi, respectively.",60010499,University of KwaZulu-Natal,Durban,South Africa,['1705'],18.3,0.25,0.18333333333333332,0,0.038135593220338986,0.13983050847457626,0.5434782608695652
528,541,541,A study on students’ awareness towards artificial intelligence,"Technology is reducing human work and increasing productivity along with efficiency. Artificial Intelligence is penetrating in many industries like Healthcare, Telecommunication, Transportation, Education, Legal, etc., so the industries are using these technologies to develop effective decision making and improve their productivity by merging artificial intelligence in HR functions will increases the overall productivity as well as profit of the organisation. There are many benefits of using artificial intelligence in organizations are rapidly automating the business process, reduce bias and rational decision making etc., Primary objective of this study is to find the awareness of artificial intelligence towards students community. This study establishes how students are feeling about the rise of artificial intelligence. The researcher used Descriptive research design because it helps to describe a particular situation. The researcher used Convenience Sampling method in this study. The data collection from Sources of primary data with well-structured questionnaire and secondary data through books, journals and websites. Statistical tools were Percentage analysis and Karl Pearson correlation.",60102677,Dr. M.G.R Educational and Research Institute,Chennai,India,['1700'],20.375,-0.033333333333333326,0.5520833333333334,1,0.11956521739130435,0.059782608695652176,0.3277777777777778
529,542,542,High-accuracy numerical methods for a parabolic system in air pollution modeling,", part of Springer Nature.We present two approaches for enhancing the accuracy of the second-order finite difference approximations of two-dimensional semilinear parabolic systems. These are the fourth-order compact difference scheme and the fourth-order scheme based on Richardson extrapolation. Our interest is concentrated on a system of ten parabolic partial differential equations in air pollution modeling. We analyze numerical experiments to compare the two approaches with respect to accuracy, computational complexity, nonnegativity preserving, etc. The sixth-order approximation based on the fourth-order compact difference scheme combined with Richardson extrapolation is also discussed numerically.",60109565,"Institute of Information and Communication Technologies, Bulgarian Academy of Sciences",Sofia,Bulgaria,"['1712', '1702']",18.2,-0.05,0.1,1,0.07964601769911504,0.035398230088495575,0.3434343434343434
530,543,543,Event-triggered asynchronous distributed optimization algorithm with heterogeneous time-varying step-sizes,", part of Springer Nature.This paper concerns distributed convex optimization problems over time-varying undirected graphs, in which the global objective function is expressed as the sum of individual objective functions of the agents. Each agent only knows its local objective functions. To figure out such problems, an event-triggered asynchronous distributed optimization algorithm (termed as EV-ADOA) with time-varying heterogeneous step-sizes is proposed, which is suitable for undirected graphs changing over time. Under two standard assumptions on strongly convex and smoothness of local objective functions, the EV-ADOA can achieve linear convergence with a proper upper bound of the heterogeneous time-varying step-sizes. EV-ADOA with event-triggered scheme can decrease network communication, and the Zeno-like behavior strictly is excluded. The efficiency of EV-ADOA is demonstrated by experiments.",60122052,Southwest University,Chongqing,China,"['1712', '1702']",20.33333333333333,0.059375,0.271875,1,0.11801242236024845,0.06832298136645963,0.35555555555555557
531,544,544,Field survey on the thermal environments and worker satisfaction of South Korean commercial kitchens,"A commercial kitchen is a space where workers spend most of the time of their daily work. Management of the thermal environments is required for food hygiene management as well as the health of workers. The heat emitted and humidity in commercial kitchens differ greatly depending on the types of business, the forms of the kitchens, and the kinds of food being cooked. Some countries present guidelines and implement regulations on the thermal environments of commercial kitchens. However, in the case of South Korea, there is no separate regulation on kitchen environments despite that the summer climates are hot and humid. In this study, the thermal environments of South Korean commercial kitchens were actually measured, questionnaire surveys were conducted with workers, and the results were analyzed. First, the room temperatures, humidity, radiation temperatures, and airflows during working hours were measured in 10 kitchens in five industries representing South Korean commercial kitchens. A thermal sensation vote and a comfort sensation vote were conducted with 46 workers in the kitchens being measured. The results of analysis indicated that South Korean commercial kitchens were quite poor in humidity control and that working environment should be considered as the probability of workers' discomfort was shown to be 58.8% on average.",60012704,Kyungpook National University,Daegu,South Korea,['1700'],22.88888888888889,0.08333333333333333,0.2355555555555556,1,0.08771929824561403,0.008771929824561403,0.31140350877192985
532,546,546,"Convergence of accounting standards, financial transgression and regulatory reforms in India and USA","The purpose of the study is to find the various reasons of financial transgression in India and USA and evaluation of subsequent changes made thereafter by regulatory bodies in the statutes so that no such cases occur in future. Secondary sources of information are used to cover cases of financial transgression in India and USA for the period 1991 till 2018. Major loopholes have been found in Indian regulatory framework rather than in USA. It is observed that even after USA proactively changed the rules, yet the financial transgression cases could not be fully eliminated by them. The timeline of the cases in India and USA is strategically hinting towards the weak regulatory system of India along with late changes made in the relevant regulatory framework. Remarkable reduction in number of cases of financial transgression has been reported but India has not learnt a lesson from US corporate failures.",60103935,Ahlia University,Manama,Bahrain,['1700'],24.83333333333333,0.015833333333333328,0.32333333333333336,1,0.08974358974358974,0.07051282051282051,0.26282051282051283
533,547,547,"Investigation of heavy metal analysis in wastewater samples around the industrial area of Gajulamandyam, Tirupati, A.P.","The present study deals with the characterization of industrial effluents released from various points of gujulamandyam industrial areas and the distribution of heavy metals in soils are enter into the soil body to disturb the soil biocommunities which are essential for the supporting of the plant growth. The excess amount of HM’s toxicants would leads to reduces the plant growth and ultimately disturb the plant ecosystem. Apart from this, accumulation of heavy metals in nearby soil and vegetation system irrigated with effluent-contaminated water is also the subject of this study. Physico-chemical analysis of effluent reveals that the concentration of total suspended solids (TSS), total hardness (TH), iron (Fe+ 2), and oil and grease are greater than the IS (1981) norms for discharge of water into inland water body. The soil along the sides of the effluent channel also shows higher concentration of heavy metals than the background soil. The enrichment of the heavy metals are in the order of Chromium (Cr),Iron (Fe),Manganese (Mn),Zinc (Zn),Copper (Cu),Cadmium (Cd). The effluent as well as contaminated water is extensively used for irrigation for growing vegetables like tomato (Lycopersicon esculatum) in the surrounding areas. Heavy metal accumulation in this agricultural soil are in the sequence of Cr, Fe, Mn, Zn, Cu and Cd. More or less similar type of accumulation pattern are also found in tomato plants except Fe and Zn exceeding Cr and Mn. Transfer Factor of heavy metals from soil to tomato plants (TFS) shows average value of ≤ 1, suggesting less uptake of heavy metals from soil. Among the plant parts studied, fruit shows least accumulation. Although tomato plants show some phenotypic changes, the survival of tomato plants as well as least accumulation of metals in fruit reveals their tolerance to heavy metals. Therefore it may be suggested that this plant can be grown successfully in the heavy metal contaminated soil. Further research work on in situ toxicity test will be necessary in order to identify the most resistive variety on this particular type of contaminated site.",122307902,S.V. College of Engineering,Tirupati,India,['1700'],23.92857142857143,-0.004166666666666668,0.4760416666666666,1,0.07552083333333333,0.07552083333333333,0.351010101010101
534,548,548,A morphology approach for fault location on transmission lines,"This paper presents a heuristic method for fault location in transmission lines. It is established based on synchronized voltages sampling in line terminals using morphology approach. The proposed method uses only pre and during fault voltage phasors while traditional distance protection approaches require current transformers (CT) (with the issue of CT saturation and their errors), knowledge of line parameters and Thevenin impedance calculation. The proposed method is based on the voltage variations in the stationary reference frame (a-P). The changes of enclosed area of the voltage curve in the Clark coordinate due to fault is selected as the location criteria. Results indicates that the method is able to estimate fault point distances. However, the estimated fault point tolerates in a variable zone.",60003666,University of Mazandaran,Babolsar,Iran,"['1711', '1709', '1708', '1702']",17.428571428571427,0.075,0.63,1,0.1223021582733813,0.02158273381294964,0.3284671532846715
535,549,549,Loss of target information in full pixel and subpixel target detection in hyperspectral data with and without dimensionality reduction,"In most hyperspectral target detection applications, targets are usually small and require both spatial as well as spectral detection. Hyperspectral imaging facilitates target detection (TD) applications greatly, however, due to large spectral content, hyperspectral data requires dimensionality reduction (DR) which also leads to loss of target information both at full pixel and subpixel level. Literature reports many DR and TD algorithms in practice. Several studies have focussed on assessing the loss of target information in DR, however, not much work seems to have been done to assess loss of target information in full pixel and subpixel TD in hyperspectral data with and without DR. This paper seeks to study various combinations of DR techniques combined with full pixel and subpixel TD algorithms. The results indicate that in the case of full pixel targets, both DR and TD contribute to the loss of target information, however, there is more loss of target information in the case when DR precedes TD in comparison to a case where TD is applied without DR. In the case of subpixel TD, however, there appears to be loss of subpixel target information in the case where TD alone is performed in comparison to a case where DR precedes TD.",60002874,Delhi Technological University,New Delhi,India,['1706'],29.0,0.24566326530612245,0.4538265306122448,1,0.09333333333333334,0.08444444444444445,0.36444444444444446
536,550,550,Information technology and e-governance: comparative policy perspective of India and Assam,"E-Governance or electronic governance relates to the integration of Information and Communication Technology (ICT) within all governmental processes. The main purpose of e-Governance is to enhance the Government’s ability to address the needs of its people in a convenient, efficient and transparent manner.In this era of information technology, digital revolution and evolution from mouse clicks to touch pads, on-premise solutions to replication of a real life scenario through digital twins, is fast becoming the determining factor for providing farfetched solutions to socio-economic problems. Information Communication Technology has not only taken up the rudder of providing solutions but also, has become the compass for identifying and determining bottlenecks. The government has already realised the importance of ICT and in this regard embarked many initiatives to digitally empower the status of common man by bringing e-Governance in almost all the departments. By amalgamating management and sectoral expertise coupled with cutting edge technology expertise, the IT & e-Governance practice continues to fulfil, the motto of efficient service delivery for various Government and Non-Government domains enriching the lives of billions of people across globe.In India, the ICT initiatives have been implemented focussing on the development of rural economies with a promise of enhanced public participation in the governance. Though such initiatives, to a reasonable extent, have been able to increase people’s participation in the governance process, it is not free from its own impediments. In this context, the study attempts to explore the challenges of ICT and e-governance in Assam. Keyword.",60016850,Gauhati University,Guwahati,India,['1700'],30.875,0.09035087719298246,0.4776315789473685,1,0.09621993127147767,0.08934707903780069,0.326007326007326
537,551,551,Improving the performance of heterogeneous hadoop clusters using the map reduce big data algorithm,"This article focuses on improving the performance of heterogeneous clusters in Hadoop after a series of steps that improve data I / O, improve the routing algorithm for heterogeneous clusters, and then improve query processing performance in such a way that they can be easily connected to the right part of execution in the shortest possible time without increasing costs at the computer level. The proposed work follows a series of steps to process these scenarios, which are described herewith.",60138937,Jaipur National University,Jaipur,India,['1700'],40.0,0.17976190476190476,0.7172619047619048,1,0.15294117647058825,0.023529411764705882,0.23529411764705882
538,552,552,A multi-channel feedforward ANC system using a novel FXLMS algorithm in solving classroom aviation-noise problems," J. Elec. & Elecn. Eng. & Telcomm.Adaptive or Active Noise Control (ANC) system is now widely used in many applications. In this paper, a novel multi-channel feedforward ANC system is presented to lower the level of the aviation noises which occurred in the KMITL University's classrooms. A system is simulated in MATLAB/Simulink environment. The proposed multichannel feedforward ANC system configurations including related equations are described in this paper. The modified Filtered-X Least-Mean-Square (FXLMS) method is used for updating the weight vector in ANC control block diagram in order to achieve the optimal weight vector resulting in minimal errors. How to find bounds on the step size and how to estimate the rate of convergence as well as the steady-state errors of the proposed system with FXLMS algorithm are also elaborated. The secondary-path effects are considered and compensated in this research. The simulation results are presented in terms of noise attenuation capabilities and the Mean-Square-Error (MSE) convergence time. Simulation results and conclusions presented in this paper will be used for further analysis to improve the system performance of the proposed ANC methodology before implementing in the actual classroom.",60021543,King Mongkut's Institute of Technology Ladkrabang,Ladkrabang Bangkok,Thailand,['1705'],14.461538461538463,0.023809523809523808,0.4428571428571429,0,0.10526315789473684,0.11842105263157894,0.391304347826087
539,553,553,A convolution neural network (CNN) based deep learning neural network forecast model for wind energy prediction,"Renewable Energy resources are susceptible to the whim and vagaries of nature and are a variable random source of power. Predicting and forecasting the power from these variable power sources define and determine the operation of these system. The forecast of wind energy generation using a deep learning neural network called convolution neural network (CNN) is proposed in this paper. Here, the inputs taken are namely the wind energy, wind speed and angle of wind direction relative to the turbine blades, which are obtained from Sotavento Galicia experimental wind energy farm. The results were verified and validated against an actual generation and compared with ANN and ANFIS based forecast. RMSE, NRMSE and Pearson coefficient are calculated for the same.",60106974,"JNTUA College of Engineering, Ananthapuramu",Anantapur,India,['1700'],19.83333333333333,-0.06666666666666668,0.2541666666666667,1,0.10687022900763359,0.0916030534351145,0.2824427480916031
540,554,554,Hybrid colour infrared image edge detection using RGB-YCbCr image fusion,"Edges are one of the most important features in images and their analysis and detection in computer vision and image processing is an essential goal. Indeed, a variety of applications such as 3-D reconstruction, shape recognition, image compression, enhancement, and restoration identifying and localizing edges are a low level tasks. This paper presents a Hybrid approach to Infrared image edge detection which becomes a vital point in pattern recognition. The acquired image which is in RGB colour space by satellite are near infrared images which can be used as subject of interest based on the radiation. Edge detection becomes a bottleneck for infrared images as it constitutes with lesser properties in terms of color. A hybrid edge detection algorithm is required to accomplish a better edge detection. Two algorithms are proposed in this process, Firs the edge detection is done in RGB colour space and the significant features extracted are fused. The second method proposed is based on YCbCr image edge detection and fusing the Luminance and R component of the image which shows better edge detection results.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],22.25,0.17756410256410254,0.4698717948717948,1,0.109375,0.026041666666666668,0.2552083333333333
541,555,555,Compact representation of near-optimal integer programming solutions,"It is often useful in practice to explore near-optimal solutions of an integer programming problem. We show how all solutions within a given tolerance of the optimal value can be efficiently and compactly represented in a weighted decision diagram. The structure of the diagram facilitates rapid processing of a wide range of queries about the near-optimal solution space, as well as reoptimization after changes in the objective function. We also exploit the paradoxical fact that the diagram can be reduced in size if it is allowed to represent additional solutions. We show that a “sound reduction” operation, applied repeatedly, yields the smallest such diagram that is suitable for postoptimality analysis, and one that is typically far smaller than a tree that represents the same set of near-optimal solutions. We conclude that postoptimality analysis based on sound-reduced diagrams has the potential to extract significantly more useful information from an integer programming model than was previously feasible.",60027950,Carnegie Mellon University,Pittsburgh,United States,['1712'],25.83333333333333,0.14487179487179486,0.4185897435897437,1,0.10285714285714286,0.0,0.24550898203592814
542,556,556,High-Level-Synthesis of Number-Theoretic Transform: A Case Study for Future Cryptosystems,"IEEECompared to traditional hardware development methodologies, High-Level Synthesis (HLS) offers a faster time-to-market and lower design-cost at the expense of implementation efficiency. Although HLS tools are becoming popular in some applications such as digital signal processing and neural network classification, their usability on cryptographic applications is largely unexplored. This feasibility is critical especially for cryptosystems that are under development such as the next-generation public-key cryptosystems needed for quantum-resistance. This paper provides a thorough investigation of HLS on Number Theoretic Transform (NTT)&#x2014;the core arithmetic function of lattice-based quantum-resistant cryptosystems. We demonstrate a fast yet extensive design space exploration of NTT through the Vivado HLS tool, analyze the shortcomings/challenges of optimized configurations, and quantitatively compare the results to software-based and hand-coded hardware designs. This work paves the way for the hardware design space exploration of the ongoing NIST post-quantum cryptography standardization and provides a baseline for future optimizations.",60004923,NC State University,Raleigh,United States,['1700'],24.33333333333333,0.12032967032967032,0.522069597069597,1,0.07567567567567568,0.07027027027027027,0.40606060606060607
543,557,557,Calculation of the invested capital profitability in the financial condition analysis process,"The article examines the issues of calculating the return on invested capital according to the financial statements. Proposals are given to implement the results of the methodology on the practice of joint-stock companies. The use of the method of factor analysis in this direction when calculating the profitability of capital investments based on financial data used in developed foreign countries has a positive result. In particular, the increase in profits under the influence of the factor of turnover of capital and profitability of income allows you to calculate the return on investment.",60071662,Tashkent State University of Economics,Tashkent,Uzbekistan,['1700'],23.0,0.061489898989898976,0.2172979797979798,1,0.12121212121212122,0.0,0.20618556701030927
544,559,559,A systematic review on the studies of climate change and its effect on public health,"Climate change refers to the fluctuations in the earth’s atmosphere that occurs over a longer period of time due to natural processes or human activities. Climate change causes increase in the occurrence of incidences and degree of severe climate events such as cyclones, heat waves, floods and droughts which are referred as direct effect. Gradual changes in climate called as indirect effect results in unpredictable rainfalls, rising sea and temperature levels, affects water and air quality. These direct and indirect effects adversely impact community health. Health impact of changing climate is distributed into multiple categories of diseases such as cardiovascular diseases, respiratory diseases, allergies, mental Illness and infectious diseases. Climate change affects human health especially when vector borne infectious diseases are concerned as survival, reproduction or distribution of disease viruses are predominantly susceptible to climatological conditions. The impact of climate variation on human health also depends on multiple parameters such as geographical location, exposure, sensitivity, vulnerable population, socio-economical condition and adaptive strategies. For investigating the consequences of climate variation on public health, a huge amount of climate data is collected regularly from metrological department. Similarly, health data such as incidences of diseases are collected along with period, place, gender and age of patients from various private/ public health centers. Analysis of this data has been done using different technologies such as big data analytics, machine learning/ deep learning algorithms. Accurate analysis of climate data and its effect on health diseases benefits early detection. The effective surveillance system can help in monitoring climate change and taking counteractive actions to improve public health conditions. This paper reviews the climate change and their causes, growth in different categories of diseases due to climate change, the impact of drastic and gradual climatic changes on social health and implemented adaptation strategies.",60104400,Symbiosis International (Deemed University),Pune,India,['1700'],22.76923076923077,0.024019607843137256,0.3831447963800905,1,0.08459214501510574,0.006042296072507553,0.30606060606060603
545,560,560,Proficiency of internal auditors and effectiveness of public sector audit in malaysian public organizations,"Public sector auditing is important, albeit not the most exciting component of government. It is presumed that internal auditors are accountable in carrying out an audit to guarantee compliance to the laws and regulations, in revealing unwarranted components that may lead to ineffective and uneconomical procedures, and in voicing out a judgment on the fairness and truth value of the financial statements. Besides, they are also accountable to make sure that the records are prepared in accordance to the commonly accepted accounting and auditing standards. However, to date, it is still questionable whether this audit is efficient and effective due to the increasing trend in the reported manipulations and frauds in government departments. Moreover, it was revealed that there were cases of auditors who were fined and prohibited from auditing because of falsifying audit report and for non-compliance with audit procedures. Hence, focusing mainly on the public sector, this paper studies the impacts of internal auditors’ proficiency on the efficacy of internal audit. The data were acquired from 203 internal auditors from Malaysian public sector organizations. In the process of collecting the information, self-administered questionnaires were distributed. The method used as the major statistical techniques was the partial least squares structural equation modelling (PLS-SEM) technique. It can be concluded that proficiency promotes the efficacy of public sector audit.",113170399,Universiti Sultan Zainal Abidin,Kuala Trengganu,Malaysia,['1700'],21.8,0.05734126984126984,0.3649470899470899,1,0.11336032388663968,0.012145748987854251,0.29045643153526973
546,561,561,Detecting tumours by segmenting MRI images using transformed differential evolution algorithm with Kapur’s thresholding,", part of Springer Nature.The speed and accuracy with which the patient affected with brain tumour is diagnosed and monitored, plays a very crucial role in providing treatment to the patient. During the diagnosis of the diseased part, a constant demand is anticipated to easily extract the specific region of interest within the complex medical image. This task of extracting only the diseased portion amid the complex body parts in the complex medical image can be achieved by image segmentation. Accuracy and speed of extracting the points or area of interest within the multipart medical image can be improved by using various evolutionary techniques. Differential evolution (DE) is an efficient evolutionary technique that can be used for solving optimisation problem like image segmentation. The main disadvantage of classical evolutionary technique is its inability to adapt its solution algorithm to a given problem. Owing to this need, more adaptable and flexible algorithms are in demand. Numerous variants of DE exist which differ in their solutions. Here, a variant of differential evolution named as transformed differential evolution (TDE) is presented which has an improved mutation strategy that is optimised to fewer function evaluations. This variant is combined with the Kapur’s multi-level thresholding for segmenting magnetic resonance imaging (MRI) images and to extract only the regions of tumour. The results obtained using TDE with Kapur’s multi-level thresholding were compared with the results using traditional Kapur’s technique and the new results improved profoundly. By introducing TDE in multilevel thresholding, the computational time significantly reduced and the resultant image quality improved greatly.",60104535,Machine Intelligence Research Labs (MIR Labs) - Scientific Network for Innovation and Research Excellence,Auburn,United States,"['1712', '1702']",21.416666666666668,0.016445707070707073,0.5272727272727272,1,0.1245674740484429,0.03806228373702422,0.3321678321678322
547,562,562,"Do fine dine restaurants satisfy customer needs?Diners’ perception of functional aspects of quality, value and satisfaction","Objectives: Guest satisfaction has emerged as a potentially important factor in restaurant performance and function. The objective of this paper is to examine the current state of guest satisfaction and factors affecting them in fine dining restaurant through a review of the literature. The review focuses on six determinants and their effect on guest satisfaction. Design: A systematic review of lighting, Type of music, food quality, food quantity, food plating and foodservice about guest satisfaction was performed. Review methods: The literature was derived from the published research articles. The selection criteria for the review included the studies that were; written in English, related to guest satisfaction in the hospitality sector, employee performance in the hospitality sector. Results: The literature review identified five distinct lines of research that have focused on guest satisfaction in fine dining restaurants. Total 52 guest satisfaction – based articles referenced in this paper, a sample of 30 studies reported on the examination of antecedents of satisfaction among guests. Key findings suggest that all the five factors that are; lighting, Type of music, food quality, food quantity food plating, and foodservice significantly impact on guest satisfaction. Conclusions: The study of Factors affecting guest satisfaction in a fine dining restaurant helps in the restaurant to build an image in the minds of their guests and creates awareness for Guests on how fine dining functions. Future research is required to provide restaurants a better understanding of their guests for their satisfaction.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],22.0,0.21611111111111111,0.4966666666666666,1,0.08487084870848709,0.0036900369003690036,0.28413284132841327
548,563,563,Automated Fortran-C++ Bindings for Large-Scale Scientific Applications,"USGovAlthough many active scientific codes use modern Fortran, most contemporary scientific software libraries are implemented in C and C++. Providing their numerical, algorithmic, or data management features to Fortran codes requires writing and maintaining substantial amounts of glue code. This article introduces a tool that automatically generates native Fortran 2003 interfaces to C and C++ libraries. The tool supports C++ features that have no direct Fortran analog, such as templated functions and exceptions. A set of simple examples demonstrate the utility and scope of the tool, and timing measurements with a mock numerical library illustrate the minimal performance impact of the generated wrapper code.",60024266,Oak Ridge National Laboratory,Oak Ridge,United States,['1700'],20.8,0.12037037037037035,0.43597883597883597,1,0.10526315789473684,0.08771929824561403,0.37719298245614036
549,564,564,Hooliganism against hospitals and medical personnel: Weak law unable to deal with the situation,"In the popular imagination of a malpractice suit instigated against a medical professional, a prior act of Hooliganism and Vandalism by patients relative straddles an anomalous but a certainly presumptive space. This is ironic. Medicine and its practice is the highest form of a scientific endeavour set sail to prevent the frailty of a human body succumbing to the vagaries of nature yet a little deviation in outcome in present day scenario leads to such devastating acts by patient’s relatives/attendants that in certain Western countries many promising practitioners have left their practice. In India this has become a growing trend. Grievously injuring an attending doctor for little or no “fault” has become a very common scene. This has increased to such an extent that in a recent happening, a 75 years old physician was beaten to death by patient’s attendant. A complete negative coverage by media lame duck laws and hesitant politicians and judiciary, has added fuel to fire. The present paper is aimed to study such a happening with reasoning as to the causation.",60076774,"Amity University, Noida",Noida,India,['1700'],21.875,-0.03229064039408867,0.40320197044334977,1,0.08854166666666667,0.015625,0.25
550,565,565,Automated inception network based cardiac image segmentation analysis,"Coronary Heart disease is one of the main threats to human health, and approximately ten million people die from heart disease annually throughout the world. Magnetic resonance imaging is widely used for cardiopathy diagnosis. Left ventricle Segmentation from cardiac magnetic resonance imaging (MRI) is considered as significant process for estimation of clinical indices such as stroke volume, ejection fraction. This research paper proposed a new automatic LV segmentation method, which is attained by using Inception based Convolutional Neural Network (ICNN). The technique uses the inception network power, which is combined with convolutional layers in deep neural network architecture. The research study empirically evaluated the segmentation accuracy of the proposed ICNN model by using publicly available benchmark dataset. The experimental results stated that the developed method achieved 94.23% segmentation accuracy than existing neural networks.",60002978,Visvesvaraya Technological University,Belgaum,India,['1700'],19.0,0.08771645021645022,0.304491341991342,1,0.11409395973154363,0.06711409395973154,0.33557046979865773
551,566,566,Kronecker’s Lemma and a converse with applications,"Kronecker’s Lemma asserts that the mean of a real sequence {an} is zero if (formula presented) converges. We give a new proof for the case an ≥ 0 . If {an } is bounded, a partial converse was given by Hlawka et al [5]. We state sevaral applications of this converse from our work.",60017870,Institute of Chartered Financial Analysts of India,Hyderabad,India,['1700'],13.5,-0.01903409090909091,0.4355113636363637,1,0.09090909090909091,0.07575757575757576,0.43283582089552236
552,567,567,Measuring the effectiveness of green computing awareness program,"Knowledge is basically the first step in the adoption process of green computing. There has been a tremendous energy wastage and a great financial loss around the world due to the lack of knowledge in green computing. Half of the world’s energy wastage is caused by the uninformed practices of users and consumers. It should be made imperative for every organization to design green awareness programs not only to educate but also to change the attitude and behavior of its employees. This study aims to design, implement and measure the effectiveness or benefits of green computing awareness program. The overall research strategy includes literature review, quantitative and qualitative data collection, statistical analysis of the data using Statistical Package for Social Science (SPSS) 24 followed by a discussion on the results. The research methodology integrated the quantitative methods including independent t-tests and ANOVAs in a stratified random convenient sample of 218 undergraduate students in 2019 in Jazan, Saudi Arabia. Two surveys were used for the data gathering, one before and the next after the completion of the awareness program. The first survey revealed that although the computer literacy among the students is very high, they have, however, little or no knowledge about green computing. This reflected in the lower score in the other domains like attitude and behavior. Based on the outcome of the first survey, a comprehensive green computing awareness program was planned, designed and implemented. The program included seminar, classroom training, focus-group training and web-based training which was followed by the green computing awareness program. The second survey was carried out to measure the effectiveness of the program. The survey revealed that the green computing awareness program was very effective. The mean score values in all the three domains: knowledge, attitude and behavior had significantly improved. The mean score test also recorded a significant difference in the mean score of the first and the second survey.",60106293,Jazan University,Jazan,Saudi Arabia,['1700'],19.8125,0.007735294117647062,0.4148872549019608,1,0.08426966292134831,0.025280898876404494,0.2564102564102564
553,568,568,Multimodal approach with face and iris to enhance the efficiency of biometric system using soft biometrics,"Biometric technology is the science of identifying human being by extracting a feature set from data and comparing with template store in database. A biometric system is used for identifying the person either genuine or imposter by using their physiological traits (hand geometry, face, fingerprint, Iris etc) and behavioral traits (voice, gait, signature etc.). A Biometric system which uses only single trait for recognition is known as unimodal biometric system. The performance of unimodal system is not good due to some limitation such as noisy sensor data, non-universality etc. Unimodal biometric system uses only single trait of biometric for recognition and do not provide better authentication for highly secured application. Multimodal biometric systems solve all the limitations related to unimodal biometric system. Multimodal combines different physical and behavioral traits such as face and finger print, fingerprint and signature etc. A new approach multimodal was developed to overcome the limitation of unimodal system and also improve the security. There are also some other traits such as skin color, age, height, hair color, eye color, gender called “soft biometric traits”. Soft biometric traits do not provide reliable authentication because the nature of these traits are not permanent. Due to the lack of permanence and distinct property in soft biometrics, it can be used with other traits for improving performance of biometric system. This paper proposes a framework by combining physical traits (face and iris) with soft biometric trait (eye color) for enhancing biometric system security and performance.",60113765,"Desh Bhagat University, Mandi Gobindgarh",Mandi Gobindgarh,India,['1700'],20.416666666666668,0.037166907166907175,0.4225493025493025,1,0.09187279151943463,0.01060070671378092,0.26785714285714285
554,569,569,YOLACT: Real-time instance segmentation,"We present a simple, fully-convolutional model for real-time instance segmentation that achieves 29.8 mAP on MS COCO at 33.5 fps evaluated on a single Titan Xp, which is significantly faster than any previous competitive approach. Moreover, we obtain this result after training on only one GPU. We accomplish this by breaking instance segmentation into two parallel subtasks: (1) generating a set of prototype masks and (2) predicting per-instance mask coefficients. Then we produce instance masks by linearly combining the prototypes with the mask coefficients. We find that because this process doesn't depend on repooling, this approach produces very high-quality masks and exhibits temporal stability for free. Furthermore, we analyze the emergent behavior of our prototypes and show they learn to localize instances on their own in a translation variant manner, despite being fully-convolutional. Finally, we also propose Fast NMS, a drop-in 12 ms faster replacement for standard NMS that only has a marginal performance penalty.",60014439,"University of California, Davis",Davis,United States,"['1712', '1707']",22.142857142857146,0.05246031746031746,0.5542063492063491,1,0.10638297872340426,0.03723404255319149,0.3693181818181818
555,570,570,Proposing a novel predictive technique using M5Rules-PSO model estimating cooling load in energy-efficient building system,", part of Springer Nature.In this study, we employed the most suitable artificial intelligence systems and optimized it with a novel evolutionary algorithm called particle swarm optimization (PSO) for the problem of cooling load (CL) in energy-efficient building (EEB) system. Then, the mentioned methods are utilised to identify a relationship between the input and output parameters of the EEB system. The amount of CL was taken as the essential output of the EEB system, while the input parameters were channel length, channel depth, channel width, and air mass flow rate. The predicted results for data sets from each of the abovementioned models were evaluated according to several known statistical indices such as correlation coefficient (R2), mean absolute error (MAE), root mean squared error (RMSE), relative absolute error (RAE), and root relative squared error (RRSE) as well as novel ranking systems of colour intensity rating and total ranking method. The M5Rules has been proposed as the best predictive network in this study. The results of the M5Rules network indicated the R2, MAE, RMSE, RAE, and RRSE for the training and testing data sets were 0.9982, 0.0426, 0.0653, 6.2344, and 6.0298 and 0.7626, 0.9903, 0.9593, and 0.9981, respectively. According to R2, RMSE, and VAF, values of 0.99983, 0.0066, and 99.98 and 0.9982, 0.065, and 84.5 were obtained for testing data set and values of proposed PSO-M5Rules prediction network models, respectively. This indicates higher reliability of the introduced PSO-M5Rules model in approximating CL of an EEB system.",60078563,Ton-Duc-Thang University,Ho Chi Minh City,Viet Nam,"['1712', '1706']",30.5,0.08676470588235295,0.4691176470588235,1,0.08496732026143791,0.08823529411764706,0.4395973154362416
556,571,571,Landslide Multi-attitude Data Measurement of Bedding Rock Slope Model,"At present, commonly used measurement methods for landslide model pay much attention to the measurement of global displacement without a detailed description of individual components. However, the multi-attitude data concerning the model of bedding rock slope lay the data foundation for describing the mechanism of landslide. In an attempt to obtain the 3D multi-attitude displacement data, this paper, based on the binocular stereo vision as the measurement tool, adopts the cyclic coded targets to follow the unique track of rock block trajectory. Furthermore, a combination of circular coded targets and assisted location marks is designed to obtain the spatial displacement and rotation angle of rock mass center implicitly through the local coordinate system. Finally, the data such as speed, accelerated speed are acquired in accordance with the relationship of time domain and spatial domain. The experiment results show that this paper provides an effective method for the collection of elaborate and accurate landslide data of the bedding rock slope model.",60028891,Chang'an University,Xi'an,China,"['1712', '1710']",26.66666666666667,0.14821428571428572,0.4916666666666667,1,0.09550561797752809,0.0,0.20114942528735633
557,572,572,Catenation of BSE and NSE,"Stock Exchanges are the vitals of an economy. Bombay Stock Exchange and National Stock Exchange provides an effective platform to exchange the securities. Marked by distinct rules, they drive an automated system with an objective of investor protection. Further, their objective is to attain an international level. The present paper is an attempt to understand the correlation, co-integration between NSE and BSE. Moreover, emphasis is also laid on the understanding between the up and down movements of share price. Tools Pearson correlation, Unit root test and johnson co-integration test have also been employed. Study concludes that there exists a strong correlation between the two existing variables.",60111704,Chandigarh University,Mohali,India,['1700'],13.25,0.12777777777777774,0.3422222222222222,1,0.08943089430894309,0.08943089430894309,0.3445378151260504
558,573,573,Consumer acceptance and adoption towards payment-type fintech services from Malaysian perspective,"Fintech is touted as a new paradigm in which information technology is driving thetransformation and innovation in the financial services industry. Fintech is evolving at a rapid speed, driven by favorable regulation, information technology and led by the consumer’s acceptance and adoption whose keen for cost reduction and improved quality of financial services. This paper conducted a descriptive analysis on consumer acceptancetowardspayment-type Fintech service by applying variables associated with Technology Acceptance Model and Diffusion of Technology. In addition, it analyzed the determinants of payment-type Fintech service adoption among Malaysian’s mobile user and the causal relationship between variables towards consumer decision in adopting payment-type Fintech service. Quantitative research and descriptive research are utilized.The outcome indicates all variable are significant except perceived ease of use and social influence.",60104614,Taylor's University Malaysia,Subang Jaya,Malaysia,['1700'],25.2,0.10893939393939392,0.27924242424242424,1,0.09027777777777778,0.08333333333333333,0.30434782608695654
559,574,574,Evaluating Researchers Based on the Criteria of Reputation Responsibility,Abstract—: This article considers the problems of developing objective criteria for evaluating researchers. The approaches to assessing academic reputation are shown to be similar to those for assessing corporate goodwill. The elements that make up academic reputation are identified. A technique of ranking researchers by reputation that combines scientometric indicators with peer appraisal is proposed. The principle of selecting peer committee members based on bibliometric indicators is enunciated. The application of collective peer appraisal methods to the construction of the scales of the indicators of the proposed reputation ranking is shown. The concept of an automated system intended for compiling the proposed reputation ranking of researchers is presented.,60014602,All-Russian Institute for Scientific and Technical Information of Russian Academy of Sciences,Moscow,Russian Federation,['1700'],15.428571428571427,0.0,0.1,1,0.18803418803418803,0.017094017094017096,0.35344827586206895
560,575,575,Enhancing model performance in detecting abnormalities on human musculoskeletal system through optimization techniques using deep learning,"Musculoskeletal Radio-graph studies have gained much attention over the recent years in the field of Medical Science and with the advancement of Deep Learning, it has gained high prominence in terms of Classification of Disease or Abnormalities in the Human Musculoskeletal Systems. In this paper, we have taken a MURA Dataset (MURA stands for Musculoskeletal Radio-graphs) and based on the previous studies by the Radiologists, we have classified the Radiograph Images as either Normal or Abnormal for Seven Categories of Studies. Those Seven categories are Elbow, Finger, Forearm, Hand, Humerus, Shoulder and Wrist. Also we have generated the AUROC curve for the results we have obtained after training the Model with the classifier. In our work, we have also used different combination of Network Architecture with the use of ADAM optimizer to compare & analyses the best one that can optimize the Model to provide the best possible results in case of MURA Dataset.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],30.8,0.19527777777777774,0.3755555555555555,1,0.08620689655172414,0.1781609195402299,0.4411764705882353
561,576,576,Nonlinear system identification using BBO-based multilayer perceptron network method,"Recently, nonlinear system identification has received increasingly more attention due to its promising applications in engineering fields. It has become a challenging task to truly apply this system due to many complex factors especially the nonlinear and dynamical properties. The objective of this paper is to design a nonlinear system identification method using an appropriate learning method. This paper proposes a biogeography-based optimization (BBO)-based multilayer perceptron (MLP) architecture for nonlinear system identification. The BBO algorithm with its habitats imitates the species migration between them. A good solution is featured by an island with a higher High Suitability Index (HSI), and a poor solution by an island with a lower HSI. Higher HSI solutions resist change more effectively than lower HSI solutions. By combining the two schemes, the proposed MLP architecture with BBO learning provides a promising scheme for nonlinear system identification. Three kinds of nonlinear system are adopted for experimental verification, including Mackey–Glass series, Henon system, and nonlinear plant system. Mean squared error (MSE) index is used to calculate the difference between the measured input and output of the systems. By employing the nonlinear cases, the proposed algorithm presents rapid convergence and excellent MSE in nonlinear system identification.",60014261,National Yunlin University of Science and Technology,Douliou,Taiwan,['1708'],18.0,0.21352272727272725,0.55125,1,0.1013215859030837,0.09251101321585903,0.3422222222222222
562,577,577,A coordination protocol language for power grid operation control,"Future power distribution grids will comprise a large number of components, each potentially able to carry out operations autonomously. Clearly, in order to ensure safe operation of the grid, individual operations must be coordinated among the different components. Since operation safety is a global property, modelling component coordination typically involves reasoning about systems at a global level. In this paper, we propose a language for specifying grid operation control protocols from a global point of view. In our model, operation control is yielded in communications driven by both the grid topology and by state-based information, features captured by novel language principles previously unexplored. We show how the global specifications can be used to automatically generate local controllers of individual components, and that the distributed implementation yielded by such controllers operationally corresponds to the global specification. We showcase our development by modelling a fault management scenario in power grids.",60102060,"Institutions Markets Technologies, Lucca",Lucca,Italy,"['1712', '1703']",21.142857142857142,0.057703081232492986,0.2722689075630252,1,0.15757575757575756,0.0,0.3006134969325153
563,578,578,Game analysis of the equity investment exit mechanism of university schools and enterprises under the background of internet multimedia convergence,"In today’s highly developed information, multimedia involves no longer just the traditional teaching and media industry, but a broader and more comprehensive process. The game analysis of using the Internet multimedia to carry out the investment exit mechanism of colleges and universities can greatly improve Management efficiency. This paper analyses the game form of the equity investment exit mechanism of colleges and universities in the context of Internet multimedia fusion, and analyses its existence and significance to enhance the equity exit mechanism of schools and enterprises, and analyses and discusses them. This paper establishes a game analysis on the exit method and exit timing of college-enterprise equity investment, which has certain reference value. The perfect exit mechanism is an inevitable requirement for the development of equity investment in colleges and universities, and it is an inseparable part of the equity investment system of colleges and universities. This will enable China’s colleges and universities to have a relatively good and standardized operating environment for equity investment, which will drive China’s economic connotation growth. This has related to the construction of many external environments such as capital markets, policies, and regulations. Therefore, it is necessary to improve the multi-level capital market as soon as possible and accelerate the construction of external systems such as policies and regulations.",113167254,Xi'an International University,Xi'an,China,"['1712', '1708', '1705']",26.875,0.1407142857142857,0.5485714285714285,1,0.075,0.0125,0.26778242677824265
564,579,579,Enhanced audio signal noise removal using five level fuzzy haar wavelet transform,"This paper develops a novel idea on noise removal for audio signals specifically while performing voice pathology detection. Existing noise removal methods have commonly proven to be effective, so far these methods characteristically revels convinced unwanted features. Elimination or modification of the original audio feature of principal audio sound is a major issue. In case of voice pathology detection, it is very essential to perform denoising which will highly improve the classification accuracy. This work proposed a fuzzy enhanced approach which not only reduces the presence of noise but also used to recognize and preserve the richness of the audio spectrum. The proposed method using fuzzy wavelet noise reduction in audio signals is compare with ordinary wavelet denoising. Simulation results illustrates that the proposed work removes noise significantly and increases the classification of voice disorder with more accuracy.",60114485,Chikkanna Government Arts College,Tiruppur,India,['1700'],19.714285714285715,0.16854166666666667,0.64625,1,0.1564625850340136,0.0,0.23129251700680273
565,580,580,How Do Market Standards Inhibit the Enactment of Digital Capabilities?: A Case Study of Airline Pricing,"Digital capabilities can improve organizations’ performance by supporting complex decision-making processes. However, when market standards constrain their enactment, the potential benefits promised by digital capabilities do not realize. The paper explores this tension by means of the critical case of a European airline, which had difficulty to enact a novel pricing approach and finds that market standards are entrenched in the airline’s pricing and distribution ecosystem. This causes the organization to focus on local improvements and IT-based workarounds instead of enacting a dramatically new and potentially improved digital pricing capability.",60030718,Freie Universität Berlin,Berlin,Germany,['1710'],22.5,0.007851239669421488,0.3549586776859504,1,0.1553398058252427,0.0,0.36
566,581,581,A study on fast moving consumer goods sector-a comparitive study on dairy and soft drink products,"A promotion announcing the benefits of a product or brand along with distribution efforts is observed in the rural markets in the FMCG category. The Customer satisfaction is essentially the culmination of a series of customer experiences or, the net result of the good ones minus the bad ones. It occurs, when the gap between customers’ expectations and their subsequent experiences has been closed. Today we notice there is shift being observed towards branded (FMCGs) Fast Moving Consumer Goods in rural areas as a result of Socio Economic & Political changes in the last 5 years. This has made rural areas more viable markets when compared to the urban areas. The Socio Economic and Political changes contributed to a great extent for changes in the life styles of countryside people who patronized branded Fast Moving Consumer Goods products. The Government policies/ approaches to advance education in restrict areas enhanced the brand awareness among the customers because of the presence at least one student pursuing higher education in a family. The diverse Government strategies are additionally being helpful for the province individuals (rural people) contributing for the in improvement in individuals income, image and mindfulness followed by a change in their lifestyles resulted in patronizing the branded products. Sales promotion is a tiny term incentive to be a magnet for the buy or sale of products and services. It includes all activities that are performed by the producers or by dealers or by businessmen to boost its sale over a period of time. Purpose behind sales promotion is to motivate and persuade the consumers to buy a certain product and to encourage repetitive purchase of that very product and enable repetitive purchase of that thing.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],25.818181818181817,0.047044334975369466,0.2898193760262726,1,0.0924092409240924,0.0297029702970297,0.3201320132013201
567,582,582,Large eddy simulation of flow past three elliptical cross-section cylinder arrays in equilateral triangle arrangement,"The stream past different bluff bodies in array has been the chief area of interest to carry out research for many analysers for the past spans of years. To judge the flow characteristics throughout assemblage of cylinders, numerical simulation of flow over three elliptic cylinders in an equilateral triangle arrangement for two Reynolds numbers i.e. 10200 and 15200 across the elliptic cylinders is examined in this paper. Simulation is performed by choosing 3-D LES (Large-eddy simulation) executed with the help of commercial software ANSYS Fluent 19R1. The simulation results consist of both qualitative and quantitative findings with velocity vectors contours of flow for both the Reynolds numbers, lift and drag coefficients, and Power spectral density plots.",60000674,National Institute of Technology Kurukshetra,Kurukshetra,India,['1700'],23.2,-0.016666666666666666,0.27847222222222223,1,0.07086614173228346,0.031496062992125984,0.3492063492063492
568,583,583,Coefficient inequality for sakaguchi kind of functions related to shell – like curves connected with fibonacci numbers,"In this paper, the Taylor-Maclaurin coefficients [Formula Presented] and [Formula Presented] of the two new subclasses of bi univalent of Sakaguchi kind of functions related to shell – likes curves connected with Fibonacci numbers in the open unit disk [Formula Presented] have been investigated. Further Fekete – Szego inequalities for these classes are determined.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],27.0,0.14727272727272728,0.5509090909090909,1,0.09230769230769231,0.2,0.5238095238095238
569,584,584,The search for embeddedness: Leveraging scientific-based modeling in disaster response," All rights reserved.During the first few hours of disaster response, confusion is at its highest, the common operational picture is most vague, communication is limited, and information overload is common. Discerning relevant from nonrelevant information presents a huge challenge to decision makers. While the top priority at this time is obtaining accurate situational awareness, this is not an easy task, due perhaps to damages to infrastructure and the complexity of the event. Using existing modeling technologies can help by providing an initial model of the event that can then be updated as more accurate information becomes available. However, to many emergency managers, the thought of adding more, not necessarily accurate, information into the chaotic response environment is undesirable. Their unfamiliarity with the technology tools adds to their skepticism. This article investigates the reasons that emergency managers in disaster response environments under-utilize scientific modeling technologies. The goal is to provide guidance to increase the utilization of these technologies by developing a model using concepts of embeddedness and technology adoption. We employ four contextual constructs (task characteristics, technology characteristics, individual user preferences, and environmental characteristics) to describe the context of system characteristics needed to support decisions on the use of scientific modeling technology during the emergency planning and response. Context is a precondition to embeddedness, and embeddedness of the technology is measured by utilization and preference. Utilization is the degree to which the technology is used to accomplish a goal. For emergency managers to rely on scientific-based modeling in a disaster environment, they must first trust the technology. Trust can be described as closeness or personal familiarity. We conceptualize trust, and the closeness between the emergency manager and the technology, as preference. Preference portrays the emergency managerâ€™s desire to use the technology to undertake a task and includes the emergency managerâ€™s feelings of trust and personal familiarity with the scientific modeling software. In our concept, the emergency manager and the scientific-based modeling technology cooperate to respond to the disaster. Our model indicates that context is a precondition to embeddedness. Emergency managers focus on making decisions to minimize the impacts of a disaster on both the human and built environments, particularly on decisions regarding mass care. Therefore, the task characteristics involve the ability of the modeling technology to support the decision-making activities regarding mass care and to contribute in a meaningful way toward the accomplishment of response efforts. Technology characteristics concern the reliability of the software/hardware, availability, flexibility to accomplish the task, and ease of use. Individual user preferences concern individualsâ€™ willingness to use the technology and their knowledge concerning appropriate usage. Environmental characteristics refer to appropriate training, organizational adoption, and culture concerning the use of scientific modeling technologies. Related but more detailed questions that can be extracted from exploration of the embeddedness model include: â€¢ What causes emergency managers to reject the use of scientific-based modeling technologies? â€¢ What are the impediments to emergency managersâ€™ use of scientific-based modeling technologies for disaster response? â€¢ What are the characteristics of the disaster context that influence the use of scientific-based modeling technologies for disaster response? The objective is to provide insights that will allow emergency managers to harness the capability that scientific-based modeling technology provides to improve decision making in the complex and chaotic disaster response environment. The focus of this article is not on developing new technology but instead on determining methods for appropriating, integrating, and using candidate technologies to respond to an extreme event. Scientific modeling technologies can enable the decision making necessary in this often-chaotic environment. We believe that the effective use of modeling technologies will improve disaster mitigation, preparedness, response, and recovery, leading to better economic and human outcomes. The challenge for disaster response managers is how to better integrate technology into their operations and how to lead others to use it effectively.",60014693,Loyola University Maryland,Baltimore,United States,"['1712', '1706']",23.48148148148148,0.19124852420306968,0.4785394529712713,0,0.12672176308539945,0.009641873278236915,0.2697274031563845
570,585,585,Text classification performance analysis on machine learning,"Automated text classification has been considered as a vital method to manage and process a vast amount of documents in digital forms that are widespread and continuously increasing. In general, text classification plays an important role in information extraction and summarization, text retrieval, and question answering. Intrusion detection system plays an important role in network security. Intrusion detection model is a predictive model used to predict the network data traffic as normal or intrusion. Machine Learning algorithms are used to build accurate models for clustering, classification and prediction. Labeled text documents are used to classify the text in supervised classifications. This paper applied these classifiers on different kinds of labeled documents and measures the accuracy of the classifiers. An Artificial Neural Network (ANN) model using Back Propagation Network (BPN) is used with several other models to create an independent platform for labeled and supervised text classification process. An existing benchmark approach is used to analysis the performance of classification using labeled documents. Experimental analysis on real data reveals which model works well in terms of classification accuracy.",60114867,"SR Engineering College, Warangal",Warangal,India,['1700'],17.7,0.06718750000000001,0.4989583333333333,1,0.13846153846153847,0.046153846153846156,0.3384615384615385
571,586,586,Optimal allocation of PV and DSTATCOM for enhancing the power quality of east delta egyptian distribution network,"This paper determines the optimal sitting and sizing of photovoltaic (PV) generation units and Distribution Static Synchronous Compensator (DSTATCOM) in the real distribution network East Delta Network (EDN). In the study using an efficient optimization algorithm called Ant lion optimizer (ALO) for enhancing the power quality of this network. The considered objective function is a multi-objective function which includes minimization of power losses, enhancement of voltage profile and improving the system stability considering the system equality and inequality constraints. The studied cases are presented in this paper including installation of PV units only, installation of DSTATCOMs only and installation of PV units along with DSTATCOMs. The simulation results reveal that, the objective function is enhanced considerably by installation of PV units along with DSTATCOMs compared to other cases. Moreover, the results verify the applicability and the effectiveness of ALO for determining the optimal locations and ratings of PV units and DSTATCOMs in this network.",60014101,Sohag University,Sohag,Egypt,['1700'],25.66666666666667,0.08437499999999999,0.5281250000000001,1,0.09770114942528736,0.10344827586206896,0.37790697674418605
572,587,587,Trends and patterns in passenger traffic in aviation sector: A comparative study of BRICS countries,"The study examines the trends and patterns in passenger traffic in five emerging economies i.e. Brazil, Russia, India, China and South Africa. It studies monthly and yearly data for the past 24 years and tries to examine the patterns of growth in the selected countries. The Compound annual growth rate (CAGR) was calculated to see the differences in passenger growth followed by paired student-t test to see if significant differences exist between the mean values. The results revealed interesting trends for Airline Industry in general and more specifically for Indian Aviation sector. The results reveal significant scope of growth in Indian aviation sector in future especially due to low current level of penetration. Further, the low fuel price and favorable government policy, exchange rate and improved liquidity provide indications of brighter prospects for Aviation sector in the near future.",60028153,Banasthali Vidyapith,Vanasthali,India,['1700'],19.857142857142858,0.06171875000000001,0.46796875,1,0.09740259740259741,0.08441558441558442,0.3202614379084967
573,588,588,The adult ambulatory chair and its influence on geriatric population,"Introduction: Falls are known as an event leading a person coming to rest inadvertently on the ground. Recently, frequency of falls in geriatrics associated with walking aids devices has been a concern within the medical fraternity. Many studies had been conducted to look into the effects of ambulatory aids as well as falls which will lead to mortality and morbidity especially in elder populations who are more than 65 years old. However, the research data found that current ambulatory aids used in geriatrics is not proven to reduce the risk of falls. Objective: The primary objective is to design a special ambulatory aid in turns to reduce the risk of fall and to improve the quality of life in geriatric population. Methods: A reliability test is carried out with 10 healthy adults who are around 20 to 30 years of age, 6 females and 4 males. The baseline measure for this study includes 5 questionnaires. This test is to test the endurance of adult ambulatory chair (AAC) under certain conditions, identify the failure rates and propose preventative measures that can increase the product’s reliability lifespan. Results and findings: Data was analyzed by using the Chi-square test. A significant result has been shown for the first and second close ended question in reliability test. Thus, our product AAC has proved to be reliable. Conclusion: As a conclusion, due to unavoidable aging related changes in elder populations, complications as limited physical and functional mobility as well as deterioration in quality of life are often exists. A suitable ambulatory device is essential to prevent these unwanted consequences.",60078092,"Asian Institute of Medicine, Science &amp; Technology",Bedong,Malaysia,['1700'],20.30769230769231,0.13888888888888887,0.3796626984126985,1,0.1054421768707483,0.013605442176870748,0.2832764505119454
574,589,589,IoT architecture for water leakage in tunnel analysis and monitoring using cloud platform,"The scarcity of water is getting increased day to day almost 70% urban cities depend on the Municipal water which passes from one place to other through the tunnels. Nowadays it is identified in the news that water is the major problem faced by the people of the country. The ideal aim is to monitor the water in the flowing tunnel with the help of sensors which monitors the flow speed and the flow rate of the water in the tunnel and the sensor data is pushed to the cloud and stream analytics is visualized in the Microsoft Azure cloud platform. When there is a leak the particular place is identified and the problem could be analyzed within minutes. By this approach, some gallons of water could be prevented from leakage and be wasted. The experimental result in this paper gave a positive result with variation in water and the Objective of this paper is to safely transfer the water in a tunnel without leakage and which carries gallons of water from one place to another place.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],29.5,0.1631439393939394,0.3753787878787879,1,0.11351351351351352,0.010810810810810811,0.17297297297297298
575,590,590,The use of trigonometry in blood stain pattern,A case study on blood stains pattern or blood spatter is analysed. Though trigonometry play a vital role in blood stain pattern during crime. In this paper we analyze the blood spatter by using Rossmo’s formula to find angle of impact via trigonometry. The recognition and analysis of blood spatter can yield useful crime investigative information. The most probable scenario resulting in blood spatter on walls and floor can be reconstructed during crime using trigonometric analysis. Forensic science considers physical evidences relating to criminal activity. Some numerical examples were given to show the effectiveness of the proposed theory.,60114457,Sri Krishna Arts and Science College,Coimbatore,India,['1700'],14.0,0.1,0.3185714285714286,1,0.1509433962264151,0.009433962264150943,0.21495327102803738
576,591,591,An automatic framework to convert component based serial code to parallel code for GPU processor,"Software module serial and parallel codes are used to reduce the delivery time and increase parallel processing time. Most of the recent software developments are applying parallel processing of the source code. The parallel processing of the source code is not only the responsibility of hardware or GPU. The source codes are also to be written in a specific form using the parallel processor. At the same time, the utilization of the software codes is to be considered along with the control flow of the software codes. The use of GPUs is introduced to improve the speed of software execution. A good number of parallel research attempts are carried out to convert the serial code into a parallel code, but this needs a very high knowledge of programming. Hence, this paper attempts to build an automatic framework to convert software component based serial code to parallel to be incorporated into the parallel applications without losing the benefits of component-based and from parallel processing of software codes. The proposed novel automated code conversion framework demonstrates a around 97% reduction of code execution time.",60115612,Stanley College of Engineering &amp; Technology for Women,Hyderabad,India,['1700'],20.222222222222218,0.0828235294117647,0.19423529411764706,1,0.116751269035533,0.02030456852791878,0.24615384615384617
577,592,592,Dynamic allocation of spectrum in hybrid access cognitive femtocell networks with practical spectrum sensing,"The demand for the data increasing progressively in the next generation cellular networks. To satisfy the demands, the operators are moving towards the data minded cellular technologies like 5G. As the frequency of operation increases, the pathlosses also becoming more and more, the service for the indoor user is becoming a serious question. To address this problem, femtocell is nominated as a candidate in the literature. Femtocells operates in the same frequencies with the macrocell, because of this co-channel interference between macro-femto (Cross-tier) and femto-femto (Co-tier) is a serious problem. Cognitve Radio (CR) technology is the one of the promising one to access the unused spectrum bands. This work deals with the incorporation of CR technology with hybrid access femtocell networks. In this paper a dynamic resource allocation technique is proposed in hybrid access cognitive femtocell networks with perfect spectrum sensing and fairness. The results are showing that this technique yields better throughput, fairness among the users.",60005694,Pondicherry Engineering College,Puducherry,India,['1700'],17.444444444444443,0.2444444444444445,0.5270833333333333,1,0.0748663101604278,0.0374331550802139,0.3202247191011236
578,593,593,Fault containment based self stabilized fuzzy relevance clustering algorithm,"In extensive scale wireless ad-hoc sensor networks for the support of self-organization and enable routing, clusters have been introduced. Robustness is a key issue due to the dynamic environment in these kinds of wireless networks. Even though numerous algorithms have already been designed for clustering, only a few of the algorithms addressed the issue of fault containment feature along with the self-stabilization in sensor networks. A system delivers fault-containment if the probability that an application fails is related to the number of resources used by that application, not to the total number of resources in the system. Thus, theproposed algorithm prevents increasingerrorsin the network at small-scale fault incidencecondition. It allowseveryCH to interact its neighbour CHs to build time concurrently and energyefficient routes. The clustering approach during cluster formation constructs spanning trees among CHs and Cluster Members (CM) using a self-stabilizing approach to regulateappropriate routes for clusters. Decreasing the amount of unusable cluster-heads in the caused topology is the main objective of implement rules for the nodes. The experimental result for the proposed approach is carried out using NS2 simulator where it is shown that performance metrics of the proposed approach is well when contrasted with the current self-stabilized, Fault containment and traditional FRCA clustering algorithm.",60105710,"Jawaharlal Nehru Technological University, Kakinada",Kakinada,India,['1700'],22.777777777777782,-0.03722222222222223,0.4605555555555556,1,0.11814345991561181,0.03375527426160337,0.33031674208144796
579,594,594,A study of factors which influences the escalation of employee attrition rate with respect to hotels in Chennai city,The hotel industry in Chennai has been developing gradually. The competition which is showcased in this industry is very powerful and result and profit oriented. Each firm is contributing “Excellent utility” to consumers by increasing the market growth and profit. These are the observation which differs from other sectors. This industry refers to service oriented which is impalpable in nature. There is always a human factor which is involved in this industry and cannot be matched by other palpable structure. Human element plays a significant role. It also channelizes their human resources department by fulfilling the organization objectives. This study analyses the factors which influences the escalation of employee attrition rate in the hotel industry in Chennai.,60102677,Dr. M.G.R Educational and Research Institute,Chennai,India,['1700'],13.0,0.1315,0.4824999999999999,1,0.12403100775193798,0.015503875968992248,0.31007751937984496
580,595,595,A comprehensive survey of articular cartilage segmentation methods on knee mri,"Articular cartilage (AC) of knee plays a vital role in the supporting mechanism of the human body. AC is a smooth, slippery surface which composed of white tissue covering the joint shell. Magnetic Resonance (MR) imaging technique is widely adopted in clinical practice to visualize and detect the defect in Knee anatomical structure. Segmentation of AC using knee MR images is an essential process to biomarker analysis during knee osteoarthritis progression. Hence it has been widely investigated by research communities. Osteoarthritis (OA) is a commonly found knee disease, in which AC is slowly and progressively lost. Early diagnosis of OA plays a significant role to look up treatment possibilities and prevent further degradation of knee AC. Segmentation methods of AC have considered various parameters of image, image quality, and tissue structure, etc. Manual segmentation of cartilage for OA diagnosis, from a large amount of MRI images produced in clinical practice, is a time-consuming and challenging process. Thus semi-automated and fully automated cartilage segmentation methods have been adopted by many researchers to provide reasonable accuracy and reliable detection of AC from knee MR images. This paper reviews knee cartilage segmentation methods from MR images. In this paper, we focus on the recent tread of knee AC segmentation techniques from MR images. First, an introduction to osteoarthritis and its causes are given. Then variety of MR imaging modalities suitable for assessment of knee OA. Finally, performance measures are explained followed by conclusion.",60097159,Mahatma Gandhi Mission Charitable Trust,Navi Mumbai,India,['1700'],16.0,0.11996753246753245,0.4675865800865802,1,0.10181818181818182,0.07272727272727272,0.36162361623616235
581,596,596,Sustainable after sale services: The effect of perceived value on customers’ behavioural intention,"There is an increasing beleive that the biggest show stopper in any industry will no longer be technology or capital, but the environment (Sheth & Sinha, 2015). It evidently defines the main problem of our world today, and the concern, regarding our future generations. Ensuring that our action today do not limit the range of economic, social, and environmental options to future generation, the fundamental principle of sustainability has emerged (Trevena, Kaldor & Downs, 2014).In light of the same concern, Recently, sustainability management has developed in the service industry. Green/sustainable after sale services in customer durables have been progressively joining the service industry. Customersupport determinesthe sustainable development of the consumer durable industry for their services. This paper aims to explore relationships among perceived values viz. hedonic and utilitarian values, and behaviour intentions of the customer. A total of 360valid questionnaires were collected, and regression method was used to measure and test the research hypotheses. Thestudy presents empirical evidence of impact of hedonic and utilitarian values on customer’sbehavioural intentions. Finally, theoretical and practical implications are discussed and suggestions for future research are provided.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],18.2,0.09000000000000001,0.2433333333333333,1,0.0947867298578199,0.02843601895734597,0.36619718309859156
582,597,597,Rough set-based rule generation and Apriori-based rule generation from table data sets: A survey and a combination," All Rights Reserved.The authors have been coping with new computational methodologies such as rough sets, information incompleteness, data mining, granular computing, etc., and developed some software tools on association rules as well as new mathematical frameworks. They simply term this research Rough sets Non-deterministic Information Analysis (RNIA). They followed several novel types of research, especially Pawlak’s rough sets, Lipski’s incomplete information databases, Orłowska’s non-deterministic information systems, Agrawal’s Apriori algorithm. These are outstanding researches related to information incompleteness, data mining, and rule generation. They have been trying to combine such novel researches, and they have been trying to realise more intelligent rule generator handling data sets with information incompleteness. This study surveys the authors’ research highlights on rule generators, and considers a combination of them.",60031838,Kyushu Institute of Technology,Kitakyushu,Japan,"['1702', '1709', '1707', '1705', '1710']",20.83333333333333,0.11704545454545455,0.4650771103896104,0,0.0949367088607595,0.05063291139240506,0.45454545454545453
583,599,599,The influence of endorser credibility on consumer’s attitude toward advertising campaign and purchase intention,"In Indonesia, a product campaign was launched for Lux soap brand using one famous married-couple – Bunga and Ashraf as endorsers for the product. The image of Lux brand had been affected by a scandal of previous endorsers. The new-product campaign was the company’s attempt to reestablish the brand through a product advertising campaign themed ‘Vibration of Love’ to help spur product sales. This is why it is important to investigate the importance of endorser credibility role on the launched product advertising campaign. In this model, endorser credibility is argued to have influence over consumer’s attitude toward the advertising campaign and also on their purchase intention of the reestablished product brand. In this model, four attributes, namely, expertise, trustworthiness, likeabilityand attractiveness are proposed to represent different types of endorser credibility while consumer’s attitude towards the advertising campaign is conceptualized as the attitude (positive/negative) displayed as a result of (series of) exposure to a specific advertisement(s) during a period of a campaign (ad stimuli). As for purchase intention, it is a behavioral outcome which can surface due to factors like advertising effectiveness. In this paper, how the variables relate to one another will be discussed.",60103730,Telkom University,Bandung West Java,Indonesia,['1700'],24.25,0.15833333333333335,0.5523809523809524,1,0.08733624454148471,0.03056768558951965,0.2807017543859649
584,600,600,Fault detection and isolation for wind turbine systems based on proportional multi-integral observer (PMIO),"This paper addresses Fault Detection and Isolation (FDI) for wind turbines based on a Proportional Multi-Integral Observer (PMIO). A wind turbine model is linearized using the Takagi-Sugeno (TS) approach based on Lyapunov stability theory and LMI condition, then the PMI observer is considered for use with the TS fuzzy model to estimate and isolate both actuator and sensor faults with the introduction of a centered noise. The kth derivatives of the actuators and sensor faults are not equal to zero but are rather bounded norms. However, based on Lyapunov stability theory and L2 performance analysis, design conditions are established through LMIs formulations. Simulation results show that our proposal outperforms some existing approaches.",60024326,"Laboratoire d'Electronique, Signaux, Systèmes et d'Informatique, Université Sidi Mohamed Ben Abdellah",Fez,Morocco,"['1711', '1709', '1708', '1702']",22.4,0.0,0.25,1,0.11538461538461539,0.11538461538461539,0.3888888888888889
585,601,601,A novel feature selection using optimized eliminated iterative distance correlation for SDN-enabled traffic anomaly detection and mitigation,"SDN-based traffic anomaly detection conventional techniques have been used to reduce the network traffic and their attacks. Sampled Density Peak technique has better detection performance based on clustering algorithm with the sampling adaptation and Unsupervised Cluster-based Feature Selection (UCFS) mechanism. However, the feature selection was not accurate due to the fixed threshold. Hence in this article, an optimized feature selection with Sampled DP technique is used. In this technique, a Backward Elimination Iterative Symmetric Uncertainty (BE-ISU) process is used to select the smallest subset of features. This removes the least influential features towards back which ensures sufficient classification accuracy. To tackle this issue, an Optimized Eliminated ISU (OE-ISU) process is proposed by using Fractional-Order Darwinian Particle Swarm Optimization (FODPSO) algorithm. Finally, the experimental result shows that the proposed technique achieves better performance with the Sampled-DP technique for reducing the data dimensionality.",60114532,CMS College of Science &amp; Commerce,Coimbatore,India,['1700'],17.625,0.04321428571428572,0.4365476190476191,1,0.13218390804597702,0.15517241379310345,0.41975308641975306
586,602,602,Features denoising-based learning for porosity classification,", part of Springer Nature.Reservoir characterization is one of the most challenging tasks that help in modeling different lithological properties like porosity, permeability and fluid saturation using seismic readings like velocity profile, impedance, etc. Such a model is required for field development, placing new wells and prediction management. Seismic attributes are being progressively utilized for the tasks of model building, exploration and properties estimation from the data. However, these tasks become very complex due to the nonlinear and heterogeneous nature of subsurface properties. In this context, present work proposes a recurrent neural network-based learning framework to classify porosity using seismic attributes as predictor variables. The approach begins by calculating different seismic attributes from the data. From the initially calculated attribute set, features that are to be used for classification are selected by using two different strategies. Firstly, the seismic attributes having good correlation strength with reservoir porosity are extracted. Subsequently, generative topographic map is utilized to select the significant features. The final reduced features set obtained by the integrated result of above two strategies is then fed as an input to the empirical mode decomposition (EMD) algorithm. The denoised features resulting from the EMD algorithm are used to train the classification models. Further, a comparison is carried out between the proposed classification framework (EMD+ RNN) and other supervised classifiers to show the performance of the proposed framework.",60031818,Indian Institute of Technology Roorkee,Roorkee,India,"['1712', '1702']",18.916666666666668,0.09149350649350647,0.43727994227994216,1,0.12790697674418605,0.023255813953488372,0.32677165354330706
587,603,603,Effectiveness of myofascial release technique versus positional release technique on myofascial pain syndrome,"Background: The Myofascial pain syndrome (MPS) is a common clinical problem of muscle pain involving sensory, motor and autonomic symptoms caused by Myofascial trigger points (MTrPs). A study regarding shoulder pain concludes that all 72 subjects included in their study presented MTrPs in shoulder girdle muscles, mainly in the infraspinatus muscle and upper trapezius. Treatment for MPS includes medication, splints, collars, physiotherapy and wide array of complementary therapies like psychological counseling. Numerous researches have been carried out on the role of physiotherapy methods such as massage, heat therapy, cryo-therapy, ultrasound therapy and therapeutic exercises to reduce MPS. The objective of the study is to compare the effectiveness between Myofascial release technique (MRT) and positional release technique (PRT) in treatment for MPS. Methodology: A total of 35 subjects fell under inclusion criteria in which 30 consented for participation. 15 subjects were allotted into each group randomly after obtaining the written informed consents. Demographic data and the outcome measures of the subjects were recorded before and after the intervention. Result & Conclusion: The results from paired “t” test shows that the Group B (PRT with ultrasound) is more effective when compared to the Group A (MRT with ultrasound). Future recommendation is to conduct a longer duration study with more number of samples. Samples at various levels of disability and pain chronicity can be included to determine the type of treatment that is effective for a particular level of disability and/or level of pain chronicity.",60078092,"Asian Institute of Medicine, Science &amp; Technology",Bedong,Malaysia,['1700'],22.0,0.096078431372549,0.4259803921568627,1,0.08214285714285714,0.060714285714285714,0.3597122302158273
588,604,604,Automated dispatch of wind power on microgrid for voltage regulation,The variability of wind power generation adversely affects the grid conditions and the utilities find it challenging to accommodate variations in the injected wind power. To resolve this issue utilities impose curtailment of wind power generation. Demand side management (DSM) strategies have gained popularity among utilities in recent years. An advanced Demand Response (DR) scheme known as Demand Dispatch (DD) enable utilities to reshape demand curve to closely follow generation. An automated DD strategy is proposed as a solution to the issues related to high penetration of wind turbine generators (WTG) on micro grid. It basically balances the WTG power injection with real time controlled dispatchable loads. DD adopts smart communication for real time data collection as well as for dispatchable load management. A field implementation of DD in maintaining voltage stability in a DC microgrid with micro-WTG (m-WTG) is studied. The experiment results presented validate the scheme.,60076784,"Amrita School of Engineering, Coimbatore",Coimbatore,India,"['1711', '1709', '1708', '1702']",16.444444444444443,0.20928571428571427,0.5041071428571429,1,0.11695906432748537,0.08771929824561403,0.38922155688622756
589,605,605,Prediction of chronic kidney disease using machine learning techniques,"Chronic kidney disease (CKD) is a hazardous disease effecting many people worldwide. Individuals with chronic kidney disease (CKD) are often unaware that the medical tests they undergo may provide useful information about CKD for other purposes and this information may not be used effectively to address disease diagnosis. The major problem of this disease is it is hard to recognize till it reaches advanced stage. In this paper we are predicting chronic kidney disease(CKD) using machine learning techniques. In this paper, we are using machine learning algorithms like decision tree, naïve Bayes classification, logistic regression(LR), support vector machine(SVM) and random forest In this paper we detect the chronic kidney disease (CKD) using the best suited method and got 99.3% as the most accurate result using random forest method.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],25.6,0.1963888888888889,0.4766666666666667,1,0.11564625850340136,0.05442176870748299,0.32679738562091504
590,606,606,Blended learning: Augmenting academic performance of high school students,"Nowadays, the usage of ICT (Information Communication Technology) in education is one of the best methods to enhance teaching as well as learning. In this time, the students are technophiles; moreover they are also digital native. The blended learning is a combination or mixing of instructional technology that is assisted for student’s academic performance in efficient manner. The main objectives of this study are to find and to estimate the efficiency of blended learning on academic performance among high school students. In this study, the sample was consisted of 40 high school student and they divided into experimental group and control group. The finding of this study revealed that have best for learning outcomes when they are learned through blended learning.",60016712,Alagappa University,Karaikudi,India,['1700'],20.166666666666668,0.28740740740740744,0.2681481481481481,1,0.1044776119402985,0.022388059701492536,0.2222222222222222
591,607,607,Exploiting flower constancy in flower pollination algorithm: improved biotic flower pollination algorithm and its experimental evaluation,"Recent growth of metaheuristic search strategies has brought a huge progress in the domain of computational optimization. The breakthrough started since the well-known Particle Swarm Optimization algorithm had been introduced and examined. Optimization technique presented in this contribution mimics the process of flower pollination. It is build on the foundation of the first technique of this kind—known as Flower Pollination Algorithm (FPA). In this paper, its simplified and improved version, obtained after extensive performance testing, is presented. It is based on only one natural phenomena—called flower constancy—the natural mechanism allowing pollen carrying insects to remember the positions of the best pollen sources. Modified FPA, named as Biotic Flower Pollination Algorithm (BFPA) and relying solely on biotic pollinators, outperforms original FPA, which itself proved to be very effective approach. The paper first presents a short description of original FPA and the changes leading to Biotic Flower Pollination Algorithm. It also discusses performance of the modified algorithm on a full set of CEC17 benchmark functions. Furthermore, in that aspect, the comparison between BFPA and other optimization algorithms is also given. Finally, brief exemplary application of modified algorithm in the field of probabilistic modeling, related to physics and engineering, is also presented.",60017351,AGH University of Science and Technology,Krakow MP,Poland,"['1712', '1702']",18.09090909090909,0.2267647058823529,0.5122549019607843,1,0.1072961373390558,0.08583690987124463,0.39111111111111113
592,608,608,Recurrent neural network based model to predict autism spectrum disorder causative genes,"Recognizing genes causing Autism Spectrum Disorder (ASD) is still a complex task. The role played by domain experts is crucial in identifying relevant contributive features and as recognizing hand-crafted attributes occupies a great deal of time, a varying successful solution is necessary. The swift advancements in the design of deep architecture models have shown substantial accomplishment in sequential data processing tasks. Deep learning models examine the data to discover associations among the features and enable faster learning without being explicitly programmed to do so. Hence the principal goal of this work is to categorize the ASD genes by applying deep learning based models without feature engineering. One hot encoding method is used to encode the gene sequences as vector of numerical values and to further simplify the input representation to aid the prediction of ASD gene sequences. Recurrent Neural Network (RNN) models like Bidirectional Recurrent Neural Network (BRNN), Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU) are employed to build the prediction models using user defined and self learned features. The performances of the models evaluated using cross validation with various metrics like precision, recall, accuracy and F-measure confirm that GRU model shows promising results using one hot encoding technique.",60114579,PSGR Krishnammal College for Women,Coimbatore,India,['1700'],25.25,0.13529411764705884,0.5941176470588236,1,0.13596491228070176,0.10087719298245613,0.39732142857142855
593,609,609,Social media and social commerce: Examining the synthetic thinking on business,"Internet, social media, and their fluctuated online publics have influenced the business procedures of advertising, sales professionals, Business owners and customers. The computerized time has empowered access for different online publics, the two people and networks, to make, offer and search data on the web and furthermore possibly to build their informative power by utilizing systems for affecting, testing or considering organizations and Social media accountable. While this study covers the impediments of Social media in business, it doesn't recognize and cover the new business. Hence, the point of this exploration is to examine the utilization of social media to defeat the restrictions of social media business for Trade.",60114400,Valliammai Engineering College,Kattankulathur,India,['1700'],27.25,0.03787878787878788,0.2984848484848485,1,0.12096774193548387,0.008064516129032258,0.3467741935483871
594,610,610,Normalized higher order statistics based automated cardiovascular disease detection using ECG,"Since from last decade, several recent Computer Aided Diagnosis (CAD) tools introduced to assist medical professionals due to accuracy, simplicity & inexpensive approach. The Electrocardiogram (ECG) signals are used with such methods for the detection of Cardiovascular Disease (CVD) detection. The efficiency of CVD detection using ECG suffered from the many research problems such as artefacts, efficient features extraction, QRS beats extraction etc. This paper presents the novel framework for CVD using the raw ECG signals. After the signal procurement, we connected the half breed pre-preparing calculation to expel the curios &clamour from the crude ECG signal. In next stage, the calculation intended to extricate the QRS & ST sections dependent on the dynamic thresh holding approach. This technique first gauge the Q, R, S, & ST fragment from the pre-preparing ECG signal. To limit the overhead of calculation, this strategy straightforwardly connected in time-area signal with the goal that no time squanders in playing out any morphological activity. At long last, the component extraction strategy structured called Normalized Higher Order Statistics (NHOS) to separate the highlights from the combination of QRS & ST divisions. The Artificial Neural Network (ANN) used to play out the characterization. The reproduction results demonstrates that proposed strategy conveyed better execution as analyzed than existing strategies.",60115150,"Government College of Engineering &amp; Research, Avasari Khurd",Ambegaon,India,['1700'],19.181818181818183,0.00012820512820513054,0.3580769230769231,1,0.108,0.132,0.4385245901639344
595,611,611,Covering in operations on fuzzy graphs,Let G be a fuzzy graph. A vertex cover of fuzzy graphs is a set of vertices such that each strong edge of the fuzzy graph is incident to at least one vertex of the set.In thispaperpresented the idea of covering in fuzzy graphs and define minimum covering in fuzzy graphs in thefirstpart and also make known to the some operations in fuzzy graphs. Further investigate the covering in fuzzy graphs operations give fuzzy examples to explain the results.,60072227,Bannari Amman Institute of Technology,Sathyamangalam,India,['1700'],26.33333333333333,0.033333333333333326,0.5333333333333333,1,0.08333333333333333,0.011904761904761904,0.2073170731707317
596,612,612,Impact of high performance human resource management practices on employee engagement with the moderating role of ethical leadership,"The present study explores the relationships between high performing human resource management practices, ethical leadership and employee engagement. 171 questionnaires were used to gather information from an employee associated with hospitality sector organization in Agra and Mathura district of Uttar Pradesh. The results show a positive relationship between the high performing human resource management practices (HPHRMP) and employee engagement and effective leadership. Finding revealed that effective leadership plays a role of moderator between high performing human resource management practices and employee engagement. Study concludes that there are possibilities of future research on the point that how we can strategically implement HPHRMP in association with ethical leadership practice to intensify the management and employee relationship and getting desired outcome.",60114077,"GLA University, Mathura",Mathura,India,['1700'],23.6,0.1774825174825175,0.4146503496503496,1,0.12698412698412698,0.05555555555555555,0.23015873015873015
597,613,613,"Erratum: Panel misalignment effects on the radiation pattern from a solid surface deployable antenna [Journal of Electromagnetic Engineering and Science, 19, 4, (2019) (253-258)] DOI: 10.26866/jees.2019.19.4.253","In the paper entitled ""Panel Misalignment Effects on the Radiation Pattern from a Solid Surface Deployable Antenna (Journal of Electromagnetic Engineering and Science, vol. 19, no. 4, pp. 253-258, 2019)"", a typographical error occurred in equation (8). The correct equation follows.",60107890,Hanwha Systems,Seoul,South Korea,['1705'],8.2,0.25,0.55,1,0.05172413793103448,0.27586206896551724,0.6842105263157895
598,615,615,A study on the influence of sustainability related factors on the online purchase decisions of customers,"The e-commerce business is growing at a tremendous rate in India. More and more customers prefer to buy for the online website due to the discounts, ease of purchase and the larger variety of products available. The e-retail companies majorly use discounts as major attraction to gain more customers. In this process of trying to increase the market share the sustainability factors are not given importance in various ways. This research paper tries to find if customers give importance to sustainability related factors and if these factors can be advertised by the e-retailers. The paper tries to find if this will have an impact on the customer purchase decisions from the e retailers. Then the e-retailers will have to have a different business strategy with sustainability factors included to attract more customers.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],18.857142857142858,0.1688888888888889,0.5050000000000001,1,0.14864864864864866,0.013513513513513514,0.2857142857142857
599,616,616,Survey of likings of traditional games amongst the school going children in Haryana,"Traditional games were very popular amongst children in our younger days, which rarely need equipments and made from natural / untreated material. When compared with modern games they hardly required any money and passed from one generation to other automatically and children remained physically fit and maintained their health and well being. But with the technological advancements focus of children has diverted from them towards electronic gadgets, mobile games and video games. Different reasons like expectation of parents, peer pressure, coaching classes and extra home work and impact of other cultures contribute for fading interest among children in our traditional games. Whereas traditional games are the part of our culture on the foundations on which our modern civilization is standing. It forced me to find out as to what were the different traditional games our time? Are they same or region specific? Are they still liked by the school children in today’s time? And why regional traditional games were so important in our life and play a very important role in educating children and saving our national cultural values.",60076774,"Amity University, Noida",Noida,India,['1700'],29.83333333333333,0.11033333333333334,0.5196666666666666,1,0.09844559585492228,0.0,0.28350515463917525
600,617,617,"Comparative analysis of support vector machine, random forest, and decision tree for intrusion detection","Interruption reputation is a key piece of safety gadgets, as an instance, bendy safety machines, interruption discovery frameworks, interruption anticipation frameworks, and firewalls. Wonderful interruption popularity strategies are applied, however their exhibition is a hassle. Interruption location execution is based totally upon precision, which desires to enhance to lower fake signs and to boom the identity fee. To determine issues on execution, multilayer perceptron, support vector machine (SVM), and precise strategies have been applied in past due artwork. Such techniques display screen impediments and are not talented for use in large informational indexes, for instance, framework and tool facts. The interruption reputation framework is achieved in analyzing awesome traffic information; alongside those traces, a skilled grouping machine is important to conquer the difficulty. This problem is taken into consideration on this paper. Understood AI strategies, to be unique, SVM, first-rate timberland, and extreme learning machine (ELM) are finished. Those strategies are awesome a right away stop prevent result in their capacity so as. The NSL–learning revelation and information mining informational series is completed, that is seemed as a benchmark in the evaluation of interruption identification systems. The effects display that ELM beats one-of-a-type methodologies.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],17.636363636363637,0.225,0.7670168067226892,1,0.08823529411764706,0.058823529411764705,0.33771929824561403
601,618,618,A study on job stress among women employees in BPO center,"The increase in the number of women in the labor market signifies an important trend regarding women's employment. This has been occurring alongside increases in labor force and workforce, especially for urban women, although rural women workers predominate in terms of participation rates and overall magnitude. The main objectives of the study are to evaluate the stress management among the BPO personnel. Primary data have been collected through issue the questionnaire. The sample size of the study is claimed as 100 women employees working in BPO Center, Coimbatore. The study makes use of statistical techniques such as Percent analysis, Chi-square test and ANOVA in analyzing the data. The study recommended that Governments should make it mandatory for companies to install Global Positioning System (GPS) in vehicles carrying women, in all industries which engage women in night shifts.",60012959,Periyar University,Salem,India,['1700'],19.571428571428573,0.08666666666666667,0.3433333333333334,1,0.1038961038961039,0.045454545454545456,0.3684210526315789
602,619,619,Smooth estimates of multiple quantiles in dynamically varying data streams,", part of Springer Nature.In this paper, we investigate the problem of estimating multiple quantiles when samples are received online (data stream). We assume a dynamical system, i.e., the distribution of the samples from the data stream changes with time.A major challenge of using incremental quantile estimators to track multiple quantiles is that we are not guaranteed that the monotone property of quantiles will be satisfied, i.e, an estimate of a lower quantile might erroneously overpass that of a higher quantile estimate.Surprisingly, we have only found two papers in the literature that attempt to counter these challenges, namely the works of Cao et al. (Proceedings of the first ACM workshop on mobile internet through cellular networks, ACM, 2009) and Hammer and Yazidi (Proceedings of the 30th international conference on industrial engineering and other applications of applied intelligent systems (IEA/AIE), France, Springer, 2017) where the latter is a preliminary version of the work in this paper. Furthermore, the state-of-the-art incremental quantile estimator called deterministic update-based multiplicative incremental quantile estimator (DUMIQE), due to Yazidi and Hammer (IEEE Trans Cybernet, 2017), fails to guarantee the monotone property when estimating multiple quantiles. A challenge with the solutions, in Cao et al.(2009) and Hammer and Yazidi(2017), is that even though the estimates satisfy the monotone property of quantiles, the estimates can be highly irregular relative to each other which usually is unrealistic from a practical point of view. In this paper, we suggest to generate the quantile estimates by inserting the quantile probabilities (e.g., 0.1 , 0.2 , … , 0.9) into a monotonically increasing and infinitely smooth function (can be differentiated infinitely many times). The function is incrementally updated from the data stream. The monotonicity and smoothness of the function ensure that both the monotone property and regularity requirement of the quantile estimates are satisfied. The experimental results show that the method performs very well and estimates multiple quantiles more precisely than the original DUMIQE (Yazidi and Hammer 2017), and the approaches reported in Hammer and Yazidi(2017) and Cao et al.(2009).",60068730,OsloMet – storbyuniversitetet,Oslo,Norway,"['1707', '1702']",37.444444444444436,0.11151785714285714,0.448154761904762,1,0.07881773399014778,0.09113300492610837,0.4075
603,620,620,Stroke prediction using distributed machine learning based on apache spark,"Stroke is one of death causes and one the primary causes of severe long-term weakness in the world. In this paper, we compare different distributed machine learning algorithms for stroke prediction on the Healthcare Dataset Stroke. This work is implemented by a big data platform that is Apache Spark. Apache Spark is one of the most popular big data platforms that handle big data and includes an MLlib library. MLlib is an API integrated with Spark to provide machine learning algorithms. Four types of machine learning classification algorithms were applied; Decision Tree, Support Vector Machine, Random Forest Classifier, and Logistic Regression were used to build the stroke prediction model. The hyperparameter tuning and cross-validation were applied with machine learning algorithms to enhance results. Accuracy, Precision, Recall, and F1-measure were used to calculate performance measures of machine learning models. The results showed that Random Forest Classifier has achieved the best accuracy at 90 %.",60018623,South Valley University,Qena,Egypt,['1700'],17.0,0.15,0.41,1,0.11494252873563218,0.14367816091954022,0.4117647058823529
604,621,621,Motion control of ultrasound probe based on master-slave robotic system for medical ultrasound applications,"Ultrasound is often used in medicine. The quality of the ultrasound image often depends on the ability of the radiologist. Many researchers have proposed robotic systems to help obtain ultrasound images. In this article, a brief description of ultrasound imaging with the help of a robot is presented. An automated system with a parallel mechanism of 3 degrees of freedom for ultrasound images was developed. This parallel mechanism allows for rotation, yaw and pitch of an ultrasound transducer. The experimental results confirm the good performance of the mechanical system with position tracking. A prototype robotic system ultrasound imaging was tested by gelatin home model. The movement accuracy between master and slave was promising results with good image quality.",60042753,Zarqa University,Zarqa,Jordan,['1700'],13.111111111111109,0.1909090909090909,0.3303030303030303,1,0.07751937984496124,0.031007751937984496,0.3178294573643411
605,622,622,Experimental analysis on titanium grade-V sheet using laser beam machining process,"Orthopaedical implantation is a challenging task because human made body parts must be biocompatible and their working should be same as natural body parts. Medical implants are mainly fabricated by titanium grade V because of its biocompatibility and strength. Body part implantation improve work efficiency of physically disabled person. So, it is necessary that body part must work or movement as natural body part. Small size holes are provided to join bio compatible with natural body part. Precise micro size hole fabrication is very difficult task on titanium alloys. In present work, 1mm and 2mm diameters hole have been fabricated on biocompatible material (Ti-6AL-4V) through laser drilling process within range of selected parameters. Hole geometrical features have been compared on the basis effect of input parameters for two different hole diameters. CCRD has been used to prepare design of experiments. ANOVA technique also used for model validation for responses hole circularity, hole taper, heat affected zone and decided significant parameters for different size of hole.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],16.5,0.026388888888888892,0.5277777777777778,1,0.10382513661202186,0.03825136612021858,0.281767955801105
606,623,623,Snappy and video stream edge detection using labview,"The LabVIEW is to form the virtual instrumentation and take an real graphical system design approach that can be successfullycontrol the opportunities and take on the challenges of recent academic research and development. The borders of objects with in the snappy can be determined using Edge location concept. The locationof edge works by identifying discontinuities in intensity. Edge location, which is used for segmentation of snappyand data removal in different parts such as snappy processing, computer vision, and machine vision. The most general edge location algorithms includes that Sobelmethod, cannymethod, Prewittmethod, Roberts’smethod, and fuzzy logic method.Video Edge technique is the fundamental technique and it have significant features in snappy processing. The most fundamental technique procedure in edge location are processing of snappy, analysis of snappy, pattern recognition of snappy, computer vision and human vision.This paper describes the physical characteristics of edges in snappy and video stream.",60114577,Vignan Institute of Technology and Science,Deshmukhi,India,['1700'],24.33333333333333,0.14772727272727273,0.38798701298701305,1,0.08433734939759036,0.03614457831325301,0.2926829268292683
607,624,624,Finding artist’s true path in life (Stream of consciousness in joyce’s novel a portrait of the artist as a young man),"The literature at the beginning of twentieth century becomes totally different. Now the writers are fascinated with the inner lives of teeming impressions. The novel of Irish writer James Joyce A Portrait of the Artist as Young Man is distinguished by its use of various techniques; most remarkable “stream of consciousness” which is an attempt to describe the inner thoughts and memory of the hero. This article is an effort to research the “stream of consciousness” as a technique used in Joyce’s A Portrait of the Artist as Young Man (1916) which is one of the greatest of modern novels. Joyce created his novel in five chapters which describe the protagonist’s life, from childhood to manhood.",60113284,Jizzax Davlat Pedagogika Instituti,Jizzakh,Uzbekistan,['1700'],23.2,0.2409090909090909,0.4348484848484848,1,0.06870229007633588,0.11450381679389313,0.2631578947368421
608,625,625,Strength performance studies on E-waste cement concrete with metakaolin,"Every year, milli0n t0nnes 0f e-waste is generated fr0m vari0us w0rking s0urces. E-Waste which is n0n-bi0degradable and cann0t be burnt as it is, as it pr0duces large c0ntent 0f t0xic gases which are harmful t0 human and envir0nment. In the c0nstructi0n filed, usage 0f c0ncrete has bec0me a vital part. Maj0r p0rti0n 0f c0ncrete is c0mp0sed 0f aggregates. There is a large depleti0n 0f natural res0urces which are used in c0ncrete. N0w a day, the disp0sal 0f e-waste has bec0me an seri0us issue. T0 0verc0me the e-waste disp0sal pr0blem it has been used as C0arse aggregate replacement in the c0ncrete, as it c0ntains very high strength. In this w0rk, 12mm t0 20mm size 0f c0arse aggregates are prepared with the e-waste material. Different c0ncrete mixes are prepared by replacing n0rmal c0arse aggregate with E-waste material in different ranges like 0%, 20%, 40%, 60%, 80%, 100%, f0r a c0ncrete mix 0f M30 and als0 cement is replaced with metaka0lin with 0% and 10%. The effect 0f replacement 0f c0arse aggregate by e-waste material and cement by metaka0lin 0n pr0perties 0f c0ncrete like c0mpressive strength and split tensile strength f0r hardened c0ncrete at the age 0f 28 days, 90 days are is evaluated in this paper.",60106974,"JNTUA College of Engineering, Ananthapuramu",Anantapur,India,['1700'],20.4,0.10457142857142857,0.4573928571428572,1,0.058823529411764705,0.16862745098039217,0.574468085106383
609,626,626,Students’ application of knowledge from a library usage and information course for undergraduate students at King Mongkut’s institute of technology Ladkrabang,"Information literacy is one of the crucial skills for student development in the 21st century. The focus is on accessing, evaluating, using, and managing information in order for students to succeed in their work and life. This research aimed to investigate students’ application of knowledge from a library usage and information course for undergraduate students at King Mongkut’s Institute of Technology Ladkrabang.A survey research method was used to collect data. The sample group consisted of 310 undergraduate students who were taking the library usage and information course in the first and second semester of 2015 educational year and in the first semester of 2016 educational year.A questionnaire was used to collect data. The results show that the students were able to apply the following kinds of knowledge at the highest level (99.7%): (1) importance of information in daily life, (2) characteristics of information sources, (3) types of information sources, (4) selection of information sources for finding relevant information, and (5) usage of the circulation service in the central library.It was also found that they were able to apply the following kinds of knowledge at the lowest level: knowledge of usage of interlibrary loan service and search as well as selection of scholarly journals from the citation index database.The results of this study suggest that lecturers should focus on giving real world examples of information sources so that students can better understand and apply them in their daily life and develop their learning into the future.",60021543,King Mongkut's Institute of Technology Ladkrabang,Ladkrabang Bangkok,Thailand,['1700'],49.0,0.12368421052631574,0.35219298245614034,1,0.09929078014184398,0.02127659574468085,0.2727272727272727
610,627,627,Contextual background modeling using deep convolutional neural network,"Moving object detection is a crucial problem in computer vision. This affects the performance of the overall system in surveillance applications. In this paper, a Deep-Convolutional Neural Network with fully convolutional approach is proposed. Convolutional networks are powerful models to extract hierarchies of non-handcrafted features. The primary objective of the paper is to build an accurate foreground segmentation system with limited user interventions. The presented work focuses to build a fully convolutional network with skip architecture to identify moving objects in complex scenarios. The network is modeled as an end-to-end fully convolutional network, and the method contains a new hierarchical pooling layer to make use of global contextual information. The presented model utilizes a pre-trained VGG-19 Net model for the construction of Deep-Convolutional Neural Network (Deep-CNN) model. The fine and coarse features are fused using skip architecture to improve the feature representation. The qualitative and quantitative performance of the Deep-CNN architecture is tested on ChangeDetection.net-2014 dataset. The results produced by the Deep-CNN method were compared with the techniques in the recent literature. The Deep-CNN method outperforms the state-of-the-art methods without relying on any post-processing techniques.",60005630,"National Institute of Technology, Tiruchirappalli",Tiruchirappalli,India,"['1712', '1708', '1705']",15.416666666666664,0.09154298082869512,0.3914811379097093,1,0.11790393013100436,0.06986899563318777,0.31840796019900497
611,628,628,Script classification at word level for a multilingual document,"India is a multilingual multi-script country. In every state of India there are two languages one is state local language and the other is English. For example in Andhra Pradesh, a state in India, the document may contain text words in English and Telugu script. For Optical Character Recognition (OCR) of such a bilingual document, it is necessary to identify the script before feeding the text words to the OCRs of individual scripts. In this paper, we are introducing a simple and efficient technique of script identification for Kannada, English and Hindi text words of a printed document. The proposed approach is based on the horizontal projection profile for the discrimination of the three scripts. The feature extraction is done based on the horizontal projection profile of each text words. We analysed 500 different words of Kannada, English and Hindi in order to extract the discrimination features and for the development of knowledge base. We use the horizontal projection profile of each text word and based on the horizontal projection profile we extract the appropriate features. The proposed system is tested on 18 different document images containing about 400 text words of each script and a classification rate of 96.25%, 99.25% and 98.87% is achieved for Kannada, English and Hindi respectively.",60097558,IEC College of Engineering and Technology,New Delhi,India,['1700'],21.1,-0.026562500000000003,0.33950892857142856,1,0.08050847457627118,0.08898305084745763,0.2606837606837607
612,629,629,Pulsed flow of rheological complex fluids in cylindrical channels (Example of blood circulation),"The paper presents the two-phase model to describe blood flow in large and in small blood vessels. Based on this model the study gives an explanation for long known features (effects) of blood flow in the vessels: dependence of the hematocrit (packed cell volume) on the diameter of the vessel, existence of cell-free plasma layer near the vessel wall, obtuse (as compared with the profile of Poiseuille flow) velocity profile of a blood; dependence of the blood viscosity on the diameter of the vessel. The researcher determines dependences of the blood rate and viscosity on the diameter of a blood vessel. With the flow of blood in small vessels (less than 200 μm), the rheological properties of the blood depend on the size of the vessel-the apparent viscosity of the blood drops with a decrease in the diameter of the blood vessel. To describe the flow of blood in small vessels, it is necessary to create an equation of state that depends (apart from other parameters) on the diameter of the vessel.",60113775,Tashkent Medical Academy,Tashkent,Uzbekistan,['1700'],34.4,-0.07273809523809524,0.4220238095238095,1,0.06532663316582915,0.010050251256281407,0.23834196891191708
613,630,630,A deep learning approach to automatic road surface monitoring and pothole detection,", part of Springer Nature.Anomalies in road surface not only impact road quality but also affect driver safety, mechanic structure of the vehicles, and fuel consumption. Several approaches have been proposed to automatic monitoring of the road surface condition in order to assess road roughness and to detect potholes. Some of these approaches adopt a crowdsensing perspective by using a built-in smartphone accelerometer to sense the road surface. Although the crowdsensing perspective has several advantages as ubiquitousness and low cost, it has certain sensibility to the false positives produced by man-made structures, driver actions, and road surface characteristics that cannot be considered as road anomalies. For this reason, we propose a deep learning approach that allows us (a) to automatically identify the different kinds of road surface, and (b) to automatically distinguish potholes from destabilizations produced by speed bumps or driver actions in the crowdsensing-based application context. In particular, we analyze and apply different deep learning models: convolutional neural networks, LSTM networks, and reservoir computing models. The experiments were carried out with real-world information, and the results showed a promising accuracy in solving both problems.",60005497,Universidad Nacional del Centro de la Provincia de Buenos Aires,Tandil,Argentina,"['1708', '1706']",26.42857142857143,0.015079365079365073,0.4420634920634921,1,0.1141552511415525,0.0136986301369863,0.33014354066985646
614,631,631,Gradient tree boosting approach for software defect prediction,"Prediction of the actual defect in software has remained a challenging task for the software developers. Any deviation in counting the no. of defects or estimating the defects may lead to serious problems like the unexpected outcome. Majorly, defects like time, cost and effort have to be computed effectively at the initial phase of software development. Some of the early developed data mining approaches are developed for quality analysis and defect prediction. But for large scale software development, these techniques are not performing well due to the high nonlinearity nature of data. This paper proposes a novel gradient boosting based machine learning approach for the effective prediction of a software defect. The proposed method has been analyzed with various performance-related factors and found to be superior among nine competitive machine learning approaches.",60114662,Aditya Institute of Technology and Management,Tekkali,India,['1700'],16.5,0.17365327380952386,0.5318898809523809,1,0.1103448275862069,0.0,0.32167832167832167
615,632,632,Performance comparison of geographic routing in WSN for measuring coverage constraints and energy consumption in cloud environments,"This paper investigates the problem of energy �efficient and consumption process in wireless sensor networks. The fundamental problem in WSN has handled the energy constraints and avoiding end-to-end delay networks. We introduce encoding technique for handling transmission data, network delays, content aware service and energy expenditure problems. The end-to-end delay varies depending up on nodes and sensor life time. We apply hamming encoding technique for estimating energy constraints with life time of buffer capacity factor. This paper proposes the novel based approach to handle group communication, senor node status, network transmission and optimal encoded behaviors. Each cluster group values are sensed by node reference time and calculate hamming code weight for each node counts. The quality of services can be achieved by energy saving measurements and data loss can be varies up on incoming packet request.We compare the encoded result with code word situation and hazard environment. We reduce the amount of data transmission factor and life time of sensor values and longer network delays. We show the simulating results with encoding scheme and reduced energy consumption. The performance can be monitored by coverage constraints and optimal transmission behaviors.",60120915,Galgotias University,Greater Noida,India,['1700'],17.181818181818183,0.25,0.25,1,0.12558139534883722,0.018604651162790697,0.30392156862745096
616,633,633,"Experimental investigation and optimization of MRR, surface roughness and overcut of AISI 316 stainless steel in EDM using taguchi method","EDM has become an important and cost-effective method of machining extremely tough and brittle electrically conductive materials. It is widely used in the process of making moulds and dies and sections of complex geometry and intricate shapes. The workpiece material selected in this experiment is AISI 316 Stainless steel taking into account its wide usage in industrial applications. In today’s world 316 stainless steel contributes to almost half of the world’s production and consumption for industrial purposes. The input variable parameters are current, pulse on time and duty cycle. Taguchi method is applied to create an L27 orthogonal array of input variables using the Design of Experiments (DOE). The effect of the variable parameters mentioned above upon machining characteristics such as Material Removal Rate (MRR), Surface Roughness (SR) and Overcut (OC) is studied and investigated. The tool material is copper. The results obtained showed that current was the most significant parameter followed by pulse on time and the least significant was the duty cycle for the entire three responses namely Material removal rate, Surface roughness and overcut. With the increase in current and duty cycle MRR increased but for pulse on time it increased only up to 100 µs and then started to decrease. SR increased significantly with the increase in current; for pulse on time it increased up to 100 µs and after that there was no significant increase; and in case of duty cycle SR increased up to 70% and then started to decrease. OC increased with the increase in current and pulse on time but in different fashion and in case of duty cycle, OC increased up to 70% and then started decreasing.",108383651,ACE Engineering College,Hyderabad,India,['1700'],23.0,0.03674768518518518,0.534375,1,0.10064935064935066,0.06818181818181818,0.32142857142857145
617,634,634,"A Social Networks Approach to Viral Advertising: The Role of Primary, Contextual, and Low Influencers","The diffusion of social networking platforms ushered in a new age of peer-to-peer distributed online advertising content, widely referred to as viral advertising. The current study proposes a social networks approach to the study of viral advertising and identifying influencers. Expanding beyond the conventional retweets metrics to include Twitter mentions as connection in the network, this study identifies three groups of influencers, based on their connectivity in their networks: Hubs, or highly retweeted users, are Primary Influencers; Bridges, or highly mentioned users who associate connect users who would otherwise be disconnected, are Contextual Influencers, and Isolates are the Low Influence users. Each of these users’ roles in viral advertising is discussed and illustrated through the Heineken’s Worlds Apart campaign as a case study. Providing a unique examination of viral advertising from a network paradigm, our study advances scholarship on social media influencers and their contribution to content virality on digital platforms.",60029747,The University of Georgia,Athens,United States,['1706'],30.2,0.08373126873126874,0.3608991008991009,1,0.10404624277456648,0.04046242774566474,0.3764705882352941
618,635,635,"Determinants of mergers and acquisitions, a tool in vuca in business: A review study","The business now-a-days is fetching a considerable and prosperous tool of the development of an economy, which laid its foundation at an unmatched position in the state. The financial growth of a country is vibrant from the steadiness of the business. Deregulation in the monetary market, markets getting liberalized, fiscal changes have observed surprising discrepancies in corporate resulting in implausible challenges and development of technology sovereignty in of late emerging phase of business. While every business is persistent in their efforts to grow into strong and operationally efficient model, thereby, one of the modes for achieving the same is through Mergers and Acquisitions. Mergers and Acquisitions is a terminology which is used for accomplishing higher progress with technical supremacy in markets and to attain international competitive advantage due to higher scale of operations leading to economies of scale. The objective of this research paper is to identify various factors affecting Mergers and Acquisitions in the Indian Business.The literature review in support of identifying the various determinants and impact of Mergers and Acquisitions is existing. This paper observes by analyzing the literature and theories available that determinants of Mergers and Acquisitions are diverse and they have impacted acquiring company in context of the value of firm, its prosperity, shareholders wealth, better return on equity thereby increasing the efficiency of the Organisation.",60009843,Indian Institute of Foreign Trade,New Delhi,India,['1700'],31.42857142857143,0.11447368421052632,0.3482456140350877,1,0.0912863070539419,0.012448132780082987,0.23829787234042554
619,636,636,A novel efficient design for wireless power transfer employing T-slot defected ground structure,"This work suggests a novel model for short-range wireless power transfer (WPT) technology. The construction achieves strong power transmission using coupled resonators composed of a T-slot defected ground structure (DGS) and incorporated with two chip capacitors. The design works at 1.05 GHz and attains power transfer efficiency of 97.8 % at a distance of 10 mm with a size of 25 mm × 25 mm. Good concurrence between the simulated, theoretical, and measured data has been obtained.",60117075,Egypt-Japan University of Science and Technology,New Borg El-Arab,Egypt,['1700'],19.25,0.37777777777777777,0.4777777777777778,1,0.12087912087912088,0.02197802197802198,0.42528735632183906
620,637,637,Citrus leaf disease detection using Svm classifier,"Technologies are progressing, but farmers are still facing problems in identifying the plant diseases. Crop diseases are becoming a threat to the farmers due to which their crop productivity is going down. Each and every plant will be having different diseases and manual analysis of those diseases is very difficult. This calls for a huge amount of work, experience on diseases in plants and also extensive time for processing. All of these variables would reduce the productivity of crops. Image processing along with machine learning paves a way for the identification of the diseases. In this project citrus leaf disease dataset is used for identifying the diseases. K-Means Segmentation is used and inputs to the classifier. Both kNN and SVM classifiers are used out of which SVM acquired better results with an accuracy of 70.31%.",60076784,"Amrita School of Engineering, Coimbatore",Coimbatore,India,['1700'],15.0,0.052430555555555564,0.6059027777777778,1,0.10067114093959731,0.053691275167785234,0.3469387755102041
621,638,638,Essential design and fabrication considerations for the reliable performance of an electrothermal MEMS microgripper,"Over the past years, microelectromechanical systems (MEMS) have become a vital component within a wide range of technologies, making the study of their performance and operational reliability a very critical aspect for their correct functionality. Microgrippers are one such type of MEMS devices with one of their key applications being the manipulation of biological tissues and cells. This paper presents a microgripper design based on the ‘hot and cold arm’ electrothermal actuation mechanism that is suitable to study the deformability properties of human red blood cells under healthy and pathological conditions. The main scope of this paper is to highlight a number of failure mechanisms that are typical of surface micromachined MEMS microgrippers. These include out-of-plane buckling of the hot arm, stress concentrations, device stiction, and residual stresses. The studied polysilicon microgripper structures were designed and fabricated in line with the specifications of the commercial fabrication process PolyMUMPsTM. The microgripper design was numerically modelled and electrothermomechanically studied using finite element analysis in CoventorWare®. Experimental testing on the fabricated structures was used to demonstrate reliable microgripper performance as well as instances of the considered failure mechanisms. Results for the reliable microgripper performance show that the microgripper arms deflected as expected when actuated, with the obtained simulation and experimental results in good agreement. The investigated failure mechanisms have led to the identification of essential design and fabrication considerations whose thorough investigation, with the aid of appropriate modelling approaches, is essential to define improvement solutions and best practices to mitigate the failure or malfunction of the microgripper during operation.",60072651,L-Università ta' Malta,Msida,Malta,['1708'],25.6,0.057777777777777775,0.4777777777777779,1,0.08480565371024736,0.014134275618374558,0.29136690647482016
622,639,639,Assessment of the trends and challenges in quality management system/iso-9001:2008/ implementation: The case of agro-food industries in India,"This research is aimed at analysing the trends and challenges faced in implementation of ISO 9001:2008 standards in agro food companies of India. The study has employed a quantitative and qualitative research approach. Both primary and secondary data sources have been used. The primary data were collected from seven conveniently selected ISO 9001 certified agro food companies selecting136 employees in a systematic random sampling way and from seven conveniently selected noncertified companies selecting 33management members with a systematic random selection technique of sample respondents. A selfadministered questionnaire was used as data collection method. The qualitative data collected through face to face interviews and FGD from key informants analysed and interpreted. The study confirmed that there is a slow trend in using this standard as mechanism of improvement in agro food companies. The other major findings are: Lack of promotion and awareness, lack of coordination among national quality infrastructure bodies and lack of policy frame work and economical background of the country are articulated. On the other hand, the presence of weak quality infrastructure across the country, Lack of support from the government (incentives, promotion, award, enactment etc), Business priority issues of the companies, Lack of awareness in benefits of QMS and Lack of understanding in the QMS process requirements executions were being identified as the main difficulties for the agro food companies not to implement ISO 9001. Companies which make attempt to get certified to ISO 9001 standard has been surging during the past years and for those already registered seem to face some challenges in implementing it. The findings are lack of corrective action and preventive action, involvement of people and lack of continual improvement. Moreover, the weakness of the main enablers for the success of matured quality system like national widened quality promotion, national quality infra structure, lack of enactment of legislation and policies and shortage of technology and skills has got a big impact on the gap that is presented in both trend and challenge of QMS. Hence, working on the enablers, on the identified challenges and on the main inhibitors is a recommendable issue. For future by adding some values on the prevailing researches to exhaust the benefit of QMS through impact and effect by enlarging the scope both in sector and geography is also a recommendable point.",60115126,Balaji Institute of Telecom &amp; Management,Pune,India,['1700'],27.285714285714285,0.0036458333333333243,0.38125,1,0.0847457627118644,0.01937046004842615,0.2784503631961259
623,640,640,PID control with multimedia interaction based on improved genetic algorithm with its application in hydraulic transmission,"Conventional hydraulic transmission device has the problem of serious under-voltage consumption, which is not suitable for the transmission of high load equipment. In order to solve the problem of high load condition, this paper introduced a novel PID control with multimedia interaction that based on the improved genetic algorithm. First, the mathematical model of hydraulic transmission is built based on PID controller with multimedia interaction, and the control of hydraulic based on the interacting of a multimedia interactive cylinder pump is analyzed. Then, the PID control with multimedia interaction that based on improved genetic algorithm is used to optimize hydraulic system, compress hydraulic system, and overturning hydraulic system. Last, the multimedia interaction system of PID control based on improved genetic algorithm in hydraulic transmission is realized. The multimedia interaction system that constructed for experiments of PID control for hydraulic transmission showed that the transmission loss rate of the proposed PID control hydraulic system is 14.24% lower than that of the conventional hydraulic transmission system, and is suitable for the transmission of different loads.",60103975,Taiyuan University of Science and Technology,Taiyuan,China,"['1712', '1708', '1705']",28.83333333333333,0.02054112554112555,0.4509956709956711,1,0.09424083769633508,0.05235602094240838,0.25925925925925924
624,641,641,Performance analysis of QOS parameters of 4 G – Long term evolution (Lte) based architecture for M-health application,"Now a day’s wireless communication technologies are the important part of the broadband infrastructure of countries for the different applications. Due to limitations on the coverage in wired technologies, wireless technologies become more advantageous & successful to support remote health services. Also due to development in mobile technologies, medical services become the new generation of health care systems. The wireless technologies are used for improving the operating way of health care services and the conditions for the users. Ability of wireless technologies to transmit differentiated services is essential for the deployment of networks for m Health applications. For effective utilization of network, identification & different requirements in real time application such as bio medical signals need to be considered. Wireless data networks, particularly 4th generation (4G) and long-term evolution (LTE) are rapidly growing which in response to its increasing popularity and penetration of mobile devices among individual, corporate, business, and government service consumers. This wireless data networks, particularly 4th generation (4G) and long-term evolution (LTE) are rapidly gaining ground as predominant telecommunication services to provide high quality services to different applications particularly in health care system. However the quality of service (QOS) is the important factor in successful adoption of such wireless communication technologies in national/international scope specifically in health care system. Also due to rapid development in the features and capabilities of smart phone devices, wireless network technologies, plays important role in of Mobile Health domain (m-Health). In m health, body area network is the key interfacing network. Body area network (BAN) which consists of different biological sensors implanted on the human body which collects different medical data & send it to network by using smart phone devices. Hence sometimes this interfacing architecture of wireless body area network with wireless 4G network with the use of smart phones for health care system is referred as next generation health care system.",60114452,St.Vincent Pallotti College of Engineering and Technology,Nagpur,India,['1700'],23.923076923076927,0.13789502164502165,0.4874476911976911,1,0.060941828254847646,0.0332409972299169,0.32763532763532766
625,643,643,Challenges and Limitations of IEEE 802.1CB-2017,"IEEEFor many Ethernet-based real-time systems, such as those from automotive, avionics and industry automation domains, fault tolerance is emerged as an essential requirement for enabling fail-safe or fail-operational behaviour. Consequently the IEEE 802.1CB-2017 standard was published. It is currently the only available TSN standard offering protection against transmission errors. It tackles these faults by preventively replicating the frames and transmitting redundant copies via different paths to the destination. However, in contrast to its obvious advantages, the standard contains some pitfalls: most notably, it lacks protection mechanisms against inadequate configurations, which can not only invalidate the intended increase in reliability, but even actively jeopardise the safety of the network. Due to the lack of alternative mechanisms, it is crucial to fully understand the fundamental properties of the standard and its implications on the safety aspects of the network traffic. In this work we identify critical aspects and limitations of the standard. We demonstrate the risks of inadequate configurations, discuss their ramifications. Finally, we provide an intuition and initial steps towards deriving the formal worst-case timing analysis of the standard, which is a key requirement for its safe and efficient implementation in the aforementioned real-time domains.",60007902,Technische Universität Braunschweig,Braunschweig,Germany,['1700'],21.555555555555557,0.07191358024691358,0.4324074074074074,1,0.08333333333333333,0.017543859649122806,0.3472222222222222
626,644,644,An optimized Dijkstra’s SPF algorithm used multihop clustering for scalable IoT systems,"The adaptability issue of the IoT framework could be helped by social affair the center points of the IoT organize into gatherings and devising an agent center point in each gathering partner with the Internet to support various centers in the bundle as opposed to devouring a for every center point Internet affiliation and correspondence. In this broadside, we recommend a multi-hop gathering framework for IoT frameworks to constrain the amount of fundamental Internet associations. In particular, the target of future instrument is to choose the base amount of facilitators, which play the job of a delegate hub for the group, i.e., consuming the Internet association for the remainder of the hubs in the group and to delineate segment of the IoT hubs onto the chosen set of organizers to limit the complete separation between the hubs and their individual organizer.",60114757,Easwari Engineering College,Chennai,India,['1700'],47.0,-0.08000000000000003,0.3125,1,0.09271523178807947,0.033112582781456956,0.21476510067114093
627,645,645,An analysis of pradhan mantri fasal bima yojana (PMFBY): Expectations and reality,"Agriculture is a risky venture which is susceptible to various risks arising from weather variability, fluctuations in input and output price, difficulties in storage, pest attack and diseases. Although there are many risk mitigating tools, whenever there is a crop failure, crop insurance is considered to be the effective mechanism to compensate the farmers for their losses. One of the policy interventions in recent times to minimise the risk associated with agricultural production is the introduction of Pradhan Mantri Fasal Bima Yojana (PMFBY) in 2016. The previously implemented schemes because of their lower penetration and coverage met with limited success. To protect and double farmers’ income by 2022 is the major objective and a shift from increasing farm production to increasing farm income is the important policy change of this present scheme. But the scheme so far hasn’t had much success as coverage is far below the expected level. Using secondary data, the present paper is an attempt to examine the performance of the scheme.",60016850,Gauhati University,Guwahati,India,['1700'],23.57142857142857,0.07409147869674186,0.3662907268170426,1,0.08241758241758242,0.03296703296703297,0.2568306010928962
628,646,646,Intelligent plant disease diagnosis system based on a multi-modal approach,"Plant disease diagnosis systems play a key role in the identification of cases of infection within the plant. Currently, most automatic disease diagnosis systems detect diseases either by analyzing the visual feature of the diseased plant image, where the user query is an image of the disease taken from the field, that usually of low quality and also has a complex background. This leads to difficulty in making the appropriate diagnosis. At the same time, the other approach to disease diagnosis is based on a natural language query describing visual observation of the symptoms expressed by farmers. Due to incompletenessin user query or difficulty expressing symptoms correctly, this approach does not accurately recognize the disease. To solve these problems, this paper introduces a new plant disease diagnosis system that supports a multi-modal approach by incorporating imaging data and farmer observation data to improve accuracy in disease detection and reduce ambiguity in user’s query.",60104126,Jouf University,Sakakah,Saudi Arabia,['1700'],25.5,-0.00811688311688312,0.4152056277056277,1,0.10714285714285714,0.005952380952380952,0.2275449101796407
629,647,647,Influence of leadership style: A review,"The motive of this study is to survey how an individual's style of leadership straight influence their capacity to successfully oversee their employees. It also helps to explore different views as to whether or not leaders are born to lead, or whether it is an ability that can be built and improved over time by individuals who have the desire to be successful in leadership roles. Leadership is described as a system through which individual attempts are made to influence other members of the group towards achieving the goals of the group. Leadership is also seen as a process that people use to make the best of themselves and others. It is said that national culture plays a key role in determining the efficacy of leadership styles. Leadership is a process by which a person can steer, guide and influence other people's actions and functions towards achieving specific goals in a given situation. Leadership is the director's willingness to inspire the subordinates to work with trust.",60109019,Shoolini University,Solan,India,['1700'],23.714285714285715,0.22272727272727275,0.5340909090909091,1,0.15730337078651685,0.0,0.21910112359550563
630,648,648,Condition of the cardiovascular system in children with chronic pyelone-phritis on the background of hyperuricemia,"Comparative clinical-laboratory and instrumental evaluation of 62 children with chronic pyelonephri-tis was carried out. It was revealed that the increase in the level of MC significantly influences the development and progression of the cardiovascular system disease, which was expressed in higher blood pressure level, statistically higher frequency of pathological changes at ECG, as well as EchoKG, which is expressed in higher frequency of left ventricular hypertrophy.",60113775,Tashkent Medical Academy,Tashkent,Uzbekistan,['1700'],33.0,0.225,0.475,1,0.06578947368421052,0.06578947368421052,0.2361111111111111
631,649,649,An analysis of digital image compression technique in image processing,"Digital images are needed in various applications, such as transmission ofimages over communication channels varying widely in their bandwidths, display at different resolution depending on the resolution of a display device, etc. In this work, we are trying to do something different what they (Dugad and Ahuja) done in their algorithms for image compression. We arealso try to extend their approach and modified versions to images andstudied their performances at different level of compression for an image.The Discrete Cosine Transform (DCT) is an example of transform coding.The current JPEG standard uses the DCT as its basis. The relocates thehighest energies to the upper left corner of the image. The lesser energyor information is relocated into other areas. The DCT is fast. It can bequickly calculated and is best for images with smooth edges like photoswith human subjects. The Inverse Discrete Cosine Transform (IDCT) canbe used to retrieve the image from its transform representation.",60097558,IEC College of Engineering and Technology,New Delhi,India,['1700'],19.125,0.08088235294117647,0.35147058823529403,1,0.09142857142857143,0.06857142857142857,0.38596491228070173
632,650,650,The linkage between spiritual intelligence and emotional intelligence in rendering better work performance amongst teachers,"The guiding force behind the success of the society are teachers who understand the emotions of self and all the connected parties in connecting individual goal of the overall goal of the firm is dependent on Emotional balance. The performance related problems and associated stress being managed and balanced through a spiritual philosophy has become a key mantra called Spiritual Intelligence. Thus, the primary objective of this paper is to study the linkage between EI and SI and its impact on work performance amongst teachers. The target respondents are teachers and the data has been collected from private educational Institutions in the city of Chennai. The researcher has used a convenient sampling method to collect primary data using a questionnaire method and the sample size is (N=264). A structural Equation Model has been used to carefully examine which of the variables associated with EI and SI contributes to the work performance. The research concludes that, Spiritual Intelligence factors such as Holism, Compassion and positive use of adversity has a very strong impact on work-performance and Emotional Intelligence factors such as optimism and openness to feelings have a positive link on work-performance. Thus, teachers have to carefully examine and concentrate on these factors which will help them in personal development and career progression through a better work-performance.",60117285,"SRM Institute of Science and Technology, Ramapuram Campus",Chennai,India,['1700'],27.0,0.07953379953379952,0.4680477855477856,1,0.08898305084745763,0.06779661016949153,0.26956521739130435
633,651,651,Deep learning adaptive sturdy guided filtering for artifacts removal in infrared and visual image fusion,"In computer visualization applications, Infrared (IR) and Visual (VIS) image fusion has been developed rapidly as an interesting research field with the intention of combining the relevant information and producing a new image with better smoothing, sharpening and edge preservation. For this purpose, a Two-Scale Decomposition using Phase congruency and Sum modified Laplacian with Adaptive Sturdy Guided Filtering (TSD-PS-ASGF) technique has been proposed to construct the weighted maps by considering the bright and spatial variations between the respective pixels. As well, the fused image quality was adequately sharpened and smoothed by using ASGF method. However, this technique does not prevent the artificial structures and blur information around the salient features. Also, it has high computational complexity for constructing the saliency maps of base and detail layers. As a result, in this paper, a TSD-Deep Neural Network (DNN)-ASGF technique is proposed that uses DNN instead of PC and SML methods for constructing the saliency maps. At first, the TSD method is applied to decompose the source image into base and detail layers. For base layer, a weighted-averaging strategy is used for fusing the base information. For detail layers, DNN is used that extracts the multi-layer features. By using these features, l1-norm and weighted-average strategy are used for creating many candidates of the fused detail information. Once these candidates are obtained, the max-choice approach is performed to get the final fused detail information. Then, fused base and detail information are combined to reconstruct the final fused image with the minimum computational complexity. This TSD-DNN-ASGF not only preserves, smoothens and sharpens the information of both IR and VIS source images, but also prevents the artifacts, artificial textures and blurred details efficiently. At last, the experimental results illustrate that the proposed TSD-DNN-ASGF based image fusion technique achieves more efficiency than the state-of-the-art techniques like TSD-PS-ASGF in terms of objective evaluation and visual quality.",60114470,Erode Arts and Science College,Erode,India,['1700'],22.071428571428577,-0.03778900112233445,0.6047362514029181,1,0.11780104712041885,0.08900523560209424,0.3914285714285714
634,652,652,"Innovative technique for measurement fingerprint of cracks and strain on the surfaces of the archaeological painting, aswan case study","This study aims to measure the cracks on the surface archeologically, measuring strain, documentation the surface exact, and harmless because it does not need to take samples This work presents a modern technological method for measure strain result from cracks and scanning surface for now the number of crack and description it, our tool extracts the properties of each node and edge individually which allows to characterize the cracks statistically. The analyze using Ellipse fit program gives a quantitative valuation of crack lines on the surface and measure the tensile strength and get a chart showing the relationship between the distance and the angle of cracking, and clarify the most areas of the surface exposed to pressure resulting from the cracks as well as the ability to sense develop of the phenomenon of cracks during conservation by comparing the stress value that resulted and the value during conservation.The analysis using Ellipse fit software scans the archaeological surface of each crack on the surface and clarifies information about site, area and direction on the surface and measuring cracks caused by different mechanical behavior of the painting then measure the stress and tension caused by the crack, and provide knowledge about Morphology of crack patterns that are fingerprints for painting and which can be of great importance to cultural heritage. This technology provides the fastest and best way in data and analysis compiled and given the nature of digital data, they are dealing in quantity, and the values of the crack is documented for the paint surface.",60107271,Aswan University,Aswan,Egypt,['1700'],85.0,0.30416666666666664,0.3333333333333333,1,0.13382899628252787,0.007434944237918215,0.19101123595505617
635,653,653,Important skills for library professionals of techno-rich environment,"Today is the era of LPG i.e. Liberalization, Privatization and Globalization. In this era people are in need of fast and easy access of information. ICT is helping the libraries for this purpose along with all housekeeping operations. To fulfil the need of users satisfactorily LIS personnel are have to be technologically advanced and should be capable of adopting new skill. Professional skills along with technological skills and communication skills are very important for LIS professionals to cope up with the time. This study is shading light on the necessary professional as well as technological skills of LIS professionals of academic libraries and specially college libraries. Moreover now-a-days marketing skill is also becoming very important for a Library Manager. These days the concept of traditional library has turned to ‘Library in Pocket’. Concept of information virtuality has arisen. This study tries to emphasise the modern skills to be adopted by the Library professionals to survive in the techno-rich environment.",60016850,Gauhati University,Guwahati,India,['1700'],14.454545454545455,0.230402342755284,0.5681945505474917,1,0.07865168539325842,0.07303370786516854,0.3352601156069364
636,654,654,Lack of visibility of eco-labels: A study on consumer deception,"This paper focuses on consumer deception and aims to understand the level of awareness of eco-labels amongst consumers, whether they fall prey to the deception of pseudo eco-claims and if so, what are the reasons for the persistence of this malpractice. It aims to answer the following questions, (1) why eco-labels are scarcely used and mostly go unnoticed while there is more awareness about regular labels, (2) how can consumers distinguish between eco-label and pseudo eco-claim, (3) is there a need to recreate the existing eco-labels which can represent an overall assessment of a product’s environmental burden over its entire life cycle. The main contributions of the paper are that it will help consumers from falling for the deceptive practices which only claim to offer eco-friendly products and it will also benefit the companies which actually stand up to their eco-claims but often get overshadowed by the existence of pseudo eco-claims. A questionnaire survey was conducted which targeted individuals from the Indian demographics who regularly purchase items from the market. The objectives of the survey were to understand the individual’s level of awareness about the eco-labels, if they could recognize eco-labels and regular labels and if they could distinguish between eco-labels and eco-claims. The systematic reviewing of earlier research literature revealed that there is a lack of consumer awareness and that there is a dire need for law enforcement. This paper highlights the fact that in spite of the existence of government accredited eco-labels and laws to stop these deceptive practices, it is still practiced.It was found that these labels mostly go unnoticed or are absent from the product and the explicit visibility of pseudoeco-claims leads to the consumers blindly accepting the authenticity of these products or getting skeptical about all eco-products/labels. In the absence of specific logos for each phase of eco-transitions, which various companies are currently going through, there arises the problem of ambiguity about what the term ‘sustainability’ stands for. The present study will contribute significantly to the existing body of knowledge in regard to creating awareness of existing pseudo eco-claims and bring about a new standard for eco-labeling. It will also benefit industries whose eco-claims are genuine.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],36.1,0.0066212121212121215,0.3604125874125875,1,0.12442396313364056,0.029953917050691243,0.24744897959183673
637,655,655,Financial distress scenario in India: Recent patterns among various listed firms,"Using financial statements of various listed firms, this study examines various types of patterns among financial distress companies in India. The study investigated financial distress patterns among various firms registered under both Board for industrial and financial reconstruction (BIFR) and Insolvency & Bankruptcy Code (IBC), 2016 by sector, ownership, and firm life cycle stage from 2006 to 2018. The study found textile, steel, edible oil and paper among major sectors faced financial distress in the past decade. Maximum percentage of firms registered with both BIFR and IBC were either widely held or family held firms and were into the maturity stage of their firm life cycle. It was also found that firms in the industries like Mining and Quarrying, Food Products and Beverages, Sugar, Services, Telecommunication and Real Estate are facing further distress. The result of the study will benefit regulators, lenders and investors in their decision making process.",60094571,Lovely Professional University,Phagwara,India,['1700'],24.83333333333333,-0.0325,0.2833333333333333,1,0.09411764705882353,0.09411764705882353,0.3764705882352941
638,656,656,Implementation and performance analysis of random multiple access protocol with variable collision length of multimedia video information,"In recent years, multimedia video services have developed rapidly. However, the increasing number and variety of videos is likely to cause packet loss and delay during video transmission. Therefore, how to use channel resources more effectively becomes an urgent problem to be solved. This paper improves the existing random multiple access protocol and designs the 1-persistent CSMA (Carrier Sense Multiple Access) protocol with variable collision length. At the same time, considering the different requirements of different video services, multi-priority 1-persistent CSMA random multiple access control protocol with variable collision length is proposed, which sets different priorities and then competes fairly. Finally, the paper analyzes the performance of the multimedia video service access algorithm: the 1-persistent CSMA access protocol with variable collision length is higher than the traditional 1-persistent CSMA throughput, the performance is better, at the same time, in the case of a relatively high arrival rate, the advantage of throughput is more obvious.",60028009,Yunnan University,Kunming,China,"['1712', '1708', '1705']",25.66666666666667,0.07318181818181818,0.4631818181818181,1,0.08522727272727272,0.056818181818181816,0.3275862068965517
639,657,657,Higher education branding towards a higher education branding: Conceptualizing and measuring factors influencing choice of study programme,"Considering the declining university-student enrolment in Asian countries, study on higher education branding is more important than ever. Particularly, Thailand is now encountering a drastic demographic challenge with a huge decline in student enrolment. While research on university branding has been widely studied to position the institutions, however, there is little research on curriculum/programme branding. This prompts us to explore factors influencing students’ choice of a particular higher education programme, which can improve the understanding of students’ decision-factors. The findings would be useful to support marketing programmes, especially for branding development. Thus, this research aims to examine the factors affecting programme choice of prospective students. The study conceptualizes, constructs and validates a measurement scale of factors affecting choice of programme, especially the BBA programme. The survey was applied with 336 prospective students in Bangkok, Thailand. This research provides the operationalization of a set of factors influencing a student’s choice of BBA programme that can be applied across different contexts. Additionally, the measured influencing factors are found to correlate to different extents with behavioural intention measure.The results will be beneficial to faculties and universities to develop appropriate branding development, which can differentiate themselves from other institutions.",60018809,Silpakorn University,Nakhon Pathom,Thailand,['1700'],19.5,0.1482843137254902,0.5318627450980392,1,0.14035087719298245,0.021929824561403508,0.38461538461538464
640,658,658,Quality value based routing protocol for energy optimization in wireless sensor networks,"From the past decade, wireless sensor networks (WSNs) raised their importance in the communication networks. Though WSNs are having the many advantages, they are lacking in efficient routing protocols. This paper considers the objective of optimizing the energy of WSNs. The proposed method considers the quality value of each node to forward the packers. The quality value is depends on the residual energy and cost. The cluster head selection is also done by the quality value of the node. The simulation analysis is performed with different parameters. The results proved the efficiency of the proposed protocol.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],12.0,0.0625,0.3625,1,0.1111111111111111,0.009259259259259259,0.3148148148148148
641,659,659,New fundamental modulation technique with SHE using shuffled frog leaping algorithm for multilevel inverters,"This paper presents the selective harmonic elimination of cascade H-bridge multilevel inverters using shuffled frog leaping algorithm. This algorithm takes the advantages of the genetic-based memetic algorithm and the social behavior-based PSO algorithm. In addition, this study provides a new fundamental modulation technique with SHE for multilevel inverters which can generate output waveforms with a full range of modulation indices. There are two control objectives formulated as a multi-objective optimization problem. The mentioned algorithm finds the optimal solution set of switching angles. Simulation is performed in MATLAB to confirm the validity of the proposed method.",60109830,"Islamic Azad University, West Tehran Branch",Tehran,Iran,['1706'],15.833333333333336,0.1732323232323232,0.3570707070707071,1,0.15454545454545454,0.01818181818181818,0.37254901960784315
642,660,660,A cost effective scalable scheme for dynamic data service in heterogeneous cloud environment,"Storing data in the past required a lot of resources and management. Because of tremendous utilization of web in distributed environment has created an urgent requirement for new techniques and frameworks that intelligently handled the information into valuable data and information. The past research methodologies and their frameworks focused only on static data which leads to wastage of resources and computational when the data is dynamic and soft. This paper proposed a new architectural framework to reduce the communication overhead, substantial switching cost and avoid lock-in dependency for the customers who uses the cloud services. The proposed framework uses K-means clustering analysis to filter the data in dynamic data services such as weather report, share market and streaming data like video or audio files while retrieving from the cloud. The unique feature of this framework is to provide the services using different service providers through a single interface. This research aims in enhancing the scalable resources based on the request made by the customers. The framework uses request analyzer to analyze the content which is based on media or numeric, resources are scheduled and allocated from the providers and deliver without communication delay to the customers. The experimental results indicates the proposed framework is better option in delivering the services without communication delay.",60069600,"St. Joseph's College, Tiruchirappalli",Tiruchirappalli,India,['1700'],23.66666666666667,0.14174306086070795,0.5356888209829386,1,0.14847161572052403,0.013100436681222707,0.25333333333333335
643,661,661,Replication of big data for increasing availability,"Substantial facts speaks to a noteworthy test for the presentation of the allotted computing stockpiling frameworks. a few distributed file systems (DFS) are notably used to hold huge records, for instance, Hadoop Distributed File System (HDFS), Google File System (GFS) and others. those DFS reproduce and store records as severa duplicates to offer accessibility and dependability, but they increment stockpiling and property utilization. In a beyond art work, we constructed a Redundant Independent Files (RIF)framework over a cloud provider (CP), referred to as CPRIF, which gives HDFS without reproduction, to beautify the general execution thru diminishing extra room, property usage, operational prices and advanced the composition and skimming execution. Be that as it can, RIF stories restricted accessibility, restrained unwavering incredible and multiplied records restoration time. in this paper, we beat the confinements of the RIF framework by using way of giving extra opportunities to get better a misplaced rectangular (accessibility) and the potential of the framework to keep operating the nearness of a out of place square (unwavering tremendous) with a lot much less calculation (time overhead). just as maintaining the benefits of potential and assets utilization executed through RIF contrasted with unique frameworks. We call this method “High Availability Redundant Independent Files” (HARIF), this is labored over CP; called CPHARIF. As indicated via way of the trial consequences of the HARIF framework the usage of the TeraGen benchmark, it is decided that the execution time of recouping data, accessibility and unwavering extremely good using HARIF were stepped forward as contrasted and RIF. furthermore, the placed away information duration and assets utilization with HARIF framework is faded contrasted with one of a kind frameworks. The large records stockpiling is spared and the statistics composing and perusing are improved.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],26.272727272727273,0.18112836438923394,0.5037060041407867,1,0.13649851632047477,0.08605341246290801,0.39233038348082594
644,662,662,Viability of low cost adsorbents for the removal of toxic pesticides in environmental matrices-A review,"In the present review article the use of low cost adsorbents derived from various materials and chemically modified adsorbents for the removal of toxic pesticides of various classes from environmental matrices has been reviewed. Innumerable pesticides may appear as serious toxic pollutants in water sources, having detrimental impacts on various life forms and even human health because of their toxicity, carcinogenicity, and mutagenicity or causing aesthetic problems such as taste and odors. These toxic pesticides pollute various segments of environment and they can be removed in aqueous media very effectively using different low-cost adsorbents and as well as chemically modified low cost adsorbents derived from various sources. It is evident from the literature survey of recently published papers those low-cost adsorbents have demonstrated outstanding removal capabilities for pesticides. An attempt was made to formulate few low cost adsorbents which are effectively used in the removal of toxic pesticides from aqueous media.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],30.2,0.08403508771929824,0.4495614035087719,1,0.11042944785276074,0.0,0.29559748427672955
645,663,663,Design and development of an advanced ICT training management system for universities,"This paper presents the design and development of an Information Communication Technology (ICT) system that can automate all the university Summer Training Unit workload. The paper will describe the system design procedure, highlighting the requirements that were identified via user questionnaires. It will then show the methodology for implementing the required software as well as the validation and usability testing based on the end user’s acceptance metrics.",60004582,King Abdulaziz University,Jeddah,Saudi Arabia,['1700'],22.33333333333333,0.0,0.0,1,0.14864864864864866,0.0945945945945946,0.3466666666666667
646,664,664,Design and analysis of nano-band pass and stop filters for high data rate applications,"For the processing of data, present day electronic equipmentis rapidly forthcoming their ultimate speed and bandwidth constraints, that is an ever more serious problem that prevents their persisted use in applications. It is believed that a promising solution is to fabricate electronic and photonic elements on the single chip. This mechanism provides a larger bandwidth that is used to construct new hybrid electronic photonic devices. This paper reports the Basic design of band-pass and band-stop filter using an even mode resonance step impedance resonator (EMRSIR) and discussed basic transmission line characteristics of metal-insulator-metal(MIM) wave guide structure. The basic transmission line characteristics propagation length,effective refractive index, and characteristic impedance of the MIM wave guiding structure are obtained through full wave simulation. Here in the proposed design of dual band band-stop and band-pass filters operates simultaneously at optical frequency bands at230.02 THz and185.72THz with low losses (approximately-35 dB return loss). Filters are designed in new way of integrated photonic devices based on surface plasmons.",60079446,K L Deemed to be University,Vaddeswaram,India,['1700'],23.142857142857146,0.056753246753246764,0.3987806637806637,1,0.10471204188481675,0.041884816753926704,0.3701657458563536
647,665,665,Effect of green human resource practices on organization commitment,"There are many studies which showed that committed employees’ perform better. Every organization needs committed employees’ to attain objectives and with stand the competition. The study is related to Atlas Copco Ltd, Hyderabad. The sample unit is employees’ of Atlas Copco Ltd. The main purpose of the present study is to find the impact of green human resource practices on organization commitment levels of the employees’. The green Human Resource practices taken in the study are Leadership practice, Work culture, Recruitment and selection and Reward management. Regression is used for finding the association of green human resource practices and organization commitment. The findings of the study showed moderate positive impact of Green human resource practices on organization commitment. Leadership practice and work culture showed positive significant impact on organization commitment. Recruitment and selection, reward management was not having significant impact on the organization commitment levels of the employees.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],14.8,0.0872895622895623,0.3819023569023569,1,0.09090909090909091,0.07878787878787878,0.3313253012048193
648,666,666,Computer desktop visualization image compression based on fuzzy clustering algorithm,"This paper studies the computer desktop visual image compression technology based on fuzzy clustering algorithm, and proposes a computer desktop image compression scheme based on HEVC and color clustering. Aiming at the active adaptive block partitioning of computer desktop image, a high quality and low complexity compression algorithm for computer desktop image compression is proposed to further promote the development of screen sharing technology. Color clustering algorithm runs color clustering, simplifies color categories, saves code flow, and improves code performance. FCM fuzzy clustering algorithm compresses image blocks to provide effective image compression for high resolution computer desktop visualization images. In the end of this paper, the computer desktop image compression scheme proposed in this paper is compared with other compression methods. The experimental results of the adaptive dynamic block classification algorithm and the static block classification algorithm are compared. The experimental results of the color clustering algorithm and the non-color clustering algorithm are compared. Experimental results show that the proposed scheme is superior to some other compression algorithms.",60102087,Yangtze Normal University,Chongqing,China,"['1712', '1708', '1705']",21.0,0.1357777777777778,0.4797777777777779,1,0.11956521739130435,0.021739130434782608,0.27472527472527475
649,667,667,IoT based intelligent health surveillance & alert system with fault prediction using machine learning,"The primary target of this paper is to watch the patient wellbeing subtleties each and each second and update the little print to Server via a complicated IoT similarly as Care takers will straightaway read or monitor the current position of patients with none hidden activities. The intention is to realize high level of accuracy and speed. Net of Things (IoT) a boon to communication field, that connects the remote individuals via international medium. The most concern of IOT is to modify the powerful network association in little devices. During this system the concentration is comprise Medication system primarily based health care police work. This technique permits the patient details to be read to international server with reference to access management perspective. With this technique, nobody will cheat the care takers, nobody will hide the patient health outline and nobody having restriction to understand regarding the particular state of affairs of several patient. During this framework, a fresh out of the box new system is presented for auxiliary wellbeing viewing (SHM) exploitation IoT advances on astute and dependable viewing. In particular, advances worried in IoT and SHM framework usage are comparative as data steering system in IoT surroundings territory unit given. since the amount of data produced by detecting gadgets region unit voluminous and faster than at any other time, colossal data arrangements region unit acquainted with handle the progressed and massive amount of information gathered from sensors put in on structures. Prediction has important role for IOT. Those data which is sensed by sensors should be analyzed and should be predicted for some another condition. In our approach from past record we should identify the heart attack possibility to aware the patient. For that we have proposed machine learning approach with decision tree and logistic regression.",60111820,Gujarat Technological University,Ahmedabad,India,['1700'],21.214285714285715,0.10389759665621734,0.4541222570532916,1,0.12149532710280374,0.03426791277258567,0.2336448598130841
650,668,668,Determinants of employee retention-using factor analysis,"The organization’s performance depends up on the performance of the skilled employees’. It is very essential for every organization to sustain the skilled employees with it. The present study explores factors explaining employee retention. The study is related to Lee Pharma, Aurobindo Pharma and Magene Life sciences of Hyderabad. The data is collected from 242 employees’. The sampling technique used is convenience sampling. The analysis is done using Factor analysis and Kruskal wallis test. The findings of the study showed that the employee retention was explained by five factors. The five factors extracted were relationship management, rewards and recognition, work environment, leadership practice and welfare facilities. Further these five factors were tested for the significant mean difference with the designation and service of the employees’. It was found that designation and experience levels of the employees’ were not significantly different with the five extracted factors. The employer should concentrate on improving the factors extracted to retain the employees’ in the organization.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],13.416666666666664,0.11805555555555555,0.4947222222222222,1,0.1092896174863388,0.04918032786885246,0.30978260869565216
651,669,669,Theoretical and simulation analysis of first generation DC-DC converters,"This paper deals with the question about the most efficient and less energy consumptive type of low voltage DC-DC converter. Different types of DC-DC converters from the first generation are analyzed in terms of voltage transfer capability and output voltage ripple. The comparison of voltage ripple of different types of converters is given. Based on the simplicity, four DC-DC converters namely, Boost converter, Elementary Positive Output Luo Converter (EPOLC), Enhanced Self-Lift Luo Converter (ESLLLC) and Super-Lift Luo Converter (SLLC) are filtered among first generation and their performance for different conduction duty are theoretically analyzed. The theoretical analysis results in the identification of best DC-DC converter, which is suitable for process automation. Further, the simulink models for those DC-DC converters are developed using MATLAB software. The results on output DC voltage validates that the SLLC is well suitable for the application involving process automation.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],20.428571428571427,0.20944741532976827,0.44581105169340457,1,0.05113636363636364,0.17045454545454544,0.4074074074074074
652,671,671,Pushover analysis of a reinforced concrete high rise frame building with aerated autoclave concrete brick infill and its behavior with and without shear wall,"In this research study, the effect of adopting Aerated Autoclave Concrete (AAC) bricks infill in high-rise buildings has been studied, with focus on its influence on the building during an Earthquake. The building models of two different heights are chosen. This paper presents the static non-linear analysis (Pushover Analysis) of high-rise concrete building using Aerated Autoclave concrete (AAC) blocks as brick infill and its behavior with and without a shear wall. By Performing pushover analysis, it gives the performance level of the building, plastic hinges and pushover curves. The static non-linear analysis provides a greater perceptive and more precise Structural seismic reliability and also the failure elements of the structure.",60106974,"JNTUA College of Engineering, Ananthapuramu",Anantapur,India,['1700'],22.0,0.2533333333333333,0.54,1,0.07518796992481203,0.06766917293233082,0.384
653,672,672,Estimating inelastic seismic response of reinforced concrete frame structures using a wavelet support vector machine and an artificial neural network,", part of Springer Nature.Modern building codes increasingly enforce evaluating the inelastic response of structures to ensure their safety in major seismic events. Although an inelastic dynamic analysis provides the most realistic and accurate measure for the seismic response, its application for large-scale structures is hampered by the excessive computational burden involved. This is particularly the case for the optimization of inelastic structures subjected to dynamic loads using metaheuristic algorithms where numerous analyses are required before the design converges to the optimum. In this regard, developing predictive models with sufficient accuracy will significantly help to reduce the computational demand, thus making the seismic analysis and optimization of large structures more feasible and common practice. Motivated by this need, this paper reports a study on the capabilities of a wavelet weighted least squares support vector machine (WWLSSVM) and a feedforward, backpropagation artificial neural network (ANN) to accurately predict the inelastic seismic responses of structures. The force- and displacement-based seismic responses of an 18-story reinforced concrete frame subjected to different earthquake ground motion records scaled to the design basis earthquake and maximum considered earthquake levels are used to train the models and examine their accuracies. The first three natural periods of the frame and combinations thereof are considered as the inputs for the model. The results indicate that both models exhibit satisfactory prediction performances, with the ANN model having a slight edge on accuracy in most of the cases studied, especially when a smaller number of samples are used for training. A parametric sensitivity analysis shows that the seismic responses predicted by the ANN model generally exhibit less sensitivity to the inputs than do those predicted by the WWLSSVM model. The results also indicate that force- and displacement-based responses exhibit the highest sensitivity to the first and second natural periods, respectively.",60030265,University of Birjand,Birjand,Iran,"['1712', '1702']",29.9,0.10005760368663597,0.4700076804915515,1,0.11854103343465046,0.0243161094224924,0.27102803738317754
654,673,673,A study on effectiveness of gamified learning among arts & science college students with special reference to Chennai City,"PURPOSE: The purpose of this study is to find out the effectiveness of gamified learning among arts and science college students in Chennai city. The other purpose of this study is to analyze the factors that influence towards gamified learning. METHODOLOGY: The data for the study is collected from 90 students in arts and science colleges in Chennai. Also, the study focuses only on 5 major departments in city colleges. Purposive sampling method has been used. TOOLS AND TECHNIQUES: Demographic profile of the respondents is studied. ANOVA and Factor Analysis are used for the study. FINDINGS: The study identifies that students feel easy to listen, understand and learn if the new teaching techniques like gamification are used in classrooms. IMPLICATIONS: The results of the study indicates that, this is the right time for the educators to adapt new technology oriented techniques in classroom as most of the students in city colleges are already being benefited because of such techniques.",123957251,Faculty of Science and Humanities,Kattankulathur,India,['1700'],17.666666666666668,0.1588083213083213,0.5725709475709475,1,0.10795454545454546,0.028409090909090908,0.3465909090909091
655,674,674,E-commerce - In the economy of the world and Uzbekistan,"The need for information technology (IT) is growing at a rapid pace in order to achieve the well-being of the world community. Economic growth and improved living standards are the result of the penetration of information technology into our daily lives. World experience shows that securing a free flow of information can accelerate the transition to a market economy and improve social welfare. The rapid development of information technology is also reflected in the economy. The main reason for the success of the economy, especially in the business sector, is the high level of development and effective use of various information technology segments. The economy of Uzbekistan is no exception. A vivid example is the steady growth of a number of information technology segments, such as data networks, information resources and electronic document exchange, business and commerce. This article discusses the role of e-commerce and the digital economy in Uzbekistan and the world community. The importance of this business will be highlighted.",60116766,Tashkent Institute of Finance,Tashkent,Uzbekistan,['1700'],18.0,0.15369047619047618,0.4278571428571429,1,0.06043956043956044,0.02197802197802198,0.19662921348314608
656,675,675,An application of pascal distribution series connected with certain subclasses of spirallike functions,"The aim of this paper is to obtain new functions involving a power series whose coefficients are probabilities of the pascal distribution. Further we find the sufficient conditions of subclass Kα [A,B] of Spirallike functions involving the defined functions.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],19.5,0.06818181818181818,0.4772727272727273,1,0.1111111111111111,0.044444444444444446,0.37777777777777777
657,676,676,Bankruptcy prediction using Altman Z-score model and data envelopment analysis model: A case of public listed realty sector companies in India,"Over the years, around the world, bankruptcy prediction models has gained the centre stage of attention to predict failure in corporate firms. Bankruptcy prediction in corporate has become a growing concern in India especially with the matter of fact that distress has ruled over almost all the sectors in the Indian economy in the last couple of years. The data of Insolvency and Bankruptcy Board of India (IBBI) shows that the companies in real estate and renting business have been affected the most. Therefore this study intends to estimate likelihood of Bankruptcy of real estate sector companies by applying accounting versions of Altman’s Z-Score Model and input oriented Data Envelopment Analysis (DEA) CRS Model. The study tested NSE listed Realty Sector companies which are constituent of the Nifty Realty index that are primarily engaged into construction of residential and commercial properties. Although the results produced by both the models employing different accounting parameters are not entirely the same. However both the models reveal that there is need of agility action in case of two financially distressed realty sector companies. The results of the study can be of great significance to all the stakeholders who are affected directly or indirectly by the financial performance of these companies.",60094571,Lovely Professional University,Phagwara,India,['1700'],25.75,0.1101851851851852,0.30925925925925923,1,0.08520179372197309,0.09865470852017937,0.3108108108108108
658,677,677,Immunocytochemical assessment of FKBP51 and Glucocorticoid receptor localization in asthmatic patients," All rights reserved.Asthma is a chronic inflammatory disease affecting 5% of the world population. FKBP51 is an important immunophilin modular protein of the glucocorticoid receptor (GC). The aim of the present study was to evaluate the levels and immunocytochemical distribution of FKBP51 and GR in lymphocyte cells of asthmatic patients, by use of immunocytochemistry method, and to assesslevels ofstress hormones (cortisol and ACTH) by radioimmuniassay (RIA). The results showed significantly increased nuclear localization and decreasedcytoplasmic distribution of FKBP51, while they showed a significant increase in nuclear localization and a non-significant decrease in cytoplasmic distribution of GRin asthmatic patients(P<0.05). Cortisol and ACTH levels were also measured and showedinsignificant increases(P<0.05)in steroid treated (338.85 ±139.5 mMol/L, 35.05±3.77 ng/ml, respectively)and non steroid treated asthmatics(280.5 ± 74.6 mMol/L, 32.0±6.43 ng/ml, respectively)as compared with the control group (234.33±29.13 mMol/L, 29.0±7.02 ng/ml, respectively).",60071152,Al-Nahrain University,Baghdad,Iraq,['1700'],27.4,0.23,0.5700000000000001,0,0.056179775280898875,0.15168539325842698,0.5084745762711864
659,678,678,"Erratum: One-dimensionally polarization-independent retrodirective metasurface [Journal of Electromagnetic Engineering and Science, 19, 4 (2019), (279-281)] DOI: 10.26866/jees.2019.19.4.279","In the above titled paper (Journal of Electromagnetic Engineering and Science, vol. 19, no. 4, pp. 279-281, 2019), we noted that inadvertently and accidentally failed to include a coauthor (Chang-Hyun Lee). The full list of authors has now been added and the authors' affiliation information is following.",60017776,Hongik University,Seoul,South Korea,['1705'],9.4,-0.037500000000000006,0.2625,1,0.09090909090909091,0.15151515151515152,0.4838709677419355
660,679,679,Optimal deep transfer learning framework for feature selection based brain tumor image classification,"Brain tumor(BT) is an important disease which affects major part of the global population including children and older people. The possibility of survival rate can be improved by the identification of the tumour at the starting level. The aspiration of feature selection (FS) method is to choose a smaller subset of features which will reduce the redundant part and increase the related part towards the target like class labels. Therefore, machine learning approaches gains maximum performance while including the chosen important features. So, presently, FS acts an important role in the classification task. Keeping this in mind, in this paper, we introduce a feature selection-based BT classification model. For FS, modified genetic algorithm (MGA) is used and deep transfer learning model is used for classification. To develop MGA, appropriate changes have been made in the traditional GA by minimizing the arbitrary behaviour. The presented DTL with MGA is validated on the collection of benchmark images and verified that the DTL results are improved by the use of FS methods.",60104311,"Presidency College, Chennai",Chennai,India,['1700'],18.777777777777782,0.10861111111111107,0.4855555555555556,1,0.13020833333333334,0.046875,0.3229166666666667
661,680,680,Cubic spline solution of nonlinear singularly perturbed boundary value problems via initial value method," All rights reserved.In this paper, a cubic spline solution of nonlinear singularly perturbed two-point boundary value problems exhibiting boundary layers is presented via initial value method. The method is distinguished by the following fact: The original problem is approximated asymptomatically by two first order unperturbed initial value problems which are, in turn, solved using polynomial cubic spline approximation method. Error estimate and numerical results are presented to assess the accuracy and the performance of the method. It is observed that the present method approximates the exact solution very well overall the problem entire domain.",60105222,Prince Sattam Bin Abdulaziz University,Al Kharj,Saudi Arabia,"['1712', '1708', '1705', '1702']",23.75,0.1075,0.2358333333333333,0,0.12149532710280374,0.0,0.2647058823529412
662,681,681,Performance analysis of MIMO-OFDM system based on SVD scheme under multi path selective fading channel,"We consider in this paper a MIMO-OFDM wireless communication system based on pre-coding and SVD techniques, which the system has the feedback of CSI to the transmitted side. The multi path channel, delay spread, Rayleigh fading and channel noise are assumed in the simulation of the proposed system. The zero forcing method is applied for detection the data received. The purpose of this study proposed is to evaluate the BER performance and see it with different case about parameters. While The contribution of the MIMO-OFDM proposed system is appeared from the BER performance presented in the section result which the system have shown good improvement of BER in typical channel modeled by Rayleigh multi path channel while the improvement is kept particularly in the complex condition of the channel while the propagation considered by more paths until ten paths are used. And also the BER resulted show that the system guard important performance for high data rate either when the more carriers are used such as 128 and 256 and when more antenna (4×4) are simulated. The robustness of that system studied comes from using SVD scheme into the process of channel, from the pre-coding technique applied over the data transmitted and the properties of OFDM multi carriers that having such as guard interval, parallel transmission, and FFT technique.",60069900,Université Hassiba Benbouali Chlef,Chlef,Algeria,"['1711', '1709', '1708', '1702']",31.285714285714285,0.1757142857142857,0.4623809523809524,1,0.11983471074380166,0.049586776859504134,0.25213675213675213
663,682,682,Physics based non-linear large-signal analysis of multiple-graphene layer exotic pin (p ++–n −–n–n ++) devices and ultra-fast SPST/SPDT/SPMT switches on Si/3C-SiC (100) substrates for application in THz-communication,"Multiple-Graphene-Layer (MGL) on Si/3C-SiC (100) substrate is proposed for designing of a vertically doped p++–n−–n–n++ device/switch array for Terahertz communication systems. In addition to the superior mechanical properties in Graphene, conducive–electrical and electronic properties, especially, high carrier mobility in MGL has made this a promising material for different novel applications in THz domain. A quantum-modified classical drift–diffusion (QMCLDD) mathematical model, incorporating quantum size effects, arising due to Multiple-Graphene-Layer, is developed by the authors for analysing the THz-characteristics of exotic-pin p++–n−–n–n++ devices and switches. The validity of the model is further established by comparing the simulation results with those of the experimental observations under similar electrical/thermal/structural operating conditions. The comprehensive study reveals that the switching behaviour of the device improves considerably due to the incorporation of MGL structure in the central i-region of the device. The device has shown considerably faster reverse recovery time (~ 0.5 ns), low forward RF series resistances (0.29Ω) and low power dissipation (0.45 dB). Central i-region width, doping concentration and mesa diameter of the device are optimized by studying the punch-through effects on the electric field profiles under large signal operation. It is observed that compared to the High-Punch-Through Device (HPTD) and Non-Punch-Through Device (NPTD), Low-Punch-Through Device (LPTD) is showing better high-frequency performances under similar operating conditions. A tradeoff between device width and doping concentration is further established for ultra-fast switching operation in the THz-regime. A comparative analysis of Insertion loss (IL) and Isolation (ISO) in Single-Pole-Single-Throw (SPST), Single-Pole-Double-Throw (SPDT) and Single-Pole-Multi-Throw (SPMT) THz-switches (with series–shunt and Shunt type arrays) is reported in the paper. The study clearly reveals the suitability of LPTD variant for the development of SPST switches in terms of lowest IL (0.015 dB) and SPMT shunt switches in terms of highest ISO (88.0 dB) at around 4.0 THz. Moreover, the authors have made quasi 2D-thermal analysis of the Device-Under-Test (DUT). The results will be extremely useful for developing ultrafast solid-state switches. To the best of authors’ knowledge this is the first ever report on vertically grown MGL-exotic pin (p++–n−–n–n++) device on Si/3C-SiC (100) substrate, as a THz ultrafast switch.",116661772,Adamas University,Kolkata,India,['1708'],24.785714285714285,0.14537142857142854,0.3898095238095239,1,0.057539682539682536,0.0992063492063492,0.46859903381642515
664,683,683,Multi operator based affine transformation function for fractal image generation with minimal distortion,"The advancement in image processing is a critical aspect in the domain of digital data transfer over a secure medium. For secure data transfer, new algorithms can be developed by implementing fractals. Generating fractal image requires the use of scaling operator in the conventional affine transformation, which results in distortion of salient objects present in the image. To overcome image resizing problem associated with conventional affine transformation, this paper proposes a new affine transformation function based on multi-operator scheme, which integrates improved seam carving algorithm with cropping and warping operators. Seam bypassing operation in the proposed algorithm and elimination of scaling operator in proposed affine transformation function optimizes the process of fractal image generation with minimum distortion in ROI. To simplify image retargeting operations, optimized image distance function was used. The optimized image distance function was formulated which combines bidirectional IMED, Dominant Color Descriptor (DCD). Promising results have been presented which demonstrates the effectiveness of the proposed function over the existing affine transformation function.",60111841,Uttarakhand Technical University,Dehradun,India,['1700'],20.5,0.0988193624557261,0.402125147579693,1,0.16483516483516483,0.02197802197802198,0.3277777777777778
665,684,684,A novel approach to design extended LFU page replacement algorithm,"Research on page replacement algorithms is a very core research field in Advance Operating Systems. Today any advancement in sorting algorithms would lead to higher hit rate and lower page fault rate, that would further decrease the time required to serve the pages. This paper discusses a newly proposed page replacement algorithm – “Extended LFU Page Replacement Algorithm.” It is basically an advancement to LFU page replacement algorithm. The purpose of this paper is to reduce the page fault rate and increase the hit rate in a page replacement process where there is repeated request of multiple pages over a request string of considerable length. This paper also compares the newly proposed algorithm with LFU page replacement algorithm in terms of hit rate and page fault rate through graphical analysis.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],26.0,0.11753246753246753,0.37987012987012986,1,0.11510791366906475,0.05755395683453238,0.2463768115942029
666,685,685,"Role of vascular endothelial growth factor (VEGF) in tumor progression among oral epithelial dysplasia (OEDs), verrucous carcinoma (VC) and oral squamous cell carcinoma (OSCC) – An immunohistochemical study","Background: Oral Squamous cell carcinoma (OSCC) is a grave health issue problem worldwide which often leads to compromised life style or sometimes lethal. It positions itself in sixth place among cancer prevalence and is one of the leading cause for death in India. Potentially Malignant Disorders (PMDs) are precursor lesions which has higher potential for transforming into oral squamous cell carcinoma. Tumor angiogenesis is an important biomarker that may govern the progression of precancerous lesion into cancerous lesion. Vascular Endothelial Growth Factor (VEGF) plays a vital part in carcinogenesis by inducing angiogenesis. Angiogenesis is establishment of new blood vessels from prevailing vasculature which is crucial for tumor development, progression and metastasis. Aim: To evaluate and compare the expression of VEGF among Oral Epithelial Dysplasia (OEDs), Verrucous Carcinoma (VCs) and different grades of Oral Squamous Cell Carcinoma (OSCCs). Material and Methods: The study comprised of 100 formalin fixed paraffin embedded tissue blocks comprising of 20 cases of OED, 20 cases of VC and 60 cases of OSCC [20-well differentiated oral squamous cell carcinoma (WD-OSCC), 20 – moderately differentiated oral squamous cell carcinoma (MD-OSCC), 20 – poorly differentiated oral squamous cell carcinoma(PD-OSCC)]. All the cases were immunostained for anti-human VEGF mouse IgG monoclonal antibody. The expression were VEGF evaluated for staining intensity, distribution and statistically analyzed with Analysis of variance (ANOVA), Post hoc Bonferroni test, Independent t-test, Pearson Chi-square test, Pearson correlation coefficient test. Results: VEGF immunoexpression was found to be increased in the order of OEDs, VC and Oral Squamous Cell Carcinoma OSCC. The percentage of positivity was found to be more in PD-OSCC, followed by MD-OSCC, WD-OSCC. Conclusion: From our study it was concluded that, angiogenesis plays major role in tumor progression and metastasis. There was significant correlation found between VEGF expression, increases in vascularity during transition from OEDs to VCs and OSCCs.",60112730,Vinayaka Mission's Sankaracharyar Dental College,Salem,India,['1700'],21.642857142857146,0.10159090909090908,0.6303030303030303,1,0.0797872340425532,0.1276595744680851,0.475
667,686,686,Urban hazmat transportation with multi-factor,"In this paper, an urban hazmat transportation problem considering multiple factors that tangle with real-world applications (i.e., weather conditions, traffic conditions, population density, time window, link closure and half link closure) is investigated. Based on multiple depot capacitated vehicle routing problem, we provide a multi-level programming formulation for urban hazmat transportation. To obtain the Pareto optimal solution, an improved biogeography-based optimization (improved BBO) algorithm is designed, comparing with the original BBO and genetic algorithm, with both simulated numerical examples and a real-world case study, demonstrating the effectiveness of the proposed approach.",60021843,Beijing University of Chemical Technology,Beijing,China,['1712'],30.33333333333333,0.034722222222222224,0.15277777777777776,1,0.1282051282051282,0.03418803418803419,0.41284403669724773
668,687,687,Hybrid intrusion detection and signature generation using Deep Recurrent Neural Networks,", part of Springer Nature.Automated signature generation for Intrusion Detection Systems (IDSs) for proactive security of networks is a promising area of research. An IDS monitors a system or activities of a network for detecting any policy violations or malicious actions and produces reports to the management system. Numerous solutions have been proposed by various researchers so far for intrusion detection in networks. However, the need to efficiently identifying any intrusion in the network is on the rise as the network attacks are increasing exponentially. This research work proposes a deep learning-based system for hybrid intrusion detection and signature generation of unknown web attacks referred as D-Sign. D-Sign is capable of successfully detecting and generating attack signatures with high accuracy, sensitivity and specificity. It has been for attack detection and signature generation of web-based attacks. D-Sign has reported significantly low False Positives and False Negatives. The experimental results demonstrated that the proposed system identifies the attacks proactively than other state-of-the-art approaches and generates signatures effectively thereby causing minimum damage due to network attacks.",60001166,Thapar Institute of Engineering &amp; Technology,Patiala,India,"['1712', '1702']",19.222222222222218,0.05999999999999998,0.5525,1,0.08823529411764706,0.06372549019607843,0.3763440860215054
669,688,688,Is digital GOOD for providing water security?- A case study of India,"We live in an urbanizing world. Large cities with population greater than 750,000 would represent US$21.8 trillion in economic activity or 47.7% global GDP. These cities are already home to 1.7 billion people, about 24% of the world’s population. By the year 2050, it is expected that ninety percent of the world’s urban population growth will occur in Asia and Africa. Economic growth goes hand-in-hand with the urban growth. With the population increase in cities, there is a need for ample and consistent supply of water. The supply of water is a fundamental component of the environmental, economic and social health of cities. There is a huge investment of US$90 billion a year in water supply infrastructure to ensure delivery of clean water to the citizens. If the current trend continues, the volume of urban water need will have to go up by 80% by the year 2030. In this context, The World Economic Forum classified water security as one of the greatest threats to global prosperity in the year 2014. Hence, it becomes essential to manage the water resources in an efficient manner to cater to a large population. The world around us is transformed by various technologies and adopted by humans. Improvement in the performance and cost of computing power, storage and bandwidth are the causes of these technologies. Fourth Industrial Revolution technologies like Virtual & Augmented Reality, Big Data Analytics, Radio Frequency Identification (RFID) and Block Chain have created disruption in various industries through the way businesses are run. India as a country has an advantage of monetising digital technologies for solutions related to social issues due to STEM qualified expertise and experience. AI4SG has got the potential to provide the most sought after Water Security for a country like India. The current study attempts to identify whether there is a dearth in the supply of water due to lack of rain or excess exploitation; or is it that the resources are available but the management of water resources is not efficient. State-wise analysis across India is conducted to identify the gap. The measure used for this study is the Composite Water Quality Index devised by Niti Aayog. The study has found that the gap between supply and demand of this significant resource can be bridged with the proven technology of Block Chain. Issue of Water loss, Water trading and Water quality could be resolved using Block Chain technology. The most common areas of improvement in Water management across various States of India are Water supply, Ground water restoration/rejuvenation, Participatory Irrigation, On-farm use, and Waste water treatment. Block Chain as a technology solution is proposed to bring in possible resolution to these issues to improve upon the water management process.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],19.695652173913047,0.12183170995670994,0.3666369047619048,1,0.08023483365949119,0.09001956947162426,0.3227722772277228
670,689,689,Design of bio-network on chip (Bio-NoC) to detect and destroy trojan and fault,"The communication inside an Integrated Chip (IC) is nowadays done by the technology called Network on Chip (NoC).NoC uses packet transfer methodology instead of signal. NoCs improves the scalability and power efficiency of multicore ICs. Similarly, the chances of failures or faults in on-chip components are also high. Apart from the physical and logical fault occurs in NoC, nowadays Malicious Trojan’s (MalT) threats the NoC security. Malicious Trojan’s are the hardware virus which causes more trouble in multicore ICs. Bio-inspired NoC is another method to detect and destroy the Trojans and it also provides fault tolerance in multicore ICs. In this work, we have determined the latency of NoC architecture without Trojans or fault. We have applied synthetic Trojans and faults to the NoC architecture and detected it during the simulation. The latency for this case is also noted. This novel Bio-NoC structure eliminates the applied Trojans, as well as faults and the latency for this process, is determined. It is showed that this novel Bio-NoC provides better results compared to the affected NoC. The outputs are compared with already existing technologies such as synaptogenesis and sprouting based NoC technologies.",60114675,Swarnandhra College of Engineering and Technology,Narsapur,India,['1700'],15.833333333333336,0.11222222222222222,0.336984126984127,1,0.11764705882352941,0.09954751131221719,0.3853211009174312
671,690,690,Yoga: An universal integrator and a potential tool for preventive health- An overview,"Introduction Yoga is gaining popularity as an indigenous system of medicine across the globe. Yoga as biophysical discipline can work in concurrence with any system of medicine to augment its efficacy in a positive way. Many studies have been published in the past 2 decades to identify the potential of yoga therapy in preventing and mitigating various systemic disorders. This review is aimed at identifying the mechanisms behind yoga in offering physiological homeostasis and thereby exploring its integrative potential with other systems of medicine. Further published literature will be explored to identify, if yoga can offer preventive health. Methods All published literature in English from the database like pubmed was identified using the key word “Yoga” is included in this review. Only original articles with full text and sample size not less than 50 are included in this study. Results We got total of 2698 papers from our literature search of which we included 22 papers with full text availability and other inclusion criteria. The review provides insights on possible mechanisms of yoga in influencing physiological parameters and thereby inducing physiological homoeostasis. Further, it can be strongly recommended as a preventive medicine tool based on the available literature, as it improves the quality of life and functional capacity. Discussion Yoga, a comprehensive system of practices for health and well-being is a common integrative tool recommended from deadly cancers to common immune disorders owing to its physiological effects. It can be effectively integrated with other systems of medicine as it complements the interventions.",124041684,Kalari Rasayana Ayurveda Hospital,Kollam,India,['1700'],21.0,0.05533108866442199,0.5785353535353536,1,0.13602941176470587,0.022058823529411766,0.2814814814814815
672,691,691,Implementation of area and delay efficient QCA circuits using 5MAJ,"The modern VLSI design aim at optimization of any of three parameters namely power, area and delay. To achieve this optimization many of the researchers employed CMOS technology. As the technology diverging day by day further optimization of various VLSI parameters is essential to make device smart and power comparative. As a part of optimization of area and power if we try to extend CMOS technology to nanometer range the length and width of the channel becomes too small and hence transistor loses its functionality. As alternative CMOS in nanometer scale a new technology QCA has been developed. QCA is one of the promising technologies that have been employed in modern VLSI design for optimization of power and area. This paper proposes design of multi input multi output 5 majority gate and further the same is employed in design of digital circuits namely Full Adder, RAM memory cell and reversible BCD. This paper aims at reducing area overhead and the obtained results covey fact that there is almost 50% to 60% reduction in area as compared to normal gate level design. Here all the three modules are implemented using free clock scheme and USE clock scheme and conclusions are drawn with respect to area and delay for the designed clock schemes.",60115658,Malla Reddy College of Engineering &amp; Technology,Hyderabad,India,['1700'],23.444444444444446,0.10559163059163057,0.4123556998556999,1,0.11160714285714286,0.03571428571428571,0.24553571428571427
673,692,692,Green logistics-a tool of optimizing benefits to the environment,"Today’s leading companies, large and small, are looking for ways to go green. They understand that if we want our planet to remain habitable for generations to come, we must work together, now to identify and reduce pollution, make our businesses more sustainable and ultimately move towards a Green environment. Logistics plays a central role in the global economy and therefore the industry can play a crucial part in the way business is done with regard to the environmental impact. Green logistics-It is not the new term, its origin was the mid 1980s. The term Green logistics is the process of minimizing damage to the environment due to the logistics operations of an organization, because logistics deals with packaging of materials. Packaging represents one of the greatest challenges to environmental friendly logistics while at the same time being vital in shipping and storage so the green logistics describes all attempts to measure and minimize the ecological impact of logistics activities, this includes all activities of the forward and reverse flows of products, information and services between the point of origin and the point of consumption. In this paper the writer tries to explain how far Green Logistics helps in optimizing the benefits for the environment.",60102677,Dr. M.G.R Educational and Research Institute,Chennai,India,['1700'],29.285714285714285,0.05002823263692829,0.4449181253529079,1,0.11607142857142858,0.017857142857142856,0.23766816143497757
674,693,693,Detection and diagnosis of breast cancer using machine learning algorithm,"As indicated by Breast Cancer Institute (BCI), Breast Cancer is one of the most risky kind deadly disease that is extremely found in Females. According to clinical master identifying this disease in its first stage helps in living longer life. For identifying breast cancer mostly machine learning methods are used. In this paper we proposed Artificial neural network(ANN) approach for diagnosed breast cancer using Wisconsin Breast Cancer database. The main focus of this work is to look at and clarify how ANN gives effective and better solution arrangement when its work with group AI calculations for diagnosing bosom malignant growth even the factors are decreased. In this paper we utilized the Wisconsin Diagnosis Breast Cancer dataset. When contrasted with related work from the writing. It is indicated that the ANN approach with calculated calculation is accomplished 99.00% precision from another AI calculation.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],17.75,0.15320512820512822,0.6051282051282051,1,0.12258064516129032,0.11612903225806452,0.36942675159235666
675,694,694,Person identification using parabolic model-based algorithm in color retinal images," J. Elec. & Elecn. Eng. & Telcomm.Retina based person identification is perceived as the most secure and accurate authentication means among biometric systems. The superiority of this method stems from the fact that the retina is unique to every individual and it would remain the same throughout a person's life. In this paper, a novel method for person identification is presented using color retinal images. It consists of a parabolic model fitting, feature extraction and finally the matching process. A model based on parabolic fit is developed and used on the main arcade of retinal vasculature. The openness angle of the fitted parabola is calculated and named as Major Arcade angle (MAA). The parameters of the parabola and MAA are considered as features and then these undergo matching criteria for authentication. Performance of the proposed method is tested on three standard databases: DRIVE, HRF, Messidor, one local hospital database, and two authentication databases: RIDB, VARIA, and some pathological images.",60109057,KLE Technological University,Hubli,India,['1705'],13.333333333333336,0.20744047619047615,0.44940476190476186,0,0.0967741935483871,0.0967741935483871,0.3224043715846995
676,695,695,Women in the conflict zone in Nigeria: A study of Chibok girls and A gift from darkness,"Women of all ages have always endured gender inequalities of one type or another and have been exposed to various forms of discrimination worldwide. Even after years of fighting against the injustice and repression of women, they are still the sufferers who suffer in society due to a lack of respect for their well-being. Armed conflict heavily depends on women's sexual harassment. Sexual violence becomes a kind of device for torturing innocent people during the time of conflict. Women in war are forced to live a disgraceful life by doing domestic and sexual slave labour. Girls who have been abducted during the time of the fighting are also forced to become wives of the combatants for their reward. This article is a study of the two narratives viz. The Chibok Girls and A Gift From Darkness that bring forth the harrowing experiences of women who became easy victims for the terrorist groups like Boko Haram. Both the narratives based on real incidents, present the condition of women in conflict zone where they are used as pawns in the objectives and missions of the warring groups.",60018003,Assam University,Silchar,India,['1700'],20.555555555555557,0.16297979797979795,0.5072222222222221,1,0.09045226130653267,0.02512562814070352,0.28426395939086296
677,696,696,Increasing flux density analysis in sensor-less brushless dc motor for artificial heart pumping system,"Now-a-days the electromechanical energy conversion is playing a vital role to convert mechanical energy into useful work. The development of life saving medical equipment’s with special electrical machines is tremendously increasing such as heart pumping pace maker, inter organ blood replacement devices, dialysis machines etc., Out of which the heart disease is the major problem faced by all the humans. For severe heart issues the best solution is to replace pace maker device for heart pumping system. In this case pace maker is an electro mechanical device that is driven by Sensorless Brushless DC Motor along with the power supply unit. The performance of motor can be improved by controlling the parameters such as flux density, torque, speed and any of the mechanical parameters like air gap length and number of phase windings. In proposed work the flux density of the machine can be increased by increasing the air gap between the stator and rotor. By increasing the air gap the flux density generation at rotor because of excitation can be increased ultimately the efficiency of the motor also increased. The efficiency of the motor is well defined by controlling the back EMF at different phases of BLDC motor. At full load operation the torque can be increased by means of load increasing at motor shaft. But in the proposed technology by increasing the air gap between the stator and rotor the speed of the machine can be maintain at rated speed without losing their efficiency. The entire system performance is analysed by developing a model of Sensor less Brushless DC Motor in MATLAB Simulink environment. The efficiency of BLDC motor can be investigated by various torque and speed operation.",60114652,"Nehru Arts and Science College, Coimbatore",Coimbatore,India,['1700'],23.33333333333333,0.14601934523809526,0.4445684523809523,1,0.11551155115511551,0.052805280528052806,0.21070234113712374
678,697,697,Some common fixed point theorem using occasionally weakly compatible and reciprocal continuity in intuitionisticfuzzy metric spaces,We are proving some common fixed point theorem using two notations occasionally weakly compatible and reciprocal continuity in intuitionistic fuzzy metric spaces.,60072227,Bannari Amman Institute of Technology,Sathyamangalam,India,['1700'],22.0,-0.19166666666666665,0.44166666666666665,1,0.13043478260869565,0.0,0.21739130434782608
679,698,698,Volatility transmission between indian commodity market and United States commodity market-evidence from literature,"Purpose – The globalization of commodity has prompted the developing pertinence of rising commodity markets. India is one of the nations with a growing commodity market that is progressively pulling funds from the other nations which increment integration. This study is done with the purpose to survey the existing literature on volatility between Indian and US commodity market. Design/methodology/approach – The paper mainly reviews the international literature related with volatility between Indian and US commodity market. Findings-The direction of volatility varies from country to country, depending on various country-specific features, data’s and the methodology used by the researcher. It is also found that India’s future commodities market work like satellite market as well as acclimatize data via global market.",60094571,Lovely Professional University,Phagwara,India,['1700'],19.83333333333333,0.005952380952380951,0.24761904761904766,1,0.10948905109489052,0.029197080291970802,0.25190839694656486
680,699,699,Comparative analysis of air pollution measurements between compact mobile sensors and standardized laboratory methods," J. Elec. & Elecn. Eng. & Telcomm.The article is devoted to the comparison of laboratory methods for measuring the concentration of gases in the air and methods using compact sensors mounted on an Unmanned Aerial Vehicle (UAV). Among the gases studied are carbon dioxide and carbon monoxide, sulfur dioxide, and nitrogen oxide. The description of the tested sensors (Gas analyser GANK-4, aspirator PU-4E, spectrophotometer PE-5400VI, Libelium Waspmote Gas Sensors PRO), measurement methods and equipment for the flight mission are presented. Special attention is paid to the influence of meteorological parameters on the measured concentration. Finally, measurement results are compared with the recommended indices of the content of the investigated gases.",60072485,"Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO",Saint Petersburg (ex Leningrad),Russian Federation,['1705'],12.333333333333336,0.17857142857142858,0.7857142857142857,0,0.07575757575757576,0.12121212121212122,0.4573643410852713
681,700,700,A novel differential modulation scheme using full-rate STBC for 4×4 MIMO OFDM," J. Elec. & Elecn. Eng. & J. Telcomm.Non-coherent communication which employs Differential Modulation (DM) technique is an interesting technique to combat the uncertainty of channel in the wireless communication system. This technique also provides a more spectral efficient system than coherent communication because it does not need the presence of signal overhead for channel estimation purpose which usually exists in the coherent transmission. To improve the performance of DM technique, differential unitary modulation technique which is combining DM and Space Time Block Code (STBC) is explored in this paper. In this paper, we modify a quasi-orthogonal STBC (QO-STBC) to be used as a unitary matrix generator, and then we introduce an element-wise calculation concept to minimize the system complexity. The experimental results show the proposed differential unitary modulation technique could be an excellent technique to overcome the uncertainty of channel in a wireless telecommunication system.",60021120,Kumamoto University,Kumamoto,Japan,['1705'],14.6,0.4071428571428571,0.5785714285714285,0,0.09826589595375723,0.12138728323699421,0.29012345679012347
682,701,701,Innovation in consumer confinement in green product for pertaining to customer value,"In a today’s technology development and the population growth the environmental issues are raising in India. This environmental problem is sizzling the organization has used the green marketing products for the concern about the human care. Green product development is the innovative technique to attract more customers and make the environment eco-friendly. The green product is used for customer confinement by various benefits to the organization in terms of increasing the organization profit, innovative technique for retaining the existing customer. The researcher focuses on the green product the innovative technique used for the customer confinement, automatically the profit of the organization and no need to spend much time to capture a new customer. The researcher use convenience sampling technique and the sample size is 45 the respondents are the customer, the primary data is collected through online survey by the questionnaire. The research will enhance the organization to confine the customer and increase the profit of the organization.",60102677,Dr. M.G.R Educational and Research Institute,Chennai,India,['1700'],22.57142857142857,0.14895104895104894,0.4965034965034965,1,0.1111111111111111,0.011695906432748537,0.15294117647058825
683,702,702,Machine vision based detection of foreign material in wheat Kernels using shape and size descriptors,"Emergence of Internet of Things (IoT) in recent years has facilitated on-line trading of agricultural produce in real-time environment. However, in order to have an effective online marketing, automated qualityinspection systemsare required invariably for estimating the market value of these products. Thus, increasing use of on-line marketing in recent years has necessitated the urgent need to develop such systems. Machine vision provides a suitable technology for the development of these quality inspection systems. The work reported in the present paper is a part of an integrated machine vision system developed for automated quality inspection of wheat and other cereal grains. Proposed machine vision module has been developed specifically for detection of foreign material in wheat kernels using neural classifier. The proposed neural classifier has been executed using shape and size based regional descriptors of wheat kernels using digital image processing. Maximum average accuracy of more than 98.5% has been achieved in the present work. Results of present investigations are quite promising. The proposed machine vision module has potential future for IoT (Internet of Things) enabled on-line marketing of agriculture produce in real time environment.",60020898,Sant Longowal Institute of Engineering and Technology,Longowal,India,['1700'],18.4,0.0973684210526316,0.3407894736842105,1,0.10476190476190476,0.009523809523809525,0.36633663366336633
684,703,703,"Profiling environmental awareness of local community on solid waste management in Nasiriyah, Iraq","The deterioration of the ecosystem as well as that of human health is caused by solid waste mismanagement and lack of awareness on the management of solid waste. In this study, public knowledge on solid waste management within the city of Nasiriyah in Iraq was investigated. In order to successfully manage solid waste in the city of Nasiriyah of Iraq, it is important to gain the support of the local community. This study was conducted to determine the level of awareness and knowledge of the local community in terms of the management of solid waste in the city of Nasiriyah, Iraq. A total of 2000 respondents were randomly selected from 12 suburbs in Nasiriyah, Iraq. A descriptive cross-sectional analysis among local communities was performed and analyzed using SPSS software. Results from the survey showed that 67% of respondents were dissatisfied with the current practice of solid waste management in Nasiriyah, Iraq. The results also showed that low-level of knowledge on law and regulation pertaining to solid waste was observed among respondents. Although half of the respondents were aware of the importance of managing solid waste, most of them failed to put their knowledge and awareness into practice. Therefore, extensive and continuous efforts by various stakeholders are urgently needed to enhance public awareness towards sustainable solid waste management in Iraq, particularly in Nasiriyah city.",60001821,Universiti Kebangsaan Malaysia,Bangi,Malaysia,['1700'],22.3,-0.025,0.19768518518518516,1,0.08130081300813008,0.052845528455284556,0.24793388429752067
685,704,704,Analysis of subthreshold swing in symmetric junctionless double gate MOSFET using high-k gate oxides," J. Elec. & Elecn. Eng. & Telcomm.We observed the change of the subthreshold swings when the high-k material was used for the gate oxide of the junctionless double gate MOSFET (JLDG MOSFET). For this purpose, the analytical subthreshold swing model is proposed using the potential model derived from Poisson's equation. The subthreshold swing derived from the model proposed in this paper is in good agreement with the subthreshold swing value from the two-dimensional numerical simulation within the error of 5%. Using this model, we observed the change of subthreshold swing with respect to the channel length, silicon thickness and gate oxide thickness with a dielectric constant as a parameter. As a result, the subthreshold swing was greatly reduced and the changing rate of the subthreshold swing by the channel length, silicon thickness, and oxide thickness was 1 mV/dec-nm or less when the material with a dielectric constant of 30 or more was used as the gate oxide. Especially, it was found that the dielectric constant of the gate oxide for the JLDG MOSFET should be more than 30 in order to have a subthreshold swing of less than 65 mV/dec.",60012684,Kunsan National University,Gunsan,South Korea,['1705'],19.1,0.15897435897435902,0.42948717948717946,0,0.06726457399103139,0.08071748878923767,0.2857142857142857
686,705,705,The effectiveness of postural correction in improving para spinal muscles spasm in dodge ball players,"Background: Para spinal muscle spasm is one of the most common issues can be seen in dodge ball players but is mostly ignored by the players until it brings discomfort to the players. The postural correction appears to be effective in preventing this discomfort to occur. Objective: To determine the effectiveness of postural correction in improving the Para spinal muscle spasm in dodge ball players based on a visual analogue scale. Methodology: A quantitative research model in the form of Quasi-experimental type of study design was carried out in this study. A convenient sampling of 30 participants among players was collected from dodge ball clubs around Kedah and Penang, Malaysia. Data was collected by structural and semi-structural, mixed type questionnaire. Data analysis was performed by Wilcoxon Signed Ranks and Mann-Whitney Test. Descriptive statistic was used for data analysis. Tabulation and computation of frequencies and percentages were calculated on selected variables. SPSS version 2.0 statistical software has been used for the analysis of data. Results: According to the data analysis, it was shown that postural correction is effective in improving the Para spinal muscle spasm significantly. However, based on the subjects’ feedback, it seemed to provide only a short-term effect rather than a long-lasting effect. The participants claimed that there was a reduction in pain over the back region after single treatment but the pain gradually return as they carry out their daily activities. Conclusion: Postural correction is effective in improving Para spinal muscle spasm in dodge ball players according to tenderness grading and visual analogue scale (VAS). It improves the quality of life of dodge ball players even with the short term relieving effect.",60078092,"Asian Institute of Medicine, Science &amp; Technology",Bedong,Malaysia,['1700'],18.266666666666666,0.17522321428571427,0.4149553571428571,1,0.10256410256410256,0.07051282051282051,0.2913907284768212
687,706,706,Secured protocol for communication between fog and cloud,"Murkiness preparing held stated as a considerably virtualized angle that may have interaction enlisting at the net of factors gadgets, proceeding inside the fringe of the advent, to hold companies and applications the majority of the greater distinguished beneficially and sufficiently. because of fact that fog enlisting starts offevolved from and is a non-minor improvement of allotted processing, it procures diverse guarantee and coverage issues of allotted figuring, inflicting the vital challenges inside the research prepare. To engage bonafide and secret exchanges amongst a get together of fog center points, on this paper, we activate a productive key exchange display relying on ciphertext association feature basically based totally encryption (cp-abe) definitely to expand relaxed correspondences the diverse people. To reap class, approval, fluctuation, and get segment to govern, we be part of cp-abe and programmed signature structures. We inspect the viability of our amassing as a few separation as assurance and with the aid of and big execution. we besides whole our social affair and appraisal it and the aid based association to depict its reachability.",60116002,Anurag Group of Institutions,Hyderabad,India,['1700'],29.33333333333333,0.017948717948717944,0.38974358974358975,1,0.135,0.05,0.28350515463917525
688,707,707,Analytical study on design and development of herichal clustering using adhs algorithm,"Wireless sensor networks (WSN) are one of the significant technologies because of their diverse applications, for example, health care monitoring, cell phones, military, catastrophe the board, and other observation frameworks. Sensor nodes are normally deployed in an enormous number that works freely in unattended cruel conditions. In this paper, we present a complete and fine-grained study on clustering routing conventions proposed in the writing for WSNs. We plot the focal points and goals of clustering for WSNs and build up a novel taxonomy of WSN clustering routing strategies dependent on complete and detailed clustering properties. We at that point stretch out this calculation to create a hierarchy of cluster heads and observe that the energy reserve funds increment with the number of levels in the hierarchy. Results in stochastic geometry are utilized to derive answers for the estimations of parameters of our calculation that minimize the all-out energy spent in the network when all sensors report data through the cluster heads to the processing focus.",101741144,Sri Satya Sai University,Puttaparthi,India,['1700'],27.5,0.016666666666666673,0.5291666666666667,1,0.10326086956521739,0.005434782608695652,0.2833333333333333
689,708,708,Organizational barriers and work life conflict as potent sources of the glass ceiling syndrome,"In today""s scenario Work life Conflict and glass ceiling is a major concern for the women who have opted to come out of their domestic chores and have chosen to work outside. Competition and challenges in the organization demand the time of women which they actually wanted to devote to their families. This imbalance can also create Glass ceiling preventing women from climbing hierarchical ladder. Review of literature on work life balance and glass ceiling of women employees has been carried out keeping in mind the objectives of the study. The researcher has reviewed the previous literature on various aspects related to work life balance (WLB). Review on Glass Ceiling is also focused in this paper. The main purpose of this paper is to find out the gap and the need to conduct this research.",124042247,Aachi Educational and Research Foundation,Chennai,India,['1700'],19.285714285714285,0.0078125,0.26875,1,0.13194444444444445,0.027777777777777776,0.2602739726027397
690,709,709,Multiplexer based high speed double precision floating point multiplication,"In this paper, double precision floating point multiplication is designed and analyzed using two algorithms such as karatsuba algorithm and vedic algorithm. Different modified 2x1 multiplexer techniques are incorporated in both Karatsuba and vedic algorithms to improve the speed. Further, the comparative analysis is made for both algorithms in terms of speed and area. From the results, it is inferred that double precision floating point multiplication with karatsuba algorithm using modified 2x1 multiplexer model V offers improved performance with high speed along with improvised in area utilization. than that of existing techniques. All the blocks involved for floating point multiplication are coded with Verilog and synthesized using Xilinx Vivado Tool.",60013919,Pondicherry University,Puducherry,India,['1700'],18.33333333333333,0.03714285714285714,0.3057142857142857,1,0.17647058823529413,0.08403361344537816,0.40336134453781514
691,710,710,Role of spirituality in the vuca world and its impact on corporate governance,"Today’s business environment is highly dynamic. With so much volatility and uncertainty there is bound to be stress, cut throat competition and worry. People working in such an environment are focusing on making material gains. Making profits by hook or crook has become the latest mantra. Business ethics and morality have taken a backseat. This race for becoming number one has negatively impacted the health of the employees. There has been a rise in the cases of heart attacks, blood pressure, depression etc. To counter this problem many companies have taken to the path of spirituality. India is a hub of spiritual leaders and there are organizations like Isha foundation. Brahmakumaris, Art of Living, Vipassana etc. who have been approached by the corporates to conduct spiritual classes for their employees. This has not only positively impacted the employees but also affected their corporate governance. This paper is an endeavor to study the linkages between the corporates and the spiritual organizations and their impact on corporate governance.",60029284,University of Delhi,New Delhi,India,['1700'],12.769230769230768,0.11266233766233764,0.3901515151515152,1,0.0918918918918919,0.032432432432432434,0.2956989247311828
692,711,711,An analysis of a block matching method on different bands of monochrome images,"In the imaging areas of medical and microwave regions, a speckle noise is generally added in acquisition process of images. This type of unnecessary signals or noises is available in all coherent imaging systems. De-speckling methods are used to de-speckle the available speckle noise from these speckled systems. In optical image formation, other noises are added like gaussian, salt and pepper, etc. An un-decimated block matching 3D (UD-BM3D) method is a state of art technique in de-speckling area to remove the noise at the fullest extent. In this paper, an analysis has been done on optical or satellite images with un-decimated BM3D method. As it is known that an optical is of different bands, it is experimented on main colour bands (Red, Blue & Green). Different quality parameters for different bands are evaluated and compared for different speckle noise variances by considering the Sentinel satellite image sub bands as single band image.",60114613,Sreenivasa Institute of Technology and Management Studies,Chittoor,India,['1700'],19.0,0.045014880952380966,0.4139136904761904,1,0.09289617486338798,0.0546448087431694,0.3567251461988304
693,712,712,Fabrication of carbon fiber reinforced polymer (CFRP) & comparing experimental result (tensile & bending) of CFRP (unidirectional & bidirectional) with aluminum (Al7075),"An application field for carbon fibers gaining more and more in importance is composite technology. The combination of reinforcing fibers and a polymer matrix leads to CFRP (carbon fiber reinforced polymer) which is having high performance material allowing weight reduction of more than 20% compared to aluminum and more than 50% compared to steel, and also much stronger and stiffer compared to glass fibers. With the advancement and continuing integration of composite materials and technology in today’s modern industries, research in this field is becoming more and more significant. Predicting these composite materials properties and how they will react under trauma over the time is one of the most critical aspects that researchers are striving to understand and expand knowledge in. This project deals with tensile strength, bending stress and characteristics of carbon fiber reinforced polymer (unidirectional and bidirectional) and comparing experimental result with aluminum alloy (AL7075).",108383651,ACE Engineering College,Hyderabad,India,['1700'],29.4,0.3560714285714286,0.5332142857142858,1,0.12804878048780488,0.012195121951219513,0.296969696969697
694,714,714,Can social media facilitate a European public sphere? Transnational communication and the Europeanization of Twitter during the Eurozone crisis,"Asking whether social media can plausibly facilitate a European public sphere, this article provides the first operationalization and empirical examination of Europeanization of social media communications. It maps the geospatial structure of Twitter activity around Greece’s 2015 bailout negotiations. We find that Twitter activity showed clear signs of Europeanization. Twitter users across Europe tweeted about the bailout negotiations and coalesced around shared grievances. Furthermore, Twitter activity was remarkably transnational in orientation, as users interacted more often with users in other European Union (EU) countries than with domestic ones. As such, social media allowed users to communicate with one another unencumbered by national boundaries, to bring into existence an ad hoc, issue-based European public sphere.",60003059,London School of Economics and Political Science,London,United Kingdom,['1706'],19.0,0.12794117647058822,0.22794117647058826,1,0.11450381679389313,0.07633587786259542,0.4153846153846154
695,715,715,A study on digital India-impacts,"Digital India is the dream project for the government which came into existence as a result of numerous advancements and innovative headways. This scheme helps in moving with the universal trends of digital innovation. This is to make sure that service of our Government are made available for all Indian citizens electronically by improving online infrastructure and by increasing the effectiveness of Internet connectivity with one mission that is to take Nation forward in both digitally and economically. In this paper we made a survey that whether it creates positive impact in the lives of people-rural and urban, young and old and how far it reached the illiterate people and the finally changes after the Digital India scheme has been implemented. This sampling is administered to nearly of 200 young people through a well-structured questionnaire to collect data. We used a recent statistical tools to analyse the data.",60114457,Sri Krishna Arts and Science College,Coimbatore,India,['1700'],24.66666666666667,0.12775119617224884,0.4149654439128124,1,0.10062893081761007,0.03773584905660377,0.22580645161290322
696,716,716,Shell and body of cat character robot for early intervention to treat children with autism spectrum disorders,"Despite consistent increase in the number of children with Autism Spectrum disorders(ASD), supply of professional facility or experts to treat the children with such condition are in great shortage. The goal is to develop functional material that can be used as shell for the robot not only to protect the robot user from harmful environment such as dust-mite, germs and etc., but also to support the emotional treatment of the robot user with its aromaticity and body action using gesture. Using the faux fur developed as part of this study, the shell of cat character robot was completed based on the drawn pattern. In the process of treating children with ASD, the keys are to promote interaction, to encourage children to exercise appropriate social skills and to enhance ability to adapt. This study aims to develop a robot that is tailored to children with ASD who experience difficulties in interaction and in forming emotional bonding with others, so that the robot can be effectively leveraged together with various treatment approaches currently employed. As part of such effort, Jasmin tea extract dyed faux fur which illustrates outstanding house dust mite repelling, anti-microbial, and aromatic functionality was developed and used as shell of the robot, so that not only emotional treatment but also the hygiene of the children can be considered at the same time. Furthermore, considering that children with ASD shows tendency of bringing toys to their mouths and that the toys needs to be washed frequently, the shell of the robot should be easily removed and applied, which will contribute to higher usability satisfaction level of the caregivers. In this paper, the field experiment was carried out to show the efficiency of the design and found the validness of this concept. This robot developed with the goal of early intervention for children with ASD is expected to reap synergy together with other treatment approaches.",60031231,Semyung University,Jecheon,South Korea,['1700'],34.888888888888886,0.13720238095238094,0.4830357142857144,1,0.13953488372093023,0.0377906976744186,0.2375366568914956
697,717,717,An explanation-based approach for experiment reproducibility in recommender systems,", part of Springer Nature.The offline evaluation of recommender systems is typically based on accuracy metrics such as the Mean Absolute Error and the Root Mean Squared Error for error rating prediction and Precision and Recall for measuring the quality of the top-N recommendations. However, it is difficult to reproduce the results since there are various libraries that can be used for running experiments and also within the same library there are many different settings that if not taken into consideration when replicating the results might vary. In this paper, we show that within the use of the same library an explanation-based approach can be used to assist in the reproducibility of experiments. Our proposed approach has been experimentally evaluated using a wide range of recommendation algorithms ranging from collaborative filtering to complicated fuzzy recommendation approaches that can solve the filter bubble problem, a real dataset, and the results show that it is both practical and effective.",60030988,Democritus University of Thrace,Komotini,Greece,"['1712', '1702']",39.25,-0.01822916666666666,0.5640625000000001,1,0.1286549707602339,0.06432748538011696,0.2545454545454545
698,718,718,Constructing a conceptual framework on sound scape approach for city user,"Integration of multiple factors that infers information to the senses influences the livability of the urban street environment. Globally, there are numerous researches of soundscape to strengthen the idea of sustaining the acoustic environment. The objective of this paper is to construct a conceptual framework on urban soundscape and analysed the application in urban design knowledge for city user. The importance of incorporating soundscape approach is also emphasised reflected in the proposed conceptual framework for urban soundscape. It is stipulated that discussion on the urban soundscape related issues in the context of Kuala Lumpur, Malaysia has been scant due to the lack of awareness regarding the important of soundscape approach in the early stage of the urban design process. Hence, understanding of soundscape is crucial to provide a basis for research framework in the area that suits the multi-cultural urban settings and the approach in analysing soundscape of urban places for a more comprehensive urban design analysis and process.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],26.5,0.046052631578947366,0.21973684210526315,1,0.09411764705882353,0.01764705882352941,0.24404761904761904
699,719,719,Design of a Virtual Reality Tour System for People with Intellectual and Developmental Disabilities: A Case Study,"IEEEThis study focuses on VR as a form of therapy for individuals with intellectual anddevelopmental disabilities(IDD). The research aim is to develop an immersive and interactive VRsystem that is tailored for IDD individuals, for which most currently available VR experiencesystems are not optimized. Being intimately familiar with a place through an interactive VR tourwill help alleviate social anxiety - very provident to IDD individuals. Accordingly, we create ahotspot-based VR tour system which can provide an almost life-like experience of visiting andlearning about the location. We have conducted experiments with non-disabled individuals,acting as the control group, and IDD individuals, acting as the experimental group, to evaluatethe tour system and compare the results between two groups. Our experiments show that the VRtour has a positive impact on the IDD individuals. In this paper, we present the design of our VRTour system and its evaluation results.",60029653,Kent State University,Kent,United States,['1700'],20.428571428571427,0.21356060606060606,0.3112121212121212,1,0.10303030303030303,0.03636363636363636,0.37267080745341613
700,720,720,Interpretation of glacial lakes and water bodies in the Himalayan region to control natural hazards using geospatial technology,"The receding of mountain glaciers worldwide is impacting the global climate changes. The melting of Himalayan glaciers is one of reason to increases related natural disasters like Glacial Lake Outburst Floods in this region. Due to glaciers retreat action form ice ‘dams’. Naturally these structures are weak & sometimes suddenly break and with in short period its lead to millions of cubic meters of water release and its causes catastrophic flooding and serious damage of life and property in the downstream area. In order to assess the risk of glacier and glacier lakes there study should done critically. As a first step preparation of database of glacier lakes and water bodies is significant. In this context, satellite remote sensing technology helps in preparing the inventory of glacier and glacier lakes are mapped using geospatial data in the Himalayan region. This project aims to identify and prepare an inventory of glacial lakes and water bodies in the Chenab, Ravi and Beas sub-basins in the Indus basin, in the study area. The Satellite images of Resources at 2 LISS 4 are used in this study. Using this data, glacial lakes and water bodies were analysed based on their location, water shed area, elevation and aspect wise. Based on this analysis we observed that in Chenab sub-basin there are 135, 33 water bodies and glacier lakes respectively, for Ravi sub-basin it has 53,18 water bodies and glacier lakes respectively and for Beas it has 131, 33 water bodies and glacier lakes respectively. Generally above 4500m most of the water bodies and Water bodies are observed. In aspect wise identified that the most of the glacier lakes and the water bodies are formed in the South-West direction.",60104649,Vignans Foundation for Science Technology and Research University,Guntur,India,['1700'],21.76923076923077,0.11958333333333332,0.41375,1,0.07911392405063292,0.060126582278481014,0.33876221498371334
701,721,721,Characterizing the relationship between sampling rate and the appearance of FIR precursors infornt of local earthquakes,"Precursory signalsadd an error in the exact time of the earthquake P-wave onset which leads to inaccurate determination of the event parameters; such as the hypocenter and magnitude of the event. These precursors had a fluctuation in the appearance before the P-wave.Thus,changingthe sampling rate will be studied to display whether it has aninfluence on the precursory signal occurrence or not. An experimental field testhas been establishedat New Abu-Dabbab station (NADB)using a portable station beside the fixed one. A portable station digitizer withtwo sampling rates (50, and 200 samples/s)beside the fixed station, which has a sampling rate of 100 samples/s.Successful 381 events have been recorded along 17 months. The three different sampling rates for one event response has been observed. These events are significantly displaying the interdependence between the sampling rate and the precursory segment occurrence. The results prove that the appearing of precursory signals increase whenthe sample rate decreases.",60030681,"National Research Institute of Astronomy and Geophysics, Cairo",Cairo,Egypt,['1700'],21.285714285714285,0.13267045454545456,0.4349431818181818,1,0.07909604519774012,0.022598870056497175,0.3473053892215569
702,722,722,Additive Number Theory via Automata Theory,"We show how some problems in additive number theory can be attacked in a novel way, using techniques from the theory of finite automata. We start by recalling the relationship between first-order logic and finite automata, and use this relationship to solve several problems involving sums of numbers defined by their base-2 and Fibonacci representations. Next, we turn to harder results. Recently, Cilleruelo, Luca, & Baxter proved, for all bases b ≥ 5, that every natural number is the sum of at most 3 natural numbers whose base-b representation is a palindrome (Cilleruelo et al., Math. Comput. 87, 3023–3055, 2018). However, the cases b = 2, 3, 4 were left unresolved. We prove that every natural number is the sum of at most 4 natural numbers whose base-2 representation is a palindrome. Here the constant 4 is optimal. We obtain similar results for bases 3 and 4, thus completely resolving the problem of palindromes as an additive basis. We consider some other variations on this problem, and prove similar results. We argue that heavily case-based proofs are a good signal that a decision procedure may help to automate the proof.",60014171,University of Waterloo,Waterloo,Canada,['1703'],15.833333333333336,0.09861111111111112,0.3254629629629629,1,0.1013215859030837,0.04405286343612335,0.4090909090909091
703,723,723,A voyage on compound image compression techniques,"The demand for storage capacity and bandwidth of communication channel exceeds the availability, though there is much technological advancement. The role of compound images is inevitable in web based applications. The compound images comprise of text and picture and they have anisotropic features, hence the conventional compression algorithms are not enough to yield good results. This paper presents a literature analysis in various compound image compression techniques.",123247526,Musaliar College of Engineering and Technology,Pathanamthitta,India,['1700'],16.75,0.1261904761904762,0.5261904761904762,1,0.0684931506849315,0.0,0.2328767123287671
704,724,724,Cancer-associated fibroblast (CAF) expression in metastatic and non-metastatic oral squamous cell carcinoma (OSCC)-a determinant in cancer progression,"Background: Tumour stroma plays a vital role in carcinogenesis. Myofibroblastic expression in stromal fibroblast (cancer-associated fibroblast, CAF) is associated with poor clinical outcome was observed in previous studies. Aim: To evaluate and compare the expression of alpha smooth muscle actin (α-SMA) in non-metastatic and metastatic oral squamous cell carcinoma (OSCC). Materials and Methods: A retrospective study was conducted in 100 formalin fixed, paraffin embedded tissue blocks which includes 50 metastatic and 50 non-metastatic OSCC. α-SMA expression was observed on the basis of proportion and intensity in the tumour stroma. Results: α-SMA shows significantly increasing expression from non-metastatic to metastatic OSCC. Statistically significant expression of α-SMA (p<0.001) was observed in metastatic OSCC. Conclusion: Expression of α-SMA in tumour stroma suggests a positive role of myofibroblast in tumour progression and a potential target for the therapeutic purpose.",60112730,Vinayaka Mission's Sankaracharyar Dental College,Salem,India,['1700'],16.875,0.11228956228956227,0.5735690235690236,1,0.09090909090909091,0.11363636363636363,0.43125
705,725,725,Development of technical specifications for the mechanism of the trading system,"The article described the Unified National Marketplace will be the only mechanism for the sale of domestically produced goods throughout the world through online access, and organizing online receipt of multicurrency payments, thus facilitating the costs associated with organizing trade in goods locally and abroad. One of the main points is the organization of receiving multi-currency payment and simplifying the difficulties associated with the export of products manufactured in the Republic of Uzbekistan, will also allow businesses and individuals to provide their goods to personal stores.There are several types of electronic trading platforms-for commercial customers, for placing government orders. The sites on which electronic transactions are performed by commercial customers are divided into specialized and multi-profile. Users, participants of the sites, held auctions and trades themselves can decide on which of the sites it is more convenient and profitable to work with. In addition, on a multiprofile resource the customer can act as a supplier, the seller-this is dependent on the scope of his activities, on the possibilities.",60111827,Tashkent University of Information Technologies named after Muhammad al-Khwarizmi,Tashkent,Uzbekistan,['1700'],33.6,0.08333333333333333,0.26666666666666666,1,0.11979166666666667,0.026041666666666668,0.33516483516483514
706,726,726,An M2M computing model for improving the performance among devices,"At present, it has been developed in automation technology for many years. Especially, the Internet of Things technology is quite mature. However, in the Internet of Things technology, there is a lack of rapid processing of distributed task service architecture. In most IoT models, active ones are mainly implemented through human operations, take the service to a hardware device system. Especially when it is necessary to expand to many device operations, it is necessary to use the Internet of Things for service applications, it will face the problem of not being able to operate at the same time. This research proposes an innovative IoT platform architecture, which improves the problem of only single behavioral event processing for existing connected devices and provides more different context application services.",60090100,Hsuan Chuang University,Hsinchu,Taiwan,['1708'],21.166666666666668,0.1580952380952381,0.5498809523809524,1,0.08450704225352113,0.0,0.33098591549295775
707,727,727,Improvement of flexural behavior of reinforced concrete cantilever hollow beam by using carbo-DUR CFRP,"The present research studied experimental and theoretical investigations that showed the effect of two variables have major influence toward improving the flexural behavior. Such as the effect of hollow length and the strengthenning by using CFRP laminate of reinforced concrete cantilever beams.The experimental work showed two important characteristics, one of them was the small effect of hollow beam sections in decreasing the flexural strength and the other significant thing was the increased flexural strength due to adding the CFRP laminate, which placed at the top concrete beam surface. Experimental results clarified the main role of using CFRP laminate through increasing the yield strength by about three times toward more rigidity and increasing the ultimate strength by about two times of solid beam through decrasing the ductility of the beam from (1.15 to 1.09) with and without CFRP laminate respectively. For beams of hollow length equal to o.5m the major increment for the ultimate load, which reached approximately to two times and the ductility ranges as (13.5 to 13.58). Cantilever beam with a hollow length equal to 1m, CFRP laminate enhanced the flexural strength by increasing the final strength by about 1.63 times despite the small decreasing in the yield strength. So, their ductilities range as (10.4 to 10.6). The last group of cantilever beam with a fully hollow length, the clearance strengthening of the CFRP laminate through increasing the final strength up to 1.83 times the same cantilever beam without CFRP. Also, the ductility back to lowest values as same as the solid beam ductility with a range: 1.04-1.06. Theoretical methods (ANSYS) for satisfying the results of complete study to make verification with results were obtained from both experimental and theoretical testing methods. All the comparisons results referred to the low differences between the experimental and ANSYS results for beams of normal reinforcement and additional strength by CFRP laminate. So, all the differnces were approximately near to 12% or less which are within the permitted from ACI 318M-14 code requirements.",60109593,Al-Mansour University College,Baghdad,Iraq,['1700'],30.0,0.03958333333333334,0.3737847222222221,1,0.07123287671232877,0.04657534246575343,0.27019498607242337
708,728,728,End-to-end communication between IoT devices to maximize energy efficiency through optimization and localization based on the bio inspired algorithms,"Network optimization is often defined as a technique for improving network performance in every environment. Every day, huge amounts of data from different types of devices and applications are fed into the network. In this regard, it is clear that an effective solution for optimizing the IoT network must reduce the traffic generated by the Internet of things, thereby degrading other network services and effectively utilizing network resources. Due to the heterogeneity of applications and device types, IoT devices generate traffic than the cellular network. IoT applications generate less data, but control-level messages generate more traffic when the device is integrated into the application. Therefore, this non-application traffic greatly increases the network load. To overcome this load, therefore, an efficient mechanism is needed for solving and optimizing the message exchange from the control level of the IoT device is required. Network optimization provides several benefits such as faster data transfer rates, data recovery, redundant data deletion, and improve application and network response times. We will confer about the necessity of network optimization and ensure network optimization in the Internet of Things, and then compare algorithms to different network parameters like Throughput, Residual Energy, Normalized Overhead, End to End Delay and Packet Loss Ratio.",108226732,SreeVidyanikethan Engineering College,Tirupati,India,['1700'],22.555555555555557,0.17023809523809524,0.4892857142857143,1,0.10822510822510822,0.05627705627705628,0.34801762114537443
709,729,729,A case study on down syndrome using pedigree analysis,"A Case study on “Down syndrome using Pedigree analysis” discuss about the genetics using Linear Algebra. Down syndrome is a genetic disease that arise when the abnormal cell division will end in extra full or partial copy of chromosome 21. In this paper, we have employed the concepts from Linear Algebra to predict the genotypic distribution of the Down syndrome disease with autosomal inheritance. Autosomal inheritance is a pattern of inheritance in which the transfer of characters depends on the presence of the alleles on the autosomes. We have used the pedigree analysis by which we have calculated the highest power of the matrix of the nth generation by which we can predict the individual’s prone to disease.",60114457,Sri Krishna Arts and Science College,Coimbatore,India,['1700'],23.6,-0.030952380952380967,0.3166666666666667,1,0.10236220472440945,0.06299212598425197,0.21875
710,730,730,Raspberry Pi based automated and efficient irrigation system with add-on field security,"Food being one of the basic need of any living being on earth, maximum percentage of human beings survive on food from plants and trees. Food taken decides the health and life span of a human being. Now-a-days, the food commodities available in market are almost mixed with chemicals and many inorganic medicines are used in agriculture procedures. Inspite of the area left for gardening this project develops an irrigation system that can be implemented by every person in their house like bungalow, farm house, individual homes, apartments etc., Efficient usage of energy and money are the added advantages when the proposed system is installed and programmed properly. Raspberry Pi based Automatic Irrigation system with IoT link up not only favors with the above advantage, it also a means of eco energy which precisely makes use of water and power. Wireless and Automated system in this work is feasible compared to high cost wired system in remote areas. Temperature, Moisture, Humidity, Light are the factors that decide the function of this system with an additional feature of IoT link and security from invaders like farm destroying animals.",60114577,Vignan Institute of Technology and Science,Deshmukhi,India,['1700'],26.714285714285715,0.0975,0.3321875,1,0.10047846889952153,0.06698564593301436,0.29901960784313725
711,731,731,Studying and analysis of the mechanical and vibro-acoustic performance of aluminum disc brake,"The global trend is now towards energy saving. Thus, reducing vehicle weight has attracted the attention of the automotive manufacturers to improve vehicle fuel consumption. Using lightweight materials in the manufacture of various parts of the vehicle is an appropriate way to save the power. In the automotive brake systems, widely used brake disc material is gray cast iron which has a high specific gravity may cause increase of the fuel consumption. Choosing the light materials such as aluminum metal matrix is help to reduce the fuel consumption, but in the same time this new material must be satisfied to the requirements of the braking processes. The current article analysis both of the mechanical performances and vibro-acoustic performance of aluminum alloy disc brake under different brake pressures and different disc rotation speeds. The results showed the mean friction coefficient and brake force has little effect both of the applied force and disc rotation speed. Used the Aluminum metal alloy reduces the brake vibration level by about 17 % at higher applied force. The brake noise increases with increase the disc rotation speed at constant applied force.",60009750,Minia University,Minia,Egypt,['1700'],20.666666666666668,0.07479797979797981,0.4702988215488215,1,0.08,0.02,0.20202020202020202
712,732,732,The mediating role of whistleblowing practice between types of audit and effectiveness of public sector audit,"The aim of this paper is to empirically analyze the mediating role of whistleblowing practice in the relationship between types of audit and its effectiveness in the context of public sector organisations. The paper is using data collected by self-administered survey targeting a convenience sample of 500 public internal auditors in Malaysia. The empirical analysis was carried out by estimating Partial Least Square Structural Equation Modeling (PLS-SEM). The key finding is that the practice of whistleblowing can act as a mediator between types of audit and effectiveness of public sector audit. Thus, whistleblowing practice can be said to play a more important role in the government sector to ensure the survival of the sustainability of the government. Although the study offers empirical evidence from a relatively large and representative of different types of public sector organisations, the specificity of the context should be noted. In particular, public organisations, while aiming to serve the best public service delivery to the citizens, somehow compete with the private sectors who aims to maximize their profit. Clearly, studies on the mediating role of whistleblowing practice in private organisations would be an important next step. Furthermore, researchers should use qualitative research to complement the quantitative findings. The novel contribution of the study lies in the focus on whistleblowing practice as a mediator in the government sector. While previous research has shown that types of audit is related to the effectiveness of public sector audit, an empirical analysis of the relationship between the types of audit, whistleblowing practice and effectiveness of public sector audit had not been undertaken.",113170399,Universiti Sultan Zainal Abidin,Kuala Trengganu,Malaysia,['1700'],23.818181818181817,0.09047619047619047,0.28317460317460313,1,0.1284722222222222,0.03125,0.24295774647887325
713,733,733,Big data stream processing: Latency and throughput,"In recent years, continuously arriving big data streams needs to be processed and respond instantaneously. In several crucial applications, it is expected to investigate and evaluate such streaming data in real time. One of the basic task of any streaming application is processing arriving data from scattered sources and generate an output promptly. The key deliberations for that desired task is: Latency and Throughput. Hence Dealing with stream imperfections such as late data, lost data and out of order data, becomes a significant research in big data stream processing. We have performed experiments for prediction on the stock market data, along with considering the price of US dollar, oil and gold as essential dependent parameters. Since the source of these dependent parameters are distributed, delay in any parameter introduce different types of latency and hence lower down the throughput of stream processing system. In this paper, we have presented the way to deal with latency and throughput with the use of appropriate pipeline and watermark in big data stream processing.",60110157,Chandubhai S Patel Institute of Technology,Changa,India,['1700'],21.25,0.028858024691358026,0.4188271604938271,1,0.11764705882352941,0.016042780748663103,0.25668449197860965
714,734,734,Biostratigraphic studies of the sarbatir formation in the foothills of kuljuktau by foraminifera,"This article is the result of the biostratigraphic studies of the Oligocene-Early Miocene sediments of the foothills of the Kuljuktau Ridge and adjacent territories. The timeliness of these works was explained by the fact that the Oligocene – Early Miocene sediments due to the poverty in them of the faunal remains did not have a sufficiently paleontological sound partitioning scheme, since the Neogene of these areas has not been studied. The need to dismember the Oligocene-Early Miocene of this territory of the Central Kyzylkum is dictated by the fact that the current state of the validity of the dismemberment and correlation does not provide the necessary accuracy and adequacy of the correlation with the International Stratigraphic Scale.",124041127,East Uzbek State Geological Survey Expedition,Tashkent,Uzbekistan,['1700'],39.0,0.05357142857142857,0.3892857142857143,1,0.04,0.104,0.21487603305785125
715,735,735,Semantic ear feature reduction for source camera identification,"Energy based Bior 4.4 feature is proven suitable for identifying source camera of ear biometric images when a small number of distinct camera sources are used. This level-2 Bior 4.4 feature vector bears 36 energy values. In this paper, a semantic way of reducing this feature vector is discussed which is capable of identifying the source camera of ear biometric images. We analyze the consequences of the reduction towards performance in terms of accuracy. Based on the mean of variances of wavelet energy feature, the size of the feature vector is gradually reduced. Reduction of accuracy of source camera identification is expected with reduction of the feature vector size. However interestingly, we can remove less important feature dimensions without affecting the accuracy much. We need to ensure preserving the feature indices that are deciding factors in yielding the accuracy. From the experiment on 3-class source camera classification, it has been found that even the feature size can be reduced to 1/3rd (i.e. up to 12 values from 36 values) with a tolerance of only 1% degradation in accuracy. Hence we grossly conclude that very low dimensional feature can be potent to predict source camera blindly with good accuracy.",60000934,National Institute of Technology Rourkela,Rourkela,India,"['1712', '1708', '1705']",18.0,0.12630208333333334,0.4913020833333334,1,0.12093023255813953,0.013953488372093023,0.27314814814814814
716,736,736,Parallel Black-Box Complexity with Tail Bounds,"CCBYWe propose a new black-box complexity model for search algorithms evaluating &#x03BB; search points in parallel. The parallel unary unbiased black-box complexity gives lower bounds on the number of function evaluations every parallel unary unbiased black-box algorithm needs to optimise a given problem. It captures the inertia caused by offspring populations in evolutionary algorithms and the total computational effort in parallel metaheuristics. We present complexity results for LeadingOnes and OneMax. Our main result is a general performance limit: we prove that on every function every &#x03BB;-parallel unary unbiased algorithm needs at least a certain number of evaluations (a function of problem size and &#x03BB;) to find any desired target set of up to exponential size, with an overwhelming probability. This yields lower bounds for the typical optimisation time on unimodal and multimodal problems, for the time to find any local optimum, and for the time to even get close to any optimum. The power and versatility of this approach is shown for a wide range of illustrative problems from combinatorial optimisation. Our performance limits can guide parameter choice and algorithm design; we demonstrate the latter by presenting an optimal &#x03BB;-parallel algorithm for OneMax that uses parallelism most effectively.",60019702,University of Birmingham,Birmingham,United Kingdom,"['1712', '1703']",24.75,0.15479282622139764,0.42901463615749336,1,0.10043668122270742,0.021834061135371178,0.29955947136563876
717,737,737,Route-the safe: A robust model for safest route prediction using crime and accidental data,"Crimes are rising day by day & thus safety & security is becoming a major concern for people today. Even while travelling, people should be aware & choose the route which is safest to travel from. People who are new to the city, have no idea about the safe routes. Though people rely on google maps for planning their routes; yet it only provides the shortest path & give no consideration for safety of the path. Although several other route planning apps exist which provide the safest route, but these do not consider all the factors that account for safety of the path. Apart from other navigation apps, this paper describes an innovative method to find safest route having lowest risk score. This paper uses updated crime and accident data available on NYC OpenData to determine average risk score of clusters/regions. Machine learning algorithms are used to generate the risk score of a path based upon average risk score of nearby clusters/regions. Also, one can get better results by increasing the number of factors that affect the safety of the path. In future, a better prediction algorithm can be introduced through which traveler can identify probable crimes which he/she might face while travelling on a specific route.",60108737,Manipal University Jaipur,Jaipur,India,['1700'],20.7,0.16169786096256686,0.456149732620321,1,0.14782608695652175,0.021739130434782608,0.2767857142857143
718,738,738,Experiment of electromotive force for electromagnetic energy harvester considering design variables,"Background/Objectives: In this paper, we propose an electromagnetic energy harvester based on magnetic fluid which converts external vibration energy into electric energy using electromagnetic induction method. Methods/Statistical analysis: There are many ways to obtain electrical energy using mechanical vibration. One is the method of obtaining the electric energy by changing the magnetic flux by moving the permanent magnet in the coil. The other is that the permanent magnet is fixed and the coil moves. Both of these methods require a large source of external vibration energy. Findings: To evaluate the performance of the energy harvester, the induced electromotive force was measured under various design conditions. The design variables were experimented by varying the amount of the first magnetic fluid. Second, the magnitude of the magnet was different. Third, the size of the container for containing the magnetic fluid is different. Finally, the shape of the ferromagnetic core through which the flux passes is tested differently. Various experiment results were obtained to combine the above three conditions to make the output of energy harvester suitable for the usage environment. Improvements/Applications: This study will contribute to the design of electromagnetic energy harvester. Particularly, it will play an important role in researching the induced electromotive force depending on the size of the magnetic fluid container, the amount of the magnetic fluid, and the shape of the ferromagnetic core.",60094949,Joongbu University,Kumsan,South Korea,['1700'],17.307692307692307,0.08938923395445135,0.3443581780538302,1,0.11328125,0.01171875,0.224
719,739,739,Equality Case in van der Corput’s Inequality and Collisions in Multiple Lattice Tilings,"Van der Corput’s provides the sharp bound vol (C) ≤ m2 d on the volume of a d-dimensional origin-symmetric convex body C that has 2 m- 1 points of the integer lattice in its interior. For m= 1 , a characterization of the equality case vol (C) = m2 d is equivalent to the well-known problem of characterizing tilings by translations of a convex body. It is rather surprising that so far, for m≥ 2 , no characterization of the equality case has been available, though a hint to the respective characterization problem can be found in the 1987 monograph of Gruber and Lekkerkerker. We give an explicit characterization of the equality case for all m≥ 2. Our result reveals that, the equality case for m≥ 2 is more restrictive than for m= 1. We also present consequences of our characterization in the context of multiple lattice tilings.",60018362,Otto von Guericke University of Magdeburg,Magdeburg,Germany,['1703'],24.66666666666667,0.1975,0.445,1,0.05357142857142857,0.125,0.3374233128834356
720,740,740,A novel 3D dual active contours approach,", part of Springer Nature.This paper investigates a 3D novel dual active contours approach to segment multiple regions in medical images. The locally based segmentation approaches can handle the heterogeneity of the image as well as the noise artefacts. In this light, a locally based dual active contours approach is proposed to separate among three regions constituting the image. The dual contours approach combines the local information along each point in the two curves conjointly with the information between them. Different parameters in this approach determine its accuracy, including the initial distance between the two curves and how much local the information is used in each curve. The approach’s efficiency is evaluated on synthetic images as well as HRpQCT and MRI data compared to state-of-the-art techniques. The computational cost of this approach is reduced using the convolution operator and the FFT transform. The experimental evaluation of the approach demonstrates its segmentation performance on synthetic images and real medical images.",60029689,Universite d'Orleans,Orleans,France,"['1707', '1702']",19.875,0.017948717948717954,0.22307692307692306,1,0.10112359550561797,0.028089887640449437,0.2631578947368421
721,741,741,Formation of accounting management information in the control system of enterprises of JSC «Uzbekistan Railways,"This article discusses the essence, content and tasks of internal accounting and its role in the management system of enterprises and formation of accounting management information in the control system of enterprises of JSC “Uzbekistan Railways”. Ensuring employment is the most important priority of the social policy of the Republic of Uzbekistan.",123158900,Tashkent Institute of Railway Engineers,Tashkent,Uzbekistan,['1700'],26.0,0.2333333333333333,0.39166666666666666,1,0.03508771929824561,0.08771929824561403,0.2807017543859649
722,742,742,A study of working capital management and profitability of auto ancillaries – gears firms in India,"This paper aims to investigate working capital management practice of auto ancillaries – gear manufacturing sector. To examine the nine auto ancillaries – gear manufacturing companies over a time period of 2009 to 2018 listed on Indian stock exchanges were selected. The profitability was used as dependent variable and the working capital ratio has been used as independent variables to test the hypothesis. Data has been used analysing different descriptive methods containing auto correlations test, multiple regressions and multi co linearity test. It is observed that cash, bank and marketable security to sales ratio has positive relation with the profitability.The results show that Cash, bank and marketable security an important variable influencing the profitability.",123269010,Pandit Deendayal Upadhyay Petroleum University,Gandhinagar,India,['1700'],22.8,0.12545454545454546,0.4540909090909091,1,0.12903225806451613,0.008064516129032258,0.32786885245901637
723,743,743,Digital literacy program to undergraduate students through priceless laptop scheme: An illuminative evaluation,"As digital categories and higher education schemes still grow, there is a pressing need to assess their perceived quality and potency. This illuminative assessment offers proof that digital literacy programs are similar and can meet the expectations of undergraduate learners while conserving prime quality levels. Objectives: To find out whether any significant difference in digital literacy among the undergraduates based on gender, locality, stream, parent’s educational level, parent’s occupation level and income in Kancheepuram district. Methodology: In the present study the investigator has chosen the Stratified random sampling technique. Sample: It consists of 605 undergraduate students from colleges in Kancheepuram District. Tool: The investigator used Digital Literacy Questionnaire for this study. Findings: The results resulted that 35.20 percent of the respondents have medium level Digital Literacy and it is followed by 28.42 percent have high and 36.36 have low Digital Literacy. There is no significant difference between undergraduate students due to locality, parent’s educational level and income and found significant difference between undergraduate students due to gender towards the Digital Literacy.",60016712,Alagappa University,Karaikudi,India,['1700'],21.375,0.03916666666666667,0.2911904761904762,1,0.08290155440414508,0.06217616580310881,0.3520408163265306
724,745,745,Integration of capacitive and piezoelectric accelerometers using a digital approach," J. Elec. & Elecn. Eng. & Telcomm.This study is to obtain an acceleration signal with a nice quality and apply it to a linear motion stage. The accelerometers used in this paper are piezoelectric and capacitive accelerometers. Since a piezoelectric accelerometer cannot measure low-frequency acceleration, its application to servo systems is limited. On the contrary, a capacitive accelerometer is able to measure low-frequency acceleration. However, its output noise is significant, and its dynamic bandwidth is small compared with the piezoelectric accelerometer. This paper proposes a high-performance accelerometer, which digitally integrates the salient features of both capacitive and piezoelectric accelerometers. The proposed accelerometer can measure both low- and high- frequency acceleration. It is also applied to compensating for load disturbance in a linear drive for performance improvement.",60022637,National Taiwan Normal University,Taipei,Taiwan,['1705'],10.583333333333334,0.14595238095238094,0.4499470899470899,0,0.09210526315789473,0.03289473684210526,0.3006993006993007
725,746,746,Study of neural network training algorithms in detection of wood surface defects,"Accurate detection of defects through machine vision improves the economical growth of wood industry. In this paper six common defects on wood surface are considered for study. Quality of wood image is enhanced by Histogram Equalization method. Contrast enhanced images are subject to Thresholding segmentation which examines the objects in the image and identifies the defect. The segmented images are cropped in to small blocks. Segmentation- based Fractal Texture Analysis (SFTA) feature extraction method is accomplished to extract 21 texture features from the wood images. The extracted features are fed in to the training algorithms such as Levenberg-Marquardt, Scaled Conjugate Gradient, Gradient Descent with Adaptive Learning Rate, Bayesian Regularization and Resilent Backpropagation. The Performance of training algorithms are analyzed with several performance metrics. The result obtained shows a considerable improvement in accuracy of 98.2 % by Bayesian Regularization tool.",60027171,Annamalai University,Chidambaram,India,"['1711', '1709', '1708', '1702']",15.444444444444445,0.031481481481481485,0.4685185185185186,1,0.11612903225806452,0.14193548387096774,0.4117647058823529
726,747,747,A novel CNFET based tunable memristor emulator,"This paper presents a novel carbon nanotube field effect transistor (CNFET) based memristor emulator circuit. The proposed memristor emulator circuit utilizes voltage differencing transconductance amplifier (VDTA) as an active building block. The emulator circuit employs two VDTAs, two grounded resistors, one grounded capacitor and one four-quadrant analog multiplier. The working concept along with the detailed derivation of the mathematical model of the circuit has been discussed analytically and numerically to confirm the operation of the circuit. The operation of the proposed emulator circuit, as governed by the established equations, has been verified by performing simulations using 32-nm Stanford CNFET model. Further, the robustness of the emulator circuit has been investigated by subjecting it to process and temperature variations. Variability analyses reveals significant tolerance towards aforementioned fluctuations in parameters.",60113861,"Presidency College, Bengaluru",Bengaluru,India,['1708'],18.285714285714285,0.10694444444444444,0.4541666666666666,1,0.13013698630136986,0.0410958904109589,0.375
727,748,748,Glass-reinforced epoxy pipes subjected to short-term high-temperature high-pressure loading conditions,"Analysis of failure in oil and gas transmission pipes has been carried out in Oman oil and gas industry for the last 10 years. It has been noticed carbon steel pipelines have shown a quite high event of failure rate. A great fraction of failure incidents were classified as pipe corrosion failure caused by adverse and corrosive environments (e.g., presence of Hydrogen Sulfide). Obstacles of introducing composite pipes into oil and gas transmission line have been primarily related to inadequate testing data to maintain materials' extended performance and integrity. Customized testing facility has been designed and fabricated to substantiate design of GRE pipes under controlled service conditions. Manufactured GRE pipes shall be qualified to be introduced and used in oil and gas pipelines in Oman. The testing procedure was conducted based on reported ASTM and ISO Standards. A pipe filled with crude oil was placed in thermal and pressure enclosure at a temperature of 65oC and an internal pressure of 130 bars. Mechanical and material tests were conducted to investigate performance and relevant pipes design specifications under such conditions.",60071768,Sultan Qaboos University,Muscat,Oman,['1700'],19.88888888888889,-0.017111111111111115,0.4671111111111112,1,0.11458333333333333,0.041666666666666664,0.3072916666666667
728,749,749,Common fixedpointtheorem in complete intuitionisticfuzzy metric space,"In this paper we have introduced rational type contractive conditions in a complete intuitionistic fuzzy metric space. Using this, we proved some common fixed-point theorem in a complete intuitionistic fuzzy metric space.",60072227,Bannari Amman Institute of Technology,Sathyamangalam,India,['1700'],16.0,-0.033333333333333326,0.43333333333333335,1,0.10810810810810811,0.0,0.22857142857142856
729,750,750,Does the E-procurement eradicate the corruption?: A lesson from e-procurement practices in Indonesia,"This paper aims to find out what benefits and challenges faced by local governments after the implementation of e-procurement system. Further, to elaborate why there is still disjunction, which use by local level government leader to exploit these practices by unfair action for their own benefit. Some benefits and challenges faced by local governments after the implementation of the e-procurement system. Moreover, the focus is how to eradicate the corruption using better system in local government to develop and manage e-procurement.",60069388,Universitas Padjadjaran,Bandung,Indonesia,['1700'],20.25,0.12,0.41,1,0.11702127659574468,0.0,0.26136363636363635
730,751,751,Physical properties of cassava (Manihot esculenta) based on gel polymer electrolyte for zinc-air battery,"This is the continuous work for the characterization of cassava (Manihot Esculenta) based on gel polymer electrolyte for zinc-air battery. In this study, the aimed is to discover the physical properties based on the viscoelastic properties. The preparation of cassava gel electrolyte was by mixing and heated the cassava powder with deionized water. The cassava gel electrolyte continues by mixed with different concentration of potassium hydroxide (KOH). The viscoelastic of cassava gel electrolyte were valued in range of cassava and KOH concentration. From the observation found out the viscosity of cassava gel polymer electrolyte was remaining constant and not signification change in value as the concentration KOH was increased from 2 to 8 M.",60090705,Universiti Malaysia Kelantan,Pengkalan Chepa,Malaysia,['1700'],19.0,0.0,0.33154761904761904,1,0.0873015873015873,0.14285714285714285,0.312
731,752,752,The comprehensive review of congestion control techniques in wireless sensor networks,"Wireless Sensor Network (WSN) is the event-based system, which consists of independent sensor nodes connected over a distributed network to monitor environmental conditions and it is the immense area of research in the field of networking. The sensor nodes are activated when any event identified and transmit the information to other sensor nodes. In this scenario, when the load becomes heavy, traffic is increased and this may prompt the congestion, and thus few important packets may be dropped in the network, throughput may be reduced, and subsequently, the degraded channel quality reduces the performance of the network. Congestion may also occur by the collision of the packets, overflow of the node buffer, rate of transmission, the techniques such as many-to-one data transmission and dynamic time-variant data transmission, etc. Congestion control in WSNs is the high noteworthy and played a major role in accomplishing high QoS of the system. In addition to this, the packet delivery ratio, end-to-end delay and consumption of energy by the sensors are also affected. Hence, the congestion control mechanism is required to monitor and manage the levels of traffic at an adequate rate. In this paper, numerous congestion control mechanisms proposed by different authors in recent years have been analyzed. We also mentioned different performance metrics that are utilized for estimating the level of congestion.",60104605,Bharath Institute of Higher Education and Research,Chennai,India,['1700'],24.33333333333333,0.03475490196078431,0.4517647058823529,1,0.11673151750972763,0.023346303501945526,0.2897959183673469
732,753,753,Structural and chemical analysis of 3d printed metal products,"Making complex metal work with additive techniques is becoming more and more important for modern industry. Such metal work can be produced by arc surfacing. Highly productive surfacing with concentrated power source allows layer-by-layer formation of solid structures, thus, realizing the principle of additive manufacturing. In additive manufacturing the metal work is produced by melting some powder or wire. The methods which use powder as a consumable material are low productive, their application for manufacturing large-size constructions is limited and the powder is used inefficiently. Surfacing with consumable electrode in the shielding gas atmosphere can be applied as the basic electric arc method of layer-by-layer formation of solid structures. Application of this process ensures good atomic interaction of the layers. Thus, the aim of this paper is to study the microstructure, the mechanical behavior and the chemical composition of the layers produced by electric arc layer-by-layer surfacing with consumable electrode in the shielding gas atmosphere. The optical metallography method was applied to study the structure and the chemical composition was estimated by atomic emission spectral analysis. The microhardness was measured by diamond points indention. The research showed that the walls of the products manufactured by electric arc layer-by-layer surfacing have the gradient structure. It is only the last surfaced layer that has the dendrite structure. The underlayers are exposed to secondary heat treatment due to the heat emission from the upper layer. The percentage ratio change of manganese, silicon and carbon in the surfaced layers was observed. The percentage ratio of chrome and nickel through the layers was determined by the chemical composition of the surfaced material. There is an opportunity of producing a flawless wall of the hull structure.",60024069,Tomsk Polytechnic University,Tomsk,Russian Federation,['1700'],17.5,0.15567857142857142,0.4349761904761904,1,0.109375,0.009375,0.20198675496688742
733,754,754,Strict Subspace and Label-Space Structure for Domain Adaptation,"One of the most important issues of transfer learning is domain adaptation which aims at adapting a classifier or model trained in the source domain for use in the target domain, while two domains may be different but related. Intuitively, a good feature representation across domain is crucial. In this paper, we put forward a novel feature representation approach for unsupervised domain adaptation, namely Strict Subspace and Label-space Structure for Domain Adaptation (SSLS). SSLS learns two feature representations that project the source domain and target domain into two different subspaces where marginal and conditional distribution shift can be reduced effectively. Specially, we make the distances of corresponding points in the projection subspaces as well as the label space close by Laplacian graph, which will guarantee the strictness of subspace structure and the quality of the pseudo labels. Extensive experiments verify that our method is superior to several state-of-the-art methods on three real world cross-domain visual recognition tasks Office+Caltech, USPS+MNIST, and PIE.",60023813,Shanghai University,Shanghai,China,['1700'],26.83333333333333,0.21978021978021986,0.5234432234432234,1,0.0748663101604278,0.0427807486631016,0.2711864406779661
734,755,755,The impact of visual merchandising on consumer buying behaviour: A case of bangalore big bazaar,"The extent of visual merchandising is developing quickly with advances in innovation. Clothing retailers need to guarantee their visual merchandising has more grounded effect, as rivalry in the present situation is high, and retailers are prepared to spend more on visual merchandising to draw in customers. Visual merchandising has therefore turned into an instrument which can be utilized by clothing retailers to separate themselves from contenders. The present investigation inspects the effect of visual merchandising, viz. store design, in-store item show, mannequin show, and limited time signage, on drive purchasing conduct of customers in attire retail locations. The respondents for the investigation included 201 clients who visit clothing stores. The information were gathered utilizing an organized poll. The consequences of the investigation recommend that visual merchandising components do significantly affect motivation buy in clothing retail locations, with store design having the most noteworthy effect, trailed by limited time signage, and mannequin show, while in store item show didn't significantly affect drive buy. Further, for men, only store layout had a significant positive impact on impulse purchase, on the other hand, for women, store layout, mannequin display and promotional signage had significant positive impact on impulse purchase.",60107346,Madanapalle Institute of Technology &amp; Science,Madanapalle,India,['1700'],21.777777777777782,0.1533342352092352,0.387150974025974,1,0.09333333333333334,0.02666666666666667,0.3004484304932735
735,756,756,Using WGAN for improving imbalanced classification performance, Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This paper investigates data synthesis with a Generative Adversarial Network (GAN) for augmenting the amount of data used for training classifiers (in supervised learning) to compensate for class imbalance (when the classes are not represented equally by the same number of training samples). Our data synthesis approach with GAN is compared with data augmentation in the context of image classification. Our experimental results show encouraging results in comparison to standard data augmentation schemes based on image transforms.,60011149,Trinity College Dublin,Dublin,Ireland,['1700'],29.66666666666667,0.1,0.2958333333333333,0,0.1111111111111111,0.1111111111111111,0.4
736,757,757,An improved pixel counting method for arbitrary zonal statistics on GlobeLand30," CC BY 4.0 License.Global Land cover is essential for ecological study, climate and environmental changes, resources management, human activities as well as sustainable development. With the finer resolution products arising, e.g. GlobeLand30, quantitative analysis of the earth dynamics based on raster data sets is becoming possible. For arbitrary zonal statistics, pixel counting method is an operational practice widely used for area estimation by counting the number of classified pixels and multiplying by the area represented by each pixel, though uncertainty. For large statistical regions, the error of the projection can not be neglect. Thus an rectified PC method is developed for arbitrary zonal statistics of all raster data sets. The test result shows that the method performance is stable and easy to zonal statistics.",60108755,"China University of Mining &amp; Technology, Beijing",Beijing,China,['1710'],17.857142857142858,0.11796536796536801,0.5465367965367964,0,0.07092198581560284,0.02127659574468085,0.2805755395683453
737,758,758,Improving the efficiency of scientific research based on digitalization,"A problem of efficiency growth of scientific and technological development by means of a purposeful management of the research process is analyzed. Rationing of working time is one of the important tools stimulating the activities of scientists. However, the issue of rationing research work in the scientific community remains open and controversial, since it is difficult to objectively assess the validity of established relationships only taking into account its specific features. The problem consists in the incompliance of the existing management system of scientific research with the requirements of scientific and technological development. The digital modeling of scientific problem solution was studied as an efficient tool of a precise, targeted management of the scientific search. It was shown that one of the priority goals of digitalization consists in a significantly exact and operational numeric calculation of forecasted results under the conditions of innovative development on the basis of use of factors that in reality reflect the conditions and means of system functioning. The purpose of the study: to develop a model for unambiguous determination of the research process management strategy when solving a scientific problem, taking into account real conditions based on a digital model. Tasks solved: 1. To explore the possibilities of quantitative assessment to justify the choice of a strategy for solving a scientific problem based on a digital model; 2. To develop a strategy for solving a scientific problem based on a digital model. The theoretical justification of strategy of a scientific problem modeling is provided. On the basis of the analysis of retrospective information of results of previous research with the help of a multi factor correlation and regressive analysis the digital modeling was carried out which allows creating the management strategy of a scientific problem solution. The digital strategy model can significantly reduce the time spent on research.",114488993,Volgograd Scientific and Technical Center,Volgograd,Russian Federation,"['1712', '1709', '1707', '1705']",23.30769230769231,0.09087301587301587,0.3936507936507937,1,0.11455108359133127,0.0,0.18885448916408668
738,759,759,FIRE SPREAD PREDICTION USING PROBABILISTIC CELLULAR AUTOMATA: The CASE of URBAN SETTLEMENTS in the PHILIPPINES,"Fire disasters are common occurrences in the urban settlements of the Philippines. Concerned agencies like the Bureau of Fire Protection (BFP) and the Disaster and Risk Reduction Management Office (DRRMO) are constantly planning ways to prevent and mitigate fire disasters. The key to an effective plan against fire disaster is understanding how a potential fire can spread in a community. By combining both GIS and Probabilistic Cellular Automata (PCA), this paper solves the task of fire spread modeling and simulation. PCA is a model that consists of a regular grid of cells, whose cells are updated according to rules that take into account both the cell's current state and the cell's neighbors' states. The model we developed factors in wind, building materials, and building density. The model was designed after several fires in major cities of Cebu, Philippines. An accuracy of 83.54% and a Cohen's Kappa coefficient of 0.67 was achieved. Further, a web-based tool was developed to aid in fire disaster planning.",60108083,University of the Philippines Cebu,Cebu,Philippines,['1710'],18.11111111111111,0.04326923076923077,0.4392504930966469,1,0.09424083769633508,0.10471204188481675,0.3915343915343915
739,760,760,"Self-supervised learning with geometric constraints in monocular video: Connecting flow, depth, and camera","We present GLNet, a self-supervised framework for learning depth, optical flow, camera pose and intrinsic parameters from monocular video - addressing the difficulty of acquiring realistic ground-truth for such tasks. We propose three contributions: 1) we design new loss functions that capture multiple geometric constraints (eg. epipolar geometry) as well as adaptive photometric loss that supports multiple moving objects, rigid and non-rigid, 2) we extend the model such that it predicts camera intrinsics, making it applicable to uncalibrated video, and 3) we propose several online refinement strategies that rely on the symmetry of our self-supervised loss in training and testing, in particular optimizing model parameters and/or the output of different tasks, leveraging their mutual interactions. The idea of jointly optimizing the system output, under all geometric and photometric constraints can be viewed as a dense generalization of classical bundle adjustment. We demonstrate the effectiveness of our method on KITTI and Cityscapes, where we outperform previous self-supervised approaches on multiple tasks. We also show good generalization for transfer learning.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",28.0,0.07164502164502164,0.2491341991341991,1,0.11442786069651742,0.03482587064676617,0.34554973821989526
740,761,761,DIWATA-2 TARGETING ASSESSMENT and ATTITUDE ERROR DETERMINATION USING A QUATERNION-BASED TRANSFORMATION SYSTEM,"Target pointing assessment of a space-borne satellite is vital to its operations especially on microsatellites that have limited camera field of view and attitude control components like in the case of Diwata-2. In this study, two scientific payloads of the satellite were used: the Enhanced Resolution Camera (ERC) with a field of view (FoV) of 89.8 × 67.5 km and a resolution of 54.6 m; and the High Precision Telescope (HPT) with a FoV of 3.1 × 2.3 km and a resolution of 4.7 m. Errors in pointing especially on a payload with a small field of view like the HPT could mean the satellite missing its target. The target pointing of Diwata-2 is assessed by firstly, computing the differences in the coordinates of the planned target, the center of the actual image taken by the satellite and the projected target from the satellite's attitude logs. As such, a quaternion-based transformation system is created to simulate the satellite's local vertical local horizontal system from a given Earth-centered inertial system. Secondly, the differences were then tabulated, and its averages were computed to derived pointing corrections. Applying the algorithm to the satellite's images shows that there is an average error in pitch and roll of 0.590° and 0.004°, 6.436° and 6.503°,-5.8465° and-6.499° between the set target to the actual image acquired, between the actual image and from attitude logs and between the set target and from the attitude logs, respectively.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],34.0,-0.030206766917293223,0.3133521303258144,1,0.10108303249097472,0.04332129963898917,0.31954887218045114
741,762,762,Temporal word embeddings for dynamic user profiling in twitter," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The research described in this paper focused on exploring the domain of user profiling, a nascent and contentious technology which has been steadily attracting increased interest from the research community as its potential for providing personalised digital services is realised. An extensive review of related literature revealed that limited research has been conducted into how temporal aspects of users can be captured using user profiling techniques. This, coupled with the notable lack of research into the use of word embedding techniques to capture temporal variances in language, revealed an opportunity to extend the Random Indexing word embedding technique such that the interests of users could be modelled based on their use of language. To achieve this, this work concerned itself with extending an existing implementation of Temporal Random Indexing to model Twitter users across multiple granularities of time based on their use of language. The product of this is a novel technique for temporal user profiling, where a set of vectors is used to describe the evolution of a Twitter user's interests over time through their use of language. The vectors produced were evaluated against a temporal implementation of another state-of-the-art word embedding technique, the Word2Vec Dynamic Independent Skip-gram model, where it was found that Temporal Random Indexing outperformed Word2Vec in the generation of temporal user profiles.",60025059,Dublin City University,Dublin,Ireland,['1700'],38.16666666666666,-0.02529761904761904,0.3854910714285715,0,0.14285714285714285,0.0873015873015873,0.3306122448979592
742,763,763,"Maltitudes, anticenters and altitudes of cyclic polygons and polyhedra","In this paper we extend to cyclical polygons the concepts of maltitude and anti-center of a cyclic quadrilateral and to cyclical polyhedra the concepts of Monge plane and Monge point of a tetrahedron. In addition, we find several properties of these new concepts. The research is conducted through the study of m-point systems, starting from the results on the centroids and the medians of these systems.",60010146,Università degli Studi di Catania,Catania,Italy,['1710'],22.0,0.04545454545454545,0.18484848484848485,1,0.05333333333333334,0.05333333333333334,0.3380281690140845
743,764,764,Policy-compliant data processing: RDF-based restrictions for data-protection,"Data processing can be restricted by policies (constraints), to, among others, protect the individual's privacy, a fundamental human right. Software used to process data may utilize ontologies to represent knowledge as concepts, relationships and restrictions, to solve the task at hand. In knowledge representations, restrictions are typically expressed as axioms, whereas policy-related restrictions have more application specific focus, and are usually expressed as constraints. Thus, various purposes demand differently modeled restrictions. However, existing methodologies do not provide guidelines on how to model restrictions, nor do they distinguish between axioms and constraints. This PhD research aims to investigate the systematic creation of RDF-based restrictions, and their use in policy-compliant data processing. In this paper, I outline my PhD research to (i) analyze the current use of restrictions in ontologies, (ii) provide methodological guidelines to model restrictions, and (iii) apply RDF-based restrictions on data processing to assess policy compliance both before and after the fact. RDF-based restrictions can be modeled by various recommended languages, including OWL, ODRL, SHACL or ShEx. Methodological guidelines to choose the appropriate language or language combinations for an application scenario are beneficial for the knowledge engineering community. Additionally, systematically created restrictions can be used for privacy-compliance assessments.",60033316,Universiteit Gent,Ghent,Belgium,['1700'],19.9,0.07242063492063493,0.4092261904761905,1,0.144,0.028,0.4327731092436975
744,765,765,Gain-scheduled controller design for cooperative adaptive cruise control: Towards automated driving," All rights reserved.In this paper, we present a cooperative adaptive cruise control problem. We have divided our problem into two operational modes. In the first mode, our objective is the gap regulation for safety consideration and in the second mode, our objective is to regulate the speed at driver’s (or passenger) preference. The gain scheduling technique is used to meet both the objectives considering real-time external conditions. The gains are tuned on various standard performance parameters. The performance of the proposed technique is tested by simulation in MATLAB environment and found to be successfully achieved the objectives.",60097223,National Institute of Technology Silchar,Silchar,India,['1700'],16.333333333333336,0.1111111111111111,0.23148148148148145,0,0.10526315789473684,0.008771929824561403,0.2545454545454545
745,766,766,Cityfiction – scenarios for densification,"The aim of the research presented in this paper is to find new ways of understanding and visualising relationships between different types of city data, and thereby support decision making regarding city growth and densification based on desires and values. To this end, a new software tool called CityFiction has been developed. This analysis tool is intended to work as a laboratory for understanding city data, and it will be shown that by interactively weighting, or prioritizing, different measures on the available input data, scenarios for the future development of a city can be efficiently and pedagogically explored. By using the city of Malmö, Sweden, as a pilot study, the tool has been applied to test the placement of e.g. new parks and train stations, and it has aided in the understanding of how the available city data interacts, and possibly conflicts, in the search for a sustainable development of the city.",124058523,FOJAB,Malmo,Sweden,['1705'],30.4,0.13090909090909092,0.4788636363636364,1,0.125,0.023809523809523808,0.2781065088757396
746,767,767,GEOSPATIAL ECOLOGICAL FOREST CORRIDOR MODELLING in the MOUNT LANTOY KEY BIODIVERSITY AREA,"In biodiversity conservation, ecological corridors are assumed to increase landscape-level connectivity and to enhance the viability of otherwise isolated wildlife populations. Mapping these corridors serves as a feasible method to support forest management efforts in pinpointing areas to give special attention to. Here, we assess the current forest presence in the 3,000 hectare Mt. Lantoy, Key Biodiversity Area in Argao, Cebu and present potential forest corridors that could enhance the canopy cover of the current protected area. We present a method to map the potential corridors through the identification of the forest patches obtained from the global forest cover dataset and the creation of a species distribution model for the black shama, an endemic bird species in Cebu island and a great biodiversity indicator for the area. Our ecological corridors were acquired through the sum of the cost distance rasters obtained from the weighted overlay and cost surface tools of the black shama habitat suitability model. With the obtained corridors from the study, four potential forest corridors/extensions were identified connecting five different forest patches. These corridors have areas that range from 0.47-2.17 square kilometers, with a potential to increase the forest cover in the KBA to more than 33% after corridor modelling.",60089572,Cebu Technological University,Cebu,Philippines,['1710'],25.25,0.11798941798941795,0.5715608465608466,1,0.09865470852017937,0.053811659192825115,0.2981651376146789
747,768,768,"Correction: Spatio-Temporal Correlation Graph for Association Enhancement in Multi-object Tracking (Knowledge Science, Engineering and Management, (2019) LNAI 11775, 10.1007/978-3-030-29551-6_35)","Unfortunately the authors of this contribution missed to add an acknowledgment. The acknowledgment should read as follows: Acknowledgement: This study is partially supported by the National Key R&D Program of China (No.2017YFC0806500), the National Natural Science Foundation of China (No.61861166002), the Science and Technology Development Fund of Macau SAR (File no. 0001/2018/AFJ) Joint Scientific Research Project, the Macao Science and Technology Development Fund (No.138/2016/A3), the Fundamental Research Funds for the Central Universities, the Open Fund of the State Key Laboratory of Software Development Environment (No. SKLSDE-2019ZX-04) and the China Scholarship Council State-Sponsored Scholarship Program (Grant No. 201806025026). Thank you for the support from HAWKEYE Group.",60013789,Beihang University,Beijing,China,['1700'],17.5,-0.07142857142857142,0.6357142857142856,1,0.051470588235294115,0.40441176470588236,0.6590909090909091
748,769,769,Performance of Transmission Latency in Software Defined Vehicle Networks,"Software defined network (SDN) technology provides potential solutions for the 5G mobile communication systems. Vehicle-to-vehicle (V2V) communications are the main topology of the Intelligent Transportation System (ITS). Its performance requirement of low latency is one of the most challenging issues. In this study, the transmission latency of V2V communications in software defined vehicular networks (SDVN) is investigated. To minimize the transmission latency in SDVNs, this work proposed five multi-hop routing connection strategies. Simulation results show that under the vehicle density 0.1 ≤ ρ ≤ 0.33, the proposed furthest vehicle (FV) routing algorithm can perform the lowest average transmission latency in SDVNs.",60072429,Asia University Taiwan,Wufong,Taiwan,"['1706', '1705', '1710']",16.833333333333336,0.25952380952380955,0.6333333333333334,1,0.08661417322834646,0.11023622047244094,0.48333333333333334
749,770,770,Context Aware Community Formation for MAS-Oriented Collective Adaptive System,"Forming an effective collaboration community is the key to any successful collaborative process. However, community formation approaches for the closed multi-agent systems may be not fit the need of collective adaptive system comprising multi-agent in open environment. We propose a context aware community formation approach (CFAgentColla) for agent collaboration in open MAS. We employ ontology-based matching and calculation techniques to search for an optimized alternative capability of an agent or to generate a commitment according to the capabilities of two collaborative agents. Then, we define an adaptive goal model and propose an executable tree strategy to generate an optimal collaboration protocol according to the goals, capabilities and commitments. Additionally, we illustrate CFAgentColla approach with a real-world medical waste automated guided vehicle transportation scenario and evaluate the feasibility of our approach by validating the mainly executive parameters and by comparing with the planning approach.",60003028,Wuhan Institute of Technology,Wuhan,China,['1700'],23.83333333333333,0.11515151515151514,0.4393939393939394,1,0.12883435582822086,0.006134969325153374,0.2645161290322581
750,771,771,Semi-automated topology adjustment of partial wall geometry,"<p>The reconstruction of Building Information Modeling objects for as-built modeling is currently the subject of ongoing research. A popular method is to extract building information from point cloud data to create a set of parametric objects. The automation of this process is highly desired by the industry but is currently hindered by occlusions, clutter and the complexity of the building geometry. To create an as-built BIM, it is vital to not only accurately reconstruct the building's structure but also to compute the topology between the objects. More specifically, we target the topology of the reconstructed partial wall geometry as this forms the basis for other objects.</p><p>In this work, a novel method is presented to automatically adjust the topology of wall geometry in an as-built BIM. We present a semi-automated method that procedurally evaluates the configuration of reconstructed objects and adjusts them to create a more faithful BIM. A wall connection evaluation algorithm is proposed that takes as input the centrelines of partial wall geometry and a set of floor and ceilings mesh segments and outputs the topologically adjusted objects. The method is tested on a variety of scenes and shows promising results to reliably compute the topology of as-built models. The generated geometry is similar to the geometric modification proposed by expert modelers. A key advantage is that the algorithm operates directly in Revit and Rhino and can be used for new models as well as for updating existing models.</p>.",60025063,KU Leuven,3000 Leuven,Belgium,['1710'],24.0,0.1055103668261563,0.4755901116427433,1,0.12915129151291513,0.055350553505535055,0.2835820895522388
751,772,772,Solidification analysis by non-equilibrium phase field model using thermodynamics data estimated by machine learning,"A multi-phase field method (MPFM) using the finite interface dissipation model is applied to simulate the solidification microstructure evolution of a stainless-steel composition, including the delta-ferrite to gamma austenite peritectic transformation. The calculation is performed for a quinary system of engineering steel in a two-dimensional field. Thermodynamics calculations using the CALPHAD database in this MPFM are replaced by machine learning prediction to reduce the numerical time. Neural network methodology is introduced for machine learning in this study. The Gibbs free energy and chemical potential values estimated from the CALPHAD database coupling results are inputted into the neural network learning procedure, together with the composition and temperature values. The microstructure evaluated using the obtained neural network parameter is in good agreement with that directly coupled with the CALPHAD database. This calculation is approximately five times faster than direct CALPHAD calculation.",60004853,Tokyo University of Agriculture and Technology,Fuchu,Japan,['1706'],19.857142857142858,0.1142857142857143,0.5571428571428572,1,0.11392405063291139,0.04430379746835443,0.2866666666666667
752,773,773,Rotoform-realization of hollow construction elements through roto-forming with hyper-elastic membrane formwork,"The paper presents a digital process chain for modeling, simulating and fabricating rotationally molded, individualized hollow concrete components using material-efficient and geometrically flexible formwork systems made from hyperelastic membranes. The hollow concrete components are to be used as prefabricated components for architectural constructions. The inner cavity can be efficient in different ways: To save weight and material, for subsequent filling with other materials (insulating, climate regulating, water heating circulation etc.) or as permanent formwork for solid, reinforced structural components that are poured with concrete. Rotoforming concrete significantly reduces the hydrostatic pressure within a formwork and therefore unlocks completely new possibilities for material-efficient and geometrically flexible formwork systems.",60011226,Technische Universität Darmstadt,Darmstadt,Germany,['1705'],26.75,0.05616883116883118,0.2800865800865801,1,0.12,0.0,0.35537190082644626
753,774,774,Temporal learning analytics based on triple-factor approach using self-organizing map,"E-learning personalization aims to deliver learning activities and materials that suits to learners' needs. Therefore, the system must have the ability to analyze the profile and characteristics of each individual learner. Characteristics of learners, among others, can be identified from their behavior in using e-learning. Their most frequent learning resource accessed, their participation on discussions, and their assessment result are some of the variables from the activity logs that can describe their learning patterns. On the other side, learners' behavior may change over time. This research aims to capture and analyze the dynamic learning pattern throughout the semester. The learning analytics are conducted using temporal clustering approach to identify the learning style, motivation, and knowledge abilities. This research performs two-level clustering analysis to acquire learning patterns from activity logs from Moodle Learning Management System using Self-Organizing Map (SOM) and k-Means. SOM enables visualization high dimensional data by projection to lower dimensions. The proto-clusters of SOM are then clustered using k-Means. The temporal clustering results show that the learning patterns of learners are changing over time.",60103730,Telkom University,Bandung West Java,Indonesia,['1706'],15.909090909090908,0.10583333333333332,0.38027777777777777,1,0.15566037735849056,0.05188679245283019,0.3787878787878788
754,775,775,Deconvolutional Pixel Layer Model for Road segmentation without Human Assistance," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The autonomous vehicle is the evolutionary goal of designing Advanced Driver Assistance System, (ADAS) to the point where human assistance is not needed anymore. To create a broad drivable geographical area and mapping for route planning we need robust and efficient semantic segmentation algorithm. Convolutional Neural Networks (CNN) have been able to achieve state of the art performance for tasks such as Image classification, Face recognition and Detection. However semantic segmentation has remained a challenging problem in the field of computer vision. With the help of convolution neural networks, we have witnessed prolific results over time. We propose a convolutional neural network model which uses Fully Convolutional Neural Network (FCN) with deconvolutional pixel layers. The goal is to create a hierarchy of features while the fully convolutional model does the primary learning and later deconvolutional model visually segments the target image. The proposed approach creates a direct link among the several adjacent pixels in the resulting feature maps. It also preserves the spatial features such as corners and edges in images and hence adding more accuracy to the resulting outputs. We test our algorithm on the Karlsruhe Institute of Technology and Toyota Technologies Institute (KITTI) street view datasets. Our method achieves a mIoU accuracy of 92.04 percent.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],19.90909090909091,0.21015625,0.42109375,0,0.09504132231404959,0.10743801652892562,0.4074074074074074
755,776,776,Application of madm methods as moora and wedba for ranking of fms flexibility,"Flexibility has been cited as a key factor to enhance the performance of flexible manufacturing system (FMS). The main aim of this paper is to rank the flexibility of FMS. The ranking decisions are complex in the manufacturing field to analyze a number of alternatives based on a set of some attributes. In this research, two MADM methods i.e. MOORA (i.e. multi-objective optimization on the basis of ratio analysis) and weighted Euclidean distance based approach (WEDBA) are used for ranking of flexibility in FMS for new part development. MOORA approach can give decision with or without considering relative importance of attributes i.e. attribute weights. While in WEDBA, integrated attribute weights are used for evaluation which included the subjective and objective weights of attributes. Objective weights are calculated by entropy method and subjective weights are calculated by analytic hierarchy process. MOORA is applied in two ways i.e. ratio based and reference point analysis. Ranking of fifteen flexibility of FMS done on the basis fifteen variables which effect flexibility of FMS. The results of MOORA and WEDBA approach shows that product flexibility has the top most flexibility in fifteen flexibilities and programme flexibility has the least impact in fifteen flexibilities.",60105382,"Amity University, Haryana",Gurgaon,India,"['1705', '1710', '1712', '1706', '1702']",14.142857142857142,-0.00881542699724518,0.4261707988980717,1,0.10550458715596331,0.05045871559633028,0.32272727272727275
756,777,777,Perception deception: Audio-visual mismatch in virtual reality using the mcGurk effect," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The audio-visual synchronisation is a big challenge in the Virtual Reality (VR) industry. Studies investigating the effect of incongruent multisensory stimuli will have a direct impact on the design of immersive experience. In this paper, we explored the effect of audio-visual mismatch on the sensory integration in a VR context. Inspired by the McGurk effect, we designed an experiment addressing a few critical VR content production concerns today including sound spatialisation and unisensory signal quality. The results confirm previous studies using 2D videos where audio spatial separation has no significant impact on the McGurk effect, yet the findings raise new thoughts regarding the future compression and multisensory signal design strategies to optimise the perceptual immersion in the 3D context.",60021285,Texas Tech University,Lubbock,United States,['1700'],26.2,0.05292699724517907,0.40192837465564735,0,0.0958904109589041,0.0684931506849315,0.38461538461538464
757,778,778,Smartphone-based volunteered geographic information (VGI) for slum mapping in Pokhara city of Nepal,"Informal settlements in urban areas are increasing rapidly throughout the world and regularisation of these settlements is being one of the challenging issues. Various study results have shown that conventional cadastral based information system approach and government managed institutional arrangements do not appropriately address land management issues of slum settlements. The aim of this study is to explore application of smartphone based Volunteered Geographic Information (VGI) and open spatial tools for slum mapping in developing countries such as in Nepal. A case of Pokhara Metropolitan city has been considered to explore the potential of utilization of smartphone based VGI and open spatial tools for slum mapping. Attribute and spatial data were collected using Smartphones and community-driven approach. Spatial and attribute data collected from 229 respondents of household's surveys are integrated, analysed and interpreted and presented in this paper. Open Street Map (OSM) platforms and QGIS open source software have been used for slum mapping. These maps could play an important role in providing spatial information to the local government and planning authority in Nepal. This research paper concludes that smartphone based VGI and open portals such OSM have great potential to contribute to develop slum database and in providing information to plan various strategies, which aims at understanding, regularisation and upgrading slums.",60020321,University of Southern Queensland,Toowoomba,Australia,['1710'],23.555555555555557,0.07261904761904762,0.5615079365079365,1,0.1341991341991342,0.07792207792207792,0.3537117903930131
758,779,779,6-DOF GraspNet: Variational grasp generation for object manipulation,"Generating grasp poses is a crucial component for any robot object manipulation task. In this work, we formulate the problem of grasp generation as sampling a set of grasps using a variational autoencoder and assess and refine the sampled grasps using a grasp evaluator model. Both Grasp Sampler and Grasp Refinement networks take 3D point clouds observed by a depth camera as input. We evaluate our approach in simulation and real-world robot experiments. Our approach achieves 88% success rate on various commonly used objects with diverse appearances, scales, and weights. Our model is trained purely in simulation and works in the real-world without any extra steps.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",17.666666666666668,0.03571428571428571,0.43333333333333335,1,0.125,0.03333333333333333,0.35344827586206895
759,780,780,MAPPING of SARGASSUM DISTRIBUTION in the EASTERN COAST of SOUTHERN LEYTE USING SENTINEL 2 SATELLITE IMAGERY,"Sargassum is a brown seaweed distributed in the Philippines and recognized as an additional source of income for fishing communities. Due to uncontrolled harvesting of the seaweed, the Department of Agriculture regulated its collection and harvesting by imposing seasonal restrictions. Hence, the need to identify the locations and cover of healthy Sargassum is vital to address the demand in the market while maintaining ecological balance in the marine ecosystem. Two Sentinel-2 satellite imagery (10 m resolution) acquired on December 08, 2017 (peak growth) and May 27, 2018 (senescence stage) were used to map the presence of Sargassum in the eastern coast of Southern Leyte. Supervised classification using maximum likelihood algorithm and accuracy assessment were conducted before generating the map. Three classes were considered namely Sargassum, clouds and land. Furthermore, Anselin Local Moran's I (cluster and outlier analysis) was conducted to determine which areas have significant clustering of ""healthy"" Sargassum using the normalized difference vegetation index (NDVI). For both image dates, high classification accuracies of Sargassum were obtained in the islands. However, there are misclassifications of Sargassum in Silago (UA Combining double low line 78.72%) and Hinunangan (PA Combining double low line 82.35%) using the May image. Furthermore, misclassification of Sargassum were obtained in Silago (PA Combining double low line 93.6%) and Hinundayan (PA Combining double low line 96.23%) using the December image. Clusters of high NDVI values are more evident in December. Healthy Sargassum are apparent in the coast of Silago and mostly found near shore and in rocky substrates.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],20.83333333333333,0.16541666666666666,0.3345833333333333,1,0.08783783783783784,0.12162162162162163,0.375
760,781,781,"A UX community of practice: design goals, practice motivations and values","This research report provides an intuitive insight into the design goals, practice values and the motivations why practitioners involved in a community of practice are motivated to practice user experience design in industry. A survey approach with instrument having closed ended questions was utilized. The results indicated that the practitioners’ design goals followed a hierarchy, in the order: usability, functionality, security, pleasure and customizability. The strongest motivation driving respondents who attended the user experience (UX) gathering was performance oriented, hingedon classic competitiveness. In addition, the highest values among the respondents (UX designers) were to make users happy, followed by a focus on clients’ happiness.",60016775,International Islamic University Malaysia,Kuala Lumpur,Malaysia,['1700'],20.8,0.39166666666666666,0.36666666666666653,1,0.10483870967741936,0.024193548387096774,0.4032258064516129
761,782,782,Fauna and seasonal dynamics of the collembolans of Uzbekistan,"The article provides information on the species and quantitative composition of the collembolan communities of various soil layers of agrocenoses and natural ecosystems of northeastern Uzbekistan. As a result of research, 33 species were found in the clover agrocenosis soil layers, 30 in the soil layers of cotton fields, 31 species in the soil layers of apple orchards, and 49 soil species were found in the soil ecosystems of natural ecosystems. The agrocenoses and soil layers of natural ecosystems were dominated by such species as Isotoma notabilis, Isotomiella (Isotoma) minor, Folsomina onychiurina, Frisea (Triaeana) mirabilis, Xenyllodes armatus, Folsomina candida, Willmia anophtalma, Xenylla maritima, Oligaphorura (Lipura) groenlandica, Isotomodella pusilla, Panchaetoma (Isotoma) communa, Schoettella (Achorutes) ununguiculatus, Acherontiellina (Acherontiella) sabina. When studying the number of collembolans by seasons, the peak period of their seasonal dynamics is observed in spring and autumn, and when studying soil layers (10-20 cm), the number of collembolans was at its maximum, in spring and autumn in agrocenoses and soils of natural ecosystems in soil at a depth of 10-20 cm number of collembolans in spring was on average 3558 copies, and in the autumn there were 3298 copies.",60071655,National University of Uzbekistan named after Mirzo Ulugbek,Tashkent,Uzbekistan,['1700'],47.5,0.02500000000000001,0.4,1,0.034334763948497854,0.09871244635193133,0.4759825327510917
762,783,783,GIS-ASSISTED RAIN-INDUCED LANDSLIDE SUSCEPTIBILITY MAPPING of BENGUET USING A LOGISTIC REGRESSION MODEL,"Landslides are a major concern in disaster risk reduction and management in Southeast Asia due to the region's geographic location and setting. These are massive downward movement of rock, soil and/or debris under the influence of gravity. Benguet, lying within the Cordilleran mountains of the Philippines, is landslide prone. The increasing demand for sustainable development and expansion of human settlements and infrastructures deems landslides as a problem for the mountainous province. More than half of Benguet's land area is highly susceptible to landslides. Hence, landslide potential identification and assessment, associated with topography, is vital in ensuring efficiency while minimizing collateral damage and unwanted casualties. This study developed a logistic regression model to map susceptibility to rainfall-induced landslides. Causative factors for the analysis in this study include rock types, soil types, land use, elevation, slope, aspect, precipitation, topographic wetness index (TWI), normalized difference vegetation index (NDVI), and leaf area index (LAI). These layers were prepared using GIS. Based on the logistic regression, the most statistically significant variables were aspect, elevation, and leaf area index (LAI). The model considered with the combination of the causative variables resulted with an R squared value of 86% which indicates good variability for the conditioning factors used for the mapping procedure. Results indicate that 69% of Benguet is highly susceptible to landslides, 7% area is moderately susceptible to landslides, and 24% area is low susceptible to landslides.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],19.25,0.14786458333333335,0.5247916666666668,1,0.07168458781362007,0.035842293906810034,0.3574007220216607
763,784,784,Improved model using estimate error for daily reservoir inflow forecasting," All rights reserved.Inflow forecasting is one of the important components for reservoir operation and resource management. To obtain enhanced accuracy for forecasting reservoir inflow, this paper proposes an improved model for forecasting the inflow of Bhumibol reservoir. The 3,169 records of daily inflow data from June 1, 2008, to February 1, 2017, had been collected to calculate the inflow into the reservoir by using Artificial Neural Networks (ANN) running the Back-Propagation Learning Algorithm for forecasting the inflow of the reservoir in the main model and error prediction model. The performance of the model is evaluated by four methods: the coefficient of determination (R2), the Nash-Sutcliffe efficiency (NSE), the Root Mean Square Error (RMSE), and the Mean Absolute Error (MAE). The proposed main and error prediction models were combined to support the forecast of reservoir inflow. The performance of the proposed model can be determined using the following measured values: R2 was 0.927, NSE was 0.925, RMSE was 6.805 and MAE was 3.611. This indicates that the improved model provides more accurate value than the model without estimate error.",60022498,Naresuan University,Pitsanulok,Thailand,"['1710', '1705']",25.57142857142857,0.05530303030303031,0.5613636363636364,0,0.102803738317757,0.1261682242990654,0.391304347826087
764,785,785,Digitalization in Services: Barriers of Regulation,"The Fourth Industrial Revolution is associated with a significant impact of modern technology in all areas of society. Digitalization of services leads to new types of services, its providers, ways of provision and consumption. The services are regulated by different branches of law. The authors investigated the civil law regulation. The goal was to explore government regulation of services in the digital economy. The authors tried to answer the following questions. Is the state able to regulate digitalization? Is this regulation necessary? Is it possible to do without it? What are the barriers to digitalization: state regulation, its absence or methods of regulation? What are the ways to overcome these barriers? How will the regulation of services develop? Methods. The consistent analysis of the civil law method of the regulation of the services, of the practice of changes in the regulation of the digital economy, of the essence of the Fourth Industrial Revolution, has been carried out. As a result, the regulatory barriers for the development of digitalization of services have been identified, the proposals for overcoming the barriers have been made, and the development of regulation has been forecasted. Results. The barriers to the development of digitalization of services may be the backlog of state regulation, restrictive state regulation and imperative regulation of contractual relations. The suggestions for overcoming these barriers have been made. Russia uses the regulation of the digital economy, which is of a permissive and imperative nature, while the flexible regulation and its decentralization, the freedom of participants to introduce and use new technologies and products are necessary. During the Fourth Industrial Revolution, the state will significantly lag in regulation from rapidly developing relations, therefore the center of regulation will shift from the state to the participants. The large service providers can become such flexible regulatory cen.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,"['1712', '1709', '1707', '1705']",20.066666666666666,0.0942960448642267,0.3892119244391971,1,0.08875739644970414,0.029585798816568046,0.29289940828402367
765,786,786,A tool for detecting ambiguity in software requirements specification,"The main goal of requirements engineering is to establish software requirements specification (SRS). The requirements in SRS are mostly specified in natural languages (NL), therefore, one of the common problems of SRS is requirements ambiguity. The requirement is said as ambiguouswhen it has more than one interpretation, subsequently, can lead torequirements inconsistency and conflict. Besides, to detect ambiguous requirements manuallyis time-consuming and tedious process. Thus, this paper presents a tool called SRS Ambiguity Detector,that able to detectautomatically the major types of ambiguity; lexical, syntactic and syntax ambiguity. This tool uses ambiguity words from the ambiguity handbook to detect lexical ambiguity, while, parts of speech (POS) tagging technique has been applied to detect syntactic and syntax ambiguities. Evaluation was conductedto assess the effectiveness, and the result has shown that the proposed tool able toidentify more ambiguous requirements as compared to manual detection.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],20.142857142857142,0.18446969696969695,0.5030303030303029,1,0.1242603550295858,0.04142011834319527,0.40119760479041916
766,787,787,Complexity analysis of FDE receivers for massive MIMO block transmission systems," All rights reserved.This paper considers massive multiple-input multiple-output (m-MIMO) schemes employing orthogonal frequency division multiplexing (OFDM) or single-carrier with frequency-domain equalisation (SC-FDE) modulation, concerning an uplink transmission. We study the performance and complexity for both conventional zero forcing (ZF) and minimum mean squared error (MMSE) (which require the inversion of channel matrix) and iterative frequency domain equalisation (FDE) receivers based on equal gain combining (EGC) and maximum ratio combining (MRC) concepts, that do not require matrix inversions. It is shown that, although matrix inversions are generally the more complex operations for relatively balanced systems (i.e., with similar numbers of transmit and receive antennas), this is not generally true for systems where the channel matrix is”very tall” (i.e., much more receive than transmit antennas), at least in terms of the number of multiplications and sums. This means that the advantage on a reduced complexity of MRC/EGC-based equalisers with respect to ZF/MMSE is, in fact, limited. However, the performance advantages combined with the possibility of parallel receiver implementations, make those techniques particularly interesting for m-MIMO schemes, either employing OFDM or SC-FDE modulations.",60022729,"Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa",Caparica,Portugal,['1706'],36.2,0.028013392857142858,0.4117187500000001,0,0.08979591836734693,0.07346938775510205,0.42792792792792794
767,788,788,A prelimenary study on the development of research data management (RDM) policy,"Data sharing is an important pre-requisite towards enhancing knowledge in science and technology in recent years. The need to systematically collect, collate and manage research data will further facilitate knowledge archiving for future reference and re-use. This paper describes the development of a policy framework for data repository in one of Malaysian public university with a focus on the awareness of data sharing among researchers. Questionnaires were distributed to 164 respondents focusing on the benefit of data sharing, lack of data sharing requirement and types of data to be included in data repository management. From the finding, the respondents are willing to share and provide data to the other researchers provided there is a proper policy document. This research also discusses the recommended guidelines for the data repository policy and also on how to promote data sharing among researchers.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],23.16666666666667,0.065625,0.3958333333333333,1,0.11842105263157894,0.0,0.24324324324324326
768,789,789,Method of variational calculation of influence of the propulsion plants of forestry machines upon the frozen and thawing soil grounds,"The forests, which grow in the conditions of complete expansion of the perpetually frozen ground, are unique forests in accordance with their taxational characteristics, quality indicators of the felled timber, and the ecological functions, which these forests perform in the nature. They are characterised by the low biological productivity, as well as by the high vulnerability due to climatological changes and human economic activities. It is fair to say that conservation of the permafrost is one of the main functions of the forests, which grow within the cryolithozone. Because of this, it is necessary to ensure special regimes for the forestry management and forest exploitation within the forests of the cryolithozone. We formulated the variational problem in order to determine influence of the changeability of the physical and mechanical properties of the thawing soil ground at the boundary with the permafrost ground.",60108900,Ural State Forest Engineering University,Yekaterinburg,Russian Federation,['1700'],28.4,0.1631292517006803,0.4759013605442177,1,0.06451612903225806,0.0,0.23870967741935484
769,790,790,Control Premium in the Russian Stock Market: Sector Aspect,"The stock market is a powerful mechanism redistributing corporate control. In recent decades, mergers and acquisitions were followed by purchasing the stock in the target company by the buying company in the stock market, which makes it relevant to study the market price changes following such operations. The objective of the article is to evaluate the target company control premium in the Russian stock market and to assess its dependence on the volume of the acquired stock and the sector affiliation of the target company. The method used to evaluate the control premium is based on the information about mergers and acquisitions, where the premium is assessed as cumulative average abnormal return observed after the market obtained information on the transaction. By the available statistic data, the control premium for the market as a whole was evaluated, the dependence of the premium on the stock size was analyzed and the premium volume was calculated and analyzed for different sectors of economy. Conclusions were drawn about the impact of insider information on the Russian market and the low efficiency of transactions from both an investment and speculative standpoints.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",31.16666666666667,0.08214285714285714,0.3535714285714285,1,0.10101010101010101,0.0,0.1717171717171717
770,791,791,The model of data interoperability in farm management information system,"The crop production process is not a single activity but is a series of activities, start for pre-planting, planting, harvesting, until marketing the product. Moreover, this process involves many resources also, both internal and external resources. to make all resources manageable effectively and efficiently, utilizing a Farm Management Information System (FMIS) is one of the tools that could be considered. Existing FMIS applications generally characterized as a closed application, focus only on few functionalities, utilize close data, and segment for the big scale farm due to some reasons. To make the FMIS application applicable to smallholder farmers, developing an FMIS application based on open source that utilizes open data is a necessity. However, utilizing open data in a data interoperability framework is not trivial, complicated, and deal with many heterogeneity problems. The four main heterogeneity problems that might arise are schema heterogeneity, the granularity of data, mismatch in entity naming and data unit, and inconsistency of data. Required a model of FMIS data interoperability which includes the algorithm to identify and tackle all those problems comprehensively. Functional requirement analysis will be employed for developing the model. To check the quality and validity of the proposed model, a series of the evaluation process will be performed. As proof of the model, this research will develop a mobile-based FMIS application. Finally, usability testing and impact analysis will be conducted to assess the benefits of using FMIS applications to the farm.",60010105,Asian Institute of Technology Thailand,Bangkok,Thailand,['1700'],19.83333333333333,0.051521164021164016,0.4512566137566137,1,0.14492753623188406,0.036231884057971016,0.3088235294117647
771,792,792,Study on 3D modeling of heel effect,". All rights reserved.In this study, we seek to present a three dimensional beam pattern and distribution of strength for the anode heel effect, by using 3D modeling on beams emitted from the X-ray tube.A digital flat panel detector was used to acquire pre-processed images for each voltage (kVp), current (mA), and field of view (FOV) of the tube. An image analysis program was used to analyze the distribution of the strength of X-rays and 3D modeling was carried out to evaluate in three dimensions the anode heel effect. The beam pattern and strength appeared until the threshold of the pixel value and then showed saturation with an increase in the voltage of the tube. When the current was increased for the same exposure dose, there was no change in the beam pattern or distribution of strength. As the field of view increased, the beam pattern and distribution of strength became more distinct. On the horizontal axis that connects the anode and cathode in the distribution of the X-ray’s strength, the strength of the anode was lower than that of the cathode. On the vertical axis, too, the strength was lower as the distance from the center of the beam increased. With analysis of the pixel value that correspond to the exposure dose and 3D modeling, we verified in three dimension the horizontal axis that connects the anode and cathode and the corresponding field of view on the vertical axis to newly define the anode heel effect.",108125371,Far East University,Chungbuk,South Korea,['1700'],27.444444444444446,0.08113636363636363,0.2404545454545455,1,0.09507042253521127,0.014084507042253521,0.22344322344322345
772,793,793,"Capacity development and education outreach in geoinformatics and land management: A case of department of geomatics engineering, Kathmandu university","The capacity development and education outreach in Geoinformatics and Land management is very important for the development of any country. The aim of this paper is to highlight the existing capacity development and education outreach in Geoinformatics and Land Management at Department of Geomatics Engineering and draws attention of all national and international geospatial community for their contributions to promote capacity development and education outreach in Geoinformatics and Land Management sectors in Nepal. The desk study has been carried out for the study by reviewing literature and using secondary data sources. This study analyzes an aspects , challenges and opportunities in collaborative efforts made by Kathmandu University and Land Management Training Center to become a center of excellence in these sectors. The study reveals that ""To make Geoinformatics and Land Administration, a leader course in Nepal and also within the region"", Kathmandu University has to overcome various challenges. Some challenges may be addressed in the national level but some require collaborations and cooperation from international geospatial community. The result indicates that the capacity development and education outreach in Geoinformatics and Land Management sector helps to develop quality geospatial professionals which in turn may incorporate the entire South Asia region as a potential Geospatial and Land Management market. Finally, Kathmandu University, Department of Geomatics Engineering is committed to develop a centre of excellence in Geoinformation and Land management sector by providing quality education, research and development.",60071792,Kathmandu University,Dhulikhel,Nepal,['1710'],29.375,0.0020000000000000018,0.4625,1,0.092,0.156,0.34
773,794,794,SEA FOG DETECTION BASED on DYNAMIC THRESHOLD ALGORITHM at DAWN and DUSK TIME,"Dawn and dusk time is the high frequency period of sea fog occurrence, which is very important for all-day sea fog remote sensing detection. Most polar orbit satellites are limited by time resolution and transit time, and can not detect sea fog at dawn and dusk. Based on the Himawari-8 geostationary satellite data and the analysis of the spectral characteristics of sea fog at dawn and dusk, this paper determines the variation law of the reflectivity and brightness temperature of sea fog at dawn and dusk, chooses sensitive bands, sets the detection index of sea fog and its corresponding dynamic threshold, and realizes the detection of sea fog at dawn and dusk. The case study results indicate that our dynamic threshold algorithm can effectively detect the sea fog at dawn and dusk.",60105111,China University of Petroleum (East China),Qingdao,China,['1710'],33.0,0.16252380952380951,0.4666190476190476,1,0.0763888888888889,0.0625,0.16901408450704225
774,795,795,The values of social education and cultural education in topeng endel character as a woman role model in Topeng tegal folklore,"Purpose –This study aims at describing the implicit values in the folklore named Topeng Tegal. Such values certainly can be considered as life learning.The values born from a literary work especially folklore contain an education so that the author wants to describe the educational value of the Topeng Endelcharacter that can be used as a life guide in the social and cultural domain implied in the Topeng Tegal folklore. Methodology – This research is presented in a descriptive form in the qualitative research domain which analyzes the value of social and cultural education in Topeng Endelcharacter in the folklore of Topeng Tegal. Data sources of the research were taken from interviews, local government documents and oral stories grown in the community. The collected data was then analyzed using content analysis techniques that were validated using data triangulation, theories, methods and researchers. Findings – The findings in this study are revealing the implied message in the form of social and cultural education values inherent in the lives of the Topeng Endelcharacter in the Topeng Tegal folklore. This can be proven by the mindset and behavior in the life of Topeng Endel character in the story and the recognition of the surrounding community. Significance – This studyresults new knowledge about the existence of educational values that have been applied since the days of our ancestors through traditionsinherited in Tegal society. One of them is through the folklore ofTopeng Tegal, especially in theTopeng Endel character as a Tegal female character believed to be able to provide a life guide for future generations. The guidance emerged from the existence of social and cultural education values interpreted from the lives ofTopengEndelcharacter. The social and cultural education valuesthat emerged and survived for ages should be followed to advance our life in the form ofmindset and behavior. It is expected to be useful for all community member including students, teachers, other researchers and readers as reflection of what is good from this finding.",60069439,Universitas Sebelas Maret,Surakarta,Indonesia,['1700'],27.16666666666667,0.1145302228635562,0.2722582972582973,1,0.11527377521613832,0.05475504322766571,0.3081395348837209
775,796,796,Impact of big data analytics in reverse supply chain of Indian manufacturing industries: An empirical research,"The main purpose of this paper is to know about the recent status of big data analytics (BDA) on various manufacturing and reverse supply chain levels (RSCL) in Indian industries. In particular, it emphasizes on understanding of BDA concept in Indian industries and proposes a structure to examine industries’ development in executing BDA extends in reverse supply chain management (RSCM). A survey was conducted through questionnaires on RSCM levels of 500 industries. Of the 500 surveys that were mailed, 125 completed surveys were returned, corresponding to a response rate of 25 percent, which was slightly greater than previous studies. The information of Indian industries with respect to BDA, the hurdles with boundaries to BDA-venture reception, and the connection with reverse supply chain levels and BDA learning were recognized. A structure was presented for the selection of BDA ventures in RSCM. This paper gives bits of knowledge to professionals to create activities including big data and RSCM, and presents utilitarian and predictable direction through the BDA-RSCM triangle structure as an extra device in the execution of BDA ventures in the RSCM factors. This paper does not provide outside legitimacy owing to limitations for the speculation of the outcomes even in the Indian surroundings, which originates from the present test. Future research ought to enhance the understanding in this area and spotlight on the effect of big data on reverse supply chains in developed countries.",60079572,Siksha O Anusandhan (Deemed to be University),Bhubaneswar,India,"['1705', '1710', '1712', '1706', '1702']",25.88888888888889,0.03777777777777778,0.23055555555555554,1,0.08812260536398467,0.038314176245210725,0.3346303501945525
776,797,797,Development of semi-burning sweet potato automorphing machine,"Background/Objectives: The objective if this study is to develop a product with variously modifying knife-replacing structures for cutting machine that automatically truncates and creates semi-arid sweet potato. Methods/Statistical analysis: Developed product is designed to perform with a press method reducing the number of added devices and efficiently utilize production space through evaluation of performance on standby power of sweet potato cutting machine and reaction time on emergency stoppage as well as hardness of a blade. Findings: It is possible only to cut sweet potato in unified shape with existing production method. However, it is possible to make sweet potato in various shapes by completing the manufacturing of replaceable blade cover and also to develop new products by cutting and processing fruits and vegetables other than sweet potato in the future with blade replacing method of developed product. Improvements/Applications: It is possible to develop new products as it becomes feasible to process new items with the development of relevant product over currently producing sweet potato-processing products.",60028021,Kwangju University,Gwangju,South Korea,['1700'],33.0,0.04736363636363637,0.6185454545454547,1,0.13368983957219252,0.0213903743315508,0.2342857142857143
777,798,798,Spatial biodiversity model to characterize biological diversity using R statistical computing environment for Nepal himalaya,"Biodiversity characters of the landscape provide basis of prioritizing the sites in conservation effort. There is an urgent need for rapid assessment of existing biodiversity using state-of-art tools and technologies at large scale. The purpose of the study is to model and prioritize biological richness based on multi-criteria decision analysis (MCDA) for conservation priority and management planning. Vegetation type map for year 2017 was developed for generation of various landscape indices e.g. fragmentation, patchiness, porosity, juxtaposition etc. The Spatial Biodiversity Model (SBM) prepared for similar landscape of Uttarakhanda, India which is scale, resolution and location independent for spatial biodiversity richness modelling was executed in R programming platform. Satellite data, non-spatial data and ancillary data were used to generate Biological Richness (BR) map which is categorized into 4 classes as low, moderate, high and very high (biodiversity rich) including non-forest area to quantify BR area. The result shows that largest area is under very high biological richness class followed by high, moderate and low BR area. Overall accuracy and Kappa Statistics of LULC/vegetation type classification is 82.61% and 0.8013 respectively. The spatial regression analysis for final output validation has been made with ground based species diversity data where R2 value for Shannon-Wiener index and Margalef's diversity index are 0.64 and 0.56 respectively. The results also re-emphasize the role of geospatial techniques in the quick appraisal of predicting biological richness. The study result is applicable in systematic inventory of biological resources, land use planning, conservation prioritization and policy support.",60004003,Indian Institute of Remote Sensing,Dehradun,India,['1710'],20.58333333333333,0.09255889724310776,0.4572406015037594,1,0.08135593220338982,0.0576271186440678,0.34285714285714286
778,799,799,A lean approach to optimize BIM information flow using value stream mapping," This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.Building Information Modelling (BIM) was introduced in the Architecture, Engineering and Construction (AEC) industry as a shared information platform that aims to improve productivity through better collaboration. The assumption is that a virtual integration of information among project stakeholders would reduce the issues around the fragmented nature of the processes that still prevail in the construction field. This paper aims to highlight the sources of waste in the information flows between an architecture firm, a Mechanical, Electrical and Plumbing (MEP) engineering firm, a general contractor (GC) and a MEP subcontractor (SC) in a BIM project - an aspect of waste little covered in the Lean literature. The focus is on the MEP process from early design to the final product. This research contributes to the identification of the main barriers to information flow, including the conflicts and waste sources that emerge from using BIM, as well as to the identification of emerging successes. Moreover, the findings offer practical implications by providing a visual of the patterns emerging from the use of BIM. Finally, by providing potential waste reduction strategies such as Value Stream Mapping (VSM) this work allows construction actors to identify and reduce sources of waste in their processes.",60026786,École de Technologie Supérieure,Montreal,Canada,['1706'],33.57142857142857,0.004734848484848494,0.3992424242424242,0,0.1,0.09259259259259259,0.3680297397769517
779,800,800,On a vibration problem of transversely isotropic bars,"In [1] transversely isotropic elastic piezoelectric nonhomogeneous bodies in the case when the poling axis coincides with one of the material symmetry axises is considered. The present paper is devoted to the dynamical problem of such materials when the constitutive coefficients depending on the body projection (i.e., on a domain lying in the plane of interest) variables may vanish either on a part or on the entire boundary of the projection.",60071909,Ivane Javakhishvili Tbilisi State University,Tbilisi,Georgia,['1706'],35.5,0.0,0.375,1,0.08974358974358974,0.0,0.21794871794871795
780,801,801,Multi-constrained authoring of occupant behavior narratives in architectural design,"Building-Information Modeling (BIM) tools provide static representations of built environments, disjointed from the expected behaviors of their future inhabitants. Current approaches for simulating buildings in use can be categorized as building-centric, where occupancy distributions are specified, behavior-centric, where multi-agent behaviors are modeled, or occupant-centric, where occupants behave based on their individual motivations. In this paper, we combine these methods into an integrated framework to author narratives that satisfy multi-level time-varying constraints, such as (a) building-level occupancy specifications, (b) zone-level behavior distributions, and (c) occupant-level motivations. Such information is encoded into customizable templates associated with BIM models. A case study highlights the ability of this approach to seamlessly author behavior narratives that can be used for visualizing, analyzing and communicating how buildings may be used by their future inhabitants.",60119141,Rutgers University–New Brunswick,New Brunswick,United States,['1705'],25.6,0.05555555555555555,0.38333333333333336,1,0.14534883720930233,0.011627906976744186,0.48026315789473684
781,802,802,DST: A Deep Urban Traffic Flow Prediction Framework Based on Spatial-Temporal Features,"Traffic flow prediction is an interesting and challenging problem in transportation modeling and management. The complex topological structure of urban road network makes it more complicated. The performance of traditional traffic flow prediction models like time series models is not satisfactory, for those methods cannot describe the complicated nonlinearity and uncertainty of the traffic flow precisely. With the rapid development of deep learning, many researchers try to apply deep learning methods to traffic flow prediction. However, those deep learning models neither consider both spatial relation and temporal relation, nor do they combine spatial relation and temporal relation in an effective way. In this paper, we propose a deep urban traffic flow prediction framework (DST) based on spatial-temporal features. In our framework, we use a local convolutional neural network (CNN) method which only considers spatially nearby regions to extract the spatial features and a long short-term memory (LSTM) model to extract the temporal features. In addtion to the traffic flow data, we also use external context data when predicting traffic flow. The experiments on a large-scale taxi trajectory dataset TaxiCQ show that our proposed model significantly outperforms other comparison models.",60122052,Southwest University,Chongqing,China,['1700'],21.0,0.08636363636363638,0.5272727272727273,1,0.08256880733944955,0.01834862385321101,0.2641509433962264
782,803,803,Black globe free convection measurement error potentials,"For thermal comfort research, black globes have become the de facto tool for mean radiant temperature, TM RT, measurement. They provide a quick, cheap means to survey the radiant environment in a space with nearly a century of trials to reassure researchers. However, as more complexity is introduced to built environments, particularly by engineering spaces to separate radiative and convective modes of heat transfer for energy efficiency and comfort, we must reassess the relationship of globe readings in the context of their environments. In particular, corrections for globe readings taking wind into account [1, 4] rely on a forced convection heat transfer coefficient. The simulation proposed in this paper demonstrates the influence of free convection on the instrument’s readings. Initial studies show that the TM RT and air temperature separations of 2 K could introduce errors equivalent to 0.1 m/s of air velocity, providing an additional mechanism for globe readings to track air temperatures.",60003269,Princeton University,Princeton,United States,['1705'],25.66666666666667,0.11704545454545455,0.4443181818181817,1,0.11428571428571428,0.045714285714285714,0.3045977011494253
783,804,804,A New Multi-objective Evolution Model for Community Detection in Multi-layer Networks,"In reality, many complex network systems can be abstracted to community detection in multi-layer networks, such as social relationships networks across multiple platforms. The composite community structure in multi-layer networks should be able to comprehensively reflect and describe the community structure of all layers. At present, most community detection algorithms mainly focus on the single layer networks, while those in multi-layer networks are still at the initial stage. In order to detect community structures in multi-layer networks, a new multi-objective evolution model is proposed in this paper. This model introduces the concept of modularity in different decision domains and the method of local search to iteratively optimize each layer of a network. Taking NSGA-II as the benchmark algorithm, the proposed multi-objective evolution model is applied to optimize the genetic operation and optimal solution selection strategies. The new algorithm is denoted as MulNSGA-II. The MulNSGA-II algorithm adopts the locus-based representation strategy, and integrates the genetic operation and local search. In addition, different optimal solution selection strategies are used to determine the optimal composite community structure. Experiments are carried out in real and synthetic networks, and results demonstrate the performance and effectiveness of the proposed model in multi-layer networks.",60122052,Southwest University,Chongqing,China,['1700'],19.7,0.10007215007215006,0.3082431457431457,1,0.09663865546218488,0.025210084033613446,0.2962962962962963
784,805,805,Discrete systems of information warfare and optimal control problems,"In the article on the basis of the new unified approach in mathematical and computer modeling of information warfare a specific integrated nonlinear discrete model of information warfare is constructed. At creation of the integrated discrete model the ideas of modeling of information opposition the offer by academician A.A. Samarsky, together with professor A.P. Mikhaylov and Professor T.I. Chilachava are used. On the basis of combining these approaches in modeling, when information flows and recipients of information were separately considered, the integrated discrete model was constructed. This model was investigated for controllability and a specific problem of optimal control of the combined discrete process was formulated.",60110406,Sokhumi State University,Tbilisi,Georgia,['1706'],15.142857142857142,0.03409090909090909,0.17613636363636365,1,0.10619469026548672,0.061946902654867256,0.26956521739130435
785,806,806,Noise spectra in the reversible-irreversible transition in amorphous solids under oscillatory driving,"We study the stress fluctuations in simulations of a two-dimensional amorphous solid under a cyclic drive. It is known that this system organizes into a reversible state for small driving amplitudes and remains in an irreversible state for high driving amplitudes, and that a critical driving amplitude separates the two regimes. Here we study the time series of the stress fluctuations below and above the reversible-irreversible transition. In the irreversible regime above the transition, the power spectrum of the stress fluctuations is broad and has a 1/f α shape with 1 < α < 2. We find that the low frequency noise power peaks near the stress at which dc yielding occurs, which is consistent with the behavior expected in systems undergoing a non-equilibrium phase transition.",60027161,Ben-Gurion University of the Negev,Beer Sheba,Israel,['1706'],25.2,0.010208333333333337,0.316875,1,0.08450704225352113,0.02112676056338028,0.27611940298507465
786,807,807,Development of Algorithm to Measure Digital Potential of High-tech Industrial Cluster,"Industry 4.0, which is aimed at the global introduction of cyber-physical systems into industry, has determined further development pathways for cluster systems; one of the pathways is digitalization of business processes, which enables cutting costs significantly, manufacturing a high-tech innovative product, reducing time for communication between all the participants in the industrial cluster, revealing new sources for project funding, simplifying human work via relevant software and robotics adopted in the industry. All these factors become more urgent in the framework of functioning high-tech industrial clusters, which have not evolved only from the protocluster to the innovative active industrial cluster, but overtook their rivals by using these innovative available tools of the digital economy. In this paper the authors have presented a range of the most applicable methods to measure the digital potential of the industrial cluster (in regard to quantity, quality and mixed research methods); they have reviewed the literature that reveal the concept ""innovative potential"" of an industry enterprise and a cluster; the authors have considered 13 stages of digital potential measurement for the industrial cluster, including the following: identification of measurement parameters, classification of parameters by 6 subpotentials, expert evaluation of parameters, tabulation of the obtained expert survey results, selection of most significant parameters, final preparation of groups of factors, determination of a scale and units of measure for every selected factor to evaluate, collection of information from accessible sources, reduction of the received data to a unified measurement system, calculation of an integral index based on the developed scales, final stage includes guideline development. On the basis of the presented stages the authors worked out a relevant measurement algorithm, novelty and peculiarity of which imply allowance for indicators that characterize cluster digitalization (i.e. digital potential) when calculating a final integral value.",60071849,Buketov Karaganda State University,Karaganda,Kazakhstan,"['1712', '1709', '1707', '1705']",58.8,0.15670677361853833,0.6185160427807486,1,0.09821428571428571,0.0,0.29607250755287007
787,808,808,How to generate a thousand master plans: A framework for computational urban design,"The current process for the design of an urban master plan typically involves a team of architects and urban planners that conceive and develop a handful of schemes based on zoning requirements with the help of CAD software. They may intend for the plan to achieve a set of performance goals (economic, environmental, etc.), but quantitative performance analysis is rarely conducted early and consistently through the design process. This makes it difficult to understand the full range of approaches that are possible on the site, and the relative performance of each scheme. In order to best accommodate rapid urbanization while making cities more sustainable, livable, and equitable, designers must utilize quantitative tools to make informed decisions about their designs. Computational design techniques have been successfully used at the building scale to test numerous designs and quantify their performance, but are challenging to apply at the urban scale due to increased computational expense, difficulty in limiting inputs, and more stakeholders involved in the process. This paper outlines a methodology developed in practice for applying computational design at the urban scale through four steps: 1) Define Inputs & Design Space 2) Procedural Geometry Generation, 3) Performance Evaluation and 4) Analysis, Communication & Stakeholder Engagement to generate and test thousands of master planning scenarios.",121646280,KPF,New York,United States,['1705'],35.166666666666664,0.17083333333333334,0.4329545454545455,1,0.12236286919831224,0.05907172995780591,0.3333333333333333
788,810,810,Tourism clusters identification procedure and specifics,"This paper intended to show the scope and complexity of the tourism clusters problem. Processes of clusters formation and functioning are of great interest for researchers in Russian Federation and abroad, especially considering governments' activity in this sphere. Key problems are as follows: Which economic activities have to be included in tourism cluster as supplementary? What are the problems of their turnover estimation? What are the criteria of tourism cluster formation? All of them have a long history, but currently are still far from being solved, among other things, we still need to calculate a share of complementary industries' sales and resources to be included in tourism activity and ""wild"" tourism turnover estimation. We propose to run a specialized survey to assess the economic effects of non-organized tourism to solve these problems. In terms of theory, it remains to be determined, what are criteria for local group of firms in tourism and complementary activities that make them arrange into a cluster considering the economic benefits of geographical concentration in certain location. Widely used procedure of cluster maturity estimation was applied to Russian Federation regions in comparison with world-class tourist clusters in Europe. We got an evidence of biases in cluster identification because of country and type of tourism specifics as well as limitations of estimating procedure. The paper shows that these problems are typical for not only Russian Federation but foreign countries too, including those with well-developed tourism industry. Clusters influence at companies efficiency is at least contradictory both from the side of demand and supply. Tourist product, resources and business processes specifics makes it much harder to extract cluster benefits and gives privileges first to large companies.",60105103,Moscow Polytechnic University,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",27.8,0.054662698412698385,0.4034722222222223,1,0.1,0.02258064516129032,0.27631578947368424
789,811,811,POST-DISASTER RECOLONIZATION of MANGROVE FORESTS with A STOCHASTIC AGENT-BASED MODEL,"Mangrove forests in the Philippine coastline are susceptible to severe damage due to tropical storms. These mangrove forests provide a home for other plants and animals as well as providing resources for people living in coastal areas. Thus, it is important to promote proper conservation and judicious replanting in areas affected by storms. Since different species vary on their tolerance to physical conditions such as water salinity and soil composition, the appropriate genus must be used in reforestation efforts. This study aims to model the change in soil composition due to the introduction of a non-native species, Rhizophora mucronata, and restoring soil condition to aid recolonization of the existing native species, Avicennia and Sonneratia. The study uses an agent-based model for the prediction of the regenerative behaviour of mangrove stands consisting of the native species and the planted or non-native species in a fragmented habitat, with the use of spatio-temporal coloured noise to simulate stochastic seedling dispersal and subject to storm damage. The model uses Salmo and Juanico's model for mangrove growth. Stochastic experiments were carried out in a shoreline habitat with an existing native population of varying ages and a larger population of planted, non-native seedlings. The GIS data of Bangrin Marine Protected Area was used to simulate the recovery trajectory of the stand after typhoon Chan-hom of 2009.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],24.444444444444446,0.032575757575757584,0.4364718614718615,1,0.10040160642570281,0.05220883534136546,0.28270042194092826
790,812,812,VALIDATION and COMPARISON of FINE-MODE AEROSOL OPTICAL DEPTH PRODUCTS between MODIS and POLDER,"Fine-mode aerosol usually comes from anthropogenic emissions. The fine-mode aerosol optical depth (AODf) is an important parameter for estimating the particulate matter with an aerodynamic diameter little than 2.5 μm (PM2.5). Compared to the ground-based observations, AODf products from satellite remote sensing have an advantage of high spatial coverage, which is suitable for monitoring the air quality at a regional or global scale. Up to now, AODf products have been released by several sensors, such as the single-angle multi-spectral intensity sensor MODIS and multi-angle multi-spectral polarization sensor POLDER, then what're the different performances of AODf products from them? In this study, the different spatial resolution AODf products respectively from MODIS latest Collection 6.1 (C6.1, 3 and 10 km) and POLDER latest level 2 version 1.01 (L2, 18 km) were firstly compared with each other in Beijing-Tianjin-Hebei (BTH) domains. Then those products were validated against the ground-based AERosol RObotic NETwork (AERONET) measurements, where has been suffering the severe air pollution since decades ago. The comparison of yearly averaged AODf products between MODIS and POLDER shows a good consistency on the spatial distribution, the higher spatial resolution products of MODIS show more details, both low values of AODf appeared in the northwest area with small population and industry, high values appeared in the southeast area with lots of cities, industries, and large population. However, the whole yearly AODf average values of MODIS are higher than that of POLDER. The results of validation against AERONET show that the accuracy of AODf products at 865 nm from POLDER (R Combining double low line 0.94, RMSE Combining double low line 0.05) is high than that at 550 nm of MODIS (3 km: R Combining double low line 0.69, RMSE Combining double low line 0.32; 10 km: R Combining double low line 0.76, RMSE Combining double low line 0.3). In this study, the performance of different spatial resolutions AODf products retrieved from the intensity (MODIS 3 and 10 km) and polarized sensors (POLDER 18 km) were evaluated. Those results not only have a great significance to provide users amore appropriate choice of the AODf products in the BTH region but also display that the accuracy and spatial resolution of MODIS and POLDER AODf products need to be improved.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1710'],37.2,0.11208603896103896,0.3978841991341992,1,0.06502242152466367,0.08295964125560538,0.4460093896713615
791,813,813,Interpreting non-flat surfaces for walkability analysis,"Through laser scanning, GIS data, new manufacturing methods, and complex designs, analysis of terrain in relation to human mobility is becoming ever more necessary. While standards for wheelchair ramps exist, they rarely show the entire picture, nor do they account for surface variation beyond a single axis. Although graph creation techniques in CAD exist for flat terrain, directional edge weights accounting for this variation are lacking. In this paper, a summary of research from both biomechanics and architecture in relation to surface walkability is presented, followed by a review of creation methods for a searchable graph representing an environment in CAD. A novel graph creation method that can respond to variations in surface height for walkability analysis is presented, where the edge weights of the graph are based on surface condition of parent-child height variations.",60022904,New Jersey Institute of Technology,Newark,United States,['1705'],27.0,0.0989935064935065,0.5168831168831169,1,0.09210526315789473,0.019736842105263157,0.28
792,814,814,SPATIAL-TEMPORAL CHARACTERISTICS of the AEROSOL OPTICAL DEPTH (AOD) DERIVED from LONGTERM (1980-2018) MERRA-2 over GUANGDONG,"This paper presents and compares the aerosol optical depth (AOD) spatial-temporal characteristics over five subsets in different locations of Guangdong, as well as Hong Kong and Macau (GDHM) since reform and opening-up. By means of GIS analysis tools and subset the onward MERRA-2 monthly mean value aerosol reanalysis dataset to the size of study area, the results reveal that the yearly mean AOD over the whole GDHM ranged from 0.18 to 0.69 during 1980 to 2018. The field average of AOD in five chosen areas approached to 0.40 and appeared linearly increased at 0.0077 per year. All the five selected areas reached their yearly mean AOD peaks at 2007. The field average AOD increased rapidly at 0.028 per year from 1997 till 2007 then appeared decreasing oscillation in a linear slope 0.0109 per year since 2007. But the average AOD of 2010-2018 is higher than the former three decadal averages. Comparing the former and the latter two decades, the high yearly mean AOD value clusters have moved from northern parts of Guangdong to central north Pearl River Delta, where also appeared more apparent AOD yearly change among the other three parts since late 1990s. Only six yearly mean AOD over southern cities of Pearl River estuary were lower than east or west comparing parts in 1980s. Eastern part of Guangdong stayed the lowest yearly mean AOD region in 21years of the past 39 years. Central, southern and western of GDHM had 36 years while northern and western of GDHM had 37 years their AOD values during February to April were the high values of the year.",60028965,Guangzhou Institute of Geochemistry Chinese Academy of Sciences,Guangzhou,China,['1710'],26.6,-0.057931034482758624,0.3958620689655172,1,0.07560137457044673,0.12371134020618557,0.37894736842105264
793,815,815,Predicting the outcome of judicial decisions made by the European court of human rights," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In this study, machine learning models were constructed to predict whether judgements made by the European Court of Human Rights (ECHR) would lead to a violation of an Article in the Convention on Human Rights. The problem is framed as a binary classification task where a judgement can lead to a “violation” or “non-violation” of a particular Article. Using auto-sklearn, an automated algorithm selection package, models were constructed for 12 Articles in the Convention. To train these models, textual features were obtained from the ECHR Judgment documents using N-grams, word embeddings and paragraph embeddings. Additional documents, from the ECHR, were incorporated into the models through the creation of a word embedding (echr2vec) and a doc2vec model. The features obtained using the echr2vec embedding provided the highest cross-validation accuracy for 5 of the Articles. The overall test accuracy, across the 12 Articles, was 68.83%. As far as we could tell, this is the first estimate of the accuracy of such machine learning models using a realistic test set. This provides an important benchmark for future work. As a baseline, a simple heuristic of always predicting the most common outcome in the past was used. The heuristic achieved an overall test accuracy of 86.68% which is 29.7% higher than the models. Again, this was seemingly the first study that included such a heuristic with which to compare model results. The higher accuracy achieved by the heuristic highlights the importance of including such a baseline.",60118335,The ADAPT Centre,Dublin,Ireland,['1700'],19.53846153846154,0.09927536231884056,0.3811076604554865,0,0.10702341137123746,0.06688963210702341,0.4006849315068493
794,816,816,A parametric workflow to conceive facades as indoor and outdoor climate givers,"Within the bounds of climate change, it is legitimate to expect that buildings will be developed to mitigate and adapt to environmental transitions. In this context, façades are essential as they are not the only determinants in reducing energy demand, but could increase the livability of indoor and outdoor spaces. Being that there are several simulation tools which allow indoor comfort simulation, and a few that enable outdoor comfort simulation, it is rare to find tools that allow simulation of both. Filling this particular gap, the present research develops a Ladybug Tools based digital workflow, which simultaneously accounts for the indoor and outdoor thermal and visual effects of façade designs. Once created, the workflow is tested and calibrated against indoor and outdoor Mean Radiant Temperature and Illuminance measurements, via the use of a test room equipped with sensors. It is concluded that the workflow is a reliable tool for the design of façades intended as a dual climate giver, for both the indoor and the outdoor.",106793179,Royal Danish Academy,Copenhagen,Denmark,['1705'],27.66666666666667,0.004924242424242422,0.32916666666666666,1,0.12087912087912088,0.038461538461538464,0.2802197802197802
795,817,817,Study on contractors performance in construction," All rights reserved.The construction industry is avital part of every economy and that performance assessment holds the key to its achievement of national socio-economic goals. Construction projects and its success are closely related to contractors. The selection of a proper construction contractor rises chances of successful completion of a construction project. It can also fulfill the client aims, and keep the schedule of the cost, time and quality. Contractor performance can be well-defined by the level and quality of projects delivered to clients. Comparison of contractors‘ performance can provide robust benchmarks for contractors and help to identify ways towards performance improvement. The study is to provide a method for evaluating the performance of contractors on Government and private construction projects. Questionnaires are to be designed depending upon the various factors which affect the contractors‘ performance in Government and private sector projects and to be distributed to various construction companies. Then the responses are yet to be received and the survey results are to be analyzed using SPSS (Statistical Package for the Social Sciences) software and the frequency of the responses can be found.",60104042,Nandha Engineering College,Erode,India,['1700'],20.444444444444443,0.10833333333333336,0.4266666666666665,0,0.11707317073170732,0.02926829268292683,0.29797979797979796
796,818,818,Regional differentiation of digital economy development in the Russian Federation,"The present stage of the world economy development is marked by building and sustaining the digital economy, which, driven by the effective use of information and communication technology (ICT), is making unprecedented advances and eventually overtakes the traditional economy. Harnessing the digital economy technologies is particularly relevant for Russia, since the country needs to move from its current resource-oriented national economy model towards the innovative one while facing severe economic sanctions. The Russian Federation is characterized by uneven socio-economic development of its constituent entities (regions). The authors attempt to test their hypothesis suggesting regional differentiation of indicators of the digital economy development. In view of ICT application as the primary driver of the latter, the article analyzes statistical indicators related to ICT usage by organizations and the population across the Russian regions. The assessment technique employed includes the calculation of range and relative range, variance, standard deviation, and coefficient of variation. It has been found that the digital economy development across the Russian regions is rather even: for all estimated indicators except one, the coefficient of variation has a value of less than 0.33. At the regional level, greater disparity is observed in the use of digital economy technologies by the population, while organizations demonstrate higher homogeneity. The Russian regions which are leading or lagging behind in terms of the digital economy development are clearly visible. The proposed methodology provides an efficient tool for prompt and accurate identification of problematic areas in the digital economy development, which offers important implications for policymakers and practitioners at all levels.",60023408,Volga State University of Technology,Yoshkar-Ola,Russian Federation,"['1712', '1709', '1707', '1705']",25.7,0.11127450980392156,0.3068627450980392,1,0.09722222222222222,0.013888888888888888,0.24647887323943662
797,819,819,Creating a Blue Economy: Research and innovation partnerships to accelerate the development of ocean-related industries,"The Blue Economy can be a driver of European growth, through the development of new competences and activities that enable a sustainable exploitation of ocean resources. This paper assesses the directions followed by the research and innovation activities performed by Portuguese organisations in the fields encompassed by the ""Blue Economy"", at the light of national and EU strategies. It analyses the projects developed by Portuguese actors in the context of European framework programmes to uncover: the areas privileged - namely the relative importance of emerging areas vs. new advances targeting established ones - and the relative position of different types of organisations in the developments taking place. The results point to stronger efforts in system domains related to marine resources and the marine environment and in some industry oriented domains. Among the latter, emerge new industries such as marine biotechnology and marine renewable energies and established industries exploiting marine living resources (fisheries, aquaculture). The results highlight the prominent position of research organisations in both new and established areas, as well as the relevant position of new technology intensive firms, in areas that require the development of application-oriented activities, where they often intermediate between research and industry. The results suggest that the international cooperation favoured by these projects permitted to open-up the national system, contributing to broaden the organisations' knowledge bases and to extend their international networks.",60106051,Universidade de Lisboa,Lisbon,Portugal,"['1712', '1709', '1707', '1705']",28.25,0.09913419913419913,0.3272727272727273,1,0.12749003984063745,0.01593625498007968,0.3481781376518219
798,820,820,An approach for evaluating the information content of remote sensing images," CC BY 4.0 License.Due to being affected by the rapid development of open science and the increasing popularity of mobile devices (e.g., smartphones), remote sensing data as frequently used data sources are broadly applied to our daily life. At the same time, remote sensing data collection also presents a trend of popularization. To improve the utilization efficiency and availability of the obtained diversified remote sensing data, we propose a novel evaluation method based on information theory and scatterplot mapping model, i.e., geometrical mapping entropy (GME). The goal is to construct a unified model of measurement to be much more effectively and accurately evaluate the information content and quality of remotely sensed imagery. Different experimental data are used to verify the performance of the proposed method, i.e., a group of the dataset that contains different four types of images; the other group of image data contains the images with different modalities and different imaging times (2016-05, 2017-08, 2018-04, and 2018-06). Experimental results indicate that the proposed approach can better characterize the spectrum features and spatial structural features contained in images and visual perception information. Additionally, it can also reflect the difference in the quality of different modality images, especially the effect for the images that contain clouds or poor lighting conditions, is better.",60017060,Central South University,Changsha,China,['1710'],30.42857142857143,0.0775,0.42983333333333335,0,0.09561752988047809,0.00796812749003984,0.3125
799,821,821,Impact of industry and export on the biomass resources,"In this paper, we have proposed and analyzed a nonlinear mathematical model to study the pattern of depletion of forest biomass due to industry and export. The existence of equilibria and their local stability under certain conditions have been discussed. We have carried out the Hopf-bifurcation analysis by considering government control as a bifurcation parameter as government vigilance for the protection of forest biomass has been remained an important factor. Moreover, the direction of Hopf-bifurcation is determined using the center manifold theorem. We have obtained the threshold values of certain constraints (government control) imposed on export and industry growth, for the sustainable development of forest biomass. Finally, all the analytical findings are properly validated using numerical simulation.",60113584,"Khalsa College, Amritsar",Amritsar,India,['1700'],19.5,0.06706349206349208,0.4130952380952381,1,0.09774436090225563,0.015037593984962405,0.27906976744186046
800,822,822,Minimum wage and minimum work hour in India,". All rights reserved.Research on wage fixing in the informal sector is totally neglected and any information in this regard is not available for India. It is widely accepted and known in theories and in general that wage in informal sector is determined by demand and supply of informal labour market. But fixing of wages in informal sector remains a kind of black hole. The paper examines the minimum work hour and over-time, knowledge and receipt of minimum wage in the construction sector in India. The result of the paper shows low paid over time job and very low level of overtime wage, hesitation in asking overtime wag end majority of the workers do not know about the minimum wage.",60079433,Madan Mohan Malaviya University of Technology,Gorakhpur,India,['1700'],20.0,0.02291666666666666,0.5091666666666665,1,0.0916030534351145,0.015267175572519083,0.16535433070866143
801,823,823,The digital transformation of irish non-profit organisations," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Irish Non-Profit Organisations have embarked on an exciting Digital Transformation journey in support of the sector's wider reform and renewal agenda. This coincides with the ambitious plans of the technology industry to deploy its Artificial Intelligence capabilities to tackle societal problems. This research investigated the current in-use experiences of AI-based and related systems in various non-profit organisations both in Ireland and internationally to determine how a non-profit organisation can become more effective and strategic in its journey to fully leverage technology. The qualitative research approach employed a series of exploratory practitioner-based interviews guided by Grounded Theory methodology to examine the technology barriers and challenges faced by the non-profit sector. The findings revealed some inspirational exemplars of practice but also found that a comprehensive transformation of the sector facilitated by emerging technologies remains outstanding, frustrated by challenges including limited funding, resource constraints, skills gaps, donor reporting requirements and sectoral tendencies to 'reinvent the wheel'. The practitioner interviews also highlighted discontinuities and a lack of synergy between the digital transformation ambitions of the sector and the Corporate Social Responsibility programmes of the technology sector.",60011149,Trinity College Dublin,Dublin,Ireland,['1700'],32.33333333333333,0.09536340852130326,0.4439223057644109,0,0.12612612612612611,0.08108108108108109,0.3894230769230769
802,824,824,Technology adoption and it’s impact over paddy farming: An empirical analysis,". All rights reserved.Mechanisation practices have been growing in rapid phase in the Indian paddy farming. The researcher emphasised over the different paddy farming practices such as, primary tillage, secondary tillage, plantation, intercultural operations and harvesting and threshing. The researcher tested the impact of mechanisation in the various paddy farming practices. Researcher deployed the paired t-test and the results are presented. The study has been carried in Tenali revenue mandal located in Guntur district of Andhra Pradesh state in India.",114211054,Vignan’s Foundation for Science,Guntur,India,['1700'],13.333333333333336,0.02000000000000001,0.4800000000000001,1,0.0967741935483871,0.053763440860215055,0.3595505617977528
803,825,825,Integration of safety assessment in bim for transportation infrastructure,"Effective and safe transportation infrastructure presents one of the crucial conditions for functional society. Its ceaseless development and construction can be taken as a proof of its importance even despite the corresponding financial and time demands. The complexity and scale of the projects related to transportation infrastructure presents an ideal field for implementation of the BIM approaches. However, it is necessary to implement the BIM to the whole life cycle of the transport structure, especially not only to the pre-investment and investment phases but also to the operation and maintenance. For every road infrastructure, it is important to observe the performance of the road, behaviour of road users and evaluate the resulting safety risks, to be able to correspond with adequate and effective measures and to secure sufficient level of safety. The paper aims to present an implementation of the road safety aspects and statistics into the processes of BIM applications and strategies, which are prepared on the base of Government Resolution No 958, on the importance of the Building Information Modelling (BIM) in the Czech Republic. The accident statistics, safety audits and inspections presents a valuable source of information that should be adequately implemented with the BIM processes.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,['1710'],28.42857142857143,0.21481481481481488,0.6217592592592593,1,0.08256880733944955,0.05963302752293578,0.24074074074074073
804,826,826,Economic aspects of national security,"Ensuring the security of the country's economy is an element of national security strategies of the state. With the development of digital technologies, threats that can harm the economy of the company and the state as a whole are transformed accordingly in economic relations. The aim of the work is to find reliable arguments confirming the reality of threats to national security, the source of which was the shadow activity of individuals in the digital economy. The object of the study were digital technologies in the financial sector, the subject of financial flows of individuals. Statistical information on transactions made in the banking sector with the use of electronic means of payment was used as an empirical base. The dynamics and structure of payments in the banking sector are studied. Applying the methods of comparison, it was found that the number of questionable transactions was decreased, and the structure of cashing money for the purposes of the shadow economy was changed due to an increase in the share of cashing through online stores in the banking sector. The number and volume of operations carried out with the use of plastic cards has increased. The most significant increase (9.7 times) in the volume of other transactions made by individuals using plastic cards was found. It is concluded that there are weighty arguments confirming the reality of the threat of expansion of the shadow sector of the economy due to the complexity of identifying and countering financial flows sent by individuals to the shadow sector of the economy or legalizing shadow income. At the same time, reliable data have not been found to reliably assess the threat of crimes committed by individuals in the digital environment to the economic and national security of the Russian Federation. Indirect data indicates that there was no noticeable transition of financial flows into cryptocurrency payments in Russia.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",25.91666666666667,-0.028985507246376812,0.2851449275362319,1,0.09036144578313253,0.009036144578313253,0.22590361445783133
805,827,827,Grid networks: A scheduling method to improve the time and cost of executing tasks in grid environment and management,"Grid was a technology that allows us to remotely access various types of resources by using communication infrastructure and computer networks, and by utilizing the limitations of the concepts and features of distributed systems. This study aimed to introduce an algorithm for improving scheduling in grid networks, which in turn results in lower cost. As the results show, the MOPSO algorithm improved the NSGA-II algorithm in all the problems in both the target time function and the target function. This improvement is between 10% and 14%. Generally, this algorithm has achieved a better response by 12.59 percent. Also, according to the objective criteria, other algorithms such as bat algorithm, firefly algorithm and ant colony algorithm have improved in simulation of the algorithm.",60109343,University of Samarra,Samarra,Iraq,['1700'],20.33333333333333,0.04642857142857143,0.3821428571428571,1,0.10071942446043165,0.05755395683453238,0.3357664233576642
806,828,828,Effective system of payment for scientific work in conditions of digitalization,"The desire of states to occupy leadership positions in the number of researchers is a reflection of the struggle for technological advantage in terms of digitalization. Russia participates in this competition, which is reflected in the program documents aimed at supporting the development of the scientific and technical sphere, in particular, in the state program ""Scientific and Technological Development of the Russian Federation"", adopted in 2019. In accordance with its targets, Russia by 2022 should take fourth place in the number of researchers in full-time equivalent in the world, and, at a minimum, keep this position on the planned horizon until 2030. The state program documents on the development of the scientific and technical sphere provide for the use of a set of tools aimed at increasing the number of researchers in the Russian Federation. The purpose of this article is to evaluate the possible contribution of these tools to the achievement of goals and justify proposals to improve the effectiveness of state support measures for the development of the scientific and technical sphere under digitalization conditions. In the course of the study, projections of changes in the number of researchers in Russia were made as well as in countries competing with it for leadership in this indicator until 2024, which made it possible to determine the growth rates required to achieve the goal set in the state program. Based on the expert analysis of program documents, the potential contribution of state support measures to the achievement of the target indicator was assessed. In view of the insufficient effectiveness of the considered instruments of the national project ""Science"", measures were proposed to reform the remuneration of Russian scientists, taking into account the need to introduce an effective contract reflecting the requirements of the compliance of the working skills and competencies of scientific workers with the digital economy.",60120710,"Russian Research Institute of Economics, Politics and Law in Science and Technology (RIEPL)",Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",38.375,0.07261904761904761,0.3345238095238096,1,0.09281437125748503,0.03293413173652695,0.2289156626506024
807,829,829,Connecting open systems of communicating finite state machines,"Communicating Finite State Machines (CFSMs) are an established model for describing and analysing distributed systems whose concurrently running components communicate via FIFO-channels. Systems of CFSMs are usually considered as closed systems which do not provide access points for communication with the environment. In our study we relax this view such that certain components of a CFSM system can be looked at as describing the behaviour of the environment interacting with the system. They are considered as interfaces and if two systems posses compatible interfaces (according to a natural notion of compatibility) they can be connected. We propose a novel connection mechanism such that interface CFSMs are replaced by automatically generated “gateway” CFSMs, enabling messages to be exchanged between the systems. As a crucial outcome of our approach we prove that, under mild assumptions, if CFSM systems are connected in such a way a number of important communicating properties is preserved: deadlock-freeness, strong deadlock-freeness, orphan-message freeness, freeness of unspecified receptions, and progress. The communication properties we consider are those enjoyed by CFSM systems obtained by end-point projections of certain global type formalisms used in the field of asynchronous multiparty session types. To this end we introduce a parametric syntax to compose global types via interface roles. As a consequence of our preservation results we get for free that composed projected systems enjoy the communication properties.",60028717,Ludwig-Maximilians-Universität München,Munich,Germany,"['1712', '1703']",24.88888888888889,0.15560224089635855,0.5074229691876749,1,0.14396887159533073,0.0311284046692607,0.3319838056680162
808,830,830,Investors’ perceptions towards the perceived risk in mutual fund selections: An empirical analysis,". All rights reserved.The prime objective of this research paper is to diagnose the mutual fund selection behaviour of the customers. The researcher considered the perceived risk as the moderating variable to determine the investment decisions towards the mutual fund selections. Furthermore, the researcher identified intrinsic fund qualities, credibility of firm, competent performance and tangible benefits are considered as the independent variables of the study. The statistical analysis revealed the mediating impact of perceived risk on investment decision over the proposed independent variables.",60104649,Vignans Foundation for Science Technology and Research University,Guntur,India,['1700'],16.6,0.06,0.2833333333333333,1,0.13043478260869565,0.0,0.26666666666666666
809,831,831,A stable non-interleaving early operational semantics for the pi-calculus," Our starting point is the non-interleaving semantics given for CCS by Mukund and Nielsen, where the so-called structural (prefixing or subject) causality and events are defined from a notion of locations derived from the syntactic structure of the process terms. We conservatively extend this semantics with a notion of extruder histories, from which we infer the so-called link (name or object) causality and events introduced by the dynamic communication topology of the pi-calculus. We prove that the semantics generalises both the standard interleaving early semantics for the pi-calculus and the non-interleaving semantics for CCS. In particular, it gives rise to a labelled asynchronous transition system unfolding to prime event structures.",60030840,Københavns Universitet,Copenhagen,Denmark,"['1712', '1703']",27.75,0.016666666666666666,0.20555555555555552,0,0.1044776119402985,0.03731343283582089,0.30578512396694213
810,832,832,Retweet Prediction Using Context-Aware Coupled Matrix-Tensor Factorization,"Retweet behavior plays an important role in the process of information diffusion on social networks. Although many researches have been studied the problem of retweet prediction, these studies ignore the important characteristic of multiple contextual dimensions for user’s decision in the modeling process. To this end, we propose a novel multiple dimensions retweet prediction model based on context-aware coupled matrix-tensor factorization (RCMTF). This model first introduces a reference tensor based on the historical retweet behavior patterns to alleviate the problem of data sparsity, and then constructs three contextual factor matrices from user and message and influence dimensions on basis of network structure, message content and historical interactions to further improve the prediction accuracy. Finally, we collaboratively factorizes these contextual factors under matrix and tensor factorization models framework for predicting user’s retweet behaviors. Extensive experiments are conducted to demonstrate the effectiveness of the proposed method on two real-world datasets. The results show that our proposed model outperforms the state-of-the-art methods.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],22.714285714285715,0.11666666666666667,0.4,1,0.10695187165775401,0.026737967914438502,0.3107344632768362
811,833,833,Breast cancer classification using GLCM and BPNN,"Among all the cancer in women, breast cancer is the most common and deadliest cancer. In 2018, there were 22.692 Indonesian women dead because of breast cancer. Until now, the main cause of breast cancer is still unknown. However, the possibility of recovery and survival rates can be increased through early detection. One of the most efficient ways of early detection is through mammography. Mammography produces images called mammograms. The main objective of this paper is to develop Computer Aided Diagnosis (CADx) system that can help radiologist determine breast cancer cases based on mammogram image. In this paper, a combination of the Gray-level Co-Occurrence matrix (GLCM) and Backpropagation Neural Network (BPNN) is used to classify normal-abnormal patient based on mammogram image. Using mammogram image provided by Mammography Imaging Analysis Society (MIAS), a test for the proposed method was concluded. The result was, accuracy 94.06%, Sensitivity 90.16% , and Specificity 95.57%.",60069392,Brawijaya University,Malang,Indonesia,['1706'],15.0,0.09333333333333332,0.3866666666666666,1,0.0918918918918919,0.0972972972972973,0.441340782122905
812,834,834,Analysis of the Russian digital economy profile,"Given the speed of the changing landscape and the requirements In the article the problems of the modern global business landscape associated with the third wave of capitalism, digital transformation and discontinuity, the dominant role of the consumer in emerging markets, Hyper drive business, moving away from hierarchic decision-making and the transition to a market-oriented and seamless network structure, etc. are highlighted. Significant indicators of ""Hierarchical changes Digital Economy Real Gross Output by Industry"" determining the global economic profile of Digital Economy are revealed. In the article the necessity of transformation of the economic profile of Russia in the direction of sustainability that will allow the use of promising technological approaches for the conservation and sustainable dynamics of development are proved. This is fully in line with the process of fundamental changes to achieve maximum economic growth with the use of innovative technologies, implemented within the framework of the concept of the limits of the growth of The Club of Rome. As a rule, the processes of change can be either gradual through simple improvements or more radical - associated with structural changes. The application of radical changes is associated with the need to provide reliable, proven knowledge. Technological foresight should become less expensive, maintaining high quality. The natural candidate for this role are ""Big Data"", ""Bitcoin"", ""Blockchain"" - attributes of Digital Economy. The conducted analysis of the Russian digital economy profile, based on the assessment of changes in big data ""Rank and Score"" and ranking by ""Indicator"" and ""Index"", revealed the most sensitive elements of the blockchain of the Russian digital economy profile. Big data ""Global Innovation Index 2018"" (""World international intellectual property organization"") were used for the analysis. The cumulate analysis of big data changes ""Rank and Score"" and ranking by ""Indicator"" and ""Index"" allowed depicting the scheme of the the blockchain of the Russian digital economy profile. Considering the dominant position of big data ""Indicator"" - ""Innovation Output Sub-index"", as well as ""Strength"" and ""Weakness"", the dominant factors that determine the blockchain of the Russian digital economy profile were identified. Among the subsidizing factors the most risk-taking is Domestic ""credit to private sector and market scale"" and ICT ""use and business model creation"" were pointed out. The Russian resource-based economy is highly dependent on foreign capital and technology, especially at the stage of changing over from the fifth to the sixth wave of the Kondratiev wave. At the same time the blockchain of the Russian digital economy profile highlights the essential role of Tertiary ""education and enrolment"". Most Russian firms urgently need addition to the stock human (intellectual) capital. In Russia that exhausted by long-term expectations of economic stability, the population and households take an interest in economic culture (""Printing, publications and other media output"").",60011928,Chuvash State University,Cheboksary,Russian Federation,"['1712', '1709', '1707', '1705']",25.444444444444446,0.042267759562841525,0.2553903200624512,1,0.07246376811594203,0.06159420289855073,0.34444444444444444
813,835,835,RESEARCH on PM2.5 CONCENTRATION COMBINATION FORECASTING MODEL BASED on COR-SVM,"PM2.5 is a pollutant that can enter the lungs, threatening human health and affecting people's living and traveling. In this paper, we use multivariate linear regression, support vector machine and their combined prediction method to predict the concentration of PM2.5. It is significant for the convenience of healthy life. This paper is based on a series of meteorological data such as O3 concentration, CO concentration, SO2 concentration, PM2.5 concentration and PM10 concentration from 2014 to 2018 in Beijing. By calculating the correlation coefficient between the concentration of PM2.5 and the concentration of the other four components, the multivariate linear regression equation was fitted by using the correlation coefficient with high correlation as the factor of multiple linear regression. Then we use support vector machine regression prediction method to predict the concentration of PM2.5. The combined prediction method is obtained by weighing the two prediction results. It is found that the prediction method of support vector machine is better in dealing with large-scale and small sample data prediction, and the multi-linear fitting method is better in processing short-term prediction. The combined prediction results based on correlation coefficients combine the advantages of the two prediction methods, and the prediction results are more reasonable.",60024045,Nanjing Agricultural University,Nanjing,China,['1710'],22.33333333333333,0.22000000000000006,0.453076923076923,1,0.09292035398230089,0.05309734513274336,0.2409090909090909
814,836,836,Aerial thermography as a tool to inform building envelope simulation models,"The building sector consumes more than 33% of global energy use and around 50% of electricity consumption, and is responsible for one third of global carbon emissions [1]. Envelope and windows alone impact over 50% of energy loads in buildings [2]. Thus, understanding building envelopes’ thermal performance is critical to the application of energy efficiency retrofits. Through detecting main envelope thermal deficiencies and areas of deterioration, suitable energy management measures can be effectively determined. While simulation models are considered as reliable tools to understand building energy performance, they rely significantly on assumptions related to envelope performance [3,4]. The main contribution of this paper stems from the proposed analysis framework, which integrates Unmanned Aerial Vehicles (UAVs) equipped with thermal cameras in estimating thermal transmittance properties of existing building envelope, specifically opaque walls, and using these data to calibrate energy simulation models for better predictions. Results revealed a significant increase in the accuracy of heating energy use prediction during winter months. With the proposed workflow, simulation errors were reduced from over 20% to less than 1%.",60022195,Massachusetts Institute of Technology,Cambridge,United States,['1705'],21.75,0.21777777777777774,0.4522222222222222,1,0.11274509803921569,0.0196078431372549,0.38235294117647056
815,837,837,Comparison of EMG activity using spectrum indices from biceps femoris muscle during treadmill walking,"Under dynamic exercise, the muscle tension is proportional to EMG activity[1], and EMG indices which represent muscle activity can be classified by magnitude indices in time domain and spectrum indices in frequency domain[2-4]. The purpose of this paper is to compare the activities of EMG indices during dynamic exercise, and to examine the spectrum index using spectrum moments which is better and more sensitive than traditional spectrum indices. Ten healthy subjects walked on the treadmill at 4.5 km/h during 30 seconds, and EMG signals are measured from biceps femoris muscle. EMG indices are extracted such as magnitude index including root mean square (RMS), and spectrum indices including mean power frequency (MPF), high-to-low ratio (HLR) and HLR using spectrum moments (SM-HLR). Experimental results shows that the correlation coefficients are not high between RMS and the other spectrum indices but very high between spectrum indices above 0.89, and the variation coefficient of logarithmic SM-HLR is above 3 and 2 times higher than those of logarithmic MPF and HLR, respectively. Therefore, SM-HLR can be a high-sensitive spectrum index to reflect changes of activities of biceps femoris muscle due to walking.",60024495,Catholic Kwandong University,Gangneung,South Korea,['1700'],31.16666666666667,0.060150000000000016,0.42751666666666666,1,0.07894736842105263,0.13157894736842105,0.3425925925925926
816,838,838,Developing key competencies in the digital economy for students in higher education,"Given the speed of the changing landscape and the requirements for specialist knowledge, the content of many higher education programs becomes obsolete even before they are completed. The study was motivated by the fact that the traditional model of education, aimed only at transmitting knowledge, is hopelessly outdated. The purpose of this study is to review existing approaches and models of education in higher education institutions aimed at developing digital competencies, social and emotional skills for success in the new digital world. The object of research is the Ryazan Institute (branch) of the Moscow Polytechnic University. To achieve this goal, we applied the following methods: observation, description, experiment and comparison. The lack of special skills for effective interaction in the digital environment does not allow students to actively apply and learn new technologies. Digital competency-based education in digitalization will help solve various problems in the use of information and communication technologies. The digitalization of the economy is manifested in a change in the relationship between the main participants in business, science and education, and is able to increase the intellectual component in all types of governance: public administration, social management, education management, business management. The speed of transformation in the digital economy affects the target vectors and technologies for the development of education. Entire groups of professions die off, new ones appear, and those that are preserved constantly require ""updated"" specialists. There are a number of forecasts, such as the McKinsey Analytical Report, which determine the demand for future specialists in the new reality of the digital economy. According to the federal project ""Personnel for the Digital Economy"", the urgent need for specialists with digital competencies requires the creation of conditions for their accelerated training. This educational track is supposed to be implemented in a pilot mode with the participation of the Ryazan Institute (branch) of the Moscow Polytechnic University with a separate regulation, the study of all the possibilities and limitations in the context of the operational passage of educational programs implemented for the tasks of the digital economy and built personalized to the capabilities and needs of each citizen with using independent evaluation and recognition of the results.",124058893,ANO Digital Region,Ryazan,Russian Federation,"['1712', '1709', '1707', '1705']",27.69230769230769,0.09750249750249748,0.3253746253746254,1,0.09429280397022333,0.04218362282878412,0.27680798004987534
817,839,839,Fuzzy neural network with intensity adjustment and median filter for classifying cervical cancer,"In this paper, we develop a fuzzy neural network model for classifying cervical cancer. A fuzzy neural network is a specific feed forward neural network which processes fuzzy variables. The fuzzy neural network model gives benefits, since the fuzzy logic accommodates cognitive uncertainty, and neural network allows learning and generalization. The cervical cancer is classified using colposcopy images. We also propose image preprocessing of intensity adjustment and median filter to enhance the contrast and to shrink the noise of the image. The parameters extracted from the image by the grey level co-occurrence matrix method are designed as the original inputs of the fuzzy neural network model. These inputs are in crisp forms, so they require to be changed in fuzzy forms. In this study, we use trapezoidal fuzzy number and OR operation. The fuzzy neural network is implemented to the original colposcopy images, to the colposcopy images with the intensity adjustment, with the median filter, and with the combination of both. The results demonstrate that the fuzzy neural network models have the same performance to all types of images on training data and deliver the best performance on the images with the combination of intensity adjustment and median filter on testing data.",60087601,Universitas Negeri Yogyakarta,Yogyakarta,Indonesia,['1706'],20.2,0.2785714285714286,0.36666666666666653,1,0.09009009009009009,0.0,0.21818181818181817
818,840,840,Research on information acquisition and accuracy analysis of ancient architecture plaque with common smart phone," CC BY 4.0 License.The ancient architectural plaque is a unique cultural heritage of the Chinese traditional culture. It is called the ""soul of ancient architecture"" and has important historical and artistic value. Due to its small size and large quantity, the preservation status is not optimistic, and it is urgent to carry out rescue protection. It is especially necessary to complete its digital information collection first. The basic images used in photogrammetry are usually taken by professional cameras. With the continuous development of technology, the shooting ability of mobile phones is constantly increasing. The method of 3D reconstruction of plaque of ancient buildings by common mobile phone cameras is studied through experiments. Several common mobile phones were selected to collect images of ancient building plaques from different acquisition distances and 3D reconstruction experiments were carried out. The results of accuracy evaluation showed that the information of ancient architectural collected by common mobile phone cameras within the suitable acquisition range can meet the accuracy of 3D reconstruction. Requirements. In addition, the image control point measurement is replaced by a standard card. The experimental results show that the size of the model can be controlled by using the card constraint. The method can utilize the commonly used camera mobile phone to efficiently obtain the image of the ancient buildings distributed in various places and carry out three-dimensional reconstruction, thereby satisfying the urgent requirement of the urgent need for protection of the ancient buildings.",60092860,Beijing University Of Civil Engineering And Architecture,Beijing,China,['1710'],18.615384615384613,0.04129720853858785,0.4429392446633826,0,0.10150375939849623,0.0037593984962406013,0.2222222222222222
819,841,841,A decentralized provenance network for linked open data,"With the growing availability of Linked Open Data (LOD) and the consequential generation of derived and aggregated data, the need for trustworthy, reproducible and accessible provenance information has increased. Yet, no consistent mechanism has been established to manage provenance data of LOD on a global dataset-level. Decentralized networks and peer-to-peer mechanisms have made their revival in the last years with blockchain and similar distributed ledger technologies. We propose a novel approach to track and store provenance information for LOD on a dataset-level by sharing an immutable, common state between data providers. The basic architecture will not disrupt existing methodologies and standards for publishing LOD, but will be transparently integrated into existing ecosystems as an additional layer to foster broad acceptance. We will investigate the application of emerging blockchain technologies and established Linked Data specifications for building this decentralized anchor of truth. We are actively involved in the design and implementation of LOD and Open Data platforms and will evaluate our approach in real-world scenarios regarding feasibility, governance, scalability and usability.",60072186,Fraunhofer Institute for Open Communication Systems FOKUS,Berlin,Germany,['1700'],24.285714285714285,-0.010984848484848484,0.32992424242424245,1,0.14285714285714285,0.061224489795918366,0.34408602150537637
820,842,842,STUDY on SUMMER RAINDROP SIZE DISTRIBUTION and RETRIEVED POLARIMETRIC RADAR PARAMETER over LEIZHOU PENINSULA," All rights reserved.Leizhou peninsula is located in the south of Guangdong Province, near South China Sea, and has a tropical and subtropical monsoon climate. Based on observed drop size distribution (DSD) data from July 2007 to August 2007 with PARSIVEL disdrometers deployed at Zhanjiang and Suixi, the characterists of DSDs are studied. Non-linear least squares method is used to fit Gamma distribution. Convective and stratiform averaged DSDs are in good agreement with Gamma distribution, especially in stratiform case. Convective average DSDs have a wider spectrum and higher peak. Microphysical parameter differences between convective and stratiform are discussed, convective precipitation has a higher mass-weighted mean diameter (Dm) and generalized intercepts (Nw) in both areas. The constrained relations between Gamma distribution parameter (μ , A, N0) is derived. The retrieved polarimetric radar parameter (KDP, ZDR, Zh) have a good self-consistency, which can be used to improve the accuracy of KDP calculation. R-KDP-ZDR is superior to the RKDP, R-ZDR-Zh in quantitative precipitation estimation (QPE), with a correlation coefficient higher than 0.98.",60064143,Nanjing University of Information Science and Technology,Nanjing,China,['1710'],18.777777777777782,0.215625,0.5739583333333335,0,0.07373271889400922,0.1336405529953917,0.44
821,843,843,SPECIES DISTRIBUTION MODELLING of TWO SPECIES ENDEMIC to the PHILIPPINES to SHOW the APPLICABILITY of MAXENT,"Maxent is a machine learning model used for species distribution modelling (SDM) that is rising in popularity. As with any species distribution model, it needs to be validated for certain species before being used to generate insights and trusted predictions. Using Maxent, SDM of two endemic species in the Philippines, Varanus palawanensis (Palawan monitor lizard) and Caprimulgus manillensis (Philippine nightjar), were created using presence-only data, with 14 V. palawanensis and 771 C. manillensis occurrences, and 19 bioclimatic variables from BIOCLIM. This study shows the consistency to historical facts of Maxent on two endemic species of the Philippines of varying nature. The applicability of Maxent on the two very different species show that Maxent has high likelihood to give good results for other species. Showing that Maxent is applicable to the species of the Philippines gives additional tools for ecologists and national administrators to lead the development of the Philippines in the direction that conserves the biodiversity of the Philippines and that increases the productivity and quality of life in the Philippines.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.375,0.15821428571428572,0.4777380952380952,1,0.10471204188481675,0.07853403141361257,0.328042328042328
822,844,844,Human behavior as the source of data in the education system,"Information technologies are fundamentally changing modern society. Almost any human activity becomes the source of data for possible analysis and processing. The authors have analyzed more than hundred examples of data mining in modern society presented in open sources focusing on the field of education. In this study, the interdisciplinary approach is used. It makes possible to consider human activity as the basis for data analysis as the complex social phenomenon from the perspective of the sociology of communication and global Internet usage. At the same time, the authors note that the current development of technologies allows analyzing behavior of people not only in the Internet (online), but also in everyday life (offline) with the help of individual devices (cameras in smartphones and computers, fitness trackers, etc.) and with the use of facial recognition for various social situations. This study focuses on learning process and human behavior usage as the source of data in this area because information and communication technologies have changed the format of modern education. Therefore a significant part of education content has moved to the online environment. Integration of various data concerning e-learning, human movement, Biological Feedback can establish complex digital education model with prognostic and recommendatory functions that take into account behavior, individual characteristics, knowledge and skills in dynamics. This model supports a lifelong trajectory of personal development not limited by initial and final indicators and framework of educational institution. Nowadays technologies that allow tracking human behavior are causing discussions related to ethics and the issue of human freedom, though they provide deeper analysis of people's activities. Certainly these opportunities can be the benefit for society and miscellaneous social environment.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",22.91666666666667,0.030921052631578943,0.3569548872180451,1,0.08794788273615635,0.009771986970684038,0.28524590163934427
823,845,845,Critical Points in the Formation and Implementation System of the Fundamental Science and Technology Innovations Life Cycle,"Issues of developing and implementing fundamental science and technology innovations is particularly relevant in current times due to the escalation of qualitatively new problems of the socio-economic development of society. However, their analysis has a predominantly descriptive form of separate stages, processes, and procedures, and is not formed on the framework of clear criteria and indicators. Fundamental science and technology innovations, based on qualitatively new physical principles, make it possible to significantly increase the efficiency of the whole social production and the social spheres of society. The life cycle of fundamental science and technology innovations is a structurally and functionally complex integrated system which includes the birth of ideas for future innovative products, the process of their materialization, material realization, and later, the operation and disposal processes due to the depletion of their consumer properties. This study determines the critical points in the system of forming and implementing the life cycle of fundamental science and technology innovations as a single integrated process in the form of specific indicator gauges. These points determine the time parameters and characteristics of the life cycle of the fundamental scientific and technological innovations, its efficiency and quality. Future products start to become obsolete the moment the idea of them is generated. The authors conceptually determined that the process of a scientifically novel idea becoming obsolete can be described by an exponential curve. This is presented in the corresponding graph. The authors determined the life cycle stages of the fundamental scientific and technological innovations and established that the pre-production stage presents an opportunity to use combination effects during two or more stages of the life cycle and to use iteration procedures. This creates new possibilities for raising the efficiency and quality of the life cycle, contributing to a significant reduction in the level of various kinds of risks. This paper is of interest to specialists in the field of innovation studies, socio-economic efficiency of science and technical progress, engineering economics in the area of information technologies, to engineers and research staff, as well as to university students, graduate students, and professors..",60072787,Tajik State National University,Dushanbe,Tajikistan,"['1712', '1709', '1707', '1705']",28.75,0.10201218534551867,0.4430535513868847,1,0.07349081364829396,0.0,0.25333333333333335
824,846,846,Enhancing Graph-Based Keywords Extraction with Node Association,"In this paper, we present an enhancing graph-based keywords extraction method with node association (GKENA), which strengths graph-based keywords extraction approaches by applying strong association rule mining and unifying three different node attributes into a single framework. Specifically, we regard one single document as a sequential transaction dataset, and apply an efficient algorithm to exploit closed frequent sets and the strong association rules are generated to represent the correlations among multiple terms for association graph construction. Each graph node represents combinations of two or more terms and three node attributes (i.e. graph structure, node semantics and associations) are unified to transfer extra node information into a Markov chain model to obtain the ranking. Besides, in order to avoid the semantic overlapping among top ranked candidate words, a trustworthy clustering algorithm is employed and the center word in each cluster is selected to construct the keywords sets. Our experiments on both Chinese and English datasets indicate that GKENA can boost the quality of keywords in graph-based keywords extraction techniques.",60020464,Guangxi Normal University,Guilin,China,['1700'],28.0,0.10825396825396824,0.27301587301587305,1,0.14210526315789473,0.03684210526315789,0.31351351351351353
825,847,847,Hesitant fuzzy TOPSIS based facility location selection problem,"This study develops a decision support methodology for facility location selection problem. The methodology is based on the TOPSIS (Technique for Order Performance by Similarity to Ideal Solution) approach in hesitant fuzzy environment. We are focusing on a special case of facility location problem, namely location planning for service centers. Such problem usually involves a set of candidate centers locations (alternatives), which are evaluated considering a set of weighted criteria. To evaluate criteria our approach implies using of experts' assessments. In the proposed methodology the values of the criteria are expressed in linguistic terms, given by all experts. Then, these linguistic terms are described by trapezoidal fuzzy numbers. Consequently, proposed approach is based on trapezoidal hesitant fuzzy TOPSIS decision-making model. The case when the information on the criteria weights is completely unknown is considered. The criteria weights identification based on De Luca-Termini information entropy is offered in context of hesitant fuzzy sets. Following the TOPSIS algorithm, first the fuzzy positive-ideal solution (FPIS) and the fuzzy negative-ideal solution (FNIS) are defined. Then the ranking of alternatives is performed in accordance with the proximity of their distances to the both FPIS and FNIS.",60071909,Ivane Javakhishvili Tbilisi State University,Tbilisi,Georgia,['1706'],15.916666666666664,0.1507936507936508,0.394973544973545,1,0.10176991150442478,0.05752212389380531,0.38073394495412843
826,848,848,Development of communicative competence integrated management system,"Background/Objectives: There has been an increasing number of patients suffering from communication problem with an increase of the elderly as well as groups with the neuro-liguistically impaired from stroke or Alzheimer's disease. In addition, smart device-based communication training service is required to minimize social costs and issues with access. In order to provide feedback and manage training for the elderly and the neuro-liguistically impaired, expert-oriented diagnosis service is required. Methods/Statistical analysis: Advice, validity review, and evaluation for usage have been proceeded through the development of expert-oriented learning/evaluation feedback module and expert advisory committee. Findings: Korean contents have been developed applying intuitive UX/UI that the elderly and the neuro-liguistically impaired are able to easily train with. At the same time, customized scenario was provided from user analysis and authoring tool while developing expert-oriented communication ability evaluation and training service technology. Improvements/Applications: By providing communication training contents and expert-oriented services, it is possible to contribute to create service integrated with language treatment field. It is expected to have supplementary effect with intellectual advancement and emotional stableness of members in society from the emergence of such an integrated service.",60028021,Kwangju University,Gwangju,South Korea,['1700'],23.25,0.13463203463203466,0.5038961038961041,1,0.11688311688311688,0.03896103896103896,0.3024390243902439
827,849,849,An optimized technique for large-scale data clustering,"The day-to-day growth of large-scale data makes data processing increasingly challenging. To handle this, there is a dire need for cluster computing systems that can parallelize the computations of large volume of data over a set of nodes. Among these is Apache Spark, a reliable framework for iterative machine learning processes such as clustering. Spark stores and processes data in-memory over the nodes of a cluster which makes it faster and fault-tolerant. On the other side, owing to its simplicity, K-means is still a significant topic for researchers. The large volume of data, however, increases the number of iterations and, thus, computational complexity. Further, good initial centroids play an important part in boosting the performance of K-means, especially with large data. This paper, therefore, proposes a new hybrid approach to handle these challenges by reducing the iterations of the K-means algorithm using a cutting-off method for the latest iterations and initializing centers through Scalable K-means++. This approach is applied with the Apache Spark framework. The proposed hybrid approach, called FSS.K-means, speeds up the clustering process over 46% of the time taken by the standard K-means while maintaining about 96% accuracy.",60012022,Mansoura University,Mansoura,Egypt,['1700'],19.0,0.2086147186147186,0.5660173160173161,1,0.09583333333333334,0.06666666666666667,0.35648148148148145
828,850,850,Canard bifurcation in the FitzHugh-Nagumo model for spikes generation in neurons,"We provide a new insight of the all-or-none-spike behavior of the solutions of the FitzHugh-Nagumo model for axon-current. Using the various tools introduced by nonstandard analysis for studying canards behavior we show how the firing of oscillations takes place by the appearance of a canard-without-head cycle that splits into two ""concentric"" cycles, the larger being stable and becoming a canard-with-head and the the smaller being unstable and collapsing down to the equilibrium, all this taking place within an exponentially small parameter interval.",60110369,Laboratoire de Mathématiques J.A. Dieudonné,Nice,France,"['1712', '1709', '1707', '1705']",41.0,0.02582972582972584,0.499062049062049,1,0.09433962264150944,0.02830188679245283,0.2727272727272727
829,851,851,Mixing-RNN: A Recommendation Algorithm Based on Recurrent Neural Network,"Collaborative filtering algorithms have been used by recommender systems for item (e.g., movie) recommendation. However, traditional collaborative filtering algorithms face challenges to provide accurate recommendation when users’ interest and context suddenly changed. In this paper, we present a new Recurrent Neural Network-based model, namely Mixing-RNN that is able to capture time and context changes for item recommendation. In particular, Mixing-RNN integrates the insight from Rating-RNN and Category-RNN which are developed to predict users’ interest based on rating and category respectively. Different from the traditional RNN, we integrate the forget gate and input gate in the model, where the forget gate decides what information to remain or discard and the input gate inputs rating information to the model. Our experiment evaluation on MovieLens indicates that Mixing-RNN outperforms the state-of-art methods.",60105478,Singapore Institute of Technology,Singapore City,Singapore,['1700'],21.5,0.1303030303030303,0.4946212121212121,1,0.10493827160493827,0.09259259259259259,0.3424657534246575
830,852,852,Delving into robust object detection from unmanned aerial vehicles: A deep nuisance disentanglement approach,"Object detection from images captured by Unmanned Aerial Vehicles (UAVs) is becoming increasingly useful. Despite the great success of the generic object detection methods trained on ground-to-ground images, a huge performance drop is observed when they are directly applied to images captured by UAVs. The unsatisfactory performance is owing to many UAV-specific nuisances, such as varying flying altitudes, adverse weather conditions, dynamically changing viewing angles, etc. Those nuisances constitute a large number of fine-grained domains, across which the detection model has to stay robust. Fortunately, UAVs will record meta-data that depict those varying attributes, which are either freely available along with the UAV images, or can be easily obtained. We propose to utilize those free meta-data in conjunction with associated UAV images to learn domain-robust features via an adversarial training framework dubbed Nuisance Disentangled Feature Transform (NDFT), for the specific challenging problem of object detection in UAV images, achieving a substantial gain in robustness to those nuisances. We demonstrate the effectiveness of our proposed algorithm, by showing state-of-the- art performance (single model) on two existing UAV-based object detection benchmarks. The code is available at https://github.com/TAMU-VITA/UAV-NDFT.",60033252,U.S. Army Research Laboratory,Adelphi,United States,"['1712', '1707']",23.125,0.3070105820105821,0.4889550264550264,1,0.13852813852813853,0.05627705627705628,0.41784037558685444
831,853,853,A method for integrating an UBEM with GIS for spatiotemporal visualization and analysis,"Leveraging Geographic Information Systems (GIS) for spatiotemporal visualization and analysis of simulated UBEM datasets and real-world data simultaneously can assist in identifying opportunities, as well as potential barriers, to energy efficient and climate adaptation strategies. However, current GIS-based models that support interactive exploration of adaptation strategies and future scenarios are scarce and do not easily incorporate building energy use data for visual analysis over time. This paper describes a workflow to integrate simulated building energy consumption data associated with variable energy efficiency scenarios within a GIS platform for interactive spatiotemporal visualization to support climate adaptation decision-making. The contribution of the work presented is in the ability to selectively view and analyze simulated building energy performance data layered with other realworld geospatial data through an automated feedback loop between an UBEM and ArcGIS. An interactive interface is designed in ArcGIS to enable users to explore building performance scenarios spatially and over time. Using a downtown neighborhood in Syracuse, New York, USA, as a case study, preliminary results demonstrate how the workflow provides insight into existing energy use issues and potential for implementing strategies such as energy load shifting or building retrofits. A discussion includes opportunities as well as challenges to the workflow in facilitating understanding of urban energy model outputs by multiple stakeholders in evaluating potential energy efficient strategies.",60030551,Syracuse University,Syracuse,United States,['1705'],31.142857142857146,-0.017108585858585858,0.473989898989899,1,0.14166666666666666,0.05,0.3162393162393162
832,854,854,"Infrastructure Potential of Creating ""Smart Cities""","Creating"" smart cities"" is becoming an integral part of the strategy to mitigate consequences of the problems caused by urban population growth and rapid urbanization. It allows finding out a new course for the development of certain regions' economy and the country as a whole. This problem is an essential new issue for the Russian Federation; however, only a few researchers focus on this topic. Most technologies and domains which a ""smart city"" is based on are connected with appropriate infrastructure. Roads and utility networks that have a significant impact on cities and regions matter a lot. The given article considers the hypothesis that the level and dynamics of the regional infrastructure development influence creation of ""smart cites"" considerably. The notion a ""smart city"" requires implementing new digital technologies, and it is based on opportunities that are offered within the transition to the new technological paradigm. Having reviewed significant amount of literature related to various branches of sciences, and used the rating of infrastructure development of regions and ""The Strategy of Spatial Development of the Russian Federation until 2025"", the city ranking in regard to opportunities of the efficient use for all regional resources is carried out. Based on the data from the portal ""The Bank of Solutions of the Smart City"" created by the Ministry of Construction, Housing and Utilities of the Russian Federation to integrate best practices of smart cities development, projects executed in the cities taking part in the research are considered. Obtained results have allowed us to make conclusions on key challenges related to the development of smart cities and those transformations of a regional space that they are accompanied by. The advantages and disadvantages of smart city creation are identified.",60110433,Institute for Problems of Regional Economics RAS,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",25.90909090909091,0.17497048406139318,0.4843171979535616,1,0.10759493670886076,0.04746835443037975,0.30063291139240506
833,855,855,Logical semantics approach for data modeling in XBRL taxonomies,"The contemporary world of human beings is as connected as ever providing for the integration, interdependence and interoperability of various industries and areas of expertise. The World Wide Web enabled by the Internet became a systematic means of communication by use of conventional symbols that represent a language tool. As any language tool, it has two major constructs - syntax and semantics. The syntax of a language defines its surface form. The well-developed, standardized and agreed upon Syntactic Web allows humans to seamlessly send and receive information in a digital form from virtually everywhere in the world. The role of the Semantic Web is to make this information unambiguously understood by both humans and machines. It represents a challenge. Despite the fact that the scientists are equipped with a plethora of methods the Semantic Web remains quite untamed. In this PhD proposal, we suggest the logical semantics approach to the Semantic Data modeling that would allow both analytic and synthetic native language users to build successful Semantic Data Models for an XBRL taxonomy. The perfect datasets to test this approach are generated at the cross-section of multidisciplinary areas of expertise: financial reporting, applied linguistics, natural language processing and computer science.",60104412,Belarus State Economic University,Minsk,Belarus,['1700'],20.0,0.1681776556776557,0.36336996336996336,1,0.10407239819004525,0.05429864253393665,0.31336405529953915
834,856,856,Characteristic analysis of current transformer by measurement of induced electromotive force,"Background/Objectives: CT is a typical measurement instrument capable of measuring alternating current in industry. When the large current such as the inrush current flows into the CT, the induced electromotive force characteristics and the magnetic field saturation characteristic analysis of the EMF coil are essential. Methods/Statistical analysis: For induction electromotive force analysis, the induced electromotive force is modeled mathematically and the numerical formula for numerical analysis of the electromagnetic field is derived. Also, various CTs were selected and the saturation characteristics of the magnetic body were analyzed by measuring the induced electromotive force. Findings: The analytical results show that saturation characteristics and induced electromotive force characteristics are analyzed. When sinusoidal wave is applied to primary winding of CT, induced electromotive force is calculated by electromagnetic field analysis using complex approximation method. In addition, the schematic waveforms of the induced electromotive force by numerically calculated and measured were compared. When a large current like a surge current flow into the CT, the magnetic core is saturated and the sensing ability of the CT is lowered. Improvements/Applications: Therefore, optimal design should be performed considering the dimension of the CT and the characteristic of the ferromagnetic core. Based on the experimental results of this paper, it may be helpful to design the magnetic core or winding of the CT used in the surge protection device.",60094949,Joongbu University,Kumsan,South Korea,['1700'],22.2,0.02936507936507936,0.4050264550264551,1,0.124,0.044,0.23770491803278687
835,857,857,GATEWAY: A GEOSPATIAL ANALYTICS SYSTEM,"This paper presents an overview of the Gateway web platform, a proprietary geospatial analytics system developed by Cobena Business Analytics and Strategy, Inc.1 The application is intended to serve as a user-friendly and easily-accessible tool for spatial data analysis and visualization geared toward non-technical specialists. Gateway's core functionalities hinge on mapping and data visualization (choropleths and points) alongside traditional scoring methods and built-in machine learning algorithms for area prioritization and site selection. Gateway provides an interactive, cloud-based environment that abstracts and simplifies common location-based analyses. A core strength of the platform is also its heavy localization to the Philippine context through a curated database of market information-with future plans to create local counterparts across SEA-which reduces the need for extensive external market data collection and reconciliation. The paper gives a brief review of the system design and key features of the platform. It also highlights some key applications across industries such as real estate, consumer goods, and retail in informing expansion and distribution strategies, prioritizing resource allocation, and analyzing historical performance against market factors.",124057982,Cobena Business Analytics and Strategy Inc.,Taguig,Philippines,['1710'],29.0,-0.014285714285714287,0.4101190476190476,1,0.11165048543689321,0.038834951456310676,0.33157894736842103
836,858,858,Micromechanical modelling of mechanochemical processes in heterogeneous materials,"There is a range of practical problems where advanced engineering heterogeneous materials undergo chemical transformations. The primary example of such system is energy storage materials, in particular anodes of Li-ion batteries containing active Si particles. The exploitation of such anodes involves extreme volumetric expansion of the active particles during the chemical reaction. The expansion is causing mechanical stress, which, in turn, influences the kinetics of chemical reactions even up to their arrest. A particular reaction between Si and Li is localised, as well as a number of other reactions, such as oxidation or precipitate formation. The model presented in this paper accounts for the kinetics of the reactions in a collection of particles inside a matrix material. The microstructure is modelled using the multiscale mean-field (MF) framework based on the incremental Mori-Tanaka (IMT) method. This is the first application of a multiscale MF technique to modelling reaction front kinetics in particles and linking the intra-particle kinetics with the response of the matrix. A number of physical effects arising from the influence of the deformation mechanisms of the matrix on the kinetics of the intra-particle reactions is investigated. Furthermore, the applicability of the proposed model and the IMT homogenisation scheme is studied by comparison to the full-field simulations in the cases of small and finite strains.",60022020,The University of Warwick,Coventry,United Kingdom,['1706'],21.5,0.03777777777777778,0.4478571428571429,1,0.06854838709677419,0.04435483870967742,0.3008474576271186
837,859,859,Preface for the special issue on Interaction and Concurrency Experience 2017, The theoretical results contributed by the ICE workshops and by these articles in particular aim at being applicable to real concurrent and distributed systems.,60032259,Università degli Studi di Cagliari,Cagliari,Italy,"['1712', '1703']",25.0,0.12222222222222225,0.2444444444444445,0,0.07692307692307693,0.0,0.28
838,860,860,Algorithm border tracing vs scanline in blob detection for robot soccer vision system,"In a robotic soccer competition, the locations of the ball and the robot are recognized through the vision system in a strong dynamic environment. Therefore, the robot and the computer need to identify the object in real-time and accurately through the vision system. In this study, algorithm border tracing and algorithm scan line were applied in vision system for the robotic soccer team of the Universitas Pembangunan Nasional UPN ""Veteran"" Yogyakarta. Two algorithms were introduced to detect the blob in order to identify the robot, the ball and the other object in the field. The Experimental results showed that border tracing algorithm has 100% accuracy in all shape (triangle, square and rectangle) of blob. Whether scan line algorithm has 25% accuracy for triangle, 0% for rectangle and 100% for square. Therefore it has been shown that border tracing algorithm is superior to scan line.",60106036,Universitas Pembangunan Nasional “Veteran” Yogyakarta,Yogyakarta,Indonesia,['1706'],20.571428571428573,0.14537037037037034,0.4009259259259259,1,0.05389221556886228,0.07784431137724551,0.30303030303030304
839,861,861,ESTIMATION of CHLOROPHYLL-A CONCENTRATION in SAMPALOC LAKE USING UAS MULTISPECTRAL REMOTE SENSING and REGRESSION ANALYSIS,"Sampaloc Lake is providing livelihood for the residents through aquaculture. An increase in the quantity of fish pens inside the lake threatens its water quality condition. One parameter being monitored is microalgal biomass by measuring Chlorophyll-a concentration. This study aims to generate a chlorophyll-a concentration model for easier monitoring of the lake. In-situ water quality data were collected using chl-a data logger and water quality meter at 357 and 12 locations, respectively. Using Parrot Sequoia+ Multispectral Camera, 1496 of 2148 images were acquired and calibrated, producing 18x18cm resolution Green (G), Red(R), Red Edge (RE) and Near Infrared (NIR) reflectance images. NIR was used to mask out non-water features, and to correct sun glint. The in-situ data and the pixel values extracted were used for Simple Linear Regression Analysis. A model with 5 variables-R/NIR, RE2, NIR2, R/NIR2, and NIR/RE2, was generated, yielding an R2 of 0.586 and RMSE of 0.958 μg/l. A chlorophyll-a concentration map was produced, showing that chl-a is higher where fish pens are located and lowers as it moves away from the pens. Although there are apparent fish pens on certain areas of the lake, it still yields low chlorophyll-a because of little amount of residential area or establishments adjacent to it. Also, not all fish pens have the same concentration of Chlorophyll-a due to inconsistent population per fish pen. The center of the lake has low chlorophyll-a as it is far from human activities. The only outlet, Sabang Creek, also indicates high concentration of Chlorophyll-a.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],17.714285714285715,0.014543650793650794,0.38436507936507935,1,0.0778816199376947,0.09968847352024922,0.4236111111111111
840,862,862,Assessment of the synergistic effect from solvency changes in M&A transactions based on a dynamic model,"The main goal of most merger and acquisition (M&A) transactions is to achieve a synergistic effect. This study proposes a method and a model for predicting the consequences of merger and acquisition transactions from the perspective of achieving synergy. The authors consider the possibility of obtaining a synergistic effect in mergers/acquisitions, which originates from a negative correlation between the liquidity flows passing through companies participating in an M&A transaction. This effect can be determined and assessed using a model that describes a company's cash flows as a Wiener process coming out of a point with a certain liquidity cushion L0 . Increments in the company's liquidity cushion at each subsequent stage are viewed as independent random values (positive or negative) governed by the normal law of distribution. Each subsequent liquidity cushion value meets the conditions of the Markov process. Solvency is assessed using a dynamic index TX . The time during which the probability of losing the liquidity cushion for the company will not exceed X%. For each individual company, the TX value depends on the parameters of the liquidity flow . L0, mean value and standard deviation. Upon conclusion of M&A transactions, the flows are combined. Calculations performed using simulation modeling based on the proposed model show that the ""S""V indicator of the combined company is determined not only by the values of L0, and of the M&A participants, but also by the pair correlation coefficient of cash flows. It is found that with the reduction of the correlation coefficient the solvency of the combined company within the framework of the proposed approach increases, reaching its maximum with the correlation coefficient = -1. In addition, by reducing correlation between the flows it is possible to achieve a significant saving of the amount of liquid funds through the reduction of its initial value L0. Another important aspect is the possibility of preliminary quantitative assessment of the synergistic effect.",60104780,Russian State University of Tourism and Service,Cherkizovo,Russian Federation,"['1712', '1709', '1707', '1705']",21.2,0.031036255411255414,0.4627191558441559,1,0.11527377521613832,0.040345821325648415,0.2556179775280899
841,864,864,Novel reusable software components for fault tolerant architecture,"The emergence of component and distributed computing technologies paved way for software engineering discipline to explore reusable software components to expedite development, reduce software development cost and effort. Many component technologies such as Distributed Component Object Model (DCOM), Enterprise Java Beans (EJB) and Common Object Request Broker Architecture (CORBA) came into existence. Many real world applications are built using the reusable components. However, the problem identified in the recent state-of-the-art is that it is very challenging problem to have fault tolerance as the components may run in different machines across the globe. Therefore there is need for a framework with fault tolerant architecture for design of reusable components in software engineering. The aim of this paper is, therefore, to investigate the present state of the art of fault tolerant architectures that provide fault tolerance to applications that make use of reusable components in distributed environment.",60114708,Sreenidhi Institute of Science &amp; Technology,Hyderabad,India,['1700'],24.16666666666667,0.1722222222222222,0.461111111111111,1,0.08928571428571429,0.08333333333333333,0.37037037037037035
842,865,865,TIDE GAUGE and SATELLITE ALTIMETRY DATA for POSSIBLE VERTICAL LAND MOTION DETECTION in SOUTH EAST BOHOL TRENCH and FAULT,"Coupled with the occurrence of regional/local sea level rise on urbanized coastal cities is the possibility of land subsidence that contaminates the measurement by the tide gauge (TG) sensors. Another technology that could possibly check the in-situ data from tide gauge is satellite altimetry. The sea surface height (SSH) measured from satellite altimeter is compared with the observed tide gauge sea level (TGSL) to detect vertical land motion (VLM). This study used satellite altimeter retracked products near the TG Stations in Tagbilaran, Bohol; Dumaguete, Negros Oriental; and Mambajao, Camiguin located in the vicinity of the South East Bohol Trench and Fault (SEBTF). Based on the results, the TG site in Tagbilaran is undergoing land subsidence. The rate of VLM is around 5 mm/year from 2009 to 2017. The same trend was manifested in the GNSS observed data in the PHIVOLCS monitoring station in Tagbilaran and the geodetic levelling done in the area. After the October 15, 2013 earthquake in Bohol, downward trends of around 27 mm/year and 17 mm/year were observed from GNSS measurements and SSH-TGSL difference respectively. These different rates may be due to the distance between the two sensors. The comparison between SSH and TGSL in Dumaguete showed small difference with a VLM rate of 1.8 mm/year. The difference in SSH-TGSL in Mambajao is quite large with a downward rate of 9.4 mm/year. This result needs to be further investigated for TG or TGBM instability or monitored for a possibility of land uplift.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],20.416666666666668,-0.00674603174603175,0.4365079365079365,1,0.07167235494880546,0.12627986348122866,0.3927272727272727
843,866,866,Crowdtesting intermediary tool for managing public service software project,"Software testing is important to ensure correctness of the software, gaining confidence from stakeholders, and contributing towards achieving high quality software. One approach to conduct software testing is through crowdtesting. It allows people from the crowd to test a particular software using their own devices in real environment. Currently in public service sector there is no existing intermediary tool to manage crowdtesting activities for public service software project. Therefore, public service software project relied on common testing approaches such as testing by internal employees or outsourced to specific suppliers, that in turn making public service software projects facing the risk of inadequate testing. This study intends to determine whether the implementation of crowdtesting is able to address the problems of inadequate testing in public service software project and to propose an application as intermediary tool for crowdtesting in public service. This study employed interviews and survey with IT practitioners in public service sector to understand the applicability of crowdtesting in public service and specifications for the proposed intermediary tool. The intermediary tool is developed and evaluated to determine its effectiveness in managing crowdtesting for public service software project. The evaluation shows that most of the participants agree that the intermediary tool shows effectiveness in terms of defect detection, cost benefit, time, and testing coverage.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],23.777777777777782,0.1107936507936508,0.301111111111111,1,0.14782608695652175,0.004347826086956522,0.28695652173913044
844,867,867,Impact of virus in a resource biomass model with industry,"In this paper, a nonlinear mathematical model is proposed and analyzed to study the effect of the virus on forest biomass in the presence of industry. The existence of equilibria and their local stability have been discussed. We have discussed the Hopf-bifurcation analysis by considering the virus as a bifurcation parameter. Further, the direction of Hopf-bifurcation is determined using the center manifold theorem. We have studied the threshold value of the rate of infection caused by the virus for the sustainable development of forest biomass. All the analytical findings are validated using numerical simulation.",60113584,"Khalsa College, Amritsar",Amritsar,India,['1700'],15.666666666666664,-0.025,0.15,1,0.11320754716981132,0.018867924528301886,0.2549019607843137
845,868,868,Agent-Based Approach for Inventory Pre- and Post-disruption Decision Support,"Due to its global nature and highly dynamic and competitive environment, supply chain arguably is more exposed to disruptions. As supply chains continue to grow in scale and complexity, inventory management in a dynamic business environment is a challenging task. The aim of this paper is to propose a multi-agent approach to quantify the impact of inventory disruptions. Our objective is to analyze the capacities of supply chains to cope with disruptions before and after stockouts by including (proactive) mitigation strategies and reactive strategies. The proposed system allows providing advice to human users in the form of decision support. A prototype system is built and validated, which demonstrates the feasibility of the proposed approach. The experiments show that the implementation of multi-agent technology makes the system much more flexible to make the final decision.",60070317,Ecole Nationale des Sciences de l'Informatique,Manouba,Tunisia,['1700'],19.142857142857142,0.1375,0.3908333333333333,1,0.12,0.0,0.2534246575342466
846,869,869,Mitigation of unintended biases against non-native English texts in sentiment analysis," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Currently the demand for text analytics grows due to the fact that textual data is being created online in large amounts. A number of tools are available for various tasks related to natural language processing such as sentiment analysis and text pre-processing. The majority of these tools are trained using unrepresentative data, which may lead to unintended biases altering the results. Previous research indicates that sentiment analysis tools show gender and race biases, and word embeddings discriminate against women. This research investigates previously undefined non-native speaker bias in sentiment analysis, i.e. unintended discrimination against English texts written by non-native speakers of English. Non-native speakers of English tend to use cognates, English words that have origin in the speaker's language. To measure the nonnative speaker bias in 4 lexicon-based sentiment analysis systems, a new Cognate Equity Evaluation Corpus was created, based on previous work in the literature for measuring racial and gender biases. The tools gave significantly different scores to English texts with features of non-native speakers. The bias discovered in lexicon-based tools was mitigated by updating 4 lexicons for English cognates in 3 languages. This paper proposes a generalisable framework for measuring and mitigating non-native speaker bias.",60104048,National College of Ireland,Dublin,Ireland,['1700'],19.0,0.036282467532467534,0.2779058441558441,0,0.11934156378600823,0.07407407407407407,0.39737991266375544
847,870,870,"CHLOROPHYLL-A CONCENTRATION RETRIEVAL USING CONVOLUTIONAL NEURAL NETWORKS in LAGUNA LAKE, PHILIPPINES","Two existing chlorophyll-a (chl-a) concentration retrieval procedures, which are analytical and empirical, are hindered by the complexity in radiative transfer equation (RTE) and in statistical analyses, respectively. Another promising model in this direction is the use of artificial neural networks (ANN). Mostly, a pixel-to-pixel with one-layer ANN model is used; where in fact that the satellite instrumental errors and man-made objects in water bodies might affect the retrieval and should be taken into account. In this study, the mask-based neural structure, called convolutional neural networks (CNN) model containing both the target and neighborhood pixels, is proposed to reduce the influence of the aforementioned premises. The proposed model is an end-to-end multiple-layer model which integrates band expansion, feature extraction, and chl-a estimation into the structure, leading to an optimal chl-a concentration retrieval. In addition to that, a two-stage training is also proposed to solve the problem of insufficient in-situ samples which happens in most of the time. In the first stage, the proposed model is trained by using the chl-a concentration derived from the water product, provided by satellite agency, and is refined with the in-situ samples in the second stage. Eight Sentinel-3 images from different acquisition time and coincide in-situ measurements over Laguna Lake waters of Philippines were utilized to conduct the model training and testing. Based on quantitative accuracy assessment, the proposed method outperformed the existing dual-and triple-bands combinations in chl-a concentration retrieval.",60071429,University of the Philippines System,Quezon City,Philippines,['1710'],26.0,0.06818181818181818,0.3393939393939394,1,0.10097719869706841,0.029315960912052116,0.3595505617977528
848,871,871,Thai finger-spelling sign language recognition employing PHOG and local features with KNN,"Sign Language recognition is an important tool for the hearing-impaired in order to communicate with both hearing-impaired and hearing individuals. Similarities in finger-spelling sign language are one of the main factors or problems influencing the accuracy of sign language recognition. This research focuses on one-stroke, Thai finger-spelling sign language (TFSL) in methods of feature extraction with the pyramid histogram of oriented gradients (PHOG) and local features, as well as the application of K-Nearest Neighbors (KNN) recognition. We present, herein, a Thai finger-spelling sign language recognition system (TFSLR) used to classify alphabets shown in similar gestures. Five signers postured fifteen Thai alphabet characters, in which images were taken in five repetitions, totaling 375 finger-spelling images. Our experiment utilizes five-fold cross-validation in order to evaluate the projected system effectiveness. Additionally, we compared the results of each experiment involving PHOG with the amalgamation of PHOG and the local features. The results showed that such amalgamation was capable of handling similarly signed characters with an average accuracy of 97.6%.",60017165,Khon Kaen University,Khon Kaen,Thailand,['1706'],20.625,0.06166666666666666,0.3433333333333333,1,0.11004784688995216,0.07655502392344497,0.42328042328042326
849,872,872,An innovative model assessment of efficient management a renewal and using the fixed assets of enterprises in the digital economy,"Currently, the competitiveness of enterprises implementing their activities in the framework of digital technologies has increased significantly. Digital economics drastically changes all stages of the activities of an enterprise from production management to its relationship with the state. As is well known, digital economics is characterized by the formation of economic models implemented in a software product that allows you to manage the activities of the enterprise continuously and to minimize the costs and risks of non-receipt of profit. The purpose of this study is to form an innovative model based on key aspects for assessing the efficient management of the renewal and use of fixed assets in the digital economy. In order to achieve this goal, we first had to clarify the classification of fixed assets, which allows us to think that the developed innovative model corresponds to the concept and technology of digital economics. Based on this clarified classification of fixed assets, we developed an innovative model for assessing the efficient management of the renewal and use of fixed assets in the digital economy. This model is a comprehensive assessment of the efficient management of the renewal and use of fixed assets. The following methods were used in the research: situational, dynamic analysis, correlation and regression analysis, the method of constructing a normative system of indicators, the method of trend extrapolation, tabular and graphical interpretation of empirical and factual information. The developed innovative model for assessing the efficient management of the renewal and use of fixed assets can be applied in enterprises in sectors of the economy.",60104088,Chernorizets Hrabar Free University of Varna,Varna,Bulgaria,"['1712', '1709', '1707', '1705']",28.777777777777782,0.13269230769230772,0.32307692307692304,1,0.10676156583629894,0.0,0.2078853046594982
850,873,873,"Enhanced cancer subtyping via pan-transcriptomics data fusion, monte-carlo consensus clustering, and auto classifier creation","Subtyping of tumor transcriptome expression profiles is a routine method used to distinguish tumor heterogeneity. Unsupervised clustering techniques are often combined with survival analysis to decipher the relationship between genes and the survival times of patients. However, the reproducibility of these subtyping based studies is poor. There are multiple reports which have conflicting subtype and gene-survival time relationship results. In this study, we introduce the issues underlying the lack of reproducibility in transcriptomic subtyping studies. This problem arises from the routine analysis of small cohorts (< 100 individuals) and use of biased traditional consensus clustering techniques. Our approach carefully combines multiple RNA-sequencing and microarray datasets, followed by subtyping via Monte-Carlo Consensus Clustering and creation of deep subtyping classifiers. This paper demonstrates an improved subtyping methodology by investigating pancreatic ductal adenocarcinoma. Importantly, our methodology identifies six biologically novel pancreatic ductal adenocarcinoma subtypes. Our approach also enables a degree of reproducibility, via our pancreatic ductal adenocarcinoma classifier PDACNet, which classical subtyping studies have failed to establish.",60015150,Imperial College London,London,United Kingdom,"['1712', '1709', '1707', '1705']",16.4,-0.08499999999999999,0.445,1,0.1276595744680851,0.031914893617021274,0.4010989010989011
851,874,874,From VR-Participation Back to Reality - an AI&VRdriven approach for building models for effective communication in e-Participation," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Successful communication between citizens and decision makers - eParticipation, despite progressing from dedicated solutions to modern, social media-based approaches has been facing many challenges. We argue that Virtual Reality technologies through its sense of presence and embodiment for discussion participants can help in alleviating some of the major obstacles hindering effective communication and collaboration. In this paper, we propose a novel approach to building AI models to support effective dialog implementation in VR. VR platforms potentially afford studies on user behavior without the overhead of complicated sensor infrastructure required for data collection. In particular, we propose machine-learning-based approach for predictive log analytics to identify behavioral patterns that support or obstruct effective collaboration in the context of structured dialog conversation. We discuss the applicability of the models to e-Participation and possible broader application of the models created. We also argue that VR-interaction-data-based models have the potentials to be transferable to managing and improving real-life interactions.",60027012,Gdańsk University of Technology,Gdansk,Poland,['1700'],23.714285714285715,0.19375,0.5785714285714285,0,0.12886597938144329,0.04639175257731959,0.3854748603351955
852,875,875,An intelligent linked data quality dashboard," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This paper describes a new intelligent, data-driven dashboard for linked data quality assessment. The development goal was to assist data quality engineers to interpret data quality problems found when evaluating a dataset using a metrics-based data quality assessment. This required construction of a graph linking the problematic things identified in the data, the assessment metrics and the source data. This context and supporting user interfaces help the user to understand data quality problems. An analysis widget also helped the user identify the root cause multiple problems. This supported the user in identification and prioritization of the problems that need to be fixed and to improve data quality. The dashboard was shown to be useful for users to clean data. A user evaluation was performed with both expert and novice data quality engineers.",60025059,Dublin City University,Dublin,Ireland,['1700'],18.0,0.27255892255892256,0.3893939393939394,0,0.16352201257861634,0.0440251572327044,0.3141025641025641
853,876,876,A study on woman employees satisfaction in various benefits schemes offered by the information technology industry,"The various benefits offered by the company either statutorily or voluntarily help in no small measure not only to boost the morale of the employees but also to shore up the loyalty factor of the employees. Further some of the benefits like transport facilities, holiday home, promotion polices, crèche and lunch facilities facilitate greatly in work life balance. The fringe benefits offered by the company entice the work force to continue their stay for a longer period. Promotion practices contribute a great deal to retaining the talent with the company. The medical claim facilities aid in keeping the health of the employees in good order so that absenteeism is minimized. In short the various benefits offered by the company tone up the morale of the employee. In this context examination of employees satisfaction level in various benefits offered by the employer is taken up for analysis. The conclusion will be given.",60027171,Annamalai University,Chidambaram,India,['1700'],18.875,0.22045454545454546,0.5272727272727272,1,0.10493827160493827,0.0,0.21604938271604937
854,877,877,Metaheuristic analytical instruments in optimizing the shopping center parking area: A transportation model,"We propose new approach to the solution of the problem of forecasting quantity of the required parking lots on the parking area. In addition, this article describes problems application of the model of the metaheuristic optimisation of discrete events with the purpose of investigation of influence of changes in design of the trading/shopping facilities upon the structure of the city traffic. This model will provide the specialists, who are engaged in planning of the urban area development, with possibilities to determine the following factors: interaction of locations of big shops; mutual influence of the parking areas of the great trading centres and the urban road networks; as well as design of various parking areas and relevant transportation systems. This model was developed in order to ensure analysis of the entire travel from the point of view of a passenger. Therefore, this model presents the entire travel of a passenger as his/her multimodal route, including movement over the road system in combination with the movements over the parking areas. It is important to emphasise that interaction between each of these components, as well as location of big shops in the city centre will exert influence upon selection of the traffic route, as well as upon selection of the relevant means of transportation. This article presents structure of this model, as well as procedure of verification with the help of this model experiment.",60104618,Penza State University of Architecture and Construction,Penza,Russian Federation,['1700'],33.0,0.15974025974025974,0.4538961038961039,1,0.05928853754940711,0.0,0.2289156626506024
855,878,878,TransI: Translating Infinite Dimensional Embeddings Based on Trend Smooth Distance,"Knowledge representation learning aims to transform entities and relationships in a knowledge base into computable forms, so that an efficient calculation can be realized. It is of great significance to the construction, reasoning and application of knowledge base. The traditional translation-based models mainly obtain the finite dimension vector representation of entities or relationships by projecting to finite dimensional Euclidean space. These simple and effective methods greatly improve the efficiency and accuracy of knowledge representation. However, they ignore a fact that the semantic space develops and grows forever with the passage of time. Finite dimensional Euclidean space is not enough in capacity for vectorizing infinitely growing semantic space. Time is moving forward forever, so knowledge base would expand infinitely with time. This determines that the vector representation of entities and relationships should support infinite capacity. We fill the gap by putting forward TransI (Translating Infinite Dimensional Embeddings) model, which extends knowledge representation learning from finite dimensions to infinite dimensions. It is trained by Trend Smooth Distance based on the idea of continuous infinite dimension vector representation. The Training Efficiency of TransI model is obviously better than TransE under the same setting, and its effect of Dimension Reduction Clustering is more obvious.",60019499,Chinese Academy of Sciences,Beijing,China,['1700'],18.181818181818183,0.09111111111111113,0.6243650793650793,1,0.12217194570135746,0.06787330316742081,0.2876712328767123
856,879,879,A Text Annotation Tool with Pre-annotation Based on Deep Learning,"In this paper, we introduce an open-source tool, YEDDA, supported by a pre-annotation module based deep learning. EPAD proposes a novel annotation workflow, combining pre-annotation and manual annotation, which improves the efficiency and quality of annotation. The pre-annotation module can effectively reduce the annotation time, and meanwhile improve the precision and recall of annotation. EPAD also contains some of the mechanisms to facilitate the usage of the pre-annotation module. As a collaborative design, EPAD provides administrators with annotation statistics and analysis functions. Experiments showed that EPAD shortened almost 60.0&#x0024;&#x0024;\%&#x0024;&#x0024; of the total annotation time, and improved 12.7&#x0024;&#x0024;\%&#x0024;&#x0024; of F-measure for annotation quality.",60010421,Southwest Jiaotong University,Chengdu,China,['1700'],17.0,0.2,0.65,1,0.11538461538461539,0.046153846153846156,0.506578947368421
857,880,880,A Simple and Effective Community Detection Method Combining Network Topology with Node Attributes,"Community detection is a fundamental problem in the study of complex networks. So far, extensive approaches, which use network topology alone or use both network topology and attribute information, have been designed to detect the community partitions of networks. However, existing approaches cannot work effectively for networks whose community structure does not match well with the ground-truth, or networks whose topological information contains serious noise, and networks where the difference of attribute similarity between nodes is tiny. Inspired by a force-directed network layout and community intuitive characteristics, we propose a simple while effective approach which utilizes attribute information to partition nodes into communities by maximizing network modularity. By using attributes as nodes to the network and the interaction between nodes, our novel method cannot only effectively improve community detection of networks, but also obtain the number of communities closer to the real one. Through extensive experiments on some real-world datasets, we demonstrate the superior performance of the new approach over some state-of-the-art approaches.",60019533,Tianjin University,Tianjin,China,['1700'],27.16666666666667,0.16450216450216448,0.6175015460729746,1,0.09844559585492228,0.0,0.287292817679558
858,881,881,"Cryptomorphic topological structures: A computational, relation-algebraic approach","In this paper we present an approach to pointless topology that is based on the study of the membership or is-element-of relation within a typed or categorical version of the component-free calculus of relations. This allows us to study several other approaches to topology, including point-set topology, on an abstract and component-free level. In particular, we will show that topologies defined by open sets, closed sets, a family of neighbourhood systems, a topological kernel-mapping, a Kuratowski closure-mapping, or a topological Aumann contact relation are cryptomorphic concepts, i.e., each concept can bijectively be transformed into any other of these concepts. All transformations are specified via relation-algebraic expressions which, in case of set-theoretic relations (that is, in case of point-set topology) can immediately be executed by the specific purpose computer algebra system RELVIEW.",60018276,Universität der Bundeswehr München,Neubiberg,Germany,"['1712', '1703']",32.75,-0.04814814814814815,0.25648148148148153,1,0.08875739644970414,0.01775147928994083,0.3624161073825503
859,882,882,Diabetic retinopathy classification using support vector machine with hyperparameter optimization,"Diabetic Retinopathy (DR) is one of the frequent comorbidities of diabetes worldwide. Diabetic eye screening has become a challenging task for ophthalmologist as they need to deal with large number of patients to be diagnosed, creating a need to develop tool that may help ophthalmologist to classify the severity of DR in order to establish an adequate therapy. Previous researchers have studied machine learning to propose an automatic DR classification using the clinical variables. However, it needs to be improvised especially in terms of accuracy. Hence, this paper aims to propose an optimal or near-optimal DR classifier using the Support Vector Machine with hyperparameter optimization. This study considered three classes of diabetic patients which were patients who do not have DR (NODR), patients with non-proliferative DR (NPDR) and patients with proliferative DR (PDR), instead of focusing only on two classes (NO DR, DR). The radial basis function, polynomial, sigmoid kernel and their respective hyperparameters were tested in this study in order to find the best kernel and combination of hyperparameters that can improve the performance of SVM. The results obtained show that SVM-radial kernel with cost value,64, 0.03 gives the best accuracy at 85.45%.",60000906,Universiti Sains Malaysia,Gelugor,Malaysia,['1706'],24.25,0.2980952380952381,0.4928571428571428,1,0.12280701754385964,0.08333333333333333,0.3783783783783784
860,883,883,Developing a Cybersecurity Risk Analysis System for High-Tech Equipment in Machine Industry,"The paper is dedicated to developing a system for identifying and assessing cyber-risks to support investment decision-making in a machine industry enterprise. It is designed for projects related to high-tech equipment development and introduction. The problem is acute because the existing methods of cyber-risk analysis have some drawbacks, which prevent them from being used at a time of growing information threats. A structural-logical scheme for the cyber-risk analysis system has been developed, and detailed descriptions are provided for some blocks of the system and their tools. The research methods include system approach to problem-studying, analysis of fundamental statements given in literature, and analysis of the existing tools used in practice for solving these problems. The presented system has some advantages in comparison with such common approaches as risk maps or factor analysis of information risks (FAIR). Since it is built on risk-control principles, it ensures that all actions of management concerning cyber-risk-control are integrated and coordinated. The system also contains effective tools and methods for assessing cyber-risks in quantitative terms, calculating a consolidated effect with due consideration of risks, assessing the impact this effect makes on the strategic goal indicator of a project, comparing project implementation scenarios given cyber threats with risk appetite to evaluate the acceptability of the project. These advantages make the system dynamic and integrative, reactive to the changes of the cyberspace and emergence of new threats. It can have a substantial practical application in managing investment projects related to the development and introduction of high-tech equipment in enterprises of the sector.",60020513,National Research University Higher School of Economics,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",25.5,0.17594696969696969,0.5371843434343434,1,0.12,0.0033333333333333335,0.31521739130434784
861,884,884,On the essence and initiality of conflicts in M-adhesive transformation systems,"Understanding conflicts between transformation steps and rules is an important topic in algebraic graph transformation. A conflict occurs when two transformation steps are not parallel independent, that is, when after applying one of them the other can no longer occur. A static analysis technique called Critical Pair Analysis allows the detection of all potential conflicts between pairs of rules, by enumerating Critical Pairs. Since these are often too numerous for even simple rules, finding appropriate subsets of critical pairs is the topic of ongoing research. We contribute to this thread by proposing a new characterization for root causes of conflicts, called “conflict essences”, exploiting a recently proposed characterization of parallel independence. Furthermore we show that conflict essences are at least as precise as the “conflict reasons” previously proposed, and uniquely determine the so-called “initial conflicts”, an appropriate subset of critical pairs, under relatively mild assumptions on the underlying category. Finally, we show that several M-adhesive categories of interest have the necessary properties for our results to hold, including typed, attributed and symbolic graphs. While our results are formulated for conflicts, they are directly applicable to dependencies in M-adhesive transformation systems.",60028868,Università di Pisa,Pisa,Italy,"['1712', '1703']",23.75,0.09826038159371492,0.534383517716851,1,0.1031390134529148,0.03587443946188341,0.37327188940092165
862,885,885,FY-4A SATELLITE BASED CLOUD MICROPHYSICAL VARIATION ANALYSIS of AIRBORNE CLOUD SEEDING OPERATIONS in SICHUAN BASIN,"Based on a satellite retrieval methodology, the cloud microphysical properties of two airborne cloud seeding operations in Sichuan Basin of Southwest China are analyzed in this paper. The methodology for the retrieval of the cloud particle effective radius (Re), cloud temperature (T) and microphysical structure is based on the data from the AGRI onboard the Chinese FY-4A satellite. A microphysical red-green-blue (RGB) composite visualization has been devised to qualitatively highlight the cloud composition. This RGB scheme is displayed by compositing visible 0.65 micron channel, near infrared 2.2 micron channel and infrared 11.0 micron channel. And the vertical structure and development status of the clouds are demonstrated by the T-Re profiles. The results show that after the cloud seeding operation on June 11, 2018, the cloud particle effective radius increases, and the ground observed PM10 and PM2.5 pollutants decrease as well. As for the cloud seeding operation on November, 17, 2018, the satellite inversion shows that the medium and low level clouds are rich in super-cooled water with small cloud particle effective radius. After the cloud seeding operation, the effective radius of the cloud droplets increases significantly. Both of these two cloud seeding operation in Sichuan Basin demonstrate obvious precipitation enhancement results in the seeding impact area.",60046504,China Meteorological Administration,Beijing,China,['1710'],22.88888888888889,0.2727272727272727,0.5840909090909091,1,0.08786610878661087,0.100418410041841,0.341991341991342
863,886,886,A simulation-based approach to sense and alert the DDoS attacks in organizations network,"DDoS assaults are the real worry in the current computerized world. Decreasing the DDoS assaults is hard particularly with regards to very appropriated Botnet-based assaults. It is important to recognize these assaults ahead of schedule to secure end-clients and the system foundation assets. The center of this work is to actualize the Intrusion detection system (IDS) which is situated at the Internet service providers (ISP) level. Utilizing our self-created simulator, it will be demonstrated that how ISPs shape the assurance rings around the host to work together and shield the movement data. In this manuscript process mining as well as data mining approach is also discussed for intrusion detection system.",60109375,"Amity University, Dubai",Dubai,United Arab Emirates,['1700'],18.33333333333333,0.12187500000000002,0.446875,1,0.11023622047244094,0.031496062992125984,0.2975206611570248
864,887,887,Estimation methodology for forest biomass in Mongolia using remote sensing,"The forest biomass is one of the most important parameters for the global carbon stock. Information on the forest volume, coverage and biomass are important to develop the global perspective on the CO2 concentration changes. Objective of this research is to estimate forest biomass in the study area. The study area is Hangal sum, Bulgan province, Mongolia. Backscatter coefficients for vertical transmit and vertical receive (VV), for vertical transmit and horizontal receive (VH) from Sentinel data and Leaf Area Index (LAI) from Landsat data were used in the study area. We developed biomass estimation approach using ground truth data which is DBH, height and soil moisture. The coefficient &alpha;, &beta;, &delta;, &gamma; were found from the approach. The output map from the approach was compared with VV and VH, LAI data. The relationship between output map and VH data shows a positive result R2&thinsp;Combining double low line&thinsp;0.61. This study suggests that the biomass estimation using Remote sensing data can be applied in forest region in the North.",60072643,National University of Mongolia,Ulaanbaatar,Mongolia,['1710'],16.7,0.13884297520661154,0.3586776859504132,1,0.06,0.115,0.3894230769230769
865,888,888,A framework for cost-optimal zero-energy lightweight construction,"During the last decade, several roof extensions took place in the European cities with the purpose to increase the height of existing buildings using timber as a lightweight material. However, building regulations and green codes do not usually guarantee the achievement of multi-objective and highly performance roof extensions. Accordingly, this research aims to develop a state of the art framework to achieve cost-optimal zero-energy for timber construction, specifically when building on rooftops. Through a simulated and calibrated passive house model, the boundary conditions of the study have been identified and further parametric simulation and optimization have been carried out. This research aims at linking scientific research with practice. The framework provides a fast track measurement that provides a solutions space for building engineers who are in charge of decision making on the design and construction process. Best practices of roof construction could be achieved in terms of cost and energy, giving a vast potential for a complete and deep renovation, and, therefore, reducing the overall ecological footprint on the city level.",60000964,Universite de Liege,Liege,Belgium,['1705'],24.42857142857143,0.119,0.3971111111111112,1,0.12435233160621761,0.0051813471502590676,0.25133689839572193
866,889,889,Analysis of factors influencing the realization of entrepreneurial ideas using logistic regression model,"Background/Objectives: It is aimed to identify the influencing factors that are involved in the initial stage of idea formation for startup and analyze the propensity and condition of each individual. Methods/Statistical Analysis: The hypothesis is that a person's tendency, preference and satisfaction affect the attempt to form an idea for startup. Therefore, a logistic regression model in which idea suggestion is a binary dependent variable while entrepreneurial tendency, platform preference and satisfaction are explanatory variables is adopted. This model enables us to understand the reasons for suggesting ideas and to lay the groundwork for establishing policies aimed at revitalizing the proposal of founding ideas. Findings: The results found the followings: First, there is no difference according to the age and region of the group. However, according to gender, occupation, platform usage reason, cognitive path, entrepreneurial experience, there are differences. In addition, the odds of suggesting an idea increase with the willingness to start and commercialization interest. The satisfaction of the related contents has a great influence on the system rather than the function of the system. Improvements/Applications: The main factors that should be prioritized for the diffusion and revitalization of entrepreneurial culture are identified, and it can be used to establish the policies of the nationwide entrepreneurship and entrepreneurship support organizations.",60025960,Korea Institute of Science and Technology,Seoul,South Korea,['1700'],23.444444444444446,0.2027777777777778,0.3694444444444445,1,0.10655737704918032,0.020491803278688523,0.25630252100840334
867,890,890,"Logical characterisations, rule formats and compositionality for input-output conformance simulation","Input-output conformance simulation (iocos_ ) has been proposed by Gregorio-Rodríguez, Llana and Martínez-Torres as a simulation-based behavioural preorder underlying model-based testing. This relation is inspired by Tretmans' classic ioco relation, but has better worst-case complexity than ioco and supports stepwise refinement. The goal of this paper is to develop the theory of iocos_ by studying logical characterisations of this relation, rule formats for it and its compositionality. More specifically, this article presents characterisations of iocos_ in terms of modal logics and compares them with an existing logical characterisation for ioco proposed by Beohar and Mousavi. It also offers a characteristic-formula construction for iocos_ over finite processes in an extension of the proposed modal logics with greatest fixed points. A precongruence rule format for iocos_ and a rule format ensuring that operations take quiescence properly into account are also given. Both rule formats are based on the GSOS format by Bloom, Istrail and Meyer. The general modal decomposition methodology of Fokkink and van Glabbeek is used to show how to check the satisfaction of properties expressed in the logic for iocos_ in a compositional way for operations specified by rules in the precongruence rule format for iocos_.",60136210,Gran Sasso Science Institute,L'Aquila,Italy,"['1712', '1703']",24.5,0.29166666666666663,0.3466666666666667,1,0.10344827586206896,0.1336206896551724,0.3744075829383886
868,891,891,Leveraging citizen science to advance interactive spatial decision support technology: A swot analysis,"Over three decades, the Spatial Decision Support System (SDSS) concept has evolved significantly exploiting information technology to assist decision maker in a variety of fields of research, development, and practice. With the communicative turn in planning, which emphasizes public participation in all levels of planning and decision making, these technologies have further matured to support participatory planning by means of supporting diverse stakeholders in the decision making process. However, for multiple reasons, SDSS are still in the domain of expert, largely failing to incorporate general citizens in its use and applications. On the same note, citizen science as a method of inquiry is gaining much attention in recent years to engage general citizens in the scientific research, thereby also empowering them to participate in the decisions of the issues affecting them. As such, it seems likely that citizen science shows great promise for advancing SDSS for achieving broad citizen engagement in planning and decision-making. This paper discusses the strengths, weaknesses, opportunities, threats (SWOT) of integrating citizen science with SDSS by analyzing existing literature on SDSS and citizen science. In particular, we explore the integration of aspects of citizen science in Interactive Planning Support System (PSS), as one form of SDSS to support wider citizen engagement.",60020599,University of Twente,Enschede,Netherlands,['1710'],29.285714285714285,0.1355282738095238,0.4119419642857143,1,0.1059322033898305,0.06779661016949153,0.37606837606837606
869,892,892,An Evidential Semi-supervised Label Aggregation Approach,"Crowdsourcing is a powerful concept that typically takes advantage of human intelligence to deal with problems in many fields most importantly in machine learning. Indeed, it enables to collect training labels in a fast and cheap way for supervised algorithms. The only major challenge is that the quality of the contributions is not always guaranteed because of the expertise heterogeneity of the participants. One of the basic strategies to overcome this problem is to assign each task to multiple workers and then combine their answers in order to obtain a single reliable one. This paper provides a new iterative approach that aggregates imperfect labels using the supervision of few gold labels under the evidence theory. Besides of inferring the consensus answers, the workers’ accuracies and the questions difficulties are as well estimated. A comparative evaluation on synthetic and real datasets confirms the effectiveness of our semi-supervised approach over the baselines.",60070638,Institut Supérieur de Gestion de Tunis,Le Bardo,Tunisia,['1700'],21.428571428571427,0.14129802489177487,0.474614448051948,1,0.10493827160493827,0.0,0.28125
870,893,893,"GEOSTATISTICS for AIR QUALITY MAPPING: CASE of BAGUIO CITY, PHILIPPINES","Mapping of air quality are often based on ground measurements using gravimetric and air portable sensors, remote sensing methods and atmospheric dispersion models. In this study, Geographic Information Systems (GIS) and geostatistical techniques are employed to evaluate coarse particulate matter (PM10) concentrations observed in the Central Business District of Baguio City, Philippines. Baguio City has been reported as one of the most polluted cities in the country and several studies have already been conducted in monitoring its air quality. The datasets utilized in this study are based on hourly simulations from a Gaussian-based atmospheric dispersion model that considers the impacts of vehicular emissions. Dispersion modeling results, i.e., PM10 concentrations at 20-meter interval, show that high values range from 135 to 422 μg/mm3. The pollutant concentrations are evident within 40 meters from the roads. Spatial variations and PM10 estimates at unsampled locations are determined using Ordinary Kriging. Geostatistical modeling estimates are evaluated based on recommended values for mean error (ME), root mean square error (RMSE) and standardized errors. Optimal predictors for pollutant concentrations at 5-meter interval include 2 to 5 search neighbors and variable smoothing factor for night-time datasets while 2 to 10 search neighbors and smoothing factors 0.3 to 0.5 were used for daytime datasets. Results from several interpolation tests indicate small ME (0.0003 to 0.0008 μg/m3) and average standardized errors (4.24 to 8.67 μg/m3). RMSE ranged from 2.95 to 5.43 μg/m3, which are approximately 2 to 3% of the maximum pollutant concentrations in the area. The methodology presented in this paper may be integrated with atmospheric dispersion models in refining estimates of pollutant concentrations, in generating surface representations, and in understanding the spatial variations of the outputs from the model simulations.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],23.5,-0.05088235294117647,0.3244117647058824,1,0.0972644376899696,0.0790273556231003,0.45425867507886436
871,894,894,Curved-crease folding and robotic incremental sheet forming in design and fabrication,"The research presented in this paper addresses the themes of generative design, material computation, large-scale fabrication and assembly technologies by incorporating two research fields, Curved Folding and Robotically Aided Single Point Incremental Sheet Forming (RA-SPIF) of sheet metal panels. The design and construction of a largescale prototype made of complex panels of sheet metal serves as the case study for the proposed methodology. Global geometry panelisation is implemented through a multiple-criteria Evolutionary Algorithm to establish an equal subdivision approximation of the initial geometry. The mathematical principles of Curved Folding are applied on the resulting mesh geometry. Iterative FEA of the component assembly defines areas where Incremental Sheet Forming needs to be applied to the curved folded components. Selected panels are formed with RA-SPIF to enhance the structure’s performance for wind loading. The primary contribution of the research is the demonstration of a methodology that integrates the precise computation of curved folded geometries and the employment of FEA as a design driver for the application of incremental sheet forming towards the geometrical and material stiffening of sheet material.",60097321,Architectural Association (AA) School of Architecture,London,United Kingdom,['1705'],25.285714285714285,0.053571428571428575,0.2705357142857143,1,0.10606060606060606,0.08080808080808081,0.3036649214659686
872,895,895,THE SPATIOTEMPORAL VARIATION of HEAVY NO2 POLLUTION CENTER (HPC): A CASE STUDY in THREE Chinese URBAN AGGLOMERATIONS,"Air pollution episode, which are periods with excessive air pollutants, can cause a sharp increase in mortality and morbidity. Nitrogen oxides have an adverse impact on human health and the environment. Previous studies mainly focus on the time period, the frequency, and the duration of heavy NO2 pollution, while ignored its spatial extent which is pivotal in providing early warning and prediction. In this study, we investigated the spatiotemporal variation of the heavy NO2 pollution extent (i.e., heavy pollution center), analyzed its association with meteorological condition and further predicted its distribution in the future. A case study in Jing-Jin-Ji (JJJ), Yangtze River Delta (YRD) and Pearl River Delta (PRD) urban agglomerations showed that the HPC exhibited evident seasonal (winter > summer) and inter-city (mega and medium cities > small cities) differences. In concretion analysis, the HPC areas were negatively correlated with temperature and precipitation, suggesting that dry and cold meteorological conditions were responsible for the severe NO2 pollution events. Trend analysis showed that the small and medium cities may serve as the HPC in the future. During the 2005-2016, the medium and small cities in JJJ experience a more rapid increase in NO2 concentration in comparison to mega cities. Meanwhile, in YRD and PRD, a more rapid decrease was witnessed in the mega cities. The results of this study would provide support for early warning and prediction of heavy air pollutants and offer scientific insights for air pollution episode management.",60029306,Wuhan University,Wuhan,China,['1710'],24.0,-0.031172839506172837,0.4296296296296297,1,0.07042253521126761,0.08450704225352113,0.34782608695652173
873,896,896,Advanced deep learning methodologies for skin cancer classification in prodromal stages," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Technology-assisted platforms provide reliable solutions in almost every field these days. One such important application in the medical field is the skin cancer classification in preliminary stages that need sensitive and precise data analysis. For the proposed study the Kaggle skin cancer dataset is utilized. The proposed study consists of two main phases. In the first phase, the images are preprocessed to remove the clutters thus producing a refined version of training images. To achieve that, a sharpening filter is applied followed by a hair removal algorithm. Different image quality measurement metrics including Peak Signal to Noise (PSNR), Mean Square Error (MSE), Maximum Absolute Squared Deviation (MXERR) and Energy Ratio/ Ratio of Squared Norms (L2RAT) are used to compare the overall image quality before and after applying preprocessing operations. The results from the aforementioned image quality metrics prove that image quality is not compromised however it is upgraded by applying the preprocessing operations. The second phase of the proposed research work incorporates deep learning methodologies that play an imperative role in accurate, precise and robust classification of the lesion mole. This has been reflected by using two state of the art deep learning models: Inception-v3 and MobileNet. The experimental results demonstrate notable improvement in train and validation accuracy by using the refined version of images of both the networks, however, the Inception-v3 network was able to achieve better validation accuracy thus it was finally selected to evaluate it on test data. The final test accuracy using state of art Inception-v3 network was 86%.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],22.08333333333333,0.16416666666666666,0.5325000000000001,0,0.1188118811881188,0.0924092409240924,0.36824324324324326
874,897,897,Comparison of traditional market performance and electronic market of new entrepreneurs,"Social media has become the main tools in promoting the entrepreneurs’s electronic marketing via particular channels such as “Facebook” and “Line” to broaden the customer due to the ease of use. Then customers can also persive the information lf goods and services to provide them at and time. Furthermore, social media are gaining prominences as marketing strategy at a time when the entrepreneurs needs to reduce the costs of market budgets as advertising and public relation. In addition to the entrepreneur’s, they should be active in requiring social media to seek the business competitiveness.",60092137,Rajamangala University of Technology Srivijaya,Thammarat,Thailand,['1700'],23.5,0.01944444444444444,0.2675925925925926,1,0.12264150943396226,0.009433962264150943,0.2962962962962963
875,898,898,"ANALYZING the STATUS of MANGO TREES in BRGY. CANTIPAY, CARMEN, CEBU USING NDVI and TIME SERIES CLUSTERING","The Department of Agriculture-Region VII reports that many mango orchards in Cebu province are dying because of the absence of required post-harvest attention. Lacklustre yields and erratic pest infestations have driven some farmers and growers to abandon mango orchards. To help revive low-yielding mango orchards, there is a need to distinguish actively bearing mango trees from those that remain dormant throughout the year. Using remote sensing techniques, mango trees from separate orchards in Brgy. Cantipay, Carmen, Cebu were mapped and studied using multi-temporal Sentinel-2 data (from January 2018 through May 2019). Prior to that, a field visit was conducted to survey the area using UAVs and field observation, and in the process, was able to identify an abandoned mango orchard. Pixel-based Normal Difference Vegetation Index (NDVI) values were extracted from each of the 822 geotagged mango trees with an average of 16 trees among 53 divisions. Time series were derived from the average of the NDVI values from each division and plotted per month of extraction from oldest to latest. Clustering was applied to the time series data using Hierarchical Clustering with Ward's Minimum Variance as an algorithm to determine the divisions with the closest time series. Using the resulting dendrogram as basis, two major clusters were selected based on the value of their distances with each other: Cluster 1 containing 29 Divisions, and Cluster 2 containing 24 Divisions. Cluster 1 contains most of the Divisions in and around the biggest active mango orchard. In contrast, Cluster 2 contains most of the Divisions that are in and around the previously identified abandoned mango orchard. An alternative dendrogram was also created by using Complete Linkage algorithm in Hierarchical Clustering, after which 3 relevant clusters were selected. The second dendrogram highlights the stark difference between Division 1, contained in Cluster 3, from the rest of the other clustered divisions at 2.17 units from the next closest one. Notably, Division 1 is located smack in the middle of the abandoned orchard The remaining clusters, Cluster 2 with 21 divisions containing most of the divisions in the abandoned orchard, is 2.46 distance units away from Cluster 1, which has 31 and hosting most of the divisions in the active mango orchards. Two major clusters emerged from using the two algorithms. Divisions with higher and more variant NDVI values seemed to come from the mango trees which were more active during the fruiting cycle. Divisions from the abandoned mango orchards were observed to have lower and less varied NDVI values because of minimal activity in the trees. Other Divisions clustered under the abandoned orchard could have been juveniles based on their size.",60108083,University of the Philippines Cebu,Cebu,Philippines,['1710'],23.0,0.1163095238095238,0.4266666666666665,1,0.12065439672801637,0.08793456032719836,0.3945720250521921
876,899,899,Location-Interest-Aware Community Detection for Mobile Social Networks Based on Auto Encoder,"Community detection partitions users in social networks into sub-groups according to structural or behavioral similarities, which had been widely adopted by a lot of applications such as friend recommendation, precision marketing, etc. In this paper, we propose a location-interest-aware community detection approach for mobile social networks. Specifically, we develop a spatial-temporal topic model to describe users’ location interest, and introduce an auto encoder mechanism to represent users’ location features and social network features as low-dimensional vectors, based on which a community detection algorithm is applied to divide users into sub-graphs. We conduct extensive experiments based on a real-world mobile social network dataset, which demonstrate that the proposed community detection approach outperforms the baseline algorithms in a variety of performance metrics.",60033100,Nanjing University,Nanjing,China,['1700'],30.0,0.00476190476190476,0.21428571428571427,1,0.11486486486486487,0.006756756756756757,0.3283582089552239
877,900,900,RGCN: Recurrent Graph Convolutional Networks for Target-Dependent Sentiment Analysis,"With the increasing numbers of user-generated content on the web, identifying the sentiment polarity of the given aspect provides more complete and in-depth results for businesses and customers. Existing deep learning methods ignore that the sentiment polarity of the target is related to the entire text structure, and prevalent approaches among them cannot effectively use the syntactic information. In this paper, we propose to use a novel framework named as recurrent graph convolutional network (RGCN) for target-dependent sentiment classification in which the given text is considered as a graph based on its syntactic structure and recurrent graph convolutional networks are used to encode the text and target. We conduct comprehensive experiments on publicly accessible datasets, and results demonstrate that our model outperforms the state-of-the-art baselines.",60029380,Inner Mongolia University China,Hohhot,China,['1700'],31.25,0.225,0.5,1,0.14189189189189189,0.006756756756756757,0.25
878,901,901,Real interpolation with variable exponent,"We present the real interpolation with variable exponent and we prove the basic properties in analogy to the classical real interpolation. More precisely, we prove that under some additional conditions, this method can be reduced to the case of fixed exponent. An application, we give the real interpolation of variable Besov and Lorentz spaces as introduced recently in Almeida and Hasto (J. Funct. Anal. 258 (5) 1628-2655, 2010) and L. Ephremidze et al. (Fract. Calc. Appl. Anal. 11 (4) (2008), 407-420).",60068760,Université Mohamed Boudiaf - M'sila,M'sila,Algeria,['1710'],6.75,0.16,0.2775,1,0.07272727272727272,0.11818181818181818,0.5094339622641509
879,902,902,A review on traffic congestion detection methodologies and tools,"Road transport is the primary means to transit goods and people from one place to another at the global level. But the slowdown of flow of vehicles, due to internal and external factors, especially of congestion, has severe impact on fuel usage, pollution from vehicular emissions, health of trespassers and considerable time from an individual's life. Being densely populated and one of the developing nations, South Asian countries have the urge to automate the process of predicting, detecting and resolving the road traffic congestion. This paper highlights the various traffic congestion detection methodologies followed till date, with pros and cons. Specific methodologies and tools adopted for lane less roads have been analysed with the scope for further development to help the future researchers.",60077564,RMK Engineering College,Kavaraipettai,India,['1700'],24.6,0.014880952380952382,0.2958333333333334,1,0.08029197080291971,0.0,0.31386861313868614
880,903,903,Sequential Recommendation Based on Long-Term and Short-Term User Behavior with Self-attention,"Product recommenders based on users’ interests are becoming increasingly essential in e-commerce. With the continuous development of the recommendation system, the available information is further enriched. In the case, user’s click or purchase behavior could be a visual representation of his or her interest. Due to the rapid update of products, users’ interests are not static, but change over time. In order to cope with the users’ interest changes, we propose a desirable work on the basis of representative recommendation algorithm. The sequence of user interaction behavior is thoroughly utilized, and the items that users interact at different times have different significance for the reflect of users’ interests. By considering the user’s sequential behaviors, this paper focuses on the recent ones to obtains the real interest of user. In this process, user behavior is divided into long-term and short-term, modeled by LSTM and Attention-based model respectively for user’s next click recommendation. We refer this model as LANCR and analyze the model in experiment. The experiment demonstrates that the proposed model has superior improvement compared with standard approaches. We deploy our model on two real datasets to verify the superior performance made in predicting user preferences.",60007711,Jilin University,Changchun,China,['1700'],17.727272727272727,0.1338235294117647,0.42794117647058827,1,0.10869565217391304,0.017391304347826087,0.30666666666666664
881,904,904,"GEOSPATIAL and CLUSTERING ANALYSIS of DENGUE CASES USING SELF-ORGANIZING MAPS: CASE of QUEZON CITY, 2010-2015","Dengue is the most rapidly spreading disease in the world with more than 30% of the world's population at risk of contracting dengue. In 2016, more than 375,000 suspected cases of dengue were reported from the Western Pacific Region, and more than half of these were reported by the Philippines. Dengue virus inflicts significant health and economic burden to the Philippines. Thus, it is important to improve the country's current schemes for dengue surveillance and response thru better understanding and knowledge on the development of dengue. In this research, geospatial and clustering analyses of dengue cases in Quezon City through GIS and self-organizing maps (SOM) were performed. Two clusters were generated for each clustering method. After clustering the barangays, the coefficient of determination increased for most scenarios compared to the OLS regression of the ungrouped data. The R2 values for the regression of whole Quezon City dataset ranged from 0.364 to 0.671, while it ranged from 0.468 to 0.839 for the SOM-clustered dataset. On the other hand, for the k-means-clustered dataset, R2 values ranged from 0.395 to 0.945. Moreover, GWR models' adjusted R2 values ranged from 0.675 to 0.876. Common predictors among the different regression models are the informal settlements and very low residential areas. Based on the significant predictors identified and the trend of the dengue cases, SOM produced more logical classification than the GIS Grouping Analysis. Although SOM takes a longer time compared to the GIS Grouping Analysis, SOM is easier and simpler to implement.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],19.0,0.23541666666666666,0.4765833333333333,1,0.09473684210526316,0.08070175438596491,0.40794223826714804
882,905,905,Data and Knowledge: An Interdisciplinary Approach for Air Quality Forecast,"Air pollution has become a critical problem in rapidly developing countries. Prior domain knowledge combined with data mining offers new ideas for air quality prediction. In this paper, we propose an interdisciplinary approach for air quality forecast based on data mining and air mass trajectory analysis. The prediction model is composed of a temporal predictor based on local factors, a spatial predictor based on geographical factors, an air mass predictor tracking air pollutants transport corridors and an aggregator for final prediction. Experimental results based on real world data show that the cross-domain data mining method can significantly improve the prediction accuracy compared with other baselines, especially in the period of severe pollution.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],22.4,0.07148760330578513,0.4731404958677686,1,0.12195121951219512,0.008130081300813009,0.23140495867768596
883,906,906,Semantic enrichment of web services using linked open data,"With the rise of the internet, a lot of web services (WSs) are offered. However, most of these WSs lack explicit and sufficient semantic information. As a result, relevant WSs are not delivered to consumers during service discovery and WS composition and selection are so challenging. A possible solution to this is to provide the existing syntactic WSs with explicit information of their meaning through an annotation. Semantic annotations play an important role in semantics-aware service discovery, recommendation and composition. In this paper, we first conduct a literature review and then we present an approach for semantically annotating WSs based on linked open data (LOD) knowledge. The proposal uses similarity measure algorithms for matching the appropriate LOD concepts to the corresponding WS' parameters. A performance evaluation on real-world WSs was performed to validate the proposed approach.",60068751,Université de Bejaia,Bejaia,Algeria,"['1710', '1708', '1705']",17.0,0.2833333333333333,0.6370370370370371,1,0.10759493670886076,0.03164556962025317,0.3181818181818182
884,907,907,"MAPPING POVERTY in the PHILIPPINES USING MACHINE LEARNING, SATELLITE IMAGERY, and CROWD-SOURCED GEOSPATIAL INFORMATION","Mapping the distribution of poverty in developing countries is essential for humanitarian organizations and policymakers to formulate targeted programs and aid. However, traditional methods for obtaining socioeconomic data can be time-consuming, expensive, and labor-intensive. Recent studies have demonstrated the effectiveness of combining machine learning and satellite images to estimate wealth in sub-Saharan African countries (Xie et al., 2016, Jean et al., 2016). In this study, we investigate the extent to which this method can be applied in the context of the Philippine archipelago to predict four different socioeconomic indicators: wealth level, years of education, access to electricity, and access to water. We also propose an alternative, cost-effective approach that leverages a combination of volunteered geographic information from OpenStreetMap and nighttime lights satellite imagery for estimating socioeconomic indicators. The best models, which incorporate regional indicators as predictors, explain approximately 63% of the variation in asset-based wealth. Our findings also indicate that models trained on publicly available, volunteer-curated geographic data achieve the same predictive performance as that of models trained using proprietary satellite images.",60008710,UNICEF,New York,United States,['1710'],24.57142857142857,0.05,0.4025,1,0.12796208530805686,0.037914691943127965,0.36548223350253806
885,908,908,A combined approach of analytic hierarchy process and zero-one goal programming to select CSR program,"In Indonesia, Corporate Social Responsibility (CSR) is an inherent responsibility of every industrial company to create and sustain a harmonious and balanced relationship with local community. The company is expected to proactively take part in supporting the basic needs of society and simultaneously developing healthy environment. The industrial company considered in this paper is crude palm oil (CPO) industry, located in Riau province of Indonesia. A set of activities program of CSR was formulated to meet the expectations of the society toward sustainable CPO industry. We use Analytic Hierarchy Process (AHP) to find the priority of the program. The zero-one goal programming is then used to choose which program to be implemented based on the priority result. The optimal result of the combined method show that the alternatives selected is in accordance with the priority result of AHP.",60069397,Universitas Sumatera Utara,Medan,Indonesia,['1700'],19.714285714285715,-0.0020833333333333264,0.2927083333333333,1,0.11612903225806452,0.08387096774193549,0.28104575163398693
886,909,909,DRAM: A Deep Reinforced Intra-attentive Model for Event Prediction,"We address the problem of event prediction which aims to predict next probable event given a sequence of previous historical events. Event prediction is meaningful and important for the government, agencies and companies to take proactive actions to avoid damages. By acquiring knowledge from large-scale news series which record sequences of real-world events, we are expected to learn from the past and see into the future. Most existing works focus on predicting known events from a given candidate set, instead of devoting to more realistic unknown event prediction. In this paper, we propose a novel deep reinforced intra-attentive model, named DRAM, for unknown event prediction, by automatically generating the text description of the next probable unknown event. Specifically, DRAM designs a novel hierarchical intra-attention mechanism to take care not only the previous events but also those words describing the events. In addition, DRAM combines standard supervised word prediction and reinforcement learning in model training, allowing it to directly optimize the non-differentiable BLEU score tracking human evaluation and generate higher quality of events. Extensive experiments on real-world datasets demonstrate that our model significantly outperforms state-of-the-art methods.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],23.125,0.07534722222222222,0.3895833333333333,1,0.13122171945701358,0.01809954751131222,0.33004926108374383
887,910,910,Generating creative ideas for new product development in frugal innovation: A hybrid technique of TRIZ contradiction matrix and morphological analysis,"New product development process for the frugal innovation needs economical and good innovation techniques. As the frugal innovation is an emergent phenomenon, there is little research in how to develop new products for the frugal innovation. It is important to generate ideas in new product development for the frugal innovation. This paper introduces a model for new product development of the frugal innovation known as the multidimensional systematic innovation technique (MSIT). The model includes the innovation dimensions and the innovation algorithms, for generating creative ideas to the frugal product development. The developing process of MSIT is divided into the fuzzy front end (FFE) and the new product development (NPD) stages. The MSIT approach is evaluated in a case study in the Chinese coal-bed gas control technology. The results show that the MSIT provides a novel research perspective for the frugal innovation by identifying the crucial role played by the innovation process in defining or framing the frugal innovation techniques. It can be used in new product development for the frugal innovation.",60025785,Shanghai Maritime University,Shanghai,China,"['1710', '1708', '1705']",19.0,0.1946678321678321,0.5944055944055943,1,0.09473684210526316,0.010526315789473684,0.2393617021276596
888,911,911,Graph-based network analysis of transcriptional regulation pattern divergence in duplicated yeast gene pairs,"The genome and interactome of Saccharomyces cerevisiae have been characterized extensively over the course of the past few decades. However, despite many insights gained over the years, both functional studies and evolutionary analyses continue to reveal many complexities and confounding factors in the construction of reliable transcriptional regulatory network models. We present here a graph-based technique for comparing transcriptional regulatory networks based on network motif similarity for gene pairs. We construct interaction graphs for duplicated transcription factor pairs traceable to the ancestral whole-genome duplication as well as other paralogues in Saccharomyces cerevisiae. We create a set of network divergence metrics predicated on the presence and size of bi-fan arrays that are associated in the literature with gene duplication, within other network motifs. We compare the developed metrics to paralogue protein, gene and promoter alignment-free sequence dissimilarity to validate our results. We observe that our network divergence metrics generally agree with paralogue protein and gene sequence dissimilarity, and notice a weaker agreement with promoter dissimilarity. Our findings indicate that genetic divergence between paralogues is accompanied by a corresponding divergence in their interaction networks, and that our approach may be useful for investigating structural similarity in the interaction networks of paralogous genes.",60071047,Institute of Mathematics and Computer Science University of Latvia,Riga,Latvia,"['1712', '1709', '1707', '1705']",25.0,0.06818181818181818,0.2939393939393939,1,0.11261261261261261,0.0,0.2757009345794392
889,912,912,"From user generated content to social data warehouse: Processes, operations and data modelling","Social data warehouse (SDW) combines corporate data with user-generated content (UGC) to improve decision maker analysis. UGC data are heterogeneous, unstructured and informal. Their mapping into meaningful and valuable information has recently become a hot topic in social business intelligence. It is established through specific extraction, transformation and loading (ETL) processes during SDW development. Our main focus, in this work, is on ETL design and the issues emerging when UGC semantic analysis is integrated into SDW modelling. In fact, the complexity of ETL modelling is managed by partitioning its aspects into processes, operations and data. Besides, ETL4Social architecture is organised in three layers: meta-modelling, modelling and instantiation. The proposed meta-models concentrate both on ETL4Social concepts and notations. Their accuracy is shown through an illustrative example entailing generic models mapping UGC into SDW. These models are implemented in ETL4SocialTool, helping the designer to model complex ETL scenario.",60064746,University of Sfax,Sfax,Tunisia,"['1710', '1708', '1705']",14.6,0.06833333333333333,0.25916666666666666,1,0.10674157303370786,0.056179775280898875,0.45348837209302323
890,913,913,VALIDATION of AEROSOL PRODUCTS from ESA/AATSR over CHINA and AOD FUSION BASED on UNCERTAINTIES,"Aerosols play an important role in climate changes and environmental changes as well as on human health. ADV v3.11, ORAC v4.10, and SU v4.32 was three new versions of Advanced Along-Track Scanning Radiometer (AATSR) aerosol datasets which are published on Climate Change Initiative (CCI). In order to evaluate the accuracy of three AATSR aerosol optical depth (AOD) datasets, and to improve the spatial coverage and accuracy of AATSR AOD dataset, this study completed two works: the first part is validated the accuracy of three AOD datasets; the second part is fused three AATSR AOD datasets based on uncertainty of each dataset. After comparing with AERONET and CARSNET ground-based data over China, results show that the root-mean-square error (RMSE) for ADV v3.11, ORAC v4.10, SU v4.32 and fused AOD are 0.22, 0.17, 0.18, 0.17 respectively.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1710'],33.5,0.1694805194805195,0.36969696969696975,1,0.0783132530120482,0.1746987951807229,0.5063291139240507
891,914,914,Demanding energy efficient mobile computational offloading scheme using machine learning approach,"In the modern-world each and everyone needs a Smartphone to achieve their communication needs globally as well as an acceptable fact is mobile devices plays a vital role in individual's life. Smartphones now-a-days are fully consumer-oriented, in which it contains a huge-variety of applications to provide service to its users. This case leads more computational power to the mobile devices as-well-as the processing ability of such devices are expected to be highly concentrated. The usage of multiple applications in simultaneous manner over mobile phones causes several issues to users such as poor-battery-lifetime, speed-issues, mobile-heating and so on. In this system, a novel' and intelligent approach is proposed to solve the issues rising due to the computational abilities of mobile offloading as well as empirically proves the advantages of mobile offloading with remote servers. The term offloading explores a hidden meaning of remote accessibility, in which the mobile devices can process the storage mechanisms and computational-needs are in outside of the mobile device, so that the processing overhead of the mobile devices are highly reduced. This combination of Mobile Devices and Remote Server Manipulation is generally called as Mobile-Cloud-Computing. The term cloud refers the remote server, all the computational needs are performed over there and the resulting summaries are portrayed over the mobile devices within fraction of seconds. The accessing nature of cloud services usually follows an important strategy called Mobile-Crowdsensing, in which it also plays a major role in Cloud-Service Selection procedures. In which the Mobile-Crowdsensing effectively sense the crowd ratio of mobile-devices and share the resources of cloud to their requirements as-well-as the Mobile-Crowdsensing also analyze and predict the application processes of general-interest. The advancement of Machine learning strategies gives hand to this nature of handling such difficult process like remote data handling and processing. This paper explores a new machine learning based approach called, Demanding Energy Efficient Mobile Computational Offloading Scheme (DEEMCOS), which concentrates more on mobile offloading issues such as huge-data transfers, complex-mobile application processing-scenarios, network-interruptions and so on. A final outcome empirically proves the integration of mobile and cloud computing results good battery-lifetime, enhanced offloading-process and security as well.",60079451,Noorul Islam University,Kanyakumari,India,['1700'],27.153846153846153,0.09197638146167554,0.4130258467023173,1,0.10478359908883828,0.05694760820045558,0.3524804177545692
892,915,915,A SCATTERING SIMULATION MODEL for NONSPHERICAL AEROSOL PARTICLES BASED on PARALLEL FDTD SCHEME,"In order to simulate the scattering properties of nonspherical aerosol particles in visible and near infrared band precisely and efficiently, a scattering computation model for aerosol particles based on parallel FDTD (Finite Difference Time Domain) is developed. The basic principle of FDTD is introduced, and a new parallel computation scheme for FDTD is proposed, and is realized by MPI repeated non-blocking communication technique. The FDTD scattering model is validated against Lorenz-Mie theory and T Matrix method. Simulation results show that, the scattering properties obtained parallel FDTD scattering model are qualitatively in good agreement with the T matrix method and Lorenz-Mie theory, validating the accuracy of our model. The relative simulation error of Mueller is slightly larger in forward scattering directions than that in backward directions for particles with small size parameter, while for large particles, the result is opposite.",60024350,National University of Defense Technology,Changsha,China,['1710'],27.8,0.10004638218923932,0.2862940630797773,1,0.09433962264150944,0.11949685534591195,0.3137254901960784
893,916,916,Classification and prioritization of the disease causing risk factors in cotton crop cultivation using fuzzy analytical hierarchy process,"Cotton is aleadingfiber crop of universal rank which has a great elevation towards the marketable value and it isone of the significant commodity crops that have massive potential to bring sustained accomplishment to farmers. “Bad Boll Opening” is a vital, multifaceted disease that affects the cotton crop after the fruiting period of the plant which declines the productivity massively [1-5]. This research develops a desired computational tool to identify and evaluate the occurrence and the severity of the said disease causing risk factors. An integrated decision making and fuzzy analytical hierarchy processing method is applied to hierarchically classify and assess the relative closeness of these hazard factors by utilizing the knowledge and experience of the domain experts which includes plant pathologists, fertilizer operation managers, pest controllers and cotton information technical specialist [6-11]. The outcome of this proposed research will support farmers in disease identification and diagnosis during the process of cultivating cotton crops.",60013041,Bharathiar University,Coimbatore,India,['1700'],30.6,-0.02045454545454544,0.6083333333333334,1,0.1111111111111111,0.017543859649122806,0.2694610778443114
894,917,917,"The study of heat island and its relation with urbanization in Gurugram, Delhi NCR for the period of 1990 to 2018","Rapid growth in population and land cover makes urban areas more vulnerable to Urban Heat Island. Due to which, cities experience higher mean temperature than its proximate surrounding rural or non-urban area. The relationship between UHI and urbanization is proven in previous studies. Delhi the capital city of India is well known for its extreme heat condition in summer and air pollution. In this study, an attempt has been made to understand UHI behavior in a satellite town of Delhi. Satellite town or cities are the small independent towns built in the vicinity of a large city or metropolitan city. In this paper 4 major satellite towns of Delhi, i.e. Gurugram (name changed from Gurgaon in April 2016), Noida, Faridabad and Ghaziabad has been studied to understand the changing trends in urbanization and temperature. The parameters used are rate of urban expansion, population density, GDP growth and increasing temperature over the last two decades. Gurugram showed the maximum urbanization and identified as study area. Gurugram has undergone a major growth journey from being a small town to ĝ€The Millennium city' of the country in a short span. The Landsat images of past three decades ranging from different time period i.e. 1990, 1996, 2002, 2009, 2014 and 2018 were investigated by applying integrated approach of GIS and Remote sensing. The images represent the condition of UHI and urbanization in different period. The temporal change in LULC was used to study the rate of urban growth in last three decades. The results showed the increase in built-up area out of the total area of Gurugram from 10% (i.e.50.6&thinsp;sq.&thinsp;km) in 1990 to 17.25% (80.5&thinsp;sq.&thinsp;km) in 2002 which further increased to 45.1% (210.4&thinsp;sq.&thinsp;km) in 2018. Thermal Infrared band of Landsat series were used to retrieve land surface temperature (LST) intensity of the study period. The results show a positive correlation (r&thinsp;Combining double low line&thinsp;0.46) between impervious surfaces and LST. The results of the study could be helpful in identifying the causative factors and level of impacts in different zones and also enable us to develop a mitigation strategy based on spatial decision support system.",60115214,TERI School of Advanced Studies,New Delhi,India,['1710'],18.42105263157895,-0.024600265326071773,0.3503718056137411,1,0.08793969849246232,0.07537688442211055,0.3855140186915888
895,918,918,Benin: Combining knockout data with time series gene expression data for the gene regulatory network inference,"Gene regulatory network inference is one of the central problems in computational biology. The limited availability of biological data as well as the intrinsic noise they contain have triggered the need of models that integrate the vast variety of data available to take advantage of the complementarity of the information they provide about regulation. With this idea in mind, we propose Benin: Biologically Enhanced Network INference. Benin is a general framework that jointly considers prior knowledge with expression data to boost the network inference. This method considers network inference as a feature selection problem. To solve it, Benin uses a penalized regression method, elastic net, combined with bootstrap resampling. Using the benchmark dataset from the DREAM 4 challenge, we demonstrate that, when using times series expression data with knockout gene expression data, Benin significantly outperforms other methods.",60033154,Concordia University,Montreal,Canada,"['1712', '1709', '1707', '1705']",19.571428571428573,0.06984126984126986,0.3936507936507936,1,0.125,0.07894736842105263,0.25
896,919,919,Voluntary disclosure of integrated reporting elements: The malaysian public listed companies evidence,"The Integrated Reporting (IR) Framework aims to provide guidelines to the corporate reporting societyconcerning the overall content of an integrated report. The objective of this study is to explore the voluntary disclosure of the eight content elements of the IR Framework by companies listed on the Bursa Malaysia. Annual reports of 603 companies listed on the Main Market of Bursa Malaysia for 2015 were examined. Findings show that majority of the respondents, 497 (82.42%), disclose between 71% to 80% information related to the companies’organizational overview and external environment, which is the first IR content element. Meanwhile the majority of the companies, 572 (94.86%), disclose between 81% to 90% information related to second IR content element that is governance. Regarding the third IR content element, business model, the majority of the companies, 411 (68.16%), disclose only between 41% to 50% of this information and 568 (94.2%) companies disclose between 51% to 60% of the information related to the companies’ risks and opportunities which is the forth IR content element. Further, for IR content element five, strategy and resource allocation, the majority of the companies, 466 (77.28%), disclose between 51% to 60% of the said information. For the next IR content element which is performance, the majority of the companies, 494 (81.92%), disclose only between 31% to 40% information concerning the companies’ performance. Subsequently, the majority of the companies, 495 (82.09%), disclose between 41% to 50% of the information on the seventh IR content element that is outlook. Finally, on the information regarding basis of presentation, the level of disclosure for the majority of the companies, 495 (82.09%), is between 41% to 50%.The findings reveal that disclosure of most of the IRcontent elements isstill below the high level in Malaysia. This implies the need to intensely encourage companies to disclose more information in supporting the initiative towards furnishing a more comprehensive corporate report.",60012005,Multimedia University,Malacca Town,Malaysia,['1700'],28.272727272727273,0.10527777777777776,0.3711111111111111,1,0.06940874035989718,0.05398457583547558,0.43765903307888043
897,920,920,Modeling Publication Activity of the Faculty and Managing Scientific Indicators of the University,"The article is devoted to the development of tools for analysis and forecasting of performance indicators of Russian universities that have a direct impact on the performance of the program ""Digital Economy of the Russian Federation"", as well as national projects. The proposed tools are based on mathematical modeling of the results of the publication activity of the University faculty, presented in the world's leading scientometric systems. For example, we consider one of the leading Russian universities (excluding branches). The publications of its employees in publications indexed in information-analytical systems of scientific citation Scopus and Web of Science from 2000 to 2018 were analyzed. All employees were divided into groups, depending on their publication activity, expressed in the form of the annual number of publications. When modeling the transition of employees from one group to another, depending on the number of their publications, the apparatus of Markov chains was used. The constructed model was used to predict possible scenarios of changes in the total number of publications of the organization in the databases of Scopus and Web of Science. The direct task of implementing several scenarios of increasing the number of publications was considered, as well as the inverse problem of finding a management solution to achieve a result in a timely manner. As a result, it was found that the most acceptable for this University scenario is the one in which a third of the faculty staff annually increases the number of publications by 1.5 units within two years. From a practical point of view, the presented results are useful for the University administration to assess the current state of the publication activity of the organization as a whole and its improvement in the near future. This will lead to an increase in the indicators of scientific activity of the University and strengthen its position in the world rankings. The use of the proposed tools will contribute to the solution of tasks to achieve the indicators of the program ""Digital Economy of the Russian Federation"", in particular, Russia's place in the ranking of GTCI, as well as the national projects Education and Science.",60031202,Petrozavodsk State University,Petrozavodsk,Russian Federation,"['1712', '1709', '1707', '1705']",29.5,0.07333333333333332,0.23541666666666666,1,0.08483290488431877,0.05912596401028278,0.268733850129199
898,921,921,"DETECTION of ALGAL BLOOM in the COASTAL WATERS of BORACAY, PHILIPPINES USING NORMALIZED DIFFERENCE VEGETATION INDEX (NDVI) and FLOATING ALGAE INDEX (FAI)","Boracay is a top tourist island in the Philippines known for its 4-km beach with powdery white sand. Recently, abundance of green algae, an indicator of high nutrient discharge, along the coastal waters of the island had led to concerns on its water quality and prompted its closure to allow ample time for rehabilitation. This study examined the algal bloom along the coastal waters of Boracay through the determination of Normalized Difference Vegetation Index (NDVI) and Floating Algae Index (FAI). ENVI and SNAP software were used to process the satellite images of Boracay obtained from its pre-closure to its reopening. Necessary corrections such as scaling to Top of Atmospheric radiance were applied. NDVI was calculated using orthotile images to determine vegetation and FAI was calculated using Sentinel-2A images. Secondary data showed that the coliform level decreased from 1 million to 18.1 MPN per 100 mL after the rehabilitation of Boracay. Lower NDVI and FAI index values were observed during the reopening of the island. The NDVI value decreased while the FAI value slightly increased on the 1st month of closure which was late dry season. Both NDVI and FAI values increased to their maximum during early wet season and eventually decreased during the reopening of Boracay. Results showed that the abundance of algae had lowered after the rehabilitation of Boracay. However, fluctuating NDVI and FAI values showed the possible seasonal effects on the algal bloom in the island. Further studies considering the other factors on algal blooms may be done.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],19.23076923076923,-0.05706349206349206,0.4729365079365079,1,0.11721611721611722,0.11355311355311355,0.3763837638376384
899,922,922,Structural performance of semi-regular topological interlocking assemblies,"The principle of Topological Interlocking (TI) suggests using discrete blocks for assembling self-supporting structures. Several studies showed high quality Finite Element analyses for simple types of interlocking assemblies, composed of either tetrahedral or cubic blocks. Recent research has revealed that there are many more types of blocks suitable for assembling interlocking structures. The presented paper is part of an ongoing research on TI in architecture. The current stage of the research focuses on the correlation between the geometry of TI blocks and the structural performance of the whole assembly. The paper presents the results of a series of numerical analyses of various TI-based structures, revealing interesting relations between geometrical parameters and the force-deformation response of TI assemblies.",60022403,Technion - Israel Institute of Technology,Haifa,Israel,['1705'],19.5,0.21909090909090911,0.42701298701298696,1,0.12030075187969924,0.06766917293233082,0.3858267716535433
900,923,923,"Using timed and coloured Petri nets for modelling, simulation, and analysis of integration solutions","Enterprise application integration (EAI) is a research field that seeks to develop methodologies, techniques and tools for the design and development of integration solutions. In this work, we propose to develop a mathematical model to simulate integration solutions in the design phase, i.e., before the implementation and testing stages. The aim of this simulation is to analyse the behaviour and identify the possible performance bottlenecks of the integration solutions. In this way, it is possible to identify problems prior to the implementation and testing stages. A conceptual model of the integration solution was translated into a mathematical model of the simulation using Petri nets. A real-life problem in the area of marketing was used as a case study. Finally, verification of the equivalence of the formal simulation model using timed and coloured Petri nets and the conceptual model, was performed using formal verification techniques widely found in the literature.",112651365,Unijuí University,Ijui,Brazil,"['1710', '1708', '1705']",21.285714285714285,-0.014285714285714287,0.4857142857142857,1,0.10179640718562874,0.017964071856287425,0.2727272727272727
901,924,924,Current Problems of the Higher Education Development in the Russian Federation Considering the Digitalization Processes,"The authors of this article single out the main characteristic of the digital economy-the constantly changing volume of information, as a result of which the need to thoroughly disseminate digital technologies meant to stimulate the formation of new ways and methods of property management, the growth of the industry efficiency and the development of the economy as a whole arises. The article remarks on one of the most significant drawbacks of the digital economy-reducing a significant number of jobs, which can later lead to some serious threats to the economic security of the state such as the increase in polarization of the populace incomes, which can result in strengthening of social tensions, the ""disappearance"" of a number of professions, which will inevitably lead to an increase in unemployment rate, which, in its turn, will contribute to the growth of crime. Currently, when the system of university education is undergoing colossal changes, the questions of digitalization of universities' business and organizational communication processes are the topics of particular interest to both the students and their employees. The topicality of the problem is based on the need to analyze current practices in organizational communications and approaches to creation and development of policies and strategies of introduction of digitalization elements in higher education organizations aimed at ensuring their competitiveness in the globalized world. The goal of this work lies in systematization of current issues in the higher education sphere in the Russian Federation and development of measures of education system development in Russia considering the digitalization processes.",60107796,The St. Petersburg State University of Economics,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",50.8,0.09544622044622043,0.3930319680319681,1,0.09025270758122744,0.01444043321299639,0.20512820512820512
902,925,925,A psychologist chatbot developing experience," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Chatbots are computer programmes that mimic human conversation to interact with users through a variety of messaging channels. They are now regularly deployed on e-commerce and business websites providing customer support. Chatbots have also been employed for research and clinical support in the healthcare domain. In the field of psychology, chatbots have been applied to clinical research where survey or interview data collection are substituted with chatbots that can interact with the subjects via phone messaging apps in a non-clinical setting. This paper examines the design and development of a chatbot for a clinical psychology research study. The stakeholders, functionality, perspectives and technical challenges are presented and discussed. We apply a quality of experience framework to explore the factors that impact stakeholders and influence design priories. We present our conclusions regarding the leveraging cloud platforms and the technical customisation required for non-standard chatbot use cases.",60005141,University College Dublin,Dublin,Ireland,['1700'],19.625,0.07142857142857142,0.19670329670329675,0,0.12,0.04,0.36470588235294116
903,926,926,Investigating company logo memorability with convolutional neural embedding models," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The present study compared several state of the art neural embedding models for the correlation of their embeddings with human judgements, relating to both human memory and relevance ranking. These models included two embedding models, DeepRank and Ranknet; two classification models, ConvNet and VisNet; and a Variational Autoencoder. To assess each model's performance, two custom evaluation metrics were developed: a fine detail coefficient and a coarse detail coefficient. These measures revealed that the embeddings produced by the DeepRank model had the highest correlation with human judgement. This design combination of a tri-linear architecture, triplet loss function and semi-hard negative sampling did best at capturing the similarities between the images, achieving the highest overall result for both the fine detail and coarse detail coefficients. The embeddings produced by the DeepRank model were then used to investigate the memorability of each company logo. However, as image memorability cannot be characterised by low-level features alone our results suffered. In addition, the results show that deep features extracted from the embedding models show markedly better results on fine classification and retrieval tasks than their classification counterparts.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],24.25,0.16944444444444445,0.31666666666666665,0,0.0990990990990991,0.06306306306306306,0.3824884792626728
904,927,927,Robust multi-modality multi-object tracking,"Multi-sensor perception is crucial to ensure the reliability and accuracy in autonomous driving system, while multi-object tracking (MOT) improves that by tracing sequential movement of dynamic objects. Most current approaches for multi-sensor multi-object tracking are either lack of reliability by tightly relying on a single input source (e.g., center camera), or not accurate enough by fusing the results from multiple sensors in post processing without fully exploiting the inherent information. In this study, we design a generic sensor-agnostic multi-modality MOT framework (mmMOT), where each modality (i.e., sensors) is capable of performing its role independently to preserve reliability, and could further improving its accuracy through a novel multi-modality fusion module. Our mmMOT can be trained in an end-to-end manner, enables joint optimization for the base feature extractor of each modality and an adjacency estimator for cross modality. Our mmMOT also makes the first attempt to encode deep representation of point cloud in data association process in MOT. We conduct extensive experiments to evaluate the effectiveness of the proposed framework on the challenging KITTI benchmark and report state-of-the-art performance. Code and models are available at https://github.com/ZwwWayne/mmMOT.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",26.285714285714285,0.040909090909090916,0.4087121212121213,1,0.08658008658008658,0.030303030303030304,0.3349282296650718
905,928,928,"Estimation of above ground forest biomass using ultra high resolution UAV images: A case study from Barandabhar forest, Nepal","Forest biomass is the sum of above ground living organic material contained in trees which is expressed as dry weight per unit area. Forest biomass acts as substantial terrestrial carbon sinks, they are estimated to absorb 2.7&thinsp;Petagrams of carbon per year, as such accurate estimation of forest carbon stock is very important. The estimation of biomass is also important because of its application in commercial exploitation as well as in global carbon cycle. Particularly in the latter context, the estimation of the total above-ground biomass (TAGB) with sufficient accuracy is vital in reporting the spatial and temporal state of forest under the United Nations Framework Convention on Climate Change (UNFCCC), Reducing Emissions from Deforestation in Developing Countries (REDD). In this research, tree height, DBH and crown cover were measured using field instruments. Individual ultra-high-resolution UAV images acquired using customized Visible-NIR, were georeferenced and tree crown were extracted using multi-resolution segmentation. A regression equation between field measured biomass and Crown Projection Area (CPA) was developed. The paper presents results from Barandabhar Forest of Chitwan District, Nepal. RMSE of ortho-mosaic was found to be 18&thinsp;cm. While R2 value of 89% was obtained for relationship between DBH and biomass, that of 61% was attained for relationship between CPA and biomass.",60071792,Kathmandu University,Dhulikhel,Nepal,['1710'],20.7,0.095,0.3822916666666667,1,0.0846774193548387,0.11290322580645161,0.430327868852459
906,929,929,An evaluation of the impact of training data locality on the effectiveness of knowledge graph embeddings models," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).As the volume and variety of data that many modern organisations deal with continue to grow, graphs are becoming increasingly important and relevant as a means of organising this data. This work looks at a possible way to improve the training of some state-of-the-art machine learning models in the area of knowledge graph embeddings. Where the interest of the user is on the ability to predict the existence of a particular link type as opposed to predicting links generally, subsets or sub-graphs could possibly be used to train the model more effectively than the entire graph. We evaluate the performance of two state-of-the-art knowledge graph embedding models on the task of predicting a specific link type. The models are first trained with all of the available training data and subsequently with subsets or sub-graphs based on the locality of the link type we wish to predict. We find that there is evidence that using less training data can in some cases actually improve the performance of the model. Finally, we look at some graph features and examine if there is any correlation between these and the accuracy/performance of the machine learning models. While no strong correlation is found, the results point to further work being required to understand this phenomenon.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],27.75,0.17536231884057968,0.5485507246376812,0,0.1225296442687747,0.02766798418972332,0.23728813559322035
907,930,930,Formalization of functional variation in HOL Light,"Functional variation is an important fundamental mathematical theory widely used in engineering analysis, especially in dynamics based design. However, its formalization still remains unexplored and this makes the verification of dynamic properties of engineering structures quite cumbersome. The present paper aims at initiating the formalization of this theory. For this purpose, the function-space theory is first formalized and then it is formally proved that this continuous function space is a Banach space. Then, linear functionals based on this function space are formalized. Further, the functional variation in the Fréchet derivative form and its main properties are formalized. Then the necessary condition of functional extrema is formally verified. Lastly, we formally verify the continuous functional and mean value theorem of functional variation for demonstrating the application of the formalized functional variation. The present formalization work can serve as a foundation for the formal verification of dynamic behavior of mechanical systems.",60020256,Capital Normal University,Beijing,China,"['1712', '1703']",16.555555555555557,0.028869047619047617,0.4038690476190476,1,0.0963855421686747,0.012048192771084338,0.23780487804878048
908,931,931,Assessing the performance of UFAD system in an office building located in various climate zones,"The energy performance of Underfloor Air Distribution (UFAD) system is previously investigated in several studies. Energy saving is known to be one of the benefits of UFAD in comparison to other all-air systems; however, there has been some controversy over the performance of UFAD system in each climate. This paper aims to investigate the role of the climatic condition on the energy behavior of the UFAD, compared to the Over Head (OH) air distribution system. To that end, the effects of temperature and humidity on the energy performance of the system are examined in detail. The overall research plan is based on simulating one story of an existing office building in Phoenix with EnergyPlus. The validated model is then used in different ASHRAE climate zones to predict energy consumption in terms of cooling loads, heating loads and fan energy usage for the two systems: UFAD and OH. These comparative analyses have led to a comprehensive understanding of the energy performance of UFAD and OH systems under different climatic conditions. The Results section highlights the overall efficiency of UFAD system, pointing to different percentages of energy saving in each climate. It is found out that UFAD system works best in San Francisco with 26 percent of energy saving and relatively warm climatic conditions, while climates that were too hot or too cold adversely effected the energy saving performance. The lowest percentage of energy saving is 10.31 percent for Duluth in the very cold climate category. The energy saving percentages were then visualized on the map to provide a better spatial understanding of this system’s effectiveness.",60006951,The University of North Carolina at Charlotte,Charlotte,United States,['1705'],24.0,0.04845238095238096,0.4708333333333333,1,0.06896551724137931,0.06896551724137931,0.2698961937716263
909,932,932,Impact of the Digital Economy on Investment Projects,"Formation and development of the digital economy is a crucial issue not only in theory, but also in practice due to the influence of digital technologies on economic growth, investment opportunities, competitiveness and economic security of both the country and its entities. Potential impact of the digital economy on innovations and investments was not sufficiently studied by domestic researchers. The study focuses on formation of a breakthrough system and approaches to investments, forecasting and management decision-making against the backdrop of development of the digital economy. The article describes the digital economy's impact on development of priority investment projects, highlights strengths of the national economy and main steps to develop the digital economy. The study is based on the principles of the methodology of economic growth, methodology of investment-driven development contributing to a new approach to the evaluation of investment projects in the conditions of the economy's digitalization. Research and methodological approaches used in the study: basic research methods (generalization, formalization, comparison), analogy, economic analysis, expert estimates. Theoretical significance of the research results is conditioned by development of basic theoretical approaches to the study of the economy's transition to the digital path of development, formation of ideas about the digital model of management. The methodological tools will allow developing an effective mechanism of interaction between public authorities, businesses and research institutions in the context of development of the digital economy. The described methodological approach will allow studying the impact of the digital economy on investment projects. The practical significance of the study lies in application of digital economy tools to investment projects in a changing environment. Research results will allow implementing digital startups which affect the performance of promising investment projects.",60021535,Ural State University of Economics,Yekaterinburg,Russian Federation,"['1712', '1709', '1707', '1705']",25.45454545454545,0.059267676767676775,0.2293181818181818,1,0.0732484076433121,0.0,0.24838709677419354
910,933,933,Digitalization of a Tourist Destination,"Today digitalization is no longer an innovative process but a necessity, since it enhances interconnection among subjects using digital technologies; it is involved in all the economy branches, including the tourism industry. One of the most important study objects in tourism is a tourist destination. Its digitalization needs to be interconnected with digitalization of tourism on all the levels of economy. Tourist destination digitalization can be viewed from the perspectives of both a process and a systematic approach. However, they do not deny but complement each other. The article reveals the tools using which an increase in the level of digitalization of the territory is achieved. The following 10 types of instruments were highlighted: digital marketing, cloud technologies, information support, Internet of things, virtual tourism, smart territory, navigation satellite systems and geographic information systems, electronic document management, artificial intelligence, big data, as well as some distributed registry utilities. Their application in the complex will increase the income of the territory, optimize tourist flows, and allow to effectively make management decisions. We have developed a rank scale of digitalization and an index of digitalization of the tourist destination as methods for assessing the level of digitalization. The rank scale is applied when considering a digital destination according to the process approach; its values depend on the number of digital tools used by the tourist destination in the digitalization process. We need to remark that in order to achieve the minimum level of digitalization, a destination has to have its own Internet website and use one or two of the digitalization tools described, and to achieve the maximum level-from nine to ten tools. The tourism destination digitalization index is used when considering digitalization as a system. It is based on an assessment of the effectiveness of digitalization and represents the ratio of the gross tourist product of a destination and the cost of implementing digital tools. Different levels of use and a set of digital tools characterize tourist destinations; however, they should all strive to improve their level of digitalization.",60107796,The St. Petersburg State University of Economics,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",24.142857142857146,0.012577639751552785,0.418167701863354,1,0.11702127659574468,0.005319148936170213,0.24331550802139038
911,934,934,Interval valued multi criteria decision making methods for the selection of flexible manufacturing system,"In real world multi criteria decision making (MCDM) problem, it is tough to solve a decision matrix with vague and imprecise data. The degree of impreciseness depends on the kind of data available. For interval valued data this impreciseness is less and interval-valued MCDM methods can be effectively used to solve the problem. A flexible manufacturing system (FMS) selection problem was taken into consideration to find the best FMS among available alternatives. An interval extension of CODAS method is proposed in this paper which was used to solve the problem along with two other interval-valued decision-making methods i.e. interval-valued TOPSIS, interval-valued EDAS. All the three methods are distance-based approaches and it was found that the interval-valued CODAS method gave the exact same ranking with that of interval-valued TOPSIS and interval-valued EDAS.",60115566,Shri Shankaracharya Institute of Professional Management and Technology,Raipur,India,"['1705', '1710', '1712', '1706', '1702']",18.714285714285715,0.1891203703703704,0.4375,1,0.13664596273291926,0.055900621118012424,0.3333333333333333
912,935,935,Managerial Decisions on the Effective Systems of Remuneration at Crisis Enterprises in Digital Environment,"Crises have become an integral part of everyday life. The development of crises in enterprises depends on the activities of all categories of workers, and the personnel management system is an essential element of crisis management. The purpose of the research is to describe the mechanism for making managerial decisions on the effective systems of remuneration at crises enterprises in a digital environment. Preservation of the most effective employees in crisis requires the use of special methods of motivation and organization of remuneration. For the financial justification of the implementation of this task, the article proposes a decision-making procedure and a system of calculations based on the separation of the principles of external and internal analysis, the development of the regulatory budget of the company and the business plan to overcome the crisis. Recommendations were made for companies: conducting an external financial analysis of the company to assess the financial capabilities of the enterprise, calculation of the regulatory budget and development of the program of internal financial analysis, conducting internal financial analysis and preparation of special reports, and development of options for a business plan for withdrawing a company from a crisis with various incentive systems for personnel to decide on financing.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",33.666666666666664,0.11654135338345865,0.2548872180451128,1,0.06912442396313365,0.0,0.1813953488372093
913,936,936,Multimodal Learning with Triplet Ranking Loss for Visual Semantic Embedding Learning,"Semantic embedding learning for image and text has been well studied in recent years. In this paper, we present a simple while effective dual-encoder (image encoder and text encoder) framework to unify image and text into a common embedding space. Inspired by deep metric learning, we utilize triplet ranking loss to minimize the gap between the two embedding spaces. We train and test our proposed framework on Flickr8k, Flickr30k and MS-COCO datasets respectively, and evaluate the framework on the Corel1k benchmark dataset as an application. Using VGG-19 for image encoder, GRU for text encoder and triplet ranking loss, we gained obvious improvement versus baseline model on image annotation and image search tasks. Additionally, we explore the vector generated by our image encoder and the one by word embedding of plain word for some arithmetic operations. The above experiments demonstrate the effectiveness of our proposed learning framework.",60122052,Southwest University,Chongqing,China,['1700'],20.857142857142858,0.008571428571428572,0.3364285714285715,1,0.12650602409638553,0.030120481927710843,0.3333333333333333
914,937,937,EXPLORING LAND COVER EFFECTS on URBAN AIR QUALITY: A CASE of 659 DISTRICTS in India,"Land use and land cover changes (LUCC) affects the atmospheric environment directly or indirectly. Therefore, understanding the atmospheric response to LUCC is of great significance to maintain and improve the ecological environment. In this study, based on fine particulate matter (PM2.5) and LC products, we first compared the differences of PM2.5 between urban and surrounding areas, and then further investigated the variations of PM2.5 in different and land cover (LC) using Mann-Kendall (MK) test and Sen's trend analysis approach at the district-level in India during 1998-2015. The results showed that the numbers of districts where the differences of PM2.5 (DPM2.5) between urban and the surrounding areas were greater than zero were increasing during 1998-2015. There is an upward trendency of annual mean PM2.5. The annual mean PM2.5 was higher than 40 μg/m3 in 58% of India's areas where there were mainly located in the Ganges plains of northern India with cropland (L01) and urban areas (L07). The annual mean PM2.5 was less than 10 μg/m3 were mainly found in north-western India with permanent ice and snow (L10), accounting for 10% of India's area. There are significant positive trends of PM2.5 concentration in 90% of cropland (L01) and 88% of urban area (L07) and the average slope were 0.83 μg/m3 and 0.82 μg/m3 respectively, which were higher than those in the rest of LC. This research serves as the basis of reference for the equitable allocation of land resources and restructuring of land use and land cover patterns in urban areas of India that severely affected by air pollution.",60019499,Chinese Academy of Sciences,Beijing,China,['1710'],28.66666666666667,0.09807800224466892,0.3666526374859708,1,0.05345911949685535,0.11635220125786164,0.37666666666666665
915,938,938,Digital Transformations in the Development of Cooperative Network Interactions,"Currently, we can observe several trends arising in modern development, namely, the transformation of digital technologies and the formation of fundamentally different properties for the development of business on their basis, as well as significant changes in the practice of business, community, consumer and government interactions. The article analyzes the processes of business development of new realities of markets and modern technologies, digitalization, and intellectual solutions as a result of basic innovation of post-industrial development. This creates new opportunities that are qualitatively different from before and require significant changes in management, interfirm and interpersonal relationships, policies of states and organizations. In researching these phenomena, we use the data obtained during our own research in the field of studying the connection of the formation of cooperative-network relations with the development of digital technologies in the modern economy. The findings of the study were obtained through the use of an integrated method that operationalizes and develops previously published works in the marketing aspect in the context of cooperation and integration of enterprises from the standpoint of co-competition and the phenomenon of collective reputation of economic agents. We can state that new processes are developing in the following directions: intensification of work with consumers and focus on the adjustments of activities and products to the consumer and his needs; change of enterprise's operational processes and increased use of modern digital technologies, chiefly software products, including those based on digital platforms; changes in business models of enterprises and, above all, the development of an effective process of achieving competitiveness and growth of economic efficiency in the value chains of cooperative network interactions. We can conclude that at specific enterprises, in their interactions with partners, infrastructure organizations, state and municipal bodies, a modern post-industrial development trend-the widespread introduction of digital technologies arises.",60075346,Siberian Federal University,Krasnoyarsk,Russian Federation,"['1712', '1709', '1707', '1705']",42.42857142857143,0.13422152560083594,0.3251828631138976,1,0.07418397626112759,0.0,0.3119266055045872
916,939,939,Measuring regional progress towards sdg 3 with geospatial and statistical information - A case study of deqing county," CC BY 4.0 License.The 17 Sustainable Development Goals (SDGs) were proposed in 2030 Agenda for Sustainable Development of the United Nations in 2015, in which SDG 3 is about ensuring healthy lives and promoting well-being for all ages. The assessment on SDG 3 helps to measure or monitor the level of sustainable and healthy development of nation or sub-nation regions. However, the SDG 3 is mainly aimed at the global or national levels, and lack of quantitative assessment and analysis. Therefore, this paper, taking Deqing County of Zhejiang Province in China as an example, presents a pilot study which measured county-level SDG 3 by using statistical information and geospatial information. There are three main steps: Firstly, a set of localized indicators for SDG 3 was built according to adaptability, scalability, and coverage, combined with the specific conditions of Deqing County. Secondly, the selected indicators were calculated by combining integration of statistical and geospatial information. Thirdly, an assessment based on dashboard was processed. The results showed that 12 of the 15 health-related indicators in Deqing County were evaluated as green, 1 was yellow, and 2 were gray. The morbidity rate and mortality rate of infectious diseases in 2010-2017 are low and essential health-care services are equally covered in space. This study provides scientific basis for the management of healthy and sustainable development in Deqing County, and provides a reference example for monitoring and evaluation of SDG 3 in other regions.",60108755,"China University of Mining &amp; Technology, Beijing",Beijing,China,['1710'],24.0,0.10989583333333336,0.259375,0,0.09219858156028368,0.0851063829787234,0.42696629213483145
917,940,940,Toward a multi-level and multi-paradigm platform for building occupant simulation,"In recent years, simulation has been used to investigate building-occupant relations while focusing on pedestrian movement, day-to-day occupancy, and energy use. Most of these efforts employ discrete-time simulation, where building and occupant properties are constantly updated at fixed time steps to reflect building and occupant dynamics. Real-world occupant behavior, however, involves a variety of decision-making patterns that unfold over different time scales and are often triggered by discrete events rather than gradual change. In working toward a platform supporting the full range of human activities in buildings, we embed a discrete-time occupant movement simulator called SteerSuite within a general-purpose discrete-event simulation framework called SyDEVS. With preexisting SteerSuite functions providing low-level steering behavior, and newly implemented SyDEVS nodes providing high-level planning behavior, our prototype represents a multi-level and multiparadigm approach to occupant simulation for building design applications.",60119141,Rutgers University–New Brunswick,New Brunswick,United States,['1705'],27.2,0.1484848484848485,0.3597643097643098,1,0.13793103448275862,0.022988505747126436,0.37333333333333335
918,941,941,An experimental study of convective heat transfer coefficient and nusseltnumber for fruits inside faccc for sustainable cold chain,"Temperature change for several agriculture products, such as fruits, for maintaining shelf life potency varies during storage and transportation. Design of Free Air Cooling Conditioning Chamber (FACCC) is introduced through this paper for temperature control of fruits to improve cold supply chain effectiveness during transportation. Temperature control by improving the heat transfer rate of fruits improves the shelf life of the commodity and maintains its potency. In this paper, we have studied the skin mass transfer coefficient of different commodities and established the same as a function of the Stanton number and Prandtl number through Reynolds analogy. Accordingly, we calculated the Stanton number of different commodities for various values of the Reynolds number, which is obtained by operating four fans fitted in FACCC. Paper calculates heat transfer rate, and Nusselt number for selected fruits and the experimental results show that Nusselt number varies 29.65 to 190 inside the FACCC with varying airflow conditions and with different temperatures. Surface heat transfer coefficient inside the FACCC varies from 17 W/m2K to 278 W/m2K supported by the different ambient condition. Validation of FACCC performance has been done by comparing the heat transfer rate and Nusselt number from published literature. Thus, it is found that the use of FACCC is effective in improving the cold chain of fruits in hot countries where a large amount of agriculture products get wasted due to improper storing and transportation.",60020458,Jamia Millia Islamia,New Delhi,India,['1700'],25.777777777777782,0.0023109243697479014,0.5399159663865546,1,0.10546875,0.078125,0.332
919,942,942,Prospects for Innovative Development of World Automotive Market in Digital Economy,"Digital transformation, creating new digital enterprises, products and business models, is changing the structure of industries. Automotive, as a high-tech industry, ranking the third in the world in terms of R&D costs, is now becoming one of the leading drivers in the development of the digital economy. The aim of this work is to study the digital technology impact on the product and regional structure of the global automotive market, as well as to assess the prospects for its innovative development. The work analyzes main trends in the automotive market, explores the R&D activity and R&D efficiency of the world's leading automakers, presents a forecast for the innovative development of the industry under the influence of digital technologies. The research results conducted in the work show that the main trends that have the most significant consequences for the future development of the automotive market in the context of its digitalization are emergence of fundamentally new digital products (autonomous, connected cars) and digital services (mobility services), as well as a change in the quality of consumer demand caused by the development of innovative technologies. Adapting new digital products and services to the needs of individual customers through the creation of an appropriate digital strategy will allow existing automotive enterprises to enter the emerging markets and win the growing digital competition with innovative startups.",60021331,Russian Academy of Sciences,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",37.0,0.198876698014629,0.3579414838035528,1,0.08943089430894309,0.0,0.256
920,943,943,Analysis of innovation development factors of the Russian economy,"The subject of the research is the innovative factors of development of the Russian economy. The aim of the study is to determine the role of factors of innovative development in the Russian economy. The study is based on a systematic approach using statistical analysis methods. In the process of analysis of the methodological provisions of innovative development numerous problems were identified: the complexity of the implementation of the contract for innovation; public funds reduce the lack of capital, but increase the corruption component; the effectiveness of RandD costs is determined by not always affordable education; competition reduces incentives for innovation by reducing monopoly rents, etc. But the need to increase productivity and the prospects for monopolization of individual markets, including through the ""targeted licensing"" of technologies, contribute to the upward trend of innovative development of both individual firms (corporations) and countries as a whole. The analysis of the factors of innovative development of the Russian economy includes the assessment of the dynamics of gross domestic expenditure on RandD, including the expenses of organizations on RandD by sources of financing and sectors of activity. The results of the analysis of the dynamics of RandD expenditures showed stable growth in the public sector and entrepreneurship. The Russian public sector for the development of entrepreneurship in multiples supports the cost of RandD of commercial enterprises. The results of the comparison of Russian GERD with Germany, Japan, the USA and China show the inability of the Russian public sector, commercial enterprises and the government to manage the costs of RandD. The assessment of the factors of innovative development of the Russian economy revealed a significant state impact on the cost structure of RandD. It is revealed that the further innovative development of the Russian economy is not possible without reducing the influence of the public sector and the growth of external technologies and investments, through the intensification of trade with China.",60011928,Chuvash State University,Cheboksary,Russian Federation,"['1712', '1709', '1707', '1705']",28.90909090909091,0.11843434343434345,0.3618686868686868,1,0.06686046511627906,0.03197674418604651,0.2398843930635838
921,944,944,Improved Feature Selection Algorithm for Biological Sequences Classification,"Biological data is undergoing exponential growth in both the volume and complexity. Indeed, the selection of biological features is an important step that aims to reduce the curse of dimensionality to improve prediction performance in classification systems. In this paper, we focus on protein sequence classification which constitutes an important problem in biological sciences. We represent in first a comparative study between classical filter feature selection algorithms and feature selection methods based on new correlation techniques in order to identify relevant, not redundant features. Then, we propose an improved version of Strong Relevant Algorithm for Subset Selection (STRASS) algorithm called “optimized STRASS algorithm” that uses new correlation metrics to reduce irrelevant and redundant features. Experimental results show the effectiveness of this work. The proposed method can be applied to high-dimensional data. The final aim of this study is to select the best pairwise combination of filter feature selection method and the best classifier that enhances the accuracy of protein classification.",60107598,Université de Jendouba,Jendouba,Tunisia,['1700'],20.0,0.25350378787878786,0.5734848484848486,1,0.11235955056179775,0.03932584269662921,0.26704545454545453
922,945,945,A Novel Method for Highly Imbalanced Classification with Weighted Support Vector Machine,"In real life, the problem of imbalanced data classification is unavoidable and difficult to solve. Traditional SVMs based classification algorithms usually cannot classify highly imbalanced data accurately, and sampling strategies are widely used to help settle the matter. In this paper, we put forward a novel undersampling method i.e., granular weighted SVMs-repetitive under-sampling (GWSVM-RU) for highly imbalanced classification, which is a weighted SVMs version of the granular SVMs-repetitive undersampling (GSVM-RU) once proposed by Yuchun Tang et al. We complete the undersampling operation by extracting the negative information granules repetitively which are obtained through the naive SVMs algorithm, and then combine the negative and positive granules again to compose the new training data sets. Thus we rebalance the original imbalanced data sets and then build new models by weighted SVMs to predict the testing data set. Besides, we explore four other rebalance heuristic mechanisms including cost-sensitive learning, undersampling, oversampling and GSVM-RU, our approach holds the higher classification performance defined by new evaluation metrics including G-Mean, F-Measure and AUC-ROC. Theories and experiments reveal that our approach outperforms other methods.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],25.285714285714285,0.0014935064935064938,0.512972582972583,1,0.11818181818181818,0.06818181818181818,0.365
923,946,946,A Causality-Based Approach to Assessing Inconsistency for Multi-context Systems,"Nonmonotonic multi-context systems provide a promising starting point to interlink heterogeneous and decentralized knowledge contexts effectively by modeling the information exchange among contexts instead of logics of contexts uniformly by virtue of bridge rules. Inconsistency handling has been considered as one of the important issues in multi-context systems, since inconsistency makes a multi-context system useless. In this paper, we propose an approach to assessing the responsibility of each bridge rule of a multi-context system for the inconsistency of that system, which helps us better understand roles of bridge rules involved in inconsistency from the point of view of causality.",60014966,Peking University,Beijing,China,['1700'],33.0,0.20000000000000004,0.5166666666666667,1,0.08849557522123894,0.017699115044247787,0.26666666666666666
924,947,947,The contribution of geomatic technologies to BIM,"There are many definitions of the commonly used abbreviation BIM, but one can say that each user or data supplier has different idea about it. There can be an economic view, or other aspects like surveying, material, engineering, maintenance, etc. The common definition says that Building Information Modelling or Building Information Management (BIM) is a digital model representing a physical and functional object with its characteristics. The model serves as a database of object information for its design, construction and operation over its life cycle, i.e. from the initial concept to the removal of the building. BIM is a collection of interconnected digital information in both protected and open formats, recording graphical and non-graphical data on model elements. There are two facets: a) BIM created simultaneously with the project, or project designed directly in BIM (it is typical of new objects designed in CAD systems - for example in the Revit software) or b) BIM for old or historical objects. The former is a modern technology, which is nowadays used worldwide. From the engineer's perspective, the issue is the creation of BIM for older objects. In this case, it is crucial to obtain a precise 3D data set - complex 3D documentation of an object is needed and it is created using various surveying techniques. The most popular technique is laser scanning or digital automatic photogrammetry, from which a point cloud is derived. But this is not the main result. While classical geodesy gives selective localized information, the above-mentioned technologies give unselected information and provide huge datasets. Fully automatic technologies that would select important information from the point cloud are still under development. This seems to be a task for the coming years. Large amounts of data can be acquired automatically and quickly, but getting the expected information is another matter. These problems will be analysed in this paper. Data conversion to BIM, especially for older objects, will be shown on several case studies. The first is an older technical building complex transferred to BIM, the second one is a historical building, and the third one will be a historic medieval bridge (Charles Bridge in Prague). The last part of this paper will refer to aspects and benefits of using Virtual Reality in BIM.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,['1710'],18.7,0.07410831921701487,0.34205015998494265,1,0.08899297423887588,0.04449648711943794,0.3113207547169811
925,948,948,Analysis of cryptocurrency commodities with motifs and LSTM," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Time Series Analysis has long been used as a method to help predict future events based on previous data. This area is well-defined and studied but there are still areas of Time Series Analysis that are problematic. One such problem is isolating patterns in highly volatile datasets over long time intervals. In an effort to help with such issues e.g. those seen in fluctuating financial datasets, a new approach is needed. Borrowing its name from Music and more recently Computational Biology, Motifs are small repeating patterns in datasets. Using these subsequences, further forecasting can be improved as Motifs can be shown to aid algorithms which require certain initial conditions. This method will potentially lead to new insights in the study of cryptocurrencies. This paper will present a case where an optimized Motif length will be used to aid the prediction of Bitcoin through the use of an LSTM Neural Network, yielding an 8% decrease in RSME for one test case.",60025059,Dublin City University,Dublin,Ireland,['1700'],19.11111111111111,0.05651731601731602,0.3881093073593073,0,0.1595744680851064,0.11702127659574468,0.3882978723404255
926,949,949,"ASSESSMENT of SEAGRASS PERCENT COVER and WATER QUALITY USING UAV IMAGES and FIELD MEASUREMENTS in BOLINAO, PANGASINAN","The sensitivity to changes in water quality inherent to seagrass communities makes them vital for determining the overall health of the coastal ecosystem. Numerous efforts including community-based coastal resource management, conservation and rehabilitation plans are currently undertaken to protect these marine species. In this study, the relationship of water quality parameters, specifically chlorophyll-a (chl-a) and turbidity, with seagrass percent cover is assessed quantitatively. Support Vector Machine, a pixel-based image classification method, is applied to determine seagrass and non-seagrass areas from the orthomosaic which yielded a 91.0369% accuracy. In-situ measurements of chl-a and turbidity are acquired using an infinity-CLW water quality sensor. Geostatistical techniques are utilized in this study to determine accurate surfaces for chl-a and turbidity. In two hundred interpolation tests for both chl-a and turbidity, Simple Kriging (Gaussian-model type and Smooth-neighborhood type) performs best with Mean Prediction equal to-0.1371 FTU and 0.0061 μg/L, Root Mean Square Standardized error equal to-0.0688 FTU and-0.0048 μg/L, RMS error of 8.7699 FTU and 1.8006 μg/L and Average Standard Error equal to 10.8360 FTU and 1.6726 μg/L. Zones are determined using fishnet tool and Moran's I to calculate for the seagrass percent cover. Ordinary Least Squares (OLS) is used as a regression analysis to quantify the relationship of seagrass percent cover and water quality parameters. The regression analysis result indicates that turbidity has an inverse relationship while chlorophyll-a has a direct relationship with seagrass percent cover.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],23.2,0.016176470588235296,0.3773809523809524,1,0.0821917808219178,0.09931506849315068,0.42857142857142855
927,950,950,A dynamic logic for learning theory,"Building on previous work [4,5] that bridged Formal Learning Theory and Dynamic Epistemic Logic in a topological setting, we introduce a Dynamic Logic for Learning Theory (DLLT), extending Subset Space Logics [18,10] with dynamic observation modalities [o]φ, as well as with a learning operator L(o→), which encodes the learner's conjecture after observing a finite sequence of data o→. We completely axiomatise DLLT, study its expressivity and use it to characterise various notions of knowledge, belief, and learning.",60029622,Universitetet i Bergen,Bergen,Norway,"['1712', '1703']",38.5,-0.011111111111111108,0.2611111111111111,1,0.1276595744680851,0.13829787234042554,0.46464646464646464
928,951,951,Voltage stability assessment of complex power system based on ga-SVM," All rights reserved.The dynamic stability assessment and prediction of a complex power system is a precondition to take the action of protecting control. This paper presents the four support vector machines (SVMs) with an improved genetic algorithm (GA) to compute their parameters automatically, that one SVM is used to simulate the tangent vector and the others for identifying the instable area. Besides, the GA was initialized by Meta-Learning method to enhance the performance and its optimal solution was selected by last test. Furthermore, a large network simplification was taken for reducing the amount of calculation and responding in real time. Study with the IEEE 118-bus test system indicated that the system status of a complex power system subjected a fault could be predicted based on this technique of the GA-SVM for simulating the tangent vector accurately. Besides, three binary SVM classifiers were trained to locate the instable area, and ranking the levels by the analysis of critical bus is help to management. Based on the test on the networks, the suggested approach can predict accurately with 98.87 % success rate and identify the fault area with 94.91 % success rate.",60013268,Taiyuan University of Technology,Taiyuan,China,"['1712', '1708', '1702']",27.285714285714285,0.10952380952380954,0.3273809523809524,0,0.13551401869158877,0.04205607476635514,0.26570048309178745
929,952,952,MODELLING URBAN GROWTH for BANGKOK and ASSESSING LINKAGES with ROAD DENSITY and SOCIO-ECONOMIC INDICATORS,"The fastest urbanization is occurring in the Global South which includes many developing nations in Asia. However, a rapid and unplanned urban growth could threaten the sustainability of the process. A key step towards a sustainable urban development is to better understand interdependencies amongst urban growth patterns, infrastructure and socio-economic indicators. Here we chose Bangkok, Thailand as a megacity case study to assess the spatio-temporal urban growth dynamics and specifically its dependency with road density at intra-city scales. The SLEUTH urban growth model is further applied for predicting future expansion over the next decade and to assess the future intra-city expansion. Urban expansion patterns for Bangkok were generated for 1987 and 2017 using Landsat derived urban land-cover maps. Open Street Map (OSM) is used to generate a 2017 road density map. The urban expansion (1987-2017) was observed to follow a radially outward expanding pattern inland, with the logarithmic urban expansion rate having an inverted concave trend with road density. The rising/falling limbs then indicated an increase/decrease of urban expansion for which a road density ""turning point"" is readily identified and further used to develop a road density-based zoning map that highlights the different intra-city urban expansion rates. The SLEUTH predicted urban growth till year 2027 which also showed expansion outward from existing urban areas. The future expansion trend is also consistent with the turning point trend. This study showed that such spatial-temporal analysis of urban expansion coupled with SLEUTH can be useful for investigating likely outcomes of city development plans.",60118800,Graduate College,Singapore City,Singapore,['1710'],20.83333333333333,0.05645161290322581,0.21693548387096773,1,0.12244897959183673,0.04421768707482993,0.3014705882352941
930,953,953,Quantifying effects of changing spatial scale on spatial entropy index: Use of fractal dimension," CC BY 4.0 License.Quantifying landscape heterogeneity and its organization at different scales is essential for understanding ecosystems and landscapes. Among hundreds of landscape metrics, entropy-related index represents an efficient tool to quantify and characterize landscape patterns. A recent development is Spatial Entropy index (Hs), and it has been validated as flexible and effective in landscape pattern analysis. However, the effects of changing spatial scale on Hs has not been quantified. This paper applies the fractal method to measure the spatial scale (grain size) sensitivity of Hs. Using the initial land-use data of Yanhe watershed, which is located in northwest of China, eleven different spatial scales were created in order to investigate the scale effects on Hs. A linear log-log regression model was then constructed based on the power law to calculate the coefficient of determination (COD) of the model and the fractal dimension (FD) of Hs. The result indicates that Spatial Entropy index shows a robust fractal feature, and it decreases as the spatial scale (or grain size) becomes lager in a moderate degree. In total, we believe that this study will help us to get a better understanding of Hs, and to facilitate further applications of this entropy-related index.",60025278,Tsinghua University,Beijing,China,['1710'],22.33333333333333,0.11,0.5,0,0.11764705882352941,0.058823529411764705,0.3303964757709251
931,954,954,Comparison and suitability assessment of slope calculation algorithms on different terrains using aerial survey,"Digital Elevation Models are one of the important datasets of any Geographic Information System (GIS) and so are the parameters derived from them. One such parameter is slope, whose accuracy can have a significant effect on many engineering and construction works. This paper addresses the eight-slope calculation methods that are currently available to calculate slope value from a DEM and compares how these methods works on different slope range and values. These methods were applied to calculate slope from DEM of 30&thinsp;m. To determine the method that calculates the most accurate slope value for a particular slope range by comparing them with actual slope value is the main objective of this paper. The methods 2FD, 3FD, 3FDWRD, Average Neighborhood, Constrained Quadratic Surface and FFD has given similar results across all slope range while the algorithms that appears to yield the most varying results are Maximum Max and Simple D. In addition, it is observed that the choice of algorithms is more important when grade slope is less than 10 percent. However, for terrains with above 10 percent slope, the choice of algorithms seems less important with only a difference of approximately 0.5 gradient.",60071792,Kathmandu University,Dhulikhel,Nepal,['1710'],24.125,0.15300000000000002,0.4746190476190476,1,0.07547169811320754,0.08962264150943396,0.3474178403755869
932,955,955,Partial Alignment of Data Sets Based on Fast Intrinsic Feature Match,"Point Feature Histograms (PFH) is a statistic and geometric invariant descriptor that has been widely used in shape analysis. Current PFH based feature extraction methods are highly affected by the time scale and become less effective for unbalanced cases, which limits their performance. In this paper, we focus on finding a framework for partial registration by an adaptive partition of point set algorithm. Firstly, we propose an adaptive partition method base on PFH coding. Secondly, we conduct a series of fast parallel implementations for efficiency. Thirdly, we plug in the PFH based partition method and trimmed strategy to our modified iterative closest point method. Experiments demonstrate that our algorithms are robust and stable.",60023813,Shanghai University,Shanghai,China,['1700'],16.142857142857142,0.003611111111111106,0.37,1,0.11023622047244094,0.031496062992125984,0.2992125984251969
933,956,956,Semantic Modeling of Textual Relationships in Cross-modal Retrieval,"Feature modeling of different modalities is a basic problem in current research of cross-modal information retrieval. Existing models typically project texts and images into one embedding space, in which semantically similar information will have a shorter distance. Semantic modeling of textural relationships is notoriously difficult. In this paper, we propose an approach to model texts using a featured graph by integrating multi-view textual relationships including semantic relationships, statistical co-occurrence, and prior relationships in knowledge base. A dual-path neural network is adopted to learn multi-modal representations of information and cross-modal similarity measure jointly. We use a Graph Convolutional Network (GCN) for generating relation-aware text representations, and use a Convolutional Neural Network (CNN) with non-linearities for image representations. The cross-modal similarity measure is learned by distance metric learning. Experimental results show that, by leveraging the rich relational semantics in texts, our model can outperform the state-of-the-art models by 3.4% on 6.3% in accuracy on two benchmark datasets.",60019499,Chinese Academy of Sciences,Beijing,China,['1700'],19.375,-0.09916666666666668,0.5175000000000001,1,0.09,0.04,0.39204545454545453
934,957,957,Marketing concepts development in the digital economic environment,"The wide use of digital technologies has transformed all aspects of society and changed the modern marketing concept. Trade has been affected in particular. The development and wide use of digital technologies in the trading industry as well as the application of new implementation tools in marketing activities have led to the formation of innovation marketing. The article deals with the study of the evolution of marketing in trade. The comparison of marketing concepts and implementation mechanisms used for manufacturing and trade has revealed significant differences in these areas. The trade industry is currently experiencing an increase in innovation activity. Innovations of different origin have changed the product and affected such things as trade and technological processes, distribution of goods, and business processes of the trading enterprise. A significant number of innovations have been brought about by the development of the digital economy. However, the great advantages offered by the digital economy are offset by threats such as job cuts, lack of qualified personnel and cyber security challenges. In the case for trade, job losses occur due to the elimination of intermediaries, this achieved through the use of digital platforms and marketplaces linking suppliers and end-consumers. Besides, the growth of e-ommerce and the gradual reduction of retail space in actual stores, as well as the reduction of cashiers and accountants, can also contribute to job losses. The second threat - the lack of qualified personnel - arises due to the changes in professional requirements at labor market. Commercial and operational personnel along with marketing specialists of commercial enterprises must satisfy high requirements established for those who apply innovative technologies in order to find solutions to problems. The third threat is posed by the growing number of cyberattacks which cause financial losses, breach of contractual obligations, loss of business reputation, and breaking up a trust of both partners and customers.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",22.071428571428577,0.0843939393939394,0.31706709956709955,1,0.07964601769911504,0.0,0.2656716417910448
935,958,958,Low-Sampling Imagery Data Recovery by Deep Learning Inference and Iterative Approach,"Block-based compressed sensing (CS) recovery aims to reconstruct the high quality image from only a small number of observations in a block-wise manner. However, when the sampling rate is very low and the existence of additive noise, there are usually some block artifacts and detail blurs which degrades the reconstructed quality. In this paper, we propose an efficient method which takes both the advantages of deep learning (DL) framework and iterative approaches. First, a deep multi-layer perceptron (DMLP) is constructed to obtain the initial reconstructed image. Then, an efficient iterative approach is applied to keep the consistence and smoothness between the adjacent blocks. The proposed method demonstrates its efficacy on benchmark datasets.",60000937,Shenzhen University,Shenzhen,China,['1700'],18.666666666666668,-0.009999999999999995,0.4125925925925926,1,0.0962962962962963,0.037037037037037035,0.3333333333333333
936,959,959,Semantic enrichment for large-scale data analytics," All rights reserved.Most of all data science projects involve a time-costly data preparation process aimed at enriching the working dataset with addi- tional information to improve the sturdiness of resulting trained models. How to ease the design of the enrichment process for data scientists is defying, as well as supporting the enrichment process at large scale. This document introduces and describes a research proposal for address- ing such problem, which focuses on harnessing the semantics as the key factor, by providing users with semantics-aided tools to design transfor- mations, along with a platform to execute pipelines at business scale.",60012306,University of Milano - Bicocca,Milan,Italy,['1700'],33.333333333333336,0.11607142857142858,0.5446428571428572,0,0.17699115044247787,0.017699115044247787,0.3018867924528302
937,960,960,On classical n-absorbing submodules,"In this paper, we introduce the notion of classical n-absorbing submodules of a module M over a commutative ring R with identity, which is a generalization of classical prime submodules. A proper submodule N of M is said to be classical n-absorbing if whenever a1a2, an+1m ε N for a1,a2, an+1 ε R and m ε M, then there are n of the ai's whose product with m is in N. We give some basic results concerning classical n-absorbing submodules. Then the classical n-absorbing avoidance theorem for submodules is proved. Finally, classical n-absorbing submodules in several classes of modules are studied.",60025339,Jundi Shapur University of Dezful,Dezful,Iran,['1710'],20.2,0.0,0.025,1,0.08130081300813008,0.0975609756097561,0.3333333333333333
938,961,961,Multiparametic Forecast Model with Variable Cryptocurrency Capitalization Assessment Framework,"One of the main directions in the development of the digital economy is Industry 4.0 in industry and Fintech in the financial sector. Financial institutions are second only to telecommunication companies in the implementation of information and communication technologies. The introduction of innovative digital technologies contributes to the formation of new forms and tools of conducting business, opening new horizons for economic development. One of such innovative tools in the financial sector, based on digital technologies, is cryptocurrency, which has become one of the breakthrough areas in the field of electronic payment methods based on blockchain technology and innovative cryptographic protection technologies. The paper considers the basic concepts and principles of the establishing of an innovative means of payment - cryptocurrencies, analyzes the stages of development of this legal tender and classifications of the existing digital money, and conducts a financial analysis of the main parameters of the global cryptocurrency market that has been formed as of today. One of the main issues in the economic sphere is the issue of effectiveness of a financial instrument, the cryptocurrency capitalization inter alia. The question to what extent this or that cryptocurrency will become a promising investment tool is currently one of the most relevant. In this regard, the article presents and analyzes a multi-parameter predictive econometric model that defines the main parameters affecting capitalization of cryptocurrencies. Based on the study, further prospects and trends of the development of cryptocurrencies, the possibility of their integration into the existing global payment system are analyzed.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",27.88888888888889,0.14058769513314973,0.3414370982552801,1,0.07352941176470588,0.014705882352941176,0.2814814814814815
939,962,962,MODELING SPECIES DISTRIBUTION of SHOREA GUISO (BLANCO) BLUME and PARASHOREA MALAANONAN (BLANCO) MERR in MOUNT MAKILING FOREST RESERVE USING MAXENT,"Climate change is regarded as one of the most significant drivers of biodiversity loss and altered forest ecosystems. This study aimed to model the current species distribution of two dipterocarp species in Mount Makiling Forest Reserve as well as the future distribution under different climate emission scenarios and global climate models. A machine-learning algorithm based on the principle of maximum entropy (Maxent) was used to generate the potential distributions of two dipterocarp species-Shorea guiso and Parashorea malaanonan. The species occurrence records of these species and sets of bioclimatic and physical variables were used in Maxent to predict the current and future distribution of these dipterocarp species. The variables were initially reduced and selected using Principal Component Analysis (PCA). Moreover, two global climate models (GCMs) and climate emission scenarios (RCP4.5 and RCP8.5) projected to 2050 and 2070 were utilized in the study. The Maxent models predict that suitable areas for P. malaanonan will decline by 2050 and 2070 under RCP4.5 and RCP 8.5. On the other hand, S. guiso was found to benefit from future climate with increasing suitable areas. The findings of this study will provide initial understanding on how climate change affects the distribution of threatened species such as dipterocarps. It can also be used to aid decision-making process to better conserve the potential habitat of these species in current and future climate scenarios.",60071494,University of the Philippines Los Banos,Los Banos,Philippines,['1710'],18.75,0.10681818181818184,0.39512987012987016,1,0.11952191235059761,0.08764940239043825,0.3346938775510204
940,963,963,A core Erlang semantics for declarative debugging,"One of the main advantages of declarative languages is their clearly established formal semantics, that allows programmers to reason about the properties of programs and to establish the correctness of tools. In particular, declarative debugging is a technique that analyses the proof trees of computations to locate bugs in programs. However, in the case of commercial declarative languages such as the functional language Erlang, sometimes the semantics is only informally defined, and this precludes these possibilities. Moreover, defining semantics for these languages is far from trivial because they include complex features needed in real applications, such as concurrency. In this paper we define a semantics for Core Erlang, the intermediate language underlying Erlang programs. We focus on the problem of concurrency and show how a medium-sized-step calculus, that avoids the details of small-step semantics but still captures the most common program errors, can be used to define an algorithmic debugger that is sound and complete.",60027282,Universidad Complutense de Madrid,Madrid,Spain,"['1712', '1703']",25.83333333333333,0.08095238095238096,0.4678571428571429,1,0.11299435028248588,0.022598870056497175,0.3157894736842105
941,964,964,"Estimating aboveground biomass of bamboo and mixed bamboo forest in thua thien-hue province, viet nam using palsar-2 and landsat oli data"," CC BY 4.0 License.In this study, above-ground biomass (AGB) performance was evaluated by PALSAR-2 L-band and Landsat data for bamboo and mixed bamboo forest. The linear regression model was chosen and validated for forest biomass estimation in A Luoi district, Thua Thien Hue province, Vietnam. A Landsat 8 OLI image and a dual-polarized ALOS/PALSAR-2 L-band (HH, HV polarizations) were used. In addition, 11 diferrent vegetation indices were extracted to test the performance of Landsat data in estimating forest AGB Total of 54 plots were collected in the bamboo and mixed bamboo forest in 2016. The linear regression is used to evaluate the sensitivity of biomass to the obtained parameters, including radar polarization, optical properties, and some vegetation indices which are extracted from Landsat data. The best-fit linear regression is selected by using the Bayesian Model Average for biomass estimation. Leave-one-out cross-validation (LOOCV) was employed to test the robustness of the model through the coefficient of determination (R squared - R2) and Root Mean Squared Error (RMSE). The results show that Landsat 8 OLI data has a slightly better potential for biomass estimation than PALSAR-2 in the bamboo and mixed bamboo forest. Besides, the combination of PALSAR-2 and Landsat 8 OLI data also has a no significant improvement (R2 of 0.60) over the performance of models using only SAR (R2 of 0.49) and only Landsat data (R2 of 0.58-0.59). The univariate model was selected to estimate AGB in the bamboo and mixed bamboo forest. The model showed good accuracy with an R2 of 0.59 and an RMSE of 29.66 tons&thinsp;ha&minus;1. The comparison between two approaches using the entire dataset and LOOCV demonstrates no significant difference in R (0.59 and 0.56) and RMSE (29.66 and 30.06 tons&thinsp;ha&minus;1). This study performs the utilization of remote sensing data for biomass estimation in bamboo and mixed bamboo forest, which is a lack of up-to-date information in forest inventory. This study highlights the utilization of the linear regression model for estimating AGB of the bamboo forest with a limited number of field survey samples. However, future research should include a comparison with non-linear and non-parametric models.",60014652,Hokkaido University,Sapporo,Japan,['1710'],23.4,0.010056390977443607,0.5279135338345864,0,0.07259953161592506,0.10070257611241218,0.4174757281553398
942,965,965,An extended data protection model based on cipher-text-policy attribute based encryption model and an XACML framework in cloud computing,"Cloud Computing is a new service that has a fast growth in IT. It can be utilized for providing software and infrastructure services deployed in data centers. Although there are several benefits of cloud computing, such as the ability to store huge amount of data and to perform a large amount of computations, there are some issues, such as data security and privacy that affect the reliability of cloud computing. Moreover, encryption of the data by data owners and sharing them on cloud leads to different efficiency and secrecy problems. Access control and user authentication are the most critical security issues in cloud computing, because effective access control models ensure that the data are accessed by legal users. Hence, in this paper, we extend the proposed model in [38], and we propose a model to control the access of the encrypted sensitive data from unauthorized users in cloud computing. The proposed model based on Cipher-Text-Policy Attribute Based encryption (CP-ABE) and Extensible Access Control Markup Language (XACML) framework. The proposed model protects the encrypted sensitive data and ensures that the data is accessed only by legal users.",60104126,Jouf University,Sakakah,Saudi Arabia,['1700'],23.25,0.16566558441558446,0.5801948051948052,1,0.102803738317757,0.06542056074766354,0.34615384615384615
943,966,966,Integrating IFC and NLP for automating change request validations," This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.SUMMARY: The management and the identification of design changes constitute an essential part of the of a design flow within the architecture, engineering and construction (AEC) industry, requiring the formalisation of a multi-disciplinary collaborative information modelling environment. Construction projects generate substantial amount of change information, which needs to be updated continuously throughout the process, from initial feasibility study to the decommissioning of facilities. Complications arise from the information storage in multiple incompatible file formats that can lead to the loss or omission of details. In addition to any unexpected changes, the mismanagement of information is another factor leading to delays and costly errors. In order to mitigate such issues, this paper proposes to integrate the Industry Foundation Classes (IFC) data model and Natural Language Processing (NLP) to validate and visually identify the result of change requests. The system is developed using C# by 1) integrating angular framework with ASP.NET (Active Server Pages) to create a dynamic single web page and 2). Using X-BIM toolkit that supports IFC format to read, create and visualise the BuildingSmart Data Models (aka IFC Models). This approach enables a web-based platform capable of generating reports and visual previews, highlighting the differences between IFC files throughout the design processes. A web-based system prototype allows users to compare subsequent versions of IFC design models in terms of additions, modifications and deletions. The prototype uses NLP to intelligently identify the changes that have been made as it compares newer and older versions of the same model, making this information available to designers and 3D modellers. Prospective work will focus on the application of artificial intelligence (AI) to automate the implementation of changes within the construction models.",60025655,Teesside University,Middlesbrough,United Kingdom,['1706'],28.45454545454545,0.08070436507936507,0.3766369047619048,0,0.11748633879781421,0.07377049180327869,0.38935574229691877
944,967,967,Ontologies and AI in recruiting. A rule-based approach to address ethical and legal auditing,"Artificial Intelligence (AI) domain-specific applications may have different ethical and legal implications depending on the domain. One of the current questions of the AI is the challenges behind the analysis of job videointerviews. The use of semantic descriptions of jobs positions and candidate profiles could improve Recruiting information management within the organization and candidate-position matching. There are additional controversial issues, pros and cons to using AI in recruitment processes, and potential ethical and legal consequences for candidates, companies and states. There is a deficit of regulation of these systems, and a need for external and neutral auditing of the types of matching made in interviews to reduce potential discrimination, for example on the basis of race or gender, in the job market. We propose, first, formally define criteria for jobs and candidates using a candidate desired skills and emotions ontology and job offers ontology to foster interoperability at company level and a multi-agent system architecture for neutral auditing to guarantee a fair, inclusive and accurate AI.",60018940,Universidad Rey Juan Carlos,Mostoles,Spain,['1700'],27.66666666666667,0.1125,0.5760416666666666,1,0.07407407407407407,0.026455026455026454,0.3333333333333333
945,968,968,AENN: A GENERATIVE ADVERSARIAL NEURAL NETWORK for WEATHER RADAR ECHO EXTRAPOLATION,"Weather radar echo is one of the fundamental data for meteorological workers to weather systems identification and classification. Through the technique of weather radar echo extrapolation, the future short-term weather conditions can be predicted and severe convection storms can be warned. However, traditional extrapolation methods cannot offer accurate enough extrapolation results since their modeling capacity is limited, the recent deep learning based methods make some progress but still remains a problem of blurry prediction when making deeper extrapolation, which may due to they choose the mean square error as their loss function and that will lead to losing echo details. To address this problem and make a more realistic and accurate extrapolation, we propose a deep learning model called Adversarial Extrapolation Neural Network (AENN), which is a Generative Adversarial Network (GAN) structure and consist of a conditional generator and two discriminators, echo-frame discriminator and echo-sequence discriminator. The generator and discriminators are trained alternately in an adversarial way to make the final extrapolation results be realistic and accurate. To evaluate the model, we conduct experiments on extrapolating 0.5h, 1h, and 1.5h imminent future echoes, the results show that our proposed AENN can achieve the expected effect and outperforms other models significantly, which has a powerful potential application value for short-term weather forecasting.",60024350,National University of Defense Technology,Changsha,China,['1710'],35.166666666666664,0.08584368530020706,0.4987836438923395,1,0.13636363636363635,0.0371900826446281,0.2948717948717949
946,969,969,"SATELLITE-DERIVED AIR POLLUTANTS and THEIR CORRELATIONS with URBAN FORM in GUANGDONG, CHINA","The ways cities grow and evolve spatially are crucial factors which affect urban aerosol pollution. Understanding the spatial distribution of air pollutants and their correlations with urban form is of great significance to the improvement of urban atmospheric environment and regional sustainable development of urbanization. In this study, we firstly examined the spatial variations of satellite-derived PM2.5 and NO2 and urban form metrics in Guangdong, and also explored their relationships. The results indicated that the highest and lowest values of PM2.5 and NO2 mainly occur over the Pearl River Delta (PRD) region, and over the eastern Guangdong, respectively. For the size and shape of urban patches, urban form had significant effects on air pollutants in Guangdong. PM2.5 was positively correlated with AREA_AM, CA and SHAPE_AM, and NO2 was positively correlated with LPI, PLAND and AREA_AM, while both of them were negatively related to PARA_AM and ENN_AM. It is inferred that polycentric urban form was associated with low PM2.5 and NO2 concentration, and reasonable urban planning would help mitigate the fine particle pollution.",60082183,Zhongkai University of Agriculture and Engineering,Guangzhou,China,['1710'],24.57142857142857,0.1268037518037518,0.2991702741702741,1,0.08808290155440414,0.11917098445595854,0.3193717277486911
947,970,970,Enabling multi-party consensual data exchange through blockchain," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The quantity and quality of data available to an organisation plays an increasingly important role in its operation. This data can relate to a variety of subjects, from the internal logistics to consumer sentiment towards a product in a specific market. This data provides increasingly optimal behaviour derived from its analysis, e.g. improved decision making. As more advanced, application-specific, machine learning models are developed, the organisation with the largest share of data will gain an advantage over its competitors. It is postulated that smaller entities with minority shares in data within a domain possess only a fragmented view of a market. This fragmented view puts the smaller entity at a disadvantage and enables larger entities to reap unfair, competitive advantages. This unequal dynamic should be rectified. To that end, in this work, a model is proposed that enables the consensual sharing of data between multiple parties using blockchain.",60105275,"Jaguar Land Rover, UK",Coventry,United Kingdom,['1700'],17.777777777777782,0.11250000000000003,0.4744791666666667,0,0.1005586592178771,0.0446927374301676,0.3463687150837989
948,971,971,Tracking CSP computations,"Tracing is one of the most important techniques for program understanding and debugging. A trace gives the user access to otherwise hidden information about a computation. In the context of concurrent languages, computations are particularly complex due to the non-deterministic execution order of processes and to the restrictions imposed on this order by synchronizations; hence, a tracer is a powerful tool to explore, understand and debug concurrent computations. In CSP, traces are sequences of events that define a particular execution. This notion of trace is completely different to the one used in other paradigms where traces are formed by those source code expressions evaluated during a particular execution. We refer to this second notion of traces as tracks. In this work, we introduce the theoretical basis for tracking concurrent and explicitly synchronized computations in process algebras such as CSP. Tracking computations in this kind of systems is a difficult task due to the subtleties of the underlying operational semantics which combines concurrency, non-determinism and non-termination. We define an instrumented operational semantics that generates as a side-effect an appropriate data structure (a track) which can be used to track computations. The formal definition of a tracking semantics improves the understanding of the tracking process, but also, it allows us to formally prove the correctness of the computed tracks.",60011476,Universitat Politècnica de València,Valencia,Spain,"['1712', '1703']",21.7,0.07598039215686274,0.5073529411764706,1,0.09349593495934959,0.008130081300813009,0.29831932773109243
949,972,972,"A study on the role of source credibility, endorser credibility and message appeal over consumers’ purchase intentions: An empirical evidence",". All rights reserved.This paper explores the effect of confined constructs source credibility, endorser credibility and message appeal on grocery items purchase intention. The study was performed on the sample of respondents residing in Guntur, Andhra Pradesh, India. The sample was determined by a non-probabilistic method (Snowball method). A survey questionnaire was prepared based on previous literature and its Stastical validated was verified using exploratory factor analysis method and multiple linear regressions was used to find the proportional variance explained by this model. The demographic factor used as a control variable (educational qualification). Finally, it is found that both endorser credibility and message appeal have shown an significant relation formation of purchase intention for grocery items and purchase decision was influenced by educational qualification of the respondents.",114477319,Technology and Research University,Guntur,India,['1700'],18.142857142857142,0.11805555555555555,0.4236111111111111,1,0.11724137931034483,0.034482758620689655,0.2624113475177305
950,973,973,Input urgent semantics for asynchronous timed session types,"We study an urgent semantics of asynchronous timed session types, where input actions happen as soon as possible, inspired to common programming primitives. We introduce a notion of asynchronous compliance for timed session types, ensuring deadlock freedom and eventual reception. As in the untimed case, asynchronous compliance is undecidable. We then show that synchronous compliance, shown decidable in previous work, is a sound approximation of asynchronous compliance.",60032259,Università degli Studi di Cagliari,Cagliari,Italy,"['1712', '1703']",16.75,-0.016666666666666663,0.5166666666666667,1,0.09090909090909091,0.0,0.24675324675324675
951,974,974,ANALYZING the EFFECTS of LAND COVER CHANGE on SURFACE TEMPERATURE in MOUNT MAKILING FOREST RESERVE (MMFR) and ITS NEIGHBORING MUNICIPALITIES USING LANDSAT DATA,"Land Surface Temperature (LST) is said to be affected by frequent changes in the land cover. Over the years, the immediate environs of Mount Makiling Forest Reserve (MMFR) have experienced such kind of change due to rapid economic growth of the area that also led to the expansion of urban centers. The study utilized Landsat imageries to determine the possible effects of land cover change on surface temperature using the integration of remote sensing and GIS technologies. Initially, the multispectral bands were radiometrically corrected using Dark Object Subtraction (DOS) while the thermal bands were corrected using Land Surface Emissivity (LSE). After these corrections were applied, the images were classified using supervised image classification technique where seven land cover types have been identified. The classified images were then validated using 200 reference data and this revealed an overall accuracy of 87.5% and 86.0% for the May 2003 and July 2015 images, respectively. Results showed that changes in land cover resulted to a significant change in Land Surface Temperature (LST). The LST in 2003 (16.49°C-40.44°C) was found higher than that of 2015 which was observed between 13.35°C and 33.83°C only. The reason behind this is the increase in green spaces from 2003 to 2015. Among the major land cover types, forest lands exhibited the lowest mean surface temperature for both years having 27.27°C in 2003 and 21.35°C in 2015 while built-up areas had the highest surface temperature having 32.60°C in 2003 and 26.00°C in 2015.",60071494,University of the Philippines Los Banos,Los Banos,Philippines,['1710'],24.3,0.054999999999999986,0.4718750000000001,1,0.09655172413793103,0.10344827586206896,0.4227941176470588
952,975,975,Communication-aware scheduling of data-parallel tasks on multicore architectures," This paper studies scheduling of data-parallel tasks on multicore architectures. Unlike traditional task scheduling, this work allows individual tasks to run on multiple cores in a data-parallel fashion. In this paper, the inter-task communication overhead is taken into account during scheduling. The communication happens if main threads of two tasks with data-dependencies are mapped onto the different processors. This paper proposes two methods for data-parallel task scheduling with communication overhead. One is two-step method, which schedules tasks without communication and then assigns threads in the task on cores. The other is integrated method, which performs task scheduling and thread assignment simultaneously. Both of the two methods are based on integer linear programming. The proposed methods are evaluated through experiments and encouraging results are obtained.",60105159,"Ritsumeikan University, Biwako-Kusatsu",Kusatsu,Japan,['1706'],13.888888888888891,0.006944444444444443,0.40972222222222215,0,0.11333333333333333,0.0,0.4233576642335766
953,976,976,"An empirical study of the relationships between the flexible work systems (FWS), Organizational commitment (OC), work life balance (WLB) and job satisfaction (JS) for the teaching staff in the United Arab Emirates (UAE)"," The respondents are chosen from the accredited colleges in the United Arab Emirates (UAE) by convenience sampling method from the cities of Sharjah, Dubai, Abudhabhi and Ajman. They differed in terms of gender, qualifications, tenure of work, department and also the nature of work. A suitable conceptual framework was developed and the proposed model illustrates that flexible work system (FWS) is thought to have an influence on both organizational commitment (OC) and work life balance (WLB). It has been proposed that WLB significantly mediates the relationship between flexible work system and job satisfaction. It is also anticipated that WLB significantly mediates the relationship between organizational commitment (OC) and job satisfaction (JS). A sample size of 224 was chosen and a structured questionnaire was used for collecting the data from the respondents in UAE. The questionnaire consists of 34 statements and they are rated on a likert scale of 1 to 5. For this study, statistical tools like confirmatory factor analysis (CFA) and structural modeling equation (SME) methods have been used through SPSS (version-25) and AMOS (version-25) for assessing the nature of relationships that existed between the studied variables (34 statements in the questionnaire). Prior to testing through structural equation modeling (SEM), the most fundamental criteria tests such as normality and confirmatory factor analysis (CFA) were conducted. As normality was established, the factor loadings were extracted by the procedure of CFA. The results from the data analysis indicated that all the hypotheses are supported and it facilitated for the acceptance of the proposed model. Thus, flexible work system (FWS) had direct effect on organizational commitment (OC) and it also had direct effect on work life balance (WLB). Similarly, organizational commitment (OC) is positively related to work-life balance (WLB). Consequently, the work life balance (WLB) displayed positive relationship towards job satisfaction (JS). The results of mediation analysis revealed the indirect effect of flexible work system (FWS) and organizational commitment (OC) towards job satisfaction (JS) through work-life balance (WLB). The study demonstrates that all the proposed hypotheses are accepted and this is evident from standardized path coefficients.",60122028,City University College of Ajman,Ajman,United Arab Emirates,['1706'],21.5625,0.19825174825174824,0.4765734265734267,0,0.08254716981132075,0.08254716981132075,0.38663484486873506
954,977,977,Ultra-relativistic limit of extended thermodynamics of rarefied polyatomic gas,The aim of this paper is to evaluate the ultra-relativistic limit of a recent causal theory proposed for polyatomic dissipative relativistic gas. The explicit expression of characteristic velocities of the hyperbolic system is found in term of the degree of freedom of the molecule and is compared with the one of monatomic gas.,60032259,Università degli Studi di Cagliari,Cagliari,Italy,['1710'],26.5,-0.03333333333333333,0.3583333333333333,1,0.07017543859649122,0.0,0.10909090909090909
955,978,978,Probabilistic software product lines,"We introduce a probabilistic extension of our previous work SPLA: a formal framework to specify and analyze software product lines. We use probabilistic information to identify those features that are more frequently used. This is done by computing the probability of having a feature in a specific software product line, from now on SPLAP. We redefine the syntax of SPLA to include probabilistic operators and define new operational and denotational semantics. We prove that the expected equivalence between these two semantic frameworks holds. Our probabilistic framework is supported by a set of scripts to show the model behavior. We briefly comment on the characteristics of the scripts and discuss the advantages of using probabilities to quantify the likelihood of having features in potential software product lines.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1703']",18.0,0.058712121212121215,0.40994318181818185,1,0.16296296296296298,0.022222222222222223,0.3037037037037037
956,979,979,Development of smart control forklift using center-of-gravity analysis of small forklift,"In this study, structural analysis results of the forklift, an agricultural machine developed jointly by Catholic Kwandong University Biomedical Engineering Lab and Sungbu Industrial LTD. For the structural analysis of the forklift, we focused on the physical properties based on simulation and basic science based on solidworks. We hope to contribute to agriculture society entering aging through structural analysis of forklift completed through research, and furthermore, contribution of agriculture industry and biomedical support based on such research.",60024495,Catholic Kwandong University,Gangneung,South Korea,['1700'],25.66666666666667,0.02,0.2335714285714286,1,0.11764705882352941,0.10588235294117647,0.3333333333333333
957,980,980,A comparative analysis of classification techniques for cervical cancer utilising at risk factors and screening test results," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Cervical cancer is a severe concern for women's health. Every year in the Republic of Ireland, approximately 300 women are diagnosed with cervical cancer, 30% for whom the diagnosis will prove fatal. It is the second most common cause of death due to cancer in women aged 25 to 39 years [14]. Recently there has been a series of controversies concerning the mishandling of results from cervical screening tests, delays in processing said tests and the recalling of individuals to retake tests [12]. The serious nature of the prognosis highlights the importance and need for the timely processing and analysis of data related to screenings. This work presents a comparative analysis of several classification techniques used for the automated analysis of known risk factors and screening tests with the aim of predicting cervical cancer outcomes via a Biopsy result. These techniques encompass methods such as tree-based, cluster-based, liner and ensemble techniques, and where applicable use parameter tuning to determine optimal model parameters. The dataset utilised for training and validation consists of 858 observations and 36 variables, including the binary target variable “Biopsy”. The data itself is heavily imbalanced with 803 negative and 55 positive observations with approximately 11.73% of the data points missing. These issues are addressed during pre-processing by methods such as mean or median imputation, as well as over-sampling, under-sampling and combination techniques which led to the creation of 6 augmented datasets of varying size, consisting of 34 variables including the response Biopsy. The results show that a SMOTE-Tomek combination resampling method in conjunction with a tuned Random Forest model produced an accuracy score of 99.69% with a recall and precision value of 0.99% for both positive and negative responses.",60001376,Cork Institute of Technology,Bishopstown,Ireland,['1700'],26.72727272727273,-0.08766469038208168,0.43130764163372864,0,0.09734513274336283,0.04424778761061947,0.39634146341463417
958,981,981,Environmentally informed robotic-aided fabrication,"The research presented in this paper addresses the integration of thermal performance with robotic toolpath generation for nomadic settlements. It is part of a larger study that describes the development of a material system and a remote on-site fabrication strategy for African nomadic dwellings using unprocessed locally sourced materials in hot arid environments. Research methods include the employment of computational design and robotic fabrication techniques to facilitate the development of improved housing conditions. Through the analysis of existing traditional earthen construction strategies, the aim is to develop a novel approach to robotic fabrication of unfired earthen envelopes by incorporating thermal performance simulation in the robotic motion path generation. The use of robot-aided fabrication eliminates the need for complicated prefabricated moulds, achieving improved environmental performance with reduced material usage. Taking into consideration the material properties and associated drying times, a layer sequencing strategy is introduced to diminish the possible errors and collapse that occur during the fabrication process. Two types of layers are identified in relation to their position within the envelope’s structure and are optimized for increasing thermal lag, and respectively, self-shading. The contribution of the research is a robot-aided fabricationaware design method for generating complex thermally performant earthen envelopes realized by overlaying continuous layers using simple toolpath geometries.",60097321,Architectural Association (AA) School of Architecture,London,United Kingdom,['1705'],26.125,-0.07187500000000001,0.3785714285714286,1,0.12987012987012986,0.008658008658008658,0.29910714285714285
959,982,982,A comparison of deep learning models in human activity recognition and behavioural prediction on the mHealth dataset," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The problem of classifying body gesture and motion along with aiming to predict states of action or behaviour during physical activity is refered to as Human Activity Recongition (HAR). Inertial Measurement Units (IMUs) prevail as the key technique to measure range of motion, speed, velocity and magnetic field orientation during these physical activities. On-body inertial sensors can be used to generate body motion and vital signs recording signals that can successfully learn models and accurately classify physical activities. In this paper, we compare the approaches of Extreme Gradient Boosting (XGBoost), Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), Long Short-Term Memory Network (LSTM), CNN + LSTM Hybrid (ConvLSTM) and Autoencoder by Random Forest (AE w/ RF) to classify human activities on the MHEALTH dataset. All six of our classification models use raw, unstructured data obtained from 4 inertial on-body sensors. We examine multiple physical activities and on-body inertial sensors, showing how body motion and vital signs recordings can be modified to be fed into machine learning models using diverse network architectures. We also compare the performance of the machine learning models to analyse which model best suits multisensory fusion analysis. The experimental results of this paper on the MHEALTH dataset consisting of 12 physical activities collected from 10 subjects with the use of four differnet inertial sensors, are highly encouraging and consistently outperform exisiting baseline models. MLP and XGBoost attain the highest performance measures with accuracy (90.55%, 89.97%), precision (91.66%, 90.09%), recall (90.55%, 89.97%) and F1 score (90.7%, 89.78%) respectively.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],29.0,0.1021692307692308,0.3739663003663004,0,0.09480122324159021,0.13761467889908258,0.525
960,983,983,RUNOFF ESTIMATION USING SCS RUNOFF CURVE NUMBER METHOD in CEBU ISLAND,"Cebu, with its growing development and increasing demand for water, needs tools and inputs to efficiently understand and manage its water resources. Rainfall runoff models were developed to model surface runoff which may be used to assess water availability. Soil Conservation System (SCS) Runoff Curve Number (CN) method predicts runoff based on an empirical curve number for ungauged watersheds. This study aims to estimate the amount of runoff for the catchments of Cebu Island using the SCS-CN Runoff technique. The data needed for the application of the method in this study were rainfall distribution data, land use/land cover and soil texture for curve number assignment, LiDAR DEM for the delineation of the catchments, and supporting runoff measurements from a different runoff estimation model for assessment of the results. The collected data were prepared by assigning the mean statistics of the rainfall distribution and the composite curve number for each catchment using Geographic Information System (GIS). The calculation of the runoff was also done using the same framework. Maps representing Cebu Island's catchments' runoff estimates were produced. Since observed runoff data were unavailable, the results were verified by comparing the SCS-CN estimated runoff to the results of a physically-based distributed hydrologic and hydraulics modelling software, FLO-2D. The SCS-CN estimations were found to coincide with the FLO-2D runoff estimates based on various statistical assessments. Although the results may have higher uncertainties due to the unavailability of observed runoff data, the SCS-CN Runoff method provided relevant results to that of a complex simulation model. Thus, the method may be applied to estimate runoff of ungauged catchments of Cebu Island, the results of which could provide relevant information for water resource management.",60108083,University of the Philippines Cebu,Cebu,Philippines,['1710'],23.16666666666667,0.06354166666666668,0.4697916666666668,1,0.12852664576802508,0.09717868338557993,0.33766233766233766
961,984,984,Canonical reduction for quadratic quotients of the rees algebra,"In this paper, we characterize when a quadratic quotient of the Rees algebra, obtained starting with a one-dimensional local ring, has a canonical reduction, generalizing a similar result obtained for Nagata idealization by Rahimi.",60010146,Università degli Studi di Catania,Catania,Italy,['1710'],34.0,0.0,0.16666666666666666,1,0.12195121951219512,0.04878048780487805,0.3333333333333333
962,985,985,Some properties on fuzzy hyperlattice ordered group,"Algebraic hyperstructure theory has vast applications in several disciplines particularly in mathematics, physics, biology and computer sciences.Here we introduced the new notion of Fuzzy hyperlattice ordered group and the main aim of the paper is to investigate the homogenity properties of Fuzzy hyperlattice ordered group.",60016712,Alagappa University,Karaikudi,India,['1700'],45.0,0.09393939393939392,0.4242424242424242,1,0.08,0.04,0.3333333333333333
963,986,986,Fixed points for non-expansive set-valued mappings,Let E be a Banach space and F: E E be a 1-Lipschitz set-valued mapping with closed convex non-empty values. We study the set of fixed points Fix(F) = [x ε E: x ε F(x)] and provide in any space E with dim(E) ≥ 2 an example of such a mapping F such that Fix(F) is not connected.,60001422,Sorbonne Universite,Paris,France,['1710'],29.0,0.04,0.38,1,0.08333333333333333,0.06944444444444445,0.40789473684210525
964,987,987,A Multi-label Active Learning Approach for Mobile App User Review Classification,"User reviews of mobile applications convey useful feedback from users, e.g. feature requests, bug descriptions, etc. The increasing number of reviews that users submit daily makes it difficult for developers to manually analyze and classify them into proper review categories. Moreover, several review messages may contain more than one information. In this paper, we propose to use multi-label active learning as a convenient solution to the problem of mobile app user reviews classification. An unlabeled and structured dataset was built from the initially unstructured large set of review messages. Moreover, in order to reduce the effort needed to assign labels to each instance in the large constructed dataset, we opted for an Active Learning approach. Experimental results have shown that, by actively querying an oracle for labels during training a binary relevance-based classifier (with logistic regression as a base classifier), we obtained a classifier that outperformed well-known classifiers in terms of performance without the need to label the whole dataset.",60091190,Prince Mohammad Bin Fahd University,Al-Khobar,Saudi Arabia,['1700'],20.0,-0.011428571428571429,0.4038095238095238,1,0.14130434782608695,0.016304347826086956,0.3407821229050279
965,988,988,TWO-DIMENSIONAL HYDRODYNAMIC MODELLING of URBAN FLOOD INUNDATION CAUSED by the SOUTHWEST MONSOON to CHARACTERIZE the IMPACT of TWENTY-YEAR DIFFERENCE in LAND USE in VALENZUELA-OBANDO-MEYCAUAYAN (VOM) USING FLO-2D,"The intensity of urban flooding area due to rapid urbanization in Metro Manila has been worsening over the years caused by the torrential rains brought by the Southwest Monsoon. To further characterize the impact of land use change influenced by urbanization, we compared the flood map generated from two periods (Year 200 Year 2020) using a two-dimensional hydrodynamic modelling simulated in FLO-2D software. In our simulations, we assigned roughness coefficient values to corresponding land use category derived from an earlier study in the area previously spearhead by JICA in 2001. Each model will incorporate the implemented Year 2000 land use and the projected Year 2010 land use classification respectively, which were used in this earlier study. Meanwhile, both models will use the same sets of parameters for the simulation: IFSAR-derived DEM elevation model and a rainfall event with 10-yr return period. The area of interest of this study is located near Valenzuela-Obando-Meycauayan (VOM) with its boundaries defined from the National Mapping and Resource Information Authority. The flood simulations conducted do not take into consideration in existing flood control measures such as drainage systems and floodwalls to minimize the complexity of the model. The results are evaluated both quantitatively and qualitatively. According to the results, the impact of the land use change on flood formation in most areas are insignificant due to a low degree of land use change. However, there has been substantial impact on flooding in specific areas where there is a major change in the land use. For further studies, we recommend the use of a longer land use change period and the consideration of more varied and precise Manning's n-values.",60110905,FEU Institute Of Technology,Manila,Philippines,['1710'],24.818181818181817,0.05504385964912281,0.3614035087719297,1,0.09771986970684039,0.06514657980456026,0.31313131313131315
966,989,989,ESTIMATION of CHLOROPHYLL-A CONCENTRATION in LAGUNA de BAY USING SENTINEL-3 SATELLITE DATA,"The mission of the European Space Agency's Sentinel-3 satellite is to provide data for land and ocean monitoring purposes. Sentinel-3's Ocean and Land Colour Instrument (OLCI) data are being used largely for monitoring offshore and coastal waters but can also be used for inland waters including lakes. It has a spatial resolution of 300 meters, a temporal resolution of 2-3 days and contains 21 spectral bands. Laguna de Bay, with a surface area of around 930 km2, suffers from periodic algal blooms resulting from excessive nutrient inputs from surrounding watersheds. This study aims to assess the applicability of Sentinel-3 OLCI for estimating chlorophylla (chl-a) concentration in Laguna Lake. Several chl-a estimation algorithms (i.e., band ratios and indices) were tested for Sentinel 3 OLCI images and compared with in-situ data obtained using a chl-a sensor. A regression model comprising of individual spectral bands, band ratios, and band indices for chl-a estimation as independent variables was developed, yielding an adjusted R2 of 0.759 and RMSE of 1.19 ug/L. The model consists of R620, R674/R708, and RED/NIR. A map was produced showing the spatial distribution of chl-a in Laguna Lake, with most of the portion of the lake having a concentration ranging from 7.5 ug/L to 15 ug/L. This shows that Sentinel 3 OLCI images can be utilized for accurately estimating chl-a in Laguna Lake.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.2,0.036428571428571435,0.4086904761904762,1,0.10583941605839416,0.13138686131386862,0.468
967,990,990,Features of the analysis of business processes of the company (on the example of customer service in a travel agency),"Currently, for the effective development of the activities of any company, modern information technologies and information systems are used. In the conditions of digitalization of the economy, special attention is paid to business processes of interaction with customers of companies, the main requirement of which is the mobility of the proposed operations and services. The use of modern tools to improve business processes is designed to increase the efficiency of any company. Depending on the scope of the company, different tools are used. In this regard, it is advisable to describe and analyze the activities of the company, and then its business processes. The result a list of business processes requiring improvement will be. This paper discusses the features and methods of automating business processes using digital technologies, analyzes the activities of the company (using the example of a travel agency), describes its main business processes. The theoretical and methodological description of the features of automation of the company showed the possibility of using modern IT tools to increase the competitiveness of the company and the level of customer satisfaction. As a result of the research of the activities of the travel agency ""1001 tour"", an analysis of external and internal factors affecting the company. Description of business processes showed the need to improve interaction with customers through the introduction of mobile technology. The theoretical significance of the study is to describe the features of improving customer service. The practical significance of this work is due to the possibility of using the results as a basis for developing models of the main business processes in the notions ""as is"" and ""to be"", preparing a project for introducing innovations and conducting a preliminary assessment of its economic efficiency.",60032982,Financial University under the Government of the Russian Federation,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",23.91666666666667,0.12542016806722692,0.3027310924369748,1,0.10062893081761007,0.0,0.2830188679245283
968,991,991,"Digital Ai ""decision Tree"" for Predicting Russian Gdp Value Based on Big Data Mining to Ensure Balanced and Sustainable Economic Growth","The relevance of the research study is due to the fact that the article attempts to prove or falsify the hypothesis that the ""AIDecision Tree"" neural network model makes it possible to obtain a forecast of Russia's GDP for various scenarios. Various aspects of the AI application in the field of big data processing, deep learning and forecasting have been investigated in the article. However, experience has proven that, certain issues of using artificial intelligence require further scientific research in order to achieve a balanced and sustainable growth of the financial and economic system. Theoretical foundations of sustainable economic growth in the country have been studied. The authors have reviewed modern domestic and foreign literature on the topic and paid special attention to the issues of balanced financial and economic system and sustainable economic growth in modern conditions. We demonstrate the factors increasing risk and market uncertainty and other in order to achieve a balanced and sustainable growth of the financial system based on the AIsystem ""Decision Tree"" developed. The trends in functioning of the financial and economic system have been determined; the dynamics of the balanced profit volumes in real sector organizations has been traced quarterly for the period of 2015-2018. Live data of the Federal State Statistics Service showed that the balanced financial result (profit except for loss) of organizations (apart from small business entities, banks, insurance organizations and state and municipal institutions) in current prices decreased by 8.5% in 2017. In order to visualize the dynamics of the effective factor - GDP a neural network model ""AI-quantization of data"" has been developed. In order to achieve a balanced and sustainable growth of the financial system based on the AI-system ""Decision Tree"" developed.",60029073,Volgograd State Technical University,Volgograd,Russian Federation,"['1712', '1709', '1707', '1705']",28.5,0.043966450216450216,0.3282738095238096,1,0.08722741433021806,0.040498442367601244,0.28253968253968254
969,992,992,Linear and classification learner models for building energy predictions and predicting saving estimations,"The need for creating building systems with smart systems is growing. Saving energy in buildings is both important in aiding the environment and saving money for the companies and organizations who run those buildings. Most buildings are now equipped with technology to produce accurate electrical outputs that can be used for improving the accuracy of energy models. This paper discusses typical data-based building energy models and proposes new improvements by utilizing a classification learner. Estimating sub-hourly and hourly electric energy consumptions are discussed using four different data-based models. The first model is a linear fit model using one regressor, the second is a linear change point fit using one regressor, and the third model is a two regressor model using a linear fit. The fourth model is a proposed Classification Learning model using three regressors. Two different types of data were collected: simulation and actual data. There are four buildings total: two with simulation and two with actual data. The results show that the proposed Classification Fine KNN model can provide accurate predictions for the data as compared to traditional linear modeling techniques. These models are then utilized to calculate saving percentage, which is then compared to the actual percentage.",60025152,University of Cincinnati,Cincinnati,United States,['1705'],18.181818181818183,0.17048406139315228,0.42715466351829984,1,0.14414414414414414,0.02702702702702703,0.3148148148148148
970,993,993,Risk measurement of it privacy and security threat in social networking sites on users perspective,"The measurement of privacy and security risks posed to users when using Social Networking Sites (SNS) is considered a challenging task for social networking users. A fundamental aspect associated with the measurement of risks is that a vast amount of data can easily be gathered virtually by any individual. This study presents a Threatware, a tool that can be used for detecting data loss in SNS. This was necessitated by the need for a framework that can identify privacy threats and risks as a way of overcoming the problem of data loss affecting most SNS. We also provided an additional functionality on the software tool that could capture risks based on several ancillary threat models. A critical evaluation of the initial results indicated that an equilibrium existed between the information on privacy threat and its relations that exist among users in SNS. These results rely heavily on users‘ willingness to disclose a significant amount of their settings derived from their friendships on Facebook. The outcome of the study ThreatWare is expected to enhance the detection of data loss as well as provide appropriate actions that can be adopted by users to mitigate privacy and security risks.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],24.5,0.14821428571428572,0.4958333333333334,1,0.14903846153846154,0.04326923076923077,0.27403846153846156
971,994,994,PRTIRG: A Knowledge Graph for People-Readable Threat Intelligence Recommendation,"People-Readable Threat Intelligence (PRTI) recommender Systems aim to address the problem of information explosion of PRTIs and make personalized recommendation for users. In general, PRTI is highly condensed, and consists of security items, network entities and emerging hacker organizations, attacks, etc. PRTI may also contain many Machine-Readable Threat Intelligence (MRTI). However, existing methods are unaware of such external knowledge and cannot fully discover latent knowledge-level connections among PRTIs. Under this scenario, the existing generic knowledge graphs will introduce too much noise and can not consider the entity relationship in terms of the attack chain. To solve the problems above, in this paper, we propose a knowledge graph for People-Readable Threat Intelligence recommendation (PRTIRG) and incorporates knowledge graph representation into PRTI recommender system for click-through prediction. The key components of PRTIRG are the denoising entity extraction module and the knowledge-aware long short-term memory neural network (KLSTM). Through extensive experiments on real-world datasets, we demonstrate that the PRTIRG is more effective and accurate than baselines.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],20.375,0.15733333333333333,0.4404444444444445,1,0.11165048543689321,0.038834951456310676,0.41578947368421054
972,995,995,TOWARDS PREDICTING RICE LOSS DUE to TYPHOONS in the PHILIPPINES,"Reliable predictions of the impact of natural hazards turning into a disaster is important for better targeting humanitarian response as well as for triggering early action. Open data and machine learning can be used to predict loss and damage to the houses and livelihoods of affected people. This research focuses on agricultural loss, more specifically rice loss in the Philippines due to typhoons. Regression and binary classification algorithms are trained using feature selection methods to find the most important explanatory features. Both geographical data from every province, and typhoon specific features of 11 historical typhoons are used as input. The percentage of lost rice area is considered as the output, with an average value of 7.1%. As for the regression task, the support vector regressor performed best with a Mean Absolute Error of 6.83 percentage points. For the classification model, thresholds of 20%, 30% and 40% are tested in order to find the best performing model. These thresholds represent different levels of lost rice fields for triggering anticipatory action towards farmers. The binary classifiers are trained to increase its ability to rightly predict the positive samples. In all three cases, the support vector classifier performed the best with a recall score of 88%, 75% and 81.82%, respectively. However, the precision score for each of these models was low: 17.05%, 14.46% and 10.84%, respectively. For both the support vector regressor and classifier, of all 14 available input features, only wind speed was selected as explanatory feature. Yet, for the other algorithms that were trained in this study, other sets of features were selected depending also on the hyperparameter settings. This variation in selected feature sets as well as the imprecise predictions were consequences of the small dataset that was used for this study. It is therefore important that data for more typhoons as well as data on other explanatory variables are gathered in order to make more robust and accurate predictions. Also, if loss data becomes available on municipality-level, rather than province-level, the models will become more accurate and valuable for operationalization.",60077790,Deutsches Rotes Kreuz,Berlin,Germany,['1710'],20.058823529411768,0.22896018455228986,0.4621140920483026,1,0.09438775510204081,0.01020408163265306,0.3118556701030928
973,996,996,Temporal shift of bagmati river over 25 years using landsat,"Bagmati River has been a terrific boon in different aspects like natural, cultural, ecological, etc. However, the river has been in a critical situation with the shift in its quality and quantity during these years. Since the changes are slow-growing, actual shifts are barely noticed. While the in-situ analysis and experimentation become costly, the analysis of Landsat images acquired with the application of Remote Sensing (RS) and Geographic Information System (GIS) provides an inexpensive technique in estimating and mapping such temporal shift in the river. Concerning the case, this study modelled the temporal changes of the Bagmati River within 25 years (1991-2016) using the multi-temporal Landsat images. We adopted the Normalized Difference Water Index (NDWI for the unsupervised extraction of the water feature and monitoring the changes. A model was developed in Arc-GIS by discerning the river, and the difference was determined for 25 years. The result indicated a major temporal shift in the river channel with a decreasing trend from 1991 to 2016. Over 25 years, the river loss almost one-third of its original water-flow channel with a severe sweep in the south-western portion of the study area. With this precise information, a field-based study can be undertaken either to analyse the damage caused by the river in those particular portions or to assess the factors affecting the river shift. Hence, we strongly recommend employing the cost-effective methods, RS and GIS, for detecting, analysing and monitoring the shifts and changes in the rivers and lakes over a while.",60111816,Purbanchal University,Biratnagar,Nepal,['1710'],22.63636363636364,0.13046875000000002,0.4885416666666666,1,0.09634551495016612,0.07308970099667775,0.39501779359430605
974,997,997,National Systems of Scientific and Technical Information Have Potential for the Development of Scientific Diplomacy in the CIS,"Abstract: This paper gives an assessment of the current state of national systems of scientific and technical information (NSs STI) in the categories of regulatory framework; government model; and structure. There is a general tendency for the CIS countries to the achievement of sustainable economic development by each state through the formation and implementation of state policy, including by increasing the role of science and technology and introducing innovations in accordance with the strategic and tactical tasks of the scientific and technological development of the countries. The development of national STI systems helps to improve the exchange of scientific and technical information, the formation of common scientific interests, and the expansion of international cooperation. Scientific and technical information resources that are concentrated in the national STI systems are the main potential for the development of scientific diplomacy and integration of the CIS member states into the information space. A proposal is formulated on the feasibility of creating a specialized electronic interdepartmental information and analytical system covering federal ministries, academies of sciences, scientific foundations, development institutions (with powers and finances for coordinated competitions), research institutes, universities and other organizations in the international sphere of scientific and technical cooperation in general and, in particular, in the CIS. Such a system will contribute to the coordination of planning joint projects, financing, the development of scientific state expertise, selection of promising research areas, topics of competitions and evaluation of the results of research and development. The format of bilateral international cooperation in joint scientific projects of the CIS countries is a promising mechanism for scientific diplomacy, introduction of innovations aimed at integrating the scientific and technological space of the CIS, and helping to strengthen the security of each CIS member state and the Commonwealth as a whole.",60014602,All-Russian Institute for Scientific and Technical Information of Russian Academy of Sciences,Moscow,Russian Federation,['1700'],41.857142857142854,0.04041666666666667,0.3220833333333334,1,0.058823529411764705,0.034055727554179564,0.2848297213622291
975,998,998,TDD-Net: A tiny defect detection network for printed circuit boards," All rights reserved.Tiny defect detection (TDD) which aims to perform the quality control of printed circuit boards (PCBs) is a basic and essential task in the production of most electronic products. Though significant progress has been made in PCB defect detection, traditional methods are still difficult to cope with the complex and diverse PCBs. To deal with these problems, this article proposes a tiny defect detection network (TDD-Net) to improve performance for PCB defect detection. In this method, the inherent multi-scale and pyramidal hierarchies of deep convolutional networks are exploited to construct feature pyramids. Compared with existing approaches, the TDD-Net has three novel changes. First, reasonable anchors are designed by using k-means clustering. Second, TDD-Net strengthens the relationship of feature maps from different levels and benefits from low-level structural information, which is suitable for tiny defect detection. Finally, considering the small and imbalance dataset, online hard example mining is adopted in the whole training phase in order to improve the quality of region-of-interest (ROI) proposals and make more effective use of data information. Quantitative results on the PCB defect dataset show that the proposed method has better portability and can achieve 98.90% mAP, which outperforms the state-of-arts. The code will be publicly available.",60014966,Peking University,Beijing,China,"['1702', '1709', '1707', '1705', '1710']",20.4,0.11884057971014493,0.5293478260869565,0,0.10588235294117647,0.03137254901960784,0.3706896551724138
976,999,999,Realisability of pomsets,"Pomsets are a model of concurrent computations introduced by Pratt. We adopt pomsets as a syntax-oblivious specification model of distributed systems where coordination happens via asynchronous message-passing. In this paper, we study conditions that ensure a specification expressed as a set of pomsets can be faithfully realised via communicating automata. Our main contributions are (i) the definition of a realisability condition accounting for termination soundness, (ii) conditions accounting for ‘‘multi-threaded’’ participants, and (iii) an algorithm to check our realisability conditions directly over pomsets, (iv) an analysis of the algorithm and its benchmarking attained with a prototype implementation.",60033125,University of Leicester,Leicester,United Kingdom,"['1712', '1703']",24.25,0.13333333333333333,0.3666666666666667,1,0.11382113821138211,0.016260162601626018,0.41025641025641024
977,1000,1000,The demand for halal certified restaurants in Indonesia,"Rapid urbanization that lead to busier lifestyles with longer work hours has increased consumer demand for convenient restaurants. Since Indonesia has a large Muslim population, this research aims to find out the demand for halal certified restaurants by analyzing the influential factors involved in consumer decision to patronize halal certified restaurants based on the Theory of Planned Behavior. By using Structural Equation Modeling, this research analyzed 149 data of respondents in South Jakarta. The finding indicates that Muslim consumers in Indonesia are becoming more conscious about halal certified restaurants and it is not simply because of Muslims obligation to obey Islamic rules, but it is also influenced by their attitude, subjective norm, perceived behavioral control, and intention before they decided to patronize halal certified restaurants. This research not only verified the high demand of halal certified restaurants in Indonesia but also provide a better understanding about Muslims' dietary rules that should be understood by the restaurants' owner and manager in order to produce products and services that in accordance with halal rules. It is also gathered that although the demand for halal products and services in the hospitality industry is growing, not many researches pertaining to halal certified restaurants. This research also suggested that the industry players and government need to work closely to facilitate halal compliance for the rising of halal products and services demand especially in hospitality industry.",60106037,Universitas Islam Negeri Syarif Hidayatullah Jakarta,Jakarta,Indonesia,['1710'],32.85714285714286,0.16742857142857145,0.6175714285714285,1,0.15040650406504066,0.044715447154471545,0.3048780487804878
978,1001,1001,Leveraging User Preferences for Community Search via Attribute Subspace,"In this paper, we propose a community search scheme via attribute subspace. This method utilizes not only network structure but also node attributes within a certain subspace to quantify a community from the perspective of both internal consistency and external separability, which is able to capture a user preferred community. Firstly, the attributes similarity and neighborhood information of nodes are combined, and the center node set of the target community can be obtained by extending the sample node given by the user with its neighbors. Secondly, an attribute subspace calculation method with entropy weights is established based on the center node set, and the attribute subspace of the community can thus be deduced. Finally, the community quality, which is the combination of internal connectivity and external separability is defined, based on which the target community with user’s preference can be detected. Experimental results on both synthetic network and real-world network datasets demonstrated the efficiency and effectiveness of the proposed algorithm.",60020464,Guangxi Normal University,Guilin,China,['1700'],26.66666666666667,0.06648351648351647,0.3330586080586081,1,0.12359550561797752,0.0,0.2033898305084746
979,1002,1002,GeneRHi-C: 3D GENomE reconstruction from Hi-C data,"Background: Many computational methods have been developed that leverage the results from biological experiments (such as Hi-C) to infer the 3D organization of the genome. Formally, this is referred to as the 3D genome reconstruction problem (3D-GRP). Hi-C data is now being generated at increasingly high resolutions. As this resolution increases, it has become computationally infeasible to predict a 3D genome organization with the majority of existing methods. None of the existing solution methods have utilized a nonprocedural programming approach (such as integer programming) despite the established advantages and successful applications of such approaches for predicting high-resolution 3D structures of other biomolecules. Our objective was to develop a new solution to the 3D-GRP that utilizes non-procedural programming to realize the same advantages. Results: In this paper, we present a three-step consensus method (called GeneRHi-C; pronounced ""generic"") for solving the 3D-GRP which utilizes both new and existing techniques. Briefly, (1) the dimensionality of the 3D-GRP is reduced by identifying a biologically plausible, ploidy-dependent subset of interactions from the Hi-C data. This is performed by modelling the task as an optimization problem and solving it efficiently with an implementation in a non-procedural programming language. The second step (2) generates a biological network (graph) that represents the subset of interactions identified in the previous step. Briefly, genomic bins are represented as nodes in the network with weighted-edges representing known and detected interactions. Finally, the third step (3) uses the ForceAtlas 3D network layout algorithm to calculate (x, y, z) coordinates for each genomic region in the contact map. The resultant predicted genome organization represents the interactions of a population-averaged consensus structure. The overallworkflow was tested with Hi-C data from Schizosaccharomyces pombe (fission yeast). The resulting 3D structure clearly recapitulated previously established features of fission yeast 3D genome organization. Conclusion: Overall, GeneRHi-C demonstrates the power of nonprocedural programming and graph theoretic techniques for providing an efficient, generalizable solution to the 3D-GRP. Project Homepage: https://github.com/kimmackay/GeneRHi-C.",60015186,University of Saskatchewan,Saskatoon,Canada,"['1712', '1709', '1707', '1705']",18.823529411764707,0.0801830808080808,0.3409343434343433,1,0.10975609756097561,0.05853658536585366,0.4323607427055703
980,1003,1003,The selection parameters of various banks in nanded district,"The Financial service industry is having cut throat competition as there are many banking and non banking financial companies competing to increase the customer database. The customer database can be increased if customers prefer the brand of that financial company. The preferred brands are selected by the customers. This present study is focused to analyze the impact of different selection parameters of banks and NBFCs. The brand selection parameters and its relative importance are studied through and Ranking based on Weighted Average Score. The present study is carried out in Nanded district and the respondents include Customers, Managers and Employees.",60026737,Swami Ramanand Teerth Marathwada University,Nanded,India,['1700'],16.666666666666664,0.03888888888888889,0.16666666666666666,1,0.1308411214953271,0.04672897196261682,0.29906542056074764
981,1004,1004,GIS-ASSISTED FLOOD HAZARD ASSESSMENT and MAPPING in SELECTED AREAS in ZAMBALES,"The Philippines experiences an average of 20 cyclones per year which cause flooding in many parts of the country and Zambales is one of them. In August 2013, Typhoon Labuyo hit the province that affected most of its municipalities and placing the town of Masinloc under the state of calamity due to occurrence of flood. Likewise, in September 2018, Typhoon Ompong hit the province of Zambales and brought heavy rains and floods to the municipalities of Sta. Cruz, Candelaria, Masinloc, and Palauig. Hence, this study was conducted to generate flood hazard maps in the northern municipalities of Zambales: Sta. Cruz, Candelaria, Masinloc, and Palauig using Geographic Information System through raster calculator. Weights of the factors considered in generating flood hazard susceptibility map, namely, elevation, slope, soil type, land classification, and distance from the river, were drawn from ten (10) experts and undergone Analytical Hierarchy Process (AHP). Field validation was also conducted to test the accuracy of maps generated. Flood hazard susceptibility was categorized into four (4) namely high, moderate, low, and no susceptibility. Results showed 15% of the total land area of Sta. Cruz, 12% of Candelaria, 15% of Masinloc, and 19% of Palauig had high susceptibility to flooding. Barangays situated in these areas should be given priority in flood adaptation and mitigating programs.",60071461,Central Luzon State University,Munoz,Philippines,['1710'],17.833333333333332,0.07681818181818181,0.464090909090909,1,0.09230769230769231,0.13076923076923078,0.4461538461538462
982,1005,1005,Inconsistency Handling for Partially Preordered Ontologies: Going Beyond Elect,"We continue investigations into computing repairs for an inconsistent Description Logic (DL) knowledge base (KB). In recent work, a tractable method, called Elect, has been introduced to restore consistency of the ABox w.r.t. the TBox. Elect deals with the case of KBs expressed in DL-Lite and when a partial preorder is applied to the ABox. It has been shown that Elect generalizes the well-known IAR semantics when no priority relation over the ABox is used, and the so-called non-defeated semantics when the relation is a total preorder. In the present paper, we propose two extensions of Elect. First, we redefine Elect by using a preference-based semantics from the literature but with the drawback of losing tractability. Second, we show under which conditions Elect can be generalized to DLs that are more expressive than DL-Lite.",60018178,Universite d'Artois,Arras,France,['1700'],16.75,0.3633333333333333,0.6355555555555555,1,0.13333333333333333,0.12121212121212122,0.39869281045751637
983,1006,1006,Evaluating the influence of three simplifications on natural ventilation rate simulation,"Measurement and simulation are two main methods to determine natural ventilation rates in a building. By contrast, the simulation method is widely used in engineering due to its simplicity and convenience. In the practical application of airflow simulation software such as CONTAMW, there exist many simplifications for the actual conditions of simulated buildings. This study focuses on three of the commonly used simplifications and analyses their effects on the simulation results. In addition, for rigorousness, tracer gas decay method is used to verify the reliability of CONTAMW simulation. The conclusions of this study can be used as guidance for airflow simulation software such as CONTAMW.",60025278,Tsinghua University,Beijing,China,['1705'],17.5,0.02685185185185185,0.4009259259259259,1,0.08695652173913043,0.06086956521739131,0.2782608695652174
984,1007,1007,Keep it fair: Equivalence and composition,"Fairness assumptions are commonly used to filter system behaviors, thereby distinguishing between realistic and unrealistic executions. This allows for key arguments in correctness proofs of distributed systems, which would not be possible otherwise. Our first contribution is an equivalence spectrum in which fairness assumptions are preserved. Although the identified equivalences allow for reasoning about correctness incorporating fairness assumptions, this does not necessarily allow for the lifting of arguments from sequential processes to parallel compositions employing arbitrary synchronization mechanisms. Our second contribution is, therefore, an analysis of parallel composition operators and their synchronization mechanisms in this respect.",60011604,Technical University of Berlin,Berlin,Germany,"['1712', '1703']",19.2,-0.04393939393939394,0.5242424242424242,1,0.1320754716981132,0.0,0.330188679245283
985,1008,1008,ProteinA: An Approach for Analyzing and Visualizing Protein Conformational Transitions Using Fuzzy and Hard Clustering Techniques,"It is not easy finding arguments against the common belief that Proteomics and Genomics are the most challenging and important research fields, posing interesting problems for our current era. Gaining insight into the protein folding process has been the goal of many in the past few decades. Understanding completely how proteins come alive and behave will revolutionize modern medicine. With the main goal of understanding the importance of the protein folding problem and uncovering hidden patterns in protein data, we are analyzing protein conformational transitions with unsupervised learning tools, by applying different types of hard and fuzzy clustering algorithms and comparing the results. As an additional goal, the paper describes a software that can perform on demand analysis on protein data and display the results in a web interface. It is a proof of concept for potential useful features that make software algorithms available for researchers of all domains.",60024417,Universitatea Babes-Bolyai din Cluj-Napoca,Cluj Napoca,Romania,['1700'],24.83333333333333,0.11208333333333334,0.4945833333333334,1,0.12578616352201258,0.012578616352201259,0.27044025157232704
986,1009,1009,Revisiting the current uav regulations in Nepal: A step towards legal dimension for uavs efficient application,"UAVs-Unmanned Aerial Vehicles- also known as drones, are an emerging geospatial technology that can facilitate data acquisition at various temporal and spatial scales. Notwithstanding, the wide application of UAVs globally, its wider application is found to be growing in Nepal as well. For instance, precision agriculture, forestry, topographical surveying, etc. It seems that there is a correlation between efficient use of UAVs in these sectors and the legal frameworks that regulate the use of UAVs. Therefore, it seems necessary to obtain holistic national view of UAVs regulations. Aligning with this necessity, this paper provides insight on existing legal provisions for UAVs in Nepal by highlighting the importance, impact, and limitations of UAV regulations. The criteria used in the framework to capture the present holistic legal dimension from literature in the web of science database are a) applicability b) technical requirements c) operational requirements/ limitations d) administration procedure e) human resource requirements and f) implementation of ethical constraints. The adopted methodological approach consists of exploratory case studies, systematic reviews of the concerned literature on UAVs regulations and the workshop on ""Flight 4 Purpose"" in which various UAVs application were discussed. The results show that the existing legal framework has both strengths and weaknesses for its use to capture the spatial data. The way forward is to harmonize the soft and hard regulations so that such geospatial technology can be applied for overall development and ultimately for the societal benefits.",60071792,Kathmandu University,Dhulikhel,Nepal,['1710'],23.8,0.03935185185185185,0.3550925925925926,1,0.09259259259259259,0.037037037037037035,0.30970149253731344
987,1010,1010,Graph transformation through graph surfing in reaction systems,"In this paper, we introduce graph-based reaction systems as a generalization of set-based reaction systems, a novel and well-investigated model of interactive computation. Graph-based reaction systems allow us to introduce a new methodology for graph transformation, which is not based on the traditional “cut, add, and paste” approach, but rather on moving within a “universe” graph B (surfing on B) from a subgraph of B to a subgraph of B, creating subgraph trajectories within B. We illustrate this approach by small case studies: approximating the Sierpinski triangle, simulating finite automata, implementing two shortest-paths algorithms, and simulating cellular automata. Finally, we introduce the notion of territorial graph surfing systems taking a more “global” look at graph-based reaction systems.",60019816,Leiden University,Leiden,Netherlands,"['1712', '1703']",29.25,0.06439393939393939,0.5174242424242425,1,0.13157894736842105,0.05263157894736842,0.36879432624113473
988,1011,1011,Study on extraction and expression methods of bulging diseases in ancient city walls," CC BY 4.0 License.The ancient city wall contains rich cultural values. Due to environmental and human factors, there are many diseases in the ancient city wall: bulging, cracking, etc., which will lead to the collapse or even death of the ancient city wall. Therefore, the monitoring and protection of the ancient city wall is imminent. This paper proposes a new scheme for bulging monitoring for wall bulging. The feature plane is fitted according to the actual scan data, the degree of bulging, the trend and the area size are determined, and the bulging deformation of the city wall is displayed in the form of an image. Simplify workflow, improve data processing efficiency, and display more intuitively.",60092860,Beijing University Of Civil Engineering And Architecture,Beijing,China,['1710'],19.5,0.1857954545454545,0.35994318181818186,0,0.11678832116788321,0.0,0.3007518796992481
989,1012,1012,Evaluation of Digital Transformation of Government: Russian and international systems of indicators,"Russian government has started the reforms based on digital transformation ideas in 2010. The reforms resulted in successful installation of quite advanced infrastructure of digital government. By E-government development index Russia is now in the group of very-high performing countries. Other ratings did not show the same success of the country in other areas of economy, governance and political life. Although digitalization enhances accountability, efficiency and transparency of government, help to reduce costs and lead to better governance, there are examples when countries do not reach these goals despite the implementation of digital technologies. An important part of it is poorly designed strategy of reforms. Particularly, the case when the indicators of achievement the goals of digitalization do not conform closely to what is widely thought to be the modern digital government. In this case even actual accomplishment of the targeted values cannot testify existence of a working e-government. The objectives of this research are to analyze the system of indicators that the Russian government set for the digital reform and to compare this system to international evaluation systems and theoretical background. The research question is whether the indicators that government set can really show the transformation to the digital government. Using analysis of e-government objectives and indicators stated in the adopted legislative acts and their relation with international digital and e-government common goals and the indicators the authors have tried to analyze the reasons why successful performance in e-government reforms in Russia did not lead to new quality of governance. The analysis showed that the system of evaluation of e-government does not meet the requirements and even the proper values of all the indicators will not help to implement real digitalization.",60107796,The St. Petersburg State University of Economics,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",23.5,0.092282196969697,0.2613399621212121,1,0.10509554140127389,0.006369426751592357,0.22666666666666666
990,1013,1013,Conversational AI: Social and ethical considerations," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Conversational Agents are becoming ubiquitous in our daily lives. They are used in various areas including customer service, education, medicine, and entertainment. As tools that are increasingly permeating various social domains, Conversational Agents can have a direct impact on individual's lives and on social discourse in general. Consequently, critical evaluation of this impact is imperative. In this paper, we highlight some emerging ethical issues and suggest ways for agent designers, developers, and owners to approach them with the goal of responsible development of Conversational Agents.",60005141,University College Dublin,Dublin,Ireland,['1700'],19.4,0.11190476190476192,0.4452380952380952,0,0.08928571428571429,0.08035714285714286,0.415929203539823
991,1014,1014,ILLUMINANCE MAPPING of NIGHTTIME ROAD ENVIRONMENT USING UNMANNED AERIAL SYSTEM,"One purpose of road lighting in night-time environment is to allow pedestrians safe passage and provide sense of security. To attain this purpose, guidelines are set to make sure that proper lighting are present in roads. Current mapping of road lighting in the Philippines is a tedious process. To address this issue, an alternative method of mapping illuminance using Unmanned Aerial System is developed. A 3D model of the road was created using overlapping images and is the basis of the data points. The results of the calibration show that each of the camera channels, as well the photopic luminance value denoted as ND, shows a linear trend with the illuminance value recorded within the subject area having a range of 0.17 to 15 lux. Linear regression models using each of the channels of the camera and ND can be used to calculate illuminance with RMSE of less than 0.6 lux. It also shows that all values calculated from all regression models exhibits similar trend with blue differing by being generally lower in value. With blue as the best linear regression model, 3D and 2D models of illuminance were created. With these results, it can be concluded that application of photogrammetry through UAV-mounted camera can be used to map illuminance at low level lighting.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.4,0.08777777777777779,0.3525925925925925,1,0.14102564102564102,0.029914529914529916,0.2956521739130435
992,1015,1015,On the validity of Bayesian neural networks for uncertainty estimation," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Deep neural networks (DNN) are versatile parametric models utilised successfully in a diverse number of tasks and domains. However, they have limitations-particularly from their lack of robustness and over-sensitivity to out of distribution samples. Bayesian Neural Networks, due to their formulation under the Bayesian framework, provide a principled approach to building neural networks that address these limitations. This work provides an empirical study evaluating and comparing Bayesian Neural Networks to their equivalent point estimate Deep Neural Networks to quantify the predictive uncertainty induced by their parameters, as well as their performance in view of uncertainty. Specifically, we evaluated and compared three point estimate deep neural networks against their alternative comparable Bayesian neural network utilising well-known benchmark image classification datasets.",60005141,University College Dublin,Dublin,Ireland,['1700'],26.2,0.17500000000000002,0.4607142857142858,0,0.1,0.08666666666666667,0.42758620689655175
993,1016,1016,CoReS: A tool for computing core graphs via SAT/SMT solvers,"When specifying graph languages via type graphs, cores provide a convenient way to minimize the type graph without changing the corresponding graph language, i.e. the set of graphs that can be mapped homomorphically into the given type graph. However, given a type graph, the problem of finding its core is NP-hard. Using the tool CoReS, we automatically encode all required properties into SAT- and SMT-formulas in order to iteratively compute cores by employing the corresponding solvers. We obtain and discuss runtime results to evaluate and compare the two encodings. Furthermore we consider two application scenarios: invariant checking for graph transformation rules and minimization of conjunctive queries in the context of databases.",60014264,Universität Duisburg-Essen,Essen,Germany,"['1712', '1703']",18.5,0.0,0.0,1,0.1746031746031746,0.03968253968253968,0.34959349593495936
994,1017,1017,Jointly Modeling Community and Topic in Social Network,"Social networks contain not only link information, but also text information. It is an important task to discover communities in social network analysis. Moreover, it is helpful to understand the community by finding its topics of interest. In fact, social networks are always dynamic. However, there are still few method to detect communities and their topics by combining link and text information in dynamic network. In this paper, we formulate the problem of detecting communities and their topics and propose a dynamic topical community detection (DTCD) method to solve the problem. DTCD integrates link, text and time in a unified way by using generative model. The community and the topic are modeled as latent variables which are learned by collapsed Gibbs sampling. DTCD can not only find communities and their topics, but also capture the temporal variations of communities and topics. Experimental results on two real-world datasets demonstrate the effectiveness of DTCD.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],15.2,0.03333333333333333,0.3541666666666667,1,0.11560693641618497,0.023121387283236993,0.30994152046783624
995,1018,1018,Naïverole: Author-contribution extraction and parsing from biomedical manuscripts," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Information about the contributions of individual authors to scientific publications is important for assessing authors' achievements. Some biomedical publications have a short section that describes authors' roles and contributions. It is usually written in natural language and hence author contributions cannot be trivially extracted in machine readable format. In this paper, we present 1) A statistical analysis of roles in author contributions sections, and 2) NaïveRole, a novel approach to extract structured authors' roles from author contribution sections. For the first part, we used co-clustering techniques, as well as Open Information Extraction, to semi-automatically discover the popular roles within a corpus of 2,000 contributions sections from PubMed Central. The discovered roles were used to automatically build a training set for NaïveRole, our role extractor approach, based on Naïve Bayes. NaïveRole extracts roles with a micro-averaged precision of 0.68, recall of 0.48 and F1 of 0.57. It is, to the best of our knowledge, the first attempt to automatically extract author roles from research papers. This paper is an extended version of a previous poster published at JCDL 2018.",60011149,Trinity College Dublin,Dublin,Ireland,['1700'],21.11111111111111,0.1788888888888889,0.4088888888888889,0,0.08071748878923767,0.08071748878923767,0.43119266055045874
996,1019,1019,Review of digital technologies to improve productivity of New Zealand construction industry," This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.The New Zealand construction industry continues to face pressures to improve productivity and lower construction costs. With the need to build more houses and infrastructure, quicker, to high quality and on time, there is a need to upscale the use of advanced technologies. Going digital is a solution that can transform the construction industry by improving productivity measures. The objectives of this paper are to: 1 Identify the availability of transformative technologies and their potential impact on productivity improvement across the construction life cycle and, 2. To investigate the benefits and barriers to technology-uptake in New Zealand construction. This paper is a review of digital technologies which analyzes their impact on productivity across the construction life cycle. As a basis for analysis, the digital technologies are isolated into three key productivity improvement functions: (1) Ubiquitous Digital Access, (2) Whole Building Whole-of-Life (WBWOL) decision making, and (3) Cost Reduction Engineering. This study is a literature-based theoretical exploration, aimed at signifying digitization as a function of productivity performance in the New Zealand construction industry. From a practical perspective, clients and contractors may be convinced to invest in digital technologies, increasing or accelerating uptake and more fully realizing the benefits digital technologies could add to productivity performance, growth and long-term success. This study may provide useful information for researchers regarding the development of case studies by analyzing organizations that implement technological innovations, their successful actions/processes, barriers overcoming actions, and sources of new ideas.",60110548,Massey University Auckland,Albany,New Zealand,['1706'],27.5,0.14001683501683498,0.3984511784511784,0,0.1033434650455927,0.0547112462006079,0.37658227848101267
997,1020,1020,HYBRID CANONICAL CORRELATION ANALYSIS and REGRESSION for RADIOMETRIC NORMALIZATION of CROSS-SENSOR SATELLITE IMAGES,"Relative radiometric normalization (RRN) minimizes radiometric differences among images caused by inconsistencies of acquisition condition. In this study, a cross-sensor RRN method is proposed for optical satellite images from Landsat 8 OLI (L8) and Landsat 7 ETM+ (L7) sensors. The data from these two sensors have different pixel depths. Therefore, a rescaling on the radiometry resolution is performed in the preprocessing. Then, multivariate alteration detection (MAD) based on kernel canonical correlation analysis (KCCA) is adopted, which is called KCCA-based MAD, to select pseudo-invariant features (PIFs). The process of RRN is performed by using polynomial regression with Gaussian weighted regression. In experiments, qualitative and quantitative analyses on images from different sensors are conducted. The experimental result demonstrates the superiority of the proposed nonlinear transformation, in terms of regression quality and radiometric consistency, compared with RRN using linear regression.",60014982,National Cheng Kung University,Tainan,Taiwan,['1710'],17.125,-0.17857142857142858,0.5142857142857143,1,0.09941520467836257,0.07602339181286549,0.48484848484848486
998,1021,1021,Evaluation of milled chamaerops fruit shell for production of brake friction materials,"Brake pads are high consumable spare parts, so it must make brake pads of environmental materials which are available, cheap, safety and having properties such as; Friction Level. Brake pedal effort should be limit by elevation the coefficient of friction, Resistance to Oil and hydrophobic Contamination, Resistance to Wear, stable in Heat, Resistance to the Intensity of Pressure and Resistance to Moisture Sensitivity, Resistance to Wear, stable in Heat, Resistance to Oil and Water Contamination, Resistance to the Intensity of Pressure and Resistance to Moisture Sensitivity. The former Model of Brake Pads made of mixed of milled Chamaerops fruit shell, milled Nano white sandstone and quarried iron oxide in Nano size. An investigation by Fourier transform Infra-red spectrometry and scanning electron microscope required to test the formed disc of Brake Pads. Examined samples are safety (Eco-friendly) because it is free asbestos. The results show that examined samples are: high limit friction, resistance to oil and water absorption, highest tensile and compression properties, and thermal stability. Choice Chamaerops for making brake due to several reasons; (1) Chamaerops excelsa peroxidases (CEP) are very stable enzymes, which has a high ph. and thermal stability. (2) Chamaerops applied as a Corrosion Inhibitor for Steel. (3) Chamaerops contains tocols, carotenoids, and chlorophyll impart significant stability against oxidative deterioration.",60018623,South Valley University,Qena,Egypt,['1700'],21.3,0.15214285714285716,0.4157142857142857,1,0.08527131782945736,0.14728682170542637,0.43700787401574803
999,1022,1022,Analysis of possibilities of low-cost photogrammetry for interior mapping,"This paper shows the possibilities of using low-cost photogrammetry for interior mapping as a tool to gather fast and accurate data for 3D modelling and BIM. To create a 3D model of a building interior with a high level of detail requires techniques such as laser scanning and photogrammetry. In the case of photogrammetry, it is possible to use standard cameras and SfM software to create an accurate point cloud which can be used for 3D modelling and then for BIM. The images captured indoor are often captured under lower light conditions. Using different exposure during capturing of images of building interior was tested. Frequent plain walls of a building interior cause that the images are usually lack of any features and their photogrammetric processing is getting much more difficult. In some cases, results of photogrammetric processing are poor and inaccurate. In this paper, an experiment of creating a 3D model of a building interior using photogrammetric processing of images was carried out. For this experiment digital camera with two different lenses (16&thinsp;mm lens and fisheye lens) was used. For photogrammetric processing were chosen different software. All the results were compared to each other and to the laser scanning data of the interior. At the end of the paper, the discussion of the advantages and disadvantages of the shown method has been made.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,['1710'],18.58333333333333,0.035300751879699256,0.5152005012531328,1,0.09876543209876543,0.00823045267489712,0.30612244897959184
1000,1023,1023,Interpretable machine learning models for assisting clinicians in the analysis of physiological data," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The analysis of physiological data plays a significant role in medical diagnostics. While state-of-the-art machine learning models demonstrate high levels of performance in classifying physiological data clinicians are slow to adopt them. A contributing factor to the slow rate of adoption is the “black-box” nature of the underlying model whereby the clinician is presented with a prediction result, but the rationale for that result omitted or not presented in an interpretable manner. This gives rise to the need for interpretable machine learning models such that clinicians can verify, and rationalise, the predictions made by a model. If a clinician understands why a model makes a prediction, they will be more inclined to accept a models assistance in analysing physiological data. This paper discusses some of the latest findings in interpretable machine learning. Thereafter, based on these findings, three models are selected and implemented to analyse ECG data that are both accurate and exhibit a high level of interpretability.",60001376,Cork Institute of Technology,Bishopstown,Ireland,['1700'],24.285714285714285,0.16624999999999998,0.5240277777777779,0,0.12886597938144329,0.041237113402061855,0.32085561497326204
1001,1024,1024,Estimation of forest coverage in northern region of Mongolia using sentinel and landsat data,This paper aims to apply Forest Index (FI) and to determine forest coverage in the study area. The study area (49&deg;&thinsp;15? to 49&deg;&thinsp;10?&thinsp;N and 104&deg;&thinsp;05? to 104&deg;&thinsp;15?&thinsp;E) is located in the northern region of Mongolia and consist of mixed forest. Larch forest (86.12%) is dominating in the study area. The Sentinel-2 satellite data for the years 2015-2019 were used in the research. The land surface temperature (LST) was produced from Landsat-8 OL. FI methodology was applied for the Sentinel data in order to estimate larch forest coverage. The output map of forest coverage was compared with ground truth measurements and thematic map. The agreement between FI map and ground measurement was 85%. LST from Landsat and FI from Sentinel were sampled in to same size. The relationship between LST (Landsat-8) and FI (Sentinel-2) was reasonable (R&thinsp;Combining double low line&thinsp;0.5). FI index and LST is applicable for different forest type in the region.,60072643,National University of Mongolia,Ulaanbaatar,Mongolia,['1710'],13.818181818181818,0.028571428571428574,0.26785714285714285,1,0.07650273224043716,0.1092896174863388,0.4669603524229075
1002,1025,1025,Estimation of network lifetime considering ageing effect on battery capacity of mobile devices in wireless ad-hoc network,"Energy of nodes in ad-hoc network is one of the critical issue. In literature we have studied various techniques and protocols which focus on energy optimization schemes. These schemes taking into consideration remaining battery power (RBP), but how RBP affected with various environmental factors is not considered. In mobile devices power estimation accuracy is greatly affected by battery ageing which limits its performance and occur all through the life of a device whether it is used or not, which is a chief limitation on actual usage. Moreover, degradations take place in every situation, but with different extent as external conditions and usage interact to aggravate degradations. While designing the energy efficient routing protocols battery aging was not taken into account for estimating RBP. Accurate information regarding battery ageing would be valuable for mobile devices in critical circumstances. To ensure accurate battery measurement and modeling, the influence of the aging effect must also be considered. Existing papers have not considered the impact of ageing while estimating the network lifetime. This paper focus on ageing along with the existing metrics while selecting a route and network lifetime of a node. In this paper the impact of different operating conditions during charging and discharging, high temperature and storage time is analyzed on the aging behavior and we observed that an aged battery will have to be recharged more frequently than when the battery was fresh. This will lead to even more wear-out and the remaining run-times will on the contrary be unacceptably short.",60105382,"Amity University, Haryana",Gurgaon,India,['1700'],20.83333333333333,0.17,0.5031481481481482,1,0.14130434782608695,0.007246376811594203,0.24814814814814815
1003,1026,1026,Extracting Hidden Preferences over Partitions in Hedonic Cooperative Games,"The prevalent assumption in hedonic games is that agents are interested solely on the composition of their own coalition. Moreover, agent preferences are usually assumed to be known with certainty. In our work, agents have hidden preferences over partitions. We first put forward the formal definition of hedonic games in partition function form (PFF-HGs), and extend well-studied classes of hedonic games to this setting. Then we exploit three well-known supervised learning models, linear regression, linear regression with basis function, and feed forward neural networks, in order to (approximately) extract the unknown hedonic preference relations over partitions. We conduct a systematic evaluation to compare the performance of these models on PFF-HGs; and, in the process, we develop an evaluation metric specifically designed for our problem. Our experimental results confirm the effectiveness of our work.",60022461,Technical University of Crete,Chania,Greece,['1700'],19.0,0.035416666666666666,0.5020833333333334,1,0.09259259259259259,0.024691358024691357,0.2987012987012987
1004,1027,1027,Extracting free energy of clusters in concentrated binary alloys from atomistic Monte Carlo simulations,"A good knowledge of clusters (thermal fluctuations or precipitates) free energy as a function of their size and temperature is essential to accurately describe nucleation and growth, even in binary alloys. Thanks to a Monte Carlo (MC) method, this quantity can be accurately calculated, but results are directly applicable only to dilute alloys. For concentrated alloys, results must be reinterpreted to account for the probability of coagulation between close clusters. To investigate this kind of situation with atomistic MC (AMC) simulations, ordered and coherent Al3Li clusters embedded in concentrated Al-Li alloys are considered. A classical pair potential limited to first and second nearest neighbours is proposed for this purpose. To enhance the MC calculation of cluster free energy, a new acceptance criterion related to the probability of coagulation is added to the classical energy one. It is shown that the properties of clusters can be directly extracted from AMC simulations. A few simple tests are provided to prove the consistency of this approach.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,['1706'],20.375,0.17795159386068474,0.4615702479338844,1,0.11351351351351352,0.05945945945945946,0.28415300546448086
1005,1028,1028,The phonetics and phonology of lenition: A Campidanese Sardinian case study,"This paper gives a detailed description of the consonant system of Campidanese Sardinian and makes methodological and theoretical contributions to the study of lenition. The data are drawn from a corpus of field recordings, including roughly 400 utterances produced by 15 speakers from the Trexenta and Western Campidanese areas. Campidanese has a complex lenition system that interacts with length, voicing, and manner contrasts. We show that the semi-automated lenition analysis presented in this journal by Ennever, Meakins, and Round can be fruitfully extended to our corpus, despite its much more heterogeneous set of materials in a genetically distant language. Intensity measurements from this method do not differ qualitatively from more traditional ones in their ability to detect lenition-fortition patterns, but do differ in interactions with stress. Lenition-fortition patterns reveal at least three levels of prosodic constituent in Campidanese, each of which is associated with medial lenition and initial fortition. Lenition affects all consonants and V-V transitions. It reduces duration, increases intensity, and probabilistically affects qualitative manner and voicing features in obstruents. Mediation analysis using regression modeling suggests that some intensity and most qualitative reflexes of lenition are explained by changes in duration, but not vice versa.",60032259,Università degli Studi di Cagliari,Cagliari,Italy,['1706'],21.777777777777782,0.06923076923076922,0.3884615384615385,1,0.10714285714285714,0.03571428571428571,0.375
1006,1029,1029,KPConv: Flexible and deformable convolution for point clouds,"We present Kernel Point Convolution (KPConv), a new design of point convolution, i.e. that operates on point clouds without any intermediate representation. The convolution weights of KPConv are located in Euclidean space by kernel points, and applied to the input points close to them. Its capacity to use any number of kernel points gives KPConv more flexibility than fixed grid convolutions. Furthermore, these locations are continuous in space and can be learned by the network. Therefore, KPConv can be extended to deformable convolutions that learn to adapt kernel points to local geometry. Thanks to a regular subsampling strategy, KPConv is also efficient and robust to varying densities. Whether they use deformable KPConv for complex tasks, or rigid KPconv for simpler tasks, our networks outperform state-of-the-art classification and segmentation approaches on several datasets. We also offer ablation studies and visualizations to provide understanding of what has been learned by KPConv and to validate the descriptive power of deformable KPConv.",60030506,Mines ParisTech,Paris,France,"['1712', '1707']",17.555555555555557,0.07070707070707069,0.2034965034965035,1,0.1043956043956044,0.06593406593406594,0.3559322033898305
1007,1030,1030,Knowledge Sharing Model for Competitive Ecosystem on Gig Economy,"Digital business with gig economy scheme had no culture to share knowledge since strictly competition among gig workers. It affects gig workers' limited ability and knowledge to accomplish projects and reduce their performance. This study proposed a knowledgesharing model to articulate insightful knowledge from scattered tacit and explicit knowledge by keep personal data and copyright. It performed Soft System Methodology to facilitate conceptualization process from founded problem until strategies formulation. It generated artifacts to clarify problems and elaborates their solutions. By decomposing the problems into fishbone analysis, this study has identified who are the involved stakeholders and how the knowledge management should run. It became root cause as baseline to conceptualize a knowledge sharing model among gig workers. As the result, this study delivered a knowledge sharing model which relied on point system to engage gig workers' participation to externalize their knowledge in knowledge repository and expert should validate them before knowledge storing. To achieve more qualified model, this study relied on validation by representative gig workers and platform applications. This model contributes to mediate knowledge circulation among gig workers by encourage their extrinsic motivation. Hence, it can deliver innovative solution to enhance digital business on modern society through gig worker empowerment.",60069377,Universitas Indonesia,Depok,Indonesia,"['1712', '1709', '1707', '1705']",18.363636363636363,0.15357142857142855,0.3241071428571428,1,0.1598173515981735,0.0228310502283105,0.2876712328767123
1008,1031,1031,Autonomous vehicle mapping withvlp-16 lidar using lidar odometry and mapping algorithm,"Mapping is one of the important aspects in Simultaneous Localization and Mapping (SLAM) methods. It is imperative for an autonomous vehicle (AV) to be able to map its surrounding environment in an accurate manner so that it can be used by the other systems in the AV. This led to the issue thatfaced by many SLAM researches that asks for the possibility for an AV to simultaneously build a consistent map of the surrounding unknown environment and verify its location within the said map. One of the obstacles in mapping the AV is localization estimation. Scattered GPS signal problem is a known factor held by the earlier AVs and to counter this issue Light Detection and Ranging (LiDAR) sensor was utilised due to its ability to collect large amount of data in a short amount of time. This research aims to provide the AV mapping by using LIDAR focusing on the optimization-based method. Data was collected using a 3D LiDAR sensor, Velodyne Puck in the selected area around UniversitiTeknologi MARA. This project was experimented with Robotic Operating System (ROS) and visualized through the RViz tool in ROS. This research employed Lidar Odometry and Mapping (LOAM) algorithm in building the map and has produced a viable result with less than 5% percent error rate. It demonstrates the benefits of the LOAM algorithm on the real-world data. With the high accuracy achieved shows this algorithm can help in the development of autonomous vehicle for the mapping process. Future works can be done to ensure the performance of the system is in excellent condition and increase its accuracy.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1700'],22.08333333333333,0.1978809523809524,0.4809285714285714,1,0.14334470989761092,0.08532423208191127,0.33217993079584773
1009,1032,1032,Towards a temporal deep learning model to support sustainable agricultural practices," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The impressive results of deep learning in many different fields, specifically in remote sensing, together with the growing availability of open Earth Observation data creates new opportunities to address global problems. One such global problem is associated with the simplification and intensification of agricultural systems which threatens the worldwide sustainability of crop production. Despite the fact that a plethora of satellite images describe a given location on earth every year, very few deep learning-based solutions have harnessed the temporal and sequential dynamics of land use to map sustainable and unsustainable cropping practices. In this paper, we present the preliminary results of a set of experiments conducted using one-dimensional Convolutional Neural Networks (CNN) for classifying multispectral time series derived from Landsat satellites constellation. The experimental data is related to agricultural practices in Sacramento County, California, United States of America. We discuss the applicability of this approach for mapping sustainable crop rotation-based practices which have been proven to mitigate the environmental impact of agricultural land use dynamics.",60027012,Gdańsk University of Technology,Gdansk,Poland,['1700'],29.5,0.11037433155080212,0.3814438502673797,0,0.1111111111111111,0.09595959595959595,0.35751295336787564
1010,1034,1034,Targeted unsupervised features learning for gene expression data analysis to predict cancer stage,"The intensive explosion in the generation of large scale cancer gene expression data brought several computational challenges, yet opened great opportunities in exploring different pathways in order to improve cancer prognosis, diagnosis and treatment. In this paper, we propose a targeted unsupervised learning model, based on deep autoencoders (TAE) to learn significant cancer representation based on the gene expression omnibus(GEO) integrated expO data set, for the ultimate goal of constructing an accurate cancer stage predictive model. Where, the trained model was tested on two gene expression cancer data sets namely, lung cancer for clinical stage and intensive breast cancer (IBC) for pathological stage. In which, the model extracted new features space for the two cancer type based on the knowledge built from the expO data set. The generated features were used to train classifiers to predict the cancer stage of each sample. We evaluated the effectiveness of our proposal by comparison to the principal component analysis (PCA) unsupervised dimensionality reduction, as well as to the supervised univariate features selection method. The experimental results, show a promising performance of our analysis model to build a collaborative knowledge from different cancer type to enhance the prediction rate of different cancer stage.",60105374,Université Abdelhamid Mehri Constantine 2,Constantine,Algeria,"['1712', '1709', '1707', '1705']",28.42857142857143,0.17120379620379625,0.5570346320346321,1,0.12556053811659193,0.02242152466367713,0.2311111111111111
1011,1035,1035,An approach for automatic recognition system for Indian vehicles numbers using k-nearest neighbours and decision tree classifier,"An Automatic Vehicle Number Plate Recognition System is presented in this paper. Basically, there are different kinds of motor vehicle number plates which are used in India. The actual number plates are not similar and most of them are deviated from the prescribed norms as laid by Government of India from time to time. The number plates of Indian vehicles are written in different languages also. The number plate characters are varied according to the language of a particular state in the country however a large portion of number plates are written in English language (legally all plates are required to be in modern Hindu-Arabic numerals with Latin letters). This is very vital in recognizing the number plates, extraction of number plate characters, segmenting the characters because of some diversity. In this paper we present a work on extraction of number plates, segmentation and recognition of number plates in the domain of English language. Prewitt filter technology is used for extracting the number plate thresholding and for segmentation of connected component analysis are used. For recognizing the characters, neural network, k-nearest neighbor and decision tree classifiers are used. The recognition rate of neural network is 96.1%, k-nearest neighbor is 95.55% and decision tree is 91.38% respectively which is acceptable for future research in this direction.",60113205,"Chitkara University, Punjab",Rajpura,India,['1700'],21.5,0.09406349206349204,0.2804603174603175,1,0.06584362139917696,0.0411522633744856,0.2869198312236287
1012,1036,1036,CORRELATION of UAV-BASED MULTISPECTRAL VEGETATION INDICES and LEAF COLOR CHART OBSERVATIONS for NITROGEN CONCENTRATION ASSESSMENT on RICE CROPS,"Fertilizer application is a crucial farming operation for regulating crop health thus crop yield. Optimal fertilizing doubles agricultural production subsequently raising farmers' income, food security and economic agriproducts. To optimize the application of fertilizers, initial monitoring of the current nutrient status of the crops is required. This research will focus on Nitrogen (N), the most extensive fertilizer nutrient in crop cultivation. Conventional N monitoring involves the use of Leaf Color Charts (LCC) wherein leaf color intensity is associated with the N content of the crops. Despite its ability to quantify the optimal amount of needed fertilizers, the LCC method requires extensive on-site labor and lacks accuracy. This study developed a method that incorporates capabilities of Unmanned Aerial Vehicles (UAVs) equipped with a multispectral sensor in N monitoring specifically in rice crops, a major agricultural product in the Philippines. In situ N level information collected through LCC was correlated with remote sensing data, particularly vegetation indices (VIs) extracted from UAV multispectral imagery of a rice plantation in San Rafael, Bulacan. Several VIs sensitive to crop N content were tested to determine which has the highest correlation with the LCC data. Through Pearson correlation and regression analysis, NDVIRed Edge was found to be the most strongly correlated with LCC data suggesting its potential in mapping variability in fertilizer requirements. An equation modelling LCC observations and NDVIRed Edge values that estimates the N levels of an entire rice plantation was generated along with the N concentration map of the study area.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.54545454545455,0.09577067669172933,0.4350250626566417,1,0.10071942446043165,0.08992805755395683,0.35507246376811596
1013,1037,1037,Memory module insertion model using torque limit function," All rights reserved.Since the use of the 64-bit based operating system has been expanded recently, more memories have been produced. In this circumstance, memory test among memory production processes has been of importance. For memory test, it is required to insert a memory in a socket. At this time, the memory appearance is damaged often. Most memory test handlers control a memory position. For this reason, if memory position data is entered incorrectly, such a handler can impose too much force on the memory appearance and thereby can raise the risk of appearance damage. Therefore, this study proposes the method of imposing a proper degree of force with the use of torque limit function when a servo motor makes position control, rather than torque control.In case of servo motor drive, it is possible to use the torque limit function for position control. Usually, in the program for servo driver, it is required to enter a torque limit value. In this study, with the use of RS485 communication, it is possible to send a command to a particular address of servo drive and control a torque limit value in real time. Memory test is important in memory production processes. A memory test handler plays an essential role in the test. A memory needs to be move to a position by a servo motor in a test. Sensors are already used to check if the equipment moves accurately and if a product is in a right position. If it is possible to impose a proper degree of force on a servo motor, the damage rates of memory products and sockets can be reduced. Therefore, production life can be lengthened and workers’ safety can be increased. The program controlling a torque limit value on the basis of the model proposed in this study was applied. As a result, a servo driver changed a torque limit value normally. When the limit value was very low at the time of inserting a memory in a socket, the memory was not inserted in the socket and thereby the memory testfailed. When a normal torque value was entered, the memory was inserted in the socket well and thereby the memory test was conducted normally. In the future, it will be necessary to make a change while test equipment is in operation, and to lower a torque limit value to prevent collision with a worker when the door of test equipment is opened.",60103616,Kongju National University,Gongju,South Korea,['1700'],20.3,0.12965367965367966,0.5326082251082251,0,0.11086474501108648,0.0066518847006651885,0.19730941704035873
1014,1038,1038,Medical image classification: A comparison of various handcrafted features,"This paper compares different feature extraction techniques exploited by various researchers for medical image classification and retrieval. They are categorized into three groups; (i) feature extraction techniques used for shape, (ii) feature extraction techniques used for texture and (iii) local patch based representation such as bag of visual words. The main aim of this work is to determine the capabilities and the challenges of medical images handcrafted feature extraction techniques as well as to see how best to improve the efficiency and accuracy of medical image classification and retrieval. It focused centrally on the analysis of the most commonly used shape and texture feature extraction techniques applied on medical images. Bag of visual words which is a type of local patch based method was also analysed. The limitations of these techniques are discussed as presented in the paper reviewed. We summarized with some conclusions and a recommendation for future exploits.",60033125,University of Leicester,Leicester,United Kingdom,['1706'],21.428571428571427,0.0803921568627451,0.2122549019607843,1,0.11515151515151516,0.006060606060606061,0.296969696969697
1015,1039,1039,CHARACTERIZATION of SPRING AIR POLLUTION of Beijing in 2019 USING ACTIVE and PASSIVE REMOTE SENSING INSTRUMENTS,"As the capital of China, the Beijing area needs to be paid special attention to its air quality. We used active remote sensing instrument (ground-based lidar), combined with passive remote sensing instrument (VIIRS onboard the NPP spacecraft), to study the serious pollution event over Beijing in spring of 2019. At the same time, the ground-based particulate matter (PM) data and the meteorological element data were analyzed. It is found that the ratio of concentrations of PM2.5 to PM10 is very large during the pollution period. The mean value of ratio is 0.75464, indicated it is fine particulate matter pollution. The Range correction signal (RCS) of lidar is very large in the layer below 0.5 km. But the volume depolarization ratio (VDR) is much less than 0.05. It indicated it is anthropogenic urban aerosols. The change in the aerosol optical depth (AOD) of VIIRS during pollution is consistent with the change in optical properties observed by lidar. The backward trajectory model of HYSPLIT shows that the pollutant came from the Hebei area where industrial pollution is serious, and the local meteorological conditions in Beijing are conducive to the continuous accumulation of pollutants. This work can deepen the understanding of the mechanism of haze formation and can help and support pollution prevention work.",60028904,Anhui Institute of Optics and Fine Mechanics,Hefei,China,['1710'],19.181818181818183,0.006785714285714286,0.37654761904761896,1,0.0778688524590164,0.06967213114754098,0.31666666666666665
1016,1040,1040,Axiomatization and computability of a variant of iteration-free PDL with fork,"We devote this paper to the axiomatization and the computability of PDL0 Δ, a variant of iteration-free PDL with fork. Concerning the axiomatization, our results are based on the following: although the program operation of fork is not modally definable in the ordinary language of PDL, it becomes definable in a modal language strengthened by the introduction of propositional quantifiers. Instead of using axioms to define the program operation of fork in the language of PDL enlarged with propositional quantifiers, we add an unorthodox rule of proof that makes the canonical model standard for the program operation of fork and we use large programs for the proof of the Truth Lemma. Concerning the computability, we prove by a selection procedure that PDL0 Δ has a strong finite property, hence is decidable.",60102124,Université Fédérale Toulouse Midi-Pyrénées,Toulouse,France,"['1712', '1703']",32.75,0.07952380952380951,0.35238095238095235,1,0.09027777777777778,0.05555555555555555,0.23943661971830985
1017,1041,1041,Multi user detection using fuzzy logic empowered adaptive back propagation neural network," All rights reserved.In Wireless communication, Multiple Input and Multiple Output (MIMO) systems have always been quite popular. Multicarrier systems are established along with different techniques of space-time coding to accomplish the demands of these systems. One of the most popular techniques is Multi-Carrier Code Division Multiple Access (MC-CDMA) with Alamouti's Space-Time Block Codes (STBC). This article, proposed the Fuzzy Logic empowered Adaptive Back Propagation Neural Network (FLeABPNN) based Multi User Detection (MUD) system, which is used to determine the receiver weights of MC-CDMA with the scheme of two variations. The proposed FLeABPNN approach takes advantage of a neuro-fuzzy hybrid system which conglomerates the competences of both fuzzy logic and neural networks for multi-user detection. It is observed that due to the fuzzy logic-based learning rate, proposed FLeABPNN based receiver without relationship & with relationship achieved the 3.04 x 10-06 and 2.05 x 10""06 Bit Error Rate (BER) respectively. The proposed FLeABPNN based receiver gives fast convergence rate & low BER as compared to other suboptimal published techniques like GA & LMS. It also observed that the Computational Complexity of the proposed FLeABPNN based MC-CDMA receiver is less then LMS based receiver up to 18 users, but higher than GA based receiver.",60159382,Lahore Garrison University,Lahore,Pakistan,"['1712', '1708', '1702']",25.25,0.11555555555555555,0.3477777777777778,0,0.108,0.188,0.5283842794759825
1018,1042,1042,Isolation and characterization of sudanese yeast strains for bread making,"We have isolated a thermotolerant yeast strains from different food sources, control, stra wberry, tomato, grape, tomato and cucumber using selective medium Sabouraud's Dextro se Agar (SDA). Differential testes were applied including morphological, physiological, c ultural and biochemical characteristics, which facilitate the opportunity for identification of the yeast. The isolated yeast strains from control (Saf instant), strawberry, tomato, gua va and cucumber were identified as S. cerevisiae, S. dairnensis S. unisporus S. kluyeri and S. exigus. The S. cerevisiae were assessed for their temperature tolerance and maltose ut ilization capacity for production of bakery yeasts.",60071741,Omdurman Islamic University,Omdurman,Sudan,['1700'],9.5,0.0,0.6333333333333333,1,0.08620689655172414,0.20689655172413793,0.46551724137931033
1019,1043,1043,Ad-hoc wireless network optimization through OPNET simulation model,"The paper presents the results of a detailed packet-level simulation comparing three multi-hop wireless ad hoc network routing protocols under the load of different probability distributions, that cover a range of design choices having different protocol viz. AODV,OLSR and TORA. We have extended the OPNET network simulator to accurately model the MAC and physical-layer behavior of the IEEE 802.11 wireless LAN standard, including a realistic wireless transmission channel model. Simulation of 100 mobile nodes has been carried out and the performance optimization is determined.",60031475,Savitribai Phule Pune University,Pune MH,India,['1700'],21.0,0.16111111111111112,0.4861111111111112,1,0.10204081632653061,0.061224489795918366,0.358695652173913
1020,1044,1044,An analytical model of economic inequality in the Russian regions and its correlation with the global trend in the digital economy,"The aim of the work is the correlation and regression modeling of the dependence of the quintile coefficient of funds (the ratio of income of the 20% group of the richest population to the income of the 20% group of the poorest) on gross domestic product per capita in various regions of Russia in the considered economic units. Based on the simulation results, an analysis of world trends of the studied dependence is carried out and their comparison with Russian trends in the development of the digital economy. As a result of the analysis, a number of reasons for the inconsistency of Russia's indicators with global trends in socio-economic development and measures that could improve the situation are considered. For research, the method of correlation and regression analysis was chosen, in which regression was used to assess global trends according to the International Monetary Fund, and for the direct analysis of the data obtained, the correlation dependence of the studied phenomena was used. As a result, a number of measures were proposed to improve the socio-economic condition of the Russian regions, thanks to which the conditions for sustainable balanced development will be formulated for the regions. In addition, the article discusses a number of problems of modern public administration in Russia. The consequences in the socioeconomic situation to which the management strategy has led are analyzed. Measures to reduce social aggravation are designed primarily to create sufficient domestic production, which will be able to provide economic growth of the Russian Federation in the future.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",31.75,0.0873015873015873,0.16111111111111112,1,0.09252669039145907,0.028469750889679714,0.21299638989169675
1021,1045,1045,TOPOPHILIA-EXPOSURE CENTRAL SPACE CONCEPT MODEL,"This study proposes how a hexagon object (rather than a perfect circle) is a better representation of a data bin to visualize weighted spatial information, in analysing location (space center), and sorted local knowledge on topophilia-exposure'. This approach which depicts the topographic features sorted in a tessellated bin, correlated with the origin (space center), and geographic knowledge on love of a place (tessellated space), was sought to understand the relationships of topo'(topography), philia' (love of), and exposure data, sorted in a hexagonal lattice shaped cell or bin as spatial objects, where each hexagon has an area of 100 hectares (tessellated bin mapping unit) at a 1 kilometer continuous interval between centroids (central space of hexagon). The topophilia-exposure' central space concept model is designed to look at the Phila' factors influencing selected exposed residents situated in spaces at risk. This paper shows the effect of Philia' elements in the exposed sample Barangays (villages) in Daraga, and Guinobatan towns, Albay, Philippines. These factors dissuade residents from permanently relocating to safer areas, despite the obvious risks involved with staying. Undesired development and sprawling in vulnerable landscapes and danger zones make reducing disaster risk difficult to accomplish; and relocation is often the required option for some areas. Undoubtedly, the factors of Topophilia complicate even the most logical and scientific options for disaster risk reduction and mitigation. This paper finally concludes that the topophilia-exposure model is a model that reflects the phenomena of disaster risk, Exposure complicated by the ""love of land"" will prevail, and may increase; surely causing complexities in Disaster Risk Reduction and Management.",60104964,Bicol University,Legazpi,Philippines,['1710'],32.625,0.14166666666666666,0.5354938271604939,1,0.12302839116719243,0.07255520504731862,0.3535031847133758
1022,1046,1046,A combined local deep-feature alignment and analytic gabor feed forward network for face recognition,"This paper combined an unsupervised framework called as Local Deep-Feature Alignment (LDFA) for dimension reduction and Analytic Gabor Feedforward Network (AGFN) for efficient face recognition. An affine transformation is exploited for aligning the local deep features of each neighborhood with the global features. A new data sample is mapped into the low-dimensional subspace. The Stacked Contractive Auto-Encoder (SCAE) maintains the locality characteristics in the neighborhood. Regularization term of each SCAE facilitates estimation of parameters from a neighborhood that does not contain more data. The difficulty in robust feature learning is reduced by minimizing the variations of the local embedding function due to the data similarity among each neighborhood. As the local features are learned from minimum data in a neighborhood, the LDFA method yields better performance. The AGFN works directly on the input raw face images and generates Gabor features at the hidden layer. Several sets of features obtained at different orientations and scales are combined. The proposed method achieves high recognition accuracy, true positive, accuracy and minimum execution time and false positive than the existing face recognition techniques.",60013041,Bharathiar University,Coimbatore,India,['1700'],17.9,0.06392365967365966,0.34526631701631705,1,0.09803921568627451,0.08333333333333333,0.3383838383838384
1023,1047,1047,On consistent criteria of hypotheses testing for non-separable complete metric space,"In this paper, we define consistent criteria of hypotheses testing for a non-separable complete metric space, such that the probability of any kind of error is zero for a given criterion. The necessary and sufficient conditions for the existence of such criteria are given.",60071909,Ivane Javakhishvili Tbilisi State University,Tbilisi,Georgia,['1706'],22.0,0.15833333333333333,0.5916666666666667,1,0.08,0.0,0.14583333333333334
1024,1048,1048,On the approximate controllability of some semilinear partial functional integrodifferential equations with unbounded delay,"This work concerns the study of the approximate controllability for some nonlinear partial functional integrodifferential equation with infinite delay arising in the modelling of materials with memory, in the framework of Hilbert spaces. We give sufficient conditions that ensure the approximate controllability of the system by supposing that its linear undelayed part is approximately controllable, admits a resolvent operator in the sense of Grimmer, and by making use of the measure of noncompactness and the Monch fixed-point Theorem. As a result, we obtain a generalization of several important results in the literature, without assuming the compactness of the resolvent operator. An example of applications is given for illustration.",60070926,University of Buea,Buea,Cameroon,['1710'],27.0,-0.15,0.5166666666666667,1,0.10084033613445378,0.03361344537815126,0.23076923076923078
1025,1049,1049,GEOVISUAL ANALYTICS on the VERIFICATION of the PAGASA OPERATIONAL NUMERICAL WEATHER PREDICTION MODEL RAINFALL FORECAST,"Assessment of NWP model performance is an integral part of operational forecasting as well as in research and development. Understanding the bias propagation of an NWP model and how it propagates across space can provide more insight in determining underlying causes and weaknesses not easily determined in traditional methods. The study aims to introduce the integration of the spatial distribution of error in interpreting model verification results by assessing how well the operational numerical weather prediction system of PAGASA captures the country's weather pattern in each of its climate type. It also discusses improvements in model performance throughout the time-frame of analysis. Error propagation patterns were identified using Geovisual Analytics to allow comparison of verification scores among individual stations. The study concluded that a major update in the physics parameterization of the model in 2016 and continued minor updates in the following years, surface precipitation forecasts greatly improved from an average RMSE of 9.3, MAE of 3.2 and Bias of 1.36 in 2015 to an RMSE of 7.9, MAE of 2.5 and bias of-0.63 in 2018.",113685700,Geophysical and Astronomical Services Administration,Quezon City,Philippines,['1710'],29.33333333333333,0.1050925925925926,0.4925925925925926,1,0.10638297872340426,0.0425531914893617,0.3064516129032258
1026,1050,1050,LONG TEMPORAL ANALYSIS of the MODIS AEROSOL PRODUCT over HUAIHAI ECONOMIC REGION in CHINA,"The Huaihai Economic Region (HER, 32.5-36.5°N, 114-121°E) with a land area of 178,000 km2, which contains 20 cities, is one of the earliest regional economic cooperative organizations in China. The huge population (100 million, about 7% of the China's population), local heavy industries, chemical enterprises and vehicle emissions have resulted in serious air pollution. In this paper, a long-term aerosol optical depth (AOD) data set from 2000 to 2018 over HER with 10 km spatial resolution has been produced and analyzed from the latest version of MODIS (MODerate resolution Imaging Spectroradiometer) aerosol products. Validation results show that MODIS AOD has a strong correlation relationship (r Combining double low line 0.94, slope Combining double low line 0.92) with Aeronet Robotic Network (AERONET) over HER. The seasonal average AOD maps indicate that the high AOD values mainly occurred with a banding distribution from southeastern to northwestern HER, with AODs larger in summer and spring than in fall and winter. Temporally, the monthly average AOD has increased since 2000 and reached the highest level in 2011 (+0.02/year); then it has obviously declined from 2012 to 2018 (0.05/year), owing to strict air pollution control implemented since 2012. In general, the annual average AOD over HER is 0.71 for the past nearly 20 years, and in 2018, the annual average AOD firstly lower than that in 2000. The study suggests that there has been a slightly improvement in air quality over HER and long-term and sustainable efforts should be made.",60004691,Jiangsu Normal University,Xuzhou,China,['1710'],30.625,0.030000000000000013,0.3971604938271605,1,0.0594059405940594,0.07920792079207921,0.44947735191637633
1027,1051,1051,Development and implementation of innovative educational modules on architectural photogrammetry for bachelor's degree curricula in architecture,"Modern specialists in the field of architecture work exclusively in three-dimensional space. At the same time, their training completely ignores the state-of-the-art technologies associated with obtaining three-dimensional models of engineering structures. In such circumstances, the connections between the three key participants in the design and construction of engineering structures, namely architects, builders, and surveyors are broken. The main technology that allows obtaining three-dimensional models is photogrammetry. The purpose of the presented article is to determine the subject matter of close-range photogrammetry in solving architectural design problems. Based on certain architectural tasks, educational modules for the discipline of architectural photogrammetry of the bachelor educational level were developed. The peculiarity of the proposed program is that it is designed in such a way that it allows using the whole complex of the modern achievements in the field of automated image processing and the specifics of setting and solving architectural problems. At the same time, this program covers such modern technologies and concepts as UAV photogrammetry, digital photogrammetry, photogrammetric scanning, BIM, GIS, etc. Such an approach allows students without problems to learn several special knowledge, which is owned by surveyors and photogrammetrists. The approximate content of the course of architectural photogrammetry for bachelor students is presented.",60103718,Kyiv National University of Construction and Architecture,Kiev,Ukraine,['1710'],20.3,0.04047619047619048,0.3733134920634921,1,0.09583333333333334,0.0125,0.3495575221238938
1028,1052,1052,On volumes of matrix ball of third type and generalized Lie balls Об объемах матричного шара третьего типа и обобщенных шаров Ли," All rights reserved.The third-type matrix ball and the generalized Lie ball that are connected with classical domains play a crucial role in the theory of several complex variable functions. In this paper the volumes of the third type matrix ball and the generalized Lie ball are calculated. The full volumes of these domains are necessary for finding kernels of integral formulas for these domains (kernels of Bergman, Cauchy-Szegö, Poisson etc.). In addition, it is used for the integral representation of a function holomorphic on these domains, in the mean value theorem and other important concepts. The results obtained in this article are the general case of results of Hua Lo-ken and his results in particular cases coincides with our results.",60071663,Tashkent State Technical University,Tashkent,Uzbekistan,['1700'],24.2,0.019097222222222224,0.4871527777777778,0,0.07092198581560284,0.07092198581560284,0.3282442748091603
1029,1053,1053,Approximate fixed points via completion,"It was proved by S. Tijs, A. Torre and R. Branzei in [1, Theorem 3.1] that every single-valued contraction from a metric space into itself has an ε-fixed point for every ε > 0. In this paper, we state this result for setvalued mappings and we give a new proof of it by using the concept of completion.",60088882,"Faculté des Sciences Tétouan, Universite Abdelmalek Essaadi",Tetuan,Morocco,['1710'],11.6,0.13636363636363635,0.4545454545454545,1,0.10144927536231885,0.10144927536231885,0.4153846153846154
1030,1054,1054,Perfect essential graphs,"Let R be a commutative ring with identity, and let Z(R) be the set of zero-divisors of R. Let EG(R) be a simple undirected graph associated with R whose vertex set is the set of all nonzero zero-divisors of R and and two distinct vertices x;y in this graph are joined by an edge if and only if AnnR(xy) is an essential ideal. A perfect graph is a graph in which the chromatic number of every induced subgraph equals the size of the largest clique of that subgraph. In this paper, we characterize all Artinian rings whose EG(R) is perfect.",60016248,K. N. Toosi University of Technology,Tehran,Iran,['1710'],25.0,0.4571428571428572,0.7081632653061225,1,0.061946902654867256,0.05309734513274336,0.2605042016806723
1031,1055,1055,Efficiently combining tweet content and social interactionsto enhance stress recognition performance,"Psychological stress will convert into adanger to person’s health at present days. With their works lot off persons are feeling stressed. Although the factthat stress itself is non-clinical and routine in life, unreasonable an dintermin able stress can besome what destructive to person’s physical and psychological happiness. Ther iseofweb-based socialnet working is trans forming people, justas studyin healthcare and happiness. With the progresss of inter personal companies like Twitter and Facebook, these are rising number of persons are happy to share their every day occasions. Emotional stressrec ognitionisi dentified withan event of sentiment study by ([1] Alec Go, Twitter Sentiment Classification using Distant Supervision) When westudy on tweet-level sentiment recognition in inter personal organizations is finished. Through Computer-supported recognition, analysis, we are proposing a half breed model which joins the FGM with a CNN where we can distinguish thegeneral population who are under stress dependent on their tweets.",60109586,Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering &amp; Technology,Hyderabad,India,['1700'],21.142857142857142,0.1309523809523809,0.3381802721088435,1,0.10285714285714286,0.09714285714285714,0.40828402366863903
1032,1056,1056,Unsupervised learning approach for identifying sub-genres in music scores," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Detecting the genre of a piece of music and whether two pieces of music are similar are subjective matters since audiences may perceive the same music differently. While the problem of the automatic detection of music genres has been studied extensively, it is still an open problem, especially when looking at sub-genres of traditional music. It can however be useful for example to discover similarities between multiple collections, to study whether a particular genre has resemblances with other genres, and to trace the origin and evolution of a particular genre. In this paper, we focus on traditional Irish music and the features and algorithms that can be used for analyzing such music through structured data (music scores). More precisely, audio, spectral, and statistical features of music scores are extracted to be used as input to unsupervised clustering methods to better understand how those features and methods can help identifying sub-genres in a music collection, and support “genre-driven” similarity-based retrieval of music in such a collection. We in particular show which features best support such tasks, and how a slight modification of the K-Means algorithm to introduce feature weights achieves good performance. We also discuss the possible use of those results, especially through a demonstration application for music information retrieval in Irish traditional music collections.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],32.285714285714285,0.13694444444444445,0.465,0,0.11196911196911197,0.02702702702702703,0.288
1033,1057,1057,Preface: The 27th AIAI irish conference on artificial intelligence and cognitive science (AICS 2019)," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The 27th AIAI Irish Conference on Artificial Intelligence and Cognitive Science(AICS) is hosted by NUI Galway on behalf of AIAI, the Artificial Intelligence Association of Ireland, on the 5th and 6th of December 2019. AICS 2019 features 23 presentations, 24 posters, and 2 keynote presentations. Papers cover topics including: Deep Learning and AI techniques for Sustainable Agricultural Practices, Human Activity Recognition, Traffic Management, Skin Cancer Classification, Quantification of Knee Osteoarthritis Severity, Epidemic Spread, Music Scores, and AI Social and Ethical Considerations.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],31.0,-0.051851851851851836,0.46296296296296297,0,0.045454545454545456,0.36363636363636365,0.7787610619469026
1034,1058,1058,A (co)algebraic theory of succinct automata,"The classical subset construction for non-deterministic automata can be generalized to other side-effects captured by a monad. The key insight is that both the state space of the determinized automaton and its semantics—languages over an alphabet—have a common algebraic structure: they are Eilenberg-Moore algebras for the powersetgen monad. In this paper we study the reverse question to determinization. We will present a construction to associate succinct automata to languages based on different algebraic structures. For instance, for classical regular languages the construction will transform a deterministic automaton into a non-deterministic one, where the states represent the join-irreducibles of the language accepted by a (potentially) larger deterministic automaton. Other examples will yield alternating automata, automata with symmetries, CABA-structured automata, and weighted automata.",60022148,UCL,London,United Kingdom,"['1712', '1703']",20.166666666666668,-0.055000000000000014,0.3426923076923077,1,0.11920529801324503,0.026490066225165563,0.2740740740740741
1035,1059,1059,Cross-X learning for fine-grained visual categorization,"Recognizing objects from subcategories with very subtle differences remains a challenging task due to the large intra-class and small inter-class variation. Recent work tackles this problem in a weakly-supervised manner: Object parts are first detected and the corresponding part-specific features are extracted for fine-grained classification. However, these methods typically treat the part-specific features of each image in isolation while neglecting their relationships between different images. In this paper, we propose Cross-X learning, a simple yet effective approach that exploits the relationships between different images and between different network layers for robust multi-scale feature learning. Our approach involves two novel components: (i) a cross-category cross-semantic regularizer that guides the extracted features to represent semantic parts and, (ii) a cross-layer regularizer that improves the robustness of multi-scale features by matching the prediction distribution across multiple layers. Our approach can be easily trained end-to-end and is scalable to large datasets like NABirds. We empirically analyze the contributions of different components of our approach and demonstrate its robustness, effectiveness and state-of-the-art performance on five benchmark datasets. Code is available at url{https://github.com/cswluo/CrossX}.",60032203,South China Agricultural University,Guangzhou,China,"['1712', '1707']",22.125,0.049345238095238095,0.512797619047619,1,0.09361702127659574,0.01276595744680851,0.40298507462686567
1036,1060,1060,SCCF Parameter and Similarity Measure Optimization and Evaluation,"Neighborhood-based Collaborative Filtering (CF) is one of the most successful and widely used recommendation approaches; however, it suffers from major flaws especially under sparse environments. Traditional similarity measures used by neighborhood-based CF to find similar users or items are not suitable in sparse datasets. Sparse Subspace Clustering and common liking rate in CF (SCCF), a recently published research, proposed a tunable similarity measure oriented towards sparse datasets; however, its performance can be maximized and requires further analysis and investigation. In this paper, we propose and evaluate the performance of a new tuning mechanism, using the Mean Absolute Error (MAE) and F1-Measure metrics, in order to show that the SCCF similarity can be radically enhanced and thus increasing its overall efficiency. Moreover, the SCCF similarity measure was tested against several other measures, targeted especially at sparse datasets, and the results show how the effectiveness of a measure significantly varies with the dataset structure and properties, and that one measure cannot be considered as better than the other when compared with a small selection of other measures.",60118388,Université Antonine,Baabda,Lebanon,['1700'],35.0,0.012973484848484844,0.5475852272727273,1,0.12745098039215685,0.07352941176470588,0.34
1037,1061,1061,Verification and control for probabilistic hybrid automata with finite bisimulations,"A hybrid automaton is a formal model for a system characterised by a combination of discrete and continuous components. Probabilistic hybrid automata generalise hybrid automata with the possibility of representing random behaviour of the discrete components of the system, in addition to nondeterministic choice regarding aspects such as time durations between mode switches and gradients of continuous flows. Two standard problems for probabilistic hybrid automata are verification and control: verification concerns the existence of a resolution of nondeterminism such that the resulting probability of an ω-regular property exceeds some bound; control concerns the existence of a resolution of the controllable nondeterminism, however the uncontrollable nondeterminism of the environment of the system is resolved, such that the probability of an ω-regular property exceeds some bound. While simple verification and control problems for (probabilistic) hybrid automata are in general undecidable, previous work has defined various subclasses for which the problems are decidable. In this paper, we generalise previous results by showing how bisimulation-based finite abstractions of non-probabilistic hybrid automata can be lifted to the setting of probabilistic hybrid automata. We apply these results to the subclass of probabilistic rectangular hybrid automata in a semantics in which discrete control transitions can occur only at integer points in time. These results allow us to show that, for this class of probabilistic hybrid automaton, the verification problems and control problems are decidable.",60012259,Università degli Studi di Torino,Turin,Italy,"['1712', '1703']",32.42857142857143,-0.0712121212121212,0.4264069264069264,1,0.09090909090909091,0.015810276679841896,0.24897959183673468
1038,1062,1062,Research data management in supporting knowledge sharing among univesity researchers,"Research data management is an important concern for institutions and several platforms to support data deposits have emerged. Thus, many research institutions have established or plan to establish research data curation services as part of their Institutional Repositories (IRs). In this paper we start by viewing the current practices in the data management workflow in one of public university in Malaysia. A survey was conducted using questionnaire for data collection among staff, researcher and postgraduate students from Public University in Malaysia. The finding shows most respondents have awareness in research data management. The finding also provided useful information to a better understanding regarding research data management. Limitation and suggestion for future research are discussed.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],16.285714285714285,0.22000000000000006,0.3158333333333333,1,0.104,0.056,0.296
1039,1063,1063,Impact of different levels of difficulty on immersion in video games," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Twelve participants played three levels of Tetris that varied by difficulty and immersion was measured after each level with a survey. The levels corresponded to the scenarios: [skill of the player > challenge; skill = challenge; skill < challenge]. Flow levels of participants were measured as well. The question asked was whether different difficulties would influence how immersed players would be, hypothesizing that players would be more immersed when cognitively overloaded than when facing a challenge adapted to their skill. Results showed no significant difference between the different conditions but pointed towards less immersion when the players faced a challenge inferior to their skill.",60005141,University College Dublin,Dublin,Ireland,['1700'],23.2,-0.01302083333333333,0.5802083333333333,0,0.1328125,0.0625,0.3875968992248062
1040,1064,1064,"EVALUATING the SPATIAL-SEASONAL VARIATION, HETEROGENEITY and DISTRIBUTION of URBAN THERMAL ENVIRONMENT: CASE STUDY of NANJING, China","Urban thermal environment (UTE), as a important parameter in urban ecosystem, strongly and directly linking to urban development and human health. In recently decades, rapid urbanization and population development resulted in serious urban thermal environment problem particularly the urban heat island (UHI) phenomenon. Today, it's urgent to control and curb urban thermal environment based on the UTE's spatial-temporal characteristics, in addition, the seasonality of UTE lacked in-depth understanding, which is also a significant question in UTE management, a better understanding the UTE will help human improve governing efficiency and effect. Thus, in our study, we investigated the spatial-seasonal variation and distribution of UTE by statistic analysis, spatial index analysis and landscape metric analysis. We found that: there has a significant spatial and temporal differences on UTE under different seasons, the UHI intensity and mean LST showing a significant difference and stability, additionally, ""heat island"" of urban showing a cluster trend in urban space particularly in high UHI intensity seasons. These results extend our understanding on the spatial-seasonal variation, heterogeneity and distribution of UTE and which can provide very significant reference and information for urban decision-makers to govern UTE.",60024045,Nanjing Agricultural University,Nanjing,China,['1710'],31.33333333333333,0.10906666666666666,0.3814333333333333,1,0.08771929824561403,0.06578947368421052,0.2889908256880734
1041,1065,1065,SEPARABILITY of TRANSPLANTED and DIRECT SEEDED RICE USING MULTI-TEMPORAL SENTINEL-1A DATA,"Occurrence of pests and diseases are influenced by several factors including weather, landscape and field-level factors such as crop management practices including crop establishment method. In this paper, we adopted and applied a method using Sentinel-1A (S-1A) Synthetic Aperture Radar (SAR) intensity to discriminate between rice fields that are transplanted and direct seeded to come up with a robust method for automated classification of crop establishment method. Multi-temporal S-1A C-band dual polarization images at 20m resolution covering the wet cropping season over four provinces in the Philippines were acquired from March to November 2018. Field measurements, observations and interviews were conducted on 186 sample fields and mean backscatter values for each of the sampled fields were generated from S-1A data acquired during the season. The reported dates of land preparation and estimated dates of crop growth stages were matched with the corresponding SAR acquisition dates. We used the Mann-Whitney U test to identify growth stages for which there are significant differences in backscatter values between transplanted and direct seeded rice. The results are generally consistent with the findings of a previous study conducted in one province in the Philippines in the dry season of 2017. We found, however, some inconsistencies in terms of the polarization where the significant differences were observed. These findings demonstrate the possibility of discriminating transplanted from direct seeded rice using SAR temporal data but suggests further fine tuning in the methodology is needed for different locations and seasons.",60071480,Philippine Rice Research Institute,Nueva Ecija,Philippines,['1710'],26.88888888888889,0.06067708333333334,0.4471354166666666,1,0.11524163568773234,0.055762081784386616,0.3576923076923077
1042,1066,1066,Digital energy performance signature extensible markup language (DEPSxml): Towards a new characterization framework for sharing simulation and measured data on building design and energy performance,"This paper introduces a new filetype that has the potential to improve data analytics in the building sector. The aim of the paper is to explore the general logic and hierarchy of the file type, explore the mechanism in which it would transmit data, and define initial user groups and the process by which they would use the file and server system. The filetype utilizes a popular green building filetype (gbXML) as a base schema. The manner in which the base schema is expanded upon is explored in the paper to clarify how a live link to a building’s automation system and utility network may be established in an Extensible Markup Language (XML) file format. The last section of the paper contributes several potential uses for the new filetype that will be put into place during the beta phase.",60010365,The University of British Columbia,Vancouver,Canada,['1705'],27.8,-0.056993006993007,0.5519813519813519,1,0.11258278145695365,0.019867549668874173,0.19736842105263158
1043,1067,1067,"AN AEROSOL TYPE CLASSIFICATION METHOD BASED on REMOTE SENSING DATA in GUANGDONG, CHINA","This paper provides an aerosol classification method based on remote sensing data in Guangdong, China in year 2010 and 2011. Aerosol Optical Depth, Angstrom Exponent and Ultraviolet Aerosol Index, as important properties of aerosols, are introduced into classification. Data of these three aerosol properties are integrated to establish a 3-dimension dataset, and k-means clustering algorithm with Mahalanobis distance is used to find out four clusters of the dataset, which respectively represents four aerosol types of urban-industrial, dust, biomass burning and mixed type. Prior knowledge about the understanding of each aerosol type is involved to associate each cluster with aerosol type. Temporal variation of the aerosol properties shows similarities between these two years. The proportion of aerosol types in different cities of Guangdong Province is also calculated, and result shows that in most cities urban-industrial aerosols takes the largest proportion while the mixed type aerosols takes the second place. Classification results prove that k-means cluster algorithm with Mahalanobis distance is a brief and efficient method for aerosol classification.",60082183,Zhongkai University of Agriculture and Engineering,Guangzhou,China,['1710'],23.857142857142854,0.08,0.32333333333333336,1,0.08376963350785341,0.12041884816753927,0.36065573770491804
1044,1068,1068,Social-Aware and Sequential Embedding for Cold-Start Recommendation,"Cold-start problem and sparse, long-tailed datasets are inevitable issues in recommendation systems. The solution to these problems is not to predict them in isolation, but to exploit the additional information from relevant activities. Hence recent sequential actions and social relationships of the user can be used to improve the effectiveness of the model. In this paper, we develop a novel approach called Socially-aware and sequential embedding (SASE) to fill the gap by leveraging convolutional filters to capture the sequential pattern and learning the individual social features from the social networks simultaneously. The core idea is to determine which item is relevant to the user’s historical actions and seek who is the user’s intimate friend, then make predictions based on these signals. Experimental results on several real-world datasets verify the superiority of our approach compared with various state-of-the-art baselines when handling the cold-start issues.",60122052,Southwest University,Chongqing,China,['1700'],23.83333333333333,0.09230769230769233,0.3961538461538462,1,0.11560693641618497,0.005780346820809248,0.2830188679245283
1045,1069,1069,Identifying extra-terrestrial intelligence using machine learning," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Since the date of establishment of the SETI Institute, its scientists have used various approaches in their search for extra-terrestrial intelligence (SETI). A novel idea involved image categorisation techniques in classifying radio signals represented by 2D spectrograms. The dataset of simulated radio signals, created for classification purposes have been used in this work to train models based on neural network architectures. It is shown in this paper that combining three different models, trained on features obtained by various techniques, has a positive impact on model accuracy and performance. Features learned by a convolutional neural network (CNN), bottleneck features from existing models and manually extracted features from the spectrograms comprised the three feature sets used as training data for the combined model. It was also shown that combining different methods of spectrogram generation resulted in improving the accuracy of the final model.",60025059,Dublin City University,Dublin,Ireland,['1700'],25.5,0.09090909090909093,0.5931818181818183,0,0.13450292397660818,0.06432748538011696,0.38235294117647056
1046,1070,1070,Machine learning methods applied to building energy production and consumption prediction," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The utilization of renewable sources of energy is growing all over the world due to pressure for sustainable solutions. It brings benefits to the environment, but also adds complexity to the electricity grid, which faces energy balancing challenges caused by an intermittent production from this kind of generation. Having a good energy prediction is essential to avoid losses and improve the quality and efficiency of the energy systems. There are many machine learning (ML) methods that can be used in these predictions; however, every consumer is different and will behave in a distinct way. Therefore, the objective of this article is to compare the application of different ML methods, aiming to predict PV energy production and energy consumption for residential users. Four different ML methods were applied in a real dataset from the RESPOND project: Linear Regression, Decision Forest regression, Boosted Decision Tree Regression and Neural Network. After the simulation, the predicted values were compared against the real data, considering 150 days of measurement from two Irish houses. Overall, all the algorithms applied achieved mean errors below 14%, but the Boosted Decision Tree overperformed, with mean errors of 2.68% and 10% for energy consumption and energy production prediction, respectively.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],26.375,0.11842105263157895,0.4184210526315788,0,0.1,0.09583333333333334,0.3941908713692946
1047,1071,1071,RESEARCH on MICROPHYSICAL PROPERTIES of A VARIETY of NONSPHERICAL AEROSOL PARTICLES,"In order to study the environment or climate of an area, it is necessary to understand the composition of atmospheric aerosol particles, as well as microphysical properties, such as extinction cross section, scattering cross section, polarization degree, etc. For a long time, when calculating the microphysical properties of atmospheric aerosol particles, the aerosol particles are always be considered as spheres. Mie theory has been used to calculate the scattering properties of spherical particles with high accuracy. However, in reality, aerosol particles are not only spherical, they have complex composition and different shapes. The influence of non-spherical aerosol particles on atmospheric radiation, scattering and absorption cannot be ignored. Therefore, it is necessary to fully understand the micro-physical characteristics of non-spherical aerosol particles for fully understand the real atmospheric environment. Until now, T-Matrix method is one of the most effective and extensive methods to study the light scattering characteristics of non-sphericalrotationally symmetric aerosol particles. In this paper, the non-spherical aerosol particles extinction section, scattering cross section,the absorption cross section are calculated using T-Matrix method. The extinction, scattering, and the absorption properties arecalculated with variety of different types aerosol particles, and compared with the properties calculated by Mie scattering theory. Itlays a foundation for more accurate simulation of the microphysical properties of aerosol particles in real atmosphere.",60006422,Northwest University for Nationalities,Lanzhou,China,['1710'],21.4,0.10041666666666668,0.4086111111111111,1,0.07692307692307693,0.06538461538461539,0.3008130081300813
1048,1072,1072,Multi-view Locality Preserving Embedding with View Consistent Constraint for Dimension Reduction,"With the diversification of data sources, the multi-view data with multiple expressions have been appeared in various application scenarios. These multi-view data generally have high dimensions, large amounts and often lack of label information. Therefore, it is very important to learn multi-view data in an unsupervised way so as to analyze and excavate the potential valuable information. In this paper, we propose a multi-view locality preserving embedding algorithm with view similarity constraint for data dimension reduction. This algorithm not only preserves the local structure into low-dimensional space for each view, but also implements the similarity constraints between different views. On this basis, the algorithm looks for a joint embedding of low-dimensional subspace, so that the neighborhood among samples in original high-dimensional space can be maintained in the subspace, and the structures corresponding to different views are consistent with each other. This algorithm achieves good experimental results both in artificial data sets and multi-view data sets, which prove the correctness and feasibility of the algorithm.",60020258,Nanjing Normal University,Nanjing,China,['1700'],23.42857142857143,0.09672268907563024,0.5613865546218487,1,0.07653061224489796,0.01020408163265306,0.29444444444444445
1049,1073,1073,MULTI-TEMPORAL ANALYSIS of DENSE and SPARSE FORESTS' RADAR BACKSCATTER USING SENTINEL-1A COLLECTION in GOOGLE EARTH ENGINE,"Radar data has been historically expensive and complex to process. However, in this milieu of cloud-computing platforms and open-source datasets, radar data analysis has become convenient and can now be performed for more exploratory researches. This study aims to perform multi-temporal analysis of radar backscatter to characterize dense and sparse forest from Sentinel-1 images. The area of study are reforested sites under the National Greening Program (NGP) of the Philippines. Ground data were collected: (1) in 2019, from a 1.35 ha-site in Brgy. Calula, Ipil, Zamboanga Sibugay, (2) in 2019, from a 1.10 ha-site in Brgy. Cabatuanan, Basay, Negros Oriental, and (3) from PhilLiDAR 2-Project 3: FRExLS' 2.4 ha-validated site in Ubay, Bohol. SAR intensity values were derived from Sentinel-1 from Google Earth Engine, which is a cloud-based platform with a repository of satellite images and functionalities for data extraction and processing. The temporal variation in C-band radar backscatter from 2014 to 2018 were analyzed. The results show, for the whole period of analysis, that: in VH polarization, dense forest samples backscatter range from-11 to-18 dB in VH and-2 to-13 dB in VV; sparse forest samples range from-12 to-21 dB in VH and-7 to-14 dB in VV; ground samples range from-12 to-24 dB in VH and-6 to-15 dB in VV; and water samples range from-21 to-30 dB in VH and-11 to-26 dB in VV. Forest backscatter are expected to saturate over time, especially in dense forests. These variations are due to differences in forest species, landscape, environmental and climatic drivers, and phenomenon or interventions on the site.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.416666666666668,-0.13437500000000002,0.596875,1,0.05642633228840126,0.1755485893416928,0.5214521452145214
1050,1074,1074,Technology for determining strategic directions for the development of a regional transport and logistics system under digitalization,"The paper is concerned with the development of a regional transport and logistics system under digitalization. The paper proposes a technology for determining strategic directions for regional transport and logistics system (RTLS) development under digitalization which comprises methodological tools for analyzing the spatial structure of freight consumption and freight generation by all the participants in a transportation service system along with an algorithm and a guidance package for arranging modes for the information interaction of its participants under the control of the single information provider, and their transformation, making it possible to ensure product and material exchanges at different levels: regional, interregional and intercountry. The concepts and stipulations of this technology are considered, drawing on the properties of a transport and logistics system as an economic system along with such principles of information provision as the comprehensiveness, divisibility, interrelatedness, orderliness, integrability, complexity, emergent nature and structuredeness of its elements. The objective of the given study is to create a technology for determining strategic directions for RTLS development under digitalization. The study intends to broaden the RTLS research domain, which makes it possible to expand theoretical knowledge of the current trends in its operation in the frame of digitalization. The general scientific methods of inquiry such as observation, analysis, generalization were used to reach the stated objective. Pursuing strategic directions for the development of a transport and logistics system within the framework of the proposed projects will allow for establishing an efficient program/project management system for area development and eliminating regional economic growth limitations related to the lack of harmonization among the participants in transportation processes.",60085089,East Siberia State University of Technology and Management,Ulan-Ude,Russian Federation,"['1712', '1709', '1707', '1705']",37.857142857142854,0.027040816326530614,0.4153061224489796,1,0.09310344827586207,0.010344827586206896,0.21180555555555555
1051,1075,1075,Software Defect Prediction Using a Hybrid Model Based on Semantic Features Learned from the Source Code,"Software defect prediction has extensive applicability thus being a very active research area in Search-Based Software Engineering. A high proportion of the software defects are caused by violated couplings. In this paper, we investigate the relevance of semantic coupling in assessing the software proneness to defects. We propose a hybrid classification model combining Gradual Relational Association Rules with Artificial Neural Networks, which detects the defective software entities based on semantic features automatically learned from the source code. The experiments we have performed led to results that confirm the interplay between conceptual coupling and software defects proneness.",60024417,Universitatea Babes-Bolyai din Cluj-Napoca,Cluj Napoca,Romania,['1700'],19.2,-0.15333333333333332,0.6633333333333333,1,0.10476190476190476,0.09523809523809523,0.36893203883495146
1052,1076,1076,A unified framework for optimizing the performance of a kinetic façade,"A noble kinetic façade system, Oculi Kinetic Façade System (OKFS) was developed to balance solar heat gain, daylighting, and user satisfaction. The study focused on a dynamic control scheme that incorporates simulation data to determine optimal angles of the OKFS for given hours. This research considered daylighting and solar irradiance as the performance metrics. In order to reflect two metrics, we employed a min-max normalization method with a weighting factor in the proposed scheme. The weighting factor is determined by the performance of OKFS at the given time. The implementation of the control scheme is demonstrated via a case study, where simulation data was generated through the Grasshopper Diva 4.0. The result indicated that the optimal control of the rotational angle of OKFS can improve the daylight performance up to around 10%. It is expected that the findings from this study can contribute to developing a systematic optimization model of a kinetic façade system as well as an evaluation scheme for the performance of kinetic façade system.",60006951,The University of North Carolina at Charlotte,Charlotte,United States,['1705'],20.875,0.15,0.44166666666666665,1,0.11891891891891893,0.07567567567567568,0.2677595628415301
1053,1077,1077,An integrated urban planning and simulation method to enforce spatial resilience towards flooding hazards,"Urban development projects in flood-prone areas are usually complex tasks where failures can cause disastrous outcomes. To tackle this problem, we introduce a toolbox (Spatial Resilience Toolbox – Flooding, short: SRTF) to integrate flooding related aspects into the planning process. This, so called toolbox enables stakeholders to assess risks, evaluate designs and identify possible mitigations of flood-related causes within the planning software environment Rhinoceros 3D and Grasshopper. The paper presents a convenient approach to integrate flooding simulation and analysis at various scales and abstractions into the planning process. The toolbox conducts physically based simulations to give the user feedback about the current state of flooding resilience within an urban fabric. It is possible to evaluate existing structures, ongoing developments as well as future plans. The toolbox is designed to handle structures in a building scale as well as entire neighborhood developments or cities. Urban designers can optimize the spatial layout according to flood resilience in an early phase of the planning process. In this way, the toolbox can help to minimize the risk of flooding and simultaneously reduces the cost arising from the implementation and maintenance of drainage infrastructure.",60103936,Austrian Institute of Technology,Vienna,Austria,['1705'],21.0,-0.06000000000000001,0.3995238095238095,1,0.13744075829383887,0.03317535545023697,0.3140096618357488
1054,1078,1078,Integrated feature-based foreground object detection from video data," All rights reserved.The existing technique for segmenting the target object the user wants from various images mainly uses two-dimensional features, resulting in various limitations due to the lack of three-dimensional information.This paper proposes a technique for segmenting objects robustly by combining two-dimensional and three-dimensional features from stereoscopic images that are received for effective clustering. In the proposed method, a stereo matching algorithm is used to acquire the depth informationexpressing the distance between the target and the camera. Then, the depth feature and the color feature are effectively clustered to detect the target object corresponding to the foreground.Through the experiment, it can be visually found that the proposed method accurately separates objects from the video with the help of depth information. However, it is sometimes difficult to extract depth information correctly because stereo matching is performed incorrectly in areas with similar color values or poor textures. To measure the performance of the suggested target segmentation approach, we defined the measure of Root Mean Square Error (RMSE). As a measure of dealing with general and specific aspects of image quality, RMSE is utilized to evaluate the difference between measured and actual values. In addition, it was confirmed quantitatively that the conventional method attempts to segment the target object using only two-dimensional features, causing many errors, while the proposed method segments the target object more accurately than the conventional method by effectively clustering and using the distance information, which is a three-dimensional feature without using only two-dimensional features.The suggestedobjectextractionapproach is expected to be useda lot in the practical areas of image analysis and pattern recognition, such as target object tracking andvideo surveillance.",60011796,Anyang University,Anyang,South Korea,['1700'],38.57142857142857,0.07398233486943165,0.4807027649769586,0,0.12779552715654952,0.019169329073482427,0.2827586206896552
1055,1079,1079,Object Detection by Combining Deep Dilated Convolutions Network and Light-Weight Network,"In recent years, the performance of object detection algorithm has been improved continuously, and it has become an important direction in the field of computer vision. All the work in this paper will be based on a two-stage object detection algorithm. First, the dilated convolution network is added to the backbone network to form the Deep_Dilated Convolution Network (D_dNet), which improves the resolution of the feature map and the size of the receptive field. In addition, in order to obtain higher accuracy, the feature map of pretraining is compressed and a light-weight network is established. Finally, to further optimize the proposed two network models, this paper introduces the transfer learning into the pretraining. The whole experiment is evaluated based on MSCOCO dataset. Experiments show that the accuracy of the proposed model is improved by 1.3 to 2.2% points.",60020464,Guangxi Normal University,Guilin,China,['1700'],19.714285714285715,0.18333333333333332,0.4972222222222222,1,0.13125,0.0375,0.2948717948717949
1056,1080,1080,DEVELOPING A DATA FUSION STRATEGY between OMNIDIRECTIONAL IMAGE and INDOORGML DATA,"As the interest in indoor spaces increases, there is a growing need for indoor spatial applications. As these spaces grow in complexity and size, research is being carried out towards effective and efficient representation. Omnidirectional images give a snapshot of interiors and give visually rich content, but only contain pixel data. For it to be used in providing indoor services, its limitations must be overcome. First, the images must be connected to each other to represent indoor space continuously based on spatial relationships that may be provided by topological data. Second, the objects and spaces that we see in these images must also be recognized. This paper presents a study on how to link omnidirectional images and an IndoorGML data without the need for data conversion, provision of reference data, or use of different data models in order to provide Indoor Location-Based Service (LBS). We introduce the use of the Spatial Extended Point (SEP) to characterize the relationship between the omnidirectional image and the topological data. Position information of the object is used to define a region of 3D space, to determine the inclusion relationship of an IndoorGML node. We conduct an experimental implementation of the integrated data in the form of a 3D Virtual Tour. The connection of the Omnidirectional images is demonstrated by a visualization of navigation through a hallway towards a room's interior delivered to the user through a clicking action on the image.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.545454545454547,0.1444444444444445,0.4842592592592593,1,0.125,0.045454545454545456,0.2748091603053435
1057,1081,1081,POSITIONAL ACCURACY ASSESSMENT USING SINGLE and MULTI-GNSS,"Global Navigation Satellite System (GNSS) provides users worldwide with a three-dimensional positioning, velocity and time solution 24-hour service using transmitted radio signals from orbiting satellites in space. Dependency on the number of satellites available during observation can improve satellite geometry and increase redundancy which be a factor for the quality of GNSS positioning result. Each position derived from different combinations of satellite systems were evaluated aside from using GPS only. The test is conducted by single and relative positioning method using survey grade receivers. Post-processing of GNSS data were processed in an open source software, RTKLIB, getting the RMS and 2DRMS of each position derived from different combination. The resulting satellite system combination for single positioning for horizontal were better considering the inclusion of GPS and BeiDou. However, position accuracy degrades when the inclusion of GLONASS and/or GALILEO during the processing. For relative positioning, position derived from the inclusion of GALILEO, BeiDou and QZSS degrades the results. For height results in single positioning method, the displacement from the mean value is about 4.00 meters which is derived from Galileo only satellite system.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],20.222222222222218,0.02665816326530613,0.4235969387755102,1,0.09313725490196079,0.08333333333333333,0.375
1058,1082,1082,A topic-based approach to multiple corpus comparison," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Corpus comparison techniques are often used to compare different types of online media, for example social media posts and news articles. Most corpus comparison algorithms operate at a word-level and results are shown as lists of individual discriminating words which makes identifying larger underlying differences between corpora challenging. Most corpus comparison techniques also work on pairs of corpora and do need easily extend to multiple corpora. To counter these issues, we introduce Multi-corpus Topic-based Corpus Comparison (MTCC) a corpus comparison approach that works at a topic level and that can compare multiple corpora at once. Experiments on multiple real-world datasets are carried demonstrate the effectiveness of MTCC and compare the usefulness of different statistical discrimination metrics - the χ2 and Jensen-Shannon Divergence metrics are shown to work well. Finally we demonstrate the usefulness of reporting corpus comparison results via topics rather than individual words. Overall we show that the topic-level MTCC approach can capture the difference between multiple corpora, and show the results in a more meaningful and interpretable way than approaches that operate at a word-level.",60005141,University College Dublin,Dublin,Ireland,['1700'],27.0,0.17333333333333334,0.4199999999999999,0,0.12962962962962962,0.09259259259259259,0.3448275862068966
1059,1083,1083,Analysing the characteristics of crowdsourcing platforms for improving throughput,"Crowdsourcing leverages human intelligence to gather solutions on tasks that cannot be accomplished by automated tools. This system consists of components such as the requester, task, worker and the crowdsourcing platform. Studies do not explore the various features of these components and the dependencies among the same. Hence, we analyse the characteristics of the components of crowdsourcing systems using a trace-driven approach. Additionally, for reproducible research, we have introduced a workload generator for crowdsourcing platforms, which generates an unbiased workload similar to the empirical workload. Finally, the impact of various characteristics on the quality of answers has been analysed using both the empirical and synthetic workloads. The results demonstrate that success rate and activeness positively affect the productivity of workers, while the number of available human intelligence tasks (HITs) and the time duration of the same affect the productivity on each task.",60109532,"Amrita University, Amritapuri Campus",Kollam,India,"['1710', '1708', '1705']",20.285714285714285,0.08848484848484847,0.3330303030303031,1,0.1111111111111111,0.006172839506172839,0.35625
1060,1084,1084,IDEAL KIOSK PLACEMENT in up DILIMAN for EQUAL PROBABILITY of CUSTOMER TURNOUT,"Kiosks scattered around the UP Diliman campus have always been playing a significant role in shaping the present culture in the university. However, competition is inevitable among owners. Some have even lowered their prices to attract more customers and increase sales and profits. One of the reasons why some kiosks earn more than others is because of the location of the kiosks and their distribution within the campus. In this study, accessibility, walkability and site availability are the main factors that were considered to create an ideal kiosk distribution model. First, road points within an area with 10% slope grade and below were only considered to obtain optimum gradient that requires the least energy. Road points that are within a buffer of 5 meters from waiting sheds and parking lots and 10 meters from buildings were accepted to consider the accessibility of each point. Closest Facility Tool (CFT) under Network Analysis was used to identify road points within 200 meters of each building. These points were considered as good candidate locations for kiosks. CFT was used again to identify buildings within 200 meters from each candidate point. Potential customer count (PCC) per building was reduced when a canteen is within 200 meters. Lastly, the PCC multiplied by the inverse of the distance was used as weight to identify the area that will result in equal demands of customers. Python code was used to iteratively identify the combination of road points that have relatively equal weights. A map showing all 20 current kiosks in their ideal locations and a list of landmarks surrounding each kiosk were produced. Results show that, ideally, five kiosks should be located near Palma Hall, which has the largest population count. Two kiosks should also be placed between the Law Center and Asian Center, between the Institute of Biology and the National Institute of Molecular Biology and Biotechnology, and near College of Arts and Letters, Institute of Electrical and Electronics Engineering (IEEE) and College of Human Kinetics (CHK). Finally, only one kiosk each should be placed near buildings such as Melchor Hall, the National Institute of Physics (NIP), the National Institute of Geological Sciences (NIGS), the Institute of Civil Engineering (ICE) and Albert Hall.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.588235294117645,0.20327380952380955,0.5145833333333334,1,0.09178743961352658,0.11835748792270531,0.39371980676328505
1061,1085,1085,An iterative learning control of the parallel gas turbines with the crossing link,". All rights reserved.Gas turbine engine has the highest performance in the engine rotation able up to 44%. In specific applications, gas turbines are used for equipment such as electrical generators, aircraft engines, high-speed boat … There is a problem with shared power of the GT when we need control parallel GTs. Gas turbine system can use into transmission turbines, cabinet pull in the general. This paper presents an iterative learning controller (ILCer) to control the Parallel Gas Turbines (PGTs) with the speed synchronization. Using Rowen’s model to study control gas turbine and analyze system on the combined ILC with PID to compensate control signals. GTs are a nonlinear delay system, we can’t use PID as a linear system. The application of intelligence to GTs provides a good method to replace traditional controllers. Simulation results for a parallel turbine system with combination of 32MW to explain the theory for detail. We will see that ILC can apply into practice with combination PID controllers to increase control qualities.",60111656,Duy Tan University,Da Nang,Viet Nam,['1700'],16.7,0.1388888888888889,0.34444444444444444,1,0.13020833333333334,0.046875,0.33157894736842103
1062,1086,1086,Research on the factors affecting the accuracy of three-dimensional reconstruction model of rotor UAV archaeological sites," CC BY 4.0 License.The work of cultural heritage protection has risen to the national strategic level in China in recent years. More and more high and new technologies are applied in the fields of cultural relics and archaeology, heritage protection, etc., including the drone photography technology. Because the cultural protection industry has high requirements for the accuracy of reconstruction results, it puts forward higher requirements for the three-dimensional reconstruction of drones. In this paper, the factors affecting the reconstruction accuracy of the rotor unmanned opportunity are analyzed and summarized in the archaeological protection of cultural relics, and the technical integration of the oblique photography technology in archaeological work is carried out to improve the quality of modeling results.",60092860,Beijing University Of Civil Engineering And Architecture,Beijing,China,['1710'],29.75,0.15045454545454548,0.27032467532467536,0,0.06716417910447761,0.014925373134328358,0.2890625
1063,1087,1087,An antlion optimizer trained anfis control scheme to improve lvrt characteristics of grid connected pmsg,"Low voltage ride-through (LVRT) is one of the essential grid code requirements for interconnecting the wind energy conversion system. The PMSG with full scale back to back conversion has attained a lot of curiosity due to its outstanding performance as per in the LVRT during grid disturbance like a fault. The conventional controllers line PI along with coordinated control schemes, even though performs good, with dynamic changes in grid parameters especially at the time of grid faults condition cannot effectively control the system. This paper aim is to present a hybrid system development by artificial intelligence (AI) methods to improve LVRT acquirement. Both Adaptive Neuro-Fuzzy Inference System (ANFIS) and Ant-Lion Optimization (ALO), which is current intelligent optimization techniques were employed here to support the connected system and its performance. According to the simulation findings, which exhibit explicitly the improved LVRT capability of the grid-connected PMSG wind generator. The results of ALO and hybrid ALO-ANFIS are compared. The proposed hybrid control scheme, ALO trained ANFIS improving the LVRT grid code requirement considering active, reactive power and DC link voltage than ALO.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],22.5,0.1146358543417367,0.4837535014005603,1,0.09389671361502347,0.10328638497652583,0.3399014778325123
1064,1088,1088,Feature selection in GSNFS-based marker identification,"Gene Sub-Network-based Feature Selection (GSNFS) is a method capable of handling case-control and multiclass studies for gene sub-network biomarker identification by an integrated analysis of gene expression, gene-set and network data. It has previously been shown to reasonably identify sub-network markers for lung cancer. However, previous studies have not assessed the importance of each subnetwork identified by GSNFS. In this work, we applied correlation-based and information gain feature selection techniques to rank the identified sub-network biomarkers (gene-set). First, the top- and bottom- 5 ranked gene-sets were selected and investigated the classification performance. Expectedly, the top-ranked gene-sets provided an excellent performance while the bottom-ranked gene-sets showed a poor performance. The identified top-ranked gene-sets such as MAPK signalling pathway were known to relate to cancer. Furthermore, combined top-ranked gene-sets from top 2 up to top 30 showed a further improvement on the performance when compared to using individual gene-sets. The results in this study are promising as significantly fewer subnetworks were needed to build a classifier and gave a comparable performance to a full data-set classifier.",60008786,King Mongkut&#x92;s University of Technology Thonburi,Bangkok,Thailand,"['1712', '1709', '1707', '1705']",19.33333333333333,0.13564814814814816,0.5217592592592593,1,0.13304721030042918,0.034334763948497854,0.39896373056994816
1065,1090,1090,UAFA: Unsupervised Attribute-Friendship Attention Framework for User Representation,"The problem of user representation has received considerable attention in recent years. A variety of social networks include not only network structures (friendships) but also information about users’ attributes. Previous studies have explored the integration of the two information to encode users. However, these methods focus on how to fuse the target user’s friendships as a whole with its attribute information to get its representation vector, without considering the inside information of friendships, that is the influence of intimacy difference between the target user and its each friend on its representation vector. In addition, most of the above methods are supervised, which can only be applied to limited social networks analysis tasks. In this paper, we investigate a novel unsupervised method for learning the user representation by considering the influence of intimacy difference. The proposed methods take both the users’ attributes and their friendships into consideration with attribute-friendship attention network. Experimental results demonstrate that the user vectors generated by the proposed methods significantly outperform state-of-the-art user representation methods on two different scale real-world networks.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],21.75,0.0788265306122449,0.4298469387755102,1,0.09359605911330049,0.0,0.28865979381443296
1066,1091,1091,ASSESSMENT of DIFFERENT IMAGE TRANSFORMATION METHODS on DIWATA-1 SMI IMAGES USING STRUCTURAL SIMILARITY MEASURE,"This paper aims to provide a qualitative assessment of different image transformation parameters as applied on images taken by the spaceborne multispectral imager (SMI) sensor installed in Diwata-1, the Philippines' first Earth observation microsatellite, with the aim of determining the order of transformation that is sufficient for operationalization purposes. Images of the Palawan area were subjected to different image transformations by manual georeferencing using QGIS 3, and cloud masks generated and applied to remove the effects of clouds. The resulting images were then subjected to structural similarity (SSIM) tests using resampled and cloud masked Landsat 8 images of the same area to generate SSIM indices, which are then used as a quantitative means to assess the best performing transformation. The results of this study point to all transformed images having good SSIM ratings with their Landsat 8 counterparts, indicating that features shown in a Diwata-1 SMI image are structurally similar to the same features in a resampled Landsat 8 data. This implies that for Diwata-1 data processing operationalization purposes, higher order transformations, with the necessary effort to implement them, offer little advantage to lower order counterparts.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],37.2,0.18295454545454548,0.4621212121212122,1,0.14705882352941177,0.06862745098039216,0.38235294117647056
1067,1092,1092,A general overview of formal languages for individual-based modelling of ecosystems,"Various formal languages have been proposed in the literature for the individual-based modelling of ecological systems. These languages differ in their treatment of time and space. Each modelling language offers a distinct view and techniques for analyzing systems. Most of the languages are based on process calculi or P systems. In this article, we present a general overview of the existing modelling languages based on process calculi. We also discuss, briefly, other approaches such as P systems, cellular automata and Petri nets. Finally, we show advantages and disadvantages of these modelling languages and we propose some future research directions.",60061982,Universidad EAFIT,Medellin,Colombia,"['1712', '1703']",14.142857142857142,0.11136363636363636,0.4,1,0.10619469026548672,0.0,0.3963963963963964
1068,1093,1093,Higher-order linearisability," Until now, linearisability has been examined for libraries in which method arguments and method results were of ground type. In this paper we extend linearisability to the general higher-order setting, where methods of arbitrary type can be passed as arguments and returned as values, and establish its soundness.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1703']",24.5,-0.024999999999999998,0.55,0,0.10714285714285714,0.0,0.3584905660377358
1069,1094,1094,DECISION TREE CLOUD DETECTION ALGORITHM BASED on FY-4A SATELLITE DATA,"In order to study the on-board processing technology of meteorological satellites, a decision tree cloud detection algorithm is proposed by taking FY-4A satellite data as an example. According to the channel setting of the Advanced Geosynchronous Radiation Imager (AGRI) on FY-4A satellite, the 0.65 μm, 1.375 μm, 3.75 μm, and 10.7 μm bands are selected as the cloud detection channels, and the reflectance, brightness temperature or bright temperature difference of the four channels are used as the cloud detection indicators, the thresholds of the four cloud detection indicators are obtained through statistics. On this basis, the decision tree cloud detection model is constructed and validated using FY-4A satellite data. The results show that the algorithm is simple, convenient and efficient, and the overall effect of cloud detection is good. It is an effective way for meteorological satellite cloud detection on-board processing technology.",60024350,National University of Defense Technology,Changsha,China,['1710'],28.4,0.4,0.5261904761904762,1,0.06707317073170732,0.06707317073170732,0.34375
1070,1095,1095,SPECTRAL CHARACTERIZATION of A CLOSED CANOPY and OPEN CANOPY FOREST in NORTHERN SIERRA MADRE NATURAL PARK,"Forest lands play crucial roles in nutrient recycling and climate regulation. The change of closed canopy forests to open canopy forests may indicate disturbance within the closed canopy forest. Within the local context of the Philippines, few studies have been conducted to monitor changes in closed canopy forest lands. Efforts to do so are limited by the spatial extent, remoteness and ruggedness of closed canopy forests. Satellite imagery can cover the spatial extent of forest lands as well as provide constant revisit periods for monitoring. However, while multispectral imaging can detect changes in land cover, it has limitations when detecting the subtler change from closed canopy to open canopy forest cover. This study aims to provide baseline spectral characterization of a closed canopy forest in the Philippines. For this study, a hyperspectral sensor (EO1-Hyperion) with 198 band channels ranging from 426.82 nm to 2395.50 nm and a pixel size of 30 m was used to characterize the spectral variations of closed canopy forest, open canopy forest, shrubs and cropland in Northern Sierra Madre, Philippines. Multiple endmember spectral mixture analysis (MESMA) was employed to sort the image into classes as well as to characterize intra-spectral variations among the identified classes. Spectral library endmembers were assembled, optimized and used to classify the image. The spectral libraries were optimized by using Endmember Average Root Mean Square Error (EAR), Minimum Average Spectral Angle (MASA) and Iterative Endmember Selection (IES). Results overall agreement is 0.56 for EAR and IES and kappa coefficient is at 0.4.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],20.83333333333333,-0.07919642857142856,0.2631845238095239,1,0.11619718309859155,0.09154929577464789,0.3829787234042553
1071,1096,1096,Investments and Risks of Investing in Innovative Enterprises of the City of Sevastopol as an Opportunity for Economic Growth in the Region,"An increase in the volume of industrial production, especially innovation-active enterprises, provides the economic growth of the regions, which ensures in the improvement of the standard of living of the population with increasing demands for the quality of goods and services. The development of the regions of the Russian Federation is largely dependent on the introduction of innovative technologies and products. Sevastopol is not an exception; therefore, the importance of evaluating investments in innovative enterprises, which is always associated with risk, is becoming more urgent. A risk is, first, the possibility of an unfavorable outcome of some test. The investment risk or the risk of losing money intended for investing in innovative enterprises is commensurate with the risk of an alternative investment in the banking sector. Such a risk can be neglected in comparison with the risk of insufficient cash funds because of a decrease in the level of dividend payments. Therefore, the main purpose of the article is to determine the risk of investing in innovation-active enterprises and their impact on the economic growth of the Sevastopol region. In the article, it has formulated an approach to calculating the risk of investments in innovatively active enterprises of the city of Sevastopol in terms of the statistical behavior of a random variable. It has studied the trends and factors influencing the innovative activity of the enterprise. A risk or making an incorrect investment decision based on disposing data using the likelihood function. The authors considered the risk of investing in innovation-active enterprises of the Sevastopol region, which introduce organizational, marketing, and production innovations. It is the fact that at present there are no enterprises in Sevastopol, the profitability of whose shares can be commensurate with bank interest. The tendency to innovate in the Sevastopol region is low, as evidenced by the statistics of innovation activity. Calculations showed that the risk of investing in the securities of existing innovation-active joint-stock companies is high. Jo actions of the Russian Government and business structures level the political and economic crisis in the city of Sevastopol. The investment attractiveness of innovative enterprises of the city of Sevastopol will grow; the risks of investments will fall, which will ensure the economic growth of the city of Sevastopol.",60105157,V.I. Vernadsky Crimean Federal University,Simferopol,Ukraine,"['1712', '1709', '1707', '1705']",23.25,0.1763047619047619,0.4714095238095237,1,0.0889423076923077,0.03125,0.23399014778325122
1072,1097,1097,"Monitoring the spatio-temporal trajectory of urban area hotspots in Wuhan, China using time-series nighttime light images"," CC BY 4.0 License.Urban area hotspots can be considered as an ideal representation of spatial heterogeneity of human activities within a city, which is susceptible to regional urban expansion pattern pattern. However, in previous studies most researchers focused on extracting urban extent, leaving the interior variation of nighttime radiance intensity poorly explored. With the help of multi-source data sets such as DMSP/OLS (NTL), LST and NDVI, we proposed an applicable framework to identify and monitor the spatiotemporal trajectory of polycentric urban area hotspots. Firstly, the original NTL dataset were calibrated to reduce inconsistency and discontinuity. And we integrated NTL, LST as well as NDVI and established an urban index TVANUI capturing the approximate urban extents. Secondly, multi-resolution segmentation algorithm, neighborhood statistics analysis and a local-optimized threshold method were employed to get more precise urban extent with an overall accuracy above 85% and a Kappa above 0.70. Thirdly, the urban extents were utilized as masks to get corresponding radiance intensity from calibrated NTL. Finally, we established the Gaussian volume model for each cluster and the resulting parameters were used to quantitatively depict hotspot features (i.e., intensity, morphology and centroid dynamics). All the identified urban hotspot showed our framework could successfully capture polycentric urban hotspots, whose fitting coefficients were over 0.7. The spatiotemporal trajectory of hotspot powerfully revealed the impact of the regional urban growth pattern and planning strategies on human activities in the city of Wuhan. This study provides important insights for further studies on the relationship between the regional urbanization and human activities.",60017060,Central South University,Changsha,China,['1710'],23.09090909090909,0.11495098039215686,0.32941176470588235,0,0.09183673469387756,0.05102040816326531,0.34275618374558303
1073,1098,1098,COMPARING A RANGE of SIMPLE PLUME RISE MODELS and MISR AEROSOL HEIGHT MEASUREMENTS,"Rapid economic development leads to increasing sources of aerosols from both urban and biomass sources, which in turn have a significant impact on the atmosphere and the environment. There are significant differences however between urban sources, which tend to be emitted at low temperature, and biomass sources, which are co-emitted with a significant amount of heat. In this work, we first analyse the spatial and temporal distribution of aerosol height from 3.5 years of day-by-day global measurements of aerosol plume height from MISR from January 2008 through June of 2011. We next use a simple plume rise model (PRM) based on FRP and various meteorological variables both from MISR and from other data sources. We find that the PRM makes a reasonable reproduction of the MISR measurements in Western Siberia, Alaska, Central Canada, Argentina, and Eastern Europe, although it underestimates the MISR measurements everywhere. We compute the amount of aerosol above the boundary layer as well as its distribution, and find that the PRM can only come close to reproducing this in conditions which are dry and found in extra-tropical regions. In specific we find that there is a slight model improvement when we apply factors to the wind speed. In general, we find the results are optimized when wind speed is adjusted by 20% around the given mean value, and the vertical velocity is adjusted by 20% to +40% of the original value. The best fitting region, Argentina, is obtained with an RMS error (model biased low) of 0.39 km, when the horizontal wind is unadjusted and the vertical wind is adjusted by 20%. We further find that the PRM approach is not applicable over those regions which have the highest magnitude of aerosol emissions, as detected by OMI and MOPITT measurements of NO2 and CO respectively, leading to future plans on how to correct for and improve this approach.",60021182,Sun Yat-Sen University,Guangzhou,China,['1710'],31.1,0.10097222222222224,0.3764880952380952,1,0.09295774647887324,0.07887323943661972,0.31412103746397696
1074,1099,1099,Adapting the SCOR model for supply chain network assessment and improvement in oil industry,Supply chain management in oil and gas industry plays an important role for the success of these companies in most countries. A reliable supply chain helps on time delivery of goods and services and leads to better performance of the firms and yields higher profitability. This paper presents an empirical investigation to measure the relative efficiency of different oil distribution companies in Iran. The proposed study uses a five-stage Supply-Chain Operations Reference (SCOR) technique to measure the relative efficiencies of 40 distribution oil companies. The study designs a questionnaire based on four balanced scorecard perspectives and distributes it among various experts who were familiar with supply chain issues. The results indicate that the network performed relatively efficient since the study did not detect any unit with low performance and most of them maintained relatively high scores.,60005096,Kharazmi University,Tehran,Iran,"['1705', '1710', '1712', '1706', '1702']",22.66666666666667,0.20566666666666664,0.36933333333333335,1,0.10135135135135136,0.02702702702702703,0.2777777777777778
1075,1100,1100,A review on machine learning techniques for QoS in WSN,"WSN is circulated, self-directed and distributed in nature. WSN is a kind of network consist of multiple nodes which are wireless sensors connected to the base station. In recent days WSN is widely used for sensing vital information and communicate to the destination by means of the base station. In this transmission, it is essential to use the best efficient path and proper utilization of the available resources. Generally, nodes in the WSN are energy constraints, on the absence of efficient path it leads to lengthening of network lifetime and results in severe causes. The wide growth of WSN and its importance in used application increase its attention in the researched area. There are several traditional approaches were designed for WSN in the motto of limited energy usages. Most of the existing methods are one-size-fits-all approaches which are reactive and centrally-managed. But these are not properly fit for satisfying and serving the future complex networks on the aspect of cost-effective as well as optimization. On this way, Hierarchical routing protocols result effective on the concern of energy efficiency. These hierarchical protocols utilize clustering approach in collecting and disseminating the data. The need for huge data to be processed on WSN during sending and receiving makes this approach still in development stage. The important factor to be considered during the WSN process is bandwidth, sensor energy consumption, and time consumptions. To overcome these issues an ML (machine learning) based effective algorithm need to develop in order to improvise the WSN characteristic in all manner. The intention of this survey is to establish Machine Learning as an applied methodology in overcoming the WSN problems especially in the term of energy efficient routing.",60080089,"Saranathan College of Engineering, Thiruchirappalli",Tiruchirappalli,India,['1700'],18.666666666666668,0.09640731292517006,0.5083758503401362,1,0.11392405063291139,0.04113924050632911,0.26973684210526316
1076,1101,1101,Towards assembly information modeling (AIM),"Nowadays digital tools support architects, engineers and constructors in many specific tasks in the construction industry. While these tools are covering almost all aspects of design and manufacturing, the planning and design for the assembly of buildings remain an unexplored area. This research aims to lay the foundations of a new framework for the design for assembly in architectural applications entitled Assembly Information Modeling. In practice, it is a central digital model containing the structure architectural design, construction details, three dimensional representations, assembly sequences, issue management and others. This framework forms the base for a multitude of novel applications for assembly design, planning and execution, such as assembly simulation and strategies communication, problem detections in the early design phases and interdisciplinary coordination. This paper describes the specifications of the digital assembly model and illustrate two use cases: collaborative assembly design using AEC cloud-based platforms and Augmented Assembly using Augmented reality devices.",122260890,Centre for IT and Architecture (CITA),Copenhagen,Denmark,['1705'],25.16666666666667,-0.006363636363636368,0.31295454545454543,1,0.07647058823529412,0.047058823529411764,0.38095238095238093
1077,1102,1102,Understanding Decision Model and Notation: DMN Research Directions and Trends,"Decision Model and Notation provides a modeling notation for decisions, supports decision management, and business rules specification. In this paper, we identify research directions concerning DMN standard, outline classification of DMN research areas and perspectives of this relatively new formalism.",60017351,AGH University of Science and Technology,Krakow MP,Poland,['1700'],20.0,0.06818181818181818,0.2272727272727273,1,0.13043478260869565,0.10869565217391304,0.41304347826086957
1078,1103,1103,PV POWER PLANTS SITES SELECTION USING GIS-FAHP BASED APPROACH in NORTH-WESTERN MOROCCO,"Energy plays a crucial role in the economy of any country. One of the most recent trends in global development is the transition to ""green"" growth. Morocco is keeping pace with its growth by promising to increase renewable energy capacity to 42% of total installed capacity by 2020 and to 52% by 2030. This study develops a framework that aims to determine the optimal areas for deploying photovoltaic (PV) installation in two stages. The first stage aims at excluding the undesirable areas such as forests, rivers and agricultural land. The second stage consists in defining the suitability of sites based on seven criteria; solar irradiation, land surface temperature, slopes, slope orientation, distance from power lines, distance from main roads, distance of urban area. In this study we are using fuzzy logic and fuzzy membership functions in order to create criteria layers in the environment of Geographic Information System (GIS) that allowing the integration of a Multi-Criterion Decision Analysis (MCDA) to identify the best sites to deploy PV solar power plants in north-western Morocco. Also, the Analytic Hierarchy Process (AHP) technique is used to determine weights for each one of the criteria. Results obtained from the spatial approach shows that the major portion of the studied area was judged inappropriate for solar farms installations. Also, it shows that only 5.11% (8500 Ha) of the territory demonstrate high suitability for PV solar installations located in the southern part of our studied area with a potential of electricity generation, from the areas with high suitability level, assuming a PV system efficiency of 6.48%; equivalent to 5.39 Twh/year with an installed capacity of 4.02 GW and an annual carbon emission reduction of 3 697.54 Kt-CO2/year. The resulting suitability map can be used as a decision support tool to help the public policy makers to integrate green energy into their policies.",60025457,Hassan II University of Casablanca,Casablanca,Morocco,['1710'],27.818181818181817,0.09996031746031746,0.4149206349206349,1,0.10112359550561797,0.0702247191011236,0.3352601156069364
1079,1104,1104,CALCULATION and ANALYSIS on SCATTERING CHARACTERISTICS of NON-SPHERICAL PARTICLES of HAZE,"The light scattering characteristics of sulfate, one of the main pollutant particles in haze, are calculated by T-Matrix method at a target wavelength of 550 nm. The variation between shape factors (such as effective radius and aspect ratio) and scattering phase functions with different types and shapes are analysed in small scale range. The influence of shape factors on scattering cross section and depolarization ratio of particles are also discussed. Results show that the shape of particles has great effects on the spatial distribution of scattering energy, and the scattering properties of particles are sensitive to aspect ratio. The depolarization of spherical particles is close to zero, while the difference between ellipsoidal and cylindrical particles reaches several orders of magnitude. When the equivalent radius is larger than 1.0 μm, the mean depolarization ratio of the non-spherical particles is greater than 0.2. The mean depolarization ratio and scattering cross section of non-spherical particle change continuously with a certain aspect ratio and particle size range, and the shape of some particles can be therefore distinguished under certain conditions.",60064143,Nanjing University of Information Science and Technology,Nanjing,China,['1710'],25.142857142857146,0.12471988795518205,0.5000700280112045,1,0.07106598984771574,0.01015228426395939,0.25654450261780104
1080,1105,1105,From BIM to VR: Defining a level of detail to guide virtual reality narratives," This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.In 2012, the Carleton Immersive Media Studio (CIMS) started a research relationship with Public Services and Procurement Canada to develop a building information model (BIM) of the Parliament Hill National Historic Site of Canada. The model was created to facilitate a multi-year rehabilitation of the site and was developed using both historical records and highly detailed geo-referenced point cloud data. In the process of planning the model, CIMS developed a unique Level of Detail (LOD) specification for heritage buildings that, in addition to standard specifications, considered cultural heritage value as part of the LOD. As the rehabilitation project unfolded, the possibility of using the BIM for public engagement through the creation of virtual reality (VR) experiences was proposed. In this paper, we discuss the transferal of CIMS' LOD from a BIM to a VR environment, arguing that the BIM LOD's focus on cultural heritage value is consistent with virtual reality LOD in that it can be used to guide participants through a virtual reality narrative by inferring that areas of higher fidelity have greater value.",60017592,Carleton University,Ottawa,Canada,['1706'],42.0,0.1605263157894737,0.3307017543859649,0,0.09016393442622951,0.10245901639344263,0.3682008368200837
1081,1106,1106,Features of calculating cost of services in educational institutions based on the ABC method,"Heads of higher educational institutions seek to optimize costs and increase the effectiveness of the educational institution. In this regard, they need to know how resources are allocated and used by type of activity. Due to its simplicity, direct costing methods are used. Overhead is distributed in proportion to the number of students. Traditional methods of costing the cost of providing services do not allow taking into account all the features of the activities of educational institutions and the business processes that occur in them, which determines the relevance of the research topic. It is necessary to apply methods that allow you to compare management accounting data with the types of activities and determine at what stage the provision of educational services requires improvement. This method is Activity-based costing. The volumes of consumed resources are calculated depending on the types of activities. The purpose of the study is to justify the use of the Activity-based Costing (hereinafter - ABC) parameter when using the cost of training programs for students in higher education. The theoretical and methodological base of the research lies in the works of leading Russian and foreign scientists concerning the substantiation of methods for calculating the cost of products (works, services), accounting regulations. The research methodology is based on the systems approach used to study various calculation systems with general scientific methods of analysis and synthesis, comparison, synthesis, grouping and classification. The use of a modern method of cost accounting and production costing ABC will allow higher education institution to form the cost of training students for each course more objectively, which will objectively form the price for paid services and generate more reliable performance indicators of individual departments and chairs. The results of the study can be used in state and commercial institutions of higher education in determining the cost of services for training students in various programs. The scientific novelty of the study consists in developing a model of the distribution of indirect costs by function using the ABC method to determine the cost of training programs for students in higher education institutions.",60032982,Financial University under the Government of the Russian Federation,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",24.785714285714285,0.09444444444444444,0.3944444444444444,1,0.13756613756613756,0.018518518518518517,0.2540106951871658
1082,1107,1107,Session types and subtyping for orchestrated interactions,"In the setting of the π-calculus with binary sessions, we aim at relaxing the notion of duality of session types by the concept of retractable compliance developed in contract theory. This leads to extending session types with a new type operator of “speculative selection” including choices not necessarily offered by a compliant partner. We address the problem of selecting successful communicating branches by means of an operational semantics based on orchestrators, which has been shown to be equivalent to the retractable semantics of contracts, but clearly more feasible. A type system, sound with respect to such a semantics, is hence provided. The introduction of subtyping when interactions are orchestrated naturally leads to explicit subtyping, where coercions are functors on orchestrators. Besides, priority-governed selection policies (either at type- or process-level) are investigated in order to get rid of nondeterministic behaviours but those of the partner processes of the interactions.",60012259,Università degli Studi di Torino,Turin,Italy,"['1712', '1703']",24.66666666666667,0.2482954545454545,0.5630681818181817,1,0.1111111111111111,0.0,0.3212121212121212
1083,1108,1108,Deep learning-based classification using Cumulants and Bispectrum of EMG signals,"Surface electromyographic signals (EMG) historically have been used to classify tasks in basis of a feature extraction scheme and low complexity classifiers. Deep networks, as Multilayer Perceptron and Convolutional Neural Network (MLP and CNN, respectively), avoid the traditional, complex and heuristic (handcrafted) process of feature extraction. Today, it is possible to face the computational cost that these automatic techniques require due to the technology advancement. This allowed deep learning techniques to be quickly generalized to countless applications. This paper proposes to use the third order cumulants and their 2D Fourier transform (Bispectrum) to directly feed CNN and MLP deep learning networks. The classifier is not user-dependent (same classifier for all users) and obtains better results than the classical scheme according to several metrics.",60017292,Universidad Nacional de San Juan,San Juan,Argentina,['1700'],20.5,0.028240740740740736,0.3416666666666667,1,0.08904109589041095,0.07534246575342465,0.3888888888888889
1084,1109,1109,"On series-parallel pomset languages: Rationality, context-freeness and automata","Concurrent Kleene Algebra (CKA) is a formalism to study concurrent programs. Like previous Kleene Algebra extensions, developing a correspondence between denotational and operational perspectives is important, both for foundations and for applications. This paper takes an important step towards such a correspondence, by precisely relating bi-Kleene Algebra (BKA), a fragment of CKA, to a novel type of automata called pomset automata (PAs). We show that PAs can implement the BKA semantics of series-parallel rational expressions, and that a class of PAs can be translated back to these expressions. We also characterise the behaviour of general PAs in terms of context-free pomset grammars; consequently, universality, equivalence and series-parallel rationality of general PAs are undecidable.",60032882,Technische Universiteit Eindhoven,Eindhoven,Netherlands,"['1712', '1703']",22.6,0.1416666666666667,0.5583333333333333,1,0.07801418439716312,0.10638297872340426,0.45864661654135336
1085,1110,1110,Resilience and sustainability of supply chain management in the Indian automobile industry,"Supply chain provides continual turbulence with unpredictable disruptions potential for enterprises with complex network infrastructure. Supply chain in enterprises needs to be resilient and sustainable to provide effective response, removing vulnerabilities and minimizing the impact of negative disturbances. This review article is based on evaluating the role of supply chain management in automobile sector of India. The overall findings derived from review of refined articles state that, in countries like India, automobile industry needs to have appropriate management commitment for sustainability and resilience of supply chain rather than rules and regulations of government. The review article examined 914 articles related to evaluating supply chain management practices in automobile sector of India. Through the analysis of the collected articles, it is evident that DEMATEL is effective technique for providing inter-relationship in automobile industry in India. Rather than economic influence in automobile sector, managerial activity is a major concern for effective sustainable and resilience practices in automobile industry of India.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,"['1705', '1710', '1712', '1706', '1702']",22.57142857142857,0.15737179487179484,0.5423076923076923,1,0.0872093023255814,0.03488372093023256,0.23529411764705882
1086,1111,1111,Visual semantic reasoning for image-text matching,"Image-text matching has been a hot research topic bridging the vision and language areas. It remains challenging because the current representation of image usually lacks global semantic concepts as in its corresponding text caption. To address this issue, we propose a simple and interpretable reasoning model to generate visual representation that captures key objects and semantic concepts of a scene. Specifically, we first build up connections between image regions and perform reasoning with Graph Convolutional Networks to generate features with semantic relationships. Then, we propose to use the gate and memory mechanism to perform global semantic reasoning on these relationship-enhanced features, select the discriminative information and gradually generate the representation for the whole scene. Experiments validate that our method achieves a new state-of-the-art for the image-text matching on MS-COCO and Flickr30K datasets. It outperforms the current best method by 6.8% relatively for image retrieval and 4.8% relatively for caption retrieval on MS-COCO (Recall@1 using 1K test set). On Flickr30K, our model improves image retrieval by 12.6% relatively and caption retrieval by 5.8% relatively (Recall@1).",60028628,Northeastern University,Boston,United States,"['1712', '1707']",21.75,0.1159090909090909,0.3191678691678692,1,0.11214953271028037,0.04672897196261682,0.3417085427135678
1087,1112,1112,Individual-specific classification of mental workload levels via an ensemble heterogeneous extreme learning machine for EEG modeling,"In a human-machine cooperation system, assessing the mental workload (MW) of the human operator is quite crucial to maintaining safe operation conditions. Among various MW indicators, electroencephalography (EEG) signals are particularly attractive because of their high temporal resolution and sensitivity to the occupation of working memory. However, the individual difference of the EEG feature distribution may impair the machine-learning based MW classifier. In this paper, we employed a fast-training neural network, extreme learning machine (ELM), as the basis to build an individual-specific classifier ensemble to recognize binary MW. To improve the diversity of the classification committee, heterogeneous member classifiers were adopted by fusing multiple ELMs and Bayesian models. Specifically, a deep network structure was applied in each weak model aiming at finding informative EEG feature representations. The structure of hyper-parameters of the proposed heterogeneous ensemble ELM (HE-ELM) was then identified and then its performance was compared against several competitive MW classifiers. We found that the HE-ELM model was superior for improving the individual-specific accuracy of MW assessments.",60008691,University of Shanghai for Science and Technology,Shanghai,China,['1701'],20.875,0.11142857142857143,0.5117857142857144,1,0.10144927536231885,0.06763285024154589,0.35602094240837695
1088,1113,1113,Learning Continuous User and Item Representations for Neural Collaborative Filtering,"Collaborative filtering (CF) is one of the most successful approach commonly used by many recommender systems. Recently, deep neural networks (DNNs) have performed very well in collaborative filtering for recommendation. Conventional DNNs based CF methods directly model the interaction between user and item features by transforming users and items into binarized sparse vectors with one-hot encoding, then map them into a low dimensional space with randomly initialized embedding layers and automatically learn the representations in training process. We argue that randomly initialized embedding layers can not capture the contextual relations of user interactions. We propose an approach that uses the optimized representations of user and item generated by doc2vec algorithm to initialize embedding layers. Items with similar contexts (i.e., their surrounding click) are mapped to vectors that are nearby in the embedding space. Our experiments on three industry datasets show significant improvements, especially in high-sparsity recommendation scenarios.",60014966,Peking University,Beijing,China,['1700'],21.0,0.0701530612244898,0.5344387755102041,1,0.13095238095238096,0.011904761904761904,0.39634146341463417
1089,1114,1114,LOST WATERWAYS: CLUES from DIGITIZED HISTORICAL MAPS of MANILA and OTHER PHILIPPINES CITIES,"We search for lost bodies of water in the cities of Manila, Tacloban, Iloilo, Cebu, Davao, and Naga by aligning their digitized Spanish-era and American-era maps to Google maps. These vanished ancient waterways can either become flooding hazards in case of extreme weather events, or liquefaction hazards, in case of earthquakes. Digitized historical maps of the cities were georectified, overlaid on current Google maps, and checked for potential missing bodies of water. Inspection through field visits and interviews with locals were conducted to verify the actual status of suspected sites. The validation identified lost, found, and even new bodies of water. There was also evidence of affected buildings, rainless flooding, and a ""new normal"" for the meaning of flooding among frequently inundated residents.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],20.5,0.019772727272727268,0.4409090909090909,1,0.11486486486486487,0.060810810810810814,0.4236111111111111
1090,1115,1115,NRSA: Neural Recommendation with Summary-Aware Attention,"Reviews are widely used in recommendation systems to handle the sparsity problem of rating matrix. However, learning the representations of users and items only from reviews would be challenging since there are less meaningful words and reviews while modeling users or items. In fact, in addition to reviews there are rich off-the-shelf summaries written by users along with reviews, but existing recommendation methods ignore this useful information. The summary of a review is to describe the review with shorter sentences, and can be seen as a high-level abstraction of the review. Thus the summary can play a guidance role to indicate the important parts in a review and the informativeness of the review. Hence, we propose a neural recommendation method to learn summary-aware representations of users and items from reviews. We firstly apply a summary encoder to learn representations of text summary, which will be used as the guidance indicator. We design a summary-aware review encoder to learn representations of reviews from raw words, and another summary-aware user/item encoder to learn representations of users or items from reviews. To be specific, we propose a hierarchical attention model with summary representations as attention vectors under word- and review-level to select important words and reviews for users/items respectively. We conduct extensive experiments on real-world benchmark datasets and the results demonstrate that our approach can effectively improve the performance of neural recommendation.",60019533,Tianjin University,Tianjin,China,['1700'],22.9,0.1885042735042735,0.5246581196581196,1,0.11235955056179775,0.0,0.31983805668016196
1091,1116,1116,Adaptive-Skip-TransE Model: Breaking Relation Ambiguities for Knowledge Graph Embedding,"Knowledge graph embedding aims to encode entities and relations into a low-dimensional vector space, obtaining its distributed vector representation for further knowledge learning and reasoning. Most existing methods assume that each relation owns one unique vector. However, in the real world, many relations are multi-semantic. We note that a reasonable adaptive learning method for the number of semantics for a given relation is lacking in knowledge graph embedding. In this paper, we propose a probabilistic model Skip-TransE, which comprehensively considers the two-way prediction ability and global loss intensity of the golden triplets. Then based on Skip-TransE, its non-parametric Bayesian extended model Adaptive-Skip-TransE is presented to automatically learn the number of semantics for each relation. Extensive experiments show that the proposed models can achieve some substantial improvements above the state-of-the-art baselines.",60019499,Chinese Academy of Sciences,Beijing,China,['1700'],18.571428571428573,0.2075,0.4333333333333333,1,0.12121212121212122,0.04242424242424243,0.3356643356643357
1092,1117,1117,Movie recommendations with conventional strategies using movielens dataset,"World Wide Web is extending in an exponential rate, the size and the complexity of the real-world data is expanding alongside it. Currently, the web contains Terra bytes of data and most of the part doesn’t interest by the users or either undesirable data or substance irrelevant information to user’s choice. To enable the users to cope with this data explosion, many organizations deploying tools of recommendation systems to guide the users in the right direction and to get the benefit themselves in terms of the business growth. Many e-commerce systems using these recommendation systems to recommend books, articles, news, products, and movies, etc. Among these, Movie recommendation systems have turned into an intriguing research area, because of the exponential increase of the users in a mobile environment. For such kind of movie recommendations, the aggregated data which include preferences of the users, feelings of the users, and reviews by the users take a key role to assist the new users for taking advantage. In this paper we presented a brief overview of the recommender systems using content-based filtering (preference of the user), collaborative filtering (preference of similar users), and hybrid-based filtering. We applied these three strategies to the minimized sample from the MovieLens dataset. However to deal with the recommendation system, we must consider timeliness and accuracy. In addition we have presented the recent works on movie recommendations using machine learning strategy and directions to be taken for getting timely and accurate recommendations.",60114593,Sree Vidyanikethan Engineering College,Tirupati,India,['1700'],24.4,0.16387987012987013,0.5441829004329004,1,0.09507042253521127,0.01056338028169014,0.33093525179856115
1093,1118,1118,USING OPENLY SOURCED 3D GEOGRAPHIC INFORMATION SYSTEMS (GIS) in DETERMINING the PHOTOVOLTAIC POTENTIAL of QUEZON CITY HALL in TERMS of RECEIVED DIRECT SOLAR RADIATION,"For the past few years the United Nations have been standing strong in advocating the 17 sustainable development goals. One of those goals focuses on affordable and clean energy, which includes renewable energy. This study focuses on the application of geomatics on renewable energy, more specifically solar energy. The research aims to determine the photovoltaic potential of Quezon City Hall in the Philippines by calculating the amount of direct solar radiation it receives through a process that uses only openly sourced 3D GIS (Geographic Information Systems). The methodology mainly consists of (1) generating a building model composed of points that contains heights derived from a LiDAR (Light Detection and Ranging) based NDSM (Normalized Digital Surface Model) through the combined use of Python and QGIS, (2) determining the intersections between the building model and the sun's light rays, incorporating shadow factors and integrating solar irradiation values using Python, and (3) visualizing and gridding for analysis through the combined use of Blender, QGIS and a Spreadsheet software. Results have shown that Quezon City Hall has good photovoltaic potential since: solar irradiation values in 2017 has shown that the city hall receives 800 W/m2 to 1000 W/m2 on average from 08:00 to 16:00, and all faces of the building receive solar radiation. This means that all sides of the building can be proper candidates for solar panel or for Building Integrated Photovoltaics (BIPV) installations.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],33.0,0.14509803921568626,0.5303921568627451,1,0.11320754716981132,0.11320754716981132,0.42911877394636017
1094,1119,1119,"Air quality meteorological and environmental information system in Western Macedonia, Hellas","This paper aims to present the development of an operational, monitoring, as well as high-resolution local-scale meteorological and air quality forecasting information system for West Macedonia region, Hellas, in a dynamic, easily accessible and user-friendly way. The system, having been operated by the Laboratory of Atmospheric Pollution and Environmental Physics since 2002, has been in a continuous process of improvement. It consists of a structured system fully accessible and manipulable by users, as well as a system for accessing and managing measurement results in a direct and dynamic way. Thus, updates of the weather and air pollution forecast for the West Macedonia region are provided for the next seven days based on current day information. The forecasts are displayed through dynamic-interactive web charts, whereas there is also a visual illustration of the atmospheric pollution of the region in a map, using images and animation images. The application has been developed using state of the art web technologies (Ajax, Google Maps, etc.) and under an open-source software philosophy, allowing users to update the code according to their needs.",60006517,University of Western Macedonia,Kozani,Greece,"['1710', '1708', '1705']",29.5,0.07916666666666666,0.18194444444444444,1,0.08095238095238096,0.05714285714285714,0.345
1095,1120,1120,A comparative study of SVM and LSTM deep learning algorithms for stock market prediction," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper presents a comparative study of the performance of Long Short-Term Memory (LSTM) neural network models with Support Vector Machine (SVM) regression models. The framework built as a part of this study comprises of eight models. In this, 4 models are built using LSTM and 4 models using SVM respectively. Two major datasets are used for this paper. One is the base standard Dow Jones Index (DJI) stock price dataset and another is the combination of this stock price dataset along with external added input parameters of crude oil and gold prices. This comparative study shows the best model in combination with our input dataset. The performance of the models is measured in terms of their Root Mean Squared Error (RMSE), Mean Squared Error (MSE), Mean Absolute Error, Mean Absolute Percentage Error (MAPE) and R squared (R2) score values. The methodologies and the results of the models are discussed and possible enhancements to this work are also provided.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],21.375,-0.04926470588235295,0.5852941176470589,0,0.07,0.19,0.49748743718592964
1096,1121,1121,"LINEAR SPECTRAL UNMIXING of SENTINEL-3 IMAGERY for URBAN LAND COVER-LAND SURFACE TEMPERATURE (LST) ANALYSIS: A CASE STUDY of METRO MANILA, PHILIPPINES","The advancement of remote sensing technologies is a huge advantage in various environmental applications including the monitoring of the rapid development in an urban area. This study aims to estimate the composition of the different classes (vegetation, impervious surfaces, soil) in Metro Manila, Philippines using a 300-meter spatial resolution Sentinel-3 Ocean and Land Colour Instrument image. The relationship between these land cover fractions with the spatial distribution of land surface temperature at this scale is evaluated. Sentinel-3 image has a higher spectral resolution (i.e. 21 bands), as compared with other Landsat and Sentinel missions, which is a requirement for an accurate cover mapping. Linear Spectral Unmixing (LSU), a sub-pixel classification method, was employed in identifying the fractional components in the image based on their spectral characteristics. Field survey using spectroradiometer was conducted to acquire spectral signatures of an impervious surface, vegetation, and soil which were used as the endmembers in the unmixing process. To assess the accuracy of the resulting vegetation fractional image, this was compared with a separate land cover pixel-based classification result using a 3-meter high spatial resolution PlanetScope image and with another vegetation index product of Sentinel-3. The results indicate that the recently available Sentinel-3 image can accurately estimate vegetation fraction with R2 Combining double low line 0.84 and 0.99, respectively. In addition, the land surface temperature (LST) retrieved from Climate Engine is negatively correlated with the vegetation fraction cover (R2 Combining double low line 0.81) and positively correlated with the impervious surface fraction cover (R2 Combining double low line 0.66). Soil, on the other hand, has no correlation with the LST.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],24.09090909090909,0.0755844155844156,0.36200577200577205,1,0.09508196721311475,0.08524590163934426,0.3509933774834437
1097,1122,1122,Mapping Industrial Corridors,"Industrial development plays a significant role in increasing a country's economic growth and competitiveness. Some countries expand their industrial development using corridors or special economic zone. However, limited publication is found regarding how a nation dealing with their industrial corridor and its impact to economic growth. This research is aimed to evaluate the focus of industrial development of Indonesia by taking into account Sulawesi corridor, Bali-Nusa Tenggara corridor, and Maluku-Papua corridor located on eastern part of the country. These corridors are expected to improve economic activities in the region and increase the national competitiveness in general. Data were obtained through pairwise comparison and analyzed using a location quotient (LQ), which aims to rank overall potential industries in a particular region. While pairwise comparison was used to process the result from LQ analysis to determine the industry with the highest potential by taking into account variables related to regional development extracted from public records. The research found two alternative scenarios for the decision-making process based on development cost, government capacity, and completion time. The first scenario considered government ability to fund all required projects to support the country's economic expansion in the future. While the second scenario evaluated a limited budget from the government allocation to accelerate infrastructure development. Both scenarios are used to make opposing decisions that need to be considered in the nearest future. The result is used as an academic exercise for those interested in regional development, government officials dealing with the economic masterplan, and other stakeholders in both national and international.",60069377,Universitas Indonesia,Depok,Indonesia,"['1712', '1709', '1707', '1705']",21.166666666666668,0.05485008818342151,0.33298059964726634,1,0.14084507042253522,0.03169014084507042,0.23741007194244604
1098,1123,1123,Using magnetic resonance imaging to distinguish a healthy brain from a bipolar brain: A transfer learning approach," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Bipolar Disorder (BD) is a recurrent psychiatric condition characterised by periods of depression and (hypo)mania, it affects more than 1% of the world's population [1]. However, accurate diagnosis can be difficult due to the lack of diagnostic tools available to practitioners. To address this knowledge gap this paper aims to understand how the application of transfer learning, in the context of machine learning techniques, can be used to improve a diagnosis of BD. Image detection of magnetic resonance images (MRI) was undertaken to identify features of grey matter in BD brains in comparison to healthy controls (HC), which may constitute a biomarker of BD. Additionally, the products of machine learning were investigated for clinical application to efficiently aid in clinical diagnosis by an end user, through a cloud-based application. The transfer learning model created demonstrated at 88% accuracy the ability to detect features present in the BD brain, not present in controls. Of limitation to this study was the amount of MR images required to train this model. However, this project identifies that it is possible with limited resources to create a model which may prove useful in diagnostic settings in the future.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],25.625,0.1235714285714286,0.3850793650793651,0,0.11392405063291139,0.06751054852320675,0.35714285714285715
1099,1124,1124,Regional features of the labor market in the digitalization of the domestic economy,"The economy's digitalization seems to be the most significant factor in its current development, but the process is unevenly implemented in the regional context, which affects all aspects of market interaction, including the labor market. It affects the market situation, determining the standard of living characteristics in individual territories of the country. Under these conditions, the role of employment centers increases, their functions are expanding and are associated primarily with a reflection of the ongoing qualitative changes in the structure of demand and supply in the labor market of a specific territory based on the existing specialization, areas of production cooperation, structure and level of development of productive forces, taking into account the continuing multi-structured Russian economy. Regional monitoring of the labor market is aimed at assessing the existing features of the labor market of a specific territory, as well as identifying trends that allow forecasting the development vector and determining the most promising areas of training and retraining. Scientific understanding of the results of monitoring by representatives of the educational community and communicating its results allows us to form the potential for mutually beneficial cooperation between employers, the state, employees and specialized educational institutions focused on training the relevant workforce. Labor market monitoring conducted in Taganrog records the changes in the labor economy of the city, and the materials obtained from its results can be used to adjust interaction programs between vocational education institutions, the Administration and the Employment Center of the city, as well as interested employers. The research findings demonstrate the presence of stable tendencies to increase the demand for workers with higher education. As Taganrog is an average Russian city, the findings can be extrapolated to other regions and used in the process of developing mechanisms for government regulation and support for regional labor markets.",60110804,Taganrog Institute of Management and Economics,Taganrog,Russian Federation,"['1712', '1709', '1707', '1705']",37.375,0.13478260869565215,0.3826086956521739,1,0.11042944785276074,0.015337423312883436,0.2932098765432099
1100,1125,1125,Detecting bot behaviour in social media using digital DNA compression," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).A major challenge faced by online social networks such as Facebook and Twitter is the remarkable rise of fake and automated bot accounts over the last few years. Some of these accounts have been reported to engage in undesirable activities such as spamming, political campaigning and spreading falsehood on the platform. We present an approach to detect bot-like behaviour among Twitter accounts by analyzing their past tweeting activity. We build upon an existing technique of analysis of Twitter accounts called Digital DNA. Digital DNA models the behaviour of Twitter accounts by encoding the post history of a user account as a sequence of characters analogous to an actual DNA sequence. In our approach, we employ a lossless compression algorithm on these Digital DNA sequences and use the compression statistics as a measure of predictability in the behaviour of a group of Twitter accounts. We leverage the information conveyed by the compression statistics to visually represent the posting behaviour by a simple two dimensional scatter plot and categorize the user accounts as bots and genuine users by using an off-the-shelf implementation of the logistic regression classification algorithm.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],28.285714285714285,0.03979166666666666,0.28952380952380946,0,0.11682242990654206,0.08411214953271028,0.33014354066985646
1101,1126,1126,RGB-infrared cross-modality person re-identification via joint pixel and feature alignment,"RGB-Infrared (IR) person re-identification is an important and challenging task due to large cross-modality variations between RGB and IR images. Most conventional approaches aim to bridge the cross-modality gap with feature alignment by feature representation learning. Different from existing methods, in this paper, we propose a novel and end-to-end Alignment Generative Adversarial Network (AlignGAN) for the RGB-IR RE-ID task. The proposed model enjoys several merits. First, it can exploit pixel alignment and feature alignment jointly. To the best of our knowledge, this is the first work to model the two alignment strategies jointly for the RGB-IR RE-ID problem. Second, the proposed model consists of a pixel generator, a feature generator and a joint discriminator. By playing a min-max game among the three components, our model is able to not only alleviate the cross-modality and intra-modality variations, but also learn identity-consistent features. Extensive experimental results on two standard benchmarks demonstrate that the proposed model performs favourably against state-of-the-art methods. Especially, on SYSU-MM01 dataset, our model can achieve an absolute gain of 15.4% and 12.9% in terms of Rank-1 and mAP.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",17.9,0.1623214285714286,0.4942857142857142,1,0.07883817427385892,0.08298755186721991,0.424390243902439
1102,1127,1127,International journal of data and network science,"Magnetic abrasives are important parts of Magnetic Assisted Abrasive Finishing (MAF). Magnetic abrasives are prepared by many processes, but sintering is the one of the best processes to prepare magnetic abrasives. The objective of this paper is to optimize the sintering process parameters. To do that, Response Surface Methodology (RSM) is used for the optimization of process parameters, Abrasive concentration in ferromagnetic particles (AC)%, Compacting Pressure (CP) N/mm2 and Sintering Time(ST)min. To check the performance of magnetic abrasives Percentage Improvement in Surface finish (PISF) is considered as a response variable. Optimization and prediction are executed through RSM and Central Composite Design (CCD) is used to conduct the experiments. The optimized values of process parameters obtained are AC (19.29%), ST (15min) and CP (6.9 N/mm2) and also predicted values for the response variable are obtained.",60111242,"Guru Nanak Dev Engineering College, Ludhiana",Ludhiana,India,"['1705', '1710', '1712', '1706', '1702']",19.142857142857142,0.38,0.4300000000000001,1,0.09523809523809523,0.14285714285714285,0.5470588235294118
1103,1128,1128,Exploring urban walkability models and pedestrian movement trends in a vancouver neighbourhood,"Walkability, or how inviting a place is to pedestrians, has proven a useful concept for urban decision-makers. Although there are now several methods to measure and evaluate the walkability of streets and neighbourhoods, these are usually dependent on large sets of data, thus making it difficult to apply them in the daily practice of architects and urban designers for evaluating design alternatives. The intention is to compare different measures as indicators of urban walkability based on the study case of the Olympic Village neighbourhood in Vancouver, Canada. Two large-scale walkability indexes were graphically compared with visibility-based measurements and pedestrian movement routes tracked in site. Each method was chosen based on the spatial scale of the variables that compose the measurements: a city-scale walkability index based on the configuration of street grid for the urban whole, a neighbourhood walkability index based on data available at 800m from each building and a pedestrian movement simulation model based on a configurational approach emphasizing visibility and movability in space. Results found similarities between the configurational model and pedestrian movement patterns at the Olympic Village but little agreement between two walkability indexes. Further research is needed to understand why there is little correlation among methods.",60023857,Universidade Federal do Rio Grande do Norte,Natal,Brazil,['1705'],28.57142857142857,-0.0006696428571428582,0.2861607142857143,1,0.09865470852017937,0.026905829596412557,0.2757009345794392
1104,1129,1129,A Multilingual Semantic Similarity-Based Approach for Question-Answering Systems,"Question-answering systems face a challenge related to the process of deciding automatically about the veracity of a given answer. This issue is particularly problematic when handling open-ended questions. In this paper, we propose a multilingual semantic similarity-based approach to estimate the similarity score between the user’s answer and the right one saved in the data tier. This approach is mainly based on semantic information notably the synonymy relationships between words and syntactico-semantic information especially semantic class and thematic role. It supports three languages: English, French and Arabic. Our approach is applied to a multilingual ontology-based question-answering training for Alzheimer’s disease patients. The performance of the pro- posed approach was confirmed through experiments on 20 patients that promising capabilities in identifying literal and some types of intelligent similarity.",60064746,University of Sfax,Sfax,Tunisia,['1700'],18.142857142857142,0.20992063492063487,0.45853174603174607,1,0.11920529801324503,0.026490066225165563,0.28368794326241137
1105,1130,1130,Transformation of activity of audit chamber of the russian federation in the conditions of digital economy,"The development of digital economy became one of the most significant factors of the modern social development. Business was the first to join the process of digital transformation. That results in the explosive growth of the electronic commerce volumes, as well as the development of Big Data and Internet of things technologies. However, the system of public administration is the most important direction of the use and storing of information and data in the digital form. The system of public administration deals with the volumes of data, which cannot be compared with that in the largest enterprises and multinational corporations. The use of digital economy technologies is necessary for the increase in the effectiveness of public administration. Recently, Russian State has taken up leading the digital transformation by approving the ""Digital Economy of the Russian Federation"" Programme in 2017. Thus, it is especially important to study the digital transformation and spread the information about the experience. This article became the result of the research on the digital transformation of Audit Chamber of the Russian Federation. Studying of the main stages and results of the digital transformation, which is being carried out in Audit Chamber, became the research objective. The methods of the situation analysis were applied. Both processes of resistance to changes and ways of their overcoming were studied along with studying of digital transformation stages. The methods of social research were used for this purpose. This analysis proved that the digitalization of the Audit Chamber is still in the preparatory stage, so it is too early to make any conclusions. However, the actions taken are optimized for the subsequent possibility of automation and the use of digital technologies, that allows us to expect the subsequent successful digitalization.",60024799,Moscow State University of Civil Engineering,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",19.2,0.12083333333333332,0.22720588235294115,1,0.0759493670886076,0.05379746835443038,0.2689873417721519
1106,1131,1131,"Streets, parks & plazas: Analyzing daylight in the public realm","Research has shown how integral daylight access is to both physical and mental health. While this has gained traction within building interiors, very little research has delved into the daylight that hits streets, parks, courtyards, and other exterior spaces that impact the urban experience. This paper provides a better understanding of how daylight affects these spaces and suggests a framework for the design of livable cities. 276 unique respondents answered a questionnaire. The results were utilized to qualitatively analyze the impact of daylighting within 25 well-known exterior urban spaces on city-users. Computer modeling, daylight simulation, and both correlation and regression analyses tied these respondents’ answers to quantitative data. New metrics, both data-driven and graphic, were used to summarize the daylighting qualities of these spaces, allowing designers to use these spaces and metrics for future comparison analyses. Given further exploration into the use of these metrics, they may also be applied to future zoning code alterations by providing the framework for a performance-based compliance path for achieving necessary daylighting at grade. Public and private sectors, from individual buildings to large-scale master plans, may utilize these metrics to create benchmarks for improving the urban experience.",113004726,ZGF Architects LLP,Seattle,United States,['1705'],21.444444444444443,0.03014520202020202,0.3507816257816258,1,0.13777777777777778,0.0,0.33488372093023255
1107,1132,1132,From drawing shapes to scripting shapes: Architectural theory mediated by shape machine,"The shape grammar formalism has offered a visual, rulebased framework for interpreting architectural languages for over forty years. However, the ability to implement grammars within a technology that allows for direct engagement with shape rules and productions so that they can be dynamically simulated, shared, understood, modified, and brought into a more active theoretical dialogue is only partially achieved. The work here asks how a new technology that allows shape rules to be implemented by drawing shapes to specify scripts instead of writing code can reinvigorate shape computation to advance formal analysis and synthesis in architectural research. More precisely, a case study to implement an analog grammar on John Portman’s domestic language with a new shape grammar interpreter, the Shape Machine, is presented to take on this question. The results are illustrated as a visual catalog of sample designs generated in the software. The results suggest further insights on Portman’s language of the house prompted by the machine-based specification.",60019647,Georgia Institute of Technology,Atlanta,United States,['1705'],26.5,0.10995670995670992,0.4077922077922077,1,0.16292134831460675,0.033707865168539325,0.30337078651685395
1108,1133,1133,SPATIAL and TEMPORAL COMMUNITY DETECTION of CAR MOBILITY NETWORK in METRO MANILA,"Transportation Network Companies (TNCs) like Uber utilize GPS and wireless connection for passenger pickup, driver navigation, and passenger drop off. Location-based information from Uber in aggregated form has been made publicly available. They capture instantaneous traffic situation of an area, which makes describing spatiotemporal traffic characteristics of the area possible. Such information is valuable, especially in highly urbanized areas like Manila that experience heavy traffic. In this research, a methodology for identifying the underlying city structure and traffic patterns in Metro Manila was developed from the Uber trip information. The trip information was modelled as a complex network and Infomap community detection was utilized to group areas with ease of access. From Uber trip dataset, the data was segregated into different hours-of-day and for each hour-of-day, a directed-weighted temporal network was generated. Hours-of-day with similar traffic characteristics were also grouped together to form hour groups. From the results of the network characterization, hours-of-day were grouped into six hour groups; 00 to 04 hours-of-day in hour group 1, 05 to 07 hours-of-day in group 2, 08 to 12 hours-of-day in group 3, 13 to 15 in group 4, 16 to 19 in group 5, and 20 to 23 in group 6. Major roads as well as river networks were observed to be the major skeleton and boundaries of the generated clusters.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.0,0.040454545454545465,0.5545454545454546,1,0.08273381294964029,0.03597122302158273,0.3861788617886179
1109,1134,1134,Spam detection on profile and social media network using principal component analysis| (PCA) and K-means clustering,"Social media as a means of communicating in cyberspace continues to grow both from the number of users, utilization, and the resulting impact. Existing social media ecosystems are influenced by the influence of public figures, trending topics, even spam, and spammers. Detection of spam accounts that have been done mostly using the method of classification or supervised learning. This will be a problem if the data is new and the supervised model is not updated it will increase the possibility of false detection. Based on the problem, this study will use Principal Component Analysis (PCA) and K-means clustering with Mahalanobis distance as a method to detect a collection of users who have similar properties to determine spam. This study uses 150 thousand twitter data with 15 thousand account data that described as graph data. The result, we find that error detection in the classification method to find spam is a class that made only two: spam and non-spam. Though in addition there are still other classes that have the characteristics of spam when it is not. In this paper, we defined the clusters on to 5 clusters: normal, news account and public activist, foreign account, public figure, and spam.",60069382,Institut Teknologi Bandung,Bandung,Indonesia,['1706'],22.11111111111111,0.015617715617715609,0.3413752913752913,1,0.11403508771929824,0.03070175438596491,0.32142857142857145
1110,1135,1135,Project offices as the locus of corporate innovative systems genesis,"The general prerequisites for studying the transformation of an economic formation as a multilevel complex of subsystems of one technological mode into a complex of subsystems of another technological mode are considered. On the basis of the general research plan, the current tasks of clarifying the classification of innovative systems and identifying the locus of one of the key subsystems origin are defined; that is the mini-economic subsystem proposed in the work called the Corporate Coordination Innovative System (CCIS) as a part of the corporate innovative system. This made it possible to propose a variant of improving the classification of innovative systems and solve the problem of identifying the locus of the corporate innovative system. Based on the conducted factor analysis of innovative activity, it was concluded that the project offices of the technostructure become the locus of corporate innovative systems forming in the post-Soviet enterprises. The analysis of the dependence of innovative activity on the quantitative and qualitative development of project offices has revealed the direct dependence of innovative activity on the professional diversity of the project office. Such a conclusion becomes the basis for the induction of the hypothesis that the project offices will become the organizational structure of management within the existing organizational structure of management, becoming in the course of their development a regeneration locus of transformation of the technostructure into a new type in accordance to the new technostructure. Based on the conclusions, promising research directions were formulated, predetermined by the goal of facilitating the accelerated development of innovative systems, and by means of that is an accelerated transition to a new wave of innovation or techno-economic paradigm. The results of the study make it possible to proceed to the study of not only the issues of forecasting the features of technostructures adapted for functioning in the conditions of information knowledge economy, but also the question of establishing patterns and the nature of new type clusters forming; they are formed by business contacts of technostructures.",60108777,Volodymyr Dahl East Ukrainian National University,Severodonetsk,Ukraine,"['1712', '1709', '1707', '1705']",41.25,0.18471074380165292,0.6232782369146005,1,0.10422535211267606,0.011267605633802818,0.22063037249283668
1111,1136,1136,FPGA implementation of reconfigurable FIR filter using vedic design with CLA adder,"Nowadays, Reconfigurable Finite Impulse Response (RFIR) filter is required for most of the Digital Signal Processing (DSP) applications. In that, the reconfigurable filter frequently changes the coefficients while performing the operation. In this paper, Vedic Design with Carry Look Ahead adder is used to design the RFIR filter (RFIR-VD-CLA). This RFIR architecture is designed using different bits and taps such as 4 bit & 3 Tap, 4 bit & 7 Tap, 8 bit & 3 Tap, and 8 bit & 7 Tap. For all the architectures, the FPGA and ASIC performances are evaluated. Cadence 180nm and 45nm technology have been used for calculating area, power, and delay of the entire architecture. From Xilinx, FPGA performances such as LUT, flip flop, slices, and frequency have been evaluated. RFIR-VD-CLA architecture utilized 103716 um2 area, 693908 nW power, and 130ps delay in 180nm technology. RFIR-VD-CLA architecture has better ASIC and FPGA performances than existing architectures.",60093995,Bangalore Institute of Technology,Bengaluru,India,['1700'],16.88888888888889,0.1375,0.440625,1,0.06598984771573604,0.19796954314720813,0.5659340659340659
1112,1137,1137,Immersive representation of urban data,"Urban environments are not comprised solely of physical objects like buildings, infrastructure, and landscapes, but also invisible, but critically influential, information like traffic patterns, economic values, and energy use. This intangible overlay of quantifiable urban behavior is essential to understanding how cities function. Vast quantities of urban data are now widely available through online open source data repositories, but the raw data remains limited in its value to support informed decision-making unless it can be synthesized and represented in a meaningful fashion. This paper describes in-progress research exploring the spatialization and representation of urban data using virtual reality (VR). This research uses Manhattan as a test case for enabling users to access urban data immersively and interactively from multiple vantage points and scales. It describes the process for visualizing the city in VR, representing urban data three-dimensionally, and creating a user interface for data interaction while in the virtual environment. The paper identifies initial steps towards creating an immersive representation of urban data to effectively inform future urban planning initiatives and design decisions.",60030551,Syracuse University,Syracuse,United States,['1705'],24.714285714285715,0.06353646353646353,0.2441933066933067,1,0.10606060606060606,0.010101010101010102,0.3072916666666667
1113,1138,1138,Extraction methods and experiment on essential forest variables for geospatially-enabled SDGs monitoring," CC BY 4.0 License.Since the United Nations passed the 17 Sustainable Development Goals (SDGs) and 169 sub-goals in 2015, many researchers have tried their best to put them into practise. However, mass data and different understanding of SDGs indicators make this work much more difficult. In this article we reference the concept of essential variables which may have some contribution to established a standard system for SDGs monitoring. Here we take SDG15 as an example. Firstly, we deeply analyse the main contents of SDG15 and select some geospatial-related indicators involved with forest land. From those forest-related and geospatial-enabled indicators we concise 5 essential forest variables (EFV4SDG15) which could be classified into 3 different types: land cover distribution and transformation, aggregative pattern and intensity and spatial-temporal evolution process. Secondly, formalized expression of EFV4SDG15 and extraction of them from multiple data source are necessary, including data processing and mathematical expression of the variables. Finally, we take global region as research target to carry out preliminary experiments. In this part, we only select 2 EFV4SDG15s: the forest coverage rate and forest land transfer matrix to show detailed operation process and then present the results in forms of figure and table. The paper has preliminary attempts to the application of essential variables in SDGs monitoring and provides an example for other fields.",60108755,"China University of Mining &amp; Technology, Beijing",Beijing,China,['1710'],21.9,0.088768115942029,0.4286231884057972,0,0.09803921568627451,0.050980392156862744,0.34710743801652894
1114,1139,1139,Sobolev inequalities via Muramatu's integral formula,"For the Sobolev spaceWm p (Rn) with positive integer m and 1< p<¥, sometimes replaced by 1 ≤ p < ¥, we consider the case m-n/p < 0 and the case m-n/p = 0, and give new proofs of the Sobolev embedding theorems by Muramatu's integral formula. When m-n/p < 0, the embedding into Lq(Rn) with q satisfying m-n/p=-n/q is derived without the Hardy-Littlewood-Sobolev inequality by incorporating the method to prove it. When m-n/p=0, we prove the embedding into the BMO space or the VMO space as well as Trudinger's inequality.",60002561,Nihon University,Tokyo,Japan,['1710'],30.33333333333333,0.2878787878787879,0.6666666666666666,1,0.061068702290076333,0.1984732824427481,0.48623853211009177
1115,1140,1140,IDML: IDentifier-Based Markup Language for Resource-Constrained Smart Objects in WoT,"Data representation for resource-constrained Smart Objects (SOs) in Web of Things (WoT) requires compatibility, interoperability, scalability and high efficiency. However, general methods of data representation on web plane have rich extra information for data and they are not efficient; and current methods on Smart Objects are not flexible and they cannot represent complex data structures, such as relational data and hierarchical data. To represent data in resource-constrained Smart Objects flexibly and efficiently, this paper presents IDentifier-based Markup Language (IDML). When constructing the framework for IDML, three ideas are proposed, i.e., structuralization of associations between keys and their values, shortening the length of metadata identifiers, utilization nonprinting characters to control the structure of data block. In IDML, three kinds of data representation methods are designed, including sequential data, relational data, and hierarchical data. Evaluation by comparison and calculation shows that, IDML not only has the scalability and flexibility of general data representation languages on web plane, but also has high efficiency on Smart Objects. Compared with ANSI10.8.2 and JSON in a case scenario, IDML can improve efficiency up to 37.4% and 50.4% respectively.",60025278,Tsinghua University,Beijing,China,['1700'],26.0,0.09014285714285714,0.5267619047619048,1,0.08558558558558559,0.07207207207207207,0.42592592592592593
1116,1141,1141,A method of building detection in remote sensing images based on deep learning with multiple lightness detectors," CC BY 4.0 License.Buildings, where most human activities happen, are one of the most important crucial objects in remote sensing images. Extracting building information is of great significance importance for conducting sustainable development-related researches. The extracted building information is a fundamental data source for further researches, including evaluating the living conditions of people, monitoring building conditions, predicting disaster risks and so on. In recent years, convolutional neural networks have been widely employed in building detection, and have gained significant progresses. However, in these automatic detection procedures, the critical brightness information is often neglected, with all buildings simply classified into the same category. To make the building detection more efficient and precise, we propose a simple yet efficient multitask method employing several lightness detectors, each of which is dedicated to the building detection in a specific brightness interval. Experiment results show that the building detection accuracy could be improved by 8.1% with the assistance of the additional lightness information.",60025278,Tsinghua University,Beijing,China,['1710'],22.714285714285715,0.17236842105263156,0.481015037593985,0,0.1092896174863388,0.0,0.3258426966292135
1117,1142,1142,Customary standards on operative pleasure and enactment effects on employment stressors and job fulfilment: A part of fundamental appraisals,"Fundamental self-evaluations (FSE)are a broad, which combined approach, it indicated by self-fulfilment, Fundamental control, self-efficacy, and (low) neuroticism (extraordinary emotional firmness). The target of the study was to scrutinize the role of fundamentalself-evaluations and its enactment in the employment stressors and job fulfilment. one hundred and twenty eight (45 males, 83 females) of Deemed university employees completed the Measures of employment Stressors which consisted of the InteractiveCrash at Work Scale, the StructuralRestrictionsRuler, and MeasureableCapabilityPortfolio, Overall Job Fulfilment, Rosenberg Self-Esteem Scale, Generalized Self-Efficacy Scale (GSES), Personality Inventory Neuroticism Scale, Internality, Powerful Others and Chance Scale (IPC), as well as Fundamental Self-Evaluation Scale (FSEs). The negative correlation of self-esteem, generalized self-efficacy and fundamental self-evaluations among interpersonal conflict at work environment are the findings of the study. Neuroticism had a positive correlation with them. Furthermore, regression analysis of the data demonstrated that self-esteem, generalized self-efficacy, neuroticism, and Fundamental self-evaluations significantly predicted interactivecrash, organizational constraints, and job fulfilment. Therefore, based on the results it could be concluded that Fundamental self-evaluation and four traits influence the job fulfilment and employment stressors with the exclusion of quantitative workload.",60014340,SRM Institute of Science and Technology,Chennai,India,['1700'],26.0,0.1109006734006734,0.5647727272727273,1,0.04743083003952569,0.11462450592885376,0.5110132158590308
1118,1143,1143,Development of the Malaysian skills certification for TVET lecturers,"This paper describes the professional development programme(PDP) framework developed for Technical and Vocational Education and Training (TVET) lecturers under the Malaysian Skills Certification (Sijil Kemahiran Malaysia-SKM). These lecturers play an important role in the practice and application oriented (PAO) teaching in delivering engineering technology programme. The success of the academic programme relies on competent lecturers who have the knowledge, competencies and skills to conducteffective teaching and learning. Apart from teaching, TVET lecturers are expected to be competent in performing research, consultancy services and community engagement. The framework was developed using DESCUM (Develop A Standard Curriculum) method and facilitated by the Department of Skills Development (Jabatan Pembangunan Kemahiran-JPK)and published as a National Occupational Skill Standard (NOSS). The NOSS Development Committee members were lecturers of the Malaysian Technical Universities (MTUs), Universiti Kuala Lumpur, Akademi Sains Malaysia as well as from the Polytechnics. The competency units identified to be critical and important for a TVET lecturer are described in this paper. It is hoped that the professional development programme(PDP) framework for TVET lecturers will be a platform to transformTVET quality and maximize its potential to improve the national higher education and economic landscape in the long run.",60078086,Universiti Teknikal Malaysia Melaka,Malacca,Malaysia,['1700'],24.25,0.14761904761904762,0.3825396825396825,1,0.09292035398230089,0.18584070796460178,0.4824561403508772
1119,1145,1145,Framing public financial policy: Transforming the classic concept in the time of digitalization,"The financial policy of the state is framed and persued on the basis of the country's strategic development plans. Today special attention is paid to approaches to planning given the achievements of digital economy. The paper characterizes the changes that have taken place in the financial policy planning of the state following the digitalization of the economy. It is stated that when the financial policy of the state is planned in the time of digitalization, new approaches should be used so that the national financial system can adapt and react flexibly to internal and external crises, shocks, transformations. The importance of transforming public financial policy planning on new grounds is justified by the results of the country comparative analysis of indices Networked Readiness Index 2018 and Open Budget Index 2017. It is stated that in Russia the financial policy of the state must consider a whole number of innovations, for example a new construction of budget rules formulated by the RF Ministry of Finance. By and large, introduction of up-to-date technologies when registering information, analyzing, controlling and making decisions is a need and actively developing in the public sector. It leads to changing the form in which the public sector of the economy is governed in the time of digital reality. As a result of the study, it has been found out that public financial policy planning on the basis of the achievements of digital economy can create the foundations for the national financial system to react swiftly to the changes occurring in the national economy and reflect them in the financial plans of the country in due time.",60110388,Pushkin Leningrad State University,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",29.88888888888889,0.04559262576503957,0.19328631138975966,1,0.12027491408934708,0.03436426116838488,0.24738675958188153
1120,1146,1146,Deep restoration of vintage photographs from scanned halftone prints,"A great number of invaluable historical photographs unfortunately only exist in the form of halftone prints in old publications such as newspapers or books. Their original continuous-tone films have long been lost or irreparably damaged. There have been attempts to digitally restore these vintage halftone prints to the original film quality or higher. However, even using powerful deep convolutional neural networks, it is still difficult to obtain satisfactory results. The main challenge is that the degradation process is complex and compounded while little to no real data is available for properly training a data-driven method. In this research, we adopt a novel strategy of two-stage deep learning, in which the restoration task is divided into two stages: The removal of printing artifacts and the inverse of halftoning. The advantage of our technique is that only the simple first stage requires unsupervised training in order to make the combined network generalize on real halftone prints, while the more complex second stage of inverse halftoning can be easily trained with synthetic data. Extensive experimental results demonstrate the efficacy of the proposed technique for real halftone prints; the new technique significantly outperforms the existing ones in visual quality.",60031828,McMaster University,Hamilton,Canada,"['1712', '1707']",24.375,0.10364304812834224,0.4638241660300486,1,0.10185185185185185,0.013888888888888888,0.24761904761904763
1121,1147,1147,Back-translation approach for code-switching machine translation: A case study," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Recently, machine translation has demonstrated significant progress in terms of translation quality. However, most of the research has focused on translating with pure monolingual texts in the source and the target side of the parallel corpora, when in fact code-switching is very common in communication nowadays. Despite the importance of handling code-switching in the translation task, existing machine translation systems fail to accommodate the code-switching content. In this paper, we examine the phenomenon of code-switching in machine translation for low-resource languages. Through different approaches, we evaluate the performance of our systems and make some observations about the role of code-mixing in the available corpora.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],23.2,0.10992857142857143,0.4825,0,0.09285714285714286,0.04285714285714286,0.3643410852713178
1122,1148,1148,PERFORMANCE of AHI HOURLY AEROSOL OPTICAL PROPERTY during FREQUENT HAZE-FOG EVENTS: A CASE STUDY of Beijing,"The Advanced Himawari Imager (AHI) onboard Himawari-8, a next-generation geostationary meteorological satellite, provided firstly the full-disk aerosol observations every 10 min at sub-kilometer spatial resolution(5 km). This is responsible for retrieving the ground-level particulate matter of fewer than 2.5 micrometers and improving assimilation model. However, the representativeness of AHI L3 hourly Aerosol Optical Thickness (AOT) products remains unclear under different air quality conditions, Especially, over frequently polluted urban areas that feature complex surface characteristics and aerosol models. In this study, One-to-one comprehensive comparisons were conducted to evaluate the performance of three types of AHI L3 AOT products (version 3.0) based on the Aerosol Robotic NETwork (AERONET) aerosol measurements over Beijing. The overall comparisons of AHI and ground AOTs show the AHI merged AOT perform best, which the R is 0.87, RMSE is 0.25 and 52.5% of retrievals fall within the envelope of Expect Error (EE, ±(0.05 + 0.2 ∗ AOTground)). For the different primary pollutants, the results suggested the three types AHI hourly AOT products are more suitable for the fine particulate matters (PM2.5) retrievals, especially the merged AOT with 0.87 of R, 0.29 of RMSE and 58.8% of within EE. Furthermore, when the slight and moderate pollution happened over Beijing, the AHI hourly AOT products perform well. And when the heavy pollution happened, the performance of the AHI merge AOT and L2 mean AOT is better. a case during low to high pollution suggested that AHI merged AOT can capture the similar spatial pattern to the MODIS (Deep Blue) DB or (Dark Target) DTDB merged AOT and has good consistency with ground-based air quality monitoring. These results demonstrate the AHI hourly merged AOT is a promising aerosol retrieval for air quality.",60029306,Wuhan University,Wuhan,China,['1710'],28.2,0.13825,0.46425,1,0.08504398826979472,0.16422287390029325,0.4954682779456193
1123,1149,1149,SPATIOTEMPORAL ANALYSIS of the URBAN COOLING ISLAND (UCI) EFFECT of WATER SPACES in A HIGHLY URBANIZED CITY: A CASE STUDY of ILOILO RIVER and ADJACENT WETLANDS,"Iloilo City, a highly urbanized city in the Philippines, experiences intensified climate change impacts due to the Urban Heat Island (UHI) phenomenon, one of which is the significant increase in temperature. To mitigate UHI, recent studies investigated the cooling effect of water bodies due to its higher rate of evapotranspiration compared to green spaces. This study aims to spatiotemporally assess the Urban Cooling Island (UCI) effect of Iloilo River and adjacent wetlands on the surrounding microclimate using geospatial techniques. Landsat images were processed to generate land surface temperature (LST) and land cover layers of the study area for the years 1994, 1998, 2003, 2005, 2013, 2016, and 2019. UCI Scale (influence range of the cooling effect), Temperature Difference (difference in temperature between water space and the area within the UCI scale), and UCI Intensity (temperature gradient within the UCI scale) were calculated using multiple-ring buffers with 50-m interval to quantify variations in cooling effect of the water space at distinct surrounding regions over a long time period. Results of the study show that wetland area has a weak negative relationship with the UCI indices which could mean that cooling effect is not solely dependent on wetland size, while moderate to very strong negative correlations were calculated between temperature difference and precipitation (r Combining double low line-0.48 to-0.82). Furthermore, rapid expansion of built-up areas at different sections along the river have resulted to reduced UCI scale (r Combining double low line-0.37 to-0.75) and stronger cooling intensity (r Combining double low line 0.55 to 0.84).",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],36.142857142857146,-0.005798611111111111,0.38253472222222223,1,0.0945945945945946,0.09121621621621621,0.4006849315068493
1124,1150,1150,Text detection using MGAPfor hangeul text feature map in convolutional neural network,". All rights reserved.In this paper, we propose a text detection method that improves the feature map of Hangeul text area using MGAP (Modified Global Average Pooling) for accurate detection of Hangeul text area. TheCNN(Convolutional Neural Network) based text region detection algorithm has result of detect a background region and including a non-text element. In order to solve these problems, we proposed an MGAP method that applied multiple filters to improve the area where text features were detected in non-text areas.The feature map of text generated by MGAP also contains some background areas, so accurate text detection is not possible.To solve this, we separated the text and background into K-means clustering by using the feature that the color of the text is the same. The final text region was extracted by comparing the clustering result image and the feature map using MGAP.In the case of Hangeul, the problem that consonants and vowels are detected separately was improved by using the structural features of Hangeul. The experimental data set was experimented with KAIST data set consisting of Hangeul and English text images. The proposed method shows an improvement on 1.7% for the English data set, 2.5% for the Hangeul data set, and 1.8% for the English and Hangeul data set when compared to the existing text detection method.",60013866,Kwangwoon University,Seoul,South Korea,['1700'],31.0,0.06818181818181819,0.2901515151515152,1,0.12903225806451613,0.09274193548387097,0.3403361344537815
1125,1151,1151,Job scheduling in cloud computing based on adaptive job size based queuing process,"Cloud computing is one of the most emerging distributed technology. It enables remotes accessing, storing, retrieving and processing of data from anywhere anytime. The main feature of this cloud technology is resource sharing at highly reliable and securable mode. The vast usage of this technology with several features had a greater impact, especially in the need for efficient methodology in resource management. Generally, there are two main components in cloud computing such as task scheduling and resource allocation. In the cloud, the major process is the computing of remote data centers. Resource scheduling and task execution are one of the major problems that still exist. It needs effective resource utilization that is assigning of available resources according to the request equally. The major issue still existing in cloud computing is time and computation cost. In this paper, we propose an Adaptive Work Size Based Queuing Process (AWSQP), this enables quick data access to the virtual machine (VM’s). The main principle is to achieve quick processing, task priority and minimum sized task are taken for the queue. At the same time, the task is executed within the deadline but without increasing the cost. Our proposed mechanism AWSQP works effectively based on the data size and chooses the best cost-effective path. The data access completion time is evaluated by the request/response time along with the mean and variance of the network service time. Then AWSQP applies the best path for the task with high priority and continues the same for the entire queue. Based on the proposed task scheduling mechanism, an experiment is conducted between CETS, ACTS, and AWSQP on the aspects of computation cost, communication cost, execution time, CPU utilization and bandwidth. The obtained results prove that achieved performance by AWSQP is far better than the existing approaches.",60115038,CARE Group of Institutions,Tiruchirappalli,India,['1700'],17.470588235294116,0.2170555555555556,0.48975,1,0.08875739644970414,0.038461538461538464,0.31044776119402984
1126,1153,1153,Deep learning human activity recognition," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Human activity recognition is an area of interest in various domains such as elderly and health care, smart-buildings and surveillance, with multiple approaches to solving the problem accurately and efficiently. For many years hand-crafted features were manually extracted from raw data signals, and activities were classified using support vector machines and hidden Markov models. To further improve on this method and to extract relevant features in an automated fashion, deep learning methods have been used. The most common of these methods are Long Short-Term Memory models (LSTM), which can take the sequential nature of the data into consideration and outperform existing techniques, but which have two main pitfalls; longer training times and loss of distant pass memory. A relevantly new type of network, the Temporal Convolutional Network (TCN), overcomes these pitfalls, as it takes significantly less time to train than LSTMs and also has a greater ability to capture more of the long term dependencies than LSTMs. When paired with a Convolutional Auto-Encoder (CAE) to remove noise and reduce the complexity of the problem, our results show that both models perform equally well, achieving state-of-the-art results, but when tested for robustness on temporal data the TCN outperforms the LSTM. The results also show, for industry applications, the TCN can accurately be used for fall detection or similar events within a smart building environment.",60025160,University College Cork,Cork,Ireland,['1700'],33.57142857142857,0.12127744050820975,0.44842080995927147,0,0.10431654676258993,0.08633093525179857,0.35471698113207545
1127,1154,1154,"A comparative assessment of remote sensing imaging techniques: Optical, sar and lidar","Remote sensing is a popular technique that is using in the mapping and monitoring of earth features. Early remote sensing was predominantly passive, i.e. it depends upon the sun for energy. Till the last decade, optical imaging is mainly used in remote sensing works. Over the time, significant innovations and improvements have been made in the active remote sensing which resulted in the form of sophisticated imaging techniques like Synthetic Aperture RADAR (SAR) and Light Detection And Ranging (LiDAR). These advancements promoted the use of multi-sensor and multi-source data in remote sensing projects. This highlights the need to review these imaging techniques. Therefore, this review work is carried out. In this review, different imaging techniques are discussed and compared. Optical, SAR and LiDAR techniques are first summarized and then they are compared on the basis of technical specification and working. Finally, an in-depth assessment is made on the applicability of these imaging techniques in different fields.",60000846,Motilal Nehru National Institute of Technology Allahabad,Allahabad,India,['1710'],14.181818181818182,0.09768518518518518,0.4671296296296296,1,0.08196721311475409,0.03278688524590164,0.4438202247191011
1128,1155,1155,Towards a categorical representation of reversible event structures,"We study categories for reversible computing, focussing on reversible forms of event structures. Event structures are a well-established model of true concurrency. There exist a number of forms of event structures, including prime event structures, asymmetric event structures, and general event structures. More recently, reversible forms of these types of event structure have been defined. We formulate corresponding categories and functors between them. We show that products and coproducts exist in many cases. We define stable reversible general event structures and stable configuration systems, and we obtain an isomorphism between the subcategory of the former in normal form and the finitely enabled subcategory of the latter. In most work on reversible computing, including reversible process calculi, a causality condition is posited, meaning that the cause of an event may not be reversed before the event itself. Since reversible event structures are not assumed to be causal in general, we also define causal subcategories of these event structures.",60015150,Imperial College London,London,United Kingdom,"['1712', '1703']",17.444444444444443,0.1954545454545454,0.4136363636363637,1,0.10674157303370786,0.0,0.32386363636363635
1129,1156,1156,"Digital modeling of strategic sustainability assessments: New approach, recommendations, prospects","The object of this study is digital assessments of the strategic sustainability of enterprises. The motivation for this study was, on the one hand, the role and importance of scientific management of strategic sustainability of enterprises for regions, especially the depressed ones, and the Russian economy as a whole, in the face of growing market turbulence, and on the other hand, the lack of development of methods and models in this area . To build models and their verification, methods of system modeling, causal analysis, content analysis, strategic analysis and forecasting were used. The main scientific results are: a new digital model of strategic sustainability, based on a causal model of key criteria for strategic sustainability and including three levels (zones) of strategic enterprise unsustainability; a new principle of priority in orienting digital assessments of strategic sustainability to present and future changes in the external and internal environment instead of the universally applied retrospective analysis used today; a new classification of scientific approaches to the study of company sustainability by the criterion of objectivity of results; new key indicators and boundaries of strategic unsustainability zones; a brief algorithm for the formation of final integrated digital assessments of the strategic sustainability of enterprises on the basis of partial criteria and threshold models. As proposals developed recommendations for the Ministry of economic development on the addition of the Order of Ministry of economic development of the Russian Federation from March 23, 2017 N 132 by the provision of the necessary digital calculations of strategic sustainability of enterprises in the 3, 5 and 10 years, as well as recommendations for the Ministry of science and higher education of the Russian Federation to stimulate development of new areas of research - digital simulation of strategic sustainability of enterprises in the universities and research institutes . The main findings of the study are: the identification and formulation of a new problem of the absence in strategic management of digital assessments of the strategic sustainability of enterprises; the rationale for the transition from standard retrospective statistical methods to priority system digital models built on the basis of models of cause-effect relationships, and the use in theory and practice of management of new digital criteria and models for assessing the strategic sustainability of enterprises.",60031888,Saint Petersburg State University,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",62.83333333333334,0.048789726533628966,0.28492239467849223,1,0.029411764705882353,0.0196078431372549,0.25862068965517243
1130,1157,1157,"Microwave drying of wood, mathematical simulation of rotating lumber in the SHF field","Lumber drying is one of the most important and integral operations in the woodworking processes, that largely determines the finished products quality and competitiveness. As a result of drying, wood is transformed from a natural raw material into an industrial environmentally friendly material meeting the various requirements in different industrial or domestic applications. The issues of high-quality and high-speed wood drying using the energy of an ultra-high frequency electromagnetic field have not been studied in depth, which complicates the practical use of this drying method. This applies to ensuring a uniform volumetric SHF heating and the required quality of wooden beams and planks. The paper suggests a mathematical simulation for drying lumber by rotating it in the SHF field in a process plant with a discrete arrangement of magnetrons. The mathematical simulation is implemented in the object-visual simulation environment of MatLab (Simulink). We studied 4 operating modes of the process plant. Based on the research, we developed a computer software for simulating SHF lumber drying in various modes. The ability to choose between SHF lumber drying modes reduces the lumber processing energy costs. The results of this study can be applied in the woodworking industry for SHF drying of various types of wood.",60095509,Bashkir State Agrarian University,Ufa,Russian Federation,['1700'],20.3,0.09723443223443223,0.386007326007326,1,0.09251101321585903,0.013215859030837005,0.2785388127853881
1131,1158,1158,"MODELLING, SIMULATION and VISUALIZATION of A MULTISPECIFIC PHILIPPINE SEAGRASS MEADOW","Seagrass meadows are constantly under threat from natural and man-made stresses due to its shallow existence in the coastal environment. Restoration and preservation of seagrasses by means of rehabilitation or transplanting strategies is possible, but the studies have been limited. An agent-based model of a mixed Philippine seagrass meadow is presented. Three species were used for testing: Enhalus acoroides, Thalassia hemprichii, and Cymodocea rotundata. The model features parameter-based clonal growth of seagrass species, recruitment of new seagrass apices through basic flowering/seeding, and a crowding logic for multiple coexisting species in a single meadow. Seagrass clonal growth is modeled using a modified Diffusion-Limited Aggregation (DLA) model. Each species has a preconfigured set of parameters for clonal growth including rhizome elongation, branching rate, vertical elongation rate, rhizome branching angle and shoot age. Seed recruitment is applied through occasional flowering/seeding events configurable per species. We developed a simple three-species competition model which controls the growth and direct competition effects based on a configurable population size and comparison radius. Upon further calibration and validation, the model would enable more accurate long-term predictions for different rehabilitation and transplanting strategies of mixed seagrass meadows. Further improvements can also be implemented, particularly taking into account the environmental variables within the meadows such as light attenuation and salinity, among other factors.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],19.363636363636363,0.04707359307359308,0.3947532467532467,1,0.11023622047244094,0.031496062992125984,0.36554621848739494
1132,1159,1159,A reduction semantics for direct-style asynchronous observables,"Asynchronous programming has gained in importance, not only due to hardware developments like multi-core processors, but also due to pervasive asynchronicity in client-side Web programming and large-scale Web applications. However, asynchronous programming is challenging. For example, control-flow management and error handling are much more complex in an asynchronous than a synchronous context. Programming with asynchronous event streams is especially difficult: expressing asynchronous stream producers and consumers requires explicit state machines in continuation-passing style when using widely-used languages like Java. In order to address this challenge, recent language designs like Google's Dart introduce asynchronous generators which allow expressing complex asynchronous programs in a familiar blocking style while using efficient non-blocking concurrency control under the hood. However, several issues remain unresolved, including the integration of analogous constructs into statically-typed languages, and the formalization and proof of important correctness properties. This paper presents a design for asynchronous stream generators for Scala, thereby extending previous facilities for asynchronous programming in Scala from tasks/futures to asynchronous streams. We present a complete formalization of the programming model based on a reduction semantics and a static type system. Building on the formal model, we contribute a complete type soundness proof, as well as the proof of a subject reduction theorem which establishes that the programming model enforces an important state transition protocol for asynchronous streams.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1703']",24.222222222222218,0.036403508771929834,0.5263157894736843,1,0.09302325581395349,0.01937984496124031,0.3458333333333333
1133,1160,1160,"CHEMICAL COMPOSITION of AEROSOLS in the WEST COAST of Taiwan STRAIT, CHINA","The chemical composition of aerosols was investigated using regular environmental air quality observation, a single particle aerosol mass spectrometer (SPAMS 0515) and an ambient ion monitor (URG 9000D) in Xiamen in 2018. The results showed that the annual average mass concentrations of PM2.5 was 22 μm/m3, and concentrations of water-soluble inorganic ions was 9.94 μm/m3 which accounted for 45.2% of PM2.5. SO42, NO3 and NH4+ were main components of secondary reactions which contributed more than 77 percent of water-soluble inorganic ion concentration. As a coastal city, Cl and Na+ contributed 13.9 percent of water-soluble inorganic ion concentration. Based on single particle aerosol mass spectrometer analysing, mobile sources emission was the most important sources of particle matter which contributed over 30%.",101229912,Xiamen Meteorological Bureau,Xiamen,China,['1710'],24.0,0.1082010582010582,0.3932030932030932,1,0.05442176870748299,0.10884353741496598,0.4264705882352941
1134,1161,1161,Towards an optimal set of initial weights for a deep neural network architecture," All rights reserved.Modern neural network architectures are powerful models. They have been proven efficient in many fields, such as imaging and acoustic. However, these neural networks involve a long-running and time-consuming process. To accelerate the training process, we propose a two-stage approach based on data analysis and focus on the gravity center concept. The neural network is first trained on reduced data represented by a set of centroids of the original data points, and then the learned weights are used to initialize a second training phase of the neural network over the full-blown data. The design of deep neural networks is extremely difficult, and the primary objective is to achieve high performance. In this study, we apply the Taguchi method to select good values for the factors required to build the proposed architecture.",60105374,Université Abdelhamid Mehri Constantine 2,Constantine,Algeria,"['1712', '1708', '1702']",19.142857142857142,0.16038461538461538,0.4864102564102565,0,0.1337579617834395,0.006369426751592357,0.2671232876712329
1135,1162,1162,Methods and techniques for data quality improvement of (linked) (open) data," All rights reserved.Good decisions need good data. Hence, only by exploiting good data it is possible to make effective decisions. The goodness of data is usually related to the task they will be used for. However, it is possible to identify some task-independent quality dimensions which are merely related to the data themselves. In order to improve the intrinsic data quality, we propose a proactive approach. Our goal is to offer data providers (and consumers) a set of methods and techniques to guide them in assessing and improving the quality of data they are interested in. We mainly focus on Linked (Open) Data. Since the published data might also contain personal data, there is the need to make the data set compliant with the General Data Protection Regulation (GDPR). Therefore, besides quality problems, we are also interested in discovering any privacy breach and - if needed - in proposing corrective actions. The final goal is to give data providers the possibility of publishing better data. The proposed approach is pragmatic. Thus, we will not only design but also implement it. We plan to wrap it into a social platform, already used by several public administrations, which enable us to test the applicability of the proposed methods in real settings.",60007061,Università di Salerno,Salerno,Italy,['1700'],16.153846153846153,0.16428571428571428,0.5412698412698413,0,0.1446280991735537,0.03305785123966942,0.31223628691983124
1136,1163,1163,A new approach for phase field modeling of grain boundaries with strongly nonconvex energy,"Grain boundaries (GBs) are key players in determining macroscopic material behavior and driving the creation of microstructure in nanocrystalline materials. Microstructure typically features irregular features and morphology such as microfaceting, due to the strong nonconvexity of GB energy with respect to boundary plane orientation. Mesoscale simulation of microstructure evolution can be done effectively using the multiphase field (MPF) method. However, strongly nonconvex boundary energies present numerical challenges in MPF simulations. The lack of convexity in GB energy causes the minimal GB energy problem to be mathematically ill-defined. Numerically, this causes mesh dependency and instability. In this work we present an additively decoupled regularization scheme utilizing a K 23 second order curvature regularization to penalize regions of sharp curvature induced by nonconvex GB energy. Physically, the K 23 regularization corresponds to corner or triple junction dislocations, and does not adversely affect the diffuse properties of the GB or the GB energy. It is shown that the additively decoupled K 23 regularization term admits a numerically convenient variational derivative, when evolved in the eigenbasis of the Hessian curvature tensor. This enables K 23 to be determined in terms of derivatives in the natural coordinate system, which is advantageous for implementations on a regular grid. The faceting behavior in GBs is demonstrated using a parallel adaptive mesh refinement code. It is shown that faceting is stable even if the GB energy exhibits cusps and the regularization parameter effectively controls the faceting length scale. Evolution of an inclusion is studied for smooth and non-smooth GB energies and results are compared against analytic Wulff shapes. The proposed scheme leverages Lagrange multipliers to use a modified fourth order Allen-Cahn system in lieu of a sixth order Cahn-Hilliard system for numerical efficiency.",60010265,University of Colorado at Colorado Springs,Colorado Springs,United States,['1706'],20.357142857142858,0.1025,0.3955723443223443,1,0.11006289308176101,0.08176100628930817,0.3419354838709677
1137,1164,1164,A Network Embedding and Clustering Algorithm for Expert Recommendation Service,"Network embedding algorithm is dedicated to learning the low-dimensional representation of network nodes. The feature representations can be used as features of various tasks based on graphs, including classification, clustering, link prediction and visualization. Currently, network embedding algorithms have evolved from considering structures only to considering structures and contents both. However, how to effectively integrate the high-order proximity and node content of the network structure is still a problem to be solved. We propose a new network embedding and clustering algorithm in this paper. We obtain the high-order proximity representation of the information network structure, and the fusion node content completes the low-dimensional representation of the node features, so as to complete the network node clustering for the input of the spectral clustering. In order to further verify the value of the algorithm, we apply the clustering results to the field of expert recommendation, and make influence and activity assessments for domain experts to achieve more valuable expert recommendations. The experimental results show that the proposed algorithm will obtain higher clustering accuracy and excellent expert recommendation results.",60009400,Nanjing University of Post and TeleCommunications,Nanjing,China,['1700'],22.125,0.24421487603305786,0.5867768595041323,1,0.13366336633663367,0.0,0.26288659793814434
1138,1165,1165,SPATIAL and TEMPORAL VARIATION of TOTAL and TROPOSPHERIC OZONE COLUMNS over CHINA,"In this study, total ozone columns collected from nine sites of the AErosol RObotic NETwork (AERONET) in China are used to evaluate total ozone column monthly mean products of the Ozone Monitoring Instrument (OMI). The results show the correlated coefficient of the two datasets is 0.95. The long temporal variations and spatial distributions of the monthly mean products of the total ozone columns and tropospheric ozone columns in spring, summer, autumn and winter were plotted. The result shown in the pictures indicate that the total ozone columns gradually increase from low latitude to high latitude, reach the maximum value in winter and spring in Northeast China, and the values in Qinghai-Tibet Plateau are lower than those of other regions of the same latitude. The monthly mean of total ozone columns at low latitude have no obvious seasonal variation. With the increase of latitude, the seasonal variation of monthly mean products of total ozone column becomes more and more obvious. Tropospheric ozone columns are the highest in summer, followed by spring and autumn, and the lowest in winter, which are mainly concentrated in the more developed areas in eastern China. The lowest value of tropospheric ozone column in China occurs in the Qinghai-Tibet Plateau in winter and the highest value in North China in summer. The study indicates that the total ozone columns vary with latitude while tropospheric ozone columns are more susceptible to human activities and natural conditions.",60004691,Jiangsu Normal University,Xuzhou,China,['1710'],26.444444444444446,0.035773809523809534,0.5133333333333334,1,0.06060606060606061,0.07954545454545454,0.2923076923076923
1139,1166,1166,RESEARCH on INVERSION of LIDAR EQUATION BASED on NEURAL NETWORK,"Lidar is an advanced atmospheric and meteorological monitoring instrument. The atmospheric aerosol physical parameters can be acquired through inversion of lidar signals. However, traditional methods of solving lidar equations require many assumptions and cannot get accurate analytical solutions. In order to solve this problem, a method of inverting lidar equation using artificial neural network is proposed. This method is based on BP (Back Propagation) artificial neural network, the weights and thresholds of BP artificial neural network is optimized by Genetic Algorithm. The lidar equation inversion prediction model is established. The actual lidar detection signals are inversed using this method, and the results are compared with the traditional method. The result shows that the extinction coefficient and backscattering coefficient inverted by the GA-based BP neural network model are accurate than that inverted by traditional method, the relative error is below 4%. This method can solve the problem of complicated calculation process, as while as providing a new method for the inversion of lidar equations.",60006422,Northwest University for Nationalities,Lanzhou,China,['1710'],18.11111111111111,-0.02575757575757575,0.5174482924482926,1,0.11956521739130435,0.09239130434782608,0.3241758241758242
1140,1167,1167,A PRELIMINARY STUDY on UPDATING HIGH DEFINITION MAPS: DETECTING and POSITIONING A TRAFFIC CONE by USING A STEREO CAMERA,"The concept of Autonomous Vehicles (AV) or self-driving cars has been increasingly popular these past few years. As such, research and development of AVs have also escalated around the world. One of those researches is about High-Definition (HD) maps. HD Maps are basically very detailed maps that provide all the geometric and semantic information on the road, which helps the AV in positioning itself on the lanes as well as mapping objects and markings on the road. This research will focus on the early stages of updating said HD maps. The methodology mainly consists of (1) running YOLOv3, a real-time object detection system, on a photo taken from a stereo camera to detect the object of interest, in this case a traffic cone, (2) applying the theories of stereo-photogrammetry to determine the 3D coordinates of the traffic cone, and (3) executing all of it at the same time on a Python-based platform. Results have shown centimeter-level accuracy in terms of obtained distance and height of the detected traffic cone from the camera setup. In future works, observed coordinates can be uploaded to a database and then connected to an application for real-time data storage/management and interactive visualization.",60014982,National Cheng Kung University,Tainan,Taiwan,['1710'],24.625,0.13366666666666668,0.43083333333333335,1,0.09623430962343096,0.03347280334728033,0.35874439461883406
1141,1168,1168,From Attribute Relationship Diagrams to Process (BPMN) and Decision (DMN) Models,"Business Process Model and Notation (BPMN) is a well established standard for modeling and managing process knowledge of organizations. Recently, the Decision Model and Notation (DMN) standard has been proposed as a complementary technique to enact particular type of knowledge, namely the organizational rules (decision logic). An integrated model of processes and rules may bring numerous benefits to the knowledge management systems, but the modeling process itself is not a trivial task. To this end, methods that facilitate prototyping and semi-automatic construction of the integrated model are of great importance. In this paper, we propose a method for generating business processes with decisions in BPMN+DMN standards, using a prototyping method called ARD. We present an algorithm that, starting from an ARD model, generates an executable process model along with decision specification. Such a model can be treated as a structured rule base that provides explicit inference flow determined by the process control flow.",60017351,AGH University of Science and Technology,Krakow MP,Poland,['1700'],21.857142857142854,0.016666666666666663,0.3433333333333334,1,0.11363636363636363,0.0625,0.3563218390804598
1142,1169,1169,Factor scoring the total potential of a region as a tool for strategically managing innovation in its socio-economic development,"The total potential of a region is the generalizing quantitative and qualitative characteristic of the presence and use of all types of resources available to the region for its innovative economic and social development. Assessing the total potential is an important part of strategic management. This is used when coming up with strategies for the long-term development of a region. This paper shows the interrelation between factor scoring the total potential of a region and choosing a plan for its socioeconomic growth. Research data on growth factors for Russian cities with a population under 500,000 people were used as the base of evidence. Studies in the region were carried out in order to improve the innovation environment and determine the ""problem area"" in its socio-economic growth. The research was based on the use of the main methodology approach for assessing the potential, problems and possibilities, risks of a region's development, without reference to the goals and objectives of its development. Studying the growth trends of the region's potential as a generalizing characteristic for the level of economic growth and as a basis for strategic innovation management was done based on the dynamic analysis of statistical data and factor scoring the potential of a region. Our research shows that all factors positively correlate with one another and can influence the management decision for choosing a plan for the socio-economic development of any territory. The studies show that factor scoring the total potential of a region can be used as a tool for the strategic management of innovations in its socio-economic growth.",60021331,Russian Academy of Sciences,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",26.0,0.04974747474747476,0.6602272727272727,1,0.09473684210526316,0.0,0.17328519855595667
1143,1170,1170,"SPATIOTEMPORAL MULTI-SATELLITE BIOPHYSICAL DATA ANALYSIS of the EFFECT of URBANIZATION on LAND SURFACE and AIR TEMPERATURE in BAGUIO CITY, PHILIPPINES","Urbanization can be observed through the occurrence of land-use changes as more land is being transformed and developed for urban use. One of the Philippine cities with high rate of urbanization is Baguio City, known for having a subtropical highland climate. To understand the spatiotemporal relationship between urbanization and temperature, this study aims to analyze the correlation of urban extent with land surface and air temperature in Baguio City using satellite-based built-up extents, land surface temperature (LST) maps, and weather station-recorded air temperature data. Built-up extent layers were derived from three satellite images: Landsat, RapidEye and PlanetScope. Land-use land cover (LULC) maps were generated from Landsat images using biophysical indices such as Normalized Difference Vegetation Index (NDVI) and Normalized Difference Built-up Index (NDBI); while RapidEye and PlanetScope built-up extent maps were generated by applying the visible green-based built-up index (VgNIR-BI). Mean LST values from 1988 to 2018 during the dry and wet seasons were calculated from the Landsat-retrieved surface temperature layers. The result of the study shows that the increase in the built-up extent significantly intensified the LST during the dry season which was observed in all satellite data-derived built-up maps: RapidEye+PlanetScope (2012-2018; r Combining double low line 0.88), Landsat 8 (2012-2018; r Combining double low line 0.63) and Landsat 5,7,8 (1988-2018; r Combining double low line 0.61). The main LST hotspots were detected inside the Central Business District where it expanded gradually from year 1998 (43 ha) to 2011 (83 ha), but have increased extensively within the years 2014 to 2019 (305 ha). On average, 98.5% of the hotspots detected from 1995 to 2019 are within the equivalent built-up area.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],30.11111111111111,0.02884920634920635,0.3437698412698412,1,0.10985915492957747,0.09577464788732394,0.4794952681388013
1144,1171,1171,A Knowledge-Based Conceptual Modelling Approach to Bridge Design Thinking and Intelligent Environments,"One aspect of knowledge management is concerned with the alignment between what is captured in the heads of people and what is encoded by technology. The alignment of knowledge is necessary as humans possess an efficient ability to design innovation based on business insights, while technological systems are able to operating efficiently in different environments. To support knowledge management, this study presents systematic foundations covering a knowledge-based conceptual modelling approach. On a systematic level, three procedures are presented to facilitate the alignment of knowledge between people and technology: the decomposition of concepts from design thinking in conceptual models, the abstraction of capabilities from intelligent environments in conceptual models, and the (semi-) automated, intelligent transformation of conceptual models. Furthermore, the architecture of ICT infrastructure supporting the three procedures is addressed. These systematic foundations are integrated in the OMiLAB ecosystem and instantiated in two projects. The first project revolves around PRINTEPS, which is a framework to develop practical Artificial Intelligence. The second project revolves around s*IoT, which is a unifying semantic-aware modelling environment for the Internet of Things. Additionally, two concrete cases are presented for both project. Due to employing common systematic foundations, transfer and reuse among the two projects is facilitated.",60025997,Keio University,Tokyo,Japan,['1700'],20.0,0.14375,0.5652777777777778,1,0.11403508771929824,0.021929824561403508,0.34513274336283184
1145,1172,1172,Becoming familiar: How infrastructure engineers begin to use collaborative virtual reality in their interdisciplinary practice," This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.The design community has recently shown increased interest in using virtual reality (VR) in project review contexts. While single-user headsets currently attract most VR-related attention, room-like immersive VR environments can help facilitate design team engagement and shared exploration of projects. However, to date relatively little research concerns how large-scale VR environments are used in and adapted for professional practice. To address this gap, we set up a bespoke portable VR display system called 3D-MOVE in a major UK construction office to investigate how project team members used and evaluated collaborative VR processes. Over a three-month period, we conducted ten video-recorded VR sessions to observe how engineering professionals familiarize themselves with VR in order to help inform its deployment in practice. The study results show that emergent discussions about design models and questioning of design-related assumptions dominated all observed sessions, even though they were staged as technology demonstrations; which supports the social aspects of large-scale collaborative VR processes. However, before participants could focus on design review, they had to familiarize themselves with the VR technology and time required to do so varied depending on the complexity of the VR configuration. As the participants engaged with the VR environment, they reflected on their processes, requirements and expectations and provided feedback for improving the VR experience. Articulating this familiarization with collaborative VR can inform its deployment with respect to minimizing the learning curve and any distractions or discomfort associated with its use while maximizing the aspects of value-added collaborative engagement. Additional considerations concerning content, interactivity and logistics emerged as necessary to address before VR technologies can become standard practice.",60015150,Imperial College London,London,United Kingdom,['1706'],30.1,0.09222222222222223,0.3777777777777777,0,0.15625,0.017045454545454544,0.3413897280966767
1146,1173,1173,Information Technology and Innovation in Taxpayer Registration and Numbering: National and International Experience,"The paper considers usage of mobile cloud computing in most regulated procedures of tax administration - taxpayer registration and numbering. The literature review of the research devoted to issues of digital taxation, tax control, tax procedures, general or specific for some states, shows a lack of scientific studies in the inter-country analysis devoted the above-mentioned issues. Therefore, relying on the experience of difference states, the authors set goals of the current research, which are to identify positive and negative aspects of integrating information and communication technologies in registering and accounting tax procedures; to come up with guidelines for tax procedure improvements. The research was conducted by two groups of countries with different geographical locations: economically developed countries (USA, United Kingdom, Switzerland, Sweden) and developing countries (Mexico, Kenya, Indonesia, Mongolia), and the Russian Federation. Based on the data of the ""The Global Competitiveness Index 4.0"" 2018 rankings (World Economic Forum), the authors evaluated digitalization in the countries under analysis and its impact on tax relations. The World Bank ""Paying Taxes"" rankings 2011- 2019 showed development of the particular tax subsystem - tax administration, determined by the intensive use of progressive technologies. The given paper presents brief characteristics of online services, mobile applications, and other software used now in the countries under analysis. The characteristics resulted from current information from websites of tax regulatory agencies in the countries. The comparative analysis as the main research method made the foundation for both general conclusions and guidelines common for all the states, and individual features that concern the Russian system of tax administration. For this purpose, the authors used the guide of the International Monetary Fund. Suggestions for improvement of tax registering and accounting procedures in Russia cover the current problems in this sphere, including long-term prospects.",60107804,The Russian Presidential Academy of National Economy and Public Administration,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",26.63636363636364,0.0319828722002635,0.3106719367588933,1,0.08746355685131195,0.0728862973760933,0.4094955489614243
1147,1174,1174,Application of Gaussian process autoregressive models for capturing the time evolution of microstructure statistics from phase-field simulations for sintering of polycrystalline ceramics,"While phase-field models have been demonstrated to be highly versatile in performing physics-based simulations of a large variety of materials phenomena involving microstructure evolution (e.g. phase transformation, recrystallization, sintering), they are not practical for rapid exploration of the process design space due to their high demand for computational resources. The extraction of reliable and robust reduced-order models from the microstructure evolution datasets produced by such sophisticated physics-based models continues to be an unsolved problem. Recent advances in the fast computation of a comprehensive set of microstructure statistics and their data-driven low-dimensional representations using principal component analyses have resulted in the successful extraction of practically useful reduced-order models connecting the microstructure statistics and the effective properties exhibited by the material. In this paper, we explore for the first time, the viability of these low-dimensional representations of the microstructure statistics for establishing reduced-order models capable of learning the important details of the microstructure evolution predicted by the computationally expensive phase-field models. More specifically, we will explore the viability of applying the Gaussian process autoregressive models used in the fields of statistics and signal processing for problems in microstructure evolution. This will be accomplished using a specific case study dealing with the time evolution of porous microstructures in sintering of polycrystalline ceramics.",60102538,Karlsruhe Institute of Technology,Karlsruhe,Germany,['1706'],29.857142857142854,0.21162698412698414,0.5301058201058201,1,0.1111111111111111,0.0,0.29910714285714285
1148,1175,1175,Using digital technologies to train new generation employees against the background of problems accompanying the formation of an innovative educational environment,"The young generation's ability to perceive and process information boosts the use of digital technologies in personnel training. While stressing the importance of digital technologies and their comprehensive penetration into daily living activities, we find it a must to identify and measure their contribution into teaching methods and forms. Present-day economic problems impact the staffing; therefore, we need the triggers that may improve the production efficiency. The present-day pace of life features an intensive renewal of social, economic, and political processes, and such distinctive features, typical for the young generation, as mobility and intensive learning capabilities, help young people to get accustomed to the present-day environment, to get integrated into the structure of social relations and organizational changes. Digital technologies become vital for the educational environment as they help to adjust to these transformations and to boost this breakthrough by fulfilling the functions of reproduction, innovation, and transmission.These issues were brought up within the framework of a sociological survey, launched at several Moscow institutions of higher education. According to its findings, many young respondents use digital technologies to communicate and to study, although they believe that no complete virtualization of their education is expedient.",60032982,Financial University under the Government of the Russian Federation,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",32.33333333333333,0.07954545454545456,0.2401515151515152,1,0.12053571428571429,0.004464285714285714,0.2638888888888889
1149,1176,1176,Demand for logistics management studies in North Eastern Thailand,"The research investigates the demand on education in the field of logistics management among the high school and vocational students at North Eastern of Thailand. The research explores the needs for labor market in logistics between the private enterprises and government agencies. The surveys were conducted among 830 respondents which include students, entrepreneurs, public and private enterprises through in-depth interviews and brainstorming sessions. The result indicates that the needs for further education among students, mostly female, aged between 19-21 years old. A total of 72.30 % required the logistics disciplines in future businesses (4.31, SD = 0.962). The nature of the curriculum should be focusing on logistics theory (4.35, SD = 0.962). The equation of multiple regressions showed that the logistics education met the labor market (Dem), income level of the parents (inc), distance from home to schools (Dis) and the labor demand in Logistics dropped even at the Northeast. The entrepreneurs and the private sectors indicated to 70 %, 18 %, state agencies, enterprises and other organizations in 12 % which agreed on education for better development in logistics market. Personnel in logistics is critical for the future (4.31, SD = 0.692), demand for logistics in trades border (4.12, SD = 0.798), transportation movement at the Northeast links with neighbouring countries (4.12, SD = 0.798) and personnel logistics with a good command of English (4.01, SD = 0.561). The exhibit shows slightly reduction on logistics trend at the Northeast due to knowledge and education. Logistics shall be the important factors due to growing of business volumes, enhance on its competitiveness and focusing on costs reduction. The government policy was very encouraging towards logistics businesses. The demand for logistics personnel are increasing and this will contribute to the economic growth at the North East. Suggestion for future development is to have a real learning on the logistics theory through government and private partnership. This will enable the best of logistics education towards improvement and quality labor for better economic in Thailand. Copyright",60020586,Loei Rajabhat University,Loei,Thailand,['1710'],20.75,0.12317204301075267,0.3512903225806452,1,0.06201550387596899,0.04392764857881137,0.3733681462140992
1150,1177,1177,Small-Scale Data Classification Based on Deep Forest,"Developing effective and efficient small-scale data classification methods is very challenging in the digital age. Recent researches have shown that deep forest achieves a considerable increase in classification accuracy compared with general methods, especially when the training set is small. However, the standard deep forest may experience over-fitting and feature vanishing in dealing with small sample size. In this paper, we tackle this problem by proposing a skip connection deep forest (SForest), which can be viewed as a modification of the standard deep forest model. It leverages multi-class-grained scanning method to train multiple binary forest from different training sub-dataset of classes to encourage the diversity of ensemble and solve the class-imbalance problem. To expand the diversity of each layer in cascade forest, five different classifiers are employed. Meanwhile, the fitting quality of each classifiers is taken into consideration in representation learning. In addition, we propose a skip connection strategy to augment the feature vector, and use Gradient Boosting Decision Tree (GBDT) as the final classifier to improve the overall performance. Experiments demonstrated the proposed model achieved superior performance than the-state-of-the-art deep forest methods with almost the same parameter.",60122052,Southwest University,Chongqing,China,['1700'],20.88888888888889,0.08750000000000001,0.4385416666666668,1,0.11790393013100436,0.026200873362445413,0.2727272727272727
1151,1178,1178,Dynamics of sinusoidal alpha waves asymmetry in brain electrical field," All rights reserved.There is no methodical approach suitable for definition of the periodical or non-periodical, stationary or nonstationary curves of brain signals with a help of amplitude, frequency, phase etc. values. It is difficult to determinate the wave shape, i.e. the problem is how to solve the respective pattern recognition. Therefore, we tried to propose a simple method for praxis by help of measurement two main wave time components, interpreting a sinusoidal alpha wave as a triangle, where there is an anterior and a posterior part of wave ascending and descending abscissas in a hope that the sufficient measure are presented by the ""legs"" only or distances between upper and bottom peak of the wave. All the values of total ascendants are divided by all values of total descendants. For the method validity estimation it was made for this computation separately in two different psychical states-the relaxation and the calculation activity, both with eyes closed. Results are presented as quotient (quotus alpha) which means alpha waves symmetry. If the quotient is equal to 1, or is near to 1, is the alpha wave full or almost symmetrical. When the quotient is lower than 1 the ascendant is shorter than descendent, then alpha wave is asymmetric and has inclination to the left side. In contrary if the quotient is higher than 1 the ascendant is longer than descendent, alpha wave is again asymmetrical, but inclination is oriented to the right side. During mentation is usually quotient lower one and the ascendant is still more lover, alpha waves are sheer, the inclination to the left is more expressive.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,"['1712', '1708', '1702']",22.25,0.1153209109730849,0.4772256728778468,0,0.0594059405940594,0.0033003300330033004,0.23905723905723905
1152,1179,1179,Development of the concept of the synthesis methodology of treatment schemes of complex form surfaces,"The article describes the development of the methodology concept for the synthesis of complex surface treatment schemes. The design of the technological equipment elements, namely, the machine, devices and metal-cutting tools is currently performed separately, without taking into account their mutual influence on the required accuracy of the machined parts, therefore the concept and methodology of the structural-parametric synthesis of metal-cutting systems was proposed. On the basis of the proposed concept of the methodology for the synthesis of machining diagrams for parts with double curvature surfaces, it is advisable to consider the synthesis process as a system of interrelated functional transformations: description of the processed surface; synthesis of initial structures; modification of initial structures; synthesis of tool-making surfaces; forming the space of project parameters of tools. In order to form the space of project parameters, within the framework of the transformation “Forming the space of project parameters of tools”, it is advisable to build a complex of mathematical models, which will allow creating the space of the initial design parameters essential for a given project level in the early design stages, and establish analytical dependencies (dimensional relationships and material properties) between the design parameters and the main indicators of quality.",60071000,Southwest State University,Kursk,Russian Federation,['1700'],50.0,-0.030303030303030307,0.193939393939394,1,0.09956709956709957,0.0,0.2914798206278027
1153,1180,1180,Method of Audit Sampling as an Instrument of Audit Services in Digital Economy,"The problems of development of audit activity have signified a drop of audit companies' business reputation. During the transformations of the global market economy of the last decades of the 21st century, the questions of minimizing costs amidst growing competition and the requirements for high professionalism of auditors, as well as the growing needs of investors and owners due to changing markets and legislation, become highly relevant in the future consideration of the issue. The article discusses and tests the methodology for using statistical research in audit based on audit materials where sampling is used as a main instrument. We analyze the possibilities of selective research utilization during an audit check of a huge amount of accounting data and reports, evaluation of the results of the check and their extrapolation to the entire population of data taking into account the correlation of the elements of the sample. In order to minimize the number of mistakes in the auditor's conclusion, we offer a sampling procedure that takes into account the points of highest risk and a method for risk evaluation. We have developed document templates to provide to auditors aimed to systemize the source data to select the sampling type, auditor's actions when processing accounting data and reports, the results of audit sampling and to reflect all the steps of sampling research at any stage of accounting process. Additionally, we have developed a set of indicators that make up the base for sampling research in audit. The method offered has been approbated on enterprise's data, which has confirmed that using these instruments of digital economics is possible, that it does not reduce the quality of the audit results, and its practical applicability from the point of view of minimization of labor.",60075346,Siberian Federal University,Krasnoyarsk,Russian Federation,"['1712', '1709', '1707', '1705']",36.25,0.05010416666666668,0.4665625,1,0.10223642172523961,0.0,0.23003194888178913
1154,1181,1181,"An analysis of opportunities & challenges towards Kisan credit card in Nagarkurnool District, Telangana","Government of India presented the Kisan Credit Card (KCC) scheme in the year 1998-99 to give opportune and sufficient credit backing to the farmers from formal banking framework in an adaptable, bother free and financially savvy way. This scheme has encouraged the accessibility of credit in time and has rearranged the methodology for benefiting loan from banks to an enormous degree. From the year 1998-99, the scheme has actualized by public sector commercial banks, RRBs (Regional Rural Banks) and cooperative banks in the nation. It has developed as a progressive credit appropriation framework to meet the credit necessities of the farmers in an opportune and simple way. The KCC instrument would enable farmers to buy agriculture data sources, for example, seeds, fertilizers, pesticides and furthermore enable them to pull back some money for meeting their other crop generation related necessities. The example size for the examination is 66 respondents. Despite the fact that there are different agricultural credits which are given by the banks.",101741144,Sri Satya Sai University,Puttaparthi,India,['1700'],23.42857142857143,0.03125,0.3165674603174604,1,0.0913978494623656,0.04838709677419355,0.33516483516483514
1155,1182,1182,Image synthesis from reconfigurable layout and style,"Despite remarkable recent progress on both unconditional and conditional image synthesis, it remains a long- standing problem to learn generative models that are capable of synthesizing realistic and sharp images from re- configurable spatial layout (i.e., bounding boxes + class labels in an image lattice) and style (i.e., structural and appearance variations encoded by latent vectors), especially at high resolution. By reconfigurable, it means that a model can preserve the intrinsic one-to-many mapping from a given layout to multiple plausible images with different styles, and is adaptive with respect to perturbations of a layout and style latent code. In this paper, we present a layout- and style-based architecture for generative adversarial networks (termed LostGANs) that can be trained end-to-end to generate images from reconfigurable layout and style. Inspired by the vanilla StyleGAN, the proposed LostGAN consists of two new components: (i) learning fine-grained mask maps in a weakly-supervised manner to bridge the gap between layouts and images, and (ii) learning object instance-specific layout-aware feature normalization (ISLA-Norm) in the generator to realize multi-object style generation. In experiments, the proposed method is tested on the COCO-Stuff dataset and the Visual Genome dataset with state-of-the-art performance obtained. The code and pretrained models are available at https://github.com/iVMCL/LostGANs.",60004923,NC State University,Raleigh,United States,"['1712', '1707']",33.833333333333336,0.1032020202020202,0.4558585858585858,1,0.10687022900763359,0.030534351145038167,0.3974358974358974
1156,1183,1183,Mercury behaviorin saline soil containing humic acidand zeolite,"Humic acid (HA) and zeolite (Zol) can reduce or even suppress mercury (Hg) mobility and bioavailability in soil. This experiment performed as a completely randomized design with three replications. For this purpose, 6 kg of saline soil in columns was treated with HA and Zol both at concentrations of 0 and 0.5 mg kg. They were also irrigated with three mercury levels of 0, 75, and 150 mg /l using HgCl2 salt. Irrigation with mercuric chloride was done every five days with equal amounts of prepared solution to each column. After 20 days, the leachate was collected from each column and mercury concentration was determined in the leachate. Then, the total and available mercury were determined in 5 sections of soil with 10 cm thickness. The resultsindicated that HA and Zol treatments play an important role in controlling Hg in saline soil. Further, HA and Zol increased the retention of total Hg in saline soil. Accordingly, HA and Zol reduced the amount of available Hg in soil and prevented transportation and leaching of Hg from the saline soil, thereby lowering the mercury content in the leachate. Note that the positive impact of HA was greater than that ofZol.",60001800,Ferdowsi University of Mashhad,Mashhad,Iran,['1700'],18.0,0.20272727272727276,0.5495454545454546,1,0.08071748878923767,0.07174887892376682,0.4170403587443946
1157,1184,1184,A knowledge graph for ecotoxicological risk assessment and effect prediction," All rights reserved.Exploring the effects a chemical compound has on a species takes a considerable experimental effort. Appropriate methods for estimating and suggesting new effects can dramatically reduce the work needed to be done by a laboratory. In this PhD research we aim at exploring the suitability of using a knowledge graph embedding approach for ecotoxicological effect prediction. A knowledge graph is being constructed from publicly available data sets, including a species taxonomy and chemical classification and similarity. We use ontology alignment techniques to integrate the effect data into the knowledge graph. Our preliminary experimental results show that the knowledge graph based approach improves the selected baselines.",60026169,Norsk institutt for vannforskning,Oslo,Norway,['1700'],18.0,0.22272727272727275,0.4340909090909091,0,0.1794871794871795,0.0,0.2631578947368421
1158,1185,1185,Judicial reform: Combatting delayed justice: “Justice delayed is justice denied”- William Ewart Gladstone,Indian Judiciary is one of the exemplary judiciary in the world. What makes it unique is its independence. But over the time it is facing certain issues pertaining to delayed and pending trials. It needs a reformation. And said reformation has been agreed and realized by various law commissions and committees. In this article the researcher has covered the landmark judgments where the delay in justice and solution to it has been covered up.,60116871,Bharati Vidyapeeth New Law College,Pune,India,['1700'],12.333333333333336,0.19642857142857145,0.6904761904761904,1,0.125,0.025,0.2875
1159,1186,1186,"ANALYSIS of the IMPACT of VEGETATION DISTRIBUTION, URBANIZATION, and SOLAR RADIATION on the SEASONAL VARIATION of the URBAN HEAT ISLAND EFFECT in CEBU CITY USING LANDSAT and GLOBAL HORIZONTAL IRRADIANCE DATA","The Urban Heat Island (UHI) phenomenon is a manifestation of the abnormal amount of heat generated in urban areas and anthropogenic land surface modifications. While urbanization can improve material comfort and be a boon to the economy, the accompanying problems associated with urbanization like the UHI effect has implications on health, demand for water and energy, and impacts the microclimate. Land surface temperature (LST), the Normalized Difference Vegetation Index (NDVI), and the Normalized Difference Built-up Index (NDBI) were calculated from historical remotely-sensed Landsat data from 2013 to present. The global horizontal irradiance (GHI) was computed from the lidar-derived elevation model of Cebu City using the Geographical Resources Analysis Support System (GRASS). It is shown that annual variation in average temperatures in Cebu is generally less than 5 °C. Mean UHI temperatures in Cebu City do not show a clear trend over time, but categorizing data by season, namely the rainy season (June-November), the cool dry season (December-February), and the hot dry season (March-May), permits the emergence of a pattern. Surface temperatures for the cool dry season and hot dry season show a linearly increasing trend with R2 values of 0.916 and 0.514, respectively. This study further investigates the temporal change in the degree and extent of the UHI in Cebu City by analyzing LST maps. Regression analysis is done to determine how LST is affected by the distribution of vegetation (NDVI) and built-up (NDBI), and the seasonal variation in solar radiation through the GHI.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],27.11111111111111,0.021271929824561404,0.3967105263157895,1,0.08278145695364239,0.1423841059602649,0.41114982578397213
1160,1187,1187,The butterfly effect in knowledge graphs: Predicting the impact of changes in the evolving web of data,"Knowledge graphs (KGs) are at the core of numerous applications and their importance is increasing. Yet, knowledge evolves and so do KGs. PubMed, a search engine that primarily provides access to medical publications, adds an estimated 500'000 new records per year-each having the potential to require updates to a medical KG, like the National Cancer Institute Thesaurus. Depending on the applications that use such a medical KG, some of these updates have possibly wide ranging impact, while others have only local effects. Estimating the impact of a change ex-ante is highly important, as it might make KG-engineers aware of the consequences of their actions during editing or may be used to highlight the importance of a new fragment of knowledge to be added to the KG for some application. This research description proposes a unified methodology for predicting the impact of changes in evolving KGs and introduces an evaluation framework to assess the quality of these predictions.",60012614,University of Zurich,Zurich,Switzerland,['1700'],26.16666666666667,0.08733766233766234,0.4327922077922078,1,0.10674157303370786,0.028089887640449437,0.3313953488372093
1161,1188,1188,Using text classification methods to detect malware," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In this paper we propose using text classification to detect malware. In our approach, we convert each binary executable to an assembly program, then use text analytics to classify whether the code is malicious or not. Using random forests as the classification model we achieve an F1 accuracy of 86%. Furthermore, to achieve this performance we only examined a limited portion of each assembly program. Our findings allow the development of malware detectors with fast responses as traditionally malware detectors need to parse the whole binary before making the decision. It also opens up the possibilities of using complex classification models like deep learning to detect malicious programs through analyzing code semantic.",60005141,University College Dublin,Dublin,Ireland,['1700'],20.666666666666668,0.002857142857142864,0.5192857142857144,0,0.14074074074074075,0.05185185185185185,0.34558823529411764
1162,1189,1189,Agile Query Processing in Statistical Databases: A Process-In-Memory Approach,"Statistical database systems are designed to answer queries on summarized data (or macro data), while queries on raw records are not allowed in such database systems. As macro data can offer aggregate information about the database, it is also an effective way to use statistical queries to provide analytical results in semantic databases. However, traditional statistical databases are proposed for security protection, i.e., hiding the raw records from user queries. Few studies are toward query optimizations on aggregate queries in statistical databases. In this paper, we propose a new process-in-memory (PIM) based processing scheme called agile query for accelerating queries in statistical databases. We present two new designs in the agile query. First, we propose an in-memory index to cache aggregate operators (e.g., sum, min, max, count, and average) in the main memory. The aggregate queries that hit in the in-memory index can be evaluated in the memory and no I/O operation will be incurred. Second, we propose to incrementally update the in-memory operator index so that we can ensure the consistency between the cached data and the original data records. We implement the agile query processing framework on top of MySQL and conduct experiments over various sizes of datasets to compare our design with the traditional method in MySQL. The results show that our proposal achieves up to 9 times higher throughput than MySQL under the skewed Zipf query set, and averagely gets about 2 times higher throughput under the random and uniform distributed queries.",60019499,Chinese Academy of Sciences,Beijing,China,['1700'],22.363636363636363,0.11261897824397825,0.4874514374514374,1,0.12110726643598616,0.02768166089965398,0.34657039711191334
1163,1190,1190,Experimental analysis of recent clustering algorithms for wireless sensor network: Application of iot based smart precision farming,". All rights reserved.The recent growth in the Internet of Things (IoT) technology suggests that it can help the farmers in many ways in their farming. The Smart Precision Farming (SPF) using the IoT gained significant attention of researchers since from the last decade to automate the various applications of farming to save the several resources and increase productivity. The functionality of SPF mainly depends on the sensor network deployed in farm areas. The sensors and actuators deployed across the farm using which farmers gain remote farms information related to temperature, soil moisture, fertilizer and water used, etc. periodically. The sensors deployed across the farm collects the periodic on-field data and transmit wirelessly towards the remote station for farm monitoring and decision-making processes. As the sensors are resource-constrained, the process of data collection and multi-hop transmission should be efficient in terms of energy consumption and Quality of Service (QoS) performances of data transmission. The clustering-based solutions proven to be effective for energy-efficient in Wireless Sensor Networks (WSNs), thus in this paper motive is to present the review of various recent clustering protocols. The clustering protocols of WSN can be applied to the smart precision agriculture to extend the network lifetime or farm sensor networks. After presenting the review of various clustering protocols, the IoT based WSN designed for smart precision agriculture application and apply two recent clustering protocols to evaluate their performances in terms of energy and QoS efficiency parameters. The networks are designed using the Zigbee protocol. The experimental results demonstrated the performances of clustering protocols by considering the SPF application of IoT enabled WSN.",105826000,University of Technology,Jaipur,India,['1700'],20.46153846153846,0.10922619047619046,0.3976785714285715,1,0.13071895424836602,0.06535947712418301,0.3561643835616438
1164,1191,1191,A self-controllable and balanced data sharing model," All rights reserved.The widespread acceptance of data sharing has promoted the relevant research in both academia and industry. ''Data sharing'' is the process of interchanging data among multiple data sources in a controllable access manner. Any such system provides common functionality of storage and access; however, there are prominent differences in non-functionalities, such as self-control, transparency, cost-effectiveness, incentive, and auditing, which make data sharing in a dilemma. In this paper, we propose a distributed data sharing model based on blockchain technology: data owner publishes data with an additional control policy; data consumer inquires data with an access request; and consensus nodes evaluate the request and make decisions. After formalizing the system model, we discuss the procedure of data sharing, reputation management, and proposed solution. With the access control policy, price compensation, and reputation management mechanism, we achieve self-control and price balance in sharing data. Our model is equally a closed-loop control system that acts as a regulator of supervising its participants. The analyses and experimental results show, comparing with the existing sharing systems, that our model is practical and can spur agents to participate actively in sharing data.",60016521,Sichuan University,Chengdu,China,['1700'],23.625,0.06296296296296297,0.5166666666666666,0,0.11587982832618025,0.004291845493562232,0.34101382488479265
1165,1192,1192,Approximation properties of partial sums of fourier series,In this paper we find a class of functions for which the Lebesgue estimate can be improved.,60110406,Sokhumi State University,Tbilisi,Georgia,['1706'],17.0,0.0,0.0,1,0.16666666666666666,0.05555555555555555,0.2777777777777778
1166,1194,1194,"MONITORING VEGETATION COVER CHANGE USING VEGETATION INDICES in TANGBO RIVER, BARANGAY TANGBO, SAMBOAN","Tangbo River is an important resource in Cebu's southern town of Samboan for being the site of Aguinid Falls, a known tourist destination. Monitoring the changes in the river's riparian vegetation is important since it has impacts on its ecological role of helping maintain biodiversity and river water quality. This study aims to detect vegetation index changes along the Tangbo River corridor using three vegetation indices: NDVI, EVI, NDMI, and Tasseled Cap indices, specifically for the years 1998, 2004, 2009, 2016, and 2019. It also aims to monitor the changes in NDVI and EVI values alongside tourism arrivals in Aguinid in 2018. Cloudless Landsat 5 (1998, 2004, 2009, and 2016) and Landsat 8 (2019) imagery were selected. Thirty reference points were plotted along the river with a 30-m distance between each point. Vegetation Indices (VI) and Tasseled Cap values were generated using data from these points and were compared for each selected year. NDVI and EVI values from the same reference points used in Landsat were generated from selected cloudless months of 2018 Planetscope imagery. Inbound tourist records were acquired from the tourism office of Samboan and the tourism arrivals for the year 2018 was then graphed with the Planetscope VI values for better visualization. Landsat imagery showed that there was a general upward trend in the vegetation indices from 1998 to 2019. Tasseled Cap Greenness and Wetness showed an increase in values from 1998-2019 while Tasseled Cap Brightness showed the opposite. Results from Planetscope data for the year 2018 showed that there was an inverse pattern between NDVI and tourism arrivals. Tourism arrivals peaked during the months of April and May based on annual records, while VI values dropped. On the other hand, both VI values peaked towards the last quarter of the year while tourist numbers dropped. This suggests that the pattern of VI values and tourism arrivals seemed to be influenced by seasonal changes rather than with each other. Findings from the study shows that further data collection is required to be able to establish a relationship between tourism and vegetation index values.",60108083,University of the Philippines Cebu,Cebu,Philippines,['1710'],21.625,0.14666666666666667,0.3911111111111111,1,0.10077519379844961,0.10852713178294573,0.42077922077922075
1167,1195,1195,Automated test case generation for the Paxos single-decree protocol using a Coloured Petri Net model," We show how a formal Coloured Petri Net model can be used to automatically generate a suite of test cases for the Paxos distributed consensus protocol. The test cases cover both normal operation of the protocol as well as failure injection. To evaluate our model-based testing approach, we have implemented the Paxos protocol in the Go programming language using the quorum abstractions provided by the Gorums framework. Our experimental evaluation shows that we obtain high code coverage for our Paxos implementation using the automatically generated test cases.",60110772,Western Norway University of Applied Sciences,Bergen,Norway,"['1712', '1703']",22.0,0.018666666666666658,0.37799999999999995,0,0.15789473684210525,0.09473684210526316,0.2826086956521739
1168,1196,1196,Russia in the mirror of the global competitiveness indices,"The paper considers the prospects of the country's development through the prism of the cluster concept application. Strengths and weaknesses of the Russian economy development are identified. It is possible to use the competitiveness index as an object of the cluster policy. The analysis of competitiveness on the basis of the Global Competitiveness Indices is carried out, threshold values are determined, and the first group of values can be used in competitiveness development programs and growth horizons, and the second group can be used to identify factors and threats, as well as to predict the critical level of economic security. It is determined that competition is a multilevel phenomenon manifested at different levels: macroeconomic, mesoeconomic, and microeconomic.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",23.4,0.05625,0.3666666666666667,1,0.1,0.03076923076923077,0.26153846153846155
1169,1197,1197,Named Entity Recognition in Traditional Chinese Medicine Clinical Cases Combining BiLSTM-CRF with Knowledge Graph,"Named entity recognition in Traditional Chinese Medicine (TCM) clinical cases is a fundamental and crucial task for follow-up work. In recent years, deep learning approaches have achieved remarkable results in named entity recognition and other natural language processing tasks. However, these methods cannot effectively solve the problem of low recognition rate of rare words, which is common in TCM field. In this paper, we propose TCMKG-LSTM-CRF model that utilizes knowledge graph information to strength the learning ability and recognize rare words. This model introduces knowledge attention vector model to implement attention mechanism between hidden vector of neural networks and knowledge graph candidate vectors and consider influence from previous word. The experiment results prove the effectiveness of our model.",60118080,School of Computer and Computing Science,Hangzhou,China,['1700'],19.666666666666668,0.0861111111111111,0.5216666666666667,1,0.10218978102189781,0.051094890510948905,0.29770992366412213
1170,1198,1198,Changes in functional responsibilities of HR-specialists in connection with the digital transformation of companies,"In the digital economy, companies will no longer be able to rely upon the old management models. In the digital transformation, it is crucial to pay attention to the introduction of new technologies and changes in the mind-set of employees, as well as to the development of digital culture in the company. The HR department becomes a service that closely interacts with the personnel. HR specialists start to play a leading role in helping the team members at various stages of the project, from inception to completion. The HR department becomes a service that closely interacts with the personnel, turns into an analytical centre that helps businesses to see new opportunities through new technologies, tools and approaches to the personnel, and becomes the direction that should be first of all affected by the changes. Formation of the efficient project teams also becomes an important functional direction. At present there exists a number of models, approaches and criteria for evaluating the efficiency of teamwork. Among other conditions for their effective work is the correct selection of team players and identification of their tasks. When looking at digital teams, a systematic approach should be used, which takes into account the interaction of its members with the internal and external environment of the company.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",23.444444444444446,0.11856060606060607,0.34983164983164977,1,0.09913793103448276,0.0,0.25217391304347825
1171,1199,1199,A COMPARISON between EXPERIENTIAL and ECMWF REANALYZED CONDENSED MOISTURE PROFILE over the NORTHEASTERN SPHERE,"Base on January and July 4-times daily ECMWF Interim data from 2009 to 2018 over the Northeast Sphere (0-180E,0-90N), the condensed moisture profile of experiential methods and that of ECMWF analysis are compared. The result shows that, the meridional-height distribution of mean cloud condensed moisture has a maximum slab spreading near ground in the Arctic region in July, and the maximum takes a circular shape at 700 hPa above 30N latitude in January. The distribution feature unlike the universal profile, it distributes in a single or double peak function manner, instead of a constant value. The quick decreasing level height and thickness varies with latitude, especially in January. The second experiential profile concerning warm cloud assumes air parcel lifting adiabatically, the liquid water path (LWP) is compared for general information. The result shows that the experiential LWP is much larger than that of the reanalysis by 1 to 2 order, decreasing with latitudes. The possible reason of LWP difference is from the critic water content value of cloud boundary identification. If the value is small, the thickness of warm cloud will be large, temperature and pressure at the cloud base are both large too, results in a larger LWP. These results will enrich the knowledge of the condensed moisture characteristics of ECMWF reanalysis and the experiential moisture profile methods.",60024350,National University of Defense Technology,Changsha,China,['1710'],24.33333333333333,-0.0055465367965367995,0.4632846320346321,1,0.07228915662650602,0.07228915662650602,0.2674897119341564
1172,1200,1200,Quality of ceramic tableware in use: User experience and expectation to usability in fine dining restaurant,". All rights reserved.One of the goals in the design of high quality ceramic tableware is to fulfill the expectations of market demands particularly the needs of users with a discerning taste. The current trend in the tourism sector is elite tourism. Most 5-star hotels have specialty restaurants which serve haute cusine and has a menu with a modern twist. This will lend an air of luxury, refinement and uniqueness to the menu. Thus, the tableware set that will be chosen has to reflect the unique menu of these restaurants and has to be extraordinarily unique. The design of tableware products focuses on the design element aspect to produce quality tableware. There is a need to study the hopes and demands of the current market demands in terms of what is expected in high quality design. This study will focus on the experience of users which will be based on the theory of Norman's Three Levels of Design. This is an in-depth study to explore the highly complex and interactive user experience with the product in question. In order to gain a deeper perspective of the affective experience, there is a need to have a clear approach to study the interpretation of user behaviour and experience in terms of product design. At the final stage of this model, it plays an important role in evaluating the emotional response of users towards the aesthetic value of the product which will be measured using user experience (UX). UX is vital in determining the success or failure of a product in the market. Presently, UX has evolved and does not merely represent the usability aspect of the product but rather it now represents the total experience of the user. In the end, it is this aspect of UX which will determine the success of the said product in the market.",112589595,Universiti Teknologi MARA,Seri Iskandar,Malaysia,['1700'],20.466666666666665,0.12136363636363635,0.4907575757575758,1,0.09880239520958084,0.017964071856287425,0.23030303030303031
1173,1201,1201,D3N: DGA Detection with Deep-Learning Through NXDomain,"Modern malware typically uses domain generation algorithm (DGA) to avoid blacklists. However, it still leaks trace by causing excessive Non-existent domain responses when trying to contact with the command and control (C&C) servers. In this paper, we propose a novel system named D3N to detect DGA domains by analyzing NXDomains with deep learning methods. The experiments show that D3N yields 99.7% TPR and 1.9% FPR, outperforming FANCI in both accuracy and efficiency. Besides, our real-world evaluation in a large-scale network demonstrates that D3N is robust in different networks.",60025278,Tsinghua University,Beijing,China,['1700'],17.6,-0.04333333333333333,0.56,1,0.11926605504587157,0.01834862385321101,0.45714285714285713
1174,1202,1202,Environmental wisdom: An observation of ecocriticism towards the javanese cyber literature in 20th century,"This research was an attempt to explore the Quadriology of Ki Padmasusastra's Novel (hereinafter referred to as QKPN) in the perspective of ecocriticism, especially the JavanesePastoral image. This study used a qualitative research paradigm. The object of this study was called cyber literature, because the data was taken from an online site. The main data sources of the study included four novels by Ki Padmasusastra. The technical data analysis used content analysis technique that was based on cultural hermeneutic. The result showed that, QKPN was a reflection of the universality of Javanese literature wrapped in text symbolism of literature. Through the plot and character of figures, implicitly or explicitly showedan ethical sense of human towards nature. The description of community life was an ideal standard of living in accordance with the values developed in Javanese culture. There was an attempt to transfer the value of environmental wisdom by Ki Padmasusastra to readers regarding the noble values of Javanese culture. The main goal of environmental wisdom in the perspective of Javanese culture wasto memayuhayuningbawana 'to maintain the balance of nature', so as to create a harmony of life among beings in the universe. An important implication of the finding was human awareness to respect each other existing entities, was a foundation of strength that could guide human to seek fellowship with nature. Through QKPN, Ki Padmasusastra also stressed about preservation, empathy, and respect for non-human beings. Thus, QKPNwas involved in ecology in three ways, namely environmentalism ethic, scientific intellectual, and practical. Through its intrinsic reading, educational values on QKPNcould be used as a platform for ethical environmental education.",60069439,Universitas Sebelas Maret,Surakarta,Indonesia,['1700'],19.071428571428573,0.18101851851851847,0.4217592592592592,1,0.07947019867549669,0.06622516556291391,0.26755852842809363
1175,1203,1203,Digital economy and e-sport in Russia,"The modern world cannot be imagined without information technologies that are being introduced into all spheres of society, including the economy. The digital economy is based on the production of electronic goods and their implementation through e-commerce. One of the components of the digital economy is e-sports. Russia became the leader of the European e-sports market in 2017 with a volume of "" 38 million. According to the forecast of PayPal and SuperData, the Russian e-sports market will continue to grow in the next two years, in 2018 its volume exceeded "" 45 million, and in 2019 will reach "" 53 million The role of e-sports in the digital economy of Russia is becoming increasingly apparent. Thus, this article gives a clear understanding of the enormous path that esports has traveled from an unknown idea to a large-scale event. In the article, the authors examined e-sports from all sides and gave a clear description. To begin with, we took advantage of historical facts to trace the phased emergence of e-sports and then be able to delve into their individual disciplines. The article analyzes 6 of the best video games that, due to their characteristics, move the e-sports arena into the future. It is also worth mentioning that in addition to the games themselves, the developers of these games make a huge contribution, investing a huge amount of money in them even after their release. And lastly, we studied how the e-sports arena is developing and moving within the framework of Peter the Great St. Petersburg Polytechnic University, where the equally capable e-sportsmen prove that the current stage of e-sports is only a small part of the great future.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",23.16666666666667,0.1608333333333333,0.3794444444444445,1,0.10091743119266056,0.03363914373088685,0.2838283828382838
1176,1204,1204,Flexible service discovery based on multiple matching algorithms,"Traditional web service discovery approaches rely on logic or non-logic matching techniques. In general, logic approaches can achieve satisfactory precision levels, but they result in modest recall scores. In contrast, non-logic approaches may ensure more balanced scores in terms of recall and precision, but they need additional aggregation schemes or optimisation methods. To improve the discovery performance, we need to combine multiple matching algorithms and fuse their results into a single ranked list of services. This combination must avoid the well-known side effects of fusion, such as overfitting or noise sensitivity. To tackle the service-discovery issue, we propose a solution based on two key ideas: first, we propose a majority voting model based on the 'Condorcet' paradigm to fuse a set of individual ranked lists (provided by the matching functions). Second, we leverage a probabilistic extension of the dominance relationship to ensure comparison between the services. The experimental evaluations indicate the proposed solution, 'probabilistic Condorcet', outperforms all individual matching functions, as well as many concurrent fusion algorithms.",60068756,Université Abou Bekr Belkaid Tlemcen,Tlemcen,Algeria,"['1710', '1708', '1705']",20.875,0.1020408163265306,0.4569727891156463,1,0.14356435643564355,0.009900990099009901,0.328125
1177,1205,1205,Application of surrogate modeling to multi-objective optimization for residential retrofit design,"This project combines surrogate modeling, a supervised machine learning technique, to bypass whole building energy simulations to enable multi-objective design optimization. We applied this method to identify Pareto optimal retrofit designs that are energy and cost effective for three residential apartments in Lisbon, Portugal. As part of our validation of this approach, we compared the surrogate model error for these Pareto optimal designs to the error in the rest of the design space when compared to a detailed energy simulation. Surrogate model error is higher towards the minimum and maximum energy consumption within the Pareto optimal designs compared to the rest of the design space. We also find that in the Pareto optimal set some design variable values are near their minimum or maximum value, which could be driving higher surrogate model error. We propose that future research should retrain the surrogate model after identifying design variable values of interest from an initial optimization run.",60025038,"University of California, Berkeley",Berkeley,United States,['1705'],25.83333333333333,0.22500000000000006,0.434375,1,0.10714285714285714,0.03571428571428571,0.21084337349397592
1178,1206,1206,E-CAD: Web-based information service for land management,"The status quo of the land management and information system in Nepal is a far cry from where the developed world stands. Paper-based system is still the spine of this system which is tedious, less accurate and difficult to store and update. So, there is a need for a digitized system providing country's land authorities with a powerful tool that creates a unified platform for the creation of an accurate spatial database, timely maintenance and updating of the database in a dynamic web platform. The database including spatial data of land features can be utilized to create a web-based thin-client mapping application which meets the needs of all the stakeholders (government authorities from Survey Offices, Land Revenue Offices, Land Reform Offices, etc.). This paper shows the use of open-source software for the creation of a web mapping system including QGIS, PostGIS extension of PostgreSQL for spatial database, HTML for markup, CSS for styling, JavaScript, Leaflet, Open-Layers for client-side scripting and Geo-Django for backend designing. The developed methodology can be utilised for the preparation of an interactive thin-client web mapping server that enables general users to dynamically view data, zoom, pan and search from the database and obtain land information. The login system enables administrators with various access to upload, verify and edit data along with performing various spatial operations while the super admin is entitled to access to the PostgreSQL database. The major finding is that the use of a thin client application for a land information system is beneficial for all stakeholders. It is also a measure of the performance of land authorities allowing better planning, preparedness, and allocation of resources.",124057917,TU,Pokhara,Nepal,['1710'],30.222222222222218,0.04583333333333334,0.5950980392156863,1,0.0880503144654088,0.050314465408805034,0.3289036544850498
1179,1207,1207,Application of interval type 2 fuzzy SAW in flood control project,"The fuzzy simple additive weighting (fuzzy SAW) has been applied to resolve numerous multi-criteria decision-making (MCDM) problems, in which triangular fuzzy numbers are employed in describing experts' linguistic evaluation. The recent discovery of interval type-2 fuzzy SAW (IT2FSAW) can offer a new method in solving MCDM problems where interval type-2 fuzzy numbers (IT2FN) are used to define experts' linguistic evaluation. Contrarily to the fuzzy SAW, which directly utilizes triangular fuzzy numbers, this method presents IT2FN to improve evaluation in solving MCDM problems. In this paper, MCDM problem in flood management is investigated where best alternative in flood control project is proposed using the IT2FSAW. Seven alternatives and seven criteria of flood management are identified to construct an MCDM problem. Four experts in flood management were invited to provide linguistic evaluation of alternatives with respect to criteria. The IT2FN linguistic terms were computed using the seven-step procedures of IT2FSAW. Computational output displays that the alternative 'catchment area' is nominated as the best alternative of flood control project. The findings of this study suggest that the authority could provide more catchment areas from which rainfall would flows to a low point.",60103919,Universiti Sultan Zainal Abidin,Kuala Terengganu,Malaysia,['1706'],21.0,0.2412587412587413,0.2893606393606393,1,0.1318181818181818,0.05909090909090909,0.37089201877934275
1180,1208,1208,An Enhanced Deep Hashing Method for Large-Scale Image Retrieval,"Hashing-based image retrieval plays an important role in approximate nearest neighbor search because of its storage and retrieval efficiency. Efficient image features are of vital importance for image retrieval task. However, the features of images may not directly suitable for image retrieval due to the illumination or cluttered background in images. In this paper, we propose an enhanced deep hashing method for image retrieval to promote the retrieval accuracy, in which we adopt an enhanced feature module that selects the attractive areas in images. It jointly explores the hashing learning, enhanced feature module, and batch normalization module in a unified framework, which can guarantee the optimal compatibility of hash coding and feature learning. The proposed deep model contains three parts: (1) a convolutional sub-network consists of several convolutional-pooling layers and the proposed enhanced feature module; (2) a batch normalization module is utilized to control the quantization errors of hash codes at a moderate level; (3) a more comprehensive loss function is introduced to enhance the discriminative of image features and minimize the prediction errors of the learned hash codes. The experimental results on three datasets show that the proposed method can achieve competitive performance compared to other hashing approaches.",60023813,Shanghai University,Shanghai,China,['1700'],28.42857142857143,0.01607142857142857,0.5642857142857144,1,0.14977973568281938,0.0,0.2895927601809955
1181,1209,1209,AUTOMATED PREDICTION SYSTEM for VEGETATION COVER BASED on MODIS-NDVI SATELLITE DATA and NEURAL NETWORKS,"Around the world, vegetation cover functioning as shelter to wildlife, clean water, food security as well as treat large part of air pollution problem. Accurate predictive data early warn and provide knowledge for decision makers to reduce the effects of changes in vegetation cover. In this paper, an automated prediction system was developed to forecast vegetation cover. Prediction system based on moderate satellite data spatial resolution and global coverage data. The tools of system automate processing Moderate Resolution Imaging Spectroradiometer (MODIS) images and training neural networks (NN) model based on 60,000 observations to forecast future density of Normalized Difference Vegetation Index (NDVI). Zonguldak data, located in north of Turkey as dense vegetation cover area utilized as case study for system application. This system significantly facilitates predictive process for users than previous long and complex models.",60085899,Karabük Üniversitesi,Karabuk,Turkey,['1710'],19.285714285714285,0.07994505494505495,0.4406593406593408,1,0.1111111111111111,0.08496732026143791,0.33986928104575165
1182,1210,1210,Towards more intelligent SPARQL querying interfaces," All rights reserved.Over years, the Web of Data has grown significantly. Various interfaces such as SPARQL endpoints, data dumps, and Triple Pattern Fragments (TPF) have been proposed to provide access to this data. Studies show that many of the SPARQL endpoints have availability issues. The data dumps do not provide live querying capabilities. The TPF solution aims to provide a trade-off between the availability and performance by dividing the workload among TPF servers and clients. In this solution, the TPF server only performs the triple patterns execution of the given SPARQL query. While the TPF client performs the joins between the triple patterns to compute the final resultset of the SPARQL query. High availability is achieved in TPF but increase in network bandwidth and query execution time lower the performance. We want to propose a more intelligent SPARQL querying server to keep the high availability along with high query execution performance, while minimizing the network bandwidth. The proposed server will offer query execution services (can be single triple patterns or even join execution) according to the current status of the workload. If a server is free, it should be able to execute the complete SPARQL query. Thus, the server will offer execution services while avoiding going beyond the maximum query processing limit, i.e. the point after which the performance start decreasing or even service shutdown. Furthermore, we want to develop a more intelligent client, which keeps track of a server's processing capabilities and therefore avoid DOS attacks and crashes.",60020238,Universität Paderborn,Paderborn,Germany,['1700'],17.857142857142858,0.2580519480519481,0.6032936507936509,0,0.14184397163120568,0.0425531914893617,0.3489208633093525
1183,1211,1211,A short proof for a determinantal formula for generalized Fibonacci numbers,The aim of this note is to provide a short and elegant proof for a recent determinantal formula for generalized Fibonacci numbers. The attractiveness of the proof presented here is its elementary nature.,60121848,Kuwait College of Science &amp; Technology,Doha,Kuwait,['1710'],16.5,0.2,0.6125,1,0.08571428571428572,0.02857142857142857,0.14285714285714285
1184,1212,1212,GEOSPATIAL ASSESSMENT of VULNERABILITIES of CROPLANDS to FLOODING RISKS: A CASE STUDY of PHILIPPINE RIVER BASINS,"This study utilized the Analytic Hierarchical Process and spatial analysis using various datasets to produce sub-provincial vulnerability maps with 20 km resolution. Five (5) indicators for exposure, four (4) for sensitivity and seven (7) for adaptive capacity were selected and weighted using aggregated rankings from twenty-three (23) experts. Based on these indicators, gridded maps of exposure, sensitivity, adaptive capacity, and vulnerability were produced. Using river basins as the unit of analysis, the Pampanga River Basin was determined to be the most vulnerable, followed by the Agus River Basin, having the highest sensitivity, and Buayan River Basin, having the lowest adaptive capacity. These areas have large agricultural regions and river systems with high flooding risk. Coastal regions in southern Mindanao and eastern Visayas were also highly vulnerable to flooding. High poverty rates with high dependence on agricultural incomes and low adaptive capacities characterize these areas. Vulnerability hotspots can easily be identified through these maps, which have value in planning initiative to reduce potential damages of floods to agricultural areas.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.0,0.0523015873015873,0.51515873015873,1,0.09045226130653267,0.07035175879396985,0.4461538461538462
1185,1213,1213,CORRECTION for the CIRRUS CLOUD TOP HEIGHT of MODIS BASED on CALIPSO in Beijing-TIANJIN-HEBEI REGION,"Cirrus plays an important role in atmospheric radiation. It affects weather system and climate change. Satellite remote sensing is an important kind of observation for cloud. As a passive remote sensing instrument, large bias was found for thin cirrus cloud top height retrieval from MODIS (Moderate Resolution Imaging Spectroradiometer). Comparatively, CALIOP (Cloud-Aerosol Lidar with Orthogonal Polarization) aboard CALIPSO (Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observation) which is an active remote sensing instrument can acquire more accurate characteristics of thin cirrus cloud. In this study, CALIPSO cirrus cloud top height data was used to correct MODIS cirrus cloud top height. The data analysis area was selected in Beijing-Tianjin-Hebei region and data came from 2013 to 2017. Linear fitting method was selected based on cross-validation method between MODIS and CALIPSO data. The results shows that the difference between MODIS and CALIPSO changes from 3∼2 km to 2.0∼2.5 km, and the maximum difference changes from about 0.8 km to about 0.2 km. In the context of different vertical levels and cloud optical depth, MODIS cirrus cloud top height is improved after correcting, which is more obvious at lower cloud top height and optical thinner cirrus.",60073482,National Satellite Meteorological Center Beijing,Beijing,China,['1710'],19.2,0.20786749482401656,0.5505175983436853,1,0.06696428571428571,0.16517857142857142,0.3598130841121495
1186,1214,1214,The effect of internal training and auditing of auditors on supply chain management: An empirical study in listed companies of Iraqi stock exchange for the period 2012-2015,"This study aimed to examine the joint effect of auditor's auditing and training on reducing financial statements' manipulation Iraqi companies listed in stock exchange. Specifically, this study focuses on the impact of internal training and auditing of internal audit staff on reduction of the rate of manipulation in earnings management practices as depicted by the discretionary accruals. The financial statements for 69 listed companies in the Iraqi Stock Exchange were analyzed in this study in order to achieve these objectives for the period of 2012-2015. The earnings management which is measured by the Kothari et al. model (2005) is the dependent variable while independent variables considered in this study are auditor's training and the internal audit. The independent variables are analyzed using a set of data gathered from the selected companies. Based on the results of study recommends the need for activating the internal control bodies which shall consider the requirements necessary before publishing financial statements in the market by the listed companies in the Iraqi stock exchange. The requirements are also necessary to be connected with the audit committees of the companies and more training courses should be conducted for the auditors. This research can be used for the universities, teachers and students. In this research, the model of the The effect of internal training and auditing of auditors on Earning Management is presented in a comprehensive and complete manner. Copyright",60071147,University of Baghdad,Baghdad,Iraq,['1710'],21.09090909090909,0.042857142857142864,0.225,1,0.1111111111111111,0.03571428571428571,0.288
1187,1215,1215,Generating acoustic diffuser arrays with shape grammars,This paper presents research on a rule-based approach to designing creative acoustic diffuser arrays. A shape grammar-influenced design method is specified that uses shape rules to recursively design arrays of quadratic residue diffusers (QRD) in ways that are neither mechanical nor deterministic.,60024609,Indiana University-Purdue University Indianapolis,Indianapolis,United States,['1705'],21.0,0.5,1.0,1,0.14,0.08,0.34782608695652173
1188,1216,1216,An pso-sfla based ensemble link weighted triple quality algorithm to improve the performance of clustering over categorical data clustering,"This paper focus on solving the issues related to the occurrence of irrelevant and null information during cluster partitioning. Hence, to avoid the serious issue arising due to such improper dataset, the proposed method uses a link based cluster ensemble technique uses weighted triple quality and multi-view point using entropy and similarity measurement, respectively. It ensembles the objects into clusters by suitably eliminating the local optimal problem and the quality of clustering is improved by reducing the high dimensional datasets. The clustering is performed using hybrid particle Swarm Optimization (PSO)-Shuffled Frog Leaping Algorithm (SFLA) algorithm. The proposed method is evaluated on categorical datasets to test its effectiveness in terms of Clustering Accuracy (CA), Normalized Mutual Information (NMI) and Adjusted Rank Indices (ARI). The results shows that the proposed approach attains better finalized clusters than the other conventional methods.",60113938,"Annamacharya Institute of Technology &amp; Sciences, Rajampet",Rajampet,India,['1700'],23.0,-0.06278388278388278,0.4972161172161172,1,0.13836477987421383,0.11320754716981132,0.44025157232704404
1189,1217,1217,"SPATIO-TEMPORAL ANALYSIS of URBAN HEAT ISLAND in MANDAUE CITY, PHILIPPINES","Extensive urbanization alters the natural landscape as vegetation were replaced with infrastructures composed of materials with low albedo and high heat capacity often resulting to increase in land surface temperatures (LST). The present study focused on the spatial and temporal variations of LST in Mandaue City, one of the metropolitan cities in the Philippines that had undergone a rapid rate of urbanization over the past years. Climate Engine (CE), a cloud computing tool that processes satellite images, was used in this study. Preprocessed LST, normalized difference water index (NDWI), normalized difference vegetation index (NDVI), shortwave infrared (SWIR 1) and near-infrared (NIR) layers were directly downloaded from CE while the normalized difference built-up index (NDBI) maps were calculated. Time-series dataset of these indices were analyzed to determine the impacts of reduced vegetation cover and increased built-up areas on surface temperature from years 2013 to 2019. The spatial distribution of LST were analyzed using Univariate Local Moran's I in GeoDa to identify hotspots within the city. Analysis results showed that the hotspots are barangays Tipolo (100%), Bakilid (100%), Ibabao-Estancia (93.5%), Alang-Alang (87.2%), Guizo (84.4%), Subangdaku (84.1%), and Centro (79.4%). The results indicated that there is a linear relationship between LST and NDBI (r Combining double low line 0.659, p < 0.01) while an inverse relationship was observed between LST with NDVI (r Combining double low line-0.527, p < 0.1) and NDWI (r Combining double low line-0.620, p < 0.01).",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],29.625,0.007857142857142858,0.22309523809523804,1,0.09235668789808917,0.12738853503184713,0.5298013245033113
1190,1218,1218,"HYDROPOWER DAM SITE SELECTION and VISUALIZATION USING GIS and RS TECHNIQUES: A CASE of MARINDUQUE, PHILIPPINES","The energy supply of the Philippines is dwindling considering rapid population growth, thus the need to maximize the advantages of harnessing renewable energy (RE) and optimizing its utilization in the grid. One of the RE sources that is considered practical due to its availability is running water, thus the development of hydropower. The use of remote sensing (RS) datasets and geographic information system (GIS) techniques are useful for pre-feasibility studies of hydropower development. This study utilizes Interferometric Synthetic Aperture Radar (IFSAR)-derived DEM, GIS-based hydrology and terrain characterization tools to identify natural reservoirs, and spatial analysis identify site for possible dam development. The methodology consists of two processes: valley determination, a component of landform classification, and flow accumulation. Different valley determination algorithms are included in the comparison analysis such as Multi-Resolution Valley Bottom Flatness (MRVBF), Topographic Position Index (TPI), Valley and Ridge Detection (VRD) and Geomorphons, with the latter best describing the valleys within the Marinduque island. The identified valleys are intersected with sites having the most suitable elevation, slope and flow accumulation. The results of the study are different indicative sites for hydropower development, the volumetric capacity for which are generated given design specifications (e.g. different dam heights). Furthermore, upon computing the volume of water that the reservoir can contain, the reservoir design is represented as three-dimensional features over the terrain to visualize the dam development.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.6,0.17115384615384616,0.44807692307692304,1,0.08455882352941177,0.09926470588235294,0.4044943820224719
1191,1219,1219,DETERMINATION of CIGARETTE SMOKE DISPERSION USING OPTICAL RGB CAMERA and DIGITAL IMAGE PROCESSING,"Across ages, the rapid prevalence of cigarette smoking has consistently posed adverse threats to both human health and the environment. Moreover, smoke dispersed from a single cigarette could expose serious respiratory problems to a number of non-smokers within the area. Cigarette smoke has always been a notorious, human-induced health risk and air pollutant thus, the urgent need to develop smoke management schemes by exploring strategies on observing cigarette smoke dispersion. This research aims to incorporate the potential of optical RGB cameras in the study of smoke dispersion. Through digital image processing of experimental smoking videos, a spatiotemporal visualization of smoke dispersion for an indoor and outdoor environment were created. Smoke movement starting from the source was observed in terms of smoke pixel density and maximum horizontal extent. Quantitatively, the results showed a relative maximum extent of 1.21 meters which lasted for 2 seconds for an outdoor environment while 1.05 meters which lasted for 6 seconds for an indoor environment. The maximum relative smoke pixel density values calculated for the outdoor and indoor environment are 1.46% and 1.12% respectively. The resulting graphs were indicative of a trend that creates a normal distribution curve that can be affected by external factors and represent a function relating dispersion and distance. The results of this study prove the capability of optical RGB cameras as an alternative and cost-efficient method in studying smoke dispersion. Furthermore, this practical method of monitoring smoke dispersion could lead to comprehensive analyses of air quality management and health exposure assessments.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.72727272727273,0.007326007326007328,0.2754578754578755,1,0.10144927536231885,0.014492753623188406,0.2740740740740741
1192,1220,1220,MAPPING FOREST ECOSYSTEM SERVICES: A REVIEW,"Managing multiple ecosystem services (ES) across forest landscape, constitute a growing field of research. It represents a key challenge that attempts to optimize the trade-offs among provisioning, supporting, regulating and cultural ES. Here, we review approaches and shortcomings on some anterior FES studies. Three main components are presented, 1) an overview of the current state of research, 2) a summary of main methods adopted 3) an identification of principal approaches' restrictions. Several conclusions emerge: most of the studies focus on a limited number of FES which might undermine the long-term provision of other FES, or converge to using free software models which are practical and low-cost but require enormous data. This reveals how the lack of existing inventories and evaluations impacts the choice of methodologies and lead to use indirect methods of measurement. However, researches that aim to understand the relationships and conflicts among multiple FES and seeks to find out the best management regime will improve our ability to sustainably fulfil economic, ecologic and social goals.",60025457,Hassan II University of Casablanca,Casablanca,Morocco,['1710'],23.857142857142854,0.15413165266106446,0.3353641456582633,1,0.14795918367346939,0.02040816326530612,0.3894736842105263
1193,1221,1221,Image forgery detection and localization using DCT-based forensic analysis approach,"Digital image tempering is widespread because of software and devices that manipulate image information without any traces are easily available for high-performance image editing. Now everything is online for a day and digital images are presented as evidence of any event, documentation where forgery hides its traces. Existing techniques for forgery detection are based on the higher complexity of computational costs. The technique proposed is robust even with pre-and post-processing operations for automatic detection and localization of specific artifacts. We proposed a DCT supported technique to obtain features from each block of images that reduce the block dimension and assist in lexicographic sorting. Tampered blocks of images are compared with predefined threshold values based on robust parameters to detect similar blocks in reduced time. Experimental results are robust to multiple forgeries with low computational complexity and retained significance of image information. On several images that are affected by different forgery types, we show our method robustly.",60104571,Manav Rachna International Institute of Research and Studies,Faridabad,India,['1700'],19.5,0.06818181818181818,0.2477272727272727,1,0.11627906976744186,0.0,0.3192771084337349
1194,1222,1222,"CANOPY COVER ESTIMATION from SATELLITE DATA for ACACIA MANGIUM PLANTATION BASAY, NEGROS ORIENTAL","Forest assessment and measurement can be costly, laborious and time-consuming when done manually. Remote Sensing aids by providing data of sufficient accuracy for large tracts of forest lands in the form of maps. These data can then assist in decision-making for better forest management. This study estimated canopy cover, a primary forest measurement parameter, using remotely-sensed data. Satellite images such as Planetscope and WorldView were used to estimate canopy cover. The results were then compared to measurements obtained from a manual inventory-in this case, of an Acacia mangium plantation. The manual inventory was conducted in a National Greening Program (NGP) site in Basay, Negros Oriental. Field inventory involved a Static Global Navigation Satellite System (GNSS) survey and a Total Station survey to get the accurate location of trees present in the plot. Diameter-at-breast was measured for all trees. Tree height and crown diameter were measured for at least 10 percent of all trees in the plot.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],15.6,0.14675324675324675,0.4374458874458875,1,0.0855614973262032,0.10160427807486631,0.37142857142857144
1195,1223,1223,"Monitoring spatial variation in tribal population at tahsils of Ahmednagar district, Maharashtra using gis technique","The tribal population represents a heterogeneous group scattered in different regions of India. The differences are noticed in language, cultural practices, socio-economic status and pattern of livelihood. The tribal population in India rapidly increased from 30.1 million in 1961 to 104.3 million in 2011. For same period tribal residing in rural area have increased by three times from 29.4 million to 93.8 million respectively. The tribal population resides in urban area is very less in number due to these people like to live in the remote areas of the proximity of natural environment. In Maharashtra, more than 47 indigenous tribes were dwelling at Sahyadri and Satpuda mountainous ranges. According to 2011 census, there are about 1, 05, 10,213 tribal populations living in Maharashtra, which constitutes 10.05% population of state. In Maharashtra, there is regional disparity in tribal population such as Nandurbar District has the highest tribal concentration while Dhule, Gadchiroli, Nasik, and Ahmednagar District have moderate tribal concentration. Therefore, present research work is an attempt to understand the Spatio-temporal variation in tribal population of Ahmednagar district using GIS technique during the period of 2001-2011. This study is to examine the tahsil-wise tribal population and identifying pattern of tribal population density in Ahmednagar District. The result shows that more than 80% of tribal population concentrated in Akole, Sangamner, and Rahuri tahsil due to hilly region, roughed terrain, river basin, and forest area. It is also demonstrated that the planning control, researchers and decision-makers should be focused on these areas for implementing policies and large numbers of tribal can be benefited.",60114376,"Modern College of Arts, Science and Commerce, Shivajinagar",Pune,India,['1710'],21.58333333333333,0.05466570466570467,0.3050132275132275,1,0.08305647840531562,0.07308970099667775,0.3539518900343643
1196,1224,1224,Efforts on gender balance capacity building in GIT,"The Hindu Kush Himalaya (HKH) region is among the most discrete and diverse region facing various ecological, environmental and socio-economic threats in terms of increasing demands for natural resources and its consequences in the form of overexploitation, disaster, droughts, extreme weather, and climate change etc. Geospatial information technology (GIT) with Earth observation (EO) data are effectively supporting the implementation of development agendas in HKH by providing extensive solutions to above-pressing issues by not only addressing them but also providing services in daily life. These technologies have effectively bolstered in time via innovation, creating jobs and confidence in people that supports filling the data and knowledge gaps in the region. However, the involvement and participation of women in GIT is mere in the region despite their vital role in environmental management and decision making. Realizing the issue, we acknowledged and implemented the twin challenges i.e. capacity building and gender equality for building the pathways to sustainable development via innovative steps and processes to bridge the gender imbalance in GIT workforce in HKH. For the purpose, we organized various capacity building trainings and workshops with a broad focus towards GIT applications in forest, agriculture, water management, drought and climate change along with the hands-on exercises. In addition, specific women focused training programs i.e. Empowering Nepali Women through Technology Training and Women in GIT were organized during 2017 and 2018 respectively. These efforts delivered optimistic results in terms of building confidence, decision making and more women participation showing an increment of ∼5% participation by women in 2017-2018 fiscal year with respect to 2016-2017 fiscal year. In HKH nations with less social parity, the information delivered by this gender mainstreaming effort will have life-changing implications to achieve workforce parity.",60071806,International Centre for Integrated Mountain Development Nepal,Kathmandu,Nepal,['1710'],25.90909090909091,0.11270833333333335,0.4477083333333334,1,0.08231707317073171,0.054878048780487805,0.3522012578616352
1197,1225,1225,SPATIAL and TEMPORAL ANALYSIS of MONTHLY WATER CONSUMPTION and LAND SURFACE TEMPERATURE (LST) DERIVED USING LANDSAT 8 and MODIS DATA,"Land Surface Temperature (LST) is one of the important factors in monitoring urban climate. Observing the variations of LST can provide a better understanding of the Urban Heat Islands (UHI) phenomenon. The aim of this research is to assess the relationship between the spatial and temporal distribution of LST and water consumption in Zamboanga City for years 2016 and 2017. Data from the city's water district were used to compute for the per capita water consumption (PCWC) of 49 barangays. Landsat 8 LST data with 30m spatial resolution were computed using inverse Plank function and other parameters such as vegetation proportion and surface emissivity to assess LST spatially while MODIS Terra data with 1km spatial resolution were used to assess LST temporally. Result showed that Landsat LST and PCWC have moderate correlations with p < 0.01: 0.59 and 0.55 for March and April 2016, respectively; 0.49 and 0.56 for March and April 2017, respectively. These indicated that warmer barangays consumed more water. The temporal correlation of the MODIS LST and the computed PCWC equated a-0.71, p < 0.01, correlation. This negative correlation indicated that when LST increases, PCWC decreases, which do not directly indicate that the city consumed less water but rather that the supply was less during warmer months. It was evident as water rationing was experienced during the first quarter of 2016 and intensified on April where the highest LST was recorded. Finally, LST was found of good use in assessing the relationship of temperature and water consumption.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.72727272727273,0.13640350877192986,0.4100877192982457,1,0.08960573476702509,0.11469534050179211,0.38267148014440433
1198,1226,1226,Including occupant behavior in building simulation: Comparison of a deterministic vs. a stochastic approach,"Data capture and analysis are transforming entire industries, enabling novel solutions developed from a numeric evaluation of real-world phenomena. This generally relies on gathering data on physical conditions and users to create accurate, predictive models and provide customized solutions. Increasingly, data-driven approaches are also becoming a part of architectural design, with the goal of creating user-centric and sustainable buildings. However, while simulation software can accurately model deterministic physical effects, it is still difficult to incorporate stochastic effects related to human factors. This paper analyses one aspect of occupant behavior – window operation – to give designers an intuition of the impact of occupant behavior and associated modelling approaches on building performance. To this end, behavioral patterns observed in a previous field study were incorporated into a dynamic energy simulation and compared to a deterministically modelled baseline. While the stochastic models appear to better capture the dynamic and probabilistic nature of occupants’ actions, the present study highlights the extent to which the assumption with regard to occupant behavior can influence the simulation-assisted performance based design process. The paper also makes suggestions as to how to interpret such simulation results in a way that quantifies the intrinsic uncertainty in stochastic models. We argue that increased data capture and analysis of building inhabitants could lead to a better understanding of their behavior, thereby affecting the decision-making process in favor of a more sustainable and responsive architecture.",60030804,Swinburne University of Technology,Melbourne,Australia,['1705'],25.88888888888889,0.1175438596491228,0.41196741854636604,1,0.15267175572519084,0.0,0.2777777777777778
1199,1227,1227,Program algebra for quantitative information flow,"Models for quantitative information flow traditionally assume that the secret, once set, never changes. More recently, however, Hidden Markov Models (HMM's) have been used to describe program features that include both state updates and information flow, thus supporting more realistic contexts where secrets can indeed be refreshed. In this paper we explore HMM's further, with the aim of bringing algebraic concepts to bear in the analysis of confidentiality properties of programs. Of particular importance is the idea that local reasoning about program fragments should remain sound even when those same fragments are executed within a larger system. We show how to extend the basic HMM model to incorporate this core idea within an algebraic setting and, in so doing, show how it is related to established notion about privacy and correlated data sets in statistical databases. Using our algebra for an HMM-style model we show how to describe and prove some foundational properties of quantitative information flow.",60019544,Macquarie University,Sydney,Australia,"['1712', '1703']",26.16666666666667,0.08854166666666666,0.3750000000000001,1,0.15254237288135594,0.03954802259887006,0.26857142857142857
1200,1228,1228,Hadoop and deductor based digital ai system for predicting cost of innovative products in conditions of digitalization of economy,"The article represents theoretical foundations investigated for application of artificial intelligence systems in Big Data processing. The most comprehensive list of tools for data analysis and machine learning has been considered. A comparative Hadoop framework and Deductor analytical platform opportunity analysis has been performed. An AI-system has been proposed for predicting the cost of innovative products in the context of digitalization of the Russian economy. A hypothesis that a neural network makes it possible to obtain a forecast for the cost of innovative products in the Russian Federation has been put forward and proved. The neural network model included such parameters as GDP (billion rubles), key rate (%), RTS index, output of innovative products (billion rubles), costs of innovative products (billion rubles), dollar exchange rate (rubles), balanced profit (billion rubles), risk, loans originated (billion rubles), VIX-Index and forecast for the volume of innovative products (billion rubles). The list of parameters presented reflects the development of both the economic sphere and Russia's financial sector quarterly for the period of from 2015 to 2018. Based on quantization and subsequent visualization of big data and using a multidimensional diagram, the artificial intelligence system developed allows revealing the GDP trend in Russia depending on the cost of innovative products and the VIX option stock-exchange quotation in the global economic landscape. The AI-system that enables prediction for the cost of innovative products using the ""what-if"" function in the Deductor platform has been developed.",60107983,"Volzhsky Polytechnic Institute, Volgograd State Technical University",Volzhsky,Russian Federation,"['1712', '1709', '1707', '1705']",26.444444444444446,0.136,0.534,1,0.08041958041958042,0.05244755244755245,0.36231884057971014
1201,1229,1229,Forecasting the net costs to organisations of building information modelling (BIM) implementation at different levels of development (LOD)," This is an open access article distributed under the terms of the Creative Commons Attribution 4.0 International (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.Numerous frameworks and tools have been proposed in the literature to assess the performance of BIM implementation in the Architecture, Engineering and Construction (AEC). However, there is yet a lack of ex-ante evaluation methods that forecast BIM implementation costs. This study aims to propose an ex-ante evaluation method to forecast the net costs of BIM implementation at different Level of Development (LOD). The proposed method is expected to assist decision makers to find the most cost-saving LOD when investing resources for implementing BIM, from an organisational perspective. The proposed method relies on an Artificial Neural Network (ANN) for each type of implementation costs and benefits. The findings suggest that decision makers need to evaluate an organisation's competency and their implemented BIM applications when choosing the BIM implementation level of BIM. Furthermore, the results show that a higher BIM implementation level does not often secure more benefits. Over 30 features were included in the ANNs with results indicating the possibility of expanding the feature set to obtain more accurate results.",60028333,University of New South Wales (UNSW) Australia,Sydney,Australia,['1706'],25.5,0.18166666666666667,0.5055555555555555,0,0.1308016877637131,0.08438818565400844,0.41304347826086957
1202,1230,1230,On some applications of almost invariant sets,Certain properties of almost invariant subsets of uncountable groups are considered and several applications of those subsets are given in measure theory and general topology.,60071909,Ivane Javakhishvili Tbilisi State University,Tbilisi,Georgia,['1706'],25.0,0.0880952380952381,0.35714285714285715,1,0.07692307692307693,0.0,0.2692307692307692
1203,1231,1231,The effect of textile fine grained mortar layers on reinforced concrete beam,"Textile fine grained mortar (TFGM) is combination of Palm Oil Fuel Ash (POFA) in Fine Grained Mortar (FGM) and Alkali Resistant Glass (AR glass) fibres. TFGM serves as a new innovative of structure technology, which is to strengthen and repair concrete structures with thin layered mortar that can sustain load. This study investigated the effect of using TFGM layers when applying on reinforced concrete (RC) beams. This study aims on replacing the normal mortar with TFGM in order to enhance both the ultimate load carrying behaviour as well as the serviceability and delaying the extension of cracking. Two (2) of RC beams with dimension 150 mm x 200 mm x 2500 mm were strengthened with TFGM made of selected proportioning with 4 and 8 layers. Unstrengthen RC beams were also included as a control specimen with the same dimension. All specimens were tested for the flexural strengthening at 28 days by using BS EN 196-1:2005. The result indicates that TFGM increased the load carrying capacity of RC beams which is about 10 % increment comparison with control specimen. The layers of TFGM were significantly delaying the crack.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1700'],20.777777777777782,0.17224517906336087,0.5958677685950413,1,0.12796208530805686,0.10426540284360189,0.4258373205741627
1204,1232,1232,"VULNERABILITY ASSESSMENT to CLIMATE-INDUCED HAZARDS of the MUNICIPALITY of MASINLOC, ZAMBALES, PHILIPPINES","The Philippines is surrounded by hundreds of kilometers of shorelines wherein communities are increasing and coastal development is emerging fast. Masinloc, Zambales is a coastal municipality wherein 11 out of 13 barangays are situated near the coast which are always affected by climate-induced hazards. The objectives of this study were to assess and validate the climate-induced hazards occurring in Masinloc and assessed the vulnerability of the coastal municipality to these various hazards. Detailed profiling was done to identify hazards of the study area. Vulnerability maps were generated and results revealed that flooding, storm surge and landslide were the most prominent hazards in the area. Results of the vulnerability assessment revealed that Masinloc was moderately vulnerable to storm surge and flooding due to low exposure and sensitivity to flooding and storm surge while its adaptive capacity was very high. Majority of settlements, agricultural lands and population are affected by these hazards. Priority programs to reduce the sensitivity and exposure to storm surge and flooding should be carried out.",60071461,Central Luzon State University,Munoz,Philippines,['1710'],20.875,0.12830000000000005,0.5627,1,0.12087912087912088,0.027472527472527472,0.25280898876404495
1205,1233,1233,Principles and methods of islamic finance," All rights reserved.Islamic finance instruments are those which are compliant with the shar’iah or Islamic jurisprudence. Shar’iah prohibits certain aspects like riba (usury), maisir (gambling), etc., which are against morality. Three principles like principle of equity, participation and ownership are found to rationalize Islamic finance. There are multiple Islamic Financial products that are now in vogue globally. Instruments of Islamic finance are not referred to as “loans’ but rather as financing modes falling under one of the three categories: Profit-and-loss sharing (PLS), non-PLS contracts, and fee-based products. The article also discusses a number of models of Islamic financing that are currently available in the markets.",60103723,"St Xavier's College, Thiruvananthapuram",Thiruvananthapuram,India,['1700'],17.666666666666668,0.12285714285714285,0.19428571428571428,0,0.057971014492753624,0.036231884057971016,0.4461538461538462
1206,1234,1234,"URBAN EFFECTS on LAND SURFACE TEMPERATURE in DAVAO CITY, PHILIPPINES","This study produced spatiotemporal hot and cold spot occurrence maps for Davao City for the period 1994-2019 using land surface temperature (LST) images. Urban heat is theorized to have been affected by some, if not all, of the following impact factors: air pollutant concentrations/particulate matter (PM10), vegetation ""abundance"" (using EVI), building ""density"" (NDBI), albedo, topography, and population density. A mobile traverse sampling was performed in the morning and afternoon of 15 April 2019 to measure PM10 in the city's identified hot spots. The remaining factors were generated from imagery (i.e., Landsat 8, Synthetic Aperture Radar) and obtained from the Philippine Statistics Authority. These factors were analyzed against the LST which was obtained through Project GUHeat's methodology. The relationships between the factors and LST were studied through multiple and quantile regression models (MRM & QRM). Results showed that variable PM10 does not have any significance in the MRM. Meanwhile, QRM were fitted to different quantile values, namely: 10th, 25th, 50th, 75th, and 90th. It is only at the 90th quantile where all the independent variables are good predictors for the LST. Albedo is the most important predictor for the LST at 10th quantile whereas Elev for the 25th quantile. However, when LST is at the 50th, 75th, and 90th quantiles NDBI is the most significant variable at predicting LST. Reliable spatiotemporal assessment and modelling of surface temperature are essential for urban planning and management to formulate sustainable strategies for the welfare of people and environment.",60071492,University of the Philippines Mindanao,Davao,Philippines,['1710'],20.33333333333333,0.1484375,0.51875,1,0.06711409395973154,0.10067114093959731,0.46598639455782315
1207,1235,1235,Giant: The 1-billion annotated synthetic bibliographic-reference-string dataset for deep citation parsing," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Extracting and parsing reference strings from research articles is a challenging task. State-of-the-art tools like GROBID apply rather simple machine learning models such as conditional random fields (CRF). Recent research has shown a high potential of deep-learning for reference string parsing. The challenge with deep learning is, however, that the training step requires enormous amounts of labelled data - which does not exist for reference string parsing. Creating such a large dataset manually, through human labor, seems hardly feasible. Therefore, we created GIANT. GIANT is a large dataset with 991,411,100 XML labeled reference strings. The strings were automatically created based on 677,000 entries from CrossRef, 1,500 citation styles in the citation-style language, and the citation processor citeproc-js. GIANT can be used to train machine learning models, particularly deep learning models, for citation parsing. While we have not yet tested GIANT for training such models, we hypothesise that the dataset will be able to significantly improve the accuracy of citation parsing. The dataset and code to create it, are freely available at https://github.com/BeelGroup/.",60118335,The ADAPT Centre,Dublin,Ireland,['1700'],16.727272727272727,0.08287619047619048,0.6098380952380953,0,0.10454545454545454,0.06363636363636363,0.42924528301886794
1208,1236,1236,Constraints of asymptotic nature and attainability problems Ограничения асимптотического характера и задачи достижимости," All rights reserved.In control problems, construction and investigation of attainability domains and their analogs are very important. This paper addresses attainability problems in topological spaces. Constraints of asymptotic nature defined in the form of nonempty families of sets are used. The solution of the corresponding attainability problem is defined as an attraction set. Points of this attraction set (attraction elements) are realized in the class of approximate solutions which are nonsequential analogs of the Warga approximate solutions. Some possibilities of applying compactifiers are discussed. Questions of the realization of attraction sets up to a given neighborhood are considered. Some topological properties of attraction sets are investigated. An example with an empty attraction set is considered.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],12.888888888888891,-0.095,0.675,0,0.1,0.007692307692307693,0.36220472440944884
1209,1237,1237,THE RICE PLANTING WINDOW in the PHILIPPINES: AN ANALYSIS USING MULTI-TEMPORAL SAR IMAGERY,"Knowing where and when rice is grown is essential for planning and decision-making in relation to food security, as well as in research wherein crop area and calendar are important inputs in crop production simulations, assessment of biotic and abiotic stresses, and analysis of the effect of climate change on crop production, among others. Remote sensing allows for efficient mapping and characterization of rice areas. In this study, we derived the rice planting window in all rice growing regions in the Philippines from 2016 to 2018 using multi-temporal Synthetic Aperture Radar (SAR), specifically TerraSAR-X and Sentinel-1. Using a rule-based method, rice area and Start of Season (SoS) were mapped based on the unique backscatter behaviour of rice corresponding to the initial deliberate agronomic flooding followed by rapid biomass increase. We defined the planting window per year and semester as the 15th and 85th percentile and the peak of planting as the dominant planting date. The accuracy of the rice map was 93% and the SoS was strongly correlated with the actual planting dates reported by farmers (R2 Combining double low line 0.71) based on 482 ground observations in the Philippines in 2018 Semester 1. From this analysis, the planting window in the Philippines for the Semester 2 (wet season) is April-August (peak in June-July), and for Semester 1 (dry season) is September-February (peak in November-December) with large differences across regions. In majority of the regions, the planting window spans more than 100 days, which can have implications on incidence of pests and diseases.",60071480,Philippine Rice Research Institute,Nueva Ecija,Philippines,['1710'],31.625,0.12738095238095234,0.4278388278388278,1,0.07590759075907591,0.066006600660066,0.3519163763066202
1210,1238,1238,Clustering and dislocation loop punching induced by different noble gas bubbles in tungsten: A molecular dynamics study,"Different behaviours of noble gas X (X = He or Ne) atoms in the bulk and on the surface of tungsten (W) have been studied with molecular dynamics simulations to explore the fuzz formation induced by different noble gas bubbles. The formation of X clusters and bubbles in bulk W were simulated at temperatures from 400 to 2000 K. The results showed that higher temperature promotes the nucleation of X bubbles, and the sizes of self-interstitial atoms and X-vacancy clusters of Ne in W were larger than those of He in W at nano-scale, which indicates that Ne atoms can be trapped more easily than He atoms in W. The continuous nucleation processes of He/Ne bubbles near the surface of bulk W were also simulated. When the sizes of the X bubbles were large enough, the behaviour of dislocation loop punching was observed for both He and Ne clusters. From the comparison of the pressure of He/Ne bubble, it is found that the He-bubble can induce the loop-punching with lower critical pressure than the case of Ne-bubble. These results indicate a new understanding of noble gas effects in W in fusion reactors.",60032356,Hunan University,Changsha,China,['1706'],27.42857142857143,0.2155988455988456,0.5877633477633477,1,0.07692307692307693,0.07239819004524888,0.3121951219512195
1211,1239,1239,GIS-BASED MAPPING of LOCAL CLIMATE ZONES USING FUZZY LOGIC and CELLULAR AUTOMATA,"Because of the vague distinction between urban and rural areas, the Local Climate Zone (LCZ) scheme was developed to better analyze the effect of Urban Heat Island. To map the LCZs in a city, the World Urban Database and Portal Tool is used as conventional method. However, this requires the assignment of training areas for each LCZ, which entails local knowledge of the area and may introduce errors, as distinction between LCZ types through visual inspection is inconclusive. This paper aims to develop a methodology and GIS tool to enhance and automate the mapping of LCZs using seven LCZ properties (sky view factor, building surface fraction, pervious surface fraction, impervious surface fraction, building height, roughness length, and surface albedo), and apply it in Quezon City, Philippines which comprises varying land use and land cover. Fuzzy Logic was used to determine the membership percentage of 100 m cells to an LCZ type based on these properties. Cellular Automata was implemented using Python to derive the LCZ map from the fuzzy layers. Results show that seven out of ten built-up LCZs and five out of seven land cover LCZs were identified. Through visual inspection on a basemap, the mapped LCZs was confirmed to match with the features of the city. Land Surface Temperature (LST) derived from Landsat 8 showed that each LCZ type displayed temperatures consistent with those observed from literature. The developed methodology and tool is ready to be used in other cities as long as the input layers are generated.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],25.0,0.03853383458646617,0.23590225563909775,1,0.12411347517730496,0.1099290780141844,0.3678571428571429
1212,1240,1240,Aggregately Regularized Multi-task Matrix Factorization for Household Energy Breakdown,"Household energy breakdown aims to disaggregate the monthly energy consumption into appliance level usage. It is an important but challenging issue due to the cost of hardware deployments. Existing approaches shed light on decomposing the energy in a non-intrusive way and utilizing matrix factorization. However, traditional matrix factorization methods overlook the relations among appliances and aggregations. In this paper, we propose an novel aggregately regularized Multi-task model, Non-negative Matrix Factorization (MultiNMF), to address this issue. By combining the per-appliance tasks with regularizations, MultiNMF can simultaneously infer the appliance level energy usage for users. The model is evaluated on both synthetic and real world datasets with different settings, and the experimental results demonstrate the effectiveness of our approach.",60108757,North China Electric Power University (Baoding),Baoding,China,['1700'],16.714285714285715,0.184375,0.640625,1,0.10714285714285714,0.03571428571428571,0.3560606060606061
1213,1241,1241,An automated framework creating parametric BIM from gis data to support design decisions,"GIS has been primarily used for urban scale projects. On the other hand, BIM has been mainly used for building scale projects. Understanding surrounding site context is essential in building design. Thus, architects often utilize GIS data to build 3D digital and physical models of the surrounding urban/natural context to help them make better design decisions. The primary challenge of building 3D models from GIS data is that the modeling process requires tremendous load of manual work due to the fact that the data scheme used in GIS is not directly compatible with the data scheme used in BIM. In this research, we analyzed the difference between GIS and BIM data schemes, formulated a data mapping protocol, devised algorithms to correctly convert 2D GIS data to 3D geometries in BIM, programed a software prototype that can automatically convert a model from GIS to BIM, and conducted pilot tests of two different cities to verify the validity of the overall framework. This automated system greatly reduced the modeling time, manual workload, and potential manmade errors. It is expected to facilitate architects in rapidly creating 3D models and study the surrounding urban/natural context.",60025664,Dassault Systemes,Velizy-Villacoublay,France,['1705'],23.875,0.12941176470588234,0.42212885154061625,1,0.1509433962264151,0.05660377358490566,0.34134615384615385
1214,1242,1242,Examining multi-level poverty-causing factors of farm household," CC BY 4.0 License.In view of the current research on the factors of poverty at home and abroad, most of them have less background effects on scale and the mechanism. This study uses a multi-level linear regression model and a geographic detector to jointly detect the poverty influencing factors in the study area. This study mainly draws the following three conclusions: (1) There are background effects on the scale of the poverty-stricken factors in the study area, and the background effects have a great impact. (2) At different scales there are significant poverty-stricken factors. (3) Different research methods lead to differences in research results.",60020256,Capital Normal University,Beijing,China,['1710'],21.0,0.0925,0.5225,0,0.05511811023622047,0.0,0.3389830508474576
1215,1243,1243,Data-driven material system of graded concrete structures,"This paper describes the development and results of strategies for improving the environmental and economic aspects of concrete structures. As (marine) sand suitable for concrete construction is becoming increasingly scarce, concrete construction is becoming consequently increasingly expensive. Thus, the need for an alternative building material arises. The inclusion of PET as a replacement for sand and making use of 3D printing as a fabrication method is examined, and the effect on structural performance will be examined further by using a gradient of plastic content. Research methods include the employment of computational design and 3D-printing fabrication tools that incorporate geometric and material constraints tested one-to-one on physical samples. Due to the fact that the material composite functions best in compression, a shell is chosen as a specimen for computational analysis. Based on the global shell´s structural limitations of concrete the effect of local variation in material composition is analysed and evaluated. The goal of the present research is to illustrate a design approach for similar material systems with the aim of improving material properties for use in more environmentally tolerable, efficient and economical building, while testing geometric and material constraints as well as using low cost fabrication methods.",60097321,Architectural Association (AA) School of Architecture,London,United Kingdom,['1705'],24.625,0.17125,0.3983928571428572,1,0.0958904109589041,0.0136986301369863,0.22535211267605634
1216,1244,1244,"RADIOMETRIC CALIBRATION of LANDSAT-8 OLI and SENTINEL-2 MSI IMAGES for WATER QUALITY MODELLING of LAGUNA LAKE, PHILIPPINES","Regular monitoring of water quality in Laguna Lake is important for it supports aquaculture and provides water supply for Metro Manila. Remote sensing makes it possible to monitor the spectral conditions of the lake on a regular time interval and with complete coverage except for the areas with cloud and shadow cover. Along with in-situ water quality measurements, bio-optical models can be developed to determine the relationship between spectral and bio-optical properties of the lake water and consequently enables the estimation of water quality through remote sensing. However, radiometric calibration is needed to minimize the effects of the changing atmospheric conditions over time and to account for the difference in sensors (e.g., Landsat-8 OLI, Sentinel-2 MSI) used for water quality assessment. Canonical correlation analysis is used to detect pseudo-invariant features (PIFs), which are ground objects that do not dramatically vary in spectral properties over time. Road surface and other large man-made infrastructures are the commonly detected PIFs. These PIFs are used to compute for the parameters used to normalize reflectance values of remotely-sensed images obtained on different dates and using different sensors. The normalization resulted to a reduction of difference in reflectance values between the reference image and the adjusted image, though not marginal. This is due to the use of a linear equation to adjust the image, which limits the ability of the reflectance values of the image to fit to the values of the reference image.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],26.444444444444446,0.02901785714285715,0.4082760989010989,1,0.10740740740740741,0.044444444444444446,0.31007751937984496
1217,1245,1245,THE AEROSOLS OPTICAL PROPERTIES INVESTIGATION during the DUST POLLUTION,"At present, the air environment in China is characterized by complex pollution. In this paper, the pollutant sources, transport paths and aerosol optical properties during the dust pollution was conducted to analyse based on ground-based lidar, space-borne sensor and atmospheric transmission model. Firstly, the NMMB/BSC-Dust model, the VIIRS-Suomi NPP date and HYSPLIT were carried out to analyse the dust transport paths and the dust particle size, and then the concentration of particles was analysed. Finally, the optical properties of aerosol particles in the dust weather were studied. During the formation of this weather, there is high dust in the Gobi and Taklamakan deserts. With the influence of wind direction, the dust moves from north to south, and the dust load significantly increased in southern China. Dust at the low altitude is generally transported from the Taklamakan Desert, while dust at the high altitude is generally transported from the Gobi Desert. The hourly average change of PM10 is from 36 μg/m3 to 818 μg/m3, while the hourly average change of PM2.5 is from 15 μg/m3 to 197 μg/m3. The dust was the main cause of the pollution weather. In this study, the formation process of the dust pollution revealed which can be used to provide guidance for government for the prevention work of dust pollution.",60028904,Anhui Institute of Optics and Fine Mechanics,Hefei,China,['1710'],21.4,0.04077777777777778,0.4081111111111112,1,0.06640625,0.1015625,0.29411764705882354
1218,1246,1246,Influence of subjective impressions of a space on brightness satisfaction: An experimental study in virtual reality,"This paper investigates the relationship between participants’ satisfaction with brightness and other key perceptual attributes of the scene to gain insight in how user satisfaction with brightness is influenced by factors other than brightness levels. In this study, a total of 100 participants were immersed in an office space using virtual reality (VR). The brightness level in all immersive scenes were held constant while the office shading system’s design pattern, rendering materials, and furniture were varied to examine how different factors influence the participants’ satisfaction with brightness. Statistical analyses indicate that there is a strong association between participants’ satisfaction with brightness and other perceptual attributes. Additionally, while the effect of furniture on brightness satisfaction was not statistically significant, the analyses revealed that colored materials had a significant effect on participants’ evaluations of their satisfaction with brightness.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,['1705'],27.2,0.08083333333333334,0.6291666666666667,1,0.0784313725490196,0.0,0.2727272727272727
1219,1247,1247,A Social Relationships Enhanced Credit Risk Assessment Approach,"With the rapid growth of personal loan applications, credit risk assessment has become very crucial both in academic and industrial domain. Research literatures show that besides “hard” information, such as individual socio-demographic information and loan application information, “soft” information such as social relationships of the borrowers is a key factor to the credit risk assessment as social capital. In social networks, a user’s position and its influence are affected not only by the direct relationships (its friends) but also the indirect relationships (friends’ friends). A user’s importance and influence in his communities are attractive and valuable for credit assessment. But due to data deficiency in real life, social relationships are rarely considered in lending markets. By leveraging data from various sources, we proposed a social relationship enhanced credit risk assessment system, by building a social network from users’ geolocation data, extracting social relationship features at three different levels: ego, community and global level to capture a user’s position and influence from direct relationships, community and whole network perspectives. A real-life loan granting dataset is utilized for verifying the performance of the system. The experiment results show that, by combining the conventional financial indicators along with the proposed social network features, our system outperforms benchmark methods. Novel social network features we proposed make a good contribution to the loan default prediction. The research highlights the power of social relationships in detecting the default loans.",60014402,Renmin University of China,Beijing,China,['1700'],23.3,0.06890331890331891,0.3663780663780663,1,0.08791208791208792,0.0,0.3161764705882353
1220,1248,1248,Evidential Artificial Immune Recognition System,"Uncertainty is one of the main classification issues that must be handled carefully and not rejected in order to make better decisions. Artificial immune recognition system (AIRS) is an immune-inspired supervised learning classifier that has shown good and competitive classification results. It works perfectly in a certain context, however it is quite the opposite in an environment pervaded with uncertainty. To overcome this limitation, we propose a new approach combining the AIRS and belief function theory one of the well-know theories managing uncertainty. Experimentations on real data sets from the U.C.I machine learning repository show good performances of the proposed approach.",60070639,"Laboratoire de Recherche Opérationnelle, de Décision et de Contrôle de processus",Le Bardo,Tunisia,['1700'],20.2,0.1917316017316017,0.5359307359307358,1,0.14035087719298245,0.02631578947368421,0.2818181818181818
1221,1249,1249,An empirical study of information security management system (ISMS) in Malaysian public sector: A PLS-SEM approach,"Many organizations have embarked on efforts to manage their organizational confidential information by implementing an Information Security Management System (ISMS). Due to organizational exposure to the information security threats, incidents, risks, and vulnerabilities, information security issues are still a major challenge and the effectiveness of ISMS has become a key concern. To improve the effectiveness of ISMS practices in organizations, several attempts have been made in the past to study the critical success factors of ISMS. However, few studies have made attempts to focus on organizational factors, which are essential in ISMS that involve not only technical but also organizational issues. While organizational factors were given emphasis in the literature as factors that should be given attention in security practices, their empirical studies are still lacking. Specifically, little is known about how the factors from the findings of the literature such as information security policy, information technology competency, management commitment, information security awareness and information security standard compliance affect the effectiveness of the ISMS. The conceptual model was proposed and tested to employees who involved with ISMS implementation in Malaysian Public Sector. The data was assessed via Partial Least Squares Structural Equation Modelling (PLS-SEM). The results of the data analysis revealed that information security awareness and information security standard compliance had a significant effect on ISMS effectiveness.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1700'],24.11111111111111,0.008333333333333331,0.365079365079365,1,0.09016393442622951,0.06967213114754098,0.3305785123966942
1222,1250,1250,Finger Gesture Recognition Based on 3D-Accelerometer and 3D-Gyroscope,"Gesture-based interaction, as a natural way for human-computer interaction, has a wide range of applications in the ubiquitous computing environment. The latest research findings reveal that user’s arm and hand gestures are likely to be identified with ease using the motion sensors worn on the wrist, but it is not clear how much of user’s finger gestures can be recognized. This paper presents a method, which is capable of recognizing the bending of fingers, based on input signals from the 3D-accelerometer and 3D-gyroscope worn on the wrist. Features from Time-domain and Frequency-domain are extracted. Gestures are recognized by five classifiers, and the recognition results were then compared with each other. In this paper, maximal information coefficient is adopted for examining the effect of features on the gesture classification. Besides, we work out a faster calculation method, which is based on the features of top 30 maximal information coefficient. Our present results can be widely applied for medical rehabilitation and consumer electronics control based on gesture interaction.",60023380,Chongqing University,Chongqing,China,['1700'],20.75,0.09375,0.4131944444444445,1,0.1065989847715736,0.015228426395939087,0.28342245989304815
1223,1251,1251,Comparison and analysis of the accuracy of gee platform pixel-based supervised classification-taking Shandong province as an example," CC BY 4.0 License.Remote sensing is going through a basic transformation, in which a wide array of data-rich applications is gradually taking the place of methods interpreting one or two imageries. These applications have been greatly facilitated by Google Earth Engine (GEE), which provides both imagery access and a platform for advanced analysis techniques. Within the field of land cover classification, GEE provides the ability to create fast new classifications, particularly at global extents. Despite the role of indices and other ancillary data in classification, GEE platform pixel-based supervised classification (GEE-PBSC), as a relatively fast and common classification method in remote sensing, was not directly analysed and assessed about accuracy in current researches. We ask how high the classification accuracy of GEE-PBSC is, and which type of land cover is more suitable to be classified by GEE-PBSC method with a credible accuracy. Here we adopt GEE-PBSC method to classify Landsat 5 TM imageries in Shandong province in 2010, and compare the result with GlobeLand30 product in 2010 from three aspects: type composition, type confusion and spatial consistency to assess the classification accuracy. Before the comparison, multiple cross-validation, which shows that the overall average test accuracy is about 74%, is required to ensure the reliability. The comparison experiment shows that the spatial consistency ratio of artificial surface, cultivated land and water is about 99.30%, 85.78% and 73.02% respectively. The pixel purity of artificial surface and cultivated land is about 90.26% and 81.45% respectively. The overall spatial consistency ratio is about 82.04%. Although the GEE-PBSC method can achieve high test accuracy, the result is still far from GlobeLand30 product in 2010. Because the GEE-PBSC only uses the pixel information of imageries and does not integrate other multi-source data to assist classification. In addition, classification result also shows that using GEE-PBSC to classify artificial surface and cropland has obvious advantages over other land classes, and their classification results is close to GlobeLand30.",60073476,National Geomatics Center of China,Beijing,China,['1710'],24.615384615384613,0.02285511363636364,0.4776420454545454,0,0.07751937984496124,0.05167958656330749,0.3370165745856354
1224,1252,1252,Ambition and consequences the future of iran's involvement in latin america after the nuclear agreement of 2015,"The Joint Comprehensive Plan of Action (JCPOA) was reached in 2015 after years of involved talks between world powers (the United States of America, Russia, the United Kingdom, China, France, and Germany) and the Islamic Republic of Iran. Negotiations between Iran and the five permanent members of the United Nations (UN) Security Council (plus Germany) began in 2006, but suffered many setbacks, causing a delay in finalizing the agreement. One major obstacle involved several of the negotiating countries imposing numerous sanctions against Iran, causing public resentment and economic hardships to the Iranian people. For the United States of America (USA) involvement in such talks was unique, as the two countries had not negotiated directly for more than three decades. Since the beginning of the Islamic Revolution the UN and USA imposed (and later expanded) trade embargoes, asset freezing, and economic sanctions on Iran due to its ""terrorist activities"". This article will examine the effect of the Iranian Nuclear Agreement on the future of Iran's ambition of expansion in Latin America by focusing on what little influence the Nuclear Deal had on Iran's hegemonic and hostile behavior in its own region, and using it to measure how it would decide to expand into Latin America. This paper explores the Islamic Republic of Iran's involvement in Latin America before the JCPOA was reached in 2015, highlighting the essence of Iranian ambition directed at creating a safe haven for its covert activities in the backyard of its perceived historical enemy: the United States of America. The presence of Iran and its presumed hidden agenda and strategies in Latin America are analyzed here in an attempt predict Iran's future plans in Latin America, especially when the world is expecting it to make progress and abandon its so-called ""terrorist activities"". This paper highlights the four factors that play an important role in the long-established aspirations of the Iranian government to expand its revolution beyond its borders in order to establish a global Islamic entity. This would eventually create a new world order where Iran is a key player in world politics, and the USA and Europe have limited influence. These four points can be categorized as the contributing factors that will shape and determine Iran's future in Latin America. These four factors are: Iran’s constitutional revolutionary principles, Iran's hegemonic activities in the Middle East, the Iranian-Saudi rivalry and their competition over expanding Latin American relations, and the effect of the nuclear agreement on modifying Iran’s behavior towards the US and the rest of the world. This paper attempts to answer this question: how effective was the Nuclear Deal in curbing Iran's ambitious plan of expanding its influence in Latin America? By answering this question, this paper offers new insights into Iranian– Latin American relations that have been flourishing over the past decade but have garnered little attention in the media, academia, or among decision makers in the Persian/Arab Gulf region and the West. The author concludes that reaching and implementing the Nuclear Deal has done little to stop Iran from pursuing destabilizing activities beyond its borders, specifically through political, intelligence, and military interference in the Persian/Arab Gulf region and other Arab countries-particularly Syria, Lebanon, and Yemen. Therefore, Tehran sees expansion in Latin America as inevitable, as Iranian interest in the region increases in an effort to protect the global advancement of its protege Hezbollah.",60077854,"University of Kuwait, College of Social Sciences",Kifan,Kuwait,['1700'],37.266666666666666,0.0781309775495822,0.3715569314406524,1,0.09937888198757763,0.14285714285714285,0.32701421800947866
1225,1253,1253,Individual factors that affect the training participation of academic staff at Malaysia’s public universities: View of administrative officers,"This study is aimed at exploring the individual factors affecting academic staff in the training program based on the views of the officer that manages the training at Malaysia’s Public Universities. The exploration data for this study was obtained using a qualitative method where a total of seven officers in charge of the training department from seven public universities were interviewed. The data were analyzed to help of NVivo version 10 software to build code and themes for studying the issues. This study found total five individual factors influenced training participation for academic staff. These factors were revealed as attitude, awareness of staff, personal limitations, promotion, and internal conflict management. The findings give significant impacts to increase the understanding of involvement in training programs. This study potentially benefits for the administrator to achieve training objectives in Malaysia’s Public Universities. In addition, this finding also provides an outlook for organizations to fulfil training objectives based on academic staff needs.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1700'],19.75,0.026785714285714284,0.3339285714285713,1,0.1329479768786127,0.028901734104046242,0.3142857142857143
1226,1254,1254,Increasing underutilised data in India: Opportunities and challenges,"India, a country with a population of 1.33 billion has observed a substantial increase in the number of smart phones and internet users. This increase in internet users has not only changed the way Indian spend their time but has also led to generation of huge chunks of structured and unstructured data in India. In today’s world where data of consumers is significant, this rise of internet users in India can change the game. This study focuses on how this increase in underutilised data in India, especially unstructured data can provide various opportunities and challenges to businesses, government and healthcare sectors in India.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],25.75,0.08418367346938775,0.7596938775510205,1,0.08928571428571429,0.05357142857142857,0.3185840707964602
1227,1255,1255,Towards the control of epidemic spread: Designing reinforcement learning environments," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Throughout history, epidemic outbreaks have led to spikes in human illness and mortality, with major challenges to communities and society in general. An epidemic situation requires decisions to be made about interventions that could reduce or contain the disease spread, taking into account all the information received and the projections of the current situation into the future. Decisions made by public health officials involve determining the best sequence of actions to perform from a set of alternatives (school closure, vaccination, isolation). In order to decide which intervention strategies to implement, decision makers need to analyse a large number of scenarios and variables. This task can be overwhelming. Reinforcement Learning (RL) optimisation strategies have been proposed in the past years to automatically find optimal intervention strategies for a disease spread in order to support decision makers. An important component in RL is the environment, which describes the task that the RL agent (solution approach) aims to optimise. This work focuses on how to design environments to represent the problem of epidemics and finding optimal interventions. We present different challenges that need to be addressed for environment design and provide diverse examples from the state of the art.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],23.11111111111111,0.1651190476190476,0.418015873015873,0,0.13852813852813853,0.04329004329004329,0.34051724137931033
1228,1256,1256,EVALUATING the INFLUENCE of SATELLITE OBSERVATION on INVERSING NOX EMISSION at REGIONAL SCALE,"In order to explore the influence of satellite observation data on the top-down NOx estimates at regional scale, the top-down NOx emissions for Yangtze River Delta (YRD) region at 9 km spatial resolution were developed with Peking University Ozone Monitoring Instrument NO2 product (POMINO) v1 and POMINO v2 satellite observation data in January and July of 2016. The differences of top-down NOx estimates derived from the two satellites were quantitative evaluated, and the reasons were comprehensively analyzed. The total NOx emissions based on POMINO v2 in January and July was 27% and 45% higher than those derived with POMINO v1, respectively. It indicated that the difference of top-down estimate derived from different satellite observation in summer was larger than that in winter. Considering that the difference between the two observations in January was similar to that in July, it was mainly because that the sensitivity of NO2 concentration to emissions was larger in summer than in winter. Top-down estimates derived from the two satellite observation were evaluated with air quality model (AQM) and ground observation. The model performances derived from top-down NOx emission based on POMINO v1 were better than those based on POMINO v2. The probable reason was that the NO2 vertical column densities (VCD) in POMINO v1 was closer to available ground-based MAX-DOAS observations during cloudless days and the satellite observation of cloudless was usually selected to inversing NOx emission.",60064143,Nanjing University of Information Science and Technology,Nanjing,China,['1710'],29.0,0.09761904761904762,0.3809523809523809,1,0.07037037037037037,0.1259259259259259,0.35826771653543305
1229,1257,1257,Convolutional neural network-based automatic prediction of judgments of the european court of human rights," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In the past few years, predictive modelling has brought revolutionary changes in the way various industries function. Advancements in the areas of Deep Learning (DL) and Natural Language Processing (NLP) have made their application to different problem areas highly promising. In the legal domain, positive results have been obtained in predicting the judgements of various Courts of different countries using DL and NLP. However, not much research has been carried out in the area of legal judgement forecasting for the European Court of Human Rights (ECHR). The models designed in the previous research employ only one Machine Learning algorithm namely a Support Vector Machine (SVM) to solve such problem. This study applies DL and NLP to the problem of automatic prediction of judgements for ECHR. Extensive experiments are conducted which compare the performance of models trained on SVM with linear kernel as part of previous research (Medvedeva, Vols & Wieling, 2018) with the models trained on Convolutional Neural Networks (CNN) as proposed in this study. To implement this, state-of-the-art NLP techniques are applied to the text data. Moreover, pre-trained and custom trained Word Embedding text representations are considered. Statistical tests are performed to gather sufficient statistical evidence to determine which algorithm performs better at providing a solution to this problem. Based on the results obtained, it is established that overall, CNN models outperform SVM models as the former achieves an average accuracy of 82% whereas the latter achieves 75%. Specifically, CNN models for four Articles out of nine achieve statistically significant higher accuracy than SVM models.",60012873,Technological University Dublin,Dublin,Ireland,['1700'],22.33333333333333,0.052377220480668764,0.3633490073145246,0,0.10543130990415335,0.14376996805111822,0.45751633986928103
1230,1258,1258,Axiomatization and characterization of BSP algorithms,"Bulk-Synchronous Parallel (BSP ) is a bridging model for HPC (High Performance Computing) algorithm design. It provides a conceptual bridge between the physical implementation of the machine and the abstraction available to a programmer, while having portable and scalable performance predictions of BSP algorithms on most HPC systems. Two questions may come to mind. What are formally BSP algorithms? And how to ensure that the programmer can effectively program every BSP algorithm with a BSP language, especially with the right cost? Gurevich proved that three convincing postulates for the sequential algorithms are equivalent to what is called Abstract State Machines (ASMs ), and thus that ASMs capture the sequential algorithms. Firstly, we extend these sequential postulates and ASMs in order to intuitively and realistically capture the BSP algorithms (and not more). Secondly, by using an operational semantics and an algorithmic simulation, we prove that [Formula presented] is equivalent to [Formula presented], a minimal imperative BSP programming language. Therefore, BSP programming languages (extending at least [Formula presented]) are BSP algorithmically complete, involving the definition of a class model of the BSP algorithms.",60013373,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,"['1712', '1703']",25.857142857142854,0.14304761904761906,0.4767936507936508,1,0.09767441860465116,0.06976744186046512,0.4225352112676056
1231,1259,1259,Perception and exception of E-banking services of commercial banks in India,"Banks need to understand the attributes that customer use to judge service quality and enhance service quality. The paper tries to examines the customers’ perceptions and expectation towards internet banking service quality of banks in Villupuram district, Tamilnadu. Information quality (content), aesthetic design, ease of use, reliability, responsiveness, security and service variety dimensions were identified to measure the service quality of internet banking. The researcher determines 385 sample for the study by adopting Cochran (1977) formula. E-banking service quality scalewas refined and it turnup with six dimensions and 23 items, loss of 18 items and responsiveness dimension in purification of scale.The study performed the perception-expectation matrix to provide strengths and weaknesses of six dimensions of the e-service quality of the banks. The e-service quality are presented in two dimensional chart to provides the cues on the dimension of e-service quality, which enables the bank to improve or sustain the various service with limited time and resources. Security and service variety comes under low-priority improvement area. The dimension of aesthetic design, reliability and information quality comes under maintenance reinforcement area.",60027171,Annamalai University,Chidambaram,India,['1700'],22.375,-0.057142857142857134,0.3476190476190477,1,0.09767441860465116,0.027906976744186046,0.32338308457711445
1232,1260,1260,Scidb based framework for storage and analysis of remote sensing big data,"<p>Earth observation data of large part of the world is available at different temporal, spectral and spatial resolution. These data can be termed as big data as they fulfil the criteria of 3 Vs of big data: Volume, Velocity and Variety. The size of image in archives are multiple petabyte size, the size is growing continuously and the data have varied resolution and usages. These big data have variety of applications including climate change study, forestry application, agricultural application and urban planning. However, these big data also possess challenge of data storage, management and high computational requirement for processing. The solution to this computational and data management requirements is database system with distributed storage and parallel computation.</p><p>In this study SciDB, an array-based database is used to store, manage and process multitemporal satellite imagery. The major aim of this study is to develop SciDB based scalable solution to store and perform time series analysis on multi-temporal satellite imagery. Total 148 scene of landsat image of 10 years period between 2006 and 2016 were stored as SciDB array. The data was then retrieved, processed and visualized. This study provides solution for storage of big RS data and also provides workflow for time series analysis of remote sensing data no matter how large is the size.</p>.",60105899,"NOVA Information Management School, Universidade Nova de Lisboa",Lisboa,Portugal,['1710'],21.3,0.059441964285714285,0.2716964285714286,1,0.0942622950819672,0.036885245901639344,0.3157894736842105
1233,1261,1261,AN INTER-COMPARISON of the SPATIAL and TEMPORAL CHARACTERISTICS of CO over HIGH FIRE REGIONS BASED on MOPITT and GFED,"The spatial and temporal distributions of Carbon Monoxide (CO) as measured by the Moderate Resolution Imaging spectroradiometer (MOPITT) instrument are analyzed in depth in this work. We specifically look at how these values, their statistics and their trends behave from 2000 to 2018 over regions defined as high fire regions, based on the carbon emissions product from the Global Fire Emission Database (GFED). Our results indicate that there are significant differences in the timing, duration, and magnitude of the fires as measured by MOPITT over different high fire regions. Our results are also different from past studies which have relied upon remotely sensed aerosol measurements, such as AOD. Over these high fire regions, we find that the fires contribute the vast majority of the CO loading, which always occurs over a short period of time, on order of weeks. Over 7 regions studied, we have found a statistically significant decreasing trend, albeit smaller than the measurement error. The correlation between the MOPITT and GFED approaches if found to be reliable over the regions where the two datasets overlap. We finally find evidence for possible long-range transport of CO from one fire region to another.",60021182,Sun Yat-Sen University,Guangzhou,China,['1710'],24.25,0.05176470588235295,0.5894117647058823,1,0.08181818181818182,0.08181818181818182,0.3440366972477064
1234,1262,1262,Modularizing tensegrity systems: An approach to controllable independent modules,"Tensegrity structures are among the most efficient types of structures. Since the introduction of tensegrity structures by Richard Buckminster Fuller, there has been a lot of interest from architects and engineers to further study tensegrity structures and expand their use cases and application. Roadblocks such as complexity of simulation and unpredictability of their behavior, as well as their nonlinear reaction to side forces, have made it difficult to use them routinely in the realms of architecture and engineering. Many research projects have studied the dynamics of tensegrity structures and possibilities for expanding them beyond a single module. While most of the previous research contributes to the control systems for interdependent tensegrity modules, limited research has been performed on simple ways to expand the tensegrity systems using independent modules or blocks. The objective of this paper is to introduce a new method for easy expansion of tensegrity structures using independent modules. Leveraging experimental methods, a new component called “node” is introduced to the tensegrity module to provide the possibility for the interaction of two adjacent modules. Simple grids of the new expandable modules are simulated to verify the stability of newly designed systems and identify the key variables for controlling interdependent modules. Factors such as tension, displacement, and utilization are also analyzed in the simulations.",60001439,Pennsylvania State University,University Park,United States,['1705'],23.777777777777782,0.08042109405745769,0.438164108618654,1,0.09482758620689655,0.017241379310344827,0.3275862068965517
1235,1263,1263,The behavior of small sets under the product operation,"For invariant (quasi-invariant) s-finite measures on an uncountable group (G, ·), the behavior of measure zero sets with respect to the product operation is studied.",60071901,Georgian Technical University,Tbilisi,Georgia,['1706'],25.0,0.0,0.0,1,0.027777777777777776,0.0,0.375
1236,1264,1264,Understanding the characteristics of UX Malaysia UXD community of practice (CoP): A participants’ observation,"This study reports on the research involving the use of a participant observation approach to understand the characteristics of UX Malaysia, a community of practice for user experience design (UXD). This qualitative approach provides insight into the behaviour, characteristics and attitude of the members of the community of practice which they may not express when other research approaches are used. The results reveal deep insight about the characteristics of the observed community of practice.",60016775,International Islamic University Malaysia,Kuala Lumpur,Malaysia,['1700'],24.66666666666667,-0.0625,0.3875,1,0.09876543209876543,0.037037037037037035,0.2716049382716049
1237,1265,1265,Gated Self-attentive Encoder for Neural Machine Translation,"Neural Machine Translation (NMT) has become a popular technology in recent years, and the RNN-based encoder-decoder model is its actual translation framework. However, it remains a major challenge for RNNs to handle long-range dependencies. To address this limitation, we propose a gated self-attentive encoder (GSAE) for NMT that aims to directly capture the dependency relationship between any two words of source-side regardless of their distance. The proposed GSAE gains access to a wider context and ensures the better representation in the encoder. We extensively evaluate the proposed model using three language pairs. Experiments on WMT’14 English-German and WMT’14 English-French tasks show that our shallow model achieves BLEU = 26.54 and BLEU = 38.94 respectively, which are comparable with the state-of-the-art deep models. On WMT’17 English-Chinese translation task, our GSAE-NMT outperforms two strong baselines by 1.61 and 1.15 BLEU points, respectively.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],20.0,0.11354166666666668,0.4013888888888889,1,0.09392265193370165,0.08839779005524862,0.4723926380368098
1238,1266,1266,Period control of the coupled clock and cell cycle systems,"The mammalian clock and cell cycle are two essential biological oscillators. In this work we investigate the coupling of these oscillators via non-linear dynamical modeling. We use previously developed reduced models of these systems and study a molecular interaction of MPF (mitosis promoting factor) repression by the CLOCK:BMAL1 protein complex, via induction of the repressor wee1. Furthermore, we propose an hypothesis whereby the clock responds to cell cycle Growth Factors (GFs) via a pathway involving the non-essential cell cycle complex cyclin D/cdk4 and study this interaction in the context of unidirectional clock → cell cycle coupling. We observe 1:1, 3:2, 4:3, 5:4 ratios of clock to cell cycle period and identify GF and the coupling strength cb as decisive control parameters for the systemfs state of synchronization. Synchronization ratios differing from 1:1, namely 3:2 and 5:4, have been observed in cells treated with the corticosteroid Dexamethasone (Dex). Here, we study Dex application and are able to reproduce the induction of ratios differing from 1:1. Finally, because slowing down the cell cycle is very relevant in the context of cancer therapies, we devise particular protocols of cell cycle period control with the use of clock inputs that are successful in substantially slowing down the cell cycle by the use of the systemfs synchronization dynamics, obtaining 2:3, 3:4, 4:5 ratios of clock to cell cycle period.",60110693,Université Côte d'Azur,Nice,France,"['1712', '1709', '1707', '1705']",28.0,0.10232323232323233,0.53510101010101,1,0.0888030888030888,0.05791505791505792,0.3557312252964427
1239,1267,1267,Centralized Reasoning Translation and Its Computing Complexity for Heterogeneous Semantic Mappings,"Bridge rules provide an important mechanism for describing semantic mapping and propagating knowledge for distributed dynamic description logics (D3L). The current research focuses on the homogeneous bridge rules that only contain atomic elements. In this paper, the research is extended to the D3L reasoning problem with heterogeneous bridge rules that contain composite elements in subset ends. The regularity of the distributed knowledge base is defined. Through the alteration of the bridge rules and transforming different forms into existing language mechanisms, we present an algorithm that can convert the D3L knowledge base with dynamic description logic DSROIQ as the local ontology language into a single DSROIQ knowledge base. Next, we study the properties of the algorithm. We prove that the algorithm will terminate in polynomial time and that the satisfiability of the target knowledge base is equivalent to the satisfiability of the original knowledge base. Thus, we prove that the worst-case time complexity of the centralized reasoning on the regular D3L knowledge base with such bridge rules is the same as that on a single DSROIQ knowledge base. The method proposed in this paper makes centralized reasoning for D3L obtain the same worst-case time complexity as the existing distributed reasoning method and solves the problem that the latter cannot handle heterogeneous composite bridge rules.",60025569,Tianjin Polytechnic University,Tianjin,China,['1700'],23.66666666666667,-0.2069940476190476,0.5141178266178266,1,0.12446351931330472,0.034334763948497854,0.24890829694323144
1240,1268,1268,A modular framework for verifying versatile distributed systems,"Putting independent components together is a common design practice of distributed systems. Besides, there exists a wide range of interaction protocols that dictate how these components interact, which impacts their compatibility. However, the communication model itself always consists in a monolithic description of the rules and properties of the communication. In this paper, we propose a mechanized framework for the compatibility checking of compositions of peers where the interaction protocol can be fine tuned through assembly of basic properties on the communication. These include whether the communication is point-to-point, multicast or convergecast, which ordering-policies are to be applied, applicative priorities, bounds on the number of messages in transit, and so on. Among these properties, we focus on a generic description of multicast communication that encompasses point-to-point and one-to-all communication as special cases. The components that form the communication model are specified in TLA+, and a system, composed of a communication model and a specification of the behavior of the peers (also in TLA+ ), is checked with the TLA+ model checker. Eventually we provide theoretical views on the relations between ordering-policies through the lenses of multicast and convergecast communication.",60102124,Université Fédérale Toulouse Midi-Pyrénées,Toulouse,France,"['1712', '1703']",23.625,0.08597883597883599,0.3134920634920635,1,0.09251101321585903,0.00881057268722467,0.32701421800947866
1241,1269,1269,A Smart Search-Based Ontology Visualization Tool Using SPARQL Patterns,"We are proposing a semantic approach that aims to identify valid linguistic web services composition scenarios. It targets both linguistic and software engineering experts. It is based on an OWL2 multilingual ontology, named LingOnto which models and reasons about linguistic knowledge. However, users especially non-ontology experts have difficulty to make sense of LingOnto as they do not understand its syntax. Hence, we decide to visualize LingOnto to attempt this issue. Nevertheless, the heterogeneity and the amount number of linguistic knowledge make the visualisation hard to comprehend due to visual clutter and information overload. In this paper, we propose a user-friendly ontology visualisation tool, named Ling-Graph. It targets both ontology and non-ontology experts and addresses the readability and understandability requirements. Ling-Graph is based on a “smart” search interaction technique, to extract and visualize, from LingOnto, a dynamic ontological view that contains only components corresponding to the user’s need. It is relied on a SPARQL patterns-based approach which takes the user’s need materialized by a set of search criteria as input and generates the ontological view that matches these criteria. The obtained tool is also applied to visualize the PersonLink ontology for non-ontology experts and a large-scale ontology DBpedia for ontology experts. Finally, we discuss the promising results derived from the evaluation of Ling-Graph.",60064746,University of Sfax,Sfax,Tunisia,['1700'],17.666666666666668,0.03058608058608059,0.4327838827838828,1,0.125,0.05078125,0.3458333333333333
1242,1270,1270,Some decidability results on one-pass reductions,"We show second-order decidability results on recognizable tree languages and one-pass reduction sequences with special term rewriting systems. For some classes of term rewriting systems the second-order IO one-pass inclusion problem, the second-order IO one-pass reachability problem, and the IO and OI one-pass common ancestor problems are decidable.",60027332,Szegedi Tudományegyetem (SZTE),Szeged,Hungary,"['1712', '1703']",24.0,0.1023809523809524,0.4404761904761905,1,0.045454545454545456,0.06060606060606061,0.5
1243,1271,1271,Multi-attention Item Recommendation Model Based on Social Relations,"Incorporating social relations in recommendation provides a promising way to alleviate problems of sparsity and cold start in collaborative filtering methods. However, most existing methods do not yet take into account social relations in a relative complete way. Besides the differences between preferences of friends, connection strength and expertise differences of users on a given item also have impacts on the spread of preference between friends. In this paper, we propose a social-aware recommendation model named Multi-Attention Item Recommendation model based on Social relations (MAIRS) which allows us to select more informative friends from the perspectives of their preferences, connection strengths, and expertise on items by their own respective attention models. And then, the three attention models are fused together by utilizing an aggregation function. We compare our method with state-of-the-art models on three real-world datasets: Delicious, Ciao and Epinions. The experimental results show that our method consistently outperforms state-of-the-art models in terms of several ranking metrics.",60014966,Peking University,Beijing,China,['1700'],22.428571428571423,0.18333333333333326,0.39,1,0.08854166666666667,0.052083333333333336,0.39080459770114945
1244,1272,1272,Knowledge-based geospatial data integration and visualization with Semantic Web technologies,"Geospatial information is indispensable for various spatially-informed analysis and decision-making, e.g. traffic analysis and built environment processes. Geospatial data often must be integrated for meaningful analysis, whereas such integration is challenging due to siloed data organization, semantic heterogeneity and multiple representation of geospatial data. Moreover, the visualization of geospatial data is one of the most prominent ways of utilizing geospatial data, however how to properly visualize the data is sometime difficult, as it pertains to a wide range of visualization (cartographic) knowledge. Semantic Web technologies unveil a promising way to mitigate these issues, as they provide means of data integration on the Web, and knowledge representation capacity to formally represent the visualization knowledge. In this PhD project, we investigate the potential values of Semantic Web technologies for geospatial data integration (particularly for geospatial data with multiple representation) and visualization in several cases, where the integration and visualization knowledge is formalized using Semantic Web technologies. All the case studies embody realworld meaning and entail data integration and visualization challenge, which have been addressed by state-of-the-art solutions inadequately. Preliminary results demonstrate great yet not fully unlocked potential of Semantic Web technologies for geospatial data, and also disclose challenges that need to be addressed.",60029170,Lunds Universitet,Lund,Sweden,['1700'],25.125,0.14956140350877192,0.5451754385964913,1,0.08974358974358974,0.021367521367521368,0.3244444444444444
1245,1273,1273,Population-based meta-heuristic for active modules identification,"The identification of condition specific gene sets from transcriptomic experiments has important biological applications, ranging from the discovery of altered pathways between different phenotypes to the selection of disease-related biomarkers. Statistical approaches using only gene expression data are based on an overly simplistic assumption that the genes with the most altered expressions are the most important in the process under study. However, a phenotype is rarely a direct consequence of the activity of a single gene, but rather reflects the interplay of several genes to perform certain molecular processes. Many methods have been proposed to analyze gene activity in the light of our knowledge about their molecular interactions. We propose, in this article, a populationbased meta-heuristics based on new crossover and mutation operators. Our method achieves state of the art performance in an independent simulation experiment used in other studies. Applied to a public transcriptomic dataset of patients afflicted with Hepatocellular carcinoma, our method was able to identify significant modules of genes with meaningful biological relevance.",60110693,Université Côte d'Azur,Nice,France,"['1712', '1709', '1707', '1705']",23.714285714285715,0.1823438466295609,0.5062822098536385,1,0.08743169398907104,0.01092896174863388,0.2849162011173184
1246,1274,1274,The spatial and temporal availability differences of cloud-free landsat images over three gorges reservoir area,"Availability analysis of cloud-free optical remote sensing data is a prerequisite for remote sensing applications. In this study, spatio-temporal availability differences of cloud-free Landsat TM, ETM+, and OLI sensors images over Three Gorges Reservoir Area (TGRA) were analyzed from 1986 to 2019 based on the Google Earth Engine (GEE). The results show that: 1) in Summer, especially in August, the probabilities of obtaining Landsat images with no more than 30% cloud cover (CC) is higher. 2) the northeast of TGRA has higher probability of acquiring cloudless images than the southwest. 3) In TGRA, annual monitoring which require at least one cloud-free observation in a year largely unaffected by CC, but when considering seasonal monitoring, cloud contaminate will become a limitation, and monthly monitoring in this area is basically not feasible even if the three sensors data are combined. The results of this paper will provide important references for the research of using optical data in this area, and although the research area is relatively small, the analysis method and the program developed in this paper have no restrictions on the area.",60013789,Beihang University,Beijing,China,['1710'],30.16666666666667,0.004166666666666668,0.43333333333333335,1,0.06451612903225806,0.06912442396313365,0.39712918660287083
1247,1275,1275,Standard dynamic financial analysis and control tools of an enterprise in the time of digital economy,"The paper provides for and tests the standard dynamic tools that can be used for more effective monitoring of the company management performance aimed at financial stability in the time of digital economy. This paper elaborates on the concept of diagnostics of structural dynamics of economic systems suggested by I.M. Syroezhin. In the study, a standard dynamic model has been developed for diagnostics and monitoring of the financial stability of an enterprise given the changes introduced on July 1, 2019 in accounting in the RF, and some tools have been suggested for estimating the integral indicator and factor analysis. The suggestions of the authors have been tested through comparison of traditional approaches and the presented tools for diagnosing the financial stability of an enterprise. The developed tools can be used for both external control over financial activities of an enterprise, and operative internal control and monitoring of the current trends in the change of the financial status. The suggested methods are aimed, primarily, at realizing the objectives of financial control ensuring the interests of the enterprisefs owner. It is caused by the need to take managerial decisions quicker in the time of increasingly faster changes in the economic system. The suggested tools make it possible to realize more effective feedback between management actions and their outcomes at the level of the enterprise. CCS CONCEPTS . Applied computing Economics . Social and professional topics Economic impact KEYWORDS Financial stability of an enterprise; Standard dynamic analysis; Ordinal model; Diagnostic and monitoring tools; Financial control.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",21.0,0.11041666666666668,0.2255208333333333,1,0.1033210332103321,0.025830258302583026,0.3235294117647059
1248,1276,1276,PRELIMINARY SENSITIVITY STUDY of AEROSOL LAYER HEIGHT from SYNTHETIC MULTIANGLE POLARIMETRIC REMOTE SENSING MEASUREMENTS,"Many previous studies have shown that multiangle, multispectral polarimetric remote sensing can provide valuable information on aerosol microphysical and optical properties, in which the aerosol layer height (ALH) is an important parameter but with less studies, especially in the near-ultraviolet (near-UV) and visible (VIS) wavelength bands. Based on the optimal estimation (OE) theory and information content analysis method, we focus on the sensitivity study of ALH with the synthetic data in the near-UV and VIS wavelength in the range of 410-865 nm, and further to assess the capability of multiangle intensity and polarization measurements for the retrieval of ALH. Unified Linearized Vector Radiative Transfer Model (UNL-VRTM) has been used as the forward model to simulate the intensity and polarized radiance at the top of atmosphere (TOA), as well as the Jacobians of TOA results with respective to corresponding parameters. The degree of freedom for signal (DFS) and a posteriori error are introduced to quantity the information content of ALH from the intensity and polarization measurements, respectively. By assuming the surface type, aerosol model, aerosol loads, prior errors and observation geometries, the sensitivity of ALH has been preliminarily investigated. The sensitivity study results show that the near-UV and polarization measurements are the important source of information content for the aerosol height retrieval in satellite remote sensing.",60019499,Chinese Academy of Sciences,Beijing,China,['1710'],35.833333333333336,0.09743589743589744,0.41025641025641024,1,0.050387596899224806,0.10465116279069768,0.34552845528455284
1249,1277,1277,SPATIAL and TEMPORAL DISTRIBUTION of the CLOUD HEIGHT and CLOUD THICKNESS over CHINA and the ADJACENT AREAS BASED on CALIOP,"Based on CALIOP data, spatial and temporal distribution of cloud height and thickness over China as well as the adjacent areas have been analysed in this paper. The results show significant regional differences. The heights of clouds that lie to the south of 27.6°N are greater than those to the north of 27.6°N. The highest and thickest clouds are located above the Bay of Bengal and the Western Pacific, while the lowest values distribute in the northwest of the Tibetan Plateau and Sichuan Basin. The clouds ranging from 0.3 km to 0.6 km thickness account for a large proportion of total clouds. And the probability of occurrence of clouds decreases as cloud thickness increases. Overall, within the area under study, the thick clouds are higher than the thin clouds. Besides, low and thin clouds occur more frequently than high and thick clouds. As for their seasonal variation, the height of clouds peaks in summer. In addition, the mean of cloud thickness to the south of 27.6°N is 2.4 km thicker in summer than in any other season.",60016318,Chengdu University of Information Technology,Chengdu,China,['1710'],17.7,0.01454365079365078,0.4725595238095238,1,0.05025125628140704,0.05025125628140704,0.31958762886597936
1250,1278,1278,Studies on infrared and Raman spectroscopy of molecules,"Raman qualitative analysis is a vital tool within the field of wave qualitative analysis and is complementary to infrared absorption qualitative analysis, the latter being a lot of common waves of qualitative analysis. Its value accenting that these 2 spectroscopies don't probe constant wave data of a molecule. Raman associate analysis of spectrographic analysis of chemical relies on an inflexible scattering method, whereas infrared associate degreealysis spectrum analysis spectrographic analysis chemical relies on an absorption method. Raman qualitative analysis detects vibrations involving an amendment in polarizability, whereas infrared qualitative analysis detects vibrations involving an amendment in the moment. As a result, the 2 spectroscopies have totally different choice rules and it's attainable that a powerful vibration mode in Raman qualitative analysis might be a weak one in infrared qualitative analysis and the other way around. In reference to this, Raman qualitative analysis is usually possible with binary compound solutions, whereas infrared qualitative analysis is severely restricted thanks to the excessive absorbance of water.",60033193,Jai Prakash University,Chapra,India,['1700'],27.16666666666667,-0.07083333333333335,0.5527777777777778,1,0.06779661016949153,0.02824858757062147,0.192090395480226
1251,1279,1279,Image2StyleGAN: How to embed images into the StyleGAN latent space?,"We propose an efficient algorithm to embed a given image into the latent space of StyleGAN. This embedding enables semantic image editing operations that can be applied to existing photographs. Taking the StyleGAN trained on the FFHD dataset as an example, we show results for image morphing, style transfer, and expression transfer. Studying the results of the embedding algorithm provides valuable insights into the structure of the StyleGAN latent space. We propose a set of experiments to test what class of images can be embedded, how they are embedded, what latent space is suitable for embedding, and if the embedding is semantically meaningful.",60092945,King Abdullah University of Science and Technology,Jeddah,Saudi Arabia,"['1712', '1707']",20.6,0.525,0.625,1,0.16666666666666666,0.008771929824561403,0.34210526315789475
1252,1280,1280,PREDICTION of FLASH FLOOD SUSCEPTIBILITY USING FUZZY ANALYTICAL HIERARCHY PROCESS (FAHP) ALGORITHMS and GIS: A STUDY CASE of GUELMIM REGION in SOUTHWESTERN of MOROCCO,"In recent decades, many of the countries around the world as well as the south-western Morocco (Guelmim region, Assaka watershed), was subject to flood-storm causing huge human and material damages. The current study focuses on the Prediction of flash flood susceptibility using Fuzzy Analytical Hierarchy Process (FAHP) algorithms and Geographic Information System (GIS) technical. Flash floods areas were identified based on seven flash flood conditioning factors (Soil Moisture Index (SMI), Drainage Density, Rainfall, LULC, Altitude, Slope and Soil). Using AHP the weight derived for the factors were SMI 37% Rainfall 24.30%, Drainage Density 15.57%, LULC 9.98% Altitude 6.39% Slope of the river basin 4.06% and Soil type 2.70%. Then, applying a fuzzy inference system to create flash flood vulnerability maps. The resulting maps were classified into three categories: low, moderate and high flash flood susceptibility; indicated that the areas at the outlet of the watershed and which are close of the main affluent wadis (Seyyad and Oum Al-Achar) were very susceptible to flooding. This study will be helping these zones to be prioritized for the conservation and managing of flash floods.",60025457,Hassan II University of Casablanca,Casablanca,Morocco,['1710'],25.857142857142854,0.1469230769230769,0.4389743589743589,1,0.06607929515418502,0.14977973568281938,0.502262443438914
1253,1281,1281,A technique for developing high-resolution residential occupancy schedules for urban energy models,"Occupants’ presence and activity schedules directly influence residential energy consumption loads. Regardless of their widely acknowledged importance, developing proper representative occupancy inputs for urban energy use studies of residential neighborhoods remains to be a challenge to overcome. The presented work aims to balance between accuracy and complexity of such occupancy models by developing a technique that takes advantage of a previously proposed sophisticated method for schedule generation and attempts to refine and simplify its results for practicality purposes. Here, we used a Markov chain transition probability matrix based on the American Time-Use Survey (ATUS) database and selectively refined its outputs according to the data collected from our own designated population of study. The resulting refined schedules were incorporated into the Urban Modeling Interface (umi) interface and were then tested on our pilot case study, a relatively low-income dense neighborhood in the Midwestern United States composed of 272 residential buildings. An initial investigation of this technique’s performance suggests that while the use of the ATUS based model provided a high level of variability and sophistication, the customization step ensured that the resulting schedules are representative of our population and its characteristics. More importantly, we were able to maintain simplicity and practicality.",60016253,Institut National des Sciences Appliquées de Lyon,Villeurbanne,France,['1705'],28.57142857142857,0.15583333333333332,0.38947916666666665,1,0.12612612612612611,0.05405405405405406,0.273972602739726
1254,1282,1282,INTRA-URBAN HEAT ISLAND DETECTION and TREND CHARACTERIZATION in METRO MANILA USING SURFACE TEMPERATURES DERIVED from MULTI-TEMPORAL LANDSAT DATA,"Unprecedented urbanization in Metro Manila has led to the proliferation of the urban heat island (UHI) effect. This is characterized by a prominent difference in the temperatures of the urban and its surrounding rural and less urbanized areas. Temperature differences occur within these UHI's indicating the existence of intra-urban heat islands (IUHI). UHI's and IUHI's are well-documented indicators of urban environmental degradation and therefore puts the population of Metro Manila at risk. In anticipation of these effects, their detection and the characterization of their behaviour through time can contribute to proper urban planning thus mitigating harmful effects. Google Earth Engine was used to retrieve land surface temperatures (LST) from Landsat data from 1997 to 2019 using emissivity estimation. The Local Moran's I statistic was then used to identify cluster and outlier types (COT). A histogram with 10 bins representing the net COT frequencies per barangay was then used to identify IUHI's. Annual temperature measurements and COT areas were plotted against time and based on linear-fit trend lines they characterize the study area as to having an annual increase in temperature of roughly 0.18 °C and hotspot area extent of around 0.03 km2, and a decrease in coldspot area extent around 0.01 km2. Hotspots were found to be frequent in the cities of Caloocan, Manila, Pasay, and Quezon while coldspots were found to be frequent in the cities of Caloocan, Las Piñas, Malabon, Navotas, and Valenzuela. In conclusion, IUHI's were detected with statistical basis, both spatially and temporally.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],22.454545454545453,0.07380952380952381,0.219047619047619,1,0.08620689655172414,0.12758620689655173,0.38869257950530034
1255,1283,1283,PROCESSING JUMP POINT of LIDAR DETECTION DATA and INVERSING the AEROSOL EXTINCTION COEFFICIENT,"For a long time, the research of the optical properties of atmospheric aerosols has aroused a wide concern in the field of atmospheric and environmental. Many scholars commonly use the Klett method to invert the lidar return signal of Mie scattering. However, there are always some negative values in the detection data of lidar, which have no actual meaningï1/4Œand which are jump points. The jump points are also called wild value points and abnormal points. The jump points are refered to the detecting points that are significantly different from the surrounding detection points, and which are not consistent with the actual situation. As a result, when the far end point is selected as the boundary value, the inversion error is too large to successfully invert the extinction coefficient profile. These negative points are jump points, which must be removed in the inversion process. In order to solve the problem, a method of processing jump points of detection data of lidar and the inversion method of aerosol extinction coefficient is proposed in this paper. In this method, when there are few jump points, the linear interpolation method is used to process the jump points. When the number of continuous jump points is large, the function fitting method is used to process the jump points. The feasibility and reliability of this method are verified by using actual lidar data. The results show that the extinction coefficient profile can be successfully inverted when different remote boundary values are chosen. The extinction coefficient profile inverted by this method is more continuous and smoother. The effective detection range of lidar is greatly increased using this method. The extinction coefficient profile is more realistic. The extinction coefficient profile inverted by this method is more favorable to further analysis of the properties of atmospheric aerosol. Therefore, this method has great practical application and popularization value.",60006422,Northwest University for Nationalities,Lanzhou,China,['1710'],18.11764705882353,0.1703102453102453,0.4406204906204906,1,0.0771513353115727,0.032640949554896145,0.228486646884273
1256,1284,1284,"ASSESSMENT of SOLAR PV POWER POTENTIAL in the ASIA PACIFIC REGION with REMOTE SENSING CONSIDERING the EFFECTS of HIGH TEMPERATURE, DUST and SNOW","The last half century has witnessed the increasing trend of renewable energy utilization with solar photovoltaic (PV) systems as one of the most popular option. Solar PV continues to supplement the main grid in powering both commercial establishments (mainly for reduced electricity expense) as well as residential houses in isolated areas (for basic energy requirement such as for lighting purposes). The objective of this study is to assess the available solar PV power (PPV) potential considering the effects of high temperature, dust and snow in the Asia Pacific region. The PPV potential was estimated considering the effects of the said meteorological parameters using several satellite data including shortwave radiation from Advanced Himawari Imager 8 (AHI8), MOD04 aerosol data from Moderate Resolution Imaging Spectroradiometer (MODIS), precipitation rate from Global Satellite Mapping of Precipitation (GSMaP), air temperature from NCEP/DOE AMIP-II Reanalysis-2 data, and snow water equivalent (SWE) from Microwave Scanning Radiometer for the Earth Observing System (AMSR-E). The model is validated by comparing its outputs with the measured PV power from two solar PV installations in Bangkok, Thailand and Perth, Australia. Results show that maximum PPV is estimated at 2.5 GW (cell efficiency of 17.47%) for the region with the maximum decrease in PPV estimated to be about < 2%, 22% and 100% due to high temperature (temperature coefficient of power Combining double low line 0.47%/K), dust and snow, respectively. Moreover, areas in India and Northern China were observed to experience the effects of both dust and temperature during March-April-May (MAM) season. Meanwhile, countries located in the higher latitudes were severely affected by snow while Australia by high temperature during Dec-Jan-Feb (DJF) season. The model has a mean percentage prediction error (PPE) range of 5% to18% and 7% to 23% in seasonal and monthly estimations, respectively. Outputs from this study can be used by stakeholders of solar PV in planning for small-scale or large-scale solar PV projects in the solar rich region of Asia Pacific.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],32.3,0.09764880952380954,0.3984821428571429,1,0.065,0.16,0.4244791666666667
1257,1285,1285,Methodology of Hype Monetization in the Internet Environment According to the Life Cycle Theory,"This paper is devoted to studying the phenomenon of hype as a new trend of communication space in the digital environment and possible methodology of its monetization. The analysis of the references has allowed determining the basic properties of hype, among which is the speed of spreading, expressed in the degree dependence between the number of queries in the main search engines and time; a short life cycle of hype projects without a prominent stage of ""maturity"" and the breadth of scope or coverage of the phenomenon in non-specialized media. Since every hype event or phenomenon is characterized by a distinctive duration of the periods of growth and decline in interest, hype study can help a company to quantify the interest of a potential target audience and make management decisions based on this. The main research question for this paper was formulated as follows: how a business can use the life cycle theory in order to monetize hype, quickly responding to the rapid growth of popularity in the Internet environment of a particular event or phenomenon. Relying on the results of empirical research, the authors proposed a method of hype monetization, based on forecasting the potential benefits from integrating marketing solutions, formed on the basis of thematic semantic constructions corresponding to the properties of hype at the early stages of its formation. The authors' hypothesis that the function of decreasing the popularity of a hype request can be determined on the basis of the function of increasing its popularity was empirically confirmed. Using the multiple regression toolkit, a function of decreasing the popularity of a hype request based on its growth function was formed. The driver of hype monetization is the increase in traffic, which is attributed to the corresponding Internet resources of a company which uses hype events when developing marketing solutions. Integration into the promotion tools of the thematic semantic constructions corresponding to the given properties of hype at the early stages of formation will allow increasing this traffic. The authors propose the inequality, on the basis of which a decision can be made regarding the expediency of implementing the developed marketing activities.",60107796,The St. Petersburg State University of Economics,Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",35.5,0.1134848484848485,0.4189772727272727,1,0.12041884816753927,0.0,0.22894736842105262
1258,1286,1286,Performance evaluation of system according to led location and angle in multiple LED-VLC systems," All rights reserved.Visible light wireless communication is a communication method in which data to be transmitted is used as a high speed wireless data transmission means using LEDs having a high on / off speed. As the VLC system evolves, the basic research problem is to secure communication reliability and improve performance. Due to the characteristics of visible light wireless communication, communication is performed only in the light reach range, which depends on the light emission angle.This is a big difference. Therefore, in this paper, we applied MIMO (Multiple Input Multiple Output) communication system using the property of several LEDs in general indoor environment, and analyzed the total power and SNR performance obtained from the receiver by changing the emission angle of the transmitter. It was. As a result of the simulation, the SNR depends on the light emission angle of the transmitter. It has been found to have a great influence on the performance and BER performance.In this paper, we assume a rectangular parallelepiped room, illuminate the ceiling and wall of the transmitter LED, and derive a communication channel model in a fixed height environment considering the height of the desk. In an environment where multiple LEDs exist, the reception performance may vary according to the light emission angle of each LED. In this paper, we analyze this performance in MIMO environment. This study is expected to be used as a technique to improve the performance by determining the emission angle and applying MIMO technology to improve the performance according to the communication area of the visible light wireless communication system.Further research on the interference from multiple LEDs is needed. It is necessary to analyze interference scenarios and cancellation techniques that have been studied so far and to find interference cancellation models suitable for sensor networks.",60031231,Semyung University,Jecheon,South Korea,['1700'],27.09090909090909,0.18129629629629626,0.5011111111111111,0,0.11782477341389729,0.01812688821752266,0.2453416149068323
1259,1287,1287,A meta heuristic approach for efficient route recovery in mobile ad hoc networks,"Routing is a complex issue in Mobile Ad hoc Networks (MANET) due to its dynamic and frequently changing network topology. Route failures, packet collision, bad channel condition and congestion are to be considered while designing reliable routing protocol in MANET, since these factors tends to increase the packet loss and degrade the bandwidth and battery power. Reliable routing protocols for mobile ad hoc networks use many link reliability metrics for finding these links; four of the most commonly used are “Link Expiration Time”, “Link Received Signal Strength”, “Residual Energy” and “Available Bandwidth”. It is shown that these metrics enhance the reliability and reduce the number of route reconstructions. However, minimization of Packet loss, Communication overhead are a challenging task to improve the performance. This paper addresses the finding of optimal path by predicting node, link lifetime using a meta heuristic algorithm called modified cuckoo search algorithm.",60075905,Andhra University College of Engineering,Visakhapatnam,India,['1700'],24.33333333333333,0.05750000000000001,0.4808333333333333,1,0.1111111111111111,0.10526315789473684,0.38011695906432746
1260,1288,1288,Paper Recommendation with Item-Level Collaborative Memory Network,"The recommendation system can recommend information to users personally and efficiently, which satisfies the user’s demand for information in the information age, and has become a hot topic in the current era. In the recommendation system, users and items and the interaction of their own information has a crucial impact on the efficiency and accuracy of the recommendations. However, most of the existing recommendation systems usually design the systems as user-base only, considering the user’s influence on the item in the recommendation, which to some extent blurs the interaction between items and users at the item level, unknown and potential connections between items and users are not well considered. In this paper, we propose a collaborative memory network that can focus on the potential relation between items and users, and consider the impact of items’ characteristics on user behavior. Experiments have shown that our improvement is better than the original method and other baseline models.",60019533,Tianjin University,Tianjin,China,['1700'],31.0,0.125,0.6803571428571429,1,0.08045977011494253,0.0,0.25287356321839083
1261,1289,1289,A uniform approach to completions of posets,"For a subset system Z and a subset selection Γ of Z−sets, we introduce two special types of subsets of a poset, called ΔΓ−continuously ⋁−existing subsets and ΔΓ−closed subsets. We define the ZΓ−completion ZΓ(P) to be the set of all ΔΓ−continuously ⋁−existing, ΔΓ−closed subsets of a given poset P. We prove that if Z is subset-hereditary, then (1) the ZΓ−completion ZΓ(P) is the smallest Z−complete subposet containing all principal ideals in the set of all ΔΓ−closed subsets of P; (2) any ΔΓ−continuous function f:P→L mapping into a Z−complete poset L extends uniquely to a Z∨−continuous function from the completion ZΓ(P) to L. The ZΓ−completion includes numerous special cases: the Dedekind-MacNeille completion, the Frink ideal completion, the ideal completion, the Z−completion, the Hoare powerdomain, etc.",60032356,Hunan University,Changsha,China,"['1712', '1703']",31.0,0.4815476190476191,0.7738095238095237,1,0.06,0.08666666666666667,0.4934210526315789
1262,1290,1290,Human body andface recognition using local binary pattern histogram algorithm," All rights reserved.In this research one of the main problems of human detection, face detection, face recognition and tracking an individual. In this research is capable of detecting a human and its face in a given video and storing Local Binary Pattern Histogram (LBPH) features of the detected faces. LBPH features are the key points extracted from an image which is used to recognize and categorize images. Once a human is detected in video, it is tracked that person assigning him a label. It is used the stored LBPH features of individuals to recognize them in any other videos. After scanning through various videos in this program gives output like person labeled as subject1 is seen in vide taken by camera1, subject1 is seen in video by camera2. In this way It is tracked an individual by recognizing him/her in the video taken by multiple cameras. In this whole work is based on the application of machine learning and image processing with the help of open CV, an open since the computer vision library.",60120915,Galgotias University,Greater Noida,India,['1700'],21.875,0.02944444444444445,0.3405555555555556,0,0.13917525773195877,0.041237113402061855,0.32275132275132273
1263,1291,1291,PROJECTION of INCIDENT SURFACE SOLAR RADIATION in CHINA under A CLIMATE CHANGE SCENARIO,"We projected incident surface solar radiation (SSR) over China in the middle (2040-2059) and end (2080-2099) of the 21st century in the Representative Concentration Pathway (RCP) 8.5 scenario using a multi-model ensemble derived from the weighted average of seven global climate models (GCMs). The multi-model ensemble captured the contemporary (1979-2005) spatial and temporal characteristics of SSR and reproduced the long-term temporal evolution of the mean annual SSR in China. However, it tended to overestimate values compared to observations due to the absence of aerosol effects in the simulations. The future changes in SSR showed increases over eastern and southern China, and decreases over the Tibetan Plateau (TP) and northwest China relative to the present day. At the end of the 21st century, there were SSR increases of 9-21 W m2 over northwest, central, and south China, and decreases of 18-30 W m2 over the TP in June-July-August (JJA). In northeast China, SSR showed seasonal variation with increases in JJA and decreases in December-January-February. The time series of annual SSR had a decreased linear trend for the TP, and a slightly increased trend for China during 2006-2099. The results of our study suggest that solar energy resources will likely decrease in the TP under future climate change scenarios.",60073580,Cold and Arid Regions Environmental and Engineering Research Institute Chinese Academy of Sciences,Lanzhou,China,['1710'],25.875,-0.05555555555555555,0.22199074074074074,1,0.06415094339622641,0.1320754716981132,0.4309623430962343
1264,1292,1292,Impact of the transition to a digital economy on the sustainable development of Russian regions,"Nowadays Russia's regions are in the process of transition to a digital economy induced by both general global trends and the Russian federal policy, manifested in implementing the National Program ""Digital Economy of the Russian Federation"" or providing support to the development of 30 Technology Platforms. This study is of immediate interest to identify potential risks to the transition of Russia's regions to a digital economy. It makes its objective to determine the levels of preparedness and overall capability in regions that would allow for their transition to a digital economy in the course of establishing and developing the regional systems of sustainable production and consumption. Moreover, structuralizing the strengths and weaknesses of the region during its transition is another area of interest to the research. The paper relies on the content analysis of the statutes and regulations governing the transition of Russia's regions to a digital economy and on the study of their implementation to elicit the major consequences of such a transition for the regional systems of production and consumption in terms of their sustainability, to shed light on prospects for sustainable production and consumption in Russia's regions during their transition to a digital economy and to formulate recommendations for the development of sustainable production and consumption against this background. The analysis has revealed that despite the overall positive impact of the digitalization of Russia's regional economies on the sustainability of regional systems of production and consumption manifested in a reduction in the ecological footprint of consumption, the improved quality of management decisions, the enhanced environmental quality of public purchases, there are considerable risks associated with a decline in lifestyle sustainability, a change in the morphological waste composition of production and consumption as well as a slowdown in the decreasing trend in the energy intensity of the economy[24].",60021331,Russian Academy of Sciences,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",50.0,0.047262396694214885,0.2255509641873278,1,0.06853582554517133,0.040498442367601244,0.21671826625386997
1265,1293,1293,Latent semantic analysis of game models using LSTM,"We are proposing a method for identifying whether the observed behaviour of a function at an interface is consistent with the typical behaviour of a particular programming language. This is a challenging problem with significant potential applications such as in security (intrusion detection) or compiler optimisation (profiling). To represent behaviour we use game semantics, a powerful method of semantic analysis for programming languages. It gives mathematically accurate models (‘fully abstract’) for a wide variety of programming languages. Game-semantic models are combinatorial characterisations of all possible interactions between a term and its syntactic context. Because such interactions can be concretely represented as sets of sequences, it is possible to ask whether they can be learned from examples. Concretely, we are using LSTM, a technique which proved effective in learning natural languages for automatic translation and text synthesis, to learn game-semantic models of sequential and concurrent versions of Idealised Algol (IA), which are algorithmically complex yet can be concisely described. We will measure how accurate the learned models are as a function of the degree of the term and the number of free variables involved. Finally, we will show how to use the learned model to perform latent semantic analysis between concurrent and sequential Idealised Algol.",60026479,University of Exeter,Exeter,United Kingdom,"['1712', '1703']",22.66666666666667,0.12717391304347828,0.6358695652173915,1,0.10683760683760683,0.02564102564102564,0.30434782608695654
1266,1294,1294,Identifying and mapping of slums in pune city using geospatial techniques,"In India, rapid growth of slums in urban areas, especially in metropolitan cities, has become a major problem for the planners and decision-makers. The slum expansion is mainly due to the rural-urban migration and pressure of the population on un-used, un-protected, and un-suitable public land. It leads to many issues like poverty, unemployment, lack of access to clean water, lack of durable housing, traffic congestion, environmental pollution, insufficient living area, inadequate sanitation, scarcity of land, inappropriate land use, skyrocketing land value and insecure tenure, etc. Planning controls are usually ineffective in slum areas due to lack of timely information and people having little regard for such things in the absence of any other alternative. In most of the municipal bodies, proper updated information/map of slums are not available, which, create a problem in the decision-making process. Thus, there is an imperative need to resolve above-mentioned issues with the help of Geospatial techniques. This paper aims to identify and mapping of slums in Pune City using Geospatial techniques. The slums were identified based on high-resolution satellite images such as Resourcesat-2 (LISS-IV) data with the help of visual interpretation and standard image processing techniques, i.e., image rectification, enhancement, and classification. Afterward, the database was created and labeled with the help of the GIS tool. In Pune, there is around 40 percent of the urban population resides in slums. Such a large proportion of slum population also adds to the burden of already scarce resources and on overall urban infrastructure. The entire slum population of the city was accommodated in a total of 477 slums of which 238 and 239 were declared and undeclared slums respectively. The most of the slums in Pune mainly occurred in the central part due to natural increases as well as migration. But, the peripheral areas it's happen due to vacant land/open areas along to river, canal, railway line and hill slope. The study reveals that more than 200 slums are located near environmentally sensitive areas and encroachment activities are increased in southern part of the city i.e., Ambegaon Bk., Vithhal Nagar and Warje areas.",60022158,International Institute for Population Sciences,Mumbai,India,['1710'],23.13333333333333,0.035134711779448616,0.3671992481203008,1,0.06443914081145585,0.04295942720763723,0.35353535353535354
1267,1295,1295,A Study on Applying Relational Association Rule Mining Based Classification for Predicting the Academic Performance of Students,"Predicting the students’ academic achievements is of great interest within the Educational Data Mining (EDM) field, having the main goal of extracting patterns relevant in deciding the students’ performance at a certain academic course. This paper analyses a classification model SPRAR (Students Performance prediction using Relational Association Rules) for predicting the academic results of students using relational association rules. Relational association rules represent an extension of classical association rules able to capture binary relationships between the attribute values. Three new classification scores are introduced in this paper and used in the classification stage of SPRAR. Their performance is analyzed using three real academic data sets from Babes-Bolyai University, Romania and compared to similar existing results from the literature.",60024417,Universitatea Babes-Bolyai din Cluj-Napoca,Cluj Napoca,Romania,['1700'],23.6,0.18979353979353975,0.3295621045621045,1,0.11278195488721804,0.11278195488721804,0.4351145038167939
1268,1296,1296,Semantic context-based on-demand service model for land cover change detection," CC BY 4.0 License.Land cover change (LCC) detection is widely used in many social-benefit areas, such as land cover updating, sustainable development and geographical situation monitoring. With the development of Web Services and cloud computing, a number of remote sensed algorithms and models have been published as web services. An on-demand service is urgent to be generated by compositing a sequence of atomic services, according to different situations. Context information plays an important role in automatic service composition. Traditional context information models mainly focus on service only, and ignore the relationships among users and services. To address this problem, we introduce the service context and user context into the context information. OWL-SC and OWL-UC are then proposed by extending the traditional service description model (i.e., OWL-S). Finally, a context-aware on-demand service model for LCC detection is built to realize service composition and optimization.",60083498,Shandong Jianzhu University,Jinan,China,['1710'],18.0,0.0787878787878788,0.6393939393939394,0,0.08333333333333333,0.05,0.36809815950920244
1269,1297,1297,The Model-Driven Enterprise Data Fabric: A Proposal Based on Conceptual Modelling and Knowledge Graphs,"Enterprise data is typically located in disparate legacy systems and heterogeneous sources. Researchers and business analysts identified the importance of integrating such data sources through a semantic data fabric to support the generation of valuable insights and consolidated views. Still, this objective is hard to attain as information is dispersed in ever-growing enterprise data lakes and silos. Some solutions are very abstract, taking the form of prescriptive enterprise frameworks, and therefore they do not provide operational mappings between data from real systems. In other cases the integration requires technical expertise that may be format-specific and, because of this, it is hard to cover heterogeneous technologies. It would be useful if those working on the enterprise architecture level could express on a high abstraction level the involved data sources and interlinking rules. This paper proposes a solution that enables integration management in a diagrammatic view that does not require expertise with data transformations. In support of this idea, we engineer a modelling method that provides (i) a front-end interface to enable the combination of relevant data with the help of an agile modelling language and (ii) the use of RDF as a common representation that captures the output of the modelled integrations in an Enterprise Knowledge Graph.",60024417,Universitatea Babes-Bolyai din Cluj-Napoca,Cluj Napoca,Romania,['1700'],25.75,0.04178571428571428,0.4248809523809524,1,0.10869565217391304,0.017391304347826087,0.29464285714285715
1270,1298,1298,Simulation Model for Business Value Strategic Management in Digital Transformation Era,"The main purpose of the study is to develop a simulation model that reflects aggregate impact assessment of an enterprise's external and internal environmental factors on its business value. Based on external and internal enterprise environmental factors and the rate of environmental changes, enterprise management evaluates each strategic decision to manage competitive advantages. Increased business value is seen as a quantitative indicator of an effective strategy. The paper describes theoretical and practical aspects of simulation modelling. A discrete simulation model in the form of a diagrammatic model of the operators-and-relations structure was chosen as the main simulation tool. The paper also defines external and internal environmental factors that emerge at certain stages of the industry life cycle and examines the key relations between them. The interaction between variables that represent the operation of the system and changes in the external environment was depicted graphically. As a result, a simulation model for assessing the impact of external and internal environmental factors on business value was developed. It includes variables as the key components of the system and demonstrates causal relationships between them. The model can be used to upgrade the strategic decision-making process. However, at the moment the described approach cannot be fully realized due to the lack of a decent informational base on individual enterprises and industries as a whole. The findings can be used to assess the potential impact of digitalization on strategic decision-making as well as its indirect impact on business value and development costs of digital models for enterprises.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",21.0,0.028720238095238094,0.3658234126984127,1,0.10108303249097472,0.0,0.20817843866171004
1271,1299,1299,Sun and wind: Integrated environmental performance analysis for building and pedestrian comfort,"Solar access and pedestrian wind are important factors for the design of comfortable dwellings and livable urban areas. At the same time they influence the shape and image of cities. Daylight is the most appreciated source of building interiors illumination. Urban wind can significantly increase the discomfort of pedestrians for its mechanical action around buildings. In Estonia the daylight standard regulates access to sun light. Different pedestrian wind comfort criteria exist. This paper presents a research work which analyzes the performance of direct solar access according the Estonian daylight standard and pedestrian wind comfort according the Lawson criteria of 27 building cluster variations in the city of Tallinn. A method which integrates different building and urban performance analysis is developed. Results show different optimal patterns for each environmental performance, though significant trade-offs are found, and critical periods of the year for pedestrian wind comfort.",60068861,Tallinna Tehnikaülikool,Tallinn,Estonia,['1705'],16.0,0.14750000000000002,0.41875,1,0.08917197452229299,0.01910828025477707,0.24516129032258063
1272,1300,1300,A framework for generating aviation risk information mobile user interfaces from knowledge graphs," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In this paper, we introduce a new framework called Flight Planner for generating Aviation Risk Information mobile-compatible user interfaces from Knowledge Graphs. The framework is divided into three components, a templating engine, a Linked Data Knowledge Graph and a mobile app. Traditional Linked Data frameworks provide poor support for user interface generation and common web frameworks do not natively support Linked Data-based Knowledge Graphs. Moreover, Aviation Risk Information systems is specialised area mainly studied by organisational psychologists or experts in human factors and it has received little attention by computer scientists. Thus, a flexible, efficient, and usable framework for Aviation Risk Information is needed. A comparative evaluation was done with Linked Data Reactor framework as a benchmark. It is observed that Flight Planner produces equivalently flexible and efficient, but less usable results despite being an early prototype.",60025059,Dublin City University,Dublin,Ireland,['1700'],21.285714285714285,-0.013739669421487605,0.4185950413223141,0,0.08284023668639054,0.21301775147928995,0.4879518072289157
1273,1301,1301,A simulation-based design analysis for the assessment of indoor comfort under the effect of solar radiation,"One of the drivers of sustainable design is to maximize daylight across the floor plan in order to decrease electric energy consumption and create more productive and healthy working spaces. However, uncontrolled incoming solar radiation can lead to significant visual and thermal comfort issues. In particular, solar radiation landing on occupants can create thermal discomfort that the HVAC system cannot compensate for, thereby causing intolerable conditions for users close to the façade. We aim to present a new climate-based annual framework, based on ASHRAE 55 appendix C (2017), to assess radiant discomfort across a space due to direct solar radiation. The framework is calculated using the hourly effective radiant field (ERF) and delta Mean Radiant Temperature (ΔMRT) across the indoor space. The Radiance-based framework coupled with the proposed Annual Radiation Discomfort metric (ARD) provides designers a robust method to assess the performance of complex fenestration systems (CFS) at reducing potential thermal discomfort caused by incoming shortwave radiation.",60025038,"University of California, Berkeley",Berkeley,United States,['1705'],26.16666666666667,0.1261946386946387,0.4865675990675991,1,0.1366120218579235,0.07650273224043716,0.30726256983240224
1274,1302,1302,Environmental data and land use: Integration of site-specific ecology and urban design,"The aim of this research focuses on how site-specific environmental data and programme-defined relationships (land use and their relation) can work collaboratively to design an integral ecological urban fabric. The paper presents a work flow applied to a case study and is formed by three main parts: data collection and elaboration, land use pattern generation and design development for critics and insights. The case study consists of a design proposal for a city for 40,000 dwellers located along the South coast-line of Isle of Grain, UK. The area is mainly made up of marshlands and the project is envisioned in a near-future scenario in the likely event of land shortage and sea level rise. In the first part, design parameters such as areas and functions for hypothetical energy, food and site protection needs are defined. At the same time, environmental data is gathered for tide frequency, topography and water speed. A suitabilitybased evaluation criterion is introduced to relate land use and environmental conditions at a specific location within the site. In the second part, we investigate two methods for generating design options of land use distribution. As both methods rely on neighbour conditions, a principle of the cellular automata algorithm (CA), their implementations deviate fundamentally from CA, such as that all the landuses generated within an iteration are quantitatively defined as a design parameter. The first methodology is based on a growing system, while the latter on a competing system. In the third and last part of the workflow, we select and carry forward one generated land-use pattern due to specific evaluation criteria and develop the design at urban scale: different building plots’ morphologies are generated depending on their location and degree of clustering. We conclude with critics and potentials, such as the applicability at different scales.",60097321,Architectural Association (AA) School of Architecture,London,United Kingdom,['1705'],24.75,0.052777777777777785,0.3071428571428571,1,0.0943952802359882,0.02654867256637168,0.24924012158054712
1275,1303,1303,Entity Linking Based on Graph Model and Semantic Representation,"A large number of applications which bridge web data with knowledge bases have led to an increase in the entity linking research. Candidate entity disambiguation plays an important role in the typical entity linking systems. Generally, graph-based candidate disambiguation approaches applied document-level topical coherence of candidate entities. Nevertheless, they do not make full use of abundant unambiguous entities to enrich semantic information during the disambiguation. To solve this problem, we propose a graph-based model combining semantic representation learning for entity linking. Specifically, we construct a referent graph based on semantic vectors trained from RDF data, in which we introduce the dynamic PageRank algorithm with unambiguous entities to enhance the performance of entity linking. Primary experiments show that this model outperforms state-of-the-art on benchmark datasets.",60005244,"Southeast University, Nanjing",Nanjing,China,['1700'],17.714285714285715,0.2052910052910053,0.5161375661375662,1,0.13513513513513514,0.02027027027027027,0.2867647058823529
1276,1304,1304,Multi-stream data analytics for enhanced performance prediction in fantasy football," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Fantasy Premier League (FPL) performance predictors tend to base their algorithms purely on historical statistical data. The main problems with this approach is that external factors such as injuries, managerial decisions and other tournament match statistics can never be factored into the final predictions. In this paper, we present a new method for predicting future player performances by automatically incorporating human feedback into our model. Through statistical data analysis such as previous performances, upcoming fixture difficulty ratings, betting market analysis, opinions of the general-public and experts alike via social media and web articles, we can improve our understanding of who is likely to perform well in upcoming matches. When tested on the English Premier League 2018/19 season, the model outperformed regular statistical predictors by over 300 points, an average of 11 points per week, ranking within the top 0.5% of players - rank 30,000 out of over 6.5 million players.",60011149,Trinity College Dublin,Dublin,Ireland,['1700'],32.4,-0.032059228650137744,0.3908243271879636,0,0.08241758241758242,0.07142857142857142,0.3867403314917127
1277,1305,1305,Permission-Based Feature Scaling Method for Lightweight Android Malware Detection,"Android system has gained the highest market share due to its openness and portability in the mobile ecosystem. Whereas, users are suffering from serious security issues these years. Many malicious Android applications are released in popular app stores and it’s hard to distinguish them. Most of the current malware detection researches are focus on collecting features as much as possible for better performance instead of mining information inside the simple features. Scaling is an effective means to improve classification results while scaling the features for a large bundle of apps remains a challenging work. In this paper, we propose a malware detection method based on Machine Learning (ML) using permission usage analysis to cope with the rapid increase in the number of Android malware, named Permission Feature Selection (PFS). PFS uses Android permission as a classification feature with high utilization. The method greatly shortens the time cost in detection without reducing the detection accuracy and makes it possible to scan large-scale samples in a short time. Besides, various experiments were designed on real-world datasets to verify the reliability of the method. The results of the evaluation show that the proposed method performed better than other feature scaling methods with 91.2% accuracy and the average time cost reduced to less than 2 s.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],21.2,0.16739177489177492,0.5636688311688312,1,0.11063829787234042,0.04680851063829787,0.3218884120171674
1278,1306,1306,Teacher effectiveness and use of technology in teaching,"The paper deals with teacher effectiveness of secondary school teachers in relation to use of technology. Survey method was employed for the study. The data was collected from 1200 secondary school teachers in Chittoor district of Andhra Pradesh state, India, through stratified random sampling technique. The self constructed teacher effectiveness questionnaire and check list for use of technology in teaching were used to collect the data. Statistical techniques like mean, standard deviation and t-test were used for analysis. Results show there is significant difference in teacher effectiveness whole tool and temperament,interpersonal relations, evaluation dimensions of teacher effectiveness among secondary school teachers with reference to use of technology. It was also found that there was no significant difference among secondary school teachers in teacher effectiveness dimensions, Conceptual expertise, Class room management, Innovativeness with reference to Use of technology in teaching.",60107415,Sri Padmavati Mahila Visvavidyalayam,Tirupati,India,['1700'],19.857142857142858,-0.16250000000000006,0.45375,1,0.07006369426751592,0.03184713375796178,0.24516129032258063
1279,1307,1307,Detecting hacker threats: Performance of word and sentence embedding models in identifying hacker communications," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Cyber security initiatives are finding new approaches to mitigating threats against the computational infrastructure of companies. One of these approaches is the use text mining techniques and classification models to detect potentially malicious messages or posts in hacker communications. This is a difficult task due the ambiguity and the strong use of technical vocabulary inherent in such posts. This paper aims to evaluate the use of robust language models for feature representation of input to downstream classification tasks of hacker communication posts. We perform the experiment against five hacker forum datasets using a variety of language models: two Word Embeddings (Word2vec and Glove), and three Sentence Embeddings (Sent2vec, InferSent and SentEncoder). We conclude that, for this task, only Sentence Embeddings enhance the performance of SVM classification models compared to traditional language models (Bag-of-words, word/char n-grams). Additionally, we found that models using CNN improves upon SVM models by achieving 93% of positive recall and 96% of average class accuracy.",60012873,Technological University Dublin,Dublin,Ireland,['1700'],24.285714285714285,0.040151515151515146,0.6044871794871794,0,0.0845771144278607,0.11442786069651742,0.4484536082474227
1280,1308,1308,AN AEROSOL LIDAR DATA VISUALIZATION METHOD BASED on ARCGIS,"The geographical information, temporal and spatial distribution of pollution sources cannot be accurately described by the traditional aerosol lidar inversion data. In order to accurately locate the pollution sources and monitor the spatial and temporal distribution of pollutants, an aerosol lidar data visualization method based on ArcGIS is proposed in this paper. A natural neighborhood method is used to perform group interpolation on ArcGIS software, and the range range-extinction coefficient relationship diagram is plotted using the aerosol optical data obtained from Klett inversion algorithm. The geographic information is added to the lidar inversion data in this diagram. The aerosol spatial and temporal distribution range and the direction of aerosol diffusion are accurately displayed directly. The change of aerosol concentration is plotted in different colors, the visually displaying the concentration of pollutants in the detection area is realized. The aerosol detection data in the sunny and haze days in Yinchuan are visualized in this paper. The result shows that this method can quickly determine the geographical location of pollution sources and visualize the spatial and temporal distribution of aerosols. This method can be used to display aerosol data with geographic information for meteorological and environmental protection departments. This method can provide data support for meteorological and environmental protection departments to quickly determine the location and concentration of pollution sources.",60006422,Northwest University for Nationalities,Lanzhou,China,['1710'],21.8,0.2066666666666667,0.505,1,0.1148936170212766,0.0851063829787234,0.18454935622317598
1281,1309,1309,PRECIPITATION and LATENT HEATING PROPERTIES of TROPICAL CYCLONE in the NORTHWEST PACIFIC MEASURED by GPM DPR and HIMAWARI-8,"Using observations from the GPM Tropical Cyclone Overpass Dataset and Himawari-8, this study statistically analyses the tropical cyclones (above Typhoon categories) in the Northwest Pacific during the tropical cyclone (TC) frequent period (from May to October) of 2014-2018. Moreover, a case (Super Typhoon ""Mangkhut"") was analysed in detail. This study uses a semi-manual method to identify three life cycle stages of tropical cyclones: developing stage, mature stage, and dissipating stage. The statistical results show that the distribution of precipitation and latent heat varies with positions and the tropical cyclone has the maximum precipitation (11.62 mm/h) at the mature stage along with the maximum convection ratio (22.97%) at the developing stage. It is most obvious that the release of latent heat in the upper cloud at developing stage and in the lower cloud at mature stage. The latent heat profile of convective precipitation presents a ""bottom-heavy"" structural, and the stratiform precipitation has a ""top-heavy"" latent heat profile. The proportion of stratiform precipitation to total precipitation (74.31%) is the largest, but the average precipitation of the stratiform (4.12 mm/h) is lower than the average precipitation of convective clouds (10.55 mm/h). The average particle radius of the stratiform precipitation is 1.13 mm, while the average precipitation particle radius of the convective cloud precipitation is 1.79 mm. Based on these statistical results, this paper briefly analyses the characteristics of cloud precipitation microphysical mechanisms in three life cycle stages. Besides, the latent heating profile distribution found in this study are related to the vertical variation of precipitation rate, which are different in terms of the type of precipitation cloud.",60024350,National University of Defense Technology,Changsha,China,['1710'],26.4,0.03725490196078432,0.3558823529411765,1,0.04923076923076923,0.06153846153846154,0.3408360128617363
1282,1310,1310,Parallel quantum random number generator (p-QRNG) design for enhancing data rate,"Internet of Things (IoT) is still an interesting research topic in recent years because it can be applied to a system in many fields. Many ecosystems, energy and renewable energy companies should be able to adapt this technology into their systems to simplify monitoring processes. There are three general issues associated with IoT applications; security, interoperability and innovations. As IoT technology is implemented in a system, a security issue of the system will be becoming a new problem. This paper will discuss designing a parallel quantum random number generator (p-QRNG) where it's generated high-speed random bits have a potential to be used in One-Time Pad (OTP) encryption system for IoT ecosystem applications. Parallel QRNG design is proposed to speed up data rate of a single QRNG's output in order to fulfill requirements of OTP encryption system.",60110255,Politeknik Negeri Jember,Jember,Indonesia,['1706'],22.66666666666667,0.11178107606679034,0.4567022263450835,1,0.10625,0.05,0.34415584415584416
1283,1311,1311,URBAN FIRE SPREAD MODELLING and SIMULATION USING CELLULAR AUTOMATON with EXTREME LEARNING MACHINE,"Urban fire continues to be a persistent disaster, especially with the proliferation of highly dense urban settlements. As a response, several measures were established to help mitigate the losses caused by fire including simulating the fire spread. The cellular automaton system has been widely used to simulate the complex process of fire development along with Physics-based models. A data-driven approach has been rarely employed. This paper presents the result of incorporating machine learning techniques to the existing cellular automaton based urban fire spread models. Specifically, instead of manually calculating the ignition probability of each cell in the automaton, the Extreme Learning Machine (ELM) was used to learn the ignition probability from the historical data. After building the model, its performance was evaluated using the data collected from the four fires in Basak, Lapu-Lapu City. By using a confusion matrix to compare the actual and the predicted values, the Burned Actual-Burned Predicted relationship was derived. Results suggest that the proposed method can effectively describe the development of fire, and the model accuracy is quite good (i.e., the Burned Actual-Burned Predicted relationship ranges from 78% to 83%). Lastly, the study was able to demonstrate the possibility of using a data-driven approach in creating a simple cellular automaton fire spread simulation model for urban areas. Further studies utilizing more fire incident data on with varying properties is recommended.",60071429,University of the Philippines System,Quezon City,Philippines,['1710'],20.454545454545453,0.11175,0.38944047619047617,1,0.1553030303030303,0.06060606060606061,0.3333333333333333
1284,1312,1312,Information Support of Decision-making Process in Creating the Real Estate Development Projects,"complication of modern real estate development project demands constant access to up to date information for decision making. certain developer companies owe their preeminence to the digital decision making environment containing information on all stages of the project. The real environment of the project decision making is difficult to define, since it si an elaborate and dynamic profceess. The role of subjective factors is enormous eg. lobbying stategies of organized interests, which are different stakeholders. of organized interests, which are different for different stakeholders. considering these difficulties. currently there seems to be no auotomated decision support systems in development. these systems are supposed to decrease the probability of choosing an unreasonable solution. The present article offers the model of information field of real estate develppment project. The distinguishing feature of the information field of the development project is that the project information having been created within the working environment goes outside, becomes known to the outsiders who then start influence the project implementation indirectly. The model presented in this article describes sources, structure of information during project impleementation, changes which this information undergoes and possiblilities of the automated information processing, is is shown hohow and why it is difficult to formalize documentary information in the developer project. consultants, draftsmen, customers and other stakeholders evaluate project decisions based on their experience and interests. under these conditions, formalized documentation. additionally, we enlist the recommended intellectual methods for processing information at different stages of development project. in the end we brief on the possible stages of developers digitalization. in accomdation of interests of participants in the project and major stakeholders is very important for the early stages of project implementation.",60024799,Moscow State University of Civil Engineering,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",16.294117647058822,0.05256377551020409,0.4617772108843538,1,0.11147540983606558,0.006557377049180328,0.26557377049180325
1285,1313,1313,State Representation Learning for Minimax Deep Deterministic Policy Gradient,"Recently, the reinforcement learning of multi-agent has been developed rapidly, especially the Minimax Deep Deterministic Policy Gradient (M3DDPG) algorithm which improves agent robustness and solves the problem that agents trained by deep reinforcement learning (DRL) are often vulnerable and sensitive to the training environment. However, agents in the real environment may not be able to perceive certain important characteristics of the environment because of their limited perceptual capabilities. So Agents often fail to achieve the desired results. In this paper, we propose a novel algorithm State Representation Learning for Minimax Deep Deterministic Policy Gradient (SRL_M3DDPG) that combines M3DDPG with the state representation learning neural network model to extract the important characteristics of raw data. And we optimize the actor and critic network by using the neural network model of state representation learning. Then the actor and critic network learn from the state representation model instead of the raw observations. Simulation experiments show that the algorithm improves the final result.",60011592,Qilu University of Technology,Jinan,China,['1700'],22.714285714285715,0.021184371184371185,0.5562423687423688,1,0.10112359550561797,0.07303370786516854,0.32386363636363635
1286,1314,1314,Adaptive occupancy scheduling: Exploiting microclimate variations in buildings,"Using natural ventilation instead of mechanical building systems to regulate indoor climate can reduce energy consumption while increasing human well-being. The feasibility of natural ventilation depends on outdoor climate conditions as well as the physical and architectural properties of a building. Based on the observation that institutional buildings are rarely occupied to full capacity, this paper proposes a building operation paradigm aimed at increasing the feasibility of natural ventilation. We introduce the concept of adaptive occupancy scheduling, a prescriptive system that allocates occupants in real time to populate only the most environmentally suitable spaces at all times. We exemplify this paradigm in a school design study, in which a fixed room schedule is replaced by a sensor network that assigns classes to classrooms with appropriate microclimatic conditions on-the-go. Our initial results indicate that a higher local architectural diversity generally increases comfort in free-running mode.",60030804,Swinburne University of Technology,Melbourne,Australia,['1705'],24.0,0.1823529411764706,0.4201680672268908,1,0.13043478260869565,0.0,0.22875816993464052
1287,1315,1315,Smart speaker design and implementation with biometric authentication and advanced voice interaction capability," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Advancements in semiconductor technology have reduced dimensions and cost while improving the performance and capacity of chipsets. In addition, advancement in the AI frameworks and libraries brings possibilities to accommodate more AI at the resource-constrained edge of consumer IoT devices. Sensors are nowadays an integral part of our environment which provide continuous data streams to build intelligent applications. An example could be a smart home scenario with multiple interconnected devices. In such smart environments, for convenience and quick access to web-based service and personal information such as calendars, notes, emails, reminders, banking, etc, users link third-party skills or skills from the Amazon store to their smart speakers. Also, in current smart home scenarios, several smart home products such as smart security cameras, video doorbells, smart plugs, smart carbon monoxide monitors, and smart door locks, etc. are interlinked to a modern smart speaker via means of custom skill addition. Since smart speakers are linked to such services and devices via the smart speaker user's account. They can be used by anyone with physical access to the smart speaker via voice commands. If done so, the data privacy, home security and other aspects of the user get compromised. Recently launched, Tensor Cam's AI Camera, Toshiba's Symbio, Facebook's Portal are camera-enabled smart speakers with AI functionalities. Although they are camera-enabled, yet they do not have an authentication scheme in addition to calling out the wake-word. This paper provides an overview of cybersecurity risks faced by smart speaker users due to lack of authentication scheme and discusses the development of a state-of-the-art camera-enabled, microphone array-based modern Alexa smart speaker prototype to address these risks.",60008539,National University of Ireland Galway,Galway,Ireland,['1700'],21.69230769230769,0.16319727891156469,0.503673469387755,0,0.08139534883720931,0.05813953488372093,0.4055727554179567
1288,1316,1316,Recyclingmethod of waste vinyl and plastic,". All rights reserved.Recently, there has been a tendency to refuse vinyl collection among industrial wastes, and there is a need for a solution. There is a need for a method that can process plastic waste, which is not perishable, together with combustible waste and efficiently use it in a cogeneration plant.The present invention provides a method of collecting vinyl and waste plastics to remove impurities, crushing them, and then extruding them by heat. In the process of preparing flammable wastes with the composition ratio of 80% light oil, 8% 2-butanol, 10% methacresol and 2% magnesium, this fuel is added to prepare solid fuel to increase calorific value and complex Could do it smoothly. The extruded solid fuel was burned to measure harmful gases and calories.The temperature duration during exotherm was up to 1 hour 30 minutes per kg and the temperature rose up to 1,300 ℃. The calorific value was 7,113 kcal / kg and 8,007 kcal / kg with the addition of a softener. The addition of a flame retardant to the waste produces little odor upon combustion. The amount of soot generated during the combustion of the added RPF was below the environmental pollution standard. As it is dried at high temperature (250 ℃), it is sterilized and hygienic.It can be used as fuel for cogeneration plants, etc., and can be used as fuel for heating a greenhouse.",100332775,Chungwoon University,Daejeon,South Korea,['1700'],25.66666666666667,0.004027777777777778,0.2938888888888889,1,0.10902255639097744,0.011278195488721804,0.29571984435797666
1289,1317,1317,Operational semantics of a weak memory model with channel synchronization,"There exists a multitude of weak memory models supporting various types of relaxations and synchronization primitives. On one hand, such models must be lax enough to account for hardware and compiler optimizations; on the other, the more lax the model, the harder it is to understand and program for. Though the right balance is up for debate, a memory model should provide what is known as the SC-DRF guarantee, meaning that data-race free programs behave in a sequentially consistent manner. We present a weak memory model for a calculus inspired by the Go programming language. Thus, different from previous approaches, we focus on buffered channel communication as the sole synchronization primitive. Our formalization is operational, which allows us to prove the SC-DRF guarantee using a standard simulation technique. Contrasting against an axiomatic semantics, where the notion of a program is abstracted away as a graph with memory events as nodes, we believe our operational semantics and simulation proof can be clearer and easier to understand. Finally, we provide a concrete implementation in K, a rewrite-based executable semantic framework, and derive an interpreter for the proposed language.",60110772,Western Norway University of Applied Sciences,Bergen,Norway,"['1712', '1703']",23.25,0.034702380952380964,0.4038690476190476,1,0.12037037037037036,0.027777777777777776,0.24519230769230768
1290,1318,1318,Enhancing the Conciseness of Linked Data by Discovering Synonym Predicates,"In the meantime of the rapidly growing of Linked Data, the quality of these datasets is yet a challenge. A close examination of the quality of this data could be very critical, especially if important researches or professional decisions depend on it. Nowadays, several Linked Data quality metrics have been proposed which cover numerous dimensions of Linked Data quality such as completeness, consistency, conciseness and interlinking. In this paper, we propose an approach to enhance the conciseness of linked datasets by discovering synonym predicates. This approach is based, in addition to a statistical analysis, on a deep semantic analysis of data and on learning algorithms. We argue that studying the meaning of predicates can help to improve the accuracy of results. A set of experiments are conducted on real-world datasets to evaluate the approach.",60014541,Conservatoire National des Arts et Metiers,Paris,France,['1700'],19.142857142857142,0.1285714285714286,0.5,1,0.11920529801324503,0.039735099337748346,0.2953020134228188
1291,1319,1319,Pineplot: An R package for visualizing symmetric relationships,"An effective publication-quality visualization tells a concise story from data. Methods and tools that facilitate making such visualizations are valuable to the scientific community. In this paper, we introduce pineplot, an R package for generating insightful visualizations called pine plots. Pine plots are applicable to a wide variety of datasets and create a holistic picture of the relationship between variables across different experimental conditions. A pine plot provides a means to visualize a group of symmetric matrices, each represented by triangular heat maps. Pine plots can be used to visualize large datasets for exploratory data analysis while controlling for different potentially confounding factors. The utility of the package is demonstrated by visualizing gene expression values of tissue-specific genes from RNA-seq data and the clinical factors in a liver disease and a heart disease dataset. The implementation of pineplot offers a straightforward procedure for generating pine plots; full control of the aesthetic elements of generated plots; and the possibility of augmenting generated plots with extra layers of graphical elements to further extend their usability.",60015186,University of Saskatchewan,Saskatoon,Canada,"['1712', '1709', '1707', '1705']",21.625,0.12423469387755105,0.4895408163265306,1,0.11979166666666667,0.015625,0.3064516129032258
1292,1320,1320,GEOSTATISTICAL and CLUSTER ANALYSIS of EARTHQUAKES in the PHILIPPINES,"The Philippine region is one of the most natural hazard-prone areas. Hazards from an earthquake event, or seismic hazards, may be addressed with the analysis of the previous occurrences across the country. This was performed by analyzing earthquake hot spots or clusters using geostatistical methods such as Getis-Ord Gi∗ and Anselin Local Moran's I. This study mapped the earthquake events per magnitude from 1975 to 2019, and determined the hot spots, and its patterns across the Philippine region. It also compared the results of a prediction output from a 2016 study, and performed a quick temporal analysis of the earthquakes from 1975 to 2019. This study was able to determine the earthquake hot spots, mostly in the southern provinces, and with most of which lie along the major trenches.",60071491,University of the Philippines Diliman,Quezon City,Philippines,['1710'],21.5,0.2199404761904762,0.4815476190476191,1,0.07534246575342465,0.0410958904109589,0.35664335664335667
1293,1321,1321,Evaluating the Need for Integrators on the Example of Digitalization of Real Estate Business,"Real estate business in Russia, throughout 30 years of its modern history, shows a trend for a slower growth and transfer to new operation tools. In Russia, differently from other countries, there is still no licensing of real estate activity or multi-listings. That is why it is important to study if this sector of the economy needs to have operations and business processes digitalized. The paper is aimed at determining the demand for integrators on the example of digitalization of real estate business. The main methods used in the work are the method of observation and data collection, the abstracting method and the logical method. The paper demonstrates that integrators in the real estate sector provide services for a commission equal to 20% of users' earnings, which is comparable to the amount of remuneration integrators obtain in hospitality business and taxi. It has been found out that the share of users' earnings that integrators receive for their services is, on average, not less than two times higher of the same indicator in other spheres of economic activity, investigated by the Licensing Industry Merchandiser's Association. Using the Azgaldov-Karpova method, it has been identified that the degree of value of a real estate market integrator exceeds by 2.5 times the peak figure of the value indicator obtained based on statistical analysis of industry average data. According the conducted research study, it has been concluded that the degree of value of an integrator in the real estate sphere is appreciated as immense by market players, which is a sign of high demand for the considered technologies in real estate business. The study presents the prospects of digitalization of real estate business, which represents interest for real estate market players.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",28.6,0.12208754208754212,0.36924242424242426,1,0.07886435331230283,0.025236593059936908,0.25559105431309903
1294,1322,1322,Performance evaluation of improved empirical mode decomposition with pedestrian dead reckoning navigation,". All rights reserved.In recent years pedestrian dead reckoning (PDR) has been a popular indoor localization technique that takes advantage of inertial navigation sensors (INS) of smartphones due to its availability. This paper proposes a model that utilizes empirical mode decomposition (EMD) as the noise filter. EMD is an unconventional filter being applied in PDR to remove noise by processing the raw signal before implementing step counts, step lengths and heading estimation. The experiment made using the proposed model was able to perform the standard PDR technique without overlaps in heading estimation.The aim of this paper is to evaluate the performance of EMD with PDR and it achieved it with slight error in distance of about 4 meters. In the two tests conducted, the total steps taken were about 151 while the estimated steps were 153, resulting to a 98.7% accuracy. The estimated trajectory was also very similar with the actual trajectory made.EMD was evaluated in two occasions but still requires more experimentation on the effectiveness of EMD and present more advances on the study of applying EMD in pedestrian dead reckoning.",60095591,TongMyong University,Busan,South Korea,['1700'],26.0,0.07984775641025643,0.3780128205128205,1,0.12745098039215685,0.05392156862745098,0.3282828282828283
1295,1323,1323,Audit of effectiveness of the government support of territorial clusters - Drivers of economic growthAudit of effectiveness of the government support of territorial clusters - Drivers of economic growth,"The article considers the audit of effectiveness as a management system element of the government participation in the formation and development of territorial clusters - drivers of economic growth. Clusters' support activities are implemented through the government programs. Cluster development and budgetary resources allocation are under the jurisdiction of various federal ministries. However, currently, the issues of evaluating an effectiveness of using the public resources to support the development of territorial clusters are not properly studied that predetermines the relevance of the research topic. The purpose of the study is to improve the theoretical and methodological foundations of the audit of effectiveness and clarify its role in the management system of territorial clusters in the context of digitalization of information databases. The subject of the study is the process of providing government support measures for cluster formations and auditing the effectiveness of their use for managerial decisions. The study is based on strategic planning documents, reports on the implementation of the government programs, the federal budget, and Rosstat for 2008-2018, reports of the Accounts Chamber of the Russian Federation on the results of control measures posted on the portal of public and municipal financial audits. The theoretical and methodological basis of the study consists of the works of the leading Russian and foreign scientists in the field of clusters, organizing an audit of effectiveness of using public resources, and standards of government auditing. The research methodology is based on the systems approach used in studying audit of effectiveness as a part of the economy's clustering process management system. According to the results of the study, conclusions are presented on the further development of the cluster-network model of economic development, increasing the role of the audit of effectiveness of government support for territorial clusters as drivers of economic Growth.",60020513,National Research University Higher School of Economics,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",29.8,0.018137254901960786,0.1740196078431373,1,0.07407407407407407,0.015432098765432098,0.24375
1296,1324,1324,ALBEDO RETRIEVING from DSCOVR/EPIC DATA and PRELIMINARY VALIDATION,"Land surface albedo plays an important role in climate change research. Satellite remote sensing has the characteristic of wide observation range, and it can make repeated observations on the same area. Therefore, using the remote sensing data to retrieve surface albedo becomes a main method to obtain the surface albedo in a wide range or even on a global scale. However, the time resolution of existing albedo products is usually low, which has a great impact on the analysis of rapid changes in surface vegetation and the climate change research. The Deep Space Climate Observatory (DSCOVR) was launched to a sun-earth first Lagrange point (L1) orbit, which is a new and unique vantage point to observe the continuously full, sunlit disk of Earth. DSCOVR can provide observation data with high time resolution, therefore, it is necessary to explore the feasibility of the new sensor DSCOVR/EPIC inversion of the daily albedo product. The relationship between the surface broadband albedo and the surface reflectance was established, and then the surface albedo with high temporal resolution was calculated using the DSCOVR/EPIC data. The Inner Mongolia Autonomous Region and parts of the Sahara Desert were selected to verify the accuracy of DSCOVR albedo compared with MODIS albedo. The results show that the correlation coefficients between DSCOVR albedo and MODIS albedo are greater than 0.7 and RMSE are less than 0.05 both in visible band and shortwave band. It can be seen that this method can be used for the albedo retrieval using DSCOVR/EPIC data.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1710'],25.0,0.12804242424242426,0.43523030303030297,1,0.09608540925266904,0.09608540925266904,0.2600732600732601
1297,1325,1325,A Comparative Analysis Methodology for Process Mining Software Tools,"Process mining is a research discipline situated at the intersection of data mining and computation intelligence on the one hand, and process modelling and analysis on the other hand. The aim of process mining is to use information stored in event logs of information systems in order to discover, monitor, and improve processes [1]. The field of process mining has gained attention over the last years and new process mining software tools, both academic and commercial, have been developed. This paper provides an extensive list of process mining software tools. Moreover, it identifies and describes many criteria that can be used in order to compare process mining software tools. Additionally, this paper introduces a new methodology that can be used for the comparative analysis of any number of process mining software tools, using any number of criteria. Furthermore, this paper describes Analytic Hierarchy Process (AHP), which can be used in order to help users decide which software tool best suits their needs.",60010667,Panepistimion Pireos,Piraeus,Greece,['1700'],23.142857142857146,0.17477272727272725,0.2784090909090909,1,0.13114754098360656,0.02185792349726776,0.3114754098360656
1298,1326,1326,Implicit Rating Methods Based on Interest Preferences of Categories for Micro-Video Recommendation,"Collaborative filtering (CF) without explicit information is one of the most challenging research directions in the field of video recommendation, as the effectiveness of traditional CF methods strongly depend on the ratings of videos for users. However, in the actual online video platforms, explicit ratings are very rare or even completely unavailable in most cases. This makes the effects of traditional recommendation algorithms are not satisfactory. In addition, micro-videos have attracted wide attention, while they have not be considered differently by the traditional recommendation algorithms. It is meaningful to study the recommendation methods for micro-videos. Considering that micro-videos have categories, two implicit rating methods based on interest preferences of categories are proposed to improve the performance of recommendation for micro-videos under implicit feedback. Its core idea is to construct a rating matrix based on implicit information by mining users’ implicit interest preference information for different categories of micro-videos, and use it as the basis of recommendation algorithms. The proposed rating methods are validated on a large online video content provider, and they are correct and can effectively mine users’ preferences without explicit ratings according to the experimental results. They can bring better results than some existing algorithms, and can be better applied to the video recommendation system.",60023813,Shanghai University,Shanghai,China,['1700'],23.0,0.2493483709273183,0.5901002506265666,1,0.09623430962343096,0.0,0.31004366812227074
1299,1327,1327,"The role of (α, β)-level set on complex intuitionistic fuzzy soft lattice ordered groups","In this paper the notion of Complex Intuitionistic Fuzzy Soft Lattice Ordered Group is introduced.Moreover,the properties of (α, β)-level sets of complex intuitionistic fuzzy soft lattice ordered group are presented and discussed.",60016712,Alagappa University,Karaikudi,India,['1700'],32.0,-0.1,0.375,1,0.10256410256410256,0.10256410256410256,0.5384615384615384
1300,1328,1328,Industrial Innovation Clusters of Saint-Petersburg: Problems and Development Prospects,"The purpose of the article is to analyze the current state and prospects for using the cluster approach as one of the priority directions of regional industrial policy for the effective socio-economic development of St. Petersburg. The article analyzes and systematizes the main factors that determine the peculiarities of the formation, functioning and development of clusters identified from the point of view of the state regional cluster policy as priorities at the regional level. As a result of the analysis of the cluster policy in St. Petersburg, both general problems of cluster policy and the economy as a whole, as well as problems created directly by the cluster, were identified. The main problems of cluster development in the city are analyzed: insufficient quality and availability of transport and engineering infrastructure; insufficient level of organizational development of the cluster, including the lack of the practice of strategic planning for the development of the cluster; lack of qualified personnel caused by the discrepancy in the content and quality of educational programs with the needs of the economy; problems with access to financial resources. The analysis showed that the cause of the problems arising within the cluster is its dynamically developing structure, which closely interacts with the environment, and, therefore, in the process of interaction, conflict situations may appear. This is mostly due to the gap in the interaction between firms and educational organizations, financial organizations, government bodies, firms within the cluster. The foreign experience of obtaining financial resources through innovative vouchers, which is aimed at optimizing the dissemination of scientific and technical knowledge among small and medium-sized businesses, and is intended to bring science and business closer, is considered. A number of established large clusters of St. Petersburg were analyzed: automotive industry; pharmaceuticals; shipbuilding; arctic cluster; clean technology cluster. The studies conducted in this paper show that the continued success of the implementation of the cluster approach in St. Petersburg largely depends on the development of a clear regional cluster policy, as well as on specific cluster programs. It is shown that it is necessary to take measures to bring all categories of cluster participants closer together and eliminate gaps between them.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",25.714285714285715,0.12410714285714285,0.36383928571428575,1,0.08,0.0225,0.25
1301,1329,1329,IMPACT of TIBETAN PLATEAU SNOW COVER on ABRUPT INTERDECADAL PRECIPITATION CHANGE over the INDOCHINA PENINSULA in the MID-1990S,"Abrupt interdecadal changes in summer precipitation (May-September) over the Indochina Peninsula in the past 40 years have been investigated based on the NCEP-NCAR reanalysis product over 1979-2013 and multiple precipitation datasets. The mechanism for the abrupt change is explored. Results indicate that an abrupt interdecadal change in summer precipitation over the Indochina Peninsula occurred in the middle 1990s, and the annual mean summer precipitation during 1994-2002 increased by about 10% compared to that during 1982-1993. The most significant precipitation change occurred in the central and northern peninsula. Further analysis reveals that the interdecadal decrease in snow cover over the Tibetan Plateau in the winter and spring contributed to the summer precipitation increase over the Indochina Peninsula. The decrease in snow cover over the Tibetan Plateau actually increased the thermal contrast between the Tibetan Plateau and the tropical Indian Ocean-northwestern Pacific, leading to intensified summer monsoon over the northwestern Pacific and the South China Sea. As a result, westerly anomalies occurred from the Bay of Bengal to the northwestern Pacific, while anomalous cyclonic circulation prevailed in the upper levels above East Asia. Correspondingly, the western Pacific subtropical high weakened and shifted eastward. Under the joint effects of the above circulation patterns, the atmosphere became wetter in the Indochina Peninsula and summer precipitation increased. Results of the present study provide a theoretical basis for the prediction of long-term summer precipitation change in the Indochina Peninsula.",60024350,National University of Defense Technology,Changsha,China,['1710'],23.3,0.005131578947368421,0.3685526315789473,1,0.07518796992481203,0.12406015037593984,0.3253968253968254
1302,1330,1330,Deep Learning: Current State,"Deep learning, a derived from machine learning, has grown into widespread usage with applications as diverse as cancer detection, elephant spotting, and game development. The number of published studies shows an increasing interest by researchers because of its demonstrated ability to achieve high performance in the solution of complex problems, the wide availability of data and computing resources, and the groundbreaking development of effective algorithms. This paper reviews the current state of deep learning. It includes a revision of basic concepts, such as the operations of feed forward and backpropagation, the use of convolution to extract features, the role of the loss function, and the optimization and learning processes; the survey of main stream techniques, in particular convolutional, recurrent, recursive, deep belief, deep generative, generative adversarial, and variational auto-enconder neural networks; the description of an ample array of applications organized by the type of technique employed; and the discussion of some of its most intriguing open problems.",60030699,Instituto Nacional de Astrofisica Optica y Electronica,Puebla,Mexico,['1700'],39.25,0.06431372549019608,0.42539215686274506,1,0.07650273224043716,0.01092896174863388,0.287292817679558
1303,1331,1331,The influences of human-made disasters on the state of government to citizens ICT services: Users’ perspectives,"The recent human-made disasters in middle-east harmed the governments’ functionality which caused difficulties on various aspects of life for citizens. These affected governments' functions include government to citizens (G2C) ICT services. There is an absence of empirical study to clarify the real situation of the government to citizens ICT services among citizens during a human-made disaster. Where government to citizens ICT services could fit and serve the affected people due to the difficulties and risks that hinder their access to the government sites. This paper attempts to fill this gap in the literature by empirically investigating these services in Iraq as a war-torn country. In this paper, the literature review has been conducted; the investigated issue is recognised by conducting a self-administered survey. Results point out that there is a lack of flexibility when using ICT services, and there is a notable ignorance about the availability of G2C ICT services among IDPs.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1700'],21.714285714285715,0.12916666666666668,0.2805555555555556,1,0.11931818181818182,0.011363636363636364,0.3795180722891566
1304,1332,1332,Development prospects of the educational Milieu of universities in the conditions of academic revolution,"The article analyzes the current situation in the educational milieu on the example of a flagship university, its place and role in the regional development and the necessary transformations that meet the concept of the knowledge-based economy in the wake of the ""fourth industrial revolution"". The massification and global knowledge-based economy, as components of the academic revolution, predetermine the need to abandon the outdated model of ""educational pipe"". The use of induction method in a synthesis of descriptive and abstract-analytical forms allows the authors to identify problems of the educational system development, highlighting the role of regional flagship universities as an object and subject of management capable of transforming and causing positive changes in the educational milieu. The result of the study is the formation of a differentiated educational system of the flagship university which predetermines a different approach, missions and goals in disciplinary areas and requires a systemic transformation to change the academic structure and academic culture. To change the academic structure, we propose to create free and elite education zones using the open curriculum format and the free education format with a ""core"" free education program. Forms of elite education include honors-programs, coworking for discussing pressing or arisen problems. The Internet revolution provides university with the opportunity to enter the online market as a provider of online courses. The article suggests to form social patterns for determining the disciplinary structure, to expand the disciplinary field and to use multi-disciplinarity and cross-disciplinarity The systematic approach proposed by the authors in changing the academic structure of the university, as an object and subject of management, through approaches, forms and means will allow the university to become a scientific, educational and innovative center of the region.",60107804,The Russian Presidential Academy of National Economy and Public Administration,Moscow,Russian Federation,"['1712', '1709', '1707', '1705']",35.625,0.10097402597402597,0.35043290043290043,1,0.10835913312693499,0.015479876160990712,0.22508038585209003
1305,1333,1333,Digitalization of the educational process: Problematic issues in the context of the development of the digital economy,"The authors analyze the problems of digitalization of education in Russia. Realizing that the widespread introduction of information and communication technologies in educational activities is dictated by the need to train new qualified personnel for the labor market in the digital economy, the authors at the same time draw attention to the possible negative consequences of this process. In their opinion, the use of digital technologies in the educational process, in addition to the undoubted advantages, which are the expansion of the resource of educational information, the ability to use educational content at a convenient time and in a convenient manner, the ability to build individual educational paths, improve educational system management tools, etc., can contribute and a decrease in the quality of education, since it changes the mechanisms of perception of information, without forcing a person to think creatively and reducing his communication skills. The digitalization of education in Russia is constrained by technical and legal problems. The main ones are: the absence in Russian educational legislation of a clear distinction between the basic concepts: ""e-learning"", ""information technology"", ""distance educational technologies"", ""information and educational environment""; lack of a regulatory framework governing the use of e-learning, distance learning technologies; lack of standards for the provision of educational services using these technologies; the spontaneous nature of the introduction of digital technology in the educational process; most teachers lack the necessary skills to work in a digital environment. In addition, distance education in the Russian Federation does not have the legal status of an independent form of education, which is a limiting factor for the digitalization of education in general. The authors conclude that the digitalization of the educational process in Russia is impossible without solving these problems and offer a number of specific recommendations in this area.",60071000,Southwest State University,Kursk,Russian Federation,"['1712', '1709', '1707', '1705']",42.285714285714285,0.11773325358851675,0.3124003189792663,1,0.07079646017699115,0.014749262536873156,0.2215568862275449
1306,1334,1334,Innovations and digital transformation of the Russian fishery complex,"Digital technologies are consistently entering the practice of various industries, forming a knowledge society of the future. The fishery complex of Russia is also gradually increasing the number of digital technologies used. Lots of innovations in the fisheries sector are based on technological approaches of the digital economy. The aim of the work is to determine the prospects for the transition of the Russian fishery complex to a model of innovative development based on the principles of the digital economy. For this, it is necessary to consider the key features of the digital economy that can influence the activities of the fisheries complex, establish the main aspects of the digital transformation process and formulate promising directions and forms of introducing the digital economy in the complex. Methods of system analysis were used, as well as agent modeling based on the description of the fishing industry as a set of active objects (agents) that are guided by a set of rules of interaction in the economic environment for the goal of the work achievement. The hypothesis that digitalization is part of the processes of informatization taking place in modern society can take into account the peculiarities of various features of the diversified complex. It allows us to apply a wide range of methods to the specific features of various types of economic activity included in the fishery complex. The study revealed that the digitalization process in the fishery complex is based on the introduction of equipment that uses digital technologies as well as business-models and methods related to them. The key factors in this are technological development and changes in human capital.",60018744,Kaliningrad State Technical University,Kaliningrad,Russian Federation,"['1712', '1709', '1707', '1705']",27.1,-0.017619047619047614,0.3380952380952381,1,0.09342560553633218,0.0034602076124567475,0.18466898954703834
1307,1335,1335,Biometric identification based scores discretization on multi forms of image structures,"Multi-Biometric Identification is one of a well-known biometric in the area of pattern recognition and has always been under study through its important role in forensic science that could help government criminal justice community. In this paper, a novel multi-biometric identification of individuals by means of both physiological and behavioural biometrics is introduced. Different from the most conventional biometric identification, the extracted physiological and behavioural biometrics will go through a proposed Multi-Biometric Feature Discretization. The intention of Discretization in this study is to prevail over the deficiencies caused by poor features mining and to attain individual unique features that could reflect the individual varianceness in order to discriminate one person from another. The experiments was conducted on real-world multiple form of images which is adopted from INF/ENIT, HITMW and FVC databases. The experimental results supported our analysis by demonstrating a remarkable potential of the new structure of multi-biometric identification adaptability on multi forms of image structures and has excellent potency to conserve the distinctiveness of individual during identification.",60021005,Universiti Teknologi Malaysia,Johor Bahru,Malaysia,['1706'],28.0,0.14490665584415585,0.5882305194805195,1,0.09947643979057591,0.05235602094240838,0.2655367231638418
1308,1336,1336,A linguistic approach to short sentences keywords identification for a question answering system,"One of the aims of question answering systems is to identify which words are more relevant to understand the users' needs. Known approaches involve the identification of the users' intentions through a set of previously built related sentences. Some limitations of these approaches are the lack of flexibility and limited selection options. In this paper, we present an approach based on computational linguistics to identify the keywords in short sentences for question answering systems. The main contribution of our approach is related to the new way we use the information generated by the natural language processing tools to identify the keywords of the sentences, by profoundly exploring the linguistic information to select the keywords of the questions. Besides, we emphasise the generalisation and the simplicity of our algorithm. The efficiency of our method was proved by the performance of 0.9776 in precision, recall value of 0.9962, resulting in an F1 score of 0.9868 reached in the validation experiment using QALD-7 as a gold standard.",60024559,Universidade do Vale do Rio dos Sinos,Sao Leopoldo,Brazil,"['1710', '1708', '1705']",23.42857142857143,0.08916202844774275,0.36410018552875695,1,0.11235955056179775,0.0056179775280898875,0.28651685393258425
1309,1337,1337,INTEGRATING IMAGE at DIFFERENT SPATIAL RESOLUTIONS and FIELD DATA for SEAGRASS PERCENT COVER MAPPING,"There are not many discussion or previous works that specifically address the issue of integrating small field plot size (1 m2) and image at different spatial resolutions in the seagrass percent cover (PC) mapping using remote sensing. This is important to determine the spatial resolution of image that can still be effectively integrated with 1 × 1 m plot size field data. This research aimed at assessing the accuracy and spatial distribution of seagrass PC map modelled from image at different spatial resolutions, using seagrass field data measure at 1 m2 plot size. Two multispectral satellite images namely WorldView-2 (2 m) and PlanetScope (3 m) were used for this research and simulated to 5 m, 10 m, 15 m, and 30 m. Kemujan and Lombok Island were selected as the study area, and seagrass beds in each island have different characteristics. Machine learning random forest regression was used to perform empirical modelling and the mapping accuracy was assessed using independent seagrass PC samples. The results indicated that 1 m2 plot size is still effective to be integrated with image up to 30 m spatial resolution, where the RMSE and overall seagrass PC pattern is relatively similar but the level of information precision is reduced at lower spatial resolution. Furthermore, we found out that the main factor that strongly determines the success use of 1 m2 plot size and the mapping accuracy is the configuration of the seagrass bed in the study area. Seagrass PC in the more continuous seagrass bed can be mapped with higher accuracy than in patchy seagrass bed.",60069380,Universitas Gadjah Mada,Yogyakarta,Indonesia,['1710'],29.0,0.10416666666666666,0.4429166666666665,1,0.0880281690140845,0.02464788732394366,0.3345070422535211
1310,1338,1338,Crop phenology classification using a representation learning network from sentinel-1 SAR data," The representation network architecture consists of a pair (VV, VH) of two regression layers (VWC, PAI) which finally converge to a classification (crop phenology) layer. The study was conducted with the Sentinel-1 C-band SAR data acquired during the SMAPVEX16 campaign in Manitoba, Canada. Using this framework, the wheat phenology was classified to an accuracy of 86.67%. However, in comparison, the classification accuracy reduced by ∼ 20% while using only the backscatter coefficients of (VV, VH) polarization channels. The results obtained from this study justifies the potential of using a representation learning scheme for crop phenology classification with SAR data.",60019967,Agriculture et Agroalimentaire Canada,Ottawa,Canada,['1706'],20.0,0.0,1.0,0,0.08870967741935484,0.12096774193548387,0.4132231404958678
1311,1339,1339,Processes of changes in the educational environment under the influence of digital technologies,"The transformation processes taking place in the field of education under the influence of digital technologies pose the problem of studying its new adaptive properties. The key direction of engineering of the educational process is the formation and maintaining a developing educational environment, which is characterized by dynamism, flexibility and resilience. Structural changes reflect shifts in communicative environments and information fields. The article analyzes the data of a sociological survey of Peter the Great SPbPU students, revealing a positive attitude of students to the process of digitalization. The problem of identifying the accompanying contradictory moments of transformation of the educational space is noted. As a baseline vulnerability, based on surveys, there was a lack of student readiness to increase the share of independent learning and to change the role of the teacher. The conclusion is made in favor of the development of nonlinear educational models and trends that implement a flexible dynamic approach to the educational environment in response to the action of factors - rising students' expectations and high market demands.",60017103,Peter the Great St. Petersburg Polytechnic University,St. Petersburg,Russian Federation,"['1712', '1709', '1707', '1705']",24.57142857142857,0.190974025974026,0.3522619047619048,1,0.10270270270270271,0.005405405405405406,0.22702702702702704
1312,1340,1340,Multi-agent methods for creating knowledge bases," All rights reserved.Currently, artificial intelligence technologies have begun to attract special attention at the state level. The development of artificial intelligence technologies will make quick and optimal decisions based on the analysis of large amounts of data, and will also give great advantages in the quality and effectiveness of engineering design and production management. The foundation of artificial intelligence is knowledge. Knowledge is initially classified according to the attributes “clarity”, “accessibility”, “propositionality” and “level of abstraction”. To build a bank of engineering knowledge, on the basis of clarity, knowledge must be explicit, on the basis of accessibility, interorganizational, on the basis of propositionality, active, and on the level of abstraction, common. There are two categories of knowledge-passive and active. Passive knowledge is text documents stored in books, methods, and the like. To transform this knowledge into artificial intelligence systems, a highly efficient technology is needed that allows knowledge carriers to create knowledge bases without the involvement of programmers. This technology is described in this article.",60033469,Bauman Moscow State Technical University,Moscow,Russian Federation,['1700'],18.444444444444443,-0.08476190476190476,0.653076923076923,0,0.0891089108910891,0.0,0.3147208121827411
1313,1341,1341,Fair and standard access to spatial data as the means for achieving sustainable development goals," CC BY 4.0 License.FAIR, which stands for Findable, Accessible, Interoperable and Reusable, are the main principles adopted for sharing scientific data across communities. Implementing FAIR principles in publishing increases the value of digital resources, and the reuse of these by humans as well as machines. Introducing FAIR practices to the geospatial domain is especially relevant for the foundation geospatial data, such as precise positioning data. Within the next five years, Global Navigation Satellite Systems (GNSS), with corrections from internet or satellite communications, will permit national coverage of positioning services with real-time accuracy of several centimetres or better. However, implementing FAIR principles is not yet common practice in the geospatial domain. There are dozens of standards available for defining and sharing geospatial data. These include the ISO 19100 series of standards, OGC specifications and several community profiles and best practice. However, in most cases these standards fall short in ensuring the FAIR distribution of geospatial resources. As our preliminary findings show, current geodetic metadata and data are not yet fully FAIR and data discovery and access is still very challenging. In this paper we discuss the concept of FAIR and its meaning for geodetic data, explore the needs of precise positioning users and their requirement for metadata and present preliminary results on the FAIRness of current geodetic standards.",60031226,Curtin University,Perth,Australia,['1710'],21.8,0.3367283950617285,0.5003086419753088,0,0.06854838709677419,0.06048387096774194,0.42386831275720166
1314,1342,1342,Scaffold of N-(2-(2-(tosylcarbamoyl)hydrazinyl)ethyl)isonicotinamidereveals anticancer effects through selective inhibition of FAP,"The limited expression of fibroblast activation protein (FAP) makes it an alluring target for cancer therapy in the activated epithelial stroma and is related to more than 90% of epithelial cancer. Among the three-enzymatic activities of FAP, the dipeptidyl peptidase activity particularly contributes to tumor progression. Repurposing of small-molecule inhibitors can be a potential therapeutic strategy in both the prevention and treatment of cancer. Drug repurposing was used for this study and doxorubicin was considered a reference drug. Due to similar domain structure and high homologous structure of FAP and dipeptidyl peptidase-4 (DPP IV), the inhibitors of DPP IV were chosen for the study. Previous studies revealed that some drugs of the gliptin and sulfonylureas families are potential DPP IV inhibitors and hence, could be enzymatic inhibitors of FAP. The aim of this study was to predict a new therapeutic indication of the drug(s) from the gliptin family that will regulate fibroblast activation protein (FAP), responsible for tumor growth. An in silico study was carried out with some anti-diabetic drugs. They binding affinities after structural modifications showed significant improvements. Binding affinity values of the substituted structures of some antidiabetic drugs were found using PyRx and interactions were observed using Discovery Studio. The ADMET properties of the compounds were also studied. The most promising drug found from this study, tolbutamide showed a binding affinity of 9.4 kcal/mol and exhibited the following ADMET properties: it did not cross the blood brain barrier and had impressive human intestinal absorption. It was observed to be a non-inhibitor of p glycoprotein inhibitor. Furthermore, the results of AMES toxicity demonstrated the substituted compound was non-AMES toxic.",60008935,BRAC University,Dhaka,Bangladesh,"['1712', '1709', '1707', '1705']",19.285714285714285,0.15131237183868765,0.4703896103896103,1,0.10289389067524116,0.05787781350482315,0.3488372093023256
1315,1343,1343,Mesosphere stratosphere troposphere (MST) radar signal using discrete wavelet transform with overlapping group shrinkage,"Nowadays one of the common challenges faced by the Communication engineers/data analysts are to remove the noise and to estimate a better version of the signal, termed as “Denoising”. This paper proposes a new method called Discrete Wavelet Transform (DWT) with Overlapping Group Shrinkage (OGS) to show signs of improvement of the signal. The algorithm is evaluated with help of parameters like Signal to Noise (SNR) ratio and variance. To test the fitness of the calculation, a predominant case was considered with SNR from-20 dB to 0 dB. Even at these least SNRs also the algorithm efficiently reproduced the signal with minimal loss. Initially, the algorithm is tested with a heavy sine signal with input SNRs ratios of the above said range, and then the same algorithm was implemented on RADAR signals taken from Indian Mesosphere Stratosphere Troposphere (MST) RADAR, Situated at National Atmospheric Research laboratory (NARL), Gadanki, India.",60008424,Sri Venkateswara University,Tirupati,India,['1700'],24.83333333333333,-0.02636363636363637,0.3179545454545455,1,0.09142857142857143,0.15428571428571428,0.43103448275862066
1316,1344,1344,Information and communication technologies for analytics of individual tracking in foreign language teaching," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Modern educational process is based on the use of computer science even in foreign language teaching at higher educational establishments. Electronic educational platforms are widely used in modern educational process as well as in foreign language teaching. The practice of using electronic educational platform MyGrammarLab proves that even ready-made authentic foreign language courses allow creating individual tracking of foreign language teaching. MyGrammarLab is intended for improving grammar skills of students who learn a foreign language at higher educational establishments. MyGrammarLab has courses of different levels that consist of diagnostic, audio and video, training and control materials. Various settings of this platform provide flexible management of any course despite the inability to change the content. Diagnostics within the course: the number of attendance and attempts to complete a task, the amount of time spent for a task, the number of completed assignments enables a teacher to coordinate each student’s work and organize individual tracking of teaching to increase the educational productivity. We carry out the ratio analysis between the time spent and the level of student’s success, and also between the number of attempts to complete a task and the final score. This statistic forms the basis to create the methodology of using MyGrammarLab and additional materials that can be uploaded into the on-line resources in order to improve the quality of education among underperforming students of higher educational establishments. When the methodology is put into practice it shows the increase in motivation of Computer Science students when they do both built-in and additionally uploaded assignments by the teachers. The teachers monitor the results by means of messages. The authors present statistics of the results obtained before and after applying the methodology. These results show qualitative improvement in educational progress due to the use of Computer Science studies. In the conclusion we propose practical recommendations for organization of individual work of Computer Science students at higher educational establishments with different levels of English using electronic educational platform MyGrammarLab.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],24.214285714285715,0.1146341463414634,0.3195121951219512,0,0.11141304347826086,0.04619565217391304,0.29315068493150687
1317,1345,1345,Analysis of NGS data on the transcriptional regulation," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The GTRD database (http://gtrd.biouml.org) contains over 30,000 uniformly processed NGS experiments on transcriptional regulation (ChIP-seq, ChIP-exo, DNase-seq, ATAC-seq, MNase-seq and FAIRE-seq). To process these types of data, pipelines have been developed for the eGrid distributed computing management system and the BioUML platform.",60068684,"Institute of Cytology and Genetics, Siberian Branch of the Russian Academy of Sciences",Novosibirsk,Russian Federation,['1700'],27.0,0.2,0.43333333333333335,0,0.07692307692307693,0.24358974358974358,0.6811594202898551
1318,1347,1347,"The use of the interactive platform VimBox in English language teaching: A Comparison of Traditional, Blended (flipped classroom), and online Models of Learning"," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Rapid growth of learning platforms in the Russian higher education system is observed over the last decade. Online learning platforms are widely used in the educational process in the English language teaching. The Ural Federal University, Russia, and the online English Skyeng School conducted a joint experiment to choose an effective English teaching model in the context of the digitalization of education. In the paper, a comparative analysis of the blended learning model and online learning model on the online learning platform Vimbox is described. The study was undertaken with students of technical specialities of the Institute of Radio-Electronics and Information Technologies at the Ural Federal University while mastering the discipline “Foreign language” during the 2nd year of the bachelor degree course. They studied the same discipline in different teaching models: the traditional face-to-face learning, flipped learning, and online learning were compared. The advantages and disadvantages of each learning model were demonstrated. The results indicate some problems that show inefficiency of two experimental learning models offered by the Skyeng for higher institutions. Poor technical implementation, inappropriate curricula of the courses elaborated by the Skyeng School, and lack of attendance control have led to disinterest and decreasing the motivation among students.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],23.555555555555557,0.06309523809523811,0.3007936507936508,0,0.09243697478991597,0.10504201680672269,0.3261802575107296
1319,1348,1348,Requirements for information systems to support scientific and educational activities," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The peculiarity of the development of modern society is characterized by an increasing volume and rapid obsolescence of scientific information. To increase the effectiveness of scientific research, scientists need access to information on the results of research carried out in the field of interest. Therefore, any scientific research usually begins with a search for scientific information about research in this field, but the search for the necessary information in an ever-increasing volume of articles, books, monographs, reports, patents is becoming more difficult. Scientists have to spend a lot of time searching and processing information that allows them to quickly get acquainted with the results of other studies and eliminate their duplication. The article gives a definition of information systems designed to support scientific and educational activities in terms of scientific communication. The task, subject area, subjects, objects, the basic functionality of the information system are determined, a list of the main types of information resources is provided. The paper analyzes the functional requirements for such systems.",60109473,"Al Farabi Kazakh National University, Institute of Information and Computer Technologies",Almaty,Kazakhstan,['1700'],25.42857142857143,0.11614583333333332,0.4947916666666666,0,0.105,0.03,0.3015075376884422
1320,1349,1349,Interference effect of submerged pipeline on the scour depth of isolated bridge pier on a mobile bed,"Pipelines are used to transport water, distilled petroleum, and some other liquid over the waterway are mostly part covered under the sediment bed. Cooperation between a submerged pipeline and the portable bed accept significance in engineering in light of the surprising expense of laying such pipelines. The pipelines may turn out to be mostly presented to the activity of water flows where the flood causes a general scour in the bed of the waterway. Additionally, as an immediate results of fast urbanization, bridges in close proximity are probably going to meddle with such pipelines improving their defenselessness to scour. It is concurred that the distinction in pressure on the upstream side and downstream side of the pipe start the piping action underneath the pipeline. Pipeline together with stagnation vortex join to decide the pipeline and imprint the beginning of scour. Maximum scour beneath the pipeline observe when there is a little hole between the pipe line and the undisturbed bed. As the hole expands, scour profundity step by step diminishes. For a pipeline set at bed level, temperamental stream as hydrograph gives more scour than that for a uniform stream. Segment like transitional backings gave underneath the pipeline and extension in nearness is probably going to build the scour extensively.",60000674,National Institute of Technology Kurukshetra,Kurukshetra,India,['1700'],21.0,0.20288461538461536,0.4698717948717948,1,0.11946902654867257,0.004424778761061947,0.1592920353982301
1321,1350,1350,Physics - Economics interdisciplinary analogies in modelling of Russian financial system," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of this paper is to construct a model for real time forecasting of ruble liquidity in Russia. The influence of both the absolute values of the dollar/ruble exchange rate (rate) and its changes per day on the balance of the Bank of Russia operations for ruble liquidity provision and absorption (saldo) was investigated. Daily data was used from January 2015 to April 2018. It was found that the change in the rate 6 days ago is the cause (according to Granger) of the saldo value. For the saldo dynamics, an oscillatory model with an external force - a change in the rate - is proposed. Using the Kalman filter, the model parameters were estimated and saldo forecasted. Found period of self-oscillation is 4.218 days and attenuation of the amplitude per day is 2.179 times. The rate growth of 1 RUB, after 6 days, causes saldo increase of approximately 20 billion rubles. In fact, the changes in rate cause the variability of the saldo not more than for found coefficient of determination (26.7%), but the ""change in the rate-liquidity saldo"" system during the crisis-free period has a high ""Q-factor,"" and changes in the rate, repeated with a period close to self-one, can cause large-amplitude fluctuations in saldo. The demonstrated fruitfulness of interdisciplinary analogy must be accentuated in higher education.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],23.2,0.06599999999999999,0.4440000000000001,0,0.06810035842293907,0.053763440860215055,0.3684210526315789
1322,1351,1351,Languages of architectural description in systems and software engineering," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The article is devoted to the study of languages describing the architecture of systems used in systems and software engineering. The purpose of the article is to stimulate the interest of university teachers to use these languages in the disciplines of computer science. For this, methods for describing system architectures are considered, languages for describing architectures are distinguished from them, and their applications are described. To study bachelors and masters in IT areas, it is proposed to use the ArchiMate and SysML languages. The pre-property of languages used in the educational process is the visibility of the graphical representation of architecture, open documentation, support in various tools, including free cross-platform ones. Languages allow students to analyze and evaluate alternative implementations of the architecture of the system being developed, qualitatively draw up project documentation, provide a link between the parties involved in the development and deployment of the system. Examples are given. ArchiMate describes the architecture of the website. SysML describes a block diagram of an unmanned aerial vehicle. We used Archi and Modelio tools - free, open source and cross-platform. They are easy to install and operate. Therefore, these tools are recommended for students study.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],17.25,0.2083333333333333,0.5483333333333332,0,0.12658227848101267,0.05485232067510549,0.38362068965517243
1323,1352,1352,Utilizing Coal Bottom Ash from Thermal Power Plants in Vietnam as Partial Replacement of Aggregates in Concrete Pavement,"In Vietnam, a large amount of coal bottom ash (CBA) is being discharged from thermal power plants and has been making serious environmental pollution. It is essential to utilize the CBA to reduce environmental pollution. So, this paper presents a series of experimental studies in the laboratory using CBA as a partial replacement of aggregates in concrete pavement for rural roads. In mixing concrete, the CBA is utilized to replace 15, 30, and 100% aggregates. The design of the composition must achieve the technical requirement of M-30 grade of concrete. A total 351 of specimens were tested on workability of fresh concrete, abrasion, compressive strength, and flexural tensile strength in order to achieve the technical requirement of concrete pavement for rural roads. Based on the experimental results, in order to achieve the required compressive strength, An Khanh CBA concrete uses more content of cement and water than control concrete; Cao Ngan CBA is only utilized to replace 15% aggregates, and Cao Ngan CBA concrete also uses more cement and water than control concrete. It also shown that the amount of water and cement content depend on types of CBA and the water amount and cement content of CBA concrete are larger than those of control concrete. The advantage of mixture CBA concrete is abrasion, and flexural tensile strength achieved the value as per the technical requirement.",60071396,Hanoi University,Hanoi,Viet Nam,['1708'],25.11111111111111,0.10623973727422002,0.3498357963875206,1,0.09126984126984126,0.06349206349206349,0.3055555555555556
1324,1353,1353,"Better to follow, follow to be better: Towards precise supervision of feature super-resolution for small object detection","In spite of recent success of proposal-based CNN models for object detection, it is still difficult to detect small objects due to the limited and distorted information that small region of interests (RoI) contain. One way to alleviate this issue is to enhance the features of small RoIs using a super-resolution (SR) technique. We investigate how to improve feature-level super-resolution especially for small object detection, and discover its performance can be significantly improved by (i) utilizing proper high-resolution target features as supervision signals for training of a SR model and (ii) matching the relative receptive fields of training pairs of input low-resolution features and target high-resolution features. We propose a novel feature-level super-resolution approach that not only correctly addresses these two desiderata but also is integrable with any proposal-based detectors with feature pooling. In our experiments, our approach significantly improves the performance of Faster R-CNN on three benchmarks of Tsinghua-Tencent 100K, PASCAL VOC and MS COCO. The improvement for small objects is remarkably large, and encouragingly, those for medium and large objects are nontrivial too. As a result, we achieve new state-of-the-art performance on Tsinghua-Tencent 100K and highly competitive results on both PASCAL VOC and MS COCO.",60014313,University of Massachusetts Amherst,Amherst MA,United States,"['1712', '1707']",28.142857142857146,-0.00857467532467532,0.4734772727272727,1,0.08300395256916997,0.07905138339920949,0.3698630136986301
1325,1354,1354,Information and communication technologies in modern digital educational environment," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The main purpose of our study was to consider the impact of the process of digitalization of modern society on students, leading to serious changes in their consciousness and psyche, due primarily to scientific and technological progress in society, as well as the process of irreversible globalization of the information space. The modern digital educational environment has a serious impact on the transformation of the entire system of information and communication technologies, causing, at the same time, often not quite adequate change in the Outlook of potential consumers of services using these technologies, which necessitated a close study and study of the problem. Modern digital resources and technologies have a serious impact on the value system and the entire way of life of people. The development of Informatization, which became the Foundation for digitalization of modern society, has made significant changes in the processes of education and training of students. Despite all the obvious advantages and prospects of the digital space, it is necessary to realize and clearly understand that the phenomenon of digitalization has not only advantages that contribute to the development of technological progress in General, but also carries a rather powerful potential threat to the full spiritual life of citizens, their health, constitutional rights and freedoms.",60070989,Russian Academy of Education,Moscow,Russian Federation,['1700'],44.2,0.08064516129032259,0.4938172043010753,0,0.05,0.041666666666666664,0.25311203319502074
1326,1355,1355,"Hunting, killing, crafting: On the use of animals in open world games","The article focuses on how violence against animals is represented in video games. Instead of studying the most outrageous visual representations, howev-er, it focuses on the less conspicuous aspects of animal violence manifested in the hunting mechanics of open world games. Taking a rhetorical approach, it considers the ideological functions implied by the procedural gameplay of the hunting element. The article addresses four main topics: how games represent the relationship between hunting, killing and crafting; construct implicit distinctions between human and non-human animals; separate species into juridical and ethical categories associated with different values; and deal with the algorithmic nature of representations of wildlife and extinction. Among the games discussed are Rockstar's Red Dead Redemption (2010), and Ubisoft's Assassin's Creed III (2012) and Far Cry 3 (2012).",60008141,Örebro Universitet,Orebro,Sweden,"['1710', '1709']",25.4,-0.03333333333333333,0.425,1,0.11038961038961038,0.06493506493506493,0.43333333333333335
1327,1356,1356,Innovative approaches in higher education on the example of the course «engineering mechanics»," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The article discusses the use of modern digital technologies in engineering education on the example of the online course ""Engineering Mechanics"". The course is hosted on the National Open Education Platform, and the Engineering Mechanics online course in 2016 was the first Ural Federal University online course hosted at the international MOOC site. The course consists of original digital content: lecture notes, training assignment base (simulators), test and homework assignments, practical examples and demonstration video materials and other educational materials allowing one of the most demanded disciplines in the training of technical specialists to significantly improve the quality of training, reduce costs, increase the motivation of students and use teachers' work more efficiently.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],41.66666666666666,0.1265625,0.4052083333333333,0,0.0851063829787234,0.12056737588652482,0.4225352112676056
1328,1357,1357,Generalized zagreb index of product graphs,"The generalized Zagreb index is an extension of both ordinary and variable Zagreb indices. In this paper, we present exact formulae for the values of the generalized Zagreb index for product graphs. Results are applied to some graphs of general and chemical interest such as nanotubes and nanotori.",60107792,"Islamic Azad University, Kazerun Branch",Kazerun,Iran,['1703'],16.0,0.010000000000000005,0.35,1,0.09615384615384616,0.057692307692307696,0.2692307692307692
1329,1358,1358,Fuzzy decision implications: Interpretation within fuzzy decision context," All Rights Reserved.Fuzzy decision implication is an extension of decision implication in the fuzzy setting, serving to uncover the dependencies of fuzzy attributes. This study presents the interpretation of fuzzy decision implication in the fuzzy decision context. Specially, they will show that from fuzzy decision contexts one can obtain a closed fuzzy set of fuzzy decision implications, and the semantical characteristic of the obtained fuzzy set can be interpreted by fuzzy decision context and can be represented by some operators of fuzzy decision context. Conversely, starting from a fuzzy set of fuzzy decision implications, they can form a fuzzy decision context, from which the given fuzzy set can be derived. The result actually implies that they have constructed a correspondence between closed fuzzy sets of fuzzy decision implications and fuzzy decision contexts, and thus shows the equivalence of two interpretations of fuzzy decision implications.",60002222,Shanxi University,Taiyuan,China,"['1702', '1709', '1707', '1705', '1710']",29.0,0.015079365079365074,0.2396825396825397,0,0.14465408805031446,0.006289308176100629,0.23076923076923078
1330,1359,1359,"Description, characteristic and algorithm for creation of a dictionary of cell types and tissues in the GTRD database"," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The GTRD database (http://gtrd.biouml.org) contains information on transcription factor binding sites and open chromatin. The cell types and tissues presented in the GTRD: 1) were arranged in a single dictionary (3954 entries); 2) were divided into 90 unique clusters; 3) 3225 records were compared with main databases of cell types; 4) were used to match experiments with the databases of transcription regulation: 588 for FANTOM 5, 5962 for ENCODE and 21720 for GTEx.",60068684,"Institute of Cytology and Genetics, Siberian Branch of the Russian Academy of Sciences",Novosibirsk,Russian Federation,['1700'],42.5,0.1617063492063492,0.507936507936508,0,0.08823529411764706,0.10784313725490197,0.6
1331,1360,1360,Marketing in Social Networks for Promoting Mass Media Brands,"Abstract: The use of the media in Russia is undergoing a transformation due to technological changes in the communication environment. The usual channels of creating and disseminating information are crowding the Internet. Traditional media are trying to compensate for the outflow of the audience by developing digital formats, moreover, not only for sites, but also for pages on social networks. The consolidation of their positions in the media market is supported by various tools for promoting both media content and their own media brand. One such tool is social media marketing (SMM).",60007457,Lomonosov Moscow State University,Moscow,Russian Federation,['1700'],18.4,0.029166666666666664,0.4508333333333333,1,0.08737864077669903,0.02912621359223301,0.2912621359223301
1332,1361,1361,Developing facial recognition software to control access to campus facilities," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of the proposed development is to improve the system for ensuring the safe functioning of the campus, and to determine the possibility of using an intelligent system of biometric identification of the subject to identify the disturber in the protected area, as well as to record attendance at classes and monitor working hours of employees. Computer technologies are widely used to organize the administration of the educational process of the University. The application of biometric identification methods to the organization of access to the campus is an actual and important task, the solution of which is presented in the form of software development based on the use of biometrics of students and employees of the educational institution. The Zorgo program is created using Python language tools and neural network algorithms of image recognition. Application of “Zorgo” software and its integration into the existing access control systems will increase the efficiency of the security service and improve the quality of the campus security system.",60068517,Sevastopol State University,Sevastopol,Ukraine,['1700'],35.4,0.2433333333333333,0.4733333333333333,0,0.11170212765957446,0.05319148936170213,0.25925925925925924
1333,1362,1362,Smart phones in schools: In what ways can coaching empower students to make a valid judgement on when and how to use their smart phone?,"Over the last few decades, smart phones have become indispensable in people's everyday lives. The trend has also penetrated the classroom, where students use their smart phones from an early age. Excessive use of smart phones for purposes that are not directly educational in schools is an issue of concern to both teachers and students. The research literature following this trend has mainly focused on the negative effects of mobile devices, for example, to what extent does smart phone overuse distract students and cause excessive multi-tasking and phubbing. There is little research on how schools, teachers and students can meet these pedagogical challenges in the classroom, while making the most of mobile devices for teaching and learning. As an alternative to a more top-down restrictive administrative approach, like investing in storage units in the classroom or banning smart phones entirely from schools, we dis-cuss a more bottom-up oriented approach. We want to empower students to make valid judgements on when and how to use their smart phones in school by means of coaching. In this article, we present a preliminary qualitative study, where a group of Norwegian secondary school students volunteered for a coaching session after having gathered and analysed data about their own smart phone user patterns as part of the lesson plan in the class ""French as a Foreign Language"" (B2). The results suggest that coaching can create cogni-tive and emotional change and may have a positive influence on students' smart phone behaviour based on their own judgement on the use of time and attention in schools. Further research is needed, but the findings show that a bottom-up strategy is an alternative to the existing top-down administrative approach to tackle smart phone overuse.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,"['1710', '1709']",28.5,0.10242888064316637,0.5023191094619666,1,0.10429447852760736,0.009202453987730062,0.27884615384615385
1334,1363,1363,Impact of time delay in a forest biomass model in the presence of export and industry,"In this paper, we have purposed and analyzed a delayed mathematical model of Forestry Resource Biomass with Industry and Export. In this model, we have studied the effect of time delay on industrial technology in the context of conservation of biomass. The existence of equilibria and their local stability have been discussed in the absence of time delay. In the presence of time delay, the system exhibits rich dynamics with the existence of Hopf-bifurcation, period-doubling phenomenon, and chaos when parameter delay passes through a sequence of intervals. The stability and direction of the bifurcating periodic solution is also determined using normal form theory and central manifold theorem. Finally, all analytical findings are validated using numerical simulation.",60113584,"Khalsa College, Amritsar",Amritsar,India,['1700'],19.33333333333333,0.0732142857142857,0.37857142857142856,1,0.09848484848484848,0.06818181818181818,0.28125
1335,1364,1364,Perspectives of gestures for gestural-based interaction systems: Towards natural interaction,"A frequently mentioned benefit of gesture-based input to computing systems is that it provides naturalness in interaction. However, it is not uncommon to find gesture sets consisting of arbitrary (hand) formations with illogically-mapped functions. This defeat the purpose of using gestures as a means to facilitate natural interaction. The root of the issue seems to stem from a separation between what is deemed as gesture in the computing field and what is deemed as gesture linguistically. To find a common ground, this paper explores the fundamental aspects of gestures in the literature of psycho-linguistic-based studies and HCI-based studies. The discussion focuses on the connection between the two perspectives-in the definition aspect through the concept of meaning and context, and in the classification aspect through the mapping of tasks (manipulative or communicative) to gesture functions (ergotic, epistemic or semiotic). By highlighting how these two perspectives interrelate, this paper provides a basis for research works that intend to propose gestures as the interaction modality for interactive systems.",60031040,Umeå Universitet,Umea,Sweden,"['1710', '1709']",23.57142857142857,-0.12000000000000002,0.5599999999999999,1,0.1282051282051282,0.010256410256410256,0.30601092896174864
1336,1365,1365,Modeling the target architecture of an entrepreneurial network as a complex system of interaction," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of this study is to develop a model for analyzing the effect of networking companies as a learning tool for education information systems. The article presents the results of applying the tools of system dynamics for modeling the target architecture of the main processes of interaction between participants in an enterprise network. For the first time, the feasibility of applying the system dynamics method for modeling indicators of the target architecture in the formation of a network format is substantiated. The control circuit for the involvement parameters of the assets of a new network participant is selected as the main regulator of the intensity of interaction that affects the change in the level of the company's accumulated profit, as well as its image, efficiency of use of information and logistics resources. The experiments of the system-dynamic model confirm the possibility of using it as an analytical tool in substantiating management decisions in the system of digging interaction. The feedback loops obtained during the simulation allow us to formulate the network architecture as an agent-based model, as well as to predict the necessary balance of resources for all participants in the network interaction. The growth of basic and controlled parameters is the main condition for maintaining sustainable interaction effects, forming the basis for the formation of the target architecture of the enterprise network.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],33.714285714285715,0.15404040404040406,0.4347643097643098,0,0.10236220472440945,0.023622047244094488,0.22310756972111553
1337,1366,1366,Comparison of the quality of life using the human development index based on the global supply chain,"Quality of life and methods of its measurement are topics that are quickly becoming the subject of both professional and social discussions based on the global supply chain. The basic idea of this article is to compare the quality of life in the Russian Federation and Germany. These are powerful economies that offer an interesting confrontation. We also contribute to this comparison using Slovakia as an example of the confrontation of large and economically strong countries with a small country. The main indicator for expressing the quality of human life in the article is the Human Development Index (HDI), based on which we used a comparative analysis. The first part of the article provides a theoretical framework and characteristics of indicators. In the second part of the article, we analyzed the 10-year development of the selected countries' indicators. The results show a positive trend in the growth of quality of life, where Germany is clearly the leader among the selected countries, and we can state the gradual slow convergence of the Russian and Slovak economy to the German one.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],22.375,0.08948804818370036,0.29705910031996985,1,0.08247422680412371,0.05154639175257732,0.22164948453608246
1338,1367,1367,Kernel modeling super-resolution on real low-resolution images,"Deep convolutional neural networks (CNNs), trained on corresponding pairs of high- and low-resolution images, achieve state-of-the-art performance in single-image super-resolution and surpass previous signal-processing based approaches. However, their performance is limited when applied to real photographs. The reason lies in their training data: Low-resolution (LR) images are obtained by bicubic interpolation of the corresponding high-resolution (HR) images. The applied convolution kernel significantly differs from real-world camera-blur. Consequently, while current CNNs well super-resolve bicubic-downsampled LR images, they often fail on camera-captured LR images. To improve generalization and robustness of deep super-resolution CNNs on real photographs, we present a kernel modeling super-resolution network (KMSR) that incorporates blur-kernel modeling in the training. Our proposed KMSR consists of two stages: We first build a pool of realistic blur-kernels with a generative adversarial network (GAN) and then we train a super-resolution network with HR and corresponding LR images constructed with the generated kernels. Our extensive experimental validations demonstrate the effectiveness of our single-image super-resolution approach on photographs with unknown blur-kernels.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",20.625,0.038348214285714284,0.364032738095238,1,0.10638297872340426,0.03404255319148936,0.47643979057591623
1339,1368,1368,Information and communication technologies and a textbook how to master scientific skills in English for academic research work in a foreign language," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Ural Federal University identifies project teaching as one of its priority areas. Thus, interdisciplinary projects are of particular significance, as graduates of universities should be prepared for the implementation of various projects, including international ones, in different scientific fields in a team with specialists from subject areas. Therefore, there is a need to create a specialized textbook that meets objectives of teaching and requirements of the students, teachers of foreign languages, and the heads of Bachelor and Master curriculums. We carried out theoretical researches of the principles of creating modern textbooks for university students. These principles of forming competences, conscientiousness and activity are determined as the priority ones. The didactic requirements for a contemporary textbook which include adequate correspondence of pedagogical process to the demands of modern life, purposefulness of education, reliance on a student and motivation are proposed in the article. We consider the use of computer science studies, information and communication technologies in the educational process at higher educational establishments as one of the essential requirements. We describe in detail the textbook How to Master Scientific Skills in English elaborated for academic research work in foreign language teaching at universities. This textbook is aimed at the formation and development of all types of speech activities (reading, speaking, writing and listening) in a foreign language and the foreign language communicative research competence in the sphere of the future career through the implementation of a project work in various fields. The results of the research include the testing assessment of the textbook with the students of the Institute of Radio Electronics and Information Technologies, who basically study Computer Science, at Ural Federal University and surveys of the teachers and students.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],29.2,0.046,0.2876666666666667,0,0.065625,0.071875,0.3364485981308411
1340,1369,1369,Information system for diagnosing pollutants based on data analysis algorithms," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper shows the influence of factors, processes and consequences of pollution of components of urban ecosystems on water pollution and hydro chemical composition of water of small rivers and the Ob river basin. The structure of the prototype of an interactive information system (IAS), which provides for the possibility of obtaining a forecast for the next five years, is described.",60016279,"Institute of Computational Technologies, Siberian Branch of the Russian Academy of Sciences",Novosibirsk,Russian Federation,['1700'],36.5,0.05,0.28,0,0.06172839506172839,0.12345679012345678,0.4024390243902439
1341,1370,1370,Reference and educational system lexsite-lextutor as information technology for foreign language learning,"The paper describes the reference and educational system LexTutor based on the English-Russian and Russian-English Internet dictionary LexSite. Both systems were developed by the authors of this paper based on their research in the field of natural language processing. This educational technology can be used for learning English by Russian-speaking students and learning Russian by English-speaking students of higher education schools including distant learning students. The new tool has bilingual user interface. It enables users to create and maintain personal learning dictionaries using the lexical database. Another part of this reference and educational system is a collection of subject-specific public dictionaries designed by the LexSite team. The public dictionaries are available for all users. Both personal and public dictionaries are equipped with the flash session function that helps learn the lexis and check the results. Flash cards are created automatically from the dictionary entries. The system also offers tests on lexis being learned. Users can obtain their learning curves computed from the results of tests taken. The personal dictionaries can be shared with other users, which, in particular, is important to teachers willing to monitor the students’ learning progress. The authors of this paper continue working on development of new educational tools based on the LexSite dictionary that match the higher education standards and help overcome the educational barriers.",60007634,Ural State Law University,Yekaterinburg,Russian Federation,['1700'],16.846153846153847,0.12747668997668998,0.3141317016317017,1,0.15040650406504066,0.044715447154471545,0.326271186440678
1342,1371,1371,Monitoring of a strategy proficiency as a tool of the pedagogical decision support system," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper presents the use of a computer in the organization of continuous monitoring and evaluation activities for the adoption of pedagogical decisions in the educational process, based on assessments of the level of knowledge of the learner's basic strategies of activity using cognitive science.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],57.0,0.1875,0.34375,0,0.06557377049180328,0.09836065573770492,0.3709677419354839
1343,1372,1372,The digital repository integration with external information services," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The evolution of society to the digital future has initiated major changes in the principles and approaches to science and education. One of the important aspects of moving along this way is open access to the results of scientific research, which can be implemented using technology and the open archives software platform. The implementation of open archives in the libraries of research and educational institutions requires solving many problems as the select and correcting of data schemes, the batch exchange of data between the library automation system and the digital archive, authentication and authorization, licensing for digital documents and collections, and etc. Some of these problems are relatively easy solved by web services that are actively developing in the process of creating a scientific communication infrastructure on the Internet and being its integral part. Their inclusion as part a digital archive, as well as exploring the possibilities and features of their functioning, is an actual task. Some services useful for libraries are considered, integration with which can be implemented using the DSpace 6.3, as well as the features of their configuration and operation.",60008166,Institute of Computational Modeling of Siberian Branch of the Russian Academy of Sciences,Krasnoyarsk,Russian Federation,['1700'],32.5,0.1284722222222222,0.3560185185185185,0,0.08530805687203792,0.037914691943127965,0.33490566037735847
1344,1373,1373,RankSRGAN: Generative adversarial networks with ranker for image super-resolution,"Generative Adversarial Networks (GAN) have demonstrated the potential to recover realistic details for single image super-resolution (SISR). To further improve the visual quality of super-resolved results, PIRM2018-SR Challenge employed perceptual metrics to assess the perceptual quality, such as PI, NIQE, and Ma. However, existing methods cannot directly optimize these indifferentiable perceptual metrics, which are shown to be highly correlated with human ratings. To address the problem, we propose Super-Resolution Generative Adversarial Networks with Ranker (RankSRGAN) to optimize generator in the direction of perceptual metrics. Specifically, we first train a Ranker which can learn the behavior of perceptual metrics and then introduce a novel rank-content loss to optimize the perceptual quality. The most appealing part is that the proposed method can combine the strengths of different SR methods to generate better results. Extensive experiments show that RankSRGAN achieves visually pleasing results and reaches state-of-the-art performance in perceptual metrics. Project page: Https://wenlongzhang0724.github.io/Projects/RankSRGAN.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",18.75,0.13157738095238095,0.3971428571428571,1,0.13829787234042554,0.09042553191489362,0.39204545454545453
1345,1374,1374,Gamification and resource pooling for improving operational efficiency and effective management of human resources: A case study with an ecommerce company," Another biggest motive behind the authors for combining these two techniques is the fact that eCommerce is a business vertical or a market place where people from all walks of life participate in online purchases. eCommerce is not a market place where it is restricted to one particular community, region, age, colour etc., So to interact, involve and conduct the business operations with an inclusive mindset, the authors thought that it would be appropriate to gamify and pooling the resources such that there would be a perfect blend of resources with utmost motivation to serve all the stakeholders, irrespective of their age, gender, community, region, economic status, in ecommerce. It turned out to be a practical solution as it proved to be promoting an atmosphere that fosters friendship and loyalty, and these close-knit relationships motivate employees; align them to work much harder, cooperate and be supportive to each other. This is possible because every individual possesses diverse talents, weaknesses, communication skills, strengths, habits, and hence it is optimally balanced out. Gamification is a method to enhance employee engagement, behavioral change and motivation. Application of gamification is not limited to eCommerce business models, but can be applied to various other business models in the sectors like education, research, healthcare etc. So also, the human resource pooling is building and grouping of human resources for best use to improve the operational efficiency and reduce the costs. The human resource pooling can happen during fine tuning of a cultural fit, organization mergers, change in organization structure, technological changes and on acquiring new technology. In this study we have considered a group of 120 employees who were further divided to 6 functional groups, having 20 employees in each functional group. In this paper we report the outcome of application of gamification and resource pooling techniques and benefits in an eCommerce industry.",60056514,"Shri Ramdeobaba College of Engineering and Management, Nagpur",Nagpur,India,['1706'],30.8,0.1611048371917937,0.4165537361189536,0,0.10285714285714286,0.011428571428571429,0.30057803468208094
1346,1375,1375,Information and communication technologies in a staged approach to formation of a foreign language communicative research competence," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This paper deals with the components of the competence model of a student of a university realizing a research in the sphere of the future career in a foreign language with the usage of computer science. The paper analyses statistics that confirm the necessity of the development of the foreign language communicative research competence in the sphere of the future career of Computer Science students in higher educational establishments. The foreign language communicative research competence is a complex and multidimensional term, which combines the following components of the student’s competency model: foreign language communicative competence, intercultural competence, career-oriented research competence, competence of scientific communication, educational competence and technological competence. The authors of the article present the methodology of organising staged research work of Computer Science students during their Bachelor degree program. On the one hand, any research work is organised according to specific stages. This paper gives seven stages of students’ research work. On the other hand, research work in higher educational establishments is realized in the form of formal and informal communication. These forms of scientific communication give an opportunity to identify the stages of the research work of students. This research work is realized in different forms during every year of education including the usage of computer science studies and information communication technologies. It starts with short reports and presentations on the career-oriented topic; and develops into interdisciplinary project for a year and a half duration which unites the work of foreign language teacher, teachers of career-oriented disciplines and Computer Science students. Moreover, this project work may be continued as Master's research paper. Analysis of statistics, psychological-pedagogical and methodological literature allowed the authors to determine the foreign language communicative research competence and highlight methods of their formation and development. Empirical methods include the questioning of university students and teachers, the introduction of research results in teaching practice at universities, the analysis of progress in the learning process, the mathematical processing of surveys, and the graphical presentation of the results. We prove in this paper that the foreign language communicative research competence is multicomponent; the sequence of stages of a research work of university students in a foreign language allows evaluating the formation of each component of the foreign language communicative research competence; the formation and development of the foreign language communicative research competence in professionally-oriented teaching of a foreign language at universities is realized in the conditions of scientific communication in a foreign language; what finally increases motivation of university students to study a foreign language and forms interdisciplinary links. The development of every component of the foreign language communicative research competence provides effective progress in the career of a Computer Science graduate.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],30.466666666666665,0.003095238095238093,0.24904761904761905,0,0.07128712871287128,0.031683168316831684,0.2655935613682093
1347,1376,1376,Visualization and analysis tools of the spectra of the Information System «Electronic Structure of Atoms»," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper describes the Internet service for visualization and comparative analysis of spectra that is implemented as part of the information system on atomic spectroscopy “Electronic structure of atoms”. The possibilities of representing spectra from the system database in the form of interactive spectrograms with a set of tools for convenient presentation and analysis are described. There is an opportunity for users of the information system to upload files with the data of experimental spectra to the system, as well as conduct their processing and visual analysis in comparison with the reference spectra of atomic systems stored in the system. The possibilities of using new tools for research and training specialists are discussed.",60023579,Budker Institute of Nuclear Physics of the Siberian Branch of the RAS,Novosibirsk,Russian Federation,['1700'],31.25,0.14727272727272728,0.3709090909090909,0,0.07518796992481203,0.06766917293233082,0.3208955223880597
1348,1377,1377,Analysis of competitive behavior strategies in the Russian banking industry," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This article is devoted to the analysis of the behavioral strategies of Russian banks which provide services to legal entities. A comparative analysis of tariff plans for the 2018 fiscal year was integrated into the study. Based on the author’s methodology of the three-phase component diagram, banks were segmented according to their various development strategies to obtain the desired exploratory results. The general situation in the market of banking services in the corporate segment is described.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],22.0,0.10714285714285714,0.31428571428571433,0,0.10309278350515463,0.061855670103092786,0.3402061855670103
1349,1378,1378,PLS equation model of student loyalty based on gender in IR 4.0 environment,"Students loyalty and attrition is an important issue for university authorities. Earlier studies have discovered that many factors influencing student loyalty towards their higher learning institutions such as student satisfaction, university image, student trust, and service quality. However, these factors have high relationship correlated with each other. Therefore, this study used the Partial Least Square (PLS) to create a path model which shows the relationship between all factors related to student loyalty. The results from this study revealed that student satisfaction is the most important factors that influence student loyalty, followed by image of university and student commitment. Analysis based on gender shows that female student model have a same pattern with overall student loyalty model but the male student loyalty model is simpler just consist student satisfaction. On the other hand, factors technology, social environment and quality of instructor gave a great influence towards student satisfaction. Therefore, in order to improve student loyalty, university should keep on improving to satisfy students' requirement.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],20.375,0.12596491228070175,0.42622807017543857,1,0.10326086956521739,0.021739130434782608,0.25
1350,1379,1379,Intelligent fuzzy enabled malicious node identification on routing and certificate authority oriented secure communication over wireless ad-hoc network,"The general behavior of Mobile AdHoc Networks (MANETs) is different in certain stages due to its mode of operations and maintenance as well as factors such as Node-Energy level, manipulation energy, randomly movable nature and the topology-changes. This type of dynamicity causes or needs over concentration and needs more security with routing-stability. For eliminating these issues and improve the security, a new methodology called Secured Fuzzy Enabled Node Identification and Routing Strategy (SFENIRS) is defined, which provides the Trusted-Network-Service and better performance with energy efficiency in security and dynamicity perspectives. This algorithm SFENIRS provides high-reliability and dynamicity to nodes, which can move frequently without any security causes and attain more robustness during performance. The selection of next node selection and forwarding is purely based on the link-stability and next-neighbor availability, which is ensured by means of the parental node by sending route-request and getting response for the request. Once the neighbor provides the response properly for the raised request the node will be treated as a next successful neighbor, otherwise the node will be considered as a malicious node and which cannot be considered for next process further. The survey results further to guarantee regarding the network robustness, dynamicity, good packet delivery ratio, goodput and secure-routing over MANET with the help of Secured Fuzzy Enabled Node Identification and Routing Strategy.",60079451,Noorul Islam University,Kanyakumari,India,['1700'],31.42857142857143,0.15199675324675327,0.4225487012987013,1,0.11068702290076336,0.09923664122137404,0.3140495867768595
1351,1380,1380,Healthcare Data Security Technology: HIPAA Compliance,"Information technology (IT) plays an increasingly important and prominent role in the health sector. Data security is more important than ever to the healthcare industry and in world in general. The number of data breaches compromising confidential healthcare data is on the rise. For data security, cloud computing is very useful for securing data. Due to data storage issue, there is a need to use the electronic communication, and a number of methods have been developed for data security technology. Health Insurance Portability and Accountability Act (HIPAA) is one of the methods that can help in healthcare research. On stored database of patient in hospital or clinic, we can develop a conservational and analytical method so as to keep the medical records of the patients in a well-preserved and adequate environment. The method includes the improvement of working possibilities by delivering all the details necessary for the patient. All the information must be identified clearly. The protection of the privacy of the patients and the security of their information are the most imperative obstacles to obtain their intakes when considering the adoption of useful health data in the electronic field of healthcare industries.",60064143,Nanjing University of Information Science and Technology,Nanjing,China,"['1710', '1705']",19.3,0.2265555555555556,0.4594444444444444,1,0.08450704225352113,0.03286384976525822,0.26066350710900477
1352,1381,1381,Information support system for assessment the level of competency formation," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The urgency of the problem of developing methods and tools of information support for assessment the level of competency formation is substantiated. A review of the scientific works of domestic and foreign researchers in the field of the competency-based approach in education is given. The expediency of using knowledge control systems and evaluation the level of competency formation in electronic interdisciplinary educational and methodological complexes (EIEMC), which are combination of educational materials, educational and methodical documentation, electronic educational resources and additional information resources in interrelated disciplines, is substantiated. A model of the EIEMC design process is presented. The concept of the information support system for accounting for current academic performance and evaluation the level of formation of students' competencies is outlined. The analysis of domestic and foreign systems of accounting for current academic performance is implemented. The author's model of the information database is presented, which is the basis of the information support system for assessment the level of competency formation. The implementation of the system contributes to the accumulation of structured information about the achievements of each student during the entire period of study, allows you to track the history of the formation of competencies, identify problematic issues and develop individual corrective actions.",60070989,Russian Academy of Education,Moscow,Russian Federation,['1700'],27.0,0.078125,0.2671875,0,0.08823529411764706,0.04201680672268908,0.2616033755274262
1353,1382,1382,"Elliptic root systems of type A1, a combinatorial study","We consider some combinatorics of elliptic root systems of type Ai. In particular, with respect to a fixed reflectable base, we give a precise description of the positive roots in terms of a ""positivity"" theorem. Also the set of reduced words of the corresponding Weyl group is precisely described. These then lead to a new characterization of the core of the corresponding Lie algebra, namely we show that the core is generated by positive root spaces.",60024836,University of Isfahan,Isfahan,Iran,['1703'],19.0,0.1071969696969697,0.5848484848484847,1,0.11764705882352941,0.03529411764705882,0.29411764705882354
1354,1383,1383,Dynamic Game and Coordination Strategy of Multichannel Supply Chain Based on Brand Competition,"In this paper, two noncooperative dynamic pricing strategies are used in a supply chain. Two dynamic Stackelberg game models have been built involving both a manufacturer and a retailer assumed to be the leader in order. In the two models, the manufacturer sells national-brand (NB) product to an independent retailer or directly to consumers through a direct channel. The retailers sell a store-brand (SB) product when they sell the NB product coming from the manufacturer. Thus, there is competition both in different channels and in products with different brands. To analyze the complexity of the model, parameter bifurcation diagrams and strange attractor diagrams have been therefore plotted. The results show that the game leader has advantages when the market is stable, but it turns disadvantageous if the state falls into unstable as the game follower can quickly adjust the strategy to seize the market. The wholesale price and the direct selling price are high that they incur larger profits if the manufacturer is dominant, but it gets worse when the adjustment speed increases. While in the model where the retailer plays a dominant role, the increase in the adjustment speed is unfavorable to retailer. By controlling the total cost of the direct channel and increasing channel competition strength and brand competition strength, the manufacturers can increase their profits in the game dominated by the retailer. In addition, the stable region within the system will be narrow since the market is sensitive to the channel competition, brand competition, and advertising indifference.",60025569,Tianjin Polytechnic University,Tianjin,China,['1700'],22.72727272727273,-0.05984126984126986,0.4380158730158731,1,0.09285714285714286,0.017857142857142856,0.2391304347826087
1355,1385,1385,Personal digital twins and their socio-morphic networks: Current research trends and possibilities of the approach," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The digital twin concept which occurred in industrial engineering, design and production, is increasingly being transferred to nature and a man. The article covers the special case of building digital twins that is twins of subjects that are created by the latter to replace themselves, for example, to help in any activity. The paper describes the features of such twins, the possibilities and ways of their implementation, highlights their ability to form multi-agent systems that are isomorphic to social networks. The article considers the set of tasks that can be effectively solved with the help of personal digital twins and the socio-morphic multi-agent systems formed by them. The article ends with a statement on the formation of a multidisciplinary research team for practice-oriented research in the field of personal digital twins and socio-morphic multi-agent systems built based on them and high-priority tasks of system prototyping.",60016279,"Institute of Computational Technologies, Siberian Branch of the Russian Academy of Sciences",Novosibirsk,Russian Federation,['1700'],31.4,0.11465201465201465,0.2721611721611721,0,0.10382513661202186,0.03278688524590164,0.3235294117647059
1356,1386,1386,Monitoring the financial performance of using open source software in government digital projects," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of this study is to develop a system for monitoring the financial effectiveness of digital development programs and the introduction of the open source software in the educational environment. The main control elements in the monitoring system is a simulation system-dynamic model which allows determining based on the experiments, the key financial indicators of the development of digital projects of an IT company in dynamics. The main advantage of the first developed model, as the basic element of the monitoring system, predicting the effectiveness of the transition to new types of information products and data management, as well as the ability to track the dynamics of the enterprise in the long term with various combinations of areas of investment into open source software distribution projects, including educational information systems. The proposed model allows you to determine key indicators of the development of an IT company: the amount of income from the sale of all IT products and services, profit, accumulated capital, additional income due to the development and expansion of the scope of the open source software, evaluation of the effectiveness of the development of information systems based on them. The results of the system-dynamic simulation are the tool for determining the balance of investment funds invested into the commercial and non-profit sector of the development of digital data of an IT company. The experimental implementation of the PowerSim simulation software in a software environment allows you to evaluate the prospects and opportunities of the IT company to switch to the expanding of the range of services and produced products by using the open source software.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],46.66666666666666,0.06710372960372961,0.3482517482517483,0,0.07260726072607261,0.036303630363036306,0.2651006711409396
1357,1387,1387,Data and application management models for content services architecture: Example of project approach to education process of master students in it," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of this study is to develop a model for managing data and applications in the architecture of content services using the example of an e-sports agency for student. A data management model was developed in the Powersim Studio 7.0 simulation environment, which allows determining the economic result of the company in the electronic sales architecture. The presented model includes several functional blocks, consisting of the key parameters of the model, such as: sales, customers, orders, income from additional services. The selected blocks were formed on the basis of the analysis of the company's business processes, which allowed us to identify the main processes that affect the formation of the nailed enterprise in the project training. After a series of simulation experiments, taking into account the initial values specified in the model and taking into account the inclusion of additional values (income from the provision of additional services to the company), results were obtained confirming the economic feasibility of including additional services. The proposed system of indicators and the developed model are an analytical comprehensive toolkit that allows you to reasonably assess the current state and results of the system, taking into account the introduction of additional services and activities, and without it, which, in turn, makes it possible to study in more detail and deeply their impact on the economic result company.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],39.333333333333336,0.12745098039215688,0.40784313725490207,0,0.10646387832699619,0.034220532319391636,0.31297709923664124
1358,1388,1388,Special features of Web-IrBis64+ system implementation at the big library, Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The problems of transition to the new version of electronic catalogues provision in Internet are discussed in the paper. Differences between Web-IRBIS64+ and previous versions of software are analyzed. Primary tasks to Web-IRBIS64+ modifying and settings changing for system implementation at the big library are defined.,60107593,The State Public Scientific Technological Library of the Siberian Branch of the Russian Academy of Sciences,Novosibirsk,Russian Federation,['1700'],19.33333333333333,0.14494949494949494,0.3702020202020202,0,0.08823529411764706,0.1323529411764706,0.49206349206349204
1359,1389,1389,Topical discourse structures: Using topic modeling in discourse analysis approaches,"With the amount textual data available to researchers rapidly increasing, the Humanities and Social Sciences have to deal with new challenges in utilizing these large quantities of texts. For several decades, Digital Humanities have offered a multitude of tools for computer-assisted or-driven research. This article will explore how distant reading approaches in general and topic mod-eling in particular can be utilized in discourse analysis. It will present theo-ries and methods that work well together and can be applied to different research projects, using a combination of Structural Topic Modeling, devel-oped by Roberts, Stewart and Tingley (2018) and Siegfried Jager's Critical Discourse Analysis approach as an example.",60005322,Ruhr-Universitat Bochum,Bochum,Germany,"['1710', '1709']",26.5,0.07505411255411255,0.3277597402597403,1,0.1484375,0.09375,0.4067796610169492
1360,1390,1390,Analysis of College Students' Public Opinion Based on Machine Learning and Evolutionary Algorithm,"The recent information explosion may have many negative impacts on college students, such as distraction from learning and addiction to meaningless and fake news. To avoid these phenomena, it is necessary to verify the students' state of mind and give them appropriate guidance. However, many peculiarities, including subject focused, multiaspect, and low consistency on different samples' interests, bring great challenges while leveraging the mainstream opinion mining method. To solve this problem, this paper proposes a new way by using a questionnaire which covers most aspects of a student's life to collect comprehensive information and feed the information into a neural network. With reliable prediction on students' state of mind and awareness of feature importance, colleges can give students guidance associated with their own experience and make macroscopic policies more effective. A pipeline is proposed to relieve overfitting during the collected information training. First, the singular value decomposition is used in pretreatment of data set which includes outlier detection and dimension reduction. Then, the genetic algorithm is introduced in the training process to find the proper initial parameters of network, and in this way, it can prevent the network from falling into the local minimum. A method of calculating the importance of students' features is also proposed. The experiment result shows that the new pipeline works well, and the predictor has high accuracy on predicting fresh samples. The design procedure and the prediction design will provide suggestions to deal with students' state of mind and the college's public opinion.",60003977,Northwestern Polytechnical University,Xi'an,China,['1700'],22.54545454545455,0.15446386946386947,0.4954778554778555,1,0.125,0.0,0.2571428571428571
1361,1391,1391,Three-stage network for age estimation," All rights reserved.Age estimation on the basis of the face has been widely used in the field of human–computer interaction and intelligent surveillance. Many existing methods extract deeper global features from the facial image and achieve significant improvement on age estimation. However, local features and their relationship are important for age estimation. In this study, the authors propose a model to use local features for age estimation. The proposed model consists of three stages, preliminary abstraction stage for extracting deeper features, local feature encoding stage to model the relationship between local features and recall stage for the combination of temporary local impressions. Extensive experiments show that their proposed method outperforms previous state-of-the-art methods.",60019616,Harbin Institute of Technology,Harbin,China,"['1702', '1709', '1707', '1705', '1710']",19.0,0.12916666666666668,0.2982142857142857,0,0.11940298507462686,0.0,0.3252032520325203
1362,1392,1392,Teaching fundamental mathematics for students of IT-specialties in the transition period," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).We consider the problems of the first-year students’ adaptation to the learning process at the university. The technique of intensive adaptation of the first-year students of IT-specialties to the development of the basic concepts and methods. These techniques are subsequently actively used both in fundamental mathematics and programming courses. Considerable attention is paid to development of the creativity and independence in the acquisition of competencies. The principle of the “Flipped class” (“Inverted class”) is used as the basic pedagogical technology. At the same time, it is supplemented by a number of methodological, information, and technological tools that reduce the effect of the known negative aspects of this technology. The network computer platform Ulearn.me is used as the information and communication mean for student learning. It is like well-known open education platforms. But it has an expanded feature set for educators. The results of experimental teaching are presented. We consider them both from the point of view of students acquiring the necessary competencies and the psychological aspects of using this technique.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],16.545454545454547,-0.0035256410256410244,0.4240384615384615,0,0.08490566037735849,0.0330188679245283,0.34146341463414637
1363,1393,1393,Channel-wise attention model-based fire and rating level detection in video," All rights reserved.Due to natural disaster and global warning, one can expect unexpected fire, which causes panic among people and extent to death. To reduce the impact of fire, the authors propose a new method for predicting and rating fire in video through deep-learning models in this work such that rescue team can save lives of people. The proposed method explores a hybrid deep convolutional neural network, which involves motion detection and maximally stable extremal region for detecting and rating fire in video. Further, the authors propose to use a channel-wise attention mechanism of the deep neural network for detecting rating of fire level. Experimental results on a large dataset show the proposed method outperforms the existing methods for detecting and rating fire in video.",60033100,Nanjing University,Nanjing,China,"['1702', '1709', '1707', '1705', '1710']",25.2,0.06506493506493508,0.4483116883116883,0,0.15492957746478872,0.0,0.2740740740740741
1364,1394,1394,Advances on QoS-aware web service selection and composition with nature-inspired computing," All Rights Reserved.Service-oriented architecture is becoming a major software framework for complex application and it can be dynamically and flexibly composed by integrating existing component web services provided by different providers with standard protocols. The rapid introduction of new web services into a dynamic business environment can adversely affect the service quality and user satisfaction. Therefore, how to leverage, aggregate and make use of individual component’s quality of service (QoS) information to derive the optimal QoS of the composite service which meets the needs of users is still an ongoing hot research problem. This study aims at reviewing the advance of the current state-of-the-art in technologies and inspiring the possible new ideas for web service selection and composition, especially with nature-inspired computing approaches. Firstly, the background knowledge of web services is presented. Secondly, various nature-inspired web selection and composition approaches are systematically reviewed and analysed for QoS-aware web services. Finally, challenges, remarks and discussions about QoS-aware web service composition are presented.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,"['1702', '1709', '1707', '1705', '1710']",23.142857142857146,0.08736631016042781,0.5828877005347594,0,0.116751269035533,0.015228426395939087,0.31843575418994413
1365,1395,1395,Software architecture of the atlas of digital oil-gas formations," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The ATLAS MPhM is a collection of digital formation models of oil and gas-saturated reservoirs. It is intended for most realistic modeling that includes changes in fluid-saturated rock properties in the borehole environment, and describes the processes of the formation fluid replacement with mud filtrate, taking into account changes in the geomechanical parameters and evolution of the spatial distribution of electric resistivity. The ATLAS software organization uses a scalable “cloud” of computing agents for high-performance scientific calculations.",60103859,Trofimuk Institute of Petroleum Geology and Geophysics of Siberian Branch of Russian Academy of Sciences,Novosibirsk,Russian Federation,['1700'],29.66666666666667,0.19444444444444445,0.32222222222222224,0,0.08737864077669903,0.10679611650485436,0.42857142857142855
1366,1396,1396,A review of social media posts from Unicredit bank in Europe: A sentiment analysis approach,"In recent times, the increasing popularity of social media websites has provided a major source of data for mining public opinion on a variety of subjects. The opinions expressed on social media enables firms to discover individual perceived strengths and weaknesses regarding their operations as well as the products/services they offer. Twitter is one platform that gives us the opportunity to evaluate the opinions expressed by users. In this study, a dataset of tweets is downloaded from the official twitter account associated with UniCredit bank‟s main public relations outfit within the European sub-region using the Twitter API. Valence Aware Dictionary and sEntiment Reasoner (VADER), a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed on social media (e.g. Twitter), was used in conducting sentiment analysis on the tweets to examine the attitudes and feelings expressed. Using VADER to conduct sentiment analysis showed that the overall discussion was positive focusing on tweets describing UniCredit‟s engagement in corporate social responsibility activities, support for small and medium scale enterprises and business innovation. Our approach will enable the bank to gain insights on how to shape their online presence and address customer and stakeholder expectations. In theory, the study adds up to broaden the scope of online banking given the interplay of consumer sentiments via the social media channel.",60008287,Univerzita Tomase Bati ve Zline,Zlin,Czech Republic,"['1712', '1709', '1707', '1705']",24.33333333333333,0.03665329768270945,0.18502673796791447,1,0.13991769547325103,0.053497942386831275,0.3277310924369748
1367,1397,1397,Influence of ice formation on the lifetime of the roof of residential buildings and the living safety,"In this paper the problems associated with the accumulation of snow and the formation of ice on the roofs of residential buildings are discussed. The mechanisms of ice and icicles formation, methods and devices for combating snow on the roofs of houses and icicles along the edges of the roofs are considered. The effect of ice formation on the lifetime of the roof. A generalization of the results is carried out.",60077692,University of Al-Qadisiyah,Al-Qadisiyah,Iraq,['1700'],17.75,0.0,0.0,1,0.06578947368421052,0.0,0.27631578947368424
1368,1398,1398,Features of virtual reality systems development," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper considers the process of creating educational virtual systems that can immerse the student in the subject area as much as possible. The possibility of developing a VR system in the context of project training of students is discussed. The results of the analysis of methods that allow effective development of modern educational environments are presented. During the experiment, it was found that the organization of VR system development is implemented by the SCRUM method most successfully. However, the methodology needs to be supplemented by the role of a game master – a specialist in training methods. The hypothesis that it is impossible to develop a high-quality educational virtual environment without the participation of a game master is confirmed. The main functions of the game master in the project activity are described.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],20.714285714285715,0.10784313725490197,0.5392156862745099,0,0.10191082802547771,0.050955414012738856,0.28205128205128205
1369,1399,1399,The Impact of Emotional Music on Active ROI in Patients with Depression Based on Deep Learning: A Task-State fMRI Study,"With the continuous development of science, more and more research results have proved that machine learning is capable of diagnosing and studying the major depressive disorder (MDD) in the brain. We propose a deep learning network with multibranch and local residual feedback, for four different types of functional magnetic resonance imaging (fMRI) data produced by depressed patients and control people under the condition of listening to positive- and negative-emotions music. We use the large convolution kernel of the same size as the correlation matrix to match the features and obtain the results of feature matching of 264 regions of interest (ROIs). Firstly, four-dimensional fMRI data are used to generate the two-dimensional correlation matrix of one person's brain based on ROIs and then processed by the threshold value which is selected according to the characteristics of complex network and small-world network. After that, the deep learning model in this paper is compared with support vector machine (SVM), logistic regression (LR), k-nearest neighbor (kNN), a common deep neural network (DNN), and a deep convolutional neural network (CNN) for classification. Finally, we further calculate the matched ROIs from the intermediate results of our deep learning model which can help related fields further explore the pathogeny of depression patients.",60073652,Tongji University,Shanghai,China,['1700'],34.166666666666664,0.05971706864564006,0.3967790146361575,1,0.08906882591093117,0.032388663967611336,0.3080168776371308
1370,1400,1400,Evaluation of antioxidant and cytotoxic activity of marine red alga scinaia furcellata (Turner) j.agardh,"Marine macro algae are important source of vast amounts of nutrients and bioactive components. These bioactive compounds are highly used in the treatment of diseases like cancer, AIDS, soreness, ache, arthritis, viral, bacterial, and fungal infections. In the present study, invitro antioxidant and cytotoxic activity of ethanol and ethylacetate extracts of Scinaia furcellata was evaluated. Antioxidant action was studied using 4 commonly used scavenging assays including DPPH (1,1-diphenyl-2-pricrylhydrazyl) free radical, hydroxyl radical, superoxide anion, ABTS radical and reducing power assay. Cytotoxic study against breast cancer cells MDA-MB-231 was studied by sulforhodamine B dye. Ethanol extract exhibited the maximum cytotoxic and antioxidant activity viz DPPH (113.53%), Hydroxyl (118.16%), ABTS (121.98%) Superoxide (113.16%) radical scavenging activity and also exhibits higher reducing activity.",60114923,V. O. Chidambaram College,Thoothukudi,India,['1700'],20.0,0.12625,0.555,1,0.08387096774193549,0.0967741935483871,0.49019607843137253
1371,1401,1401,Some upper bounds for the signless laplacian spectral radius of digraphs,"Let G = (V(G), E(G) be a digraph without loops and multiarcs, where V(G) = (v1, v2,..., vn) and E(G) are the vertex set and the arc set of G, respectively. Let be the outdegree of the vertex vi. Let A(G) be the adjacency matrix of G and D(G) = diag be the diagonal matrix with outdegrees of the vertices of G. Then we call Q(G) = D(G) +-4(G) the signless Laplacian matrix of G. The spectral radius of Q(G) is called the signless Laplacian spectral radius of G. denoted by q(G). In this paper, some upper bounds for q(G) are obtained. Furthermore, some upper bounds on q(G) involving outdegrees and the average 2-outdegrees of the vertices of G are also derived.",60003977,Northwestern Polytechnical University,Xi'an,China,['1703'],15.25,-0.275,0.4166666666666667,1,0.058823529411764705,0.1503267973856209,0.4157303370786517
1372,1402,1402,Decomposing deontic modality: Evidence from Korean," Published by Oxford University Press. All rights reserved.Korean deontic modal expressions inform about the composition of modality which is not evident from languages that express modal concepts via an auxiliary or a verb. They are expressed in terms of a conditional and an evaluative predicate: permission and obligation respectively translate to 'even if φ, good' and 'only if φ, good', where φ is the prejacent. i. John-un maykcwu-lul masi-eto toy-n-ta John-TOP beer-ACC drink-even.if GOOD-PRES-DECL 'John may drink beer.' ii. John-un maykcwu-lul masi-eya toy-n-ta John-TOP beer-ACC drink-only.if GOOD-PRES-DECL 'John must/should/ought to drink beer.' Their transparent morphosyntax lets us probe deeper into the interior of deontic modal concepts. I propose that Korean deontic modal expressions do not set up the domain of quantification in which the prejacent is evaluated. Instead, they assess the goodness of the prejacent and its alternatives, all else being equal. I allude to the possibility that English obligation also involves similar reasoning by offering a counterfactual-based account of the Professor Procrastinate puzzle. On the other hand, Korean permission gives rise to a specific interpretation of strong permission, conveying that the truth or falsity of the prejacent does not affect the deontic status. I additionally point out that Korean has a separate copula-based construction for expressing modal possibility, which hints that there are in fact two types of permission in natural language.",60021784,New York University,New York,United States,['1702'],20.363636363636363,0.14027777777777778,0.40277777777777785,0,0.09698996655518395,0.10033444816053512,0.3548387096774194
1373,1403,1403,Visualization of rating system to increase student motivation using electronic resources," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The rating system is used quite actively in the current assessment of student performance, allowing students to be motivated during the inter-sessional period. However, it is not always tied to the e-learning system. Using the principles of the rating system and information visualizing the dynamics of learning at the level of electronic courses allows students of higher education to plan audit and independent work more effectively. The integration of the test system into the educational environment within the framework of electronic resources allows in the training mode to adjust the mastery of professional requirements to the level of competence and to change the software development life cycle (SDLC). Visualization of the assessment of the level of achievements in e-learning allows the student to react more quickly to deviations from the performance of tasks online and to make changes to the schedule of works.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],31.0,0.2416666666666667,0.4395833333333333,0,0.09941520467836257,0.05263157894736842,0.28313253012048195
1374,1404,1404,TLBO with variable weights applied to shop scheduling problems," All Rights Reserved.The teaching–learning-based optimisation (TLBO) algorithm is a population-based metaheuristic inspired on the teaching–learning process observed in a classroom. It has been successfully used in a wide range of applications. In this study, the authors present a variant version of TLBO. In the proposed version, different weights are assigned to students during the student phase, with higher weights being assigned to students with better solutions. Three different approaches to assign weights are investigated. Numerical experiments with benchmark instances of the flow-shop and the job-shop scheduling problems are carried out to investigate the performance of the proposed approaches. They compare the proposed approaches with the original TLBO algorithm and with two variants of TLBOs proposed in the literature in terms of solution quality, convergence speed and simulation time. The results obtained by the application of a Friedman statistical test showed that the proposed approaches outperformed the original version of TLBO in terms of convergence, with no significant losses in the average makespan. The additional simulation time required by the proposed approaches is small. The best performance was achieved with the approach of assigning a fixed weight to half the students with the best solutions and assigning zero to other students.",60020457,Universidade Federal do Ceara,Fortaleza,Brazil,"['1702', '1709', '1707', '1705', '1710']",20.1,0.1982843137254902,0.4745098039215687,0,0.1206896551724138,0.021551724137931036,0.3778801843317972
1375,1405,1405,Neighbourhood systems based attribute reduction in formal decision contexts," All Rights Reserved.Attribute reduction of formal decision context mainly uses the relationship between two concept lattices generated by the condition and decision attributes to remove redundant condition attributes. By using decision attributes to observe the covering of objects, this study defines two types of consistent sets and reducts in a consistent formal decision context based on neighbourhood systems. Four types of reductions in inconsistent formal decision contexts are also studied. The methods to calculate all types of reductions are formulated by discernibility matrix. Finally, an approach to obtain the decision rules in consistent formal decision context is proposed.",60002786,Hebei Normal University,Shijiazhuang,China,"['1702', '1709', '1707', '1705', '1710']",19.8,0.11944444444444445,0.3805555555555555,0,0.12037037037037036,0.0,0.3523809523809524
1376,1406,1406,Dog breed classifier using non-linear convolutional neural network (CNN),". All rights reserved.The Convolutional Neural Networks (CNN) research in the AI model of data can be trained easily for any domain or group of set of data in this research, to build a pipeline that can be used within a web or mobile app to process real-world, user-supplied images. Given an image of a dog, the algorithm will identify an estimate of the canine’s breed. If supplied an image of a human, the code will identify the resembling dog breed. Along with exploring state-of-the-art CNN models for classification, it will make important design decisions about the user experience for this app. The goal is that by completing this research, to understand the challenges involved in piecing together a series of models designed to perform various tasks in a data processing and image processing pipeline, dog breed categorization is a very specific application of convolutional neural networks. The Stanford dogs dataset is an open-get to picture dataset of puppy breeds. There are a sum of 120 classes of dogs, with 20580 pictures altogether, divided into 8580 test pictures, and 12000 preparing pictures. The picture dataset accompanies comments that stamp out the bouncing boxes which best incorporate the dogs in the picture. There were numerous explanations behind this. In the first place, the class urges understudies to learn Sci kit learn, which is an open-utilize programming bundle that has an improved trade-off between usability and speed.",60120915,Galgotias University,Greater Noida,India,['1700'],21.363636363636363,0.18703703703703706,0.4921296296296296,1,0.1223021582733813,0.03597122302158273,0.3218390804597701
1377,1407,1407,"Integrated modular model linking metabolism, signaling transduction and gene expression regulation in human skeletal muscle"," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Exercised-induced adaption of skeletal muscle to aerobic endurance training is ensured by instant activation of signaling transduction pathways in the muscle cells with consequent alteration of both metabolic fluxes and expression for a versatile group of genes. Despite the experimentally based efforts to disentangle the complexity of the muscle adaptation process caused by multiple interactions and intersections on signaling, metabolic and gene expression levels, the quantitative and mechanistic contribution of each component of the signaling cascades on downstream genetic regulation processes has not been fully elucidated. Data-driven mathematical models provide a rigorous way to analyze and understand such intricate biological systems. Herein a novel mathematical model linking anaerobic and aerobic metabolism, Ca2+-dependent signaling pathway and downstream transcription regulation of early and late response genes in human skeletal muscle during and after acute exercise developed in BioUML platform has been presented.",60069097,"Institute for Biomedical Problems, Russian Academy of Sciences",Moscow,Russian Federation,['1700'],38.0,0.08461538461538462,0.36666666666666653,0,0.10240963855421686,0.04819277108433735,0.30434782608695654
1378,1408,1408,Methods of introducing scientific achievements over the last seven years into the physics course," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).A methodological approach is proposed in the work, which allows providing students with the achievements of physics of the last seven years and increasing the cognitive motive of learning. The goal is achieved by using an electronic preprint system updated annually. A collection of preprints of 2019 is announced. It includes topics related to the discoveries of the features of global synergetic processes. The processes of the formation of blue oceans and the sky of the Earth, the mechanisms of climate formation and other global synergetic processes that have been discovered in the last seven years are considered. A feature of the electronic form of the manual is the ability to use a significant number of color illustrations that provide a non-verbal channel of information. Many years of experience in teaching physics to bachelors and masters of information specialties have shown the high efficiency of the proposed methodology for stimulating a cognitive learning motive. The proposed work is one of the first in which the synergistic interaction of learning motives is analyzed. A scheme of synergistic interaction of the four most important motives for learning is presented: professional, social, pragmatic and cognitive. It was found that the introduction of the theme “Physics Achievements of the Last Seven Years” into the physics course helps to stimulate a cognitive motive and increase the professional motive. The electronic form of the publication ensures its dynamic nature, allows you to use it in various forms: classroom, distance and for students to work independently.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],23.72727272727273,0.12696969696969698,0.31280303030303025,0,0.10175438596491228,0.03859649122807018,0.2887323943661972
1379,1409,1409,Frequency analysis of transactions in local payment system, Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The goal of experimental economics study is frequency analysis of transactions between local community agents. Agents are students at their project training. All transactions for goods and services were in points (local financial instrument) and took place in the local educational payment system. In the interval of 2 ‒ 50 days the most significant were transactions with periodicity of 6 ‒ 7 and 12 days. Such periodicity reflects the week cycles of human activity in studies as well as in goods and services consumption.,60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],19.2,0.14375000000000002,0.3020833333333333,0,0.028846153846153848,0.07692307692307693,0.4
1380,1410,1410,Vectorization of documents and analysis of their identity using a neural network," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of this article is to design a convenient and fast system for searching of similar documents. The natural language processing is dedicated to this. The system is based on the idea of vectorization of documents. The optimal strategy for selecting doc2vec hyperparameters based on Word2vec for the best quality of searching of similar documents is described and tested in practice. Word2vec collects statistics on the joint appearance of words in expressions and solves the problem of reducing dimension. Word2vec is based on a two-layer neural network. The model produces compact vector representations of words that reflect the relations of these words in processed texts. This approach may give an accuracy of about 90%. Vectorization of documents has appeared recently, but this experience provides great potential for research and practical application in the classification and search of texts.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],16.77777777777778,0.25999999999999995,0.51,0,0.12121212121212122,0.06060606060606061,0.3475609756097561
1381,1411,1411,Application of educational environments when learning at accelerated programs," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The experience of the use of educational environments in training under accelerated programs of higher professional education is considered. The specifics of accelerated learning are analyzed. A compact laboratory workshop on network technologies is proposed, which fully covers the material of the network academy, used in learning.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],19.666666666666668,0.22000000000000006,0.37,0,0.12307692307692308,0.1076923076923077,0.3787878787878788
1382,1412,1412,The concept of using electronic information space in the process of forming digital competencies of university students," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The purpose of the article is to present the results of a study on the use of electronic information space in the process of forming digital competencies of university students conducted by its authors. The study used the concepts of «digital literacy» and «digital competencies», consistent with existing international approaches. The authors gave a definition to the concept of «electronic information space», showing its differences from the «information-educational environment». It is concluded that there is a need to change the structure of students’ activity with digital information resources, from using ready-made resources laid out by teachers and staff to organize the educational process in the electronic information and educational environment of the university, to joint formation by teachers, students and representatives of the professional community of electronic information space. The subspaces of electronic information space used by students are highlighted, namely: global; professional community; university; academic discipline; student groups; learner’s personal space. The pedagogical goals of the use of electronic information space in the formation of digital competencies of university students are determined, the choice of software products, including cloud application, for creating electronic information space is made. The authors determined the internal and external structure of digital information resources placed in the electronic information space, and also proposed forms of organization of educational work on the formation of digital competencies of university students. The authors of the article conducted an experiment confirming the reliability of the proposed approaches.",60108633,Cherepovets State University,Cherepovets,Russian Federation,['1700'],31.375,0.085,0.13,0,0.0896551724137931,0.02413793103448276,0.3194444444444444
1383,1413,1413,Deep closest point: Learning representations for point cloud registration,"Point cloud registration is a key problem for computer vision applied to robotics, medical imaging, and other applications. This problem involves finding a rigid transformation from one point cloud into another so that they align. Iterative Closest Point (ICP) and its variants provide simple and easily-implemented iterative methods for this task, but these algorithms can converge to spurious local optima. To address local optima and other difficulties in the ICP pipeline, we propose a learning-based method, titled Deep Closest Point (DCP), inspired by recent techniques in computer vision and natural language processing. Our model consists of three parts: A point cloud embedding network, an attention-based module combined with a pointer generation layer to approximate combinatorial matching, and a differentiable singular value decomposition (SVD) layer to extract the final rigid transformation. We train our model end-to-end on the ModelNet40 dataset and show in several settings that it performs better than ICP, its variants (e.g., Go-ICP, FGR), and the recently-proposed learning-based method PointNetLK. Beyond providing a state-of-the-art registration technique, we evaluate the suitability of our learned features transferred to unseen objects. We also provide preliminary analysis of our learned model to help understand whether domain-specific and/or global features facilitate rigid registration.",60022195,Massachusetts Institute of Technology,Cambridge,United States,"['1712', '1707']",24.875,-0.003333333333333336,0.3504761904761905,1,0.13043478260869565,0.06324110671936758,0.36681222707423583
1384,1414,1414,Development of client-server technology for access to the database of algorithms on the VUE.jS platform in," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In this paper, the creation of an information system is considered, the main task of which is to provide information on algorithms in a form accessible for training, namely a general description of the algorithm, examples of implementations in programming languages, links to sources with additional information, visualization of their work. In addition, there are tasks to develop such functions: comparing performance algorithms, step-by-step execution of the algorithm with reference to its visualization. The methodology for developing a client-server application is demonstrated, the architecture of the system as a whole is described, and its individual elements are described in detail: the client part is the Vue.js framework, as well as its add-ons: for rapid prototyping of the user interface (Vuetify), for managing the global state of the application (Vuex); the server part, which is a H2 relational database, as well as a server application written in the Java programming language using the Spring MVC framework, which involves the allocation of layers such as controllers responsible for redistributing requests from clients to services that have access to special repositories that, in turn, refer to the layer that implements the database interaction interface (DAO). The result was a prototype application in which the basic functions are implemented, divided into two roles: a regular user with the rights to view content, and an administrator who has the ability to both view materials, and create, edit and delete them; as well as directions for the further development of this information system, including for educational purposes..",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],65.75,0.13117559523809524,0.3801053113553113,0,0.07741935483870968,0.04516129032258064,0.33003300330033003
1385,1415,1415,Expanded models of the project portfolio selection problem with learning effect," All Rights Reserved.This research develops two new models for project portfolio selection, in which the candidate projects are composed of multiple repetitive units. To reflect some real situations, the learning effect is considered in the project portfolio selection problem for the first time. The mathematical representations of the relationship between learning experience and investment cost are provided. One numerical example under different scenarios is demonstrated and the impact of considering learning effect is then discussed.",60021227,North China Electric Power University,Beijing,China,"['1702', '1709', '1707', '1705', '1710']",19.0,0.04805194805194805,0.27683982683982683,0,0.14285714285714285,0.0,0.24691358024691357
1386,1416,1416,Software-based three-dimensional deconvolution microscopy of cytoskeletal proteins in cultured fibroblast using open-source software and open hardware," Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).As conventional fluorescence microscopy and confocal laser scanning microscopy generally produce images with blurring at the upper and lower planes along the z-axis due to non-focal plane image information, the observation of biological images requires “deconvolution.” Therefore, a microscope system's individual blur function (point spread function) is determined theoretically or by actual measurement of microbeads and processed mathematically to reduce noise and eliminate blurring as much as possible. Here the author describes the use of open-source software and open hardware design to build a deconvolution microscope at low cost, using readily available software and hardware. The advantage of this method is its cost-effectiveness and ability to construct a microscope system using commercially available optical components and open-source software. Although this system does not utilize expensive equipment, such as confocal and total internal reflection fluorescence microscopes, decent images can be obtained even without previous experience in electronics and optics.",60092288,National University Corporation Tsukuba University of Technology,Tsukuba,Japan,"['1707', '1704']",34.8,0.029107142857142863,0.4307738095238095,0,0.08292682926829269,0.05365853658536585,0.3299492385786802
1387,1417,1417,Numerical analysis of the strategies of the competitive behavior of confectionery enterprises of the Sverdlovsk region: Example of project approach to education process of master students in IT," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The article was directed to a comparative analysis of competitive strategies of behavior of large confectionery enterprises of the Sverdlovsk Region according to the financial statements for 2013-2017. The following research method was used in this article: a comparative analysis of the competitive strategies of behavior that was performed using the collected data. Based on the analysis built on the basis of revenue figures provided by the enterprises, the enterprises were classified according to their appropriate development strategies. The results of this information process can potentially improve the annual proceed of profitability of confectionery enterprises in the Sverdlovsk Region. This article described the behavior strategies of confectionary enterprises and the trends of its economic development. The article provides computational materials that also can be a remedy for economical education processes. This article is a part of students’ laboratory work that will be further used in a graduation dissertation as a part of project approach in higher education process.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],24.285714285714285,0.17857142857142858,0.4662337662337663,0,0.1092896174863388,0.06557377049180328,0.2802197802197802
1388,1418,1418,Integration of knowledge and data in active seismology, Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper presents the principles of organization of an information environment providing a holistic view of the subject area and various aspects of scientific activity in active seismology. The subject ontology “Active Seismology” is used as a conceptual basis and information model.,60025485,"Institute of Computational Mathematics and Mathematical Geophysics, Siberian Branch of the Russian Academy of Sciences",Novosibirsk,Russian Federation,['1700'],27.0,-0.014285714285714278,0.480952380952381,0,0.06779661016949153,0.13559322033898305,0.36666666666666664
1389,1419,1419,Influence of kernel clustering on an RBFN," All Rights Reserved.Classical radial basis function network (RBFN) is widely used to process the non-linear separable data sets with the introduction of activation functions. However, the setting of parameters for activation functions is random and the distribution of patterns is not taken into account. To process this issue, some scholars introduce the kernel clustering into the RBFN so that the clustering results are related to the parameters about activation functions. On the base of the original kernel clustering, this study further discusses the influence of kernel clustering on an RBFN when the setting of kernel clustering is changing. The changing involves different kernel-clustering ways [bubble sort (BS) and escape nearest outlier (ENO)], multiple kernel-clustering criteria (static and dynamic) etc. Experimental results validate that with the consideration of distribution of patterns and the changes of setting of kernel clustering, the performance of an RBFN is improved and is more feasible for corresponding data sets. Moreover, though BS always costs more time than ENO, it still brings more feasible clustering results. Furthermore, dynamic criterion always cost much more time than static one, but kernel number derived from dynamic criterion is fewer than the one from static.",60073652,Tongji University,Shanghai,China,"['1702', '1709', '1707', '1705', '1710']",24.375,0.1355263157894737,0.5131578947368421,0,0.10869565217391304,0.017391304347826087,0.3167420814479638
1390,1420,1420,Software and methodological support of remote sensing data processing," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The content of the cycle of disciplines providing training of specialists familiar with all stages of technology of obtaining and storing digital data, digital image processing and application of remote sensing data is presented. The cycle includes the following disciplines: «fundamentals of the remote sensing of the Earth», «radio electronic remote sensing systems», «remote sensing data processing software», «satellite technologies in geophysics», «digital terrain models». The methodological support of the cycle is developed, which allows using effectively the Space monitoring center of the Ural Federal University hardware and software in the educational process. This methodological support includes two textbooks published by the authors, guidelines for the use of remote sensing data processing software in educational and research work, four modular cycles of laboratory works on the basis of the Space monitoring center hardware and software, guidelines for the organization of project training. Three online courses on remote sensing data processing with the prospect of their posting on the open education platform have been developed. The examples performed by the students’ lab works are «cataloging of ground truth information and satellite imagery for monitoring of natural objects», «forest fires detection using the remote sensing data», «building of digital elevation models using a satellite radar interferometry».",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],36.0,0.06704545454545452,0.2636363636363636,0,0.07936507936507936,0.05555555555555555,0.41106719367588934
1391,1421,1421,Use of information and communication technologies for teaching mathematics," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The paper discusses the ways to improve methods and algorithms of the automated control of knowledge, approaches to the establishment and effective functioning of electronic teaching complexes, which include tests of a new generation, and their use is not limited control purpose only. Possibilities of computer-based Internet-testing system SCIENTIA are presented. This system is a tool to automate the control of knowledge that can be used for the assessment and monitoring of students’ knowledge in different types of exams, self-control of students’ knowledge, making test materials, creating a unified database of tests on a wide range of subjects etc. Successful operation of informational system is confirmed in practice during the study of the course of mathematics in the Technical University.",60030998,Plekhanov Russian University of Economics,Moscow,Russian Federation,['1700'],33.0,0.21109799291617476,0.5861275088547816,0,0.10596026490066225,0.052980132450331126,0.3767123287671233
1392,1422,1422,Suppression in interpreting adjective noun combinations and the nature of the lexicon," Published by Oxford University Press. All rights reserved.A common assumption about our internal lexicon is that the meaning of words is underspecified and this underspecified representation is filled in based on the context in which the word occurs. In this paper I would like to explore a different hypothesis, that words are stored with overspecified representations which are 'trimmed down' by the context. This view seems to be in line with a well-known mechanism from psycholinguistics: suppression. Many studies have shown that conceptual properties of a word are initially activated but subsequently suppressed when these properties are in conflict with the context the word occurs in. This mechanism has not been tested, however, in a context where compositional application takes place as between an adjective and a noun. In this study I will discuss two lexical decision experiments testing the interpretation of two types of adjective noun combinations. For both types of combinations it is expected that the representation of the noun undergoes a change due to the conflicting information provided by the adjective. It is hypothesized that the properties of the noun that are in conflict with the adjective are initially activated, but subsequently suppressed to form a coherent representation of the adjective noun combination. While the results provide evidence for the initial activation of the conceptual properties, no evidence for the subsequent suppression was found. The initial activation shows that also in the case of adjective noun combinations, conceptual features do not 'wait for' an initial well-formed semantic structure. The lack of evidence for suppression primarily suggests the need for further research. If future experiments confirm that suppression does not take place within the time frame tested in the experiments, we must conclude, based on experimental findings by Schumacher (2013), that conceptual specification takes place after the shift in reference of the noun.",60016529,Radboud University Nijmegen,Nijmegen,Netherlands,['1702'],23.538461538461537,0.058068783068783075,0.2828042328042328,0,0.12316715542521994,0.011730205278592375,0.2469879518072289
1393,1423,1423,Training methods of geospatial remote sensing data processing," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Techniques of active learning in thematic processing methods of multispectral and radar remote sensing of the Earth data for undergraduate and graduate students for the «applied informatics», «radio engineering», «information security» master programs on the basis of software and hardware of the Space monitoring center of the Ural Federal University are considered. It is shown, that exploratory laboratory works and individual or group projects are quite suitable forms for the active training for the methods of remote sensing data processing. Themes of exploratory laboratory works and projects themes are revealed.",60103702,Ural Federal University,Yekaterinburg,Russian Federation,['1700'],34.0,0.04833333333333335,0.3850000000000001,0,0.043478260869565216,0.12173913043478261,0.3879310344827586
1394,1424,1424,An efficient feature selection based heart disease prediction model,"Heart disease is one of the health concerns of humans. It has caused thousands sad demises of people early in their life. There are different kinds of heart diseases and each one has its symptoms and they are preventable or even curable if detected early. Therefore, early detection of heart disease is wiser way of diagnosing it. Fortunately, health data of a person is sufficient to detect the probability of heart disease accurately. This has motivated many researchers and academia investigating into data-driven approaches towards solution. Machine learning techniques that are part of Artificial Intelligence (AI) play key role in the prediction of heart diseases. The existing research on it revealed their utility in garnering Business Intelligence (BI) for making expert decisions. However, in terms of feature selection and improving performance of detection mechanisms there is need for further scope of the research. In this paper a novel feature selection algorithm named Entropy and Gain-based Feature Selection (EGFS) is proposed. The hypothesis “feature selection improves performance of heart disease prediction models” is evaluated using EGFS by applying it with state of the art machine learning methods like k-Nearest Neighbour (k-NN), Naïve Bayes (NB), Decision Tree (DT), Random Forest (RF) and Support Vector Machines (SVM). These methods are used to form heart disease prediction models. The empirical study revealed that the performance of the prediction models is improved with EGFS. The effectiveness of prediction models is enhanced with feature selection process.",60075905,Andhra University College of Engineering,Visakhapatnam,India,['1700'],17.142857142857142,0.007692307692307701,0.5717948717948717,1,0.08391608391608392,0.1048951048951049,0.4136690647482014
1395,1425,1425,Fifth generation internet network in of higher education. Issues of medical and information security of students' personality," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).People have talked about the 5G mobile Internet networks for a long time, and their moment has finally come. Since July 2019 of this year there is already one state completely covered by 5G. This is Monaco [1]. The time of transition to 5G mobile networks is close. However, along with the technological advantages of these networks, there are a number of negative, or rather side effects on humans. They should be known, because some of them are emergent properties of networks of this type (microwave, electric, magnetic fields etc.), and should be regulated by applicable law. Most of the side effects are likely to be caused by the lack of awareness of the trainees and, accordingly, is quite surmountable under condition of formation of a certain information culture in terms of information, technological and medical safety. In the framework of this work, we will consider precisely these aspects of the information security of a person in terms educational organization of higher education and the educational space of a student. For children and teenagers, the Internet and gadgets are now the basis of socialization and life. With all the positive examples of the active use of digital media and digital educational resources (DER) in teaching practice, there is no hygienic regulation in terms of the use of the media (gadgets), and in terms of the safety of DER. Below we will try to present the observations of a number of researchers regarding the influence of the fifth-generation networks on the trainees.",60070989,Russian Academy of Education,Moscow,Russian Federation,['1700'],23.90909090909091,0.1229112554112554,0.4233441558441558,0,0.04966887417218543,0.03642384105960265,0.31666666666666665
1396,1426,1426,Rough set-based rule generation and Apriori-based rule generation from table data sets II: SQL-based environment for rule generation and decision support," All Rights Reserved.This study follows the previous study entitled ‘Rough set-based rule generation and Apriori-based rule generation from table data sets: A survey and a combination’, and this is the second study on ‘Rough set-based rule generation and Apriori-based rule generation from table data sets’. The theoretical aspects are described in the previous study, and here the aspects of application, an SQL-based environment for rule generation and decision support, are described. At first, the implementation of rule generator defined in the previous study is explained, then the application of the obtained rules to decision support is considered. Especially, the following two issues are focused on, (i) Rule generator from table data sets with uncertainty in SQL, (ii) The manipulation in decision support below: (ii-a) In the case that an obtained rule matches the condition, (ii-b) In the case that any obtained rule does not match the condition. The authors connect such cases with decision support and realised an effective decision support environment in SQL.",60031838,Kyushu Institute of Technology,Kitakyushu,Japan,"['1702', '1709', '1707', '1705', '1710']",33.0,-0.04615384615384615,0.3948717948717949,0,0.10952380952380952,0.023809523809523808,0.35751295336787564
1397,1427,1427,Photo Crowdsourcing Based Privacy-Protected Healthcare,"In this paper, the concept of crowdsourcing is applied to the medical field and a health monitoring mechanism based on photo crowdsourcing is proposed. Specifically, with photo crowdsourcing by many participators, the routine circumstances of users may be represented. However, these photos may include other people than the user, such as the visibility requestor, the invisibility requestor, and the passerby. The visibility and invisibility requestor are the participators in the system, whose identity can be set as visible or invisible, while the passerbys do not participate in the system. Hence, a privacy protection mechanism is proposed for this system, which includes two categories: i) The image fuzzy processing is provided for the invisibility requestor, while the original image is reserved for the visibility requestor. ii) The passerby's image is directly fuzzy processed for privacy protection.",60025761,Huazhong University of Science and Technology,Wuhan,China,"['1703', '1708', '1712']",22.5,0.14166666666666666,0.4208333333333333,1,0.10828025477707007,0.0,0.3248407643312102
1398,1428,1428,A Differential Privacy-Based Query Model for Sustainable Fog Data Centers,"With the increasing computation and storage capabilities of mobile devices, the concept of fog computing was proposed to tackle the high communication delay inherent in cloud computing, and also improve the security to some extent. This paper concerns with the privacy issue inherent in the sustainable fog computing platform. However, there is no universal solution to the privacy problem in fog computing due to the device heterogeneity. In this paper, we proposed a differential privacy-based query model for sustainable fog computing supported data center. We designed a method that can quantify the quality of privacy preserving through rigorous mathematical proof. The proposed method uses the query model to capture the structure information of the sustainable fog computing supported data center, and the datasets for the query result are mapped to real vectors. Then, we implemented the differential privacy preserving by injecting Laplacian noise. The experiment results demonstrated that the proposed method can effectively resist various popular privacy attacks, and achieve relatively high data utility under the premise of better privacy preserving.",60009400,Nanjing University of Post and TeleCommunications,Nanjing,China,"['1703', '1708', '1712']",21.375,0.15791666666666665,0.3879166666666666,1,0.13297872340425532,0.005319148936170213,0.26344086021505375
1399,1429,1429,Some simulation results on performance analysis of voip services in WIMAX systems,"WiMAX is a wireless networking technology that provides quick access to mobile data and provides communications services. This technology allows server-based coding applications, Voice over Internet Protocol (VOIP) allows. Challenges that threaten the system, reducing the resources that will be send to voice packet loss. In this paper an analytical queuing model with consideration of Markov MMPP traffic model is studied and simulated. We present various performance metrics, such as the average uplink throughput of Wimax, average packet delay and average length of the uplink queue and average numbers of arrived packets.",60104371,"Islamic Azad University, Rasht Branch",Rasht,Iran,['1706'],18.4,-0.03333333333333333,0.3875,1,0.12380952380952381,0.0761904761904762,0.39805825242718446
1400,1430,1430,Decentralization of health in the era of extensive autonomy in north konawe district,"The policies of the North Konawe District Government in the health sector consist of, First, after the enactment of regional autonomy, the North Konawe District government has exercised the authority to regulate it either by issuing laws and regulations in the form of regional regulations or by making health service programs whose arrangements are carried out in regional planning documents. Second, the implementation of regulatory authority in North Konawe Regency when viewed from the legal products produced is still very limited, both in terms of quantity and substance, although it has been given the authority to regulate, but the dependency of the North Konawe District regional government in health sector regulation to the guidelines given by the central government still very high. Third, the policies adopted by the North Konawe District Government in the health sector are the standby village program policies and the one nurse and one midwife program policies in one village.",60069405,Universitas Sriwijaya,Indralaya,Indonesia,['1700'],51.33333333333334,0.08073469387755103,0.2387210884353741,1,0.07272727272727272,0.10909090909090909,0.30303030303030304
1401,1431,1431,"Antibacterial activity of methanol extract of Gracilaria Salicornia, Halimeda Gracilis, Halimeda Macroloba, and Hypnea Asperi from Indonesia","The research aimed to find out the ability of methanol extract of G. salicornia, H. gracilis, H. macroloba, and H. asperi from Indonesia as antibacterial in inhibiting E. coli (ATCC 8739), S. aureus (ATCC 6539), and P. aeruginosa (ATCC 9027). The research design is quasi experimental by using statistic group comparison. The test method for antibacterial activity is well diffusion which refers to CLSI document M02-A11. The antibacterial activity test showed the highest inhibitory zone to E. coli, only in methanol extract of G. salicornia 20%, the highest inhibitory zone to S. aureus is in methanol extract of H. asperi 20%, and the highest inhibitory zone to P. aeruginosa is in methanol extract of H. gracilis 20%. The differences in the effect of macro algae methanol extract which tested at the same concentration on S. aureus showed that significant effect on methanol extract of H. asperi and G. salicornia at concentration 20% (p ≤ 0, 05) and to P. aeruginosa did not showed significant difference of influence, and comparison of methanol macro algae extract effect at same concentration between S. aureus and P. aeruginosa did not show significant effect difference (p> 0,05).",60104064,Universitas Nasional,Jakarta,Indonesia,['1700'],8.0,0.17500000000000002,0.6107142857142858,1,0.04504504504504504,0.1981981981981982,0.4144144144144144
1402,1433,1433,Solution to SPDDE using exponentially fitted spline method,"Within this paper, We have answered of SPDDE along with delay. Also, advanced parameters utilizing an exponentially fitted spline approach. At first, the given second order differential-difference equation is replaced by an asymptotically proportionate second order singular perturbation problem. At that point, a fitting factor is brought into the exponentially fitted spline Method. The value of fitting factor is obtained by the singular perturbations theory. The Thomas algorithm is used to solve the tridiagonal system obtained by the method. We have charted maximum absolute errors for the instances selected from the literature. Numerical results, along with comparison, along with the various other strategies, are revealed to expatiate the effectiveness of the technique for arbitrary λ1, λ2 such that λ1 +λ2 =1/2.",60114415,Kamala Institute of Technology &amp; Science,Karimnagar,India,['1700'],15.125,0.1477272727272727,0.4371212121212121,1,0.11347517730496454,0.03546099290780142,0.32116788321167883
1403,1434,1434,Employing multi-level authentication protocol for securing intelligent systems,"Most authentication schemes are using passwords only to restrict access to services. Which are suffering from many weaknesses, such as key-logger attack and dictionary attack. Also, other authentication schemes are using physical token such as smart cards. These schemes are also impractical due to their infrastructure requirements. Since, many researchers have proposed a various of authentication schemes which rely on a single level security. So it is important to use multi-level security which is implemented especially in sensitive applications. This paper proposes an efficient multi-level user authentication protocol called ”ElDahshan Authentication protocol” based on different authentication methods for each level. Where each level contains different authentication methods with its own privileges.These security levels are managed by an identity Manager. To validate the proposed protocol we applied it for user authentication on two web services such as Content Management System and Online Voting System.",60012577,"National Center of Radiation Research and Technology, Cairo",Cairo,Egypt,['1706'],15.888888888888891,0.14404761904761906,0.5805555555555555,1,0.09696969696969697,0.048484848484848485,0.3821656050955414
1404,1435,1435,Automated usability evaluation of government and private sector educational websites of Pakistan,"Web usability is an important field of Human computer interaction (HCI). Now-a-days customer satisfaction and performance related to websites usability are important factor in web development. Web usability is important for customers, who mostly depend on websites and get information easily, Such as online advertisement, Admission on different categories, tender, educational activities and courses etc. According, educational websites further need to describe the different types of usability issues in websites. Website usability needs greater interest of research and improvement in content field. Some general and technical issues identified by educational websites of Pakistan by using SEO (Search Engine Optimization) tool. For usability testing total number of 15 universities are selected for the study. These websites include 10 public sector universities and 5 private sector universities. A comprehensive analysis of the data presents the usability of educational websites. Three usability attribute are considered for usability testing i.e high, medium and low. These attribute are tested by applying on different universities websites.",60064058,Quaid-i-Azam University,Islamabad,Pakistan,['1706'],14.545454545454545,0.1482608695652174,0.4752898550724637,1,0.07526881720430108,0.03225806451612903,0.3791208791208791
1405,1436,1436,Self-adaptive dna-based steganography using neural networks,"Steganography is the science of concealing the secret information within a digital cover-object such as the files text, image, video and etc. Recently, the deoxyribonucleic acid (DNA) sequences are used as a cover-object for data hiding. In this work, an effective algorithm called the self-adaptive DNABS (DNA-based steganography) is proposed. This algorithm is applied for data hiding without changing the function or the type of the original DNA protein. It is implemented using a DNA-based steganography and a Neural Network (backpropagation) algorithm to achieve a lower cracking probability than other techniques. The performance of the algorithm is analyzed and tested by measuring four parameters: the embedding capacity, data payload, cracking probability and the bits per nucleotide (bpn).",60000617,Assiut University,Assiut,Egypt,['1706'],19.5,0.06428571428571428,0.4821428571428572,1,0.12162162162162163,0.02027027027027027,0.4057971014492754
1406,1437,1437,Knowledge attitude and perception of birth control information and services among women of child bearing age in Samaru,"This study explored the access and use of birth control information, with direct focus on women of child bearing age in Samaru. The study is guided by three objectives: to identify if information on birth control is available to women of child bearing age in Samaru, to identify the sources of information on birth control to women of child bearing age in Samaru and to examine the factors affecting the utilization of birth control information among women of child bearing age in Samaru. For this work, quite a number of related literatures were reviewed to get other authors perspective on the topic. The research adopted a quantitative survey technique by employing the use of a structured questionnaire. The population of study consists of married women of reproductive age in Hayin-Dogo Primary Health Care Center Samaru; a convenient sampling technique was employed in selecting 131 women of child bearing age for the study. The questionnaire was used for collecting data, and data collected were analyzed using frequency table and simple percentages. The study revealed that about 109(92.4%) of the women indicated that information on birth control is available while about 9(7.6%) responded not to be aware of such information. The most common sources of birth control information were found to be clinics, radio, religious institutions, family and the community. 87(25.51%) heard birth control information from the clinic, making it the highest source of birth control information, 47(13.78%) heard the information from radio and 40(11.73%) and 40(11.73%) got the information from religious institutions and their families respectively including the community 34(9.97%). The actual practice of birth control methods was found to be about 89(75%) at the time of the survey which is still below the desired threshold. For type of birth control method subscribed to, dual protection with 36(23.65%), Widrawal with 20(13.25%) and fertility awareness with 18(11.92%) are the birth control methods with the highest prevalence rate. Also, For the factors militating against the effective utilization of birth control information, from the study it was revealed that 32(14.95%) is attributed to lack of male spouse involvement as the major factor, 29(13.55%) indicated religious beliefs as a factor and 27(12.62%) indicated fear of infertility later in life as a factor, while 26(12.15%) is attributed to fear of side effects. Based on the current revelations and findings in this study, the study recommends: re-educating current users and educating potential users about the benefits of birth control measures cannot be overemphasized. This can be achieved by employing a very robust and holistic communication strategy that emphasizes the health benefit of birth control, the types of methods available, the relative effectiveness and side effects of the various methods and improving client counseling, including accurate information about specific birth control methods. These are some of the effective strategies that can dispel myths and misconceptions about side effects, and fertility related issues.",60109513,Bingham University,Karu,Nigeria,['1706'],31.6,0.12234848484848485,0.3709235209235209,1,0.09689213893967093,0.021937842778793418,0.3403141361256545
1407,1438,1438,Physiological interference reduction for near infrared spectroscopy brain activity measurement based on recursive least squares adaptive filtering and least squares support vector machines," Published by Informa UK Limited, trading as Taylor & Francis Group.Near infrared spectroscopy is the promising and noninvasive technique that can be used to detect the brain functional activation by monitoring the concentration alternations in the haemodynamic concentration. The acquired NIRS signals are commonly contaminated by physiological interference caused by breathing and cardiac contraction. Though the adaptive filtering method with least mean squares algorithm or recursive least squares algorithm based on multidistance probe configuration could improve the quality of evoked brain activity response, both methods can only remove the physiological interference occurred in superficial layers of the head tissue. To overcome the shortcoming, we combined the recursive least squares adaptive filtering method with the least squares support vector machine to suppress physiological interference both in the superficial layers and deeper layers of the head tissue. The quantified results based on performance measures suggest that the estimation performances of the proposed method for the evoked haemodynamic changes are better than the traditional recursive least squares method.",60019616,Harbin Institute of Technology,Harbin,China,['1706'],33.2,-0.1179945054945055,0.4677197802197802,0,0.13068181818181818,0.03977272727272727,0.26011560693641617
1408,1439,1439,Model predictive control for energy optimization problems,"Since the fuel cost of electric power generation from thermal plants is very high, several researchers have devoted their efforts to offer new strategies to minimize such cost. But reducing the fuel cost will increase the emission of gaseous pollutants such as CO2, CO, NOx and SO2. Therefore, the dynamic economic emission dispatch problem (DEED) is formulated with the objective of simultaneously minimizing the fuel cost and emission so as to meet the predicted demand over a certain period under ramp rate limits and other operational and system constraints. Spinning reserve plays a crucial role in maintaining the power system reliability and security against sudden load changes and generation outages. To consider the spinning reserve into the DEED, we formulate dynamic economic emission and spinning reserve dispatch (DEESRD) problem which integrates the spinning reserve into the DEED problem. DEESRD determines the optimal power and spinning reserve schedule by simultaneously minimizing the power and spinning reserve costs, and the amount of emission under some constraints. The optimal solutions of the DEESRD problem are open loop. The open-loop nature cannot deals with inaccuracies, modeling uncertainties and unexpected external disturbances where the power system components suffer from. To overcome this problem we designed closed-loop solutions using a suitable version of MPC approach. The performance of the MPC has been investigated by applying the MPC strategy to the DEESRD problem with test system consisting of five generating units and five customers.",60110530,University of Bisha,Bisha,Saudi Arabia,['1706'],23.7,0.08242496392496393,0.4325726310726311,1,0.11026615969581749,0.049429657794676805,0.29343629343629346
1409,1440,1440,Image quality aware secured image sharing method with guaranteed digital rights management,". All rights reserved.Digital rights management is the process providing the ownership or authority to the users for their own images. Thus the other persons cannot use those contents without assessing permission from the users. It is concentrated and sorted out in our previous research work by proposing the system namely secured and Attribute based User access control (SA-UAC) methodology. Nevertheless this research methodology doesn’t emphasis on the quality of the images which might get affected while researcher attempts to ensure the security of the image sharing. This is paid attention and worked out in this research work by means of introducing the new technique that can guarantee the image quality concerned secured image sharing. In this research work, Image Quality aware Secured Image Sharing Method (IQ-SISM) is introduced for the optimal images with controlled image access and guaranteed image quality. In this work security is enhanced by adapting the separable reversible data hiding techniques which requires having both keys for the encryption and decryption techniques. After data hiding image encryption is done by introducing revocation attribute based encryption. The complete assessment of the research work is conducted in the matlab simulation environment and the achieved results demonstrate that the proposed research approach manages to make certain the secured image transmission.",60113913,"P. A. College of Engineering and Technology, Pollachi",Pollachi,India,['1700'],21.1,0.1441403834260977,0.4596629560915275,1,0.15879828326180256,0.055793991416309016,0.32456140350877194
1410,1441,1441,Prospective on human resources management in startups,"Human resources management (HRM) is interested in studying factors and best practices to manage the workforce to reach maximum efficiency. However, HRM models for large organizations are not applicable to startups. The startup workforce lives in a different environment and constraints that should be dealt with differently. In addition, the inherent uncertainty in the startup nature places implications and changes in the workforce, which need different HRM approaches. Most of the previous HRM researches have been focusing on studying large firms despite the impact on startups on economies and job creation. In this paper, a literature review is given on startups and their differences for big corporates, in addition to the current startup HRM models. As entrepreneurial activity is not limited to startups, HRM model for corporate entrepreneurship is discussed. Despite the rise of interest in startup HRM, a more rigorous and comprehensive startup HRM model is missing.",60110815,Applied Science University,Al Eker,Bahrain,['1706'],18.5,0.14672619047619045,0.3385416666666667,1,0.08484848484848485,0.048484848484848485,0.3878787878787879
1411,1442,1442,Comparative study of online learning management systems: A survey in pakistan,"Teacher and students are main stockholder in educational institutes. However E-management of class activities are one of important and very simple method to communicate with students. Online course management tools are widely adapted in educational institutes for teacher and student effective communication. Online learning Management Systems (LMS) is one of efficient tool for class activities management. This study surveys effective tool and measure their performance parameters according to memory, integrity, user experience and other features. It is found from comprehensive survey that Moodle is popular and adopted by many institutes. Google classroom is second effective tool and also popular due to freely available features with G-suite. Blackboard is good enough in security perspective because of its good and effective security management system and well content provider system. On the basis of this survey, the more than 80% participants were not aware from online LMS tools. However rest of 20% who were familiar only from one or two popular LMS tools and they were concerned people of IT field including students and as well as teachers.",60035791,University of Sindh,Jamshoro,Pakistan,['1706'],17.5,0.31866666666666665,0.5679047619047621,1,0.04591836734693878,0.030612244897959183,0.3020833333333333
1412,1443,1443,Green Spectrum Assignment in Secure Cloud Radio Network with Cluster Formation,"As the occurrence of cloud computing, the exponential growth of various application services results in the urgent demand for green computing and resource sustainability on the premise of guaranteeing service performance. Especially, Cloud Radio Access Network (CRAN) has been recognized as a promising approach to provide smart computing and sustainable resource usage for fulfilling the increasing traffic demand. Moreover, the secure network environment is also a vital element for achieving reliable application services. In this paper, we propose a cluster-based secure Cloud Radio Access Network (CSC-RAN), which optimizes the trade-off between performance and resource utilization to satisfy the requirements of the sustainable green network. Based on the powerful ability of cloud computing, the abundant network resource can be dynamically allocated according to the varying traffic. A traffic-aware RRHs cluster formation (TRCF) algorithm is proposed for realizing efficient resource utilization while improving the Quality of Service(QoS). Furthermore, a spectrum allocation genetic algorithm (SAGA) is introduced to solve the optimal spectrum allocation problem for the formatted cluster, which is proved to be a mixed-integer programming problem. Finally, the effectiveness of the TRCF and SAGA algorithms are verified through a series of numerical simulations.",60024979,Zhongnan University of EcoNomics and Law,Wuhan,China,"['1703', '1708', '1712']",23.875,0.1511904761904762,0.6494047619047619,1,0.09691629955947137,0.07048458149779736,0.3607305936073059
1413,1444,1444,Distributed Data Center Bandwidth Allocation for Cloud-Based Streaming,"Cloud-based video streaming systems such as YouTube and Netflix are usually supported by the content delivery networks and data centers that can consume many megawatts of power. Most existing work independently studies the issues of improving quality of experience (QoE) for viewers and reducing the cost and emissions associated with the enormous energy usage of data centers. By contrast, this paper addresses them both, and jointly optimizes the QoE, the energy cost and emissions by intelligently allocating data center bandwidth among different client groups. Specially, we propose a distributed algorithm to achieve the optimal bandwidth allocation, given the prediction of future workload. The algorithm novelly decomposes the optimization process into separate ones, which are solved iteratively across data centers and clients. Further, the algorithm has robust performance guarantee in terms of the variance of the prediction error. We demonstrate its convergence and robustness by both proofs using theoretical analysis and validation based on trace-driven simulations. The results further show that the proposed algorithm converges very fast and achieves much better QoE-cost balance than existing approaches.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1703', '1708', '1712']",21.875,0.16044642857142855,0.4657142857142857,1,0.12121212121212122,0.025252525252525252,0.3333333333333333
1414,1445,1445,The caputo-fabrizio fractional integral to generate some new inequalities,"In this paper, we use the Caputo-Fabrizio (CF) fractional integral to establish some new integral inequalities in the case of functions with the same sense of variation.",60046703,Universidad de La Habana,Havana,Cuba,['1706'],27.0,0.06818181818181818,0.2897727272727273,1,0.06060606060606061,0.09090909090909091,0.2903225806451613
1415,1446,1446,STC: Exposing Hidden Compromised Devices in Networked Sustainable Green Smart Computing Platforms by Partial Observation,"Large-scale smart computing is generally more vulnerable to cyber attacks since their system devices are normally distributed as networked platforms and each device could be a target and get compromised. Due to resource constraints (i.e., Sustainable Computing demand) and cost-efficiency issues (i.e., Green Computing demand), we usually monitor only a few devices (i.e., partial observation) to ensure all operations across different platforms are under a secure environment. This leads to a critical problem for detecting compromised devices that are out of surveillance. To the best of our knowledge, this problem has not been solved so far. In this paper, we propose an unsupervised classifier based on source-tracing technique (STC in short) to expose hidden compromised devices with partial observation on the networked sustainable green smart computing platforms. STC mainly focuses on the cyber threats that can spread in the platform and compromise various system devices. To expose hidden compromised devices that are out-of-surveillance, STC first captures the spreading source by the reverse dissemination technique, and then relies on microscopic propagation modelling to probabilistically identify the most probable compromised devices. We carried out a series of experiments to validate the performance of our proposed method. The evaluations are based on three real networked platforms: Air Traffic Control system, AS-level Internet platform, and US Power Grid. The experiment results demonstrated that STC can accurately expose the hidden compromised devices in terms of following aspects: 1) Source-tracing (more than 80 percent runs got exact real source and 95 percent within two hops of real source); 2) Modelling (very close to the simulation results); 3) Exposing accuracy (almost all $>$> 90 percent); and 4) Comparison to baseline (superiority to three supervised and two unsupervised classifiers).",60025578,Xidian University,Xi'an,China,"['1703', '1708', '1712']",28.1,0.09618347338935576,0.4356092436974791,1,0.119533527696793,0.04081632653061224,0.42857142857142855
1416,1447,1447,Reduced-Complexity Deep Neural Networks Design Using Multi-Level Compression,"Deep Neural Network has achieved great success in many fields. However, many DNN models are both deep and large thereby causing high storage and energy consumption during the training and inference phases. This paper proposes multi-level compression framework. By utilizing cross-layer parameter-reducing techniques ranging from structure compression to weight compression to representation compression, the proposed compression strategy can enable order-of-magnitude reduction in network size for both training and inference with negligible accuracy loss, thereby leading to very high-efficiency and high-accuracy DNN models. Experiments show that the proposed strategy can achieve around 1.8K compression ratio in terms of dense matrices and around 30x for the overall model.",60030551,Syracuse University,Syracuse,United States,"['1703', '1708', '1712']",21.2,0.26742857142857146,0.3818571428571428,1,0.10852713178294573,0.03875968992248062,0.3157894736842105
1417,1448,1448,Developing an expert system for assessment of information-psychological influence," All rights reserved.Nowadays solving practical problems in various sectors using intelligent solutions, based on expert systems are becoming more and more widespread. In this paper an expert system method is proposed for assessment and prediction of destructive influences. All disadvantages of existing assessment systems are taken into account during the development and analysis phases. The most important estimated parameters are determined. This method is based on quantitative methods of expert evaluation, which gives the advantage: There is no need to collect large amounts of statistical data and clear formalization of the current situation.",60062395,Al-Balqa Applied University,Al Salt,Jordan,"['1711', '1710', '1708', '1705']",18.8,0.2603896103896104,0.5965367965367965,0,0.125,0.0,0.3069306930693069
1418,1449,1449,Energy efficient backhauling for 5g small cell networks,"While the concept of ultra-dense small cell networks (SCNs) has brought a number of significant opportunities for the telecommunication industry, it has also introduced a major challenge for researchers, who must develop techniques to reduce the sharp increase in power consumption that will be required to backhaul traffic from SCNs to the core network. In this research, we investigate the green backhauling challenge for a fifth generation (5G) wireless communication network that uses both the passive optical network (PON) and millimeter wave (mmWave) backhauling to support its diverse groups of customers and applications. Our approach is based on the fact that the energy efficiency figures for the PON and themmWave technologies are different under a given load condition. The PON technology is more energy efficient under heavy load conditions, whereas the mmWave technology offers better energy efficiency under low load conditions. As such, in response to varying traffic loads during various hours of the day, a fixed backhauling strategy is insufficient to guarantee the minimumpower consumption and the required data rates. We formulate an optimization problemthat considers the estimated hourly traffic load and determines the most energy efficient backhauling strategy for various hours of the day. Considering the complexity of the optimization problem, we also propose an energy efficient heuristic solution to solve this problem. Simulation results indicate that the proposed solution provides up to 32 percent more energy savings than the existing solution.",60105210,"Edith Cowan University, Joondalup",Perth,Australia,"['1703', '1708', '1712']",29.25,0.10955882352941176,0.4661764705882353,1,0.11538461538461539,0.015384615384615385,0.3035019455252918
1419,1450,1450,Software reusability metrics estimation from the social media by using evolutionary algorithms: Refactoring prospective," Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.Software expansion is rising with the help of the standard paradigm in the 21st century. The maximum contribution of software growth focuses mainly on object-oriented development methodologies. This paradigm helps the developer to develop code quickly and makes sure that the platform assists in producing a quality product. The software reusability metrics play a crucial role for software development. To overcome the scalability issues, researchers and developers both adopt a CK metrics suite to extract the software metrics to extract the features from the repositories. The main objective of this article is to extract the set of metrics from social media by using novel evolutionary techniques. Dissimilar features within this area are examined with a suitable research query that discovers the potential and extent.",60097686,"Gandhi Institute of Engineering and Technology, Gunupur",Gunupur,India,['1712'],20.0,0.14583333333333334,0.4143518518518519,0,0.125,0.019736842105263157,0.2857142857142857
1420,1451,1451,Application of intelligent multi agent based systems for E-healthcare security,"In recent years, availability and usage of extensive systems for Electronic Healthcare Record (EHR) is increased. In medical centers such hospitals and other laboratories, more health data sets were formed during the treatment process. In order to enhance the standard of the services provided in healthcare, these records where shared and can be used by various users depends on their requirements. As a result, notable issues in the security and privacy where obtained which should be monitored and removed in order to make the use of EHR more effectively. Various researches have been done in the past literature for improving the standards of the security and privacy in E-health systems. In spite of this, it is not completely enhanced. In this paper, a comprehensive analysis is done by selecting the existing approaches and models which were proposed for the security and privacy of the E-healthcare systems. Also, a novel Intelligent-based Access Control Security Model (IBAC) based on multi agents is proposed to maintain and support the security and privacy of E-healthcare systems. This system uses agents in order to maintain security and privacy while accessing the E-health data between the users.",60110524,Shaqra University,Shaqra,Saudi Arabia,['1706'],21.222222222222218,0.08269230769230769,0.3544871794871795,1,0.12669683257918551,0.049773755656108594,0.36492890995260663
1421,1452,1452,Greening Cloud-Enabled Big Data Storage Forensics: Syncany as a Case Study,"The pervasive nature of cloud-enabled big data storage solutions introduces new challenges in the identification, collection, analysis, preservation, and archiving of digital evidences. Investigation of such complex platforms to locate and recover traces of criminal activities is a time-consuming process. Hence, cyber forensics researchers are moving towards streamlining the investigation process by locating and documenting residual artefacts (evidences) of forensic value of users' activities on cloud-enabled big data platforms in order to reduce the investigation time and resources involved in a real-world investigation. In this paper, we seek to determine the data remnants of forensic value from Syncany private cloud storage service, a popular storage engine for big data platforms. We demonstrate the types and the locations of the artifacts that can be forensically recovered. Findings from this research contribute to an in-depth understanding of cloud-enabled big data storage forensics, which can result in reduced time and resources spent in real-world investigations involving Syncany-based cloud platforms.",60008250,University of Salford,Salford,United Kingdom,"['1703', '1708', '1712']",26.0,-0.005303030303030312,0.30662878787878795,1,0.13756613756613756,0.010582010582010581,0.3583815028901734
1422,1453,1453,Super resolution reconstruction for medical image based on adaptive multi-dictionary learning and structural self-similarity," Published by Informa UK Limited, trading as Taylor & Francis Group.To improve the quality of the super-resolution (SR) reconstructed medical images, an improved adaptive multi-dictionary learning method is proposed, which uses the combined information of medical image itself and the natural images database. In training dictionary section, it uses the upper layer images of pyramid which are generated by the self-similarity of low resolution images. In reconstruction section, the top layer image of pyramid is taken as the initial reconstruction image, and medical image’s SR reconstruction is achieved by regularization term which is the non-local structure self-similarity of the image. This method can make full use of the same scale and different scale similar information of medical images. Simulation experiments are carried out on natural images and medical images, and the experimental results show the proposed method is effective for improving the effect of medical image SR reconstruction.",60025569,Tianjin Polytechnic University,Tianjin,China,['1706'],29.8,0.08834586466165413,0.2430451127819549,0,0.09090909090909091,0.05113636363636364,0.3048780487804878
1423,1454,1454,Reasoning about opinion dynamics in social networks," Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.This article introduces a logic to reason about a well-known model of opinion dynamics in social networks initially developed by Morris DeGroot as well as Keith Lehrer and Carl Wagner. The proposed logic is an extension of Łukasiewicz' fuzzy logic with additional equational expressivity, modal operators, machinery from hybrid logic and dynamic modalities. The model of opinion dynamics in social networks is simple enough to be easily grasped, but still complex enough to have interesting mathematical properties and applications. Thus, developing a logic to reason about this particular model serves as a paradigmatic example of how logic can be useful in social network analysis.",60029170,Lunds Universitet,Lund,Sweden,"['1712', '1708']",19.5,0.09285714285714286,0.2921768707482993,0,0.08955223880597014,0.08955223880597014,0.31297709923664124
1424,1455,1455,Improvement of the parallel importation logistics process using big data,"South Korea has allowed parallel importation since 1995. Parallel importation causes competition among importers in the logistics process allowing, consumers to purchase foreign brand products at low prices. Most parallel importers base product pricing on subjective judgements. Fashion products in particular, have different sales rates depending on trends and seasons, so sales performance varies greatly depending on selling price timing and policy. The merchandiser (MD) set the price on parallel importation products by aggregating information on imported products and pricing goods. However, this customized process is very time consuming for the MD. This is because the logistics process of parallel importation's customs clearance procedures and repair works is complicated and takes a significant amount of time. In this paper, we propose an improved parallel importation logistics process based on big data, which automatically sets the price of parallel importation products.",60095591,TongMyong University,Busan,South Korea,"['1710', '1705']",17.5,0.03425925925925926,0.32685185185185184,1,0.12101910828025478,0.025477707006369428,0.35668789808917195
1425,1456,1456,UN-CODE: Software for structuring and visualizing collective decision-making based on qualitative data,"UN-CODE is a web-based tool for structuring and visualizing collective decision-making processes using qualitative, case-based data. It offers a database management tool and visualization method in one. The structure of the database and the visualizations derive from a model that is rooted in evolutionary biology and that has been transformed for social scientists. It features three principal dimensions: problem and solution definitions (PSD), weighted connectedness (c_score) as a network measure, and fitness (FIT) to describe the probability of actors reaching their goals in the collective decision-making process. The results are visualized in a scalable 3D-environment that shows the main dynamics of such in one quick overview.",60022265,Erasmus Universiteit Rotterdam,Rotterdam,Netherlands,"['1712', '1710']",21.2,0.1722222222222222,0.3,1,0.12781954887218044,0.03759398496240601,0.371900826446281
1426,1457,1457,Depth-induced multi-scale recurrent attention network for saliency detection,"In this work, we propose a novel depth-induced multi-scale recurrent attention network for saliency detection. It achieves dramatic performance especially in complex scenarios. There are three main contributions of our network that are experimentally demonstrated to have significant practical merits. First, we design an effective depth refinement block using residual connections to fully extract and fuse multi-level paired complementary cues from RGB and depth streams. Second, depth cues with abundant spatial information are innovatively combined with multi-scale context features for accurately locating salient objects. Third, we boost our model's performance by a novel recurrent attention module inspired by Internal Generative Mechanism of human brain. This module can generate more accurate saliency results via comprehensively learning the internal semantic relation of the fused feature and progressively optimizing local details with memory-oriented scene understanding. In addition, we create a large scale RGB-D dataset containing more complex scenarios, which can contribute to comprehensively evaluating saliency models. Extensive experiments on six public datasets and ours demonstrate that our method can accurately identify salient objects and achieve consistently superior performance over 16 state-of-the-art RGB and RGB-D approaches.",60004538,Dalian University of Technology,Dalian,China,"['1712', '1707']",20.222222222222218,0.1749047619047619,0.4488095238095239,1,0.12844036697247707,0.022935779816513763,0.3434343434343434
1427,1458,1458,Differential evolution with multi-strategies based soft island model,"Differential evolution (DE) is an uncomplicated and serviceable developmental algorithm. Nevertheless, its execution depends on strategies and regulating structures. The combination of several strategies between subpopulations helps to stabilize the probing on DE. In this paper, we propose a unique k-mean soft island model DE(KSDE) algorithm which maintains population diversity through soft island model (SIM). A combination of various approaches, called KSDE, intended for migrating the subpopulation information through SIM is developed in this study. First, the population is divided into k subpopulations using the k-means clustering algorithm. Second, the mutation pattern is singled randomly from a strategy pool. Third, the subpopulation information is migrated using SIM. The performance of KSDE was analyzed using 13 benchmark indices and compared with those of high-technology DE variants. The results demonstrate the efficiency and suitability of the KSDE system, and confirm that KSDE is a cost-effective algorithm compared with four other DE algorithms.",60073572,Jiujiang University,Jiujiang,China,"['1710', '1705']",15.0,0.027272727272727268,0.3371212121212121,1,0.11602209944751381,0.0718232044198895,0.41714285714285715
1428,1459,1459,"A comparative study of multi-focus, multi-resolution image fusion transforms and methods","Multi-resolution image decomposition transforms are a popular approach to current image processing problems such as image fusion, noise reduction, and deblurring. Over the past few decades, new algorithms have been developed based on the wavelet transform to remedy its directional and shift invariant shortcomings (undecimated discrete wavelet transform is shift invariant). This study provides a comprehensive analysis of multi-focus image fusion techniques using six different multi-resolution decomposition transforms to determine the optimal transform for an image fusion application. The transforms investigated are the wavelet, double-density wavelet, dual-tree wavelet, curvelet, contourlet, and bandelet. Furthermore, for each transform, seven transform coefficient fusion algorithms are analyzed and the performance is evaluated using eight no-reference objective image fusion metrics. The transforms and algorithms selected are applied to a data set that has 27 pairs of multi-focus source images used for image fusion. By bringing together the transforms, fusion algorithms, and metrics presented in this study as derived separately from different authors, the study seeks to compare these methods. However, a complete comparison amongst the different transforms, algorithms, and metrics has not been found in any of the existing literature. Our goal is to provide useful insight into their applications in image fusion. The summary of the aggregated results indicates that (1) the curvelet is the most robust transform, (2) down-up and linear are the most effect methods of fusion, and (3) Tsallis is the best metric for multi-focus image fusion.",60019187,Indiana University of Pennsylvania,Indiana,United States,['1700'],23.6,0.17414772727272726,0.4065340909090909,1,0.0896551724137931,0.010344827586206896,0.3639705882352941
1429,1460,1460,Influence of rainfall characteristics and land surface imperviousness on rainfall-runoff relationship,"The changes of land surface imperviousness due to rapid development had contributed to the occurrence of flash floods. The runoff coefficient, C that represents the rainfall-runoff relationship in the catchment is one of important parameter being considered in estimating the peak discharge due to a rainfall event. This study aimed to investigate the influence of rainfall characteristics and land surface imperviousness on rainfall-runoff relationship. A series of laboratory experiments were conducted in a 2m x 1m sand flume to simulate the hydrological cycle in a laboratory scale catchment by varying the rainfall characteristics under different land cover conditions. The spatial distribution of rainfall was found to influence the flood peak and runoff volume in this study. The results revealed that the runoff coefficient was higher under non-uniformly distributed rainfall event. This study indicated that both spatial and temporal variations of rainfall should be considered to improve the accuracy in estimating the flood peak.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1700'],21.857142857142854,0.08,0.5700000000000001,1,0.10650887573964497,0.005917159763313609,0.19254658385093168
1430,1461,1461,A comparison of ARIMA and ANN techniques in predicting port productivity and berth effectiveness,"Business process evaluation is a common norm in small-medium-large industries globally and information obtained during such evaluation have been used in simulating the future performance of most industries using mathematical models such as Autoregressive Integrated Moving Average (ARIMA) and artificial neural network (ANN). This study explored the possibility of predicting port productivity and berth effectiveness of a seaport using ANN and ARIMA. A comparative analysis of a multi-layer perceptron (MLP) back propagation algorithm and ARIMA performance was carried out based on ships days at port, days at berth and tonnage: the model’s input parameters, while port productivity and berth effectiveness were the model outputs. The MLP-ANN and ARIMA (1, 0, 4-port productivity) and (1, 0, 4-berth effectiveness) results were compared based on their coefficient of correlation and mean square error. The coefficient of correlation for port productivity prediction using MLP-ANN was 0.998. This value outperformed that of ARIMA (0.9862) for port productivity; berth effectiveness coefficients of correlation of 0.9956 and 0.9928 were obtained using the MLP-ANN and the ARIMA models, respectively.",60089366,Bells University of Technology,Ota,Nigeria,"['1705', '1710', '1712', '1706', '1702']",28.5,-0.071875,0.359375,1,0.08056872037914692,0.08056872037914692,0.4
1431,1462,1462,A Novel Three-Layer QR Code Based on Secret Sharing Scheme and Liner Code,"Quick Response (QR) code, a machine-readable symbol, is widely employed in all walks of life due to its large information capacity, strong error correction ability, and fast reading speed. However, anyone with a standard decoder could obtain stored information. In this paper, utilizing the characteristics of the Hamming code, wet paper code, and the recognition mechanism of the QR code, we introduce a high-capacity QR code with three-layer information to protect the sensitive information. In the proposed scheme, we utilize the XOR-based secret-sharing algorithm to embed the second-layer information on the column vector of the constructed random matrix block. Then, without affecting the embedding result of the second layer information, the matrix block elements are reused again, and the Hamming code is constructed with the column vector. Based on the error correction mechanism of the Hamming code, the third layer of information is embedded on the column vector and encoded by wet paper coding to realize the blind extraction. Finally, based on the recognition mechanism of the QR code, the random matrix block containing the secret information is fused with the carrier QR code, and the public information of the carrier QR code is used as the first-layer information. Compared with other schemes, the proposed scheme has the advantages of high information payload, low computational complexity, and strong robustness.",60069731,Information Engineering University China,Zhengzhou,China,"['1710', '1705']",27.375,-0.02616883116883117,0.4599350649350649,1,0.09505703422053231,0.04182509505703422,0.30120481927710846
1432,1463,1463,The probabilistic logic of communication and change," Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.This article introduces a Probabilistic Logic of Communication and Change, which captures in a unified framework subjective probability, arbitrary levels of mutual knowledge and a mechanism for multi-agent Bayesian updates that can model complex social-epistemic scenarios, such as informational cascades. We show soundness, completeness and decidability of our logic, and apply it to a concrete example of cascade.",60029378,California State University Long Beach,Long Beach,United States,"['1712', '1708']",17.75,-0.0625,0.45,0,0.10227272727272728,0.07954545454545454,0.43373493975903615
1433,1464,1464,ZVS asymmetrical PWM full-bridge high voltage gain DC-DC converter controlled by ANFIS for energy harvesting applications,"Adaptive neuro-fuzzy inference system (ANFIS) controller for zero voltage switching (ZVS) asymmetrical pulse width modulated (APWM) full-bridge DC-DC converter with high voltage gain is proposed for energy harvesting applications. Converter has given continuous input current, low switching losses, higher efficiency and higher power density as a result of zero voltage switching. ANFIS controller has provided superior control to maintain constant converter output voltage for any one of energy harvesting applications. ANFIS controller performance has been compared with proportional integral (PI), fuzzy logic (FLC) and fuzzy proportional, integral and derivative (Fuzzy PID) controllers. Proposed system has been simulated using PSIM and MATLAB/Simulink tools boxes and results presented. Also, hardware prototype of proposed system with 1.6KW rating has been fabricated and tested.",60106283,Sethu Institute of Technology,Kariapatti,India,['1700'],20.0,0.16999999999999998,0.5279166666666667,1,0.08609271523178808,0.09933774834437085,0.44755244755244755
1434,1465,1465,A fuzzy multi-criteria approach for hosting-right selection: A case study of sport event,"Decision-making process is an integral part of every sporting event across the globe. This process uses inputs from single to multi-decision makers. To make a sporting event a success, appropriate decision making needs to be made starting from hosting-right to the end of the event. Thus, this study presents a framework that scientifically determines the hosting-right for a sporting event. The framework is based on techno-economic analysis of potential hosting locations for a sporting event. Techno-economic criteria are analysed using fuzzy TOPSIS (technique for order preference by similarity to ideal solution) method. The analysis of the hosting-right is also performed through technical, economic, techno-economic and cost-benefit ratio perspectives. A case study of national sports festival in Nigeria is used to demonstrate the applicability of the proposed framework. Twelve technical and eight economic criteria are considered in the proposed framework. Six locations are considered during the implementation of the proposed framework. The results obtained show that the issue of hosting-right award depends on the evaluation criteria that are considered by decision-makers.",60089366,Bells University of Technology,Ota,Nigeria,"['1705', '1710', '1712', '1706', '1702']",15.454545454545455,0.20285714285714285,0.3414285714285715,1,0.13875598086124402,0.019138755980861243,0.27807486631016043
1435,1466,1466,MPPT design using artificial neural network and backstepping sliding mode approach for photovoltaic system under various weather conditions,"This paper presents a novel hybrid technique for tracking the maximum power point of the photovoltaic panel. This approach includes two loops: The first one is the ANN (Artificial neural network) loop that is used to estimate and generate the reference of optimal voltage. While, the second loop consists of the BSM (Backstepping Sliding Mode) controller. Effectively, the proposed controller is designed to track the signal of the desired voltage, which is generated using the first loop, by adjusting the duty cycle of the boost converter. Thus, this loop allows the DC/DC converter to product the maximum power at the terminals of the PV module and the load. Indeed, in contrary to the traditional backstepping, the proposed ANN-BSM technique guarantee zero steady-state error. On the one hand, by using the ANN, the system can quickly predict the desired optimal voltage, also it allows the system to avoid the unnecessary calculations and research of the maximum point of power. On the other hand, the sliding mode and the backstepping controller are used to provide the good performances and robustness against the rapid changes of insolation. In addition, the asymptotic stability of this system is made by applying the Lyapunov approach. To show the effectiveness and the tracking performances of the proposed ANN-BSM technique, a comparative study with the classical methods, P&O and incremental conductance algorithms, and hybrid approaches such as the ANN-Backstepping controllers and the ANN-Integral Sliding mode, is investigated in MATLAB/Simulink software.",60019337,Mohammed V University in Rabat,Agdal Rabat,Morocco,['1700'],24.2,0.08402777777777777,0.5076388888888889,1,0.11846689895470383,0.07317073170731707,0.32
1436,1467,1467,Comparison of sentiment analysis from large twitter datasets by naive bayes and natural language processing methods,"Recently, effort to obtain various information from the vast amount of social network services (SNS) big data generated in daily life has expanded. SNS big data comprise sentences classified as unstructured data, which complicates data processing. As the amount of processing increases, a rapid processing technique is required to extract valuable information from SNS big data. We herein propose a system that can extract human sentiment information from vast amounts of SNS unstructured big data using the naive Bayes algorithm and natural language processing (NLP). Furthermore, we analyze the effectiveness of the proposed method through various experiments. Based on sentiment accuracy analysis, experimental results showed that the machine learning method using the naive Bayes algorithm afforded a 63.5% accuracy, which was lower than that yielded by the NLP method. However, based on data processing speed analysis, the machine learning method by the naive Bayes algorithm demonstrated a processing performance that was approximately 5.4 times higher than that by the NLP method.",60005665,Kyungil University,Gyeongsan,South Korea,"['1710', '1705']",23.0,-0.04298245614035088,0.4587719298245614,1,0.12154696132596685,0.06077348066298342,0.3425414364640884
1437,1468,1468,Unethical Authorship in Scientific Publications (A Review of the Problem),"Abstract: Unfair authorship in scientific publications is one of the most common types of violations of publication ethics, which is associated either with the unfair inclusion among authors of persons who do not meet the criteria for authorship, or, conversely, with the concealment of the real performers of scientific work. The main reasons for the intense spread of unethical behavior in relation to authorship in recent years include the imperfection of the science management system, which requires high rates of publication activity from researchers; partly discriminatory policies of journals in relation to young authors, which force them to include authoritative scientists as co-authors; and conflicts of interest in medical publications, which prompt pharmaceutical companies to exclude real the performers of the work. The scientific and publishing international communities have been offered a set of approaches both to the fight against unfair authorship and to its prevention, including the development of additional criteria for authorship; clarification of instructions and guidelines for authors, reviewers, and editors; and organization of training events to familiarize authors with the principles of publication ethics. The scientometric methods for identifying unacceptable types of authorship seem promising. This review article presents the current state of the problem and the ways to solve it that have been outlined by the professional community.",60107593,The State Public Scientific Technological Library of the Siberian Branch of the Russian Academy of Sciences,Novosibirsk,Russian Federation,['1700'],42.6,0.01814814814814815,0.5012962962962964,1,0.08085106382978724,0.00425531914893617,0.26180257510729615
1438,1469,1469,"Performance comparison for local feature extraction algorithms: SURF, SIFT and ORB to detect concealed weapons in X-ray images","The process of detecting hidden weapons is an important process right now due to the increase in terrorist operations, so the process of building an automatic weapons detection system is an important process to reduce errors resulting from manual detection. In the proposed work, the pre-processing was given high importance because the x-ray images contain noise and low resolution, therefore image smoothing has been used to reduce the noise where histogram equalization has been used for image enhancement and increase of contrast. The local algorithms: SIFT, SURF and ORB have been used to detect and describe the features from the region of interest, then KNN algorithm has been used to match and index the similarity between the query image and the extracted features from the data set. KNN and Random Sample used a consensus on the three methods to see which local algorithm performs best. RANSAC has been used to reject false matches that may be taken as correct matches. The performance of the SIFT algorithm with the KNN outweighed both of the algorithms in spite of the fact that it was slow. SURF and the ORB algorithms as a position in the result where SURF was the fastest one with high performance and showing its dominance in illumination changes and rotation.",60071157,University of Babylon,Babylon,Iraq,['1700'],30.285714285714285,0.06528911564625849,0.4588605442176871,1,0.11353711790393013,0.0611353711790393,0.2311111111111111
1439,1470,1470,Adversarial fine-grained composition learning for unseen attribute-object recognition,"Recognizing unseen attribute-object pairs never appearing in the training data is a challenging task, since an object often refers to a specific entity while an attribute is an abstract semantic description. Besides, attributes are highly correlated to objects, i.e., an attribute tends to describe different visual features of various objects. Existing methods mainly employ two classifiers to recognize attribute and object separately, or simply simulate the composition of attribute and object, which ignore the inherent discrepancy and correlation between them. In this paper, we propose a novel adversarial fine-grained composition learning model for unseen attribute-object pair recognition. Considering their inherent discrepancy, we leverage multi-scale feature integration to capture discriminative fine-grained features from a given image. Besides, we devise a quintuplet loss to depict more accurate correlations between attributes and objects. Adversarial learning is employed to model the discrepancy and correlations among attributes and objects. Extensive experiments on two challenging benchmarks indicate that our method consistently outperforms state-of-the-art competitors by a large margin.",60114181,Tencent,Shenzhen,China,"['1712', '1707']",20.25,0.1922108843537415,0.4714795918367347,1,0.13333333333333333,0.0,0.3128491620111732
1440,1471,1471,Evaluation and classification of the brain tumor MRI using machine learning technique,"The proposed work implements a Machine-Learning-Technique (MLT) to evaluate and classify the tumor regions into low/high grade based on the analysis carriedout with the brain MRI slices. The MLT implements a sequence of procedures, such as pre-processing, post-processing and classification procedures. The pre-processing enhances the tumor section based on Social Group Optimization (SGO) algorithm assisted Fuzzy-Tsallis thresholding. The robustness of the proposed thresholding is also confirmed by considering the noise corrupted MRI slices. The post-processing implements the Level-Set Segmentation (LSS) to mine the tumor region. The performance of the LSS is validated with segmentation procedures, like Active-Contour (ACS) and Chan-Vese (CVS) technique. The fundamental data of the tumor section is then extracted using the Gray Level Co-occurrence Matrix (GLCM) and most dominating features are then chosen with a statistical test. Finally, a two-class classifier is implemented using the Support Vector Machine with Radial Basis Function (SVM-RBF) kernel and its performance is then validated with other classifiers, like the Random-Forest and k-Nearest Neighbor. The outcome of the proposed work confirms that, implemented tool with the SVM-RBF helps to achieve an accuracy of >94% on the benchmark BRATS2015 database.",60100946,St. Joseph's College of Engineering,Chennai,India,['1700'],20.777777777777782,0.13472222222222222,0.5736111111111111,1,0.09523809523809523,0.1626984126984127,0.481651376146789
1441,1472,1472,Sufficient condition for a nil-clean element to be clean in a certain subring OFM3(Z),"Abstract: Diesl has proved that a nil-clean ring is clean. However, not all nil-clean element of any ring is clean as showed by Andrica by providing counter examples in 2 x 2 matrices over Z. The objective of this study is to determine sufficient condition for a nil-clean element tobe clean in a certain subring of M3(Z). The two main methods are constructing certain subring, namely X3(Z), of M3(Z) and then identifying idempotent and nilpotent elements in X3(Z). This construction provides examples as the extension of those matrices founded by Andrica in the sense of matrix order and the different form of those matrices. The methods are used in finding the sufficient condition for nil-clean elements to be clean in a certain subring of M3(Z). By this finding, we follow up the previous researches especially from Diesl and Andrica. As the application, it is provided nil-clean elements in X3(Z) which are clean and some other elements which are not clean.",60104775,Universitas Negeri Malang,Malang,Indonesia,['1700'],20.0,0.14452380952380953,0.5659523809523809,1,0.06349206349206349,0.05291005291005291,0.34375
1442,1473,1473,Program models and semi-public environments," Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.We develop a logic for reasoning about semi-public environments, i.e. environments in which a process is executing, and where agents in the environment have partial and potentially different views of the process. Previous work on this problem illustrated that it was problematic to obtain both an adequate semantic model and a language for reasoning about semi-public environments. We here use program models for representing the changes that occur during the execution of a program. These models serve both as syntactic objects and as semantic models, and are a modification of action models in Dynamic Epistemic Logic, in the sense that they allow for ontic change (i.e. change in the world or state). We show how program models can elegantly capture a notion of observation of the environment. The use of these models resolves several difficulties identified in earlier work, and admit a much simpler treatment than was possible in previous work on semi-public environments.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1708']",16.7,0.058333333333333334,0.3777777777777778,0,0.10416666666666667,0.036458333333333336,0.33689839572192515
1443,1474,1474,Design and Usability of Library Websites,"Abstract: This paper considers the results of the analysis of 125 websites of Russian libraries on web design and usability, which was conducted at the State Public Scientific and Technical Library of the Siberian Branch of the Russian Academy of Sciences. Using the site rating checklist, the data from this study and similar foreign works were compared. A profile of the typical website of the academic, university and public library in terms of design, content, service and general usability was obtained.",60017604,"Siberian Branch, Russian Academy of Sciences",Novosibirsk,Russian Federation,['1700'],27.0,-0.024166666666666663,0.17583333333333334,1,0.05555555555555555,0.1111111111111111,0.3333333333333333
1444,1475,1475,Formulation of 3D Euclidean distance for network clustering in wireless sensor network,"In wireless sensor networks, nodes operating under dynamic topology are often correlated with their behavior. Correlated behavior may pose devastating impact towards network connectivity. A node may change its behaviour from cooperative node to misbehave node which directly affects the network's connectivity. Misbehaviour nodes tend to have correlated effect which creates partitioning within the network. To improve network connectivity in providing an efficient communication in the events of the correlated behaviors, a new formulation of correlated degree to perform network clustering is required. This paper proposes a formulation on correlated degree using 3D Euclidean distance to achieve higher network connectivity under correlated node behavior. The key idea behind the 3D Euclidean distance in network clustering is to identify a set of sensors whose sensed values present some data correlation referring to correlated degree. The correlated degree is formulated based on three-point distance within a correlation region to identify the level of node correlation within neighboring nodes. In addition, the correlated degree also be able to detect the same group of node behavior which is grouped in correlated regions. 3D Euclidean distance is shown in mathematical analysis and how the new formulation calculates correlated degree is also discussed. It is also expected that the new 3D Euclidean distance formulation may help correlation region to change it cluster formation dynamically to achieve the required network connectivity.",122017150,Universiti Sains IslamMalaysia(USIM),Nilai,Malaysia,['1700'],20.363636363636363,-0.01720779220779221,0.4485930735930736,1,0.1825726141078838,0.008298755186721992,0.200836820083682
1445,1476,1476,Maximum node interconnection by a given sum of euclidean edge lengths,"This paper proposes a solution to the problem of finding a subgraph for a given instance of many terminals on a Euclidean plane. The subgraph is a tree, whose nodes represent the chosen terminals from the problem instance, and whose edges are line segments that connect two corresponding terminals. The tree is required to have the maximum number of nodes while the length is limited and is not sufficient to interconnect all the given terminals. The problem is shown to be NP-hard, and therefore a genetic algorithm is designed as an efficient practical approach. The method is suitable to various probable applications in layout optimization in areas such as communication network construction, industrial construction, and a variety of machine and electronics design problems. The proposed heuristic can be used as a general-purpose practical solver to reduce industrial costs by determining feasible interconnections among many types of components over different types of physical planes.",60003087,The Catholic University of Korea,Youngdeungpo,South Korea,"['1710', '1705']",25.5,0.18482142857142855,0.4544642857142857,1,0.09523809523809523,0.005952380952380952,0.22560975609756098
1446,1477,1477,Augmented reality technology-based dental radiography simulator for preclinical training and education on dental anatomy,"It is important that students are provided opportunities to practice their skills in acquiring radiographic images. However, these opportunities are currently limited because of the risk of radiation exposure. To overcome this limitation, a new augmented reality-based radiography simulator was developed that enables students to practice radiographic techniques as part of selfdirected learning without time and space constraints. Subsequently, cross-sectional images of a manikin phantom head obtained via computed tomography were reconstructed into a three-dimensional object. An image marker that could be recognized by a mobile device and could allow users to practice dental radiography techniques was devised. The three-dimensional object was augmented to the mobile device; consequently, among 106 stored dental radiographs on the device, a radiograph corresponding to specific imaging conditions was opened when users performed radiographic procedures. This technology could improve dental students' understanding of dental anatomy and contribute to improving their competency in acquiring dental radiographs.",60080750,Namseoul University,Cheonan,South Korea,"['1710', '1705']",21.428571428571427,0.09415584415584416,0.3454004329004329,1,0.16279069767441862,0.0,0.3353658536585366
1447,1478,1478,1.9-GHz CMOS power amplifier using adaptive biasing technique at AC ground,"A 1.9-GHz linear CMOS power amplifier is presented. An adaptive bias circuit (ABC) that utilizes an AC ground to detect the power level of the input signal is proposed to enhance the linearity and efficiency of the power amplifier. The ABC utilizes the second harmonic component as the input to mitigate the distortion of the fundamental signal. The input power level of the ABC was detected at the AC ground located at the VDD node of the power amplifier. The output of the ABC was fed into the inputs of the power stage. The input signal distortion was mitigated by detecting the input power level at the AC ground. The power amplifier was designed using a 180 nm RFCMOS process to evaluate the feasibility of the application of the proposed ABC in the power amplifier. The measured output power and power-added efficiency were improved by 1.7 dB and 2.9%, respectively.",60014156,Soongsil University,Seoul,South Korea,"['1710', '1705']",18.75,0.0,0.05,1,0.10975609756097561,0.07926829268292683,0.2654320987654321
1448,1479,1479,Development of branch processing system using webassembly and javascript,"Existing web applications and services have historically been implemented using JavaScript. However, new technologies such as artificial intelligence, the Internet of Things, and Big Data are being developed as part of the Fourth Industrial Revolution. With the definition of the HTML5 web standard, services (such as the technologies mentioned above) that were previously not available through the Web become available. These services, however, need to have the same performance as native applications, and implementing these services will require new technologies. Therefore, additional tools that can work on the Web with native performance are needed. In this paper, a system for branching processing was established using JavaScript and WebAssembly, a language that can operate on the Web. This system performs user requests in advance, and requests are branched in a language that produces faster results. Therefore, a service capable of quick response times can be implemented.",60009962,Korea University of Technology and Education,Cheonan,South Korea,"['1710', '1705']",18.125,0.031628787878787874,0.32713068181818183,1,0.1377245508982036,0.0658682634730539,0.40718562874251496
1449,1480,1480,"Coalition logic with individual, distributed and common knowledge"," Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.Coalition logic is currently one of the most popular logics for multi-agent systems. While logics combining coalitional and epistemic operators have received considerable attention, completeness results for epistemic extensions of coalition logic have so far been missing. In this paper we provide several such results and proofs. We prove completeness for epistemic coalition logic with common knowledge, with distributed knowledge, and with both common and distributed knowledge, respectively. Furthermore, we completely characterise the complexity of the satisfiability problem for each of the three logics. We also study logics with interaction axioms connecting coalitional ability and knowledge.",60029622,Universitetet i Bergen,Bergen,Norway,"['1712', '1708']",13.625,0.05000000000000002,0.44166666666666665,0,0.09375,0.03125,0.36
1450,1481,1481,Design and development of a mechanism for lower limb movement," J. Mech. Eng. Rob. Res.Robotics for human rehabilitation consents to respond on open challenges and opportunities to integrate engineering concepts into human service. This paper presents a modular and reconfigurable robotic device focused on ankle rehabilitation tasks. The proposed configuration guarantees the rehabilitation progression and torque assistance during the ankle exercise, avoiding any potential disturbance. The design has been guided by patients' requirements and ankle motion. The kinematic, dynamic analyses and the mechatronic model are proposed. The hardware in the loop strategy was adopted and validated using a number of simulations. Finally, the device was validated through a set of experimental tests. The obtained results confirmed the theoretical and simulation models, thereby highlighting the potential effectiveness of the proposed system for ankle rehabilitation.",60015300,Università degli Studi di Brescia,Brescia,Italy,['1702'],10.333333333333334,0.03636363636363637,0.506060606060606,0,0.11971830985915492,0.028169014084507043,0.3597122302158273
1451,1482,1482,Machine vision systems in precision agriculture for crop farming,"Machine vision for precision agriculture has attracted considerable research interest in recent years. The aim of this paper is to review the most recent work in the application of machine vision to agriculture, mainly for crop farming. This study can serve as a research guide for the researcher and practitioner alike in applying cognitive technology to agriculture. Studies of different agricultural activities that support crop harvesting are reviewed, such as fruit grading, fruit counting, and yield estimation. Moreover, plant health monitoring approaches are addressed, including weed, insect, and disease detection. Finally, recent research efforts considering vehicle guidance systems and agricultural harvesting robots are also reviewed.",60158100,International Hellenic University,Thermi,Greece,"['1707', '1704']",17.5,0.09583333333333333,0.39166666666666666,1,0.1,0.0,0.3
1452,1483,1483,A new technique based on 3D convolutional neural networks and filtering optical flow maps for action classification in infrared video,"Human action in video sequences provides three-dimensional spatio-temporal signals that characterize both visual appearance and motion dynamics. The aim of this work is to recognize human action in infrared video by focusing mainly on dynamic information. We developed a new technique based on deep 3D convolutional neural networks (3D CNNs) that take optical flow maps as input. Our approach consists mainly of three parts: 1) computation of optical flow maps; 2) filtering of these maps, using an entropy measurement in order to increase the classification rate and reduce the run time by eliminating sequences that do not contain human action; and 3) classification using 3D CNN. The experimental results obtained by our approach on the InfAR dataset show considerable improvement in comparison with results obtained by existing models.",60087352,Université de Boumerdes,Boumerdes,Algeria,['1700'],25.6,0.06450216450216449,0.2217532467532468,1,0.11643835616438356,0.0136986301369863,0.352112676056338
1453,1484,1484,On the stability of nonlinear minimum variance control for a second-order volterra series model,"In this paper, the stability of a closed-loop system with nonlinear minimum variance controller for a second order Volterra series model is studied. It is shown that the closed-loop system with secondorder Volterra series model and minimum variance control signal is a state-dependent switching system with an arbitrary switching signal. The necessary condition for asymptotic stability of this system is the stability of its all subsystems and is investigated using a linearization approach. Also, a sufficient closedloop stability condition with nonlinear minimum variance control is introduced. It is shown that if the sufficient stability condition is violated, it can be satisfied by using a generalized output and nonlinear generalized minimum variance control.",60016248,K. N. Toosi University of Technology,Tehran,Iran,['1700'],22.4,0.1,0.65,1,0.0873015873015873,0.015873015873015872,0.20833333333333334
1454,1485,1485,Mean squared error applied in back propagation for non linear rainfall prediction,"Analyzing global weather forecasts is challenging and expensive. Machine learning algorithms analyze trends in weather data by adopting regression model and neural network model. Our proposed model is based on two methodologies Multiple Linear Regression (MLR) and Artificial Neural Network (ANN) to predict rainfall. MLR determines most significant parameters of rainfall data for ANN. Mean Squared Error (MSE) generated at ANN model was back propagated to get more accurate results. The model was tested on five year (2013 to 2017) meteorological data of Bengaluru station. ANN with Back Propagation Neural Network (BPNN) was applied to forecast low rainfall, average rainfall and heavy rainfall. Performance of the model was measured by R and MSE value. Experimental result shows that back propagation of MSE and data normalization yields good results.",118612393,BIT,Bengaluru,India,['1700'],14.222222222222221,0.07291666666666667,0.4497685185185186,1,0.10135135135135136,0.16216216216216217,0.44594594594594594
1455,1486,1486,Genetically optimized ANFIS-based PID controller design for posture-stabilization of self-balancing-robots under depleting battery conditions,"It is well known that in battery-powered control applications, the continuous drop in battery's output-power progressively degrades the dynamic performance of the system. The battery depletion phenomenon deteriorates the reliability of correctional effort if the controller gains are not adaptively adjusted as function of the available power level. Hence, this paper presents an adaptive neuro-fuzzy inference system (ANFIS) that dynamically adjusts the controller gains of a close-loop dynamic system as function of battery power-level in order to maintain desired performance while the battery is depleting. The proposed methodology is verified on an inherently unstable two-wheeled self-balancing-robot. The Proporional-Integral-Derivative (PID) controller is used for robot's posture-stabilization. Initially, trivial sets of PID gains are selected via genetic algorithm to yield best control effort at various battery powerlevels, using hardware-in-the-loop strategy. The acquired data is then used to train a power-level dependedent ANFIS that dynamically adjusts the PID gains in real-time. The performance of a fixed gain PID controller is compared with that of the proposed self-tuning PID controller for two different powerdepletion scenarios that emulate real-world situations. The corresponding experimental results validate the robustness of the proposed control scheme to maintain the robot's postural stability under discharging battery condition.",60070602,National University of Computer and Emerging Sciences Lahore,Lahore,Pakistan,['1700'],21.88888888888889,0.17777777777777778,0.30370370370370364,1,0.11857707509881422,0.039525691699604744,0.2995391705069124
1456,1487,1487,Instrumental Monitoring of Compliance of Websites with the Legislation Requirement in the Area of Personal Data,Abstract: The relevance of developing a tool for monitoring websites for compliance with legal requirements in the field of personal data is shown. The result of the software implementation of such a tool is described. The advantages of the developed product in comparison with manual monitoring are noted.,60008009,South Ural State University,Chelyabinsk,Russian Federation,['1700'],16.0,0.07500000000000001,0.325,1,0.11538461538461539,0.019230769230769232,0.2692307692307692
1457,1488,1488,Hybrid Aeroacoustic Computations: State of Art and New Achievements,"This paper collects the state of the art and the tremendous progress that has been made in hybrid modeling of aeroacoustic sound. Hybrid modeling is defined such that flow and acoustics are modeled separate and connected by an aeroacoustic model. The contributions will be classified with respect to the aeroacoustic models being developed, covering Lighthill's analogy, Ffowcs Williams and Hawkings, vortex sound, linearized Euler equations (LEE), and different perturbation equations modeling flow induced sound. Within each topic, specific applications, such as jet noise, aircraft noise, ground mobility, noise, fan noise and human phonation, are covered. We focus on the accomplishments and provide the authors' contribution to aeroacoustic research. Eventually, a concise summary of the different methods and their capabilities is included.",60018163,Technische Universitat Wien,Vienna,Austria,['1706'],20.166666666666668,0.14444444444444446,0.4604166666666665,1,0.09722222222222222,0.041666666666666664,0.3611111111111111
1458,1489,1489,Hardware in loop cosimulation of LMS algorithm for shunt active filter to mitigate harmonics and reactive power-Xilinx system generator approach,"The performance of the shunt active filter depends mainly on the reference current generator and pulse generator which switches the active devices. This maintains the supply current near to unity power factor and sinusoidal. Hence, the objective of the paper is to develop a control algorithm for shunt active filter using Xilinx system generator to achieve sinusoidal current waveform with unity power factor. Many research works discuss about adaptive filter using Least Mean Square algorithm with multiple parameters. However, the complexity of the algorithm increases with increase in parameters. So, LMS algorithm with minimum parameters is mandate. Therefore, the proposed algorithm with minimal parameters is developed in digital simulator and prototyping DSP/FPGA board. In this paper, an adaptive filter is developed in system generator tool box in MATLAB and Spartan 6 Field Programmable Gate Array board is used as Hardware In Loop Cosimulation system. The adaptive filter extract the fundamental real component of the load current and voltage control loop generates the reference current. The indirect current control technique is adopted and the gating pulses are generated by Hysteresis controller. The control algorithm results exhibit sinusoidal current waveform with near to unity power factor which proves the efficacy of the algorithm.",60005147,SASTRA Deemed University,Thanjavur,India,['1700'],18.272727272727273,0.018923611111111117,0.3717013888888889,1,0.1050228310502283,0.0821917808219178,0.2857142857142857
1459,1490,1490,The effect of measurement errors on the double sampling X chart,"The purpose of this study is to investigate the performance of the double sampling (DS) Xbarchart when measurement errors exist. The effects of measurement error ratio, parameter of the linearly covariate error model and multiple measurements on the performance of the DS Xbar chart are evaluated. The numerical results show that the performance of the DS Xbar chart is affected by the presence of measurement errors. An example is presented to illustrate the application of the DS Xbar chart under measurement errors.",60031630,Swinburne University of Technology Sarawak Campus,Kuching,Malaysia,['1700'],20.5,0.0,0.0,1,0.07865168539325842,0.0898876404494382,0.2696629213483146
1460,1491,1491,Processing-node status-based message scattering and gathering for multi-processor systems on chip,"This paper presents processing-node status-based message scattering and gathering algorithms for multi-processor systems on chip to reduce the communication time between processors. In the message-scattering part of the message-passing interface (MPI) scatter function, data transmissions are ordered according to the proposed linear algorithm, based on the processor status. The MPI hardware unit in the root processing node checks whether each processing node's status is 'free' or 'busy' when an MPI scatter message is received. Then, it first transfers the data to a 'free' processing node, thereby reducing the scattering completion time. In the message-gathering part of the MPI gather function, the data transmissions are ordered according to the proposed linear algorithm, and the gathering is performed. The root node receives data from the processing node that wants to transfer first, and reduces the completion time during the gathering. The experimental results show that the performance of the proposed algorithm increases at a greater rate as the number of processing nodes increases.",60016912,Yonsei University,Seoul,South Korea,"['1710', '1705']",23.0,0.275,0.44583333333333336,1,0.1377551020408163,0.03571428571428571,0.3370165745856354
1461,1492,1492,An improved artificial bee colony algorithm based harmonic control for multilevel inverter,"In this paper, an Improved Artificial Bee Colony (IABC) Algorithm is proposed for eliminating voltage harmonics in the Multilevel Inverter (MLI). It is achieved by reducing the THD present in the MLI output voltage. In an MLI, the harmonics can be eliminated by an optimal selection of switching angles. The proposed IABC technique utilizes an Artificial Bee Colony (ABC) Algorithm and Recurrent Neural Networks (RNN) for the optimal selection of switching angles. An IABC algorithm is used to evaluate the optimum switching angles that are obtained from the iteration as well as the RNN. Here, the voltage variation of the MLI is determined from the actual load voltage and the reference voltage. The voltage variation at different time interval has been applied to the IABC algorithm. According to the voltage variations, the switching angles can be generated from the RNN. These switching angles can make the MLI output voltage with reduced THD. The proposed algorithm is tested with a seven-level inverter, and the resultant fundamental and harmonics voltages are analyzed. The experimental result shows the efficiency of the proposed algorithm in eliminating the harmonics that are generated by the inverter. The proposed algorithm is instructed in the MATLAB/Simulink working platform. The effectiveness of the suggested algorithm is evaluated by the MLI output voltage with some traditional techniques like a genetic algorithm (GA), ABC.",60103697,"Anna University of Technology, Tiruchirappalli",Tiruchirappalli,India,['1700'],17.153846153846153,-0.05,0.59375,1,0.12109375,0.125,0.373015873015873
1462,1493,1493,"Digital Literacy in Society: The Situation, Problems, and Prospects at the Current Stage of Scientific and Technical Progress",Abstract: The major problems of the formation of digital literacy in the population of Russia are systematized. The role of modern libraries in the adaptation of society to the digital environment and the formation of its basic digital competencies is outlined.,60108633,Cherepovets State University,Cherepovets,Russian Federation,['1700'],20.5,0.04375,0.15416666666666667,1,0.045454545454545456,0.045454545454545456,0.18181818181818182
1463,1494,1494,Improving clinic queues in Malaysia using time-series extrapolation forecast and web-based appointment,"In University of Science, Malaysia (USM), Sejahtera Centre is the main healthcare centre that provides medical care to the university students, employees and pensioners. Along the years, the increasing demand for these services has led to long queue problems in the clinic. As a result, the clinic becomes congested during peak hours, leaving both patients and healthcare staffs dissatisfied. Apart from Sejahtera Centre, long queue issue has been a common problem in many government outpatient departments across Malaysia. Therefore, this paper proposes a low-cost, user-friendly clinic management system that consists of a web application for clinic staff and a hybrid mobile application for patients. Real-time queue monitoring and queue forecasting using Time-Series Extrapolation is incorporated to help patients avoid peak hours and empower better clinic workforce management in handling different patient flow peaks. The web-based appointment approach allows patients to conveniently reschedule their appointments online and receive appointment reminders via the mobile application. To demonstrate the feasibility and effectiveness of the proposed system, a prototype is developed and evaluated based on several interviews. The prototype serves as a basic working model that outlines the feasibility of the proposed concepts to improve queue issues in other clinics across Malaysia.",60000906,Universiti Sains Malaysia,Gelugor,Malaysia,['1700'],22.0,0.06180555555555555,0.3361111111111111,1,0.11790393013100436,0.0611353711790393,0.3744292237442922
1464,1495,1495,Fast parameter identification of permanent magnet synchronous motor for electric vehicles,"This paper proposes a new recurrent neural network method (RNN) that can be used for parameter identification and optimal current (OC) solution for interior permanent magnet synchronous motor (IPMSM) in electric vehicles (EVs). Firstly, the problem of parameter identification of IPMSM is modeled as a regression problem, and the least absolute deviation method (LAD) is used to estimate the parameters. Then the optimization theory and variational theory are adopted to convert it into a variational problem, and the projection dynamic equation (PDS) is utilized to find the solution. Finally, the RNN corresponding to the PDS is designed which can be multiplexed for the optimal solution, aiming at achieving the motor parameter identification in parallel. This paper proves the convergence of the proposed projection dynamic equation. The convergence value and the identity of the PMSM parameter are estimated. The IPMSM drive system is built and simulated. The simulation results show that the proposed method can identify the motor parameters quickly and accurately, and it verifies the rationality and effectiveness of the proposed method.",60005027,Guizhou University,Guiyang,China,['1700'],21.5,0.10997474747474748,0.4128787878787879,1,0.13636363636363635,0.050505050505050504,0.29292929292929293
1465,1496,1496,Process tree-based analysis method of declare relation constraints in acyclic bridge-less well-structured workflow nets," All rights reserved.In this paper, we proposed a method to analyze workflows’ constraints whose templates are defined in a declarative language called DECLARE. Checking such constraints is important but known to be intractable in general. Our results show three things. First, utilizing a tree representation of workflow process called process tree, we provided necessary and sufficient conditions on the constraints. Second, those conditions enable us to not only check a given constraint in polynomial time but also find a clue for improving the net if it violates the constraint. Third, we revealed the relationship among the constraint templates.",60020739,Yamaguchi University,Yamaguchi,Japan,"['1710', '1705']",16.5,0.07777777777777778,0.4814814814814816,0,0.1592920353982301,0.0,0.33636363636363636
1466,1497,1497,Mathematical and numerical modeling of a drop-shaped microcavity laser," Spiridonov, Evgenii M. KarchevskiiThis paper studies electromagnetic fields, frequencies of lasing, and emission thresholds of a drop-shaped microcavity laser. From the mathematical point of view, the original problem is a nonstandard two-parametric eigenvalue problem for the Helmholtz equation on the whole plane. The desired positive parameters are the lasing frequency and the threshold gain, the corresponding eigenfunctions are the amplitudes of the lasing modes. This problem is usually referred to as the lasing eigenvalue problem. In this study, spectral characteristics are calculated numerically, by solving the lasing eigenvalue problem on the basis of the set of Muller boundary integral equations, which is approximated by the Nyström method. The Muller equations have weakly singular kernels, hence the corresponding operator is Fredholm with zero index. The Nyström method is a special modification of the polynomial quadrature method for boundary integral equations with weakly singular kernels. This algorithm is accurate for functions that are well approximated by trigonometric polynomials, for example, for eigenmodes of resonators with smooth boundaries. This approach leads to a characteristic equation for mode frequencies and lasing thresholds. It is a nonlinear algebraic eigenvalue problem, which is solved numerically by the residual inverse iteration method. In this paper, this technique is extended to the numerical modeling of microcavity lasers having a more complicated form. In contrast to the microcavity lasers with smooth contours, which were previously investigated by the Nyström method, the drop has a corner. We propose a special modification of the Nyström method for contours with corners, which takes also the symmetry of the resonator into account. The results of numerical experiments presented in the paper demonstrate the practical effectiveness of the proposed algorithm.",60070941,Kazan Federal University,Kazan,Russian Federation,"['1706', '1703']",18.466666666666665,0.09270156926406926,0.5065611471861472,0,0.06430868167202572,0.03858520900321544,0.3333333333333333
1467,1498,1498,Monocular Vision Aided Autonomous UAV Navigation in Indoor Corridor Environments,"Deployment of autonomous Unmanned Aerial Vehicles (UAV) in various sectors such as disaster hit environments, industries, agriculture, etc., not only improves productivity but also reduces human intervention resulting in sustainable benefits. In this regard, we present a model for autonomous navigation and collision avoidance of UAVs in GPS-denied corridor environments. In the first stage, we suggest a fast procedure to estimate the set of parallel lines whose intersection would yield the position of the vanishing point (VP) inside the corridor. A suitable measure is then formulated based on the position of VP on the intersecting lines in reference to any of the image boundary axes. The knowledge of VP location alongside the formulated mechanism govern the necessary set of commands to safely navigate the UAV avoiding any collision with the side walls. Furthermore, the relative Euclidean distance scale expansion of matched scale-invariant keypoints in a pair of frames is taken into account to estimate the depth of a frontal obstacle; usually a wall at the end of the corridor. However, turbulence in the UAV arising due to its rotors or other external factors such as wind may introduce uncertainty in depth estimation. It is rectified with the help of a constant velocity aided Kalman filter model. Necessary set of control commands are then generated to avoid the frontal wall before collision. Exhaustive experiments in different corridors reveal the efficacy of the proposed scheme.",60004538,Dalian University of Technology,Dalian,China,"['1703', '1708', '1712']",23.3,0.0818181818181818,0.4643939393939394,1,0.10727969348659004,0.038314176245210725,0.28125
1468,1499,1499,Machine Learning Based Trust Computational Model for IoT Services,"The Internet of Things has facilitated access to a large volume of sensitive information on each participating object in an ecosystem. This imposes many threats ranging from the risks of data management to the potential discrimination enabled by data analytics over delicate information such as locations, interests, and activities. To address these issues, the concept of trust is introduced as an important role in supporting both humans and services to overcome the perception of uncertainty and risks before making any decisions. However, establishing trust in a cyber world is a challenging task due to the volume of diversified influential factors from cyber-physical-systems. Hence, it is essential to have an intelligent trust computation model that is capable of generating accurate and intuitive trust values for prospective actors. Therefore, in this paper, a quantifiable trust assessment model is proposed. Built on this model, individual trust attributes are then calculated numerically. Moreover, a novel algorithm based on machine learning principles is devised to classify the extracted trust features and combine them to produce a final trust value to be used for decision making. Finally, our model's effectiveness is verified through a simulation. The results show that our method has advantages over other aggregation methods.",60028355,Liverpool John Moores University,Liverpool,United Kingdom,"['1703', '1708', '1712']",20.1,0.15634920634920635,0.6589947089947089,1,0.11061946902654868,0.0,0.2927927927927928
1469,1500,1500,Advanced Media-Based Smart Big Data on Intelligent Cloud Systems,"Today's advanced media technology preaches an enthralling time that will enormously bear on daily life. Moreover, the rapid raise of wireless communications and networking will ultimately bring advanced media to our lives anytime, anywhere, and on any device. According to the National Institute of Standards and Technology (NIST), Cloud Computing (CC) is a scheme for enabling convenient, on-demand network access to a shared pool of configurable computing pores (for example networks, applications, storage, servers, and services) which could be promptly foresighted and delivered with minimal management effort or service provider interaction. This paper proposed an efficient algorithm for advanced scalable Media-basedSmart Big Data (3D, Ultra HD) on Intelligent Cloud Computing systems. The proposed encoding algorithmoutperforms the conventional HEVC standard which demonstrated by the performance evaluations. In order to ratify the proposed approach, in addition, a relative study has been carried out. The proposed method could be used and integrated into HEVC, as a Smart Big Data, without violating the standard.",60001086,Panepistimion Makedonias,Thessaloniki,Greece,"['1703', '1708', '1712']",22.857142857142854,0.13142857142857142,0.4266666666666665,1,0.11855670103092783,0.09278350515463918,0.4473684210526316
1470,1501,1501,Sustainable and Efficient Data Collection in Cognitive Radio Sensor Networks,"Cognitive Radio is a promising technology that maximize spectrum efficiency and can apply to Wireless Sensor Networks. This paper proposes a system architecture which introduces enhancements at lower layers of a Software Defined Network of Wireless Sensors Network with Cognitive Radio capabilities for efficient sensors' power management, energy consuming channel handoffs elimination, efficient spectrum brokerage, and QoS provision in terms of data rate to the sensors' applications via the SDN flows. The large Wireless Sensors Network is divided into clusters for power efficiency - as sensor operate in lower power - which connect to a cloud-assisted Central Controller. The protocol encompasses an optimal reinforcement learning scheme for efficient spectrum utilization that enables efficient sensors' data collection, while sustainability issues are satisfied. Software Defined Wireless Sensor Network dynamically adapts to the spectrum and interference conditions on per flow basis and predicts Primary Users' traffic to totally avoid collision with the licensed users. The paper is concentrated on sustainable solutions for sensors' data collection by the cluster heads leveraging the Cognitive Radio Network facilities and taking into account the demands of the applications running on the sensors. The Cognitive Radio Sensor Network is considered as large organized on a local basis to extend networks lifetime and allow resource reuse.",60001086,Panepistimion Makedonias,Thessaloniki,Greece,"['1703', '1708', '1712']",29.57142857142857,0.19107142857142856,0.4821428571428572,1,0.12444444444444444,0.1288888888888889,0.37668161434977576
1471,1502,1502,IBrownout: An Integrated Approach for Managing Energy and Brownout in Container-Based Clouds,"Energy consumption of Cloud data centers has been a major concern of many researchers, and one of the reasons for huge energy consumption of Clouds lies in the inefficient utilization of computing resources. Besides energy consumption, another challenge of data centers is the unexpected loads, which leads to the overloads and performance degradation. Compared with VM consolidation and Dynamic Voltage Frequency Scaling that cannot function well when the whole data center is overloaded, brownout has shown to be a promising technique to handle both overloads and energy consumption through dynamically deactivating application optional components, which are also identified as containers/microservices. In this work, we propose an integrated approach to manage energy consumption and brownout in container-based cloud data centers. We also evaluate our proposed scheduling policies with real traces in a prototype system. The results show that our approach reduces about 40, 20, and 10 percent energy than the approach without power-saving techniques, brownout-overbooking approach and auto-scaling approach, respectively, while ensuring Quality of Service.",60026553,University of Melbourne,Parkville,Australia,"['1703', '1708', '1712']",27.33333333333333,0.15625,0.4466666666666666,1,0.09895833333333333,0.041666666666666664,0.3626373626373626
1472,1503,1503,A Holistic Optimization Framework for Mobile Cloud Task Scheduling,"Mobile cloud computing (MCC) is extensively ubiquitous in the mobile Internet era and embraces complex environments because of the heterogeneity of devices and complexity of communications. Balancing the costs of different influencing objectives (e.g., energy consumption, system reliability, and quality of experience (QoE)) in MCC faces great challenges. This paper focuses on reasonably allocating computational tasks to suitable cores of mobile devices or cloud in MCC to minimize the total energy consumption, and maximize the system reliability and QoE. Concretely, this paper 1 proposes a holistic mobile cloud optimization model including energy consumption, system reliability, and QoE; 2 presents a DVFS-enabled and thermal-aware global energy consumption model which simultaneously considers the synergy of multiple factors concerning mobile devices, cloud, and networks; 3 constructs a tensor-based representation model to comprehensively reflect the complex relationship of multiple influencing factors and cope with their heterogeneity; and 4 proposes a customized optimization framework and two heuristic single-objective optimization (SOO) and triple-objective optimization (TOO) algorithms based on simulated annealing. Experimental results demonstrate that the proposed scheme outperforms the state-of-the-art scheduling schemes in SOO and the Pareto front in TOO can provide appropriate solutions to satisfy different application requirements.",60073572,Jiujiang University,Jiujiang,China,"['1703', '1708', '1712']",38.6,0.11333333333333333,0.4255555555555556,1,0.1148936170212766,0.0425531914893617,0.41818181818181815
1473,1504,1504,A Joint Anypath Routing and Duty-Cycling Model for Sustainable Underwater Sensor Networks,"Recent advancements in underwater wireless sensor networks (UWSNs) are enabling day-one underwater monitoring applications. However, energy efficient and reliable UWSNs must be developed for achieving large scale and sustainable underwater monitoring and exploration applications. In this regard, the use of the underwater acoustic channel poses several daunting challenges. The acoustic channel is energy hungry and has low reliability, which shortens the UWSN lifetime and diminishes the performance of underwater monitoring applications. In the literature, both challenges have been addressed separately by means of duty-cycling and opportunistic routing, respectively. In this paper, we shed light on the symbiotic design of anypath routing and duty-cycling for sustainable UWSNs. We propose novel strobed preamble low power listening (LPL) and low power probing (LPP) methodologies for the design of asynchronous duty-cycling protocols, which symbiotically consider anypath routing for data delivery. Moreover, we develop an analytical framework for the performance evaluation of such a symbiotic design. Numerical results highlight potentials and drawbacks of this proposed approach in different classes of UWSN applications, and provide useful insights for the future symbiotic design of opportunistic routing and duty-cycling protocols for UWSNs.",60030074,Universidade Federal de Minas Gerais,Belo Horizonte,Brazil,"['1703', '1708', '1712']",20.444444444444443,0.07802197802197802,0.3002747252747253,1,0.08256880733944955,0.01834862385321101,0.3701923076923077
1474,1505,1505,Using Energy-Aware Scheduling Weather Forecast Based Harvesting for Reconfigurable Hardware,"Energy is the most limited resource for sustainable systems, especially battery-based systems, such as Wireless Sensor Network (WSN) or Cyber-Physical System (CPS) nodes. Harvesting energy from a deployed environment is proved to be a feasible method to enable a sustainable operation. Meanwhile, field-programmable gate arrays (FPGAs), which are a reconfigurable fabric, are widely used in sustainable systems. Various applications can be configured into FPGA as required. The available energy varies during the harvesting process. Therefore, configuring FPGA to match the processing requirement within the varied energy is an important issue. As opposed to the traditional scheduling methods that solely focus on reducing computational energy, we adapted a weather forecast method in studying the history data to predict the future harvested data in this study. The predicted future harvested energy was then used in energy-based scheduling. Experiment results indicate that reconfigurable hardware can save up to 50 percent energy compared to software-based execution. Using the weather forecasted scheduling method can execute 35 percent more task compared to the past-predict-future method.",60031031,Shandong University,Jinan,China,"['1703', '1708', '1712']",16.9,0.1357142857142857,0.4952380952380953,1,0.15048543689320387,0.05339805825242718,0.390625
1475,1506,1506,Resource Shared Galois Field Computation for Energy Efficient AES/CRC in IoT Applications,"End-to-end encryption and reliability of the transmitted data are essential requirements in the present era of internet enabled smart devices. Adhering to current industry standards, the Advanced Encryption Standard (AES) and Cyclic Redundancy Check (CRC) are the two most utilized methods for ensuring security and reliability. To integrate AES and CRC functionality in ultra-low-power embedded System on Chips (SoCs), dedicated computation engines/co-processors are often used, consuming valuable silicon area and additional battery power. This paper presents the design of an energy-efficient multipurpose encryption engine capable of processing both AES and CRC algorithms using a shared Galois Field Computation Unit (GFCU). By decomposing the necessary Galois Field operations of AES and CRC to their fundamental binary steps, it was possible to identify shared operations in these two algorithms. This approach allowed the development of a resource shared system architecture capable of computing AES-128 and CRC-32 using a single computation unit. The GFCU based design was implemented in an area of 151μm x 151μm in 90nm technology node. The energy consumption of the design operating at 0.8 V supply voltage for a 25.6 Mbps throughput was less than 280pJ and 140pJ for AES-128 encryption and CRC-32, respectively.",60010449,Apple Computer,Cupertino,United States,"['1703', '1708', '1712']",24.375,0.091156462585034,0.4017006802721089,1,0.09523809523809523,0.12554112554112554,0.4398148148148148
1476,1507,1507,SPFC: An Effective Optimization for Vertex-Centric Graph Processing Systems,"The real-world demands of mining big data and smart data of graph structure have led to an active research of distributed graph processing. Many distributed graph processing systems [19] , [22] , [23] adopt a vertex-centric programming paradigm. In these systems, messages are passed between vertices to propagate the latest states. The communication efficiency and the high overhead of synchronization are two key considerations of these systems [8] , [12]. In this paper, we propose a Slow Passing Fast Consuming (SPFC) approach which can effectively improve the overall performance of vertex-centric graph processing systems. In our approach, the message passing is slow but the consuming is fast. More specifically, at the message sender side, priority is given to those smart messages which contribute more to the algorithm convergence, and at the message receiver side, messages are consumed right after arriving without any delay and intermediate buffer. Besides, by using a two-phase termination check protocol, the global synchronous barrier can be completely eliminated. In addition, based on the slow message passing strategy, further performance improvement can be achieved with some accuracy loss by eliminating those messages which are less useful for algorithm convergence. We implement our approach based on Apache Giraph [1] and evaluate it on a 12-machine cluster. The experimental results show that our method can effectively reduce the amount of message traffic and achieve up to an order of magnitude performance improvement compared with Giraph and GraphLab [3].",60015095,Fordham University,New York,United States,"['1703', '1708', '1712']",21.727272727272727,0.1509714285714286,0.4731238095238096,1,0.11228070175438597,0.031578947368421054,0.33574007220216606
1477,1508,1508,Energy-Efficient Scheduling for Real-Time Systems Based on Deep Q-Learning Model,"Energy saving is a critical and challenging issue for real-time systems in embedded devices because of their limited energy supply. To reduce the energy consumption, a hybrid dynamic voltage and frequency scaling (DVFS) scheduling based on Q-learning (QL-HDS) was proposed by combining energy-efficient DVFS techniques. However, QL-HDS discretizes the system state parameters with a certain step size, resulting in a poor distinction of the system states. More importantly, it is difficult for QL-HDS to learn a system for various task sets with a Q-table and limited training sets. In this paper, an energy-efficient scheduling scheme based on deep Q-learning model is proposed for periodic tasks in real-time systems (DQL-EES). Specially, a deep Q-learning model is designed by combining a stacked auto-encoder and a Q-learning model. In the deep Q-learning model, the stacked auto-encoder is used to replace the Q-function for learning the Q-value of each DVFS technology for any system state. Furthermore, a training strategy is devised to learn the parameters of the deep Q-learning model based on the experience replay scheme. Finally, the performance of the proposed scheme is evaluated by comparison with QL-HDS on different simulation task sets. Results demonstrated that the proposed algorithm can save average 4.2\% energy than QL-HDS.",60032048,Saint Francis Xavier University,Antigonish,Canada,"['1703', '1708', '1712']",20.3,0.0012605042016806745,0.5308123249299721,1,0.1111111111111111,0.06296296296296296,0.37554585152838427
1478,1509,1509,A K-Anonymity Based Schema for Location Privacy Preservation,"In recent years, with the development of mobile devices, the location based services (LBSs) have become more and more prevailing and most applications installed on these devices call for location information. Yet, the untrusted LBS provider can collect this location information, which may potentially threaten users' location privacy. In view of this challenge, we propose a two-tier schema for the privacy preservation based on $k-$k-anonymity principle meanwhile reducing the cost for privacy protection. Concretely, we divide the users into groups in order to maximize the privacy level and in each group one proxy is selected to generate dummy locations and share the returned results from LBS provider; then, on each group, an auction mechanism is proposed to determine the payment of each user to the proxy as the compensation, which satisfies budget balance and incentive compatibility. To evalue the performance of the proposed schema, a simulated experiment is conducted.",60117772,"School of Computing and Communications, Lancaster University",Lancaster,United Kingdom,"['1703', '1708', '1712']",29.8,0.275,0.5083333333333333,1,0.13872832369942195,0.028901734104046242,0.28654970760233917
1479,1510,1510,Robust Malware Detection for Internet of (Battlefield) Things Devices Using Deep Eigenspace Learning,"Internet of Things (IoT) in military settings generally consists of a diverse range of Internet-connected devices and nodes (e.g., medical devices and wearable combat uniforms). These IoT devices and nodes are a valuable target for cyber criminals, particularly state-sponsored or nation state actors. A common attack vector is the use of malware. In this paper, we present a deep learning based method to detect Internet Of Battlefield Things (IoBT) malware via the device's Operational Code (OpCode) sequence. We transmute OpCodes into a vector space and apply a deep Eigenspace learning approach to classify malicious and benign applications. We also demonstrate the robustness of our proposed approach in malware detection and its sustainability against junk code insertion attacks. Lastly, we make available our malware sample on Github, which hopefully will benefit future research efforts (e.g., to facilitate evaluation of future malware detection approaches).",60026914,Shiraz University,Shiraz,Iran,"['1703', '1708', '1712']",20.285714285714285,0.01805555555555556,0.2458333333333333,1,0.09411764705882353,0.052941176470588235,0.42771084337349397
1480,1511,1511,Integration of distributed generation and compensating capacitor in radial distribution system via firefly algorithm," All rights reserved.This paper presents an integration of distributed generation and capacitor in radial distribution system via Firefly Algorithm (FA). In this study, the FA is developed in order to determine the optimal location and size for compensation schemes namely distributed generation (DG) and compensating capacitor (CC). The FA which is a meta-heuristic algorithm is inspired by the flashing behavior of fireflies. The proposed technique was tested on IEEE Reliability Test systems namely the IEEE 69-bus and the program was developed using the MATLAB programming software. The results shown a significant reduction in the line losses and voltage profile improvement has been obtained with the installation of distributed generation and capacitor in the system.",60090652,Universiti Malaysia Perlis,Arau,Malaysia,"['1711', '1710', '1708', '1705']",23.0,0.19166666666666665,0.4916666666666667,0,0.11450381679389313,0.0916030534351145,0.3492063492063492
1481,1512,1512,A Tensor Computation and Optimization Model for Cyber-Physical-Social Big Data,"With an objective to provide the proactive and personalized services for human beings, Cyber-Physical-Social Systems (CPSS), which combine the cyber space, physical space, and social space together, need to process the large scale heterogenous data first. Tensor, as an appropriate data representation tool, has been widely used for representation of heterogeneous Cyber-Physical-Social big data. When computationally processing such tensor, many necessary constraints have to be taken into account, e.g., the execution time, energy consumption, economic cost, security as well as reliability. However, the systematic integration of these constraints and then the modelling of general optimization for tensor processing become more challenging. In this paper, with such constraints being considered together, a general model for tensor computation that optimizes the execution time, energy consumption, and economic cost with acceptable security and reliability is proposed. From diverse perspectives of user requirements, a case study for the tree-based distributed High-Order Singular Value Decomposition (HOSVD) is measured. With the focus on multi-objective combination, the experimental results validate the applicability and generality of the proposed model.",60032048,Saint Francis Xavier University,Antigonish,Canada,"['1703', '1708', '1712']",24.42857142857143,0.1498809523809524,0.3985714285714286,1,0.07407407407407407,0.046296296296296294,0.3465346534653465
1482,1513,1513,Wavelength-Reused Hierarchical Optical Network on Chip Architecture for Manycore Processors,"Manycore processor is becoming the mainstream platform for cloud computing applications. However, the design of high-performance and sustainable inter-core communication network is still a challenging problem. Optical Network on Chip (ONoC) is an emerging chip-scale optical communication technology with high bandwidth capacity and energy efficiency. In this paper, we present a Wavelength Reused Hierarchical ONoC architecture, WRH-ONoC. It leverages the nonblocking wavelength-routed λλ-router and hierarchical networking to reuse the limited number of wavelengths. In WRH-ONoC, all the cores are grouped into multiple subsystems, and the cores in the same subsystem are directly interconnected using a λλ-router for nonblocking communication. For inter-subsystem communication, all subsystems are further connected through multiple λλ-routers and gateways in a hierarchical manner. Thus, the available wavelengths can be reused in different λλ-routers. Furthermore, WRHm-ONoC, an efficient extension with multicast ability is also proposed. Given the numbers of cores and available wavelengths, we derive the minimum hardware requirement, the expected end-to-end delay, and the maximum data rate. Theoretical analysis and simulation results indicate WRH-ONoC achieves prominent improvement on the communication performance and sustainability, e.g., 46.0 percent of reduction on zero-load delay and 72.7 percent of improvement on throughput for 400 cores with the modest hardware/energy costs.",60025578,Xidian University,Xi'an,China,"['1703', '1708', '1712']",18.09090909090909,0.14344537815126052,0.43281512605042016,1,0.07335907335907337,0.04633204633204633,0.40707964601769914
1483,1514,1514,Neural Nets via Forward State Transformation and Backward Loss Transformation,"This article studies (multilayer perceptron) neural networks with an emphasis on the transformations involved - both forward and backward - in order to develop a semantic/logical perspective that is in line with standard program semantics. The common two-pass neural network training algorithms make this viewpoint particularly fitting. In the forward direction, neural networks act as state transformers, using Kleisli composition for the multiset monad - for the linear parts of network layers. In the reverse direction, however, neural networks change losses of outputs to losses of inputs, thereby acting like a (real-valued) predicate transformer. In this way, backpropagation is functorial by construction, as shown in other works recently. We illustrate this perspective by training a simple instance of a neural network.",60028928,Research Organization of Information and Systems National Institute of Informatics,Tokyo,Japan,['1700'],20.166666666666668,0.010714285714285716,0.2831632653061225,1,0.0763888888888889,0.041666666666666664,0.34782608695652173
1484,1515,1515,Quantitative Logics for Equivalence of Effectful Programs,"In order to reason about effects, we can define quantitative formulas to describe behavioural aspects of effectful programs. These formulas can for example express probabilities that (or sets of correct starting states for which) a program satisfies a property. Fundamental to this approach is the notion of quantitative modality, which is used to lift a property on values to a property on computations. Taking all formulas together, we say that two terms are equivalent if they satisfy all formulas to the same quantitative degree. Under sufficient conditions on the quantitative modalities, this equivalence is equal to a notion of Abramsky's applicative bisimilarity, and is moreover a congruence. We investigate these results in the context of Levy's call-by-push-value with general recursion and algebraic effects. For example, the results apply to (combinations of) nondeterministic choice, probabilistic choice, global store, and error.",60031106,University of Ljubljana,Ljubljana,Slovenia,['1700'],19.857142857142858,0.07500000000000001,0.2458333333333333,1,0.08383233532934131,0.011976047904191617,0.32298136645962733
1485,1516,1516,Bisimulation Maps in Presheaf Categories,"The category of presheaves on a (small) category is a suitable semantic universe to study behaviour of various dynamical systems. In particular, presheaves can be used to record the executions of a system and their morphisms correspond to simulation maps for various kinds of state-based systems. In this paper, we introduce a notion of bisimulation maps between presheaves (or executions) to capture well known behavioural equivalences in an abstract way. We demonstrate the versatility of this framework by working out the characterisations for standard bisimulation, ?-fair bisimulation, and branching bisimulation.",60020621,FernUniversität in Hagen,Hagen,Germany,['1700'],22.5,0.16666666666666666,0.4833333333333333,1,0.11428571428571428,0.0,0.34951456310679613
1486,1517,1517,Dimensionality Reduction Reconstitution for Extreme Multistability in Memristor-Based Colpitts System,"In this paper, a four-dimensional (4-D) memristor-based Colpitts system is reaped by employing an ideal memristor to substitute the exponential nonlinear term of original three-dimensional (3-D) Colpitts oscillator model, from which the initials-dependent extreme multistability is exhibited by phase portraits and local basins of attraction. To explore dynamical mechanism, an equivalent 3-D dimensionality reduction model is built using the state variable mapping (SVM) method, which allows the implicit initials of the 4-D memristor-based Colpitts system to be changed into the corresponding explicitly initials-related system parameters of the 3-D dimensionality reduction model. The initials-related equilibria of the 3-D dimensionality reduction model are derived and their initials-related stabilities are discussed, upon which the dynamical mechanism is quantitatively explored. Furthermore, the initials-dependent extreme multistability is depicted by two-parameter plots and the coexistence of infinitely many attractors is demonstrated by phase portraits, which is confirmed by PSIM circuit simulations based on a physical circuit.",60104429,Changzhou University,Changzhou,China,['1700'],37.5,0.240625,0.6741071428571429,1,0.11764705882352941,0.026737967914438502,0.38323353293413176
1487,1518,1518,"Taylor Expansion, Finiteness and Strategies","We examine some recent methods introduced to extend Ehrhard and Regnier's result on Taylor expansion: infinite linear combinations of approximants of a lambda-term can be normalized while keeping all coefficients finite. The methods considered allow to extend this result to non-uniform calculi; we show that when focusing on precise reduction strategies, such as Call-By-Value, Call-By-Need, PCF or variants of Call-By-Push-Value, the extension of Ehrhard and Regnier's finiteness result can hold or not, depending on the structure of the original calculus. In particular, we introduce a resource calculus for Call-By-Need, and show that the finiteness result about its Taylor expansion can be derived from our Call-By-Value considerations. We also introduce a resource calculus for a presentation of PCF with an explicit fixpoint construction, and show how it interferes with the finiteness result. We examine then Ehrhard and Guerrieri's Bang Calculus which enjoys some Call-By-Push-Value features in a slightly different presentation.",60123660,Institut de Recherche en Informatique Fondamentale (IRIF),Paris,France,['1700'],29.8,0.15694444444444444,0.5388888888888889,1,0.1407035175879397,0.07035175879396985,0.32934131736526945
1488,1519,1519,Towards a Directed Homotopy Type Theory,"In this paper, we present a directed homotopy type theory for reasoning synthetically about (higher) categories and directed homotopy theory. We specify a new 'homomorphism' type former for Martin-Löf type theory which is roughly analogous to the identity type former originally introduced by Martin-Löf. The homomorphism type former is meant to capture the notions of morphism (from the theory of categories) and directed path (from directed homotopy theory) just as the identity type former is known to capture the notions of isomorphism (from the theory of groupoids) and path (from homotopy theory). Our main result is an interpretation of these homomorphism types into Cat, the category of small categories. There, the interpretation of each homomorphism type homC(a,b) is indeed the set of morphisms between the objects a and b of the category C. We end the paper with an analysis of the interpretation in Cat with which we argue that our homomorphism types are indeed the directed version of Martin-Löf's identity types.",60003500,The Ohio State University,Columbus,United States,['1700'],27.0,0.05254820936639118,0.2579889807162534,1,0.078125,0.052083333333333336,0.2727272727272727
1489,1520,1520,A Denotational Semantics for Low-Level Probabilistic Programs with Nondeterminism,"Probabilistic programming is an increasingly popular formalism for modeling randomness and uncertainty. Designing semantic models for probabilistic programs has been extensively studied, but is technically challenging. Particular complications arise when trying to account for (i) unstructured control-flow, a natural feature in low-level imperative programs; (ii) general recursion, an extensively used programming paradigm; and (iii) nondeterminism, which is often used to represent adversarial actions in probabilistic models, and to support refinement-based development. This paper presents a denotational-semantics framework that supports the three features mentioned above, while allowing nondeterminism to be handled in different ways. To support both probabilistic choice and nondeterministic choice, the semantics is given over control-flow hyper-graphs. The semantics follows an algebraic approach: it can be instantiated in different ways as long as certain algebraic properties hold. In particular, the semantics can be instantiated to support nondeterminism among either program states or state transformers. We develop a new formalization of nondeterminism based on powerdomains over sub-probability kernels. Semantic objects in the powerdomain enjoy a notion we call generalized convexity, which is a generalization of convexity. As an application, the paper sketches an algebraic framework for static analysis of probabilistic programs, which has been proposed in a companion paper.",60101641,"GrammaTech, Inc",Ithaca,United States,['1700'],19.9,0.17399891774891774,0.5162067099567099,1,0.13580246913580246,0.00823045267489712,0.3624454148471616
1490,1521,1521,Asymptotic Behavior of Ruin Probabilities in an Insurance Risk Model with Quasi-Asymptotically Independent or Bivariate Regularly Varying-Tailed Main Claim and By-Claim,"This paper considers a by-claim risk model under the asymptotical independence or asymptotical dependence structure between each main claim and its by-claim. In the presence of heavy-tailed main claims and by-claims, we derive some asymptotic behavior for ruin probabilities.",60089945,Nanjing Audit University,Nanjing,China,['1700'],19.5,0.16666666666666666,0.3333333333333333,1,0.04,0.0,0.2857142857142857
1491,1522,1522,Learning along a Channel: The Expectation part of Expectation-Maximisation,"This paper first investigates a form of frequentist learning that is often called Maximal Likelihood Estimation (MLE). It is redescribed as a natural transformation from multisets to distributions that commutes with marginalisation and disintegration. It forms the basis for the next, main topic: learning of hidden states, which is reformulated as learning along a channel. This topic requires a fundamental look at what data is and what its validity is in a particular state. The paper distinguishes two forms, denoted as 'M' for 'multiple states' and 'C' for 'copied states'. It is shown that M and C forms exist for validity of data, for learning from data, and for learning along a channel. This M/C distinction allows us to capture two completely different examples from the literature which both claim to be instances of Expectation-Maximisation.",60016529,Radboud University Nijmegen,Nijmegen,Netherlands,['1700'],19.285714285714285,0.06458333333333333,0.29166666666666663,1,0.1111111111111111,0.05555555555555555,0.36129032258064514
1492,1523,1523,Condition/Decision Duality and the Internal Logic of Extensive Restriction Categories,"In flowchart languages, predicates play an interesting double role. In the textual representation, they are often presented as conditions, i.e., expressions which are easily combined with other conditions (often via Boolean combinators) to form new conditions, though they only play a supporting role in aiding branching statements choose a branch to follow. On the other hand, in the graphical representation they are typically presented as decisions, intrinsically capable of directing control flow yet mostly oblivious to Boolean combination. While categorical treatments of flowchart languages are abundant, none of them provide a treatment of this dual nature of predicates. In the present paper, we argue that extensive restriction categories are precisely categories that capture such a condition/decision duality, by means of morphisms which, coincidentally, are also called decisions. Further, we show that having these categorical decisions amounts to having an internal logic: Analogous to how subobjects of an object in a topos form a Heyting algebra, we show that decisions on an object in an extensive restriction category form a De Morgan quasilattice, the algebraic structure associated with the (three-valued) weak Kleene logic K3w. Full classical propositional logic can be recovered by restricting to total decisions, yielding extensive categories in the usual sense, and confirming (from a different direction) a result from effectus theory that predicates on objects in extensive categories form Boolean algebras. As an application, since (categorical) decisions are partial isomorphisms, this approach provides naturally reversible models of classical propositional logic and weak Kleene logic.",60030840,Københavns Universitet,Copenhagen,Denmark,['1700'],30.75,0.06300097751710655,0.4313294232649073,1,0.10139860139860139,0.024475524475524476,0.3546099290780142
1493,1524,1524,Optimizing the Pairs-Trading Strategy Using Deep Reinforcement Learning with Trading and Stop-Loss Boundaries,"Many researchers have tried to optimize pairs trading as the numbers of opportunities for arbitrage profit have gradually decreased. Pairs trading is a market-neutral strategy; it profits if the given condition is satisfied within a given trading window, and if not, there is a risk of loss. In this study, we propose an optimized pairs-trading strategy using deep reinforcement learning-particularly with the deep Q-network-utilizing various trading and stop-loss boundaries. More specifically, if spreads hit trading thresholds and reverse to the mean, the agent receives a positive reward. However, if spreads hit stop-loss thresholds or fail to reverse to the mean after hitting the trading thresholds, the agent receives a negative reward. The agent is trained to select the optimum level of discretized trading and stop-loss boundaries given a spread to maximize the expected sum of discounted future profits. Pairs are selected from stocks on the S&P 500 Index using a cointegration test. We compared our proposed method with traditional pairs-trading strategies which use constant trading and stop-loss boundaries. We find that our proposed model is trained well and outperforms traditional pairs-trading strategies.",60016912,Yonsei University,Seoul,South Korea,['1700'],20.222222222222218,0.02790404040404041,0.5488215488215489,1,0.167420814479638,0.01809954751131222,0.3482587064676617
1494,1525,1525,Bisimulation for Feller-Dynkin Processes,"Bisimulation is a concept that captures behavioural equivalence. It has been studied extensively on nonprobabilistic systems and on discrete-time Markov processes and on so-called continuous-time Markov chains. In the latter, time is continuous but the evolution still proceeds in jumps. We propose two definitions of bisimulation on continuous-time stochastic processes where the evolution is a flow through time. We show that they are equivalent and we show that when restricted to discrete-time, our concept of bisimulation encompasses the standard discrete-time concept. The concept we introduce is not a straightforward generalization of discrete-time concepts.",60002494,McGill University,Montreal,Canada,['1700'],15.5,-0.046875,0.17708333333333331,1,0.08695652173913043,0.02608695652173913,0.3564356435643564
1495,1526,1526,On Bisimilarity in Lambda Calculi with Continuous Probabilistic Choice,"Applicative bisimiliarity is a coinductively-defined program equivalence in which programs are tested as argument-passing processes. Starting with the seminal work by Abramsky, applicative bisimiliarity has been proved to be a powerful technique for higher-order program equivalence. Recently, applicative bisimiliarity has also been generalised to lambda calculi with algebraic effects, and with discrete probabilistic choice in particular. In this paper, we show that applicative bisimiliarity behaves well in a lambda-calculus in which probabilistic choice is available in a more general form, namely through an operator for sampling of values from continuous distributions. Our main result shows that applicative bisimilarity is sound for contextual equivalence, hence providing a new reasoning principle for higher-order probabilistic languages.",60121727,IMDEA Software Institute,Pozuelo de Alarcon,Spain,['1700'],22.6,0.29426406926406923,0.4658008658008658,1,0.07462686567164178,0.014925373134328358,0.29838709677419356
1496,1527,1527,Deriving Logical Relations from Interpretations of Predicate Logic,"This paper extends the results of Hermida's thesis about logical predicates to more general logical relations and a wider collection of types. The extension of type constructors from types to logical relations is derived from an interpretation of those constructors on a model of predicate logic. This is then further extended to n-ary relations by pullback. Hermida's theory shows how right adjoints in the category of fibrations are composed from a combination of Cartesian lifting and a local adjunction. This result is generalised to make it more applicable to left adjoints, and then shown to be stable under pullback, deriving an account of n-ary relations from standard predicate logic. A brief discussion of lifting monads to predicates includes the existence of an initial such lifting, generalising existing results.",60022109,"Queen Mary, University of London",London,United Kingdom,['1700'],21.33333333333333,0.1489795918367347,0.2942176870748299,1,0.09090909090909091,0.02097902097902098,0.302158273381295
1497,1528,1528,The Construction of Set-Truncated Higher Inductive Types,"We construct finitary set-truncated higher inductive types (HITs) from quotients and the propositional truncation. For that, we first define signatures as a modification of the schema by Basold et al., and we show they give rise to univalent categories of algebras in both sets and setoids. To interpret HITs, we use the well-known method of initial algebra semantics. The desired algebra is obtained by lifting the quotient adjunction to the level of algebras and adapting Dybjer's and Moeneclaey's interpretation of HITs in setoids. From this construction, we conclude that the equality types of HITs are freely generated and that HITs are unique. The results are formalized in the UniMath library.",60016529,Radboud University Nijmegen,Nijmegen,Netherlands,['1700'],18.33333333333333,0.255,0.5266666666666666,1,0.11627906976744186,0.08527131782945736,0.3709677419354839
1498,1529,1529,The Effects of Effects on Constructivism,"It is commonly understood that Countable Choice holds constructively due to the underlying computational nature of constructivism. However, in this paper we demonstrate that invoking different notions of computation result in radically different behaviors regarding Countable Choice. In particular, we illustrate that, although deterministic computation guarantees Countable Choice, non-deterministic computation can negate Countable Choice. We then further show that using stateful computation can restore Countable Choice even in the presence of non-determinism. This finding suggests that much of the modern discourse of constructivism assumes a deterministic underlying computational system, despite non-determinism being a fundamental aspect of modern-day computation.",60007776,Cornell University,Ithaca,United States,['1700'],19.6,0.01770833333333334,0.4260416666666667,1,0.13793103448275862,0.06896551724137931,0.3425925925925926
1499,1530,1530,"From Global to Local State, Coalgebraically and Compositionally","We describe a type theory or metalanguage for constructing and reasoning about higher-order programs with global and local state, and its categorical model. This provides an encapsulation primitive for abstracting global state and making it local to an object, so that it is passed only between its invocations. Our calculus and its semantics extend the interpretation of lambda-terms in a Cartesian closed category with a monoidal action on a category of evaluation contexts - the sequoid - which is dual to the action of the function type. This gives an interpretation of a new type constructor which allows the representation of both global state - via ""state-passing-style"" interpretation which uses it to represent output states - and local state, via encapsulation, which corresponds to the unique map into a final coalgebra for the sequoid. This provides the equational theory of our calculus with a coinduction rule for proving equivalence between objects with local state. We show that this theory is sound and complete with respect to the categorical semantics by constructing a term model and we show that it is consistent by giving a concrete example based on a category of games and strategies previously used to interpret general references.",60030480,University of Bath,Bath,United Kingdom,['1700'],33.333333333333336,0.06973484848484847,0.2885606060606061,1,0.10454545454545454,0.0,0.22641509433962265
1500,1531,1531,Pix2Vox: Context-aware 3D reconstruction from single and multi-view images,"Recovering the 3D representation of an object from single-view or multi-view RGB images by deep neural networks has attracted increasing attention in the past few years. Several mainstream works (e.g., 3D-R2N2) use recurrent neural networks (RNNs) to fuse multiple feature maps extracted from input images sequentially. However, when given the same set of input images with different orders, RNN-based approaches are unable to produce consistent reconstruction results. Moreover, due to long-term memory loss, RNNs cannot fully exploit input images to refine reconstruction results. To solve these problems, we propose a novel framework for single-view and multi-view 3D reconstruction, named Pix2Vox. By using a well-designed encoder-decoder, it generates a coarse 3D volume from each input image. Then, a context-aware fusion module is introduced to adaptively select high-quality reconstructions for each part (e.g., table legs) from different coarse 3D volumes to obtain a fused 3D volume. Finally, a refiner further refines the fused 3D volume to generate the final output. Experimental results on the ShapeNet and Pix3D benchmarks indicate that the proposed Pix2Vox outperforms state-of-the-arts by a large margin. Furthermore, the proposed method is 24 times faster than 3D-R2N2 in terms of backward inference time. The experiments on ShapeNet unseen 3D categories have shown the superior generalization abilities of our method.",60019616,Harbin Institute of Technology,Harbin,China,"['1712', '1707']",19.0,0.009962406015037594,0.443609022556391,1,0.10780669144981413,0.026022304832713755,0.4309623430962343
1501,1532,1532,Joint prediction for kinematic trajectories in vehicle-pedestrian-mixed scenes,"Trajectory prediction for objects is challenging and critical for various applications (e.g., autonomous driving, and anomaly detection). Most of the existing methods focus on homogeneous pedestrian trajectories prediction, where pedestrians are treated as particles without size. However, they fall short of handling crowded vehicle-pedestrian-mixed scenes directly since vehicles, limited with kinematics in reality, should be treated as rigid, non-particle objects ideally. In this paper, we tackle this problem using separate LSTMs for heterogeneous vehicles and pedestrians. Specifically, we use an oriented bounding box to represent each vehicle, calculated based on its position and orientation, to denote its kinematic trajectories. We then propose a framework called VP-LSTM to predict the kinematic trajectories of both vehicles and pedestrians simultaneously. In order to evaluate our model, a large dataset containing the trajectories of both vehicles and pedestrians in vehicle-pedestrian-mixed scenes is specially built. Through comparisons between our method with state-of-the-art approaches, we show the effectiveness and advantages of our method on kinematic trajectories prediction in vehicle-pedestrian-mixed scenes.",60030904,Institute of Computing Technology Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.5,0.2636363636363637,0.5766233766233767,1,0.11961722488038277,0.009569377990430622,0.3850267379679144
1502,1533,1533,Variable rate deep image compression with a conditional autoencoder,"In this paper, we propose a novel variable-rate learned image compression framework with a conditional autoencoder. Previous learning-based image compression methods mostly require training separate networks for different compression rates so they can yield compressed images of varying quality. In contrast, we train and deploy only one variable-rate image compression network implemented with a conditional autoencoder. We provide two rate control parameters, i.e., the Lagrange multiplier and the quantization bin size, which are given as conditioning variables to the network. Coarse rate adaptation to a target is performed by changing the Lagrange multiplier, while the rate can be further fine-tuned by adjusting the bin size used in quantizing the encoded representation. Our experimental results show that the proposed scheme provides a better rate-distortion trade-off than the traditional variable-rate image compression codecs such as JPEG2000 and BPG. Our model also shows comparable and sometimes better performance than the state-of-the-art learned image compression models that deploy multiple networks trained for varying rates.",60010484,Samsung Group,Suwon,South Korea,"['1712', '1707']",22.857142857142854,0.11944444444444445,0.4930555555555555,1,0.15025906735751296,0.031088082901554404,0.3352601156069364
1503,1534,1534,Citizen satisfaction with online passport service innovation in Indonesia within an electronic governance perspective,"This research investigated, measured, analyzed and explained citizen satisfaction with the online passport application service innovation introduced by the Immigration Office of East Java Immigration Area. In addition, this research also evaluated which types of innovation (technology, access, process, and product and payment method) had the strongest and weakest influence on citizen satisfaction. This research was conducted using a quantitative method, allowing researchers to systematically measure, analyze and explain the effect of the online passport application service on citizen satisfaction. The population for this research included all online passport applicants determined by the quota of each office in the study (189,000, applicants per year). A total of 250 samples were selected based on Slovin’s formula. This research was conducted over 6 months in Immigration Office Class 1 of Surabaya, Immigration Office Class 1 of Malang and Immigration Office Class 2 of Blitar. Research data were analyzed using product moment analysis in order to investigate the partial and multiple regression of the independent variable (technology, access, process, product and payment method) X toward the dependent variable (citizen satisfaction) Y. The results of statistical tests showed that of the innovations studied (technology, access, process, product and payment method) had both partial and multiple contributions and a significant effect on citizen satisfaction. The originality of this research lies on the fact that both national and international-scale research on the contribution of five innovations (technology, access, process, product and payment method) toward citizen satisfaction when applying online for a passport had not been conducted before.",60069392,Brawijaya University,Malang,Indonesia,['1706'],27.88888888888889,0.025,0.3357142857142857,1,0.08532423208191127,0.07167235494880546,0.3515358361774744
1504,1535,1535,Attacking optical flow,"Deep neural nets achieve state-of-the-art performance on the problem of optical flow estimation. Since optical flow is used in several safety-critical applications like self-driving cars, it is important to gain insights into the robustness of those techniques. Recently, it has been shown that adversarial attacks easily fool deep neural networks to misclassify objects. The robustness of optical flow networks to adversarial attacks, however, has not been studied so far. In this paper, we extend adversarial patch attacks to optical flow networks and show that such attacks can compromise their performance. We show that corrupting a small patch of less than 1% of the image size can significantly affect optical flow estimates. Our attacks lead to noisy flow estimates that extend significantly beyond the region of the attack, in many cases even completely erasing the motion of objects in the scene. While networks using an encoder-decoder architecture are very sensitive to these attacks, we found that networks using a spatial pyramid architecture are less affected. We analyse the success and failure of attacking both architectures by visualizing their feature maps and comparing them to classical optical flow techniques which are robust to these attacks. We also demonstrate that such attacks are practical by placing a printed pattern into real scenes.",60030569,Max Planck Institute for Intelligent Systems,Tubingen,Germany,"['1712', '1707']",20.9,0.09587301587301586,0.4603174603174604,1,0.12133891213389121,0.0,0.31277533039647576
1505,1536,1536,Fine-grained action retrieval through multiple parts-of-speech embeddings,"We address the problem of cross-modal fine-grained action retrieval between text and video. Cross-modal retrieval is commonly achieved through learning a shared embedding space, that can indifferently embed modalities. In this paper, we propose to enrich the embedding by disentangling parts-of-speech (PoS) in the accompanying captions. We build a separate multi-modal embedding space for each PoS tag. The outputs of multiple PoS embeddings are then used as input to an integrated multi-modal space, where we perform action retrieval. All embeddings are trained jointly through a combination of PoS-aware and PoS-agnostic losses. Our proposal enables learning specialised embedding spaces that offer multiple views of the same embedded entities. We report the first retrieval results on fine-grained actions for the large-scale EPIC dataset, in a generalised zero-shot setting. Results show the advantage of our approach for both video-to-text and text-to-video action retrieval. We also demonstrate the benefit of disentangling the PoS for the generic task of cross-modal video retrieval on the MSR-VTT dataset.",60020650,University of Bristol,Bristol,United Kingdom,"['1712', '1707']",16.1,0.035,0.16583333333333333,1,0.13145539906103287,0.03755868544600939,0.4011299435028249
1506,1537,1537,End-to-end learning of representations for asynchronous event-based data,"Event cameras are vision sensors that record asynchronous streams of per-pixel brightness changes, referred to as 'events'. They have appealing advantages over frame based cameras for computer vision, including high temporal resolution, high dynamic range, and no motion blur. Due to the sparse, non-uniform spatio-temporal layout of the event signal, pattern recognition algorithms typically aggregate events into a grid-based representation and subsequently process it by a standard vision pipeline, e.g., Convolutional Neural Network (CNN). In this work, we introduce a general framework to convert event streams into grid-based representations by means of strictly differentiable operations. Our framework comes with two main advantages: (i) allows learning the input event representation together with the task dedicated network in an end to end manner, and (ii) lays out a taxonomy that unifies the majority of extant event representations in the literature and identifies novel ones. Empirically, we show that our approach to learning the event representation end-to-end yields an improvement of approximately 12% on optical flow estimation and object recognition over state-of-the-art methods.",60030838,Ryerson University,Toronto,Canada,"['1712', '1707']",28.33333333333333,-0.023461538461538457,0.4003846153846154,1,0.09216589861751152,0.018433179723502304,0.3622448979591837
1507,1538,1538,CAMP: Cross-modal adaptive message passing for text-image retrieval,"Text-image cross-modal retrieval is a challenging task in the field of language and vision. Most previous approaches independently embed images and sentences into a joint embedding space and compare their similarities. However, previous approaches rarely explore the interactions between images and sentences before calculating similarities in the joint space. Intuitively, when matching between images and sentences, human beings would alternatively attend to regions in images and words in sentences, and select the most salient information considering the interaction between both modalities. In this paper, we propose Cross-modal Adaptive Message Passing (CAMP), which adaptively controls the information flow for message passing across modalities. Our approach not only takes comprehensive and fine-grained cross-modal interactions into account, but also properly handles negative pairs and irrelevant information with an adaptive gating scheme. Moreover, instead of conventional joint embedding approaches for text-image matching, we infer the matching score based on the fused features, and propose a hardest negative binary cross-entropy loss for training. Results on COCO and Flickr30k significantly surpass state-of-the-art methods, demonstrating the effectiveness of our approach.",60013789,Beihang University,Beijing,China,"['1712', '1707']",21.625,0.039920634920634926,0.506031746031746,1,0.10747663551401869,0.02336448598130841,0.37628865979381443
1508,1539,1539,Changing technological environments: Impact and influences on youth in Thane city," One needs to understand the effects it has on the psychology and perceptions of such students in the age group of 18-24 and the effects it has on their overall mental wellbeing and health. What needs to be examined is the extent and effect of the influence, its pros and cons, its impact on the youth and identification of specific issues so as to aid in the process of finding ways and means to tackle a phenomenon that is here to stay.",60031475,Savitribai Phule Pune University,Pune MH,India,['1706'],41.5,-0.025,0.20625,0,0.10112359550561797,0.0,0.19767441860465115
1509,1540,1540,Recognizing part attributes with insufficient data,"Recognizing the attributes of objects and their parts is central to many computer vision applications. Although great progress has been made to apply object-level recognition, recognizing the attributes of parts remains less applicable since the training data for part attributes recognition is usually scarce especially for internet-scale applications. Furthermore, most existing part attribute recognition methods rely on the part annotations which are more expensive to obtain. In order to solve the data insufficiency problem and get rid of dependence on the part annotation, we introduce a novel Concept Sharing Network (CSN) for part attribute recognition. A great advantage of CSN is its capability of recognizing the part attribute (a combination of part location and appearance pattern) that has insufficient or zero training data, by learning the part location and appearance pattern respectively from the training data that usually mix them in a single label. Extensive experiments on CUB, Celeb A, and a newly proposed human attribute dataset demonstrate the effectiveness of CSN and its advantages over other methods, especially for the attributes with few training samples. Further experiments show that CSN can also perform zero-shot part attribute recognition.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",26.857142857142854,0.08366341991341994,0.4346915584415584,1,0.09433962264150944,0.04716981132075472,0.28640776699029125
1510,1541,1541,Simultaneous multi-view instance detection with learned geometric soft-constraints,"We propose to jointly learn multi-view geometry and warping between views of the same object instances for robust cross-view object detection. What makes multi-view object instance detection difficult are strong changes in viewpoint, lighting conditions, high similarity of neighbouring objects, and strong variability in scale. By turning object detection and instance re-identification in different views into a joint learning task, we are able to incorporate both image appearance and geometric soft constraints into a single, multi-view detection process that is learnable end-to-end. We validate our method on a new, large data set of street-level panoramas of urban objects and show superior performance compared to various baselines. Our contribution is threefold: A large-scale, publicly available data set for multi-view instance detection and re-identification; an annotation tool custom-tailored for multi-view instance detection; and a novel, holistic multi-view instance detection and re-identification method that jointly models geometry and appearance across views.",60027031,Institut de Recherche en Informatique et Systèmes Aléatoires,Rennes,France,"['1712', '1707']",29.6,0.16705916305916305,0.506937950937951,1,0.05670103092783505,0.0,0.3048780487804878
1511,1542,1542,CIIdefence: Defeating adversarial attacks by fusing class-specific image inpainting and image denoising,"This paper presents a novel approach for protecting deep neural networks from adversarial attacks, i.e., methods that add well-crafted imperceptible modifications to the original inputs such that they are incorrectly classified with high confidence. The proposed defence mechanism is inspired by the recent works mitigating the adversarial disturbances by the means of image reconstruction and denoising. However, unlike the previous works, we apply the reconstruction only for small and carefully selected image areas that are most influential to the current classification outcome. The selection process is guided by the class activation map responses obtained for multiple top-ranking class labels. The same regions are also the most prominent for the adversarial perturbations and hence most important to purify. The resulting inpainting task is substantially more tractable than the full image reconstruction, while still being able to prevent the adversarial attacks. Furthermore, we combine the selective image inpainting with wavelet based image denoising to produce a non differentiable layer that prevents attacker from using gradient backpropagation. Moreover, the proposed nonlinearity cannot be easily approximated with simple differentiable alternative as demonstrated in the experiments with Backward Pass Differentiable Approximation (BPDA) attack. Finally, we experimentally show that the proposed Class-specific Image Inpainting Defence (CIIDefence) is able to withstand several powerful adversarial attacks including the BPDA. The obtained results are consistently better compared to the other recent defence approaches.",60104350,Indian Institute of Technology Indore,Indore,India,"['1712', '1707']",22.4,0.17588888888888887,0.5082380952380954,1,0.13043478260869565,0.023715415019762844,0.3360323886639676
1512,1543,1543,Object guided external memory network for video object detection,"Video object detection is more challenging than image object detection because of the deteriorated frame quality. To enhance the feature representation, state-of-the-art methods propagate temporal information into the deteriorated frame by aligning and aggregating entire feature maps from multiple nearby frames. However, restricted by feature map's low storage-efficiency and vulnerable content-address allocation, long-term temporal information is not fully stressed by these methods. In this work, we propose the first object guided external memory network for online video object detection. Storage-efficiency is handled by object guided hard-attention to selectively store valuable features, and long-term information is protected when stored in an addressable external data matrix. A set of read/write operations are designed to accurately propagate/allocate and delete multi-level memory feature under object guidance. We evaluate our method on the ImageNet VID dataset and achieve state-of-the-art performance as well as good speed-accuracy tradeoff. Furthermore, by visualizing the external memory, we show the detailed object-level reasoning process across frames.",60029738,Queen's University Belfast,Belfast,United Kingdom,"['1712', '1707']",19.5,0.17307692307692307,0.4262820512820512,1,0.11165048543689321,0.014563106796116505,0.3430232558139535
1513,1544,1544,Spatial correspondence with generative adversarial network: Learning depth from monocular videos,"Depth estimation from monocular videos has important applications in many areas such as autonomous driving and robot navigation. It is a very challenging problem without knowing the camera pose since errors in camera-pose estimation can significantly affect the video-based depth estimation accuracy. In this paper, we present a novel SC-GAN network with end-to-end adversarial training for depth estimation from monocular videos without estimating the camera pose and pose change over time. To exploit cross-frame relations, SC-GAN includes a spatial correspondence module which uses Smolyak sparse grids to efficiently match the features across adjacent frames, and an attention mechanism to learn the importance of features in different directions. Furthermore, the generator in SC-GAN learns to estimate depth from the input frames, while the discriminator learns to distinguish between the ground-truth and estimated depth map for the reference frame. Experiments on the KITTI and Cityscapes datasets show that the proposed SC-GAN can achieve much more accurate depth maps than many existing state-of-the-art methods on monocular videos.",60029306,Wuhan University,Wuhan,China,"['1712', '1707']",27.33333333333333,0.3386363636363636,0.618939393939394,1,0.11442786069651742,0.05472636815920398,0.32571428571428573
1514,1545,1545,Efficient and robust registration on the 3D special euclidean group,"We present a robust, fast and accurate method for registration of 3D scans. Using correspondences, our method optimizes a robust cost function on the intrinsic representation of rigid motions, i.e., the Special Euclidean group SE(3). We exploit the geometric properties of Lie groups as well as the robustness afforded by an iteratively reweighted least squares optimization. We also generalize our approach to a joint multiview method that simultaneously solves for the registration of a set of scans. Our approach significantly outperforms the state-of-the-art robust 3D registration method based on a line process in terms of both speed and accuracy. We show that this line process method is a special case of our principled geometric solution. Finally, we also present scenarios where global registration based on feature correspondences fails but multiview ICP based on our robust motion estimation is successful.",60020304,University of Maryland,College Park,United States,"['1712', '1707']",19.857142857142858,0.13660714285714287,0.491765873015873,1,0.10126582278481013,0.0379746835443038,0.3181818181818182
1515,1546,1546,Multi vehicle speed detection using euclidean distance based on video processing," All rights reserved.One component of smart city is smart transportation, known as Intelligent Transportation Systems (ITS). In this study, we discuss the estimation of moving vehicle speed based on video processing using the Euclidean Distance method. In this study, we examine the effect of camera angles on the video acquisition to speed estimation accuracy. In addition, Region of Interest (ROI) will be designed into three parts to determine which area is the most appropriate to be chosen, so that the estimated vehicle speed will be better. These approaches have never been studied by previous researchers. The separation between the background and foreground is conducted using Gaussian Mixture Models method. By comparing the displacement distance and the number of frames per second (fps), we obtain speed estimate for each vehicle. According to the experimental results, our system can estimate the speed of the vehicle with an accuracy of 99.38%.",60070707,Institut Teknologi Sepuluh Nopember,Surabaya,Indonesia,"['1701', '1712', '1710', '1708', '1705']",18.625,0.2957671957671958,0.4724867724867725,0,0.1329479768786127,0.057803468208092484,0.3235294117647059
1516,1547,1547,Real-time collaborative annotation system supporting separation of content and annotation,"In earlier collaborative annotation system, the details of all comments were presented in the form of images and were marked directly on the contents. This approach may cause visual confusion no matter what style people choose to display annotations by overlaying contents or by overlapping other comments. This article introduces a new annotation display model to separate contents and annotations, and the MPSAC (Multi-processing and Separation of Annotation and Content) strategy was presented to achieve the consistency maintenance of different collaborative sites based on this model. With the foundation of controlling executive operations’ effect and maintaining the consistency of annotations, the strategy discovers and resolves the collision problem among overlapped annotations and provide a better interactive experience for users. The feasibility and correctness of this strategy were verified by case analysis and CoNote model system at the end of this paper.",60008691,University of Shanghai for Science and Technology,Shanghai,China,['1700'],28.2,0.08892045454545455,0.4286931818181817,1,0.11688311688311688,0.03896103896103896,0.2894736842105263
1517,1548,1548,Learning joint 2D-3D representations for depth completion,"In this paper, we tackle the problem of depth completion from RGBD data. Towards this goal, we design a simple yet effective neural network block that learns to extract joint 2D and 3D features. Specifically, the block consists of two domain-specific sub-networks that apply 2D convolution on image pixels and continuous convolution on 3D points, with their output features fused in image space. We build the depth completion network simply by stacking the proposed block, which has the advantage of learning hierarchical representations that are fully fused between 2D and 3D spaces at multiple levels. We demonstrate the effectiveness of our approach on the challenging KITTI depth completion benchmark and show that our approach outperforms the state-of-the-art.",60016849,University of Toronto,Toronto,Canada,"['1712', '1707']",23.4,0.22000000000000006,0.5028571428571429,1,0.11678832116788321,0.014598540145985401,0.3228346456692913
1518,1549,1549,CompenNet++: End-to-end full projector compensation,"Full projector compensation aims to modify a projector input image such that it can compensate for both geometric and photometric disturbance of the projection surface. Traditional methods usually solve the two parts separately, although they are known to correlate with each other. In this paper, we propose the first end-to-end solution, named CompenNet++, to solve the two problems jointly. Our work non-trivially extends CompenNet, which was recently proposed for photometric compensation with promising performance. First, we propose a novel geometric correction subnet, which is designed with a cascaded coarse-to-fine structure to learn the sampling grid directly from photometric sampling images. Second, by concatenating the geometric correction subset with CompenNet, CompenNet++ accomplishes full projector compensation and is end-to-end trainable. Third, after training, we significantly simplify both geometric and photometric compensation parts, and hence largely improves the running time efficiency. Moreover, we construct the first setup-independent full compensation benchmark to facilitate the study on this topic. In our thorough experiments, our method shows clear advantages over previous arts with promising compensation quality and meanwhile being practically convenient.",60030398,Temple University,Philadelphia,United States,"['1712', '1707']",19.444444444444443,0.1223809523809524,0.4014285714285714,1,0.11682242990654206,0.014018691588785047,0.30303030303030304
1519,1550,1550,Phrase localization without paired training examples,"Localizing phrases in images is an important part of image understanding and can be useful in many applications that require mappings between textual and visual information. Existing work attempts to learn these mappings from examples of phrase-image region correspondences (strong supervision) or from phrase-image pairs (weak supervision). We postulate that such paired annotations are unnecessary, and propose the first method for the phrase localization problem where neither training procedure nor paired, task-specific data is required. Our method is simple but effective: We use off-the-shelf approaches to detect objects, scenes and colours in images, and explore different approaches to measure semantic similarity between the categories of detected visual elements and words in phrases. Experiments on two well-known phrase localization datasets show that this approach surpasses all weakly supervised methods by a large margin and performs very competitively to strongly supervised methods, and can thus be considered a strong baseline to the task. The non-paired nature of our method makes it applicable to any domain and where no paired phrase localization annotation is available.",60015150,Imperial College London,London,United Kingdom,"['1712', '1707']",28.66666666666667,0.15864661654135334,0.5036340852130325,1,0.1188118811881188,0.0,0.31382978723404253
1520,1551,1551,Clustered object detection in aerial images,"Detecting objects in aerial images is challenging for at least two reasons: (1) target objects like pedestrians are very small in pixels, making them hardly distinguished from surrounding background; and (2) targets are in general sparsely and non-uniformly distributed, making the detection very inefficient. In this paper, we address both issues inspired by observing that these targets are often clustered. In particular, we propose a Clustered Detection (ClusDet) network that unifies object clustering and detection in an end-to-end framework. The key components in ClusDet include a cluster proposal sub-network (CPNet), a scale estimation sub-network (ScaleNet), and a dedicated detection network (DetecNet). Given an input image, CPNet produces object cluster regions and ScaleNet estimates object scales for these regions. Then, each scale-normalized cluster region is fed into DetecNet for object detection. ClusDet has several advantages over previous solutions: (1) it greatly reduces the number of chips for final object detection and hence achieves high running time efficiency, (2) the cluster-based scale estimation is more accurate than previously used single-object based ones, hence effectively improves the detection for small objects, and (3) the final DetecNet is dedicated for clustered regions and implicitly models the prior context information so as to boost detection accuracy. The proposed method is tested on three popular aerial image datasets including VisDrone, UAVDT and DOTA. In all experiments, ClusDet achieves promising performance in comparison with state-of-the-art detectors.",60030398,Temple University,Philadelphia,United States,"['1712', '1707']",25.444444444444446,0.04902777777777778,0.5813194444444444,1,0.11564625850340136,0.05102040816326531,0.4117647058823529
1521,1552,1552,Multi-view stereo by temporal nonparametric fusion,"We propose a novel idea for depth estimation from multi-view image-pose pairs, where the model has capability to leverage information from previous latent-space encodings of the scene. This model uses pairs of images and poses, which are passed through an encoder-decoder model for disparity estimation. The novelty lies in soft-constraining the bottleneck layer by a nonparametric Gaussian process prior. We propose a pose-kernel structure that encourages similar poses to have resembling latent spaces. The flexibility of the Gaussian process (GP) prior provides adapting memory for fusing information from nearby views. We train the encoder-decoder and the GP hyperparameters jointly end-to-end. In addition to a batch method, we derive a lightweight estimation scheme that circumvents standard pitfalls in scaling Gaussian process inference, and demonstrate how our scheme can run in real-time on smart devices.",60103653,Aalto University,Espoo,Finland,"['1712', '1707']",19.0,0.007936507936507936,0.2015873015873016,1,0.12650602409638553,0.012048192771084338,0.3493150684931507
1522,1553,1553,Face de-occlusion using 3D morphable model and generative adversarial network,"In recent decades, 3D morphable model (3DMM) has been commonly used in image-based photorealistic 3D face reconstruction. However, face images are often corrupted by serious occlusion by non-face objects including eyeglasses, masks, and hands. Such objects block the correct capture of landmarks and shading information. Therefore, the reconstructed 3D face model is hardly reusable. In this paper, a novel method is proposed to restore de-occluded face images based on inverse use of 3DMM and generative adversarial network. We utilize the 3DMM prior to the proposed adversarial network and combine a global and local adversarial convolutional neural network to learn face de-occlusion model. The 3DMM serves not only as geometric prior but also proposes the face region for the local discriminator. Experiment results confirm the effectiveness and robustness of the proposed algorithm in removing challenging types of occlusions with various head poses and illumination. Furthermore, the proposed method reconstructs the correct 3D face model with de-occluded textures.",60028876,"Inha University, Incheon",Incheon,South Korea,"['1712', '1707']",17.333333333333332,-0.032692307692307694,0.3814102564102564,1,0.11413043478260869,0.021739130434782608,0.39655172413793105
1523,1554,1554,Making history matter: History-advantage sequence training for visual dialog,"We study the multi-round response generation in visual dialog, where a response is generated according to a visually grounded conversational history. Given a triplet: An image, Q&A history, and current question, all the prevailing methods follow a codec (i.e., encoder-decoder) fashion in a supervised learning paradigm: A multimodal encoder encodes the triplet into a feature vector, which is then fed into the decoder for the current answer generation, supervised by the ground-truth. However, this conventional supervised learning does NOT take into account the impact of imperfect history, violating the conversational nature of visual dialog and thus making the codec more inclined to learn history bias but not contextual reasoning. To this end, inspired by the actor-critic policy gradient in reinforcement learning, we propose a novel training paradigm called History Advantage Sequence Training (HAST). Specifically, we intentionally impose wrong answers in the history, obtaining an adverse critic, and see how the historic error impacts the codec's future behavior by History Advantage - a quantity obtained by subtracting the adverse critic from the gold reward of ground-truth history. Moreover, to make the codec more sensitive to the history, we propose a novel attention network called History-Aware Co-Attention Network (HACAN) which can be effectively trained by using HAST. Experimental results on three benchmarks: VisDial v0.9&v1.0 and GuessWhat?!, show that the proposed HAST strategy consistently outperforms the state-of-the-art supervised counterparts.",60005510,Nanyang Technological University,Singapore City,Singapore,"['1712', '1707']",32.285714285714285,0.09547619047619048,0.3688095238095238,1,0.12411347517730496,0.06382978723404255,0.38721804511278196
1524,1555,1555,View independent generative adversarial network for novel view synthesis,"Synthesizing novel views from a 2D image requires to infer 3D structure and project it back to 2D from a new viewpoint. In this paper, we propose an encoder-decoder based generative adversarial network VI-GAN to tackle this problem. Our method is to let the network, after seeing many images of objects belonging to the same category in different views, obtain essential knowledge of intrinsic properties of the objects. To this end, an encoder is designed to extract view-independent feature that characterizes intrinsic properties of the input image, which includes 3D structure, color, texture etc. We also make the decoder hallucinate the image of a novel view based on the extracted feature and an arbitrary user-specific camera pose. Extensive experiments demonstrate that our model can synthesize high-quality images in different views with continuous camera poses, and is general for various applications.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",23.33333333333333,0.05330578512396695,0.4102617079889808,1,0.1402439024390244,0.018292682926829267,0.3116883116883117
1525,1556,1556,Co-evolutionary compression for unpaired image translation,"Generative adversarial networks (GANs) have been successfully used for considerable computer vision tasks, especially the image-to-image translation. However, generators in these networks are of complicated architectures with large number of parameters and huge computational complexities. Existing methods are mainly designed for compressing and speeding-up deep neural networks in the classification task, and cannot be directly applied on GANs for image translation, due to their different objectives and training procedures. To this end, we develop a novel co-evolutionary approach for reducing their memory usage and FLOPs simultaneously. In practice, generators for two image domains are encoded as two populations and synergistically optimized for investigating the most important convolution filters iteratively. Fitness of each individual is calculated using the number of parameters, a discriminator-aware regularization, and the cycle consistency. Extensive experiments conducted on benchmark datasets demonstrate the effectiveness of the proposed method for obtaining compact and effective generators.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",20.857142857142858,0.16287202380952384,0.6168898809523811,1,0.10344827586206896,0.005747126436781609,0.3597560975609756
1526,1557,1557,SROBB: Targeted perceptual loss for single image super-resolution,"By benefiting from perceptual losses, recent studies have improved significantly the performance of the super-resolution task, where a high-resolution image is resolved from its low-resolution counterpart. Although such objective functions generate near-photorealistic results, their capability is limited, since they estimate the reconstruction error for an entire image in the same way, without considering any semantic information. In this paper, we propose a novel method to benefit from perceptual loss in a more objective way. We optimize a deep network-based decoder with a targeted objective function that penalizes images at different semantic levels using the corresponding terms. In particular, the proposed method leverages our proposed OBB (Object, Background and Boundary) labels, generated from segmentation labels, to estimate a suitable perceptual loss for boundaries, while considering texture similarity for backgrounds. We show that our proposed approach results in more realistic textures and sharper edges, and outperforms other state-of-the-art algorithms in terms of both qualitative results on standard benchmarks and results of extensive user studies.",60069912,Swisscom AG,Bern,Switzerland,"['1712', '1707']",27.0,0.10852130325814537,0.3654135338345864,1,0.11616161616161616,0.015151515151515152,0.36813186813186816
1527,1559,1559,ViCo: Word embeddings from visual co-occurrences,"We propose to learn word embeddings from visual co-occurrences. Two words co-occur visually if both words apply to the same image or image region. Specifically, we extract four types of visual co-occurrences between object and attribute words from large-scale, textually-annotated visual databases like VisualGenome and ImageNet. We then train a multi-task log-bilinear model that compactly encodes word ''meanings'' represented by each co-occurrence type into a single visual word-vector. Through unsupervised clustering, supervised partitioning, and a zero-shot-like generalization analysis we show that our word embeddings complement text-only embeddings like GloVe by better representing similarities and differences between visual concepts that are difficult to obtain from text corpora alone. We further evaluate our embeddings on five downstream applications, four of which are vision-language tasks. Augmenting GloVe with our embeddings yields gains on all tasks. We also find that random embeddings perform comparably to learned embeddings on all supervised vision-language tasks, contrary to conventional wisdom.",60000745,University of Illinois at Urbana-Champaign,Urbana,United States,"['1712', '1707']",19.0,-0.05494505494505494,0.2458791208791209,1,0.12121212121212122,0.015151515151515152,0.39880952380952384
1528,1560,1560,Online model distillation for efficient video inference,"High-quality computer vision models typically address the problem of understanding the general distribution of real-world images. However, most cameras observe only a very small fraction of this distribution. This offers the possibility of achieving more efficient inference by specializing compact, low-cost models to the specific distribution of frames observed by a single camera. In this paper, we employ the technique of model distillation (supervising a low-cost student model using the output of a high-cost teacher) to specialize accurate, low-cost semantic segmentation models to a target video stream. Rather than learn a specialized student model on offline data from the video stream, we train the student in an online fashion on the live video, intermittently running the teacher to provide a target for learning. Online model distillation yields semantic segmentation models that closely approximate their Mask R-CNN teacher with 7∼to∼17times lower inference runtime cost (11∼to∼26times in FLOPs), even when the target video's distribution is non-stationary. Our method requires no offline pretraining on the target video stream, achieves higher accuracy and lower cost than solutions based on flow or video object segmentation, and can exhibit better temporal stability than the original teacher. We also provide a new video dataset for evaluating the efficiency of inference over long running video streams.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",26.0,0.11380188439011968,0.4821861471861471,1,0.1016260162601626,0.016260162601626018,0.2826086956521739
1529,1561,1561,Ground-to-aerial image geo-localization with a hard exemplar reweighting triplet loss,"The task of ground-to-aerial image geo-localization can be achieved by matching a ground view query image to a reference database of aerial/satellite images. It is highly challenging due to the dramatic viewpoint changes and unknown orientations. In this paper, we propose a novel in-batch reweighting triplet loss to emphasize the positive effect of hard exemplars during end-to-end training. We also integrate an attention mechanism into our model using feature-level contextual information. To analyze the difficulty level of each triplet, we first enforce a modified logistic regression to triplets with a distance rectifying factor. Then, the reference negative distances for corresponding anchors are set, and the relative weights of triplets are computed by comparing their difficulty to the corresponding references. To reduce the influence of extreme hard data and less useful simple exemplars, the final weights are pruned using upper and lower bound constraints. Experiments on two benchmark datasets show that the proposed approach significantly outperforms the state-of-the-art methods.",60024350,National University of Defense Technology,Changsha,China,"['1712', '1707']",19.75,-0.010650623885918007,0.4844665138782786,1,0.11398963730569948,0.0,0.32748538011695905
1530,1562,1562,Bit-flip attack: Crushing neural network with progressive bit search,"Several important security issues of Deep Neural Network (DNN) have been raised recently associated with different applications and components. The most widely investigated security concern of DNN is from its malicious input, a.k.a adversarial example. Nevertheless, the security challenge of DNN's parameters is not well explored yet. In this work, we are the first to propose a novel DNN weight attack methodology called Bit-Flip Attack (BFA) which can crush a neural network through maliciously flipping extremely small amount of bits within its weight storage memory system (i.e., DRAM). The bit-flip operations could be conducted through well-known Row-Hammer attack, while our main contribution is to develop an algorithm to identify the most vulnerable bits of DNN weight parameters (stored in memory as binary bits), that could maximize the accuracy degradation with a minimum number of bit-flips. Our proposed BFA utilizes a Progressive Bit Search (PBS) method which combines gradient ranking and progressive search to identify the most vulnerable bit to be flipped. With the aid of PBS, we can successfully attack a ResNet-18 fully malfunction (i.e., top-1 accuracy degrade from 69.8% to 0.1%) only through 13 bit-flips out of 93 million bits, while randomly flipping 100 bits merely degrades the accuracy by less than 1%. Code is released at: Https://github.com/elliothe/Neural-Network-Weight-Attack.",60003892,Arizona State University,Tempe,United States,"['1712', '1707']",26.125,0.02894736842105264,0.4859649122807018,1,0.10588235294117647,0.08627450980392157,0.4204081632653061
1531,1563,1563,SF-KCCA: Sample factoring induced kernel canonical correlation analysis,"The Canonical Correlation analysis (CCA), such as linear CCA and Kernel Canonical Correlation Analysis (KCCA) are efficient methods for dimensionality reduction (DR). In this paper, a method of sample factoring induced KCCA is proposed. Different from traditional KCCA method, sample factors are introduced to impose penalties on the sample spaces to suppress the effect of corrupt data samples. By using a sample factoring strategies: cosine similarity metrics, the relationships between data samples and the principal projections are iteratively learned in order to obtain better correlation projections. By this way, the authentic and corrupt data samples can be discriminated and the impact of the corrupt data samples can be suppressed. Extensive experiments conducted on face image datasets, such as Yale, AR, show our approach has better classification and DR performance than that of linear CCA and KCCA, especially in noisy datasets.",60017482,Jiangsu University,Zhenjiang,China,['1700'],23.33333333333333,0.0,0.7027777777777778,1,0.09259259259259259,0.09876543209876543,0.4074074074074074
1532,1564,1564,Cap2Det: Learning to amplify weak caption supervision for object detection,"Learning to localize and name object instances is a fundamental problem in vision, but state-of-the-art approaches rely on expensive bounding box supervision. While weakly supervised detection (WSOD) methods relax the need for boxes to that of image-level annotations, even cheaper supervision is naturally available in the form of unstructured textual descriptions that users may freely provide when uploading image content. However, straightforward approaches to using such data for WSOD wastefully discard captions that do not exactly match object names. Instead, we show how to squeeze the most information out of these captions by training a text-only classifier that generalizes beyond dataset boundaries. Our discovery provides an opportunity for learning detection models from noisy but more abundant and freely-available caption data. We also validate our model on three classic object detection benchmarks and achieve state-of-the-art WSOD performance. Our code is available at https://github.com/yekeren/Cap2Det.",60074542,Google Switzerland GmbH,Zurich,Switzerland,"['1712', '1707']",20.285714285714285,0.1951388888888889,0.513888888888889,1,0.11560693641618497,0.023121387283236993,0.3375796178343949
1533,1565,1565,Reasoning based virtual machine mapping toward physical machine,"Cloud computing is an arising paradigm to run and hosts a number of applications and services. These computing services are accommodated by a set of virtual machines. These virtual machines are an abstraction of real servers or physical machines. A physical machine can hosts a number of virtual machines, depending on its capacity. Virtual machine placement has a direct effect on the quality of the services for both end-users and cloud service providers. In this study, we address the problem of virtual machine placement and migration for minimization of resources and power consumption. We formulate this problem as a multi-objective optimization and propose a resource-aware reasoning based scheme with state-of-the-art solutions. The simulations results with real-world traces show that the integrated schemes use a fewer number of physical servers to accommodate more virtual machines.",60025761,Huazhong University of Science and Technology,Wuhan,China,['1700'],16.75,0.13333333333333333,0.2714285714285714,1,0.0949367088607595,0.0,0.3333333333333333
1534,1566,1566,Factors effecting performance management system: An empirical analysis with reference to health care industry around Hyderabad metro," The authors surveyed 750 staff working in various healthcare centres including hospitals, training centres consisting of 435 men and 315 women employees, to evaluate the how the said factors effect the performance management system in healthcare industry. The reliability statistics Cronbach Alpha, Kaiser-Meyer-Olkin Measure of Sampling Adequacy and Bartlett’s tests of sample adequacy, principal component analysis and multiple linear regression analysis carried out. The Cronbach alpha measured at for performance management 0.870 factors for improvement of employee performance 0.776 and factors for Impact of performance appraisal system on organization is 0.742. The KMO-Bartlett tests reveal a strong relationship among the study variables and Bartlett’s test of Sphericity is significant (P<0.001) for all the three factors indicating the correlation matrix is not an identify matrix. The multiple regression analysis reveals the three factors significantly influencing the performance management system in healthcare industry in the Metro of Hyderabad.",60056514,"Shri Ramdeobaba College of Engineering and Management, Nagpur",Nagpur,India,['1706'],29.4,0.19722222222222224,0.4972222222222222,0,0.0783132530120482,0.10240963855421686,0.34355828220858897
1535,1567,1567,Localization of deep inpainting using high-pass fully convolutional network,"Image inpainting has been substantially improved with deep learning in the past years. Deep inpainting can fill image regions with plausible contents, which are not visually apparent. Although inpainting is originally designed to repair images, it can even be used for malicious manipulations, e.g., removal of specific objects. Therefore, it is necessary to identify the presence of inpainting in an image. This paper presents a method to locate the regions manipulated by deep inpainting. The proposed method employs a fully convolutional network that is based on high-pass filtered image residuals. Firstly, we analyze and observe that the inpainted regions are more distinguishable from the untouched ones in the residual domain. Hence, a high-pass pre-filtering module is designed to get image residuals for enhancing inpainting traces. Then, a feature extraction module, which learns discriminative features from image residuals, is built with four concatenated ResNet blocks. The learned feature maps are finally enlarged by an up-sampling module, so that a pixel-wise inpainting localization map is obtained. The whole network is trained end-to-end with a loss addressing the class imbalance. Extensive experimental results evaluated on both synthetic and realistic images subjected to deep inpainting have shown the effectiveness of the proposed method.",60000937,Shenzhen University,Shenzhen,China,"['1712', '1707']",16.583333333333336,0.10686274509803922,0.4632352941176471,1,0.1483050847457627,0.00423728813559322,0.36036036036036034
1536,1568,1568,Program-guided image manipulators,"Humans are capable of building holistic representations for images at various levels, from local objects, to pairwise relations, to global structures. The interpretation of structures involves reasoning over repetition and symmetry of the objects in the image. In this paper, we present the Program-Guided Image Manipulator (PG-IM), inducing neuro-symbolic program-like representations to represent and manipulate images. Given an image, PG-IM detects repeated patterns, induces symbolic programs, and manipulates the image using a neural network that is guided by the program. PG-IM learns from a single image, exploiting its internal statistics. Despite trained only on image inpainting, PG-IM is directly capable of extrapolation and regularity editing in a unified framework. Extensive experiments show that PG-IM achieves superior performance on all the tasks.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",17.285714285714285,0.0935064935064935,0.3406926406926407,1,0.12179487179487179,0.09615384615384616,0.42857142857142855
1537,1569,1569,Evaluating robustness of deep image super-resolution against adversarial attacks,"Single-image super-resolution aims to generate a high-resolution version of a low-resolution image, which serves as an essential component in many image processing applications. This paper investigates the robustness of deep learning-based super-resolution methods against adversarial attacks, which can significantly deteriorate the super-resolved images without noticeable distortion in the attacked low-resolution images. It is demonstrated that state-of-the-art deep super-resolution methods are highly vulnerable to adversarial attacks. Different levels of robustness of different methods are analyzed theoretically and experimentally. We also present analysis on transferability of attacks, and feasibility of targeted attacks and universal attacks.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",18.6,0.03958333333333333,0.3895833333333333,1,0.104,0.0,0.42574257425742573
1538,1570,1570,Emotion recognition from human gait features based on DCT transform,"Emotion recognition is of great value in human-computer interaction, psychology, etc. Gait is an important pattern of emotion recognition. In this paper, 59 volunteer’s gait data with angry or happy emotion, have been collected by the aid of Microsoft Kinect. The gait data are treated as discrete time signals, and we extract a series of frequency features based on the discrete cosine transform. Simultaneously, we have established emotion recognizing models with SVM, the K-nearest neighbors, and decision tree. The best recognition rate can exceed 80%, which indicates that our proposed features are useful for recognizing emotions.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],16.0,0.4666666666666666,0.6749999999999999,1,0.09401709401709402,0.03418803418803419,0.3508771929824561
1539,1571,1571,X-section: Cross-section prediction for enhanced RGB-D fusion,"Detailed 3D reconstruction is an important challenge with application to robotics, augmented and virtual reality, which has seen impressive progress throughout the past years. Advancements were driven by the availability of depth cameras (RGB-D), as well as increased compute power, e.g. in the form of GPUs - but also thanks to inclusion of machine learning in the process. Here, we propose X-Section, an RGB-D 3D reconstruction approach that leverages deep learning to make object-level predictions about thicknesses that can be readily integrated into a volumetric multi-view fusion process, where we propose an extension to the popular KinectFusion approach. In essence, our method allows to complete shape in general indoor scenes behind what is sensed by the RGB-D camera, which may be crucial e.g. for robotic manipulation tasks or efficient scene exploration. Predicting object thicknesses rather than volumes allows us to work with comparably high spatial resolution without exploding memory and training data requirements on the employed Convolutional Neural Networks. In a series of qualitative and quantitative evaluations, we demonstrate how we accurately predict object thickness and reconstruct general 3D scenes containing multiple objects.",60015150,Imperial College London,London,United Kingdom,"['1712', '1707']",22.875,0.1652941176470588,0.5572549019607843,1,0.11267605633802817,0.03755868544600939,0.32019704433497537
1540,1572,1572,Reasoning about human-object interactions through dual attention networks,"Objects are entities we act upon, where the functionality of an object is determined by how we interact with it. In this work we propose a Dual Attention Network model which reasons about human-object interactions. The dual-attentional framework weights the important features for objects and actions respectively. As a result, the recognition of objects and actions mutually benefit each other. The proposed model shows competitive classification performance on the human-object interaction dataset Something-Something. Besides, it can perform weak spatiotemporal localization and affordance segmentation, despite being trained only with video-level labels. The model not only finds when an action is happening and which object is being manipulated, but also identifies which part of the object is being interacted with.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",16.857142857142858,3.9650822308041295e-18,0.5999999999999999,1,0.12142857142857143,0.02142857142857143,0.3153846153846154
1541,1573,1573,Overcoming catastrophic forgetting with unlabeled data in the wild,"Lifelong learning with deep neural networks is well-known to suffer from catastrophic forgetting: The performance on previous tasks drastically degrades when learning a new task. To alleviate this effect, we propose to leverage a large stream of unlabeled data easily obtainable in the wild. In particular, we design a novel class-incremental learning scheme with (a) a new distillation loss, termed global distillation, (b) a learning strategy to avoid overfitting to the most recent task, and (c) a confidence-based sampling method to effectively leverage unlabeled external data. Our experimental results on various datasets, including CIFAR and ImageNet, demonstrate the superiority of the proposed methods over prior methods, particularly when a stream of unlabeled data is accessible: Our method shows up to 15.8% higher accuracy and 46.5% less forgetting compared to the state-of-the-art method. The code is available at https://github.com/kibok90/iccv2019-inc.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1707']",27.6,0.14297028728846908,0.377090712317985,1,0.10982658959537572,0.011560693641618497,0.31901840490797545
1542,1574,1574,Intention classification based on transfer learning: A case study on insurance data,"With the rapid development of Artificial Intelligence and Big Data technology, intelligent chatbot in insurance industry has become the major technical means to reduce labor costs and improve the quality of service. The core technology of this application is to understand and classify the users’ intentions accurately. However, insurance as a product with complex knowledge system and long service cycle, users’ intentions and the corresponding corpus is rather scattered. The initial corpus is especially scarce at the early stage of new business. So it is very important to classify the customers’ intentions accurately based on the rare corpus. This paper offers an empirical case study on intention classification of insurance data by using transfer learning model BERT. The experimental comparative analysis result shows that method based on BERT model can better reduce the error rate than other existing model methods (TextCNN, HAN, ELMo).",60016541,Shanghai Polytechnic University,Pudong District,China,['1700'],20.428571428571427,0.12219318181818185,0.484810606060606,1,0.09375,0.05,0.29375
1543,1575,1575,A real-time update approach for visualizing multidimensional big data,"Multidimensional data in different fields (e.g., science and technology resources, medicine, finance and transportation) have emerged in the big data era. Technology of visualization is critical to analyze multidimensional data which is large-scale. Thus, the highly variability of multidimensional data leads to the necessity of improving data management efficiency by updating data in real time. Nevertheless, traditional real-time communication technology suffers from low efficiency and large bandwidth consumption. Based on WebSocket, this paper proposes a multidimensional data service platform architecture that is scalable, real-time and versatile. First, on the platform, we compare the network load and network latency above Ajax polling and WebSocket. Secondly, for multidimensional data, we further validate the effectiveness of WebSocket in the application scenarios of frequent updating and multi-user concurrent requests. WebSocket-based platform greatly shortens the time for people to understand and analyze massive and complex multidimensional data. The application results show that the design is effective for real-time updating of multidimensional data.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],17.444444444444443,0.07912698412698413,0.4834391534391535,1,0.07853403141361257,0.020942408376963352,0.3016759776536313
1544,1576,1576,VTNFP: An image-based virtual try-on network with body and clothing feature preservation,"Image-based virtual try-on systems with the goal of transferring a desired clothing item onto the corresponding region of a person have made great strides recently, but challenges remain in generating realistic looking images that preserve both body and clothing details. Here we present a new virtual try-on network, called VTNFP, to synthesize photo-realistic images given the images of a clothed person and a target clothing item. In order to better preserve clothing and body features, VTNFP follows a three-stage design strategy. First, it transforms the target clothing into a warped form compatible with the pose of the given person. Next, it predicts a body segmentation map of the person wearing the target clothing, delineating body parts as well as clothing regions. Finally, the warped clothing, body segmentation map and given person image are fused together for fine-scale image synthesis. A key innovation of VTNFP is the body segmentation map prediction module, which provides critical information to guide image synthesis in regions where body parts and clothing intersects, and is very beneficial for preventing blurry pictures and preserving clothing and body part details. Experiments on a fashion dataset demonstrate that VTNFP generates substantially better results than state-of-the-art methods.",60031863,"Northeastern University, China",Shenyang,China,"['1712', '1707']",24.625,0.1963869463869464,0.4785547785547785,1,0.12393162393162394,0.029914529914529916,0.2962962962962963
1545,1577,1577,Unconstrained motion deblurring for dual-lens cameras,"Recently, there has been a renewed interest in leveraging multiple cameras, but under unconstrained settings. They have been quite successfully deployed in smartphones, which have become de facto choice for many photographic applications. However, akin to normal cameras, the functionality of multi-camera systems can be marred by motion blur which is a ubiquitous phenomenon in hand-held cameras. Despite the far-reaching potential of unconstrained camera arrays, there is not a single deblurring method for such systems. In this paper, we propose a generalized blur model that elegantly explains the intrinsically coupled image formation model for dual-lens set-up, which are by far most predominant in smartphones. While image aesthetics is the main objective in normal camera deblurring, any method conceived for our problem is additionally tasked with ascertaining consistent scene-depth in the deblurred images. We reveal an intriguing challenge that stems from an inherent ambiguity unique to this problem which naturally disrupts this coherence. We address this issue by devising a judicious prior, and based on our model and prior propose a practical blind deblurring method for dual-lens cameras, that achieves state-of-the-art performance.",60025757,Indian Institute of Technology Madras,Chennai,India,"['1712', '1707']",22.625,0.153517316017316,0.4711038961038961,1,0.11818181818181818,0.0,0.325
1546,1578,1578,Relational attention network for crowd counting,"Crowd counting is receiving rapidly growing research interests due to its potential application value in numerous real-world scenarios. However, due to various challenges such as occlusion, insufficient resolution and dynamic backgrounds, crowd counting remains an unsolved problem in computer vision. Density estimation is a popular strategy for crowd counting, where conventional density estimation methods perform pixel-wise regression without explicitly accounting the interdependence of pixels. As a result, independent pixel-wise predictions can be noisy and inconsistent. In order to address such an issue, we propose a Relational Attention Network (RANet) with a self-attention mechanism for capturing interdependence of pixels. The RANet enhances the self-attention mechanism by accounting both short-range and long-range interdependence of pixels, where we respectively denote these implementations as local self-attention (LSA) and global self-attention (GSA). We further introduce a relation module to fuse LSA and GSA to achieve more informative aggregated feature representations. We conduct extensive experiments on four public datasets, including ShanghaiTech A, ShanghaiTech B, UCF-CC-50 and UCF-QNRF. Experimental results on all datasets suggest RANet consistently reduces estimation errors and surpasses the state-of-the-art approaches by large margins.",60013789,Beihang University,Beijing,China,"['1712', '1707']",20.0,0.060544217687074825,0.3751133786848072,1,0.09012875536480687,0.07725321888412018,0.3951219512195122
1547,1579,1579,Block annotation: Better image annotation with sub-image decomposition,"Image datasets with high-quality pixel-level annotations are valuable for semantic segmentation: Labelling every pixel in an image ensures that rare classes and small objects are annotated. However, full-image annotations are expensive, with experts spending up to 90 minutes per image. We propose block sub-image annotation as a replacement for full-image annotation. Despite the attention cost of frequent task switching, we find that block annotations can be crowdsourced at higher quality compared to full-image annotation with equal monetary cost using existing annotation tools developed for full-image annotation. Surprisingly, we find that 50% pixels annotated with blocks allows semantic segmentation to achieve equivalent performance to 100% pixels annotated. Furthermore, as little as 12% of pixels annotated allows performance as high as 98% of the performance with dense annotation. In weakly-supervised settings, block annotation outperforms existing methods by 3-4% (absolute) given equivalent annotation time. To recover the necessary global structure for applications such as characterizing spatial context and affordance relationships, we propose an effective method to inpaint block-annotated images with high-quality labels without additional human effort. As such, fewer annotations can also be used for these applications compared to full-image annotation.",60007776,Cornell University,Ithaca,United States,"['1712', '1707']",20.88888888888889,0.08661764705882354,0.5111764705882352,1,0.12658227848101267,0.0,0.4272300469483568
1548,1580,1580,Transductive episodic-wise adaptive metric for few-shot learning,"Few-shot learning, which aims at extracting new concepts rapidly from extremely few examples of novel classes, has been featured into the meta-learning paradigm recently. Yet, the key challenge of how to learn a generalizable classifier with the capability of adapting to specific tasks with severely limited data still remains in this domain. To this end, we propose a Transductive Episodic-wise Adaptive Metric (TEAM) framework for few-shot learning, by integrating the meta-learning paradigm with both deep metric learning and transductive inference. With exploring the pairwise constraints and regularization prior within each task, we explicitly formulate the adaptation procedure into a standard semi-definite programming problem. By solving the problem with its closed-form solution on the fly with the setup of transduction, our approach efficiently tailors an episodic-wise metric for each task to adapt all features from a shared task-agnostic embedding space into a more discriminative task-specific metric space. Moreover, we further leverage an attention-based bi-directional similarity strategy for extracting the more robust relationship between queries and prototypes. Extensive experiments on three benchmark datasets show that our framework is superior to other existing approaches and achieves the state-of-the-art performance in the few-shot literature.",60014966,Peking University,Beijing,China,"['1712', '1707']",27.142857142857146,0.13999594155844156,0.4050459956709957,1,0.09623430962343096,0.02092050209205021,0.3188405797101449
1549,1581,1581,Meteornet: Deep learning on dynamic 3D point cloud sequences,"Understanding dynamic 3D environment is crucial for robotic agents and many other applications. We propose a novel neural network architecture called MeteorNet for learning representations for dynamic 3D point cloud sequences. Different from previous work that adopts a grid-based representation and applies 3D or 4D convolutions, our network directly processes point clouds. We propose two ways to construct spatiotemporal neighborhoods for each point in the point cloud sequence. Information from these neighborhoods is aggregated to learn features per point. We benchmark our network on a variety of 3D recognition tasks including action recognition, semantic segmentation and scene flow estimation. MeteorNet shows stronger performance than previous grid-based methods while achieving state-of-the-art performance on Synthia. MeteorNet also outperforms previous baseline methods that are able to process at most two consecutive point clouds. To the best of our knowledge, this is the first work on deep learning for dynamic raw point cloud sequences.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",16.666666666666664,0.10495951417004047,0.3576248313090418,1,0.11046511627906977,0.023255813953488372,0.35802469135802467
1550,1582,1582,Understanding generalized whitening and coloring transform for universal style transfer,"Style transfer is a task of rendering images in the styles of other images. In the past few years, neural style transfer has achieved a great success in this task, yet suffers from either the inability to generalize to unseen style images or fast style transfer. Recently, an universal style transfer technique that applies zero-phase component analysis (ZCA) for whitening and coloring image features realizes fast and arbitrary style transfer. However, using ZCA for style transfer is empirical and does not have any theoretical support. In addition, other whitening and coloring transforms (WCT) than ZCA have not been investigated. In this report, we generalize ZCA to the general form of WCT, provide an analytical performance analysis from the angle of neural style transfer, and show why ZCA is a good choice for style transfer among different WCTs and why some WCTs are not well applicable for style transfer.",60013372,The University of Texas at Austin,Austin,United States,"['1712', '1707']",24.66666666666667,0.05937500000000001,0.390625,1,0.08333333333333333,0.041666666666666664,0.2891566265060241
1551,1583,1583,SynDeMo: Synergistic deep feature alignment for joint learning of depth and ego-motion,"Despite well-established baselines, learning of scene depth and ego-motion from monocular video remains an ongoing challenge, specifically when handling scaling ambiguity issues and depth inconsistencies in image sequences. Much prior work uses either a supervised mode of learning or stereo images. The former is limited by the amount of labeled data, as it requires expensive sensors, while the latter is not always readily available as monocular sequences. In this work, we demonstrate the benefit of using geometric information from synthetic images, coupled with scene depth information, to recover the scale in depth and ego-motion estimation from monocular videos. We developed our framework using synthetic image-depth pairs and unlabeled real monocular images. We had three training objectives: First, to use deep feature alignment to reduce the domain gap between synthetic and monocular images to yield more accurate depth estimation when presented with only real monocular images at test time. Second, we learn scene specific representation by exploiting self-supervision coming from multi-view synthetic images without the need for depth labels. Third, our method uses single-view depth and pose networks, which are capable of jointly training and supervising one another mutually, yielding consistent depth and ego-motion estimates. Extensive experiments demonstrate that our depth and ego-motion models surpass the state-of-the-art, unsupervised methods and compare favorably to early supervised deep models for geometric understanding. We validate the effectiveness of our training objectives against standard benchmarks thorough an ablation study.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",23.4,0.08035714285714286,0.2840773809523809,1,0.12056737588652482,0.0,0.31007751937984496
1552,1585,1585,Reppoints: Point set representation for object detection,"Modern object detectors rely heavily on rectangular bounding boxes, such as anchors, proposals and the final predictions, to represent objects at various recognition stages. The bounding box is convenient to use but provides only a coarse localization of objects and leads to a correspondingly coarse extraction of object features. In this paper, we present textbf{RepPoints} (representative points), a new finer representation of objects as a set of sample points useful for both localization and recognition. Given ground truth localization and recognition targets for training, RepPoints learn to automatically arrange themselves in a manner that bounds the spatial extent of an object and indicates semantically significant local areas. They furthermore do not require the use of anchors to sample a space of bounding boxes. We show that an anchor-free object detector based on RepPoints can be as effective as the state-of-the-art anchor-based detection methods, with 46.5 AP and 67.4 AP-{50} on the COCO test-dev detection benchmark, using ResNet-101 model. Code is available at href{https://github.com/microsoft/RepPoints}{color{cyan}{https://github.com/microsoft/RepPoints}}.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",23.285714285714285,0.12075757575757574,0.4886363636363636,1,0.09803921568627451,0.04411764705882353,0.3910891089108911
1553,1586,1586,GAN-tree: An incrementally learned hierarchical generative framework for multi-modal data distributions,"Despite the remarkable success of generative adversarial networks, their performance seems less impressive for diverse training sets, requiring learning of discontinuous mapping functions. Though multi-mode prior or multi-generator models have been proposed to alleviate this problem, such approaches may fail depending on the empirically chosen initial mode components. In contrast to such bottom-up approaches, we present GAN-Tree, which follows a hierarchical divisive strategy to address such discontinuous multi-modal data. Devoid of any assumption on the number of modes, GAN-Tree utilizes a novel mode-splitting algorithm to effectively split the parent mode to semantically cohesive children modes, facilitating unsupervised clustering. Further, it also enables incremental addition of new data modes to an already trained GAN-Tree, by updating only a single branch of the tree structure. As compared to prior approaches, the proposed framework offers a higher degree of flexibility in choosing a large variety of mutually exclusive and exhaustive tree nodes called GAN-Set. Extensive experiments on synthetic and natural image datasets including ImageNet demonstrate the superiority of GAN-Tree against the prior state-of-the-art.",60014097,"Indian Institute of Science, Bengaluru",Bengaluru,India,"['1712', '1707']",24.285714285714285,0.1085021645021645,0.3418961038961039,1,0.11737089201877934,0.051643192488262914,0.35294117647058826
1554,1587,1587,"Constraining and enhancing factors of business enterprise in Occidental Mindoro, Philippines"," The Michael Porter’s Diamond Model of Competitive Advantage was used as the analytical framework. Data obtained from the survey were analysed using Descriptive Statistics. The research revealed that businesses are negatively constrained by three most critical factors such as insufficient and unreliable electric supply, unfavorable tax system and the cost of transport which is very important since Occidental Mindoro is an island province. The enhancing factors, on the other hand, are the incentives in the compensation of management, favorable market size and the nature of competitive advantage which are unique among industries. However, this study also revealed that the environment for the business enterprise is not enabling because majority of the competitive determinants showed competitive disadvantage.",122149580,Occidental Mindoro State College,San Jose,Philippines,['1706'],23.4,0.13857142857142854,0.6535714285714286,0,0.078125,0.0703125,0.265625
1555,1588,1588,Temporal structure mining for weakly supervised action detection,"Different from the fully-supervised action detection problem that is dependent on expensive frame-level annotations, weakly supervised action detection (WSAD) only needs video-level annotations, making it more practical for real-world applications. Existing WSAD methods detect action instances by scoring each video segment (a stack of frames) individually. Most of them fail to model the temporal relations among video segments and cannot effectively characterize action instances possessing latent temporal structure. To alleviate this problem in WSAD, we propose the temporal structure mining (TSM) approach. In TSM, each action instance is modeled as a multi-phase process and phase evolving within an action instance, emph{i.e.}, the temporal structure, is exploited. Meanwhile, the video background is modeled by a background phase, which separates different action instances in an untrimmed video. In this framework, phase filters are used to calculate the confidence scores of the presence of an action's phases in each segment. Since in the WSAD task, frame-level annotations are not available and thus phase filters cannot be trained directly. To tackle the challenge, we treat each segment's phase as a hidden variable. We use segments' confidence scores from each phase filter to construct a table and determine hidden variables, i.e., phases of segments, by a maximal circulant path discovery along the table. Experiments conducted on three benchmark datasets demonstrate the state-of-the-art performance of the proposed TSM.",60120916,Snap Inc.,Santa Monica,United States,"['1712', '1707']",20.181818181818183,0.028174603174603175,0.3757936507936507,1,0.11827956989247312,0.025089605734767026,0.35361216730038025
1556,1589,1589,Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation,"Domain adaptation enables the learner to safely generalize into novel environments by mitigating domain shifts across distributions. Previous works may not effectively uncover the underlying reasons that would lead to the drastic model degradation on the target task. In this paper, we empirically reveal that the erratic discrimination of the target domain mainly stems from its much smaller feature norms with respect to that of the source domain. To this end, we propose a novel parameter-free Adaptive Feature Norm approach. We demonstrate that progressively adapting the feature norms of the two domains to a large range of values can result in significant transfer gains, implying that those task-specific features with larger norms are more transferable. Our method successfully unifies the computation of both standard and partial domain adaptation with more robustness against the negative transfer issue. Without bells and whistles but a few lines of code, our method substantially lifts the performance on the target task and exceeds state-of-the-arts by a large margin (11.5% on Office-Home and 17.1% on VisDA2017). We hope our simple yet effective approach will shed some light on the future research of transfer learning. Code is available at https://github.com/jihanyang/AFN.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",21.444444444444443,0.16607142857142854,0.4438311688311689,1,0.0990990990990991,0.02252252252252252,0.28773584905660377
1557,1590,1590,Multi-garment net: Learning to dress 3D people from images,"We present Multi-Garment Network (MGN), a method to predict body shape and clothing, layered on top of the SMPL model from a few frames (1-8) of a video. Several experiments demonstrate that this representation allows higher level of control when compared to single mesh or voxel representations of shape. Our model allows to predict garment geometry, relate it to the body shape, and transfer it to new body shapes and poses. To train MGN, we leverage a digital wardrobe containing 712 digital garments in correspondence, obtained with a novel method to register a set of clothing templates to a dataset of real 3D scans of people in different clothing and poses. Garments from the digital wardrobe, or predicted by MGN, can be used to dress any body shape in arbitrary poses. We will make publicly available the digital wardrobe, the MGN model, and code to dress SMPL with the garments at https://virtualhumans.mpi-inf.mpg.de/mgn.",60000256,Max Planck Institute for Informatics,Saarbrucken,Germany,"['1712', '1707']",25.33333333333333,0.07432900432900434,0.2445887445887446,1,0.125,0.056818181818181816,0.3390804597701149
1558,1591,1591,Fast computation of content-sensitive superpixels and supervoxels using Q-distances,"State-of-the-art researches model the data of images and videos as low-dimensional manifolds and generate superpixels/supervoxels in a content-sensitive way, which is achieved by computing geodesic centroidal Voronoi tessellation (GCVT) on manifolds. However, computing exact GCVTs is slow due to computationally expensive geodesic distances. In this paper, we propose a much faster queue-based graph distance (called q-distance). Our key idea is that for manifold regions in which q-distances are different from geodesic distances, GCVT is prone to placing more generators in them, and therefore after few iterations, the q-distance-induced tessellation is an exact GCVT. This idea works well in practice and we also prove it theoretically under moderate assumption. Our method is simple and easy to implement. It runs 6-8 times faster than state-of-the-art GCVT computation, and has an optimal approximation ratio O(1) and a linear time complexity O(N) for N-pixel images or N-voxel videos. A thorough evaluation of 31 superpixel methods on five image datasets and 8 supervoxel methods on four video datasets shows that our method consistently achieves the best over-segmentation accuracy. We also demonstrate the advantage of our method on one image and two video applications.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",20.88888888888889,0.10989583333333333,0.43221726190476173,1,0.06910569105691057,0.024390243902439025,0.38317757009345793
1559,1592,1592,O2U-Net: A simple noisy label detection approach for deep neural networks,"This paper proposes a novel noisy label detection approach, named O2U-net, for deep neural networks without human annotations. Different from prior work which requires specifically designed noise-robust loss functions or networks, O2U-net is easy to implement but effective. It only requires adjusting the hyper-parameters of the deep network to make its status transfer from overfitting to underfitting (O2U) cyclically. The losses of each sample are recorded during iterations. The higher the normalized average loss of a sample, the higher the probability of being noisy labels. O2U-net is naturally compatible with active learning and other human annotation approaches. This introduces extra flexibility for learning with noisy labels. We conduct sufficient experiments on multiple datasets in various settings. The experimental results prove the state-of-the-art of O2S-net.",60118460,Alibaba Group Holding Limited,Yu Hang,China,"['1712', '1707']",13.777777777777779,0.06973684210526318,0.4214912280701754,1,0.09554140127388536,0.012738853503184714,0.3597122302158273
1560,1593,1593,Unsupervised domain adaptation via regularized conditional alignment,"We propose a method for unsupervised domain adaptation that trains a shared embedding to align the joint distributions of inputs (domain) and outputs (classes), making any classifier agnostic to the domain. Joint alignment ensures that not only the marginal distributions of the domains are aligned, but the labels as well. We propose a novel objective function that encourages the class-conditional distributions to have disjoint support in feature space. We further exploit adversarial regularization to improve the performance of the classifier on the domain for which no annotated data is available.",60005247,David Geffen School of Medicine at UCLA,Los Angeles,United States,"['1712', '1707']",22.5,0.1,0.5,1,0.10784313725490197,0.0,0.3
1561,1594,1594,Semi-supervised skin detection by network with mutual guidance,"We present a new data-driven method for robust skin detection from a single human portrait image. Unlike previous methods, we incorporate human body as a weak semantic guidance into this task, considering acquiring large-scale of human labeled skin data is commonly expensive and time-consuming. To be specific, we propose a dual-task neural network for joint detection of skin and body via a semi-supervised learning strategy. The dual-task network contains a shared encoder but two decoders for skin and body separately. For each decoder, its output also serves as a guidance for its counterpart, making both decoders mutually guided. Extensive experiments were conducted to demonstrate the effectiveness of our network with mutual guidance, and experimental results show our network outperforms the state-of-the-art in skin detection.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",20.666666666666668,-0.07306096681096681,0.2765692640692641,1,0.09740259740259741,0.0,0.27941176470588236
1562,1595,1595,SPLINE-Net: Sparse photometric stereo through lighting interpolation and normal estimation networks,This paper solves the Sparse Photometric stereo through Lighting Interpolation and Normal Estimation using a generative Network (SPLINE-Net). SPLINE-Net contains a lighting interpolation network to generate dense lighting observations given a sparse set of lights as inputs followed by a normal estimation network to estimate surface normals. Both networks are jointly constrained by the proposed symmetric and asymmetric loss functions to enforce isotropic constrain and perform outlier rejection of global illumination effects. SPLINE-Net is verified to outperform existing methods for photometric stereo of general BRDFs by using only ten images of different lights instead of using nearly one hundred images.,60025278,Tsinghua University,Beijing,China,"['1712', '1707']",25.0,0.05625,0.475,1,0.13392857142857142,0.125,0.3584905660377358
1563,1597,1597,"Tell, draw, and repeat: Generating and modifying images based on continual linguistic instruction","Conditional text-to-image generation is an active area of research, with many possible applications. Existing research has primarily focused on generating a single image from available conditioning information in one step. One practical extension beyond one-step generation is a system that generates an image iteratively, conditioned on ongoing linguistic input or feedback. This is significantly more challenging than one-step generation tasks, as such a system must understand the contents of its generated images with respect to the feedback history, the current feedback, as well as the interactions among concepts present in the feedback history. In this work, we present a recurrent image generation model which takes into account both the generated output up to the current step as well as all past instructions for generation. We show that our model is able to generate the background, add new objects, and apply simple transformations to existing objects. We believe our approach is an important step toward interactive generation. Code and data is available at: Https://www.microsoft.com/en-us/research/project/generative-neural-visual-artist-geneva/.",60113142,Montreal Institute for Learning Algorithms,Montreal,Canada,"['1712', '1707']",20.375,0.16908008658008658,0.4600487012987014,1,0.0855614973262032,0.0053475935828877,0.2692307692307692
1564,1598,1598,"MultiSeg: Semantically meaningful, scale-diverse segmentations from minimal user input","Existing deep learning-based interactive image segmentation approaches typically assume the target-of-interest is always a single object and fail to account for the potential diversity in user expectations, thus requiring excessive user input when it comes to segmenting an object part or a group of objects instead. Motivated by the observation that the object part, full object, and a collection of objects essentially differ in size, we propose a new concept called scale-diversity, which characterizes the spectrum of segmentations w.r.t. different scales. To address this, we present MultiSeg, a scale-diverse interactive image segmentation network that incorporates a set of two-dimensional scale priors into the model to generate a set of scale-varying proposals that conform to the user input. We explicitly encourage segmentation diversity during training by synthesizing diverse training samples for a given image. As a result, our method allows the user to quickly locate the closest segmentation target for further refinement if necessary. Despite its simplicity, experimental results demonstrate that our proposed model is capable of quickly producing diverse yet plausible segmentation outputs, reducing the user interaction required, especially in cases where many types of segmentations (object parts or groups) are expected.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",27.42857142857143,0.05749704840613931,0.5054014167650531,1,0.13716814159292035,0.008849557522123894,0.2830188679245283
1565,1599,1599,Learning across tasks and domains,"Recent works have proven that many relevant visual tasks are closely related one to another. Yet, this connection is seldom deployed in practice due to the lack of practical methodologies to transfer learned concepts across different training processes. In this work, we introduce a novel adaptation framework that can operate across both task and domains. Our framework learns to transfer knowledge across tasks in a fully supervised domain (e.g., synthetic data) and use this knowledge on a different domain where we have only partial supervision (e.g., real data). Our proposal is complementary to existing domain adaptation techniques and extends them to cross tasks scenarios providing additional performance gains. We prove the effectiveness of our framework across two challenging tasks (i.e., monocular depth estimation and semantic segmentation) and four different domains (Synthia, Carla, Kitti, and Cityscapes).",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1707']",22.5,0.09821428571428573,0.4874999999999999,1,0.10191082802547771,0.025477707006369428,0.33121019108280253
1566,1600,1600,Guided curriculum model adaptation and uncertainty-aware evaluation for semantic nighttime image segmentation,"Most progress in semantic segmentation reports on daytime images taken under favorable illumination conditions. We instead address the problem of semantic segmentation of nighttime images and improve the state-of-the-art, by adapting daytime models to nighttime without using nighttime annotations. Moreover, we design a new evaluation framework to address the substantial uncertainty of semantics in nighttime images. Our central contributions are: 1) a curriculum framework to gradually adapt semantic segmentation models from day to night via labeled synthetic images and unlabeled real images, both for progressively darker times of day, which exploits cross-time-of-day correspondences for the real images to guide the inference of their labels; 2) a novel uncertainty-aware annotation and evaluation framework and metric for semantic segmentation, designed for adverse conditions and including image regions beyond human recognition capability in the evaluation in a principled fashion; 3) the Dark Zurich dataset, which comprises 2416 unlabeled nighttime and 2920 unlabeled twilight images with correspondences to their daytime counterparts plus a set of 151 nighttime images with fine pixel-level annotations created with our protocol, which serves as a first benchmark to perform our novel evaluation. Experiments show that our guided curriculum adaptation significantly outperforms state-of-the-art methods on real nighttime sets both for standard metrics and our uncertainty-aware metric. Furthermore, our uncertainty-aware evaluation reveals that selective invalidation of predictions can lead to better results on data with ambiguous content such as our nighttime benchmark and profit safety-oriented applications which involve invalid inputs.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",39.833333333333336,0.1877164502164502,0.3794913419913421,1,0.09059233449477352,0.006968641114982578,0.3281853281853282
1567,1601,1601,Cross-view policy learning for street navigation,"The ability to navigate from visual observations in unfamiliar environments is a core component of intelligent agents and an ongoing challenge for Deep Reinforcement Learning (RL). Street View can be a sensible testbed for such RL agents, because it provides real-world photographic imagery at ground level, with diverse street appearances; it has been made into an interactive environment called StreetLearn and used for research on navigation. However, goal-driven street navigation agents have not so far been able to transfer to unseen areas without extensive retraining, and relying on simulation is not a scalable solution. Since aerial images are easily and globally accessible, we propose instead to transfer a ground view policy, from training areas to unseen (target) parts of the city, by utilizing aerial view observations. Our core idea is to pair the ground view with an aerial view and to learn a joint policy that is transferable across views. We achieve this by learning a similar embedding space for both views, distilling the policy across views and dropping out visual modalities. We further reformulate the transfer learning paradigm into three stages: 1) cross-modal training, when the agent is initially trained on multiple city regions, 2) aerial view-only adaptation to a new area, when the agent is adapted to a held-out region using only the easily obtainable aerial view, and 3) ground view-only transfer, when the agent is tested on navigation tasks on unseen ground views, without aerial imagery. Our experimental results suggest that the proposed cross-view policy learning enables better generalization of the agent and allows for more effective transfer to unseen environments.The ability to navigate from visual observations in unfamiliar environments is a core component of intelligent agents and an ongoing challenge for Deep Reinforcement Learning (RL). Street View can be a sensible testbed for such RL agents, because it provides real-world photographic imagery at ground level, with diverse street appearances; it has been made into an interactive environment called StreetLearn and used for research on navigation. However, goal-driven street navigation agents have not so far been able to transfer to unseen areas without extensive retraining, and relying on simulation is not a scalable solution. Since aerial images are easily and globally accessible, we propose instead to train a multi-modal policy on ground and aerial views, then transfer the ground view policy to unseen (target) parts of the city by utilizing aerial view observations. Our core idea is to pair the ground view with an aerial view and to learn a joint policy that is transferable across views. We achieve this by learning a similar embedding space for both views, distilling the policy across views and dropping out visual modalities. We further reformulate the transfer learning paradigm into three stages: 1) cross-modal training, when the agent is initially trained on multiple city regions, 2) aerial view-only adaptation to a new area, when the agent is adapted to a held-out region using only the easily obtainable aerial view, and 3) ground view-only transfer, when the agent is tested on navigation tasks on unseen ground views, without aerial imagery. Experimental results suggest that the proposed cross-view policy learning enables better generalization of the agent and allows for more effective transfer to unseen environments.",60111161,DeepMind Technologies Limited,London,United Kingdom,"['1712', '1707']",35.53333333333333,0.21323953823953826,0.4930735930735931,1,0.0976,0.0192,0.2984822934232715
1568,1602,1602,Generative adversarial minority oversampling,"Class imbalance is a long-standing problem relevant to a number of real-world applications of deep learning. Oversampling techniques, which are effective for handling class imbalance in classical learning systems, can not be directly applied to end-to-end deep learning systems. We propose a three-player adversarial game between a convex generator, a multi-class classifier network, and a real/fake discriminator to perform oversampling in deep learning systems. The convex generator generates new samples from the minority classes as convex combinations of existing instances, aiming to fool both the discriminator as well as the classifier into misclassifying the generated samples. Consequently, the artificial samples are generated at critical locations near the peripheries of the classes. This, in turn, adjusts the classifier induced boundaries in a way which is more likely to reduce misclassification from the minority classes. Extensive experiments on multiple class imbalanced image datasets establish the efficacy of our proposal.",60024948,"Indian Statistical Institute, Kolkata",Kolkata,India,"['1712', '1707']",21.0,0.07559808612440191,0.5256778309409887,1,0.11363636363636363,0.017045454545454544,0.3148148148148148
1569,1603,1603,Detecting unseen visual relations using analogies,"We seek to detect visual relations in images of the form of triplets t = (subject, predicate, object), such as 'person riding dog', where training examples of the individual entities are available but their combinations are unseen at training. This is an important set-up due to the combinatorial nature of visual relations : Collecting sufficient training data for all possible triplets would be very hard. The contributions of this work are three-fold. First, we learn a representation of visual relations that combines (i) individual embeddings for subject, object and predicate together with (ii) a visual phrase embedding that represents the relation triplet. Second, we learn how to transfer visual phrase embeddings from existing training triplets to unseen test triplets using analogies between relations that involve similar objects. Third, we demonstrate the benefits of our approach on three challenging datasets : On HICO-DET, our model achieves significant improvement over a strong baseline for both frequent and unseen triplets, and we observe similar improvement for the retrieval of unseen triplets with out-of-vocabulary predicates on the COCO-a dataset as well as the challenging unusual triplets in the UnRel dataset.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,"['1712', '1707']",31.0,0.058179012345679,0.4625,1,0.08108108108108109,0.018018018018018018,0.3588516746411483
1570,1604,1604,Adaptative inference cost with convolutional neural mixture models,"Despite the outstanding performance of convolutional neural networks (CNNs) for many vision tasks, the required computational cost during inference is problematic when resources are limited. In this context, we propose Convolutional Neural Mixture Models (CNMMs), a probabilistic model embedding a large number of CNNs that can be jointly trained and evaluated in an efficient manner. Within the proposed framework, we present different mechanisms to prune subsets of CNNs from the mixture, allowing to easily adapt the computational cost required for inference. Image classification and semantic segmentation experiments show that our method achieve excellent accuracy-compute trade-offs. Moreover, unlike most of previous approaches, a single CNMM provides a large range of operating points along this trade-off, without any re-training.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,"['1712', '1707']",23.4,0.2543650793650793,0.4741071428571429,1,0.1056338028169014,0.04225352112676056,0.373134328358209
1571,1605,1605,Multi-class part parsing with joint boundary-semantic awareness,"Object part parsing in the wild, which requires to simultaneously detect multiple object classes in the scene and accurately segments semantic parts within each class, is challenging for the joint presence of class-level and part-level ambiguities. Despite its importance, however, this problem is not sufficiently explored in existing works. In this paper, we propose a joint parsing framework with boundary and semantic awareness to address this challenging problem. To handle part-level ambiguity, a boundary awareness module is proposed to make mid-level features at multiple scales attend to part boundaries for accurate part localization, which are then fused with high-level features for effective part recognition. For class-level ambiguity, we further present a semantic awareness module that selects discriminative part features relevant to a category to prevent irrelevant features being merged together. The proposed modules are lightweight and implementation friendly, improving the performance substantially when plugged into various baseline architectures. Without bells and whistles, the full model sets new state-of-the-art results on the Pascal-Part dataset, in both multi-class and the conventional single-class setting, while running substantially faster than recent high-performance approaches.",60014966,Peking University,Beijing,China,"['1712', '1707']",25.57142857142857,0.17325036075036074,0.5265752765752767,1,0.11160714285714286,0.008928571428571428,0.3181818181818182
1572,1606,1606,SceneGraphNet: Neural message passing for 3D indoor scene augmentation,"In this paper we propose a neural message passing approach to augment an input 3D indoor scene with new objects matching their surroundings. Given an input, potentially incomplete, 3D scene and a query location, our method predicts a probability distribution over object types that fit well in that location. Our distribution is predicted though passing learned messages in a dense graph whose nodes represent objects in the input scene and edges represent spatial and structural relationships. By weighting messages through an attention mechanism, our method learns to focus on the most relevant surrounding scene context to predict new scene objects. We found that our method significantly outperforms state-of-the-art approaches in terms of correctly predicting objects missing in a scene based on our experiments in the SUNCG dataset. We also demonstrate other applications of our method, including context-based 3D object recognition and iterative scene generation.",60014313,University of Massachusetts Amherst,Amherst MA,United States,"['1712', '1707']",24.0,0.1803030303030303,0.5565656565656565,1,0.15337423312883436,0.006134969325153374,0.2838709677419355
1573,1607,1607,Dynamic-Net: Tuning the objective without re-training for synthesis tasks,"One of the key ingredients for successful optimization of modern CNNs is identifying a suitable objective. To date, the objective is fixed a-priori at training time, and any variation to it requires re-training a new network. In this paper we present a first attempt at alleviating the need for re-training. Rather than fixing the network at training time, we train a ''Dynamic-Net'' that can be modified at inference time. Our approach considers an ''objective-space'' as the space of all linear combinations of two objectives, and the Dynamic-Net is emulating the traversing of this objective-space at test-time, without any further training. We show that this upgrades pre-trained networks by providing an out-of-learning extension, while maintaining the performance quality. The solution we propose is fast and allows a user to interactively modify the network, in real-time, in order to obtain the result he/she desires. We show the benefits of such an approach via several different applications.",60022403,Technion - Israel Institute of Technology,Haifa,Israel,"['1712', '1707']",19.25,0.14575757575757578,0.4258585858585858,1,0.11274509803921569,0.00980392156862745,0.3275862068965517
1574,1608,1608,Learning a mixture of granularity-specific experts for fine-grained categorization,"We aim to divide the problem space of fine-grained recognition into some specific regions. To achieve this, we develop a unified framework based on a mixture of experts. Due to limited data available for the fine-grained recognition problem, it is not feasible to learn diverse experts by using a data division strategy. To tackle the problem, we promote diversity among experts by combing an expert gradually-enhanced learning strategy and a Kullback-Leibler divergence based constraint. The strategy learns new experts on the dataset with the prior knowledge from former experts and adds them to the model sequentially, while the introduced constraint forces the experts to produce diverse prediction distribution. These drive the experts to learn the task from different aspects, making them specialized in different subspace problems. Experiments show that the resulting model improves the classification performance and achieves the state-of-the-art performance on several fine-grained benchmark datasets.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",20.857142857142858,0.0339935064935065,0.2697402597402597,1,0.16091954022988506,0.011494252873563218,0.27848101265822783
1575,1609,1609,Anchor diffusion for unsupervised video object segmentation,"Unsupervised video object segmentation has often been tackled by methods based on recurrent neural networks and optical flow. Despite their complexity, these kinds of approach tend to favour short-term temporal dependencies and are thus prone to accumulating inaccuracies, which cause drift over time. Moreover, simple (static) image segmentation models, alone, can perform competitively against these methods, which further suggests that the way temporal dependencies are modelled should be reconsidered. Motivated by these observations, in this paper we explore simple yet effective strategies to model long-term temporal dependencies. Inspired by the non-local operators, we introduce a technique to establish dense correspondences between pixel embeddings of a reference 'anchor' frame and the current one. This allows the learning of pairwise dependencies at arbitrarily long distances without conditioning on intermediate frames. Without online supervision, our approach can suppress the background and precisely segment the foreground object even in challenging scenarios, while maintaining consistent performance over time. With a mean IoU of 81.7%, our method ranks first on the DAVIS-2016 leaderboard of unsupervised methods, while still being competitive against state-of-the-art online semi-supervised approaches. We further evaluate our method on the FBMS dataset and the video saliency dataset ViSal, showing results competitive with the state of the art.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",22.555555555555557,0.16442307692307695,0.5603937728937729,1,0.12704918032786885,0.00819672131147541,0.37117903930131
1576,1610,1610,Embodied amodal recognition: Learning to move to perceive objects,"Passive visual systems typically fail to recognize objects in the amodal setting where they are heavily occluded. In contrast, humans and other embodied agents have the ability to move in the environment and actively control the viewing angle to better understand object shapes and semantics. In this work, we introduce the task of Embodied Amodel Recognition (EAR): An agent is instantiated in a 3D environment close to an occluded target object, and is free to move in the environment to perform object classification, amodal object localization, and amodal object segmentation. To address this problem, we develop a new model called Embodied Mask R-CNN for agents to learn to move strategically to improve their visual recognition abilities. We conduct experiments using a simulator for indoor environments. Experimental results show that: 1) agents with embodiment (movement) achieve better visual recognition performance than passive ones and 2) in order to improve visual recognition abilities, agents can learn strategic paths that are different from shortest paths.",60021121,Indiana University Bloomington,Bloomington,United States,"['1712', '1707']",27.0,0.048430735930735935,0.3592532467532467,1,0.12432432432432433,0.03783783783783784,0.3551912568306011
1577,1611,1611,Person-in-WiFi: Fine-grained person perception using WiFi,"Fine-grained person perception such as body segmentation and pose estimation has been achieved with many 2D and 3D sensors such as RGB/depth cameras, radars (e.g. RF-Pose), and LiDARs. These solutions require 2D images, depth maps or 3D point clouds of person bodies as input. In this paper, we take one step forward to show that fine-grained person perception is possible even with 1D sensors: WiFi antennas. Specifically, we used two sets of WiFi antennas to acquire signals, i.e., one transmitter set and one receiver set. Each set contains three antennas horizontally lined-up as a regular household WiFi router. The WiFi signal generated by a transmitter antenna, penetrates through and reflects on human bodies, furniture, and walls, and then superposes at a receiver antenna as 1D signal samples. We developed a deep learning approach that uses annotations on 2D images, takes the received 1D WiFi signals as input, and performs body segmentation and pose estimation in an end-to-end manner. To our knowledge, our solution is the first work based on off-the-shelf WiFi antennas and standard IEEE 802.11n WiFi signals. Demonstrating comparable results to image-based solutions, our WiFi-based person perception solution is cheaper and more ubiquitous than radars and LiDARs, while invariant to illumination and has little privacy concern comparing to cameras.",60003970,Zhejiang University,Hangzhou,China,"['1712', '1707']",21.0,0.096875,0.3925213675213675,1,0.11153846153846154,0.06538461538461539,0.4435146443514644
1578,1612,1612,Batch weight for domain adaptation with mass shift,"Unsupervised domain transfer is the task of transferring or translating samples from a source distribution to a different target distribution. Current solutions unsupervised domain transfer often operate on data on which the modes of the distribution are well-matched, for instance have the same frequencies of classes between source and target distributions. However, these models do not perform well when the modes are not well-matched, as would be the case when samples are drawn independently from two different, but related, domains. This mode imbalance is problematic as generative adversarial networks (GANs), a successful approach in this setting, are sensitive to mode frequency, which results in a mismatch of semantics between source samples and generated samples of the target distribution. We propose a principled method of re-weighting training samples to correct for such mass shift between the transferred distributions, which we call batch weight. We also provide rigorous probabilistic setting for domain transfer and new simplified objective for training transfer networks, an alternative to complex, multi-component loss functions used in the current state-of-the art image-to-image translation models. The new objective stems from the discrimination of joint distributions and enforces cycle-consistency in an abstract, high-level, rather than pixel-wise, sense. Lastly, we experimentally show the effectiveness of the proposed methods in several image-to-image translation tasks.",60113142,Montreal Institute for Learning Algorithms,Montreal,Canada,"['1712', '1707']",26.375,0.05427807486631015,0.4064171122994653,1,0.09541984732824428,0.003816793893129771,0.3008474576271186
1579,1613,1613,Semi-supervised learning by augmented distribution alignment,"In this work, we propose a simple yet effective semi-supervised learning approach called Augmented Distribution Alignment. We reveal that an essential sampling bias exists in semi-supervised learning due to the limited number of labeled samples, which often leads to a considerable empirical distribution mismatch between labeled data and unlabeled data. To this end, we propose to align the empirical distributions of labeled and unlabeled data to alleviate the bias. On one hand, we adopt an adversarial training strategy to minimize the distribution distance between labeled and unlabeled data as inspired by domain adaptation works. On the other hand, to deal with the small sample size issue of labeled data, we also propose a simple interpolation strategy to generate pseudo training samples. Those two strategies can be easily implemented into existing deep neural networks. We demonstrate the effectiveness of our proposed approach on the benchmark SVHN and CIFAR10 datasets. Our code is available at https://github.com/qinenergy/adanet.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",19.25,0.08299319727891155,0.3850340136054423,1,0.13953488372093023,0.029069767441860465,0.29411764705882354
1580,1614,1614,Computational hyperspectral imaging based on dimension-discriminative low-rank tensor recovery,"Exploiting the prior information is fundamental for the image reconstruction in computational hyperspectral imaging. Existing methods usually unfold the 3D signal as a 1D vector and treat the prior information within different dimensions in an indiscriminative manner, which ignores the high-dimensionality nature of hyperspectral image (HSI) and thus results in poor quality reconstruction. In this paper, we propose to make full use of the high-dimensionality structure of the desired HSI to boost the reconstruction quality. We first build a high-order tensor by exploiting the nonlocal similarity in HSI. Then, we propose a dimension-discriminative low-rank tensor recovery (DLTR) model to characterize the structure prior adaptively in each dimension. By integrating the structure prior in DLTR with the system imaging process, we develop an optimization framework for HSI reconstruction, which is finally solved via the alternating minimization algorithm. Extensive experiments implemented with both synthetic and real data demonstrate that our method outperforms state-of-the-art methods.",60102437,China Academy of Space Technology,Beijing,China,"['1712', '1707']",21.714285714285715,0.012499999999999995,0.33055555555555555,1,0.10869565217391304,0.03804347826086957,0.30952380952380953
1581,1615,1615,Face alignment with kernel density deep neural network,"Deep neural networks achieve good performance in many computer vision problems such as face alignment. However, when the testing image is challenging due to low resolution, occlusion or adversarial attacks, the accuracy of a deep neural network suffers greatly. Therefore, it is important to quantify the uncertainty in its predictions. A probabilistic neural network with Gaussian distribution over the target is typically used to quantify uncertainty for regression problems. However, in real-world problems especially computer vision tasks, the Gaussian assumption is too strong. To model more general distributions, such as multi-modal or asymmetric distributions, we propose to develop a kernel density deep neural network. Specifically, for face alignment, we adapt state-of-the-art hourglass neural network into a probabilistic neural network framework with landmark probability map as its output. The model is trained by maximizing the conditional log likelihood. To exploit the output probability map, we extend the model to multi-stage so that the logits map from the previous stage can feed into the next stage to progressively improve the landmark detection accuracy. Extensive experiments on benchmark datasets against state-of-the-art unconstrained deep learning method demonstrate that the proposed kernel density network achieves comparable or superior performance in terms of prediction accuracy. It further provides aleatoric uncertainty estimation in predictions.",60025534,Rensselaer Polytechnic Institute,Troy,United States,"['1712', '1707']",18.818181818181817,0.14687499999999998,0.5399305555555556,1,0.0931174089068826,0.0,0.2576419213973799
1582,1616,1616,DAGMapper: Learning to map by discovering lane topology,"One of the fundamental challenges to scale self-driving is being able to create accurate high definition maps (HD maps) with low cost. Current attempts to automate this pro- cess typically focus on simple scenarios, estimate independent maps per frame or do not have the level of precision required by modern self driving vehicles. In contrast, in this paper we focus on drawing the lane boundaries of complex highways with many lanes that contain topology changes due to forks and merges. Towards this goal, we formulate the problem as inference in a directed acyclic graphical model (DAG), where the nodes of the graph encode geo- metric and topological properties of the local regions of the lane boundaries. Since we do not know a priori the topology of the lanes, we also infer the DAG topology (i.e., nodes and edges) for each region. We demonstrate the effectiveness of our approach on two major North American Highways in two different states and show high precision and recall as well as 89% correct topology.",60016849,University of Toronto,Toronto,Canada,"['1712', '1707']",28.33333333333333,0.08181372549019607,0.3938515406162464,1,0.08900523560209424,0.031413612565445025,0.31216931216931215
1583,1617,1617,Orientation-aware semantic segmentation on icosahedron spheres,"We address semantic segmentation on omnidirectional images, to leverage a holistic understanding of the surrounding scene for applications like autonomous driving systems. For the spherical domain, several methods recently adopt an icosahedron mesh, but systems are typically rotation invariant or require significant memory and parameters, thus enabling execution only at very low resolutions. In our work, we propose an orientation-aware CNN framework for the icosahedron mesh. Our representation allows for fast network operations, as our design simplifies to standard network operations of classical CNNs, but under consideration of north-aligned kernel convolutions for features on the sphere. We implement our representation and demonstrate its memory efficiency up-to a level-8 resolution mesh (equivalent to 640 x 1024 equirectangular images). Finally, since our kernels operate on the tangent of the sphere, standard feature weights, pretrained on perspective data, can be directly transferred with only small need for weight refinement. In our evaluation our orientation-aware CNN becomes a new state of the art for the recent 2D3DS dataset, and our Omni-SYNTHIA version of SYNTHIA. Rotation invariant classification and segmentation tasks are additionally presented for comparison to prior art.",60031101,University of Cambridge,Cambridge,United Kingdom,"['1712', '1707']",23.0,0.04414983164983165,0.434419191919192,1,0.0787037037037037,0.027777777777777776,0.32524271844660196
1584,1618,1618,PLMP - Point-line minimal problems in complete multi-view visibility,"We present a complete classification of all minimal problems for generic arrangements of points and lines completely observed by calibrated perspective cameras. We show that there are only 30 minimal problems in total, no problems exist for more than 6 cameras, for more than 5 points, and for more than 6 lines. We present a sequence of tests for detecting minimality starting with counting degrees of freedom and ending with full symbolic and numeric verification of representative examples. For all minimal problems discovered, we present their algebraic degrees, i.e. the number of solutions, which measure their intrinsic difficulty. It shows how exactly the difficulty of problems grows with the number of views. Importantly, several new mini- mal problems have small degrees that might be practical in image matching and 3D reconstruction.",60019647,Georgia Institute of Technology,Atlanta,United States,"['1712', '1707']",18.714285714285715,0.0943181818181818,0.3802272727272727,1,0.1111111111111111,0.0,0.36551724137931035
1585,1619,1619,Neural inverse rendering of an indoor scene from a single image,"Inverse rendering aims to estimate physical attributes of a scene, e.g., reflectance, geometry, and lighting, from image(s). Inverse rendering has been studied primarily for single objects or with methods that solve for only one of the scene attributes. We propose the first learning based approach that jointly estimates albedo, normals, and lighting of an indoor scene from a single image. Our key contribution is the Residual Appearance Renderer (RAR), which can be trained to synthesize complex appearance effects (e.g., inter-reflection, cast shadows, near-field illumination, and realistic shading), which would be neglected otherwise. This enables us to perform self-supervised learning on real data using a reconstruction loss, based on re-synthesizing the input image from the estimated components. We finetune with real data after pretraining with synthetic data. To this end, we use physically-based rendering to create a large-scale synthetic dataset, named SUNCG-PBR, which is a significant improvement over prior datasets. Experimental results show that our approach outperforms state-of-the-art methods that estimate one or more scene attributes.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",20.625,0.1165873015873016,0.4342063492063492,1,0.12558139534883722,0.037209302325581395,0.38071065989847713
1586,1620,1620,Homography from two orientation- and scale-covariant features,"This paper proposes a geometric interpretation of the angles and scales which the orientation- and scale-covariant feature detectors, e.g. SIFT, provide. Two new general constraints are derived on the scales and rotations which can be used in any geometric model estimation tasks. Using these formulas, two new constraints on homography estimation are introduced. Exploiting the derived equations, a solver for estimating the homography from the minimal number of two correspondences is proposed. Also, it is shown how the normalization of the point correspondences affects the rotation and scale parameters, thus achieving numerically stable results. Due to requiring merely two feature pairs, robust estimators, e.g. RANSAC, do significantly fewer iterations than by using the four-point algorithm. When using covariant features, e.g. SIFT, this additional information is given at no cost. The method is tested in a synthetic environment and on publicly available real-world datasets.",60024855,Computer and Automation Research Institute Hungarian Academy of Sciences,Budapest,Hungary,"['1712', '1707']",13.0,0.0465909090909091,0.5198863636363636,1,0.1130952380952381,0.017857142857142856,0.4
1587,1621,1621,Semantic part detection via matching: Learning to generalize to novel viewpoints from limited training data,"Detecting semantic parts of an object is a challenging task, particularly because it is hard to annotate semantic parts and construct large datasets. In this paper, we present an approach which can learn from a small annotated dataset containing a limited range of viewpoints and generalize to detect semantic parts for a much larger range of viewpoints. The approach is based on our matching algorithm, which is used for finding accurate spatial correspondence between two images and transplanting semantic parts annotated on one image to the other. Images in the training set are matched to synthetic images rendered from a 3D CAD model, following which a clustering algorithm is used to automatically annotate semantic parts of the CAD model. During the testing period, this CAD model can synthesize annotated images under every viewpoint. These synthesized images are matched to images in the testing set to detect semantic parts in novel viewpoints. Our algorithm is simple, intuitive, and contains very few parameters. Experiments show our method outperforms standard deep learning approaches and, in particular, performs much better on novel viewpoints. For facilitating the future research, code is available: Https://github.com/ytongbai/SemanticPartDetection.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",20.88888888888889,0.07102756892230577,0.3526441102756892,1,0.15865384615384615,0.014423076923076924,0.3238095238095238
1588,1622,1622,Joint monocular 3D vehicle detection and tracking,"Vehicle 3D extents and trajectories are critical cues for predicting the future location of vehicles and planning future agent ego-motion based on those predictions. In this paper, we propose a novel online framework for 3D vehicle detection and tracking from monocular videos. The framework can not only associate detections of vehicles in motion over time, but also estimate their complete 3D bounding box information from a sequence of 2D images captured on a moving platform. Our method leverages 3D box depth-ordering matching for robust instance association and utilizes 3D trajectory prediction for re-identification of occluded vehicles. We also design a motion learning module based on an LSTM for more accurate long-term motion extrapolation. Our experiments on simulation, KITTI, and Argoverse datasets show that our 3D tracking pipeline offers robust data association and tracking. On Argoverse, our image-based method is significantly better for tracking 3D vehicles within 30 meters than the LiDAR-centric baseline methods.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",21.857142857142854,0.17777777777777778,0.4537037037037037,1,0.11299435028248588,0.02824858757062147,0.3939393939393939
1589,1623,1623,Human uncertainty makes classification more robust,"The classification performance of deep neural networks has begun to asymptote at near-perfect levels. However, their ability to generalize outside the training set and their robustness to adversarial attacks have not. In this paper, we make progress on this problem by training with full label distributions that reflect human perceptual uncertainty. We first present a new benchmark dataset which we call CIFAR10H, containing a full distribution of human labels for each image of the CIFAR10 test set. We then show that, while contemporary classifiers fail to exhibit human-like uncertainty on their own, explicit training on our dataset closes this gap, supports improved generalization to increasingly out-of-training-distribution test datasets, and confers robustness to adversarial attacks.",60003269,Princeton University,Princeton,United States,"['1712', '1707']",22.8,0.11275252525252526,0.3337121212121212,1,0.10294117647058823,0.014705882352941176,0.31746031746031744
1590,1624,1624,Local aggregation for unsupervised learning of visual embeddings,"Unsupervised approaches to learning in neural networks are of substantial interest for furthering artificial intelligence, both because they would enable the training of networks without the need for large numbers of expensive annotations, and because they would be better models of the kind of general-purpose learning deployed by humans. However, unsupervised networks have long lagged behind the performance of their supervised counterparts, especially in the domain of large-scale visual recognition. Recent developments in training deep convolutional embeddings to maximize non-parametric instance separation and clustering objectives have shown promise in closing this gap. Here, we describe a method that trains an embedding function to maximize a metric of local aggregation, causing similar data instances to move together in the embedding space, while allowing dissimilar instances to separate. This aggregation metric is dynamic, allowing soft clusters of different scales to emerge. We evaluate our procedure on several large-scale visual recognition datasets, achieving state-of-the-art unsupervised transfer learning performance on object recognition in ImageNet, scene recognition in Places 205, and object detection in PASCAL VOC.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",28.5,-0.007539682539682539,0.4330687830687831,1,0.14356435643564355,0.01485148514851485,0.31382978723404253
1591,1625,1625,Incremental learning using conditional adversarial networks,"Incremental learning using Deep Neural Networks (DNNs) suffers from catastrophic forgetting. Existing methods mitigate it by either storing old image examples or only updating a few fully connected layers of DNNs, which, however, requires large memory footprints or hurts the plasticity of models. In this paper, we propose a new incremental learning strategy based on conditional adversarial networks. Our new strategy allows us to use memory-efficient statistical information to store old knowledge, and fine-tune both convolutional layers and fully connected layers to consolidate new knowledge. Specifically, we propose a model consisting of three parts, i.e., a base sub-net, a generator, and a discriminator. The base sub-net works as a feature extractor which can be pre-trained on large scale datasets and shared across multiple image recognition tasks. The generator conditioned on labeled embeddings aims to construct pseudo-examples with the same distribution as the old data. The discriminator combines real-examples from new data and pseudo-examples generated from the old data distribution to learn representation for both old and new classes. Through adversarial training of the discriminator and generator, we accomplish the multiple continuous incremental learning. Comparison with the state-of-the-arts on public CIFAR-100 and CUB-200 datasets shows that our method achieves the best accuracies on both old and new classes while requiring relatively less memory storage.",60018008,"NEC Laboratories America, Inc.",Princeton,United States,"['1712', '1707']",21.3,0.01077256077256078,0.3670288045288045,1,0.12790697674418605,0.015503875968992248,0.3347457627118644
1592,1626,1626,Deep CG2Real: Synthetic-to-real translation via image disentanglement,"We present a method to improve the visual realism of low-quality, synthetic images, e.g. OpenGL renderings. Training an unpaired synthetic-to-real translation network in image space is severely under-constrained and produces visible artifacts. Instead, we propose a semi-supervised approach that operates on the disentangled shading and albedo layers of the image. Our two-stage pipeline first learns to predict accurate shading in a supervised fashion using physically-based renderings as targets, and further increases the realism of the textures and shading with an improved CycleGAN network. Extensive evaluations on the SUNCG indoor scene dataset demonstrate that our approach yields more realistic images compared to other state-of-the-art approaches. Furthermore, networks trained on our generated ''real'' images predict more accurate depth and normals than domain adaptation approaches, suggesting that improving the visual realism of the images can be more effective than imposing task-specific losses.",60030612,"University of California, San Diego",San Diego,United States,"['1712', '1707']",19.857142857142858,0.2261111111111111,0.3827777777777778,1,0.14124293785310735,0.005649717514124294,0.3961038961038961
1593,1627,1627,3D point cloud generative adversarial network based on tree structured graph convolutions,"In this paper, we propose a novel generative adversarial network (GAN) for 3D point clouds generation, which is called tree-GAN. To achieve state-of-the-art performance for multi-class 3D point cloud generation, a tree-structured graph convolution network (TreeGCN) is introduced as a generator for tree-GAN. Because TreeGCN performs graph convolutions within a tree, it can use ancestor information to boost the representation power for features. To evaluate GANs for 3D point clouds accurately, we develop a novel evaluation metric called Fr'echet point cloud distance (FPD). Experimental results demonstrate that the proposed tree-GAN outperforms state-of-the-art GANs in terms of both conventional metrics and FPD, and can generate point clouds for different semantic parts without prior knowledge.",60014237,Chung-Ang University,Seoul,South Korea,"['1712', '1707']",22.6,0.07142857142857145,0.3980952380952381,1,0.1118421052631579,0.046052631578947366,0.4230769230769231
1594,1628,1628,Better and faster: Exponential loss for image patch matching,"Recent studies on image patch matching are paying more attention on hard sample learning, because easy samples do not contribute much to the network optimization. They have proposed various hard negative sample mining strategies, but very few addressed this problem from the perspective of loss functions. Our research shows that the conventional Siamese and triplet losses treat all samples linearly, thus make the training time consuming. Instead, we propose the exponential Siamese and triplet losses, which can naturally focus more on hard samples and put less emphasis on easy ones, meanwhile, speed up the optimization. To assist the exponential losses, we introduce the hard positive sample mining to further enhance the effectiveness. The extensive experiments demonstrate our proposal improves both metric and descriptor learning on several well accepted benchmarks, and outperforms the state-of-the-arts on the UBC dataset. Moreover, it also shows a better generalizability on cross-spectral image matching and image retrieval tasks.",60025578,Xidian University,Xi'an,China,"['1712', '1707']",21.714285714285715,0.040845186559472266,0.4293300350443208,1,0.12429378531073447,0.005649717514124294,0.28402366863905326
1595,1629,1629,Camera distance-aware top-down approach for 3D multi-person pose estimation from a single RGB image,"Although significant improvement has been achieved recently in 3D human pose estimation, most of the previous methods only treat a single-person case. In this work, we firstly propose a fully learning-based, camera distance-aware top-down approach for 3D multi-person pose estimation from a single RGB image. The pipeline of the proposed system consists of human detection, absolute 3D human root localization, and root-relative 3D single-person pose estimation modules. Our system achieves comparable results with the state-of-the-art 3D single-person pose estimation models without any groundtruth information and significantly outperforms previous 3D multi-person pose estimation methods on publicly available datasets. The code is available in footnote{url{https://github.com/mks0601/3DMPPE-ROOTNET-RELEASE}}textsuperscript{,}footnote{url{https://github.com/mks0601/3DMPPE-POSENET-RELEASE}}.",60120116,Automation and Systems Research Institute,Seoul,South Korea,"['1712', '1707']",20.6,0.14965986394557826,0.4379251700680273,1,0.06622516556291391,0.039735099337748346,0.4701492537313433
1596,1630,1630,Towards precise end-to-end weakly supervised object detection network,"It is challenging for weakly supervised object detection network to precisely predict the positions of the objects, since there are no instance-level category annotations. Most existing methods tend to solve this problem by using a two-phase learning procedure, i.e., multiple instance learning detector followed by a fully supervised learning detector with bounding-box regression. Based on our observation, this procedure may lead to local minima for some object categories. In this paper, we propose to jointly train the two phases in an end-to-end manner to tackle this problem. Specifically, we design a single network with both multiple instance learning and bounding-box regression branches that share the same backbone. Meanwhile, a guided attention module using classification loss is added to the backbone for effectively extracting the implicit location information in the features. Experimental results on public datasets show that our method achieves state-of-the-art performance.",60024350,National University of Defense Technology,Changsha,China,"['1712', '1707']",20.285714285714285,0.13779761904761906,0.37757936507936507,1,0.14367816091954022,0.0,0.30128205128205127
1597,1631,1631,Softtriple loss: Deep metric learning without triplet sampling,"Distance metric learning (DML) is to learn the embeddings where examples from the same class are closer than examples from different classes. It can be cast as an optimization problem with triplet constraints. Due to the vast number of triplet constraints, a sampling strategy is essential for DML. With the tremendous success of deep learning in classifications, it has been applied for DML. When learning embeddings with deep neural networks (DNNs), only a mini-batch of data is available at each iteration. The set of triplet constraints has to be sampled within the mini-batch. Since a mini-batch cannot capture the neighbors in the original set well, it makes the learned embeddings sub-optimal. On the contrary, optimizing SoftMax loss, which is a classification loss, with DNN shows a superior performance in certain DML tasks. It inspires us to investigate the formulation of SoftMax. Our analysis shows that SoftMax loss is equivalent to a smoothed triplet loss where each class has a single center. In real-world data, one class can contain several local clusters rather than a single one, e.g., birds of different poses. Therefore, we propose the SoftTriple loss to extend the SoftMax loss with multiple centers for each class. Compared with conventional deep metric learning algorithms, optimizing SoftTriple loss can learn the embeddings without the sampling phase by mildly increasing the size of the last fully connected layer. Experiments on the benchmark fine-grained data sets demonstrate the effectiveness of the proposed loss function.",60118460,Alibaba Group Holding Limited,Yu Hang,China,"['1712', '1707']",17.285714285714285,0.0858095238095238,0.41095238095238096,1,0.09824561403508772,0.042105263157894736,0.3443223443223443
1598,1632,1632,SC-FEGAN: Face editing generative adversarial network with user's sketch and color,"We present a novel image editing system that generates images as the user provides free-form masks, sketches and color as inputs. Our system consists of an end-to-end trainable convolutional network. In contrast to the existing methods, our system utilizes entirely free-form user input in terms of color and shape. This allows the system to respond to the user's sketch and color inputs, using them as guidelines to generate an image. In this work, we trained the network with an additional style loss, which made it possible to generate realistic results despite large portions of the image being removed. Our proposed network architecture SC-FEGAN is well suited for generating high-quality synthetic images using intuitive user inputs.",60001558,Electronics and Telecommunications Research Institute,Daejeon,South Korea,"['1712', '1707']",19.166666666666668,0.07619047619047617,0.4773809523809524,1,0.1223021582733813,0.014388489208633094,0.36220472440944884
1599,1633,1633,Anchor loss: Modulating loss scale based on prediction difficulty,"We propose a novel loss function that dynamically re-scales the cross entropy based on prediction difficulty regarding a sample. Deep neural network architectures in image classification tasks struggle to disambiguate visually similar objects. Likewise, in human pose estimation symmetric body parts often confuse the network with assigning indiscriminative scores to them. This is due to the output prediction, in which only the highest confidence label is selected without taking into consideration a measure of uncertainty. In this work, we define the prediction difficulty as a relative property coming from the confidence score gap between positive and negative labels. More precisely, the proposed loss function penalizes the network to avoid the score of a false prediction being significant. To demonstrate the efficacy of our loss function, we evaluate it on two different domains: Image classification and human pose estimation. We find improvements in both applications by achieving higher accuracy compared to the baseline methods.",60031581,California Institute of Technology,Pasadena,United States,"['1712', '1707']",19.125,0.05795454545454545,0.44971590909090897,1,0.11834319526627218,0.005917159763313609,0.24550898203592814
1600,1634,1634,Robust person re-identification by modelling feature uncertainty,"We aim to learn deep person re-identification (ReID) models that are robust against noisy training data. Two types of noise are prevalent in practice: (1) label noise caused by human annotator errors and (2) data outliers caused by person detector errors or occlusion. Both types of noise pose serious problems for training ReID models, yet have been largely ignored so far. In this paper, we propose a novel deep network termed DistributionNet for robust ReID. Instead of representing each person image as a feature vector, DistributionNet models it as a Gaussian distribution with its variance representing the uncertainty of the extracted features. A carefully designed loss is formulated in DistributionNet to unevenly allocate uncertainty across training samples. Consequently, noisy samples are assigned large variance/uncertainty, which effectively alleviates their negative impacts on model fitting. Extensive experiments demonstrate that our model is more effective than alternative noise-robust deep models. The source code is available at: Https://github.com/TianyuanYu/DistributionNet.",60027272,University of Edinburgh,Edinburgh,United Kingdom,"['1712', '1707']",17.11111111111111,0.08029100529100527,0.5420634920634922,1,0.0989010989010989,0.03296703296703297,0.3707865168539326
1601,1635,1635,Suicidal ideation detection via social media analytics,"Suicide is one of the increasingly serious public health problems in modern society. Traditional suicidal ideation detection using questionnaires or patients’ self-report about their feelings and experiences is normally considered insufficient, passive, and untimely. With the advancement of Internet technology, social networking platforms are becoming increasingly popular. In this paper, we propose a suicidal ideation detection method based on multi-feature weighted fusion. We extracted linguistic features set that related to suicide by three different dictionaries, which are data-driven dictionary, Chinese suicide dictionary, and Language Inquiry and Word Count (LIWC). Two machine learning algorithms are utilized to build weak classification model with these three feature sets separately to generate six detection results. And after logistic regression, to get the final weighted results. In such a scheme, the results of model evaluation reveal that the proposed detection method achieves significantly better performance than that use existing feature selection methods.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],18.375,0.08281250000000001,0.4984375,1,0.09826589595375723,0.028901734104046242,0.3413173652694611
1602,1636,1636,Bridging the gap between detection and tracking: A unified approach,"Object detection models have been a source of inspiration for many tracking-by-detection algorithms over the past decade. Recent deep trackers borrow designs or modules from the latest object detection methods, such as bounding box regression, RPN and ROI pooling, and can deliver impressive performance. In this paper, instead of redesigning a new tracking-by-detection algorithm, we aim to explore a general framework for building trackers directly upon almost any advanced object detector. To achieve this, three key gaps must be bridged: (1) Object detectors are class-specific, while trackers are class-agnostic. (2) Object detectors do not differentiate intra-class instances, while this is a critical capability of a tracker. (3) Temporal cues are important for stable long-term tracking while they are not considered in still-image detectors. To address the above issues, we first present a simple target-guidance module for guiding the detector to locate target-relevant objects. Then a meta-learner is adopted for the detector to fast learn and adapt a target-distractor classifier online. We further introduce an anchored updating strategy to alleviate the problem of overfitting. The framework is instantiated on SSD and FasterRCNN, the typical one- and two-stage detectors, respectively. Experiments on OTB, UAV123 and NfS have verified our framework and show that our trackers can benefit from deeper backbone networks, as opposed to many recent trackers.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",19.545454545454547,0.1147878787878788,0.5118008658008658,1,0.11313868613138686,0.021897810218978103,0.3861788617886179
1603,1637,1637,FCOS: Fully convolutional one-stage object detection,"We propose a fully convolutional one-stage object detector (FCOS) to solve object detection in a per-pixel prediction fashion, analogue to semantic segmentation. Almost all state-of-the-art object detectors such as RetinaNet, SSD, YOLOv3, and Faster R-CNN rely on pre-defined anchor boxes. In contrast, our proposed detector FCOS is anchor box free, as well as proposal free. By eliminating the pre-defined set of anchor boxes, FCOS completely avoids the complicated computation related to anchor boxes such as calculating overlapping during training. More importantly, we also avoid all hyper-parameters related to anchor boxes, which are often very sensitive to the final detection performance. With the only post-processing non-maximum suppression (NMS), FCOS with ResNeXt-64x4d-101 achieves 44.7% in AP with single-model and single-scale testing, surpassing previous one-stage detectors with the advantage of being much simpler. For the first time, we demonstrate a much simpler and flexible detection framework achieving improved detection accuracy. We hope that the proposed FCOS framework can serve as a simple and strong alternative for many other instance-level tasks. Code is available at: Https://tinyurl.com/FCOSv1.",60009512,The University of Adelaide,Adelaide,Australia,"['1712', '1707']",19.11111111111111,0.14189393939393938,0.5711580086580086,1,0.09606986899563319,0.0611353711790393,0.39303482587064675
1604,1638,1638,Once a MAN: Towards multi-target attack via learning multi-target adversarial network once,"Modern deep neural networks are often vulnerable to adversarial samples. Based on the first optimization-based attacking method, many following methods are proposed to improve the attacking performance and speed. Recently, generation-based methods have received much attention since they directly use feed-forward networks to generate the adversarial samples, which avoid the time-consuming iterative attacking procedure in optimization-based and gradient-based methods. However, current generation-based methods are only able to attack one specific target (category) within one model, thus making them not applicable to real classification systems that often have hundreds/thousands of categories. In this paper, we propose the first Multi-target Adversarial Network (MAN), which can generate multi-target adversarial samples with a single model. By incorporating the specified category information into the intermediate features, it can attack any category of the target classification model during runtime. Experiments show that the proposed MAN can produce stronger attack results and also have better transferability than previous state-of-the-art methods in both multi-target attack task and single-target attack task. We further use the adversarial samples generated by our MAN to improve the robustness of the classification model. It can also achieve better classification accuracy than other methods when attacked by various methods.",60019118,University of Science and Technology of China,Hefei,China,"['1712', '1707']",21.66666666666667,0.10622294372294372,0.3873917748917749,1,0.14634146341463414,0.012195121951219513,0.36574074074074076
1605,1639,1639,A fast and accurate one-stage approach to visual grounding,"We propose a simple, fast, and accurate one-stage approach to visual grounding, inspired by the following insight. The performances of existing propose-and-rank two-stage methods are capped by the quality of the region candidates they propose in the first stage - - if none of the candidates could cover the ground truth region, there is no hope in the second stage to rank the right region to the top. To avoid this caveat, we propose a one-stage model that enables end-to-end joint optimization. The main idea is as straightforward as fusing a text query's embedding into the YOLOv3 object detector, augmented by spatial features so as to account for spatial mentions in the query. Despite being simple, this one-stage approach shows great potential in terms of both accuracy and speed for both phrase localization and referring expression comprehension, according to our experiments. Given these results along with careful investigations into some popular region proposals, we advocate for visual grounding a paradigm shift from the conventional two-stage methods to the one-stage framework.",60027165,University of Rochester,Rochester,United States,"['1712', '1707']",28.33333333333333,0.13339598997493735,0.47537593984962395,1,0.10194174757281553,0.0048543689320388345,0.26344086021505375
1606,1640,1640,A geometry-inspired decision-based attack,"Deep neural networks have recently achieved tremendous success in image classification. Recent studies have however shown that they are easily misled into incorrect classification decisions by adversarial examples. Adversaries can even craft attacks by querying the model in black-box settings, where no information about the model is released except its final decision. Such decision-based attacks usually require lots of queries, while real-world image recognition systems might actually restrict the number of queries. In this paper, we propose qFool, a novel decision-based attack algorithm that can generate adversarial examples using a small number of queries. The qFool method can drastically reduce the number of queries compared to previous decision-based attacks while reaching the same quality of adversarial examples. We also enhance our method by constraining adversarial perturbations in low-frequency subspace, which can make qFool even more computationally efficient. Altogether, we manage to fool commercial image recognition systems with a small number of queries, which demonstrates the actual effectiveness of our new algorithm in practice.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",20.375,0.04368686868686869,0.3738636363636363,1,0.14736842105263157,0.015789473684210527,0.33146067415730335
1607,1641,1641,DANet: Divergent activation for weakly supervised object localization,"Weakly supervised object localization remains a challenge when learning object localization models from image category labels. Optimizing image classification tends to activate object parts and ignore the full object extent, while expanding object parts into full object extent could deteriorate the performance of image classification. In this paper, we propose a divergent activation (DA) approach, and target at learning complementary and discriminative visual patterns for image classification and weakly supervised object localization from the perspective of discrepancy. To this end, we design hierarchical divergent activation (HDA), which leverages the semantic discrepancy to spread feature activation, implicitly. We also propose discrepant divergent activation (DDA), which pursues object extent by learning mutually exclusive visual patterns, explicitly. Deep networks implemented with HDA and DDA, referred to as DANets, diverge and fuse discrepant yet discriminative features for image classification and object localization in an end-to-end manner. Experiments validate that DANets advance the performance of object localization while maintaining high performance of image classification on CUB-200 and ILSVRC datasets.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",23.42857142857143,0.013749999999999995,0.41125,1,0.14659685863874344,0.041884816753926704,0.3048128342245989
1608,1642,1642,Cascaded parallel filtering for memory-efficient image-based localization,"Image-based localization (IBL) aims to estimate the 6DOF camera pose for a given query image. The camera pose can be computed from 2D-3D matches between a query image and Structure-from-Motion (SfM) models. Despite recent advances in IBL, it remains difficult to simultaneously resolve the memory consumption and match ambiguity problems of large SfM models. In this work, we propose a cascaded parallel filtering method that leverages the feature, visibility and geometry information to filter wrong matches under binary feature representation. The core idea is that we divide the challenging filtering task into two parallel tasks before deriving an auxiliary camera pose for final filtering. One task focuses on preserving potentially correct matches, while another focuses on obtaining high quality matches to facilitate subsequent more powerful filtering. Moreover, our proposed method improves the localization accuracy by introducing a quality-aware spatial reconfiguration method and a principal focal length enhanced pose estimation method. Experimental results on real-world datasets demonstrate that our method achieves very competitive localization performances in a memory-efficient manner.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",21.0,0.06495238095238096,0.5579047619047621,1,0.12690355329949238,0.015228426395939087,0.32432432432432434
1609,1643,1643,Few-shot adversarial learning of realistic neural talking head models,"Several recent works have shown how highly realistic human head images can be obtained by training convolutional neural networks to generate them. In order to create a personalized talking head model, these works require training on a large dataset of images of a single person. However, in many practical scenarios, such personalized talking head models need to be learned from a few image views of a person, potentially even a single image. Here, we present a system with such few-shot capability. It performs lengthy meta-learning on a large dataset of videos, and after that is able to frame few- and one-shot learning of neural talking head models of previously unseen people as adversarial training problems with high capacity generators and discriminators. Crucially, the system is able to initialize the parameters of both the generator and the discriminator in a person-specific way, so that training can be based on just a few images and done quickly, despite the need to tune tens of millions of parameters. We show that such an approach is able to learn highly realistic and personalized talking head models of new people and even portrait paintings.",60107405,Skolkovo Institute of Science and Technology,Moscow,Russian Federation,"['1712', '1707']",27.0,0.09546453546453544,0.3899458874458875,1,0.12206572769953052,0.004694835680751174,0.25853658536585367
1610,1644,1644,Making the invisible visible: Action recognition through walls and occlusions,"Understanding people's actions and interactions typically depends on seeing them. Automating the process of action recognition from visual data has been the topic of much research in the computer vision community. But what if it is too dark, or if the person is occluded or behind a wall? In this paper, we introduce a neural network model that can detect human actions through walls and occlusions, and in poor lighting conditions. Our model takes radio frequency (RF) signals as input, generates 3D human skeletons as an intermediate representation, and recognizes actions and interactions of multiple people over time. By translating the input to an intermediate skeleton-based representation, our model can learn from both vision-based and RF-based datasets, and allow the two tasks to help each other. We show that our model achieves comparable accuracy to vision-based action recognition systems in visible scenarios, yet continues to work accurately when people are not visible, hence addressing scenarios that are beyond the limit of today's vision-based action recognition.",60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,"['1712', '1707']",27.5,-0.024404761904761898,0.2791666666666667,1,0.13333333333333333,0.015384615384615385,0.31891891891891894
1611,1645,1645,Dual attention matching for audio-visual event localization,"In this paper, we investigate the audio-visual event localization problem. This task is to localize a visible and audible event in a video. Previous methods first divide a video into short segments, and then fuse visual and acoustic features at the segment level. The duration of these segments is usually short, making the visual and acoustic feature of each segment possibly not well aligned. Direct concatenation of the two features at the segment level can be vulnerable to a minor temporal misalignment of the two signals. We propose a Dual Attention Matching (DAM) module to cover a longer video duration for better high-level event information modeling, while the local temporal information is attained by the global cross-check mechanism. Our premise is that one should watch the whole video to understand the high-level event, while shorter segments should be checked in detail for localization. Specifically, the global feature of one modality queries the local feature in the other modality in a bi-directional way. With temporal co-occurrence encoded between auditory and visual signals, DAM can be readily applied in various audio-visual event localization tasks, e.g., cross-modality localization, supervised event localization. Experiments on the AVE dataset show our method outperforms the state-of-the-art by a large margin.",60030452,Texas State University,San Marcos,United States,"['1712', '1707']",20.3,0.029648526077097507,0.2811224489795919,1,0.08097165991902834,0.012145748987854251,0.28
1612,1646,1646,Data-free learning of student networks,"Learning portable neural networks is very essential for computer vision for the purpose that pre-trained heavy deep models can be well applied on edge devices such as mobile phones and micro sensors. Most existing deep neural network compression and speed-up methods are very effective for training compact deep models, when we can directly access the training dataset. However, training data for the given deep network are often unavailable due to some practice problems (eg privacy, legal issue, and transmission), and the architecture of the given network are also unknown except some interfaces. To this end, we propose a novel framework for training efficient deep neural networks by exploiting generative adversarial networks (GANs). To be specific, the pre-trained teacher networks are regarded as a fixed discriminator and the generator is utilized for derivating training samples which can obtain the maximum response on the discriminator. Then, an efficient network with smaller model size and computational complexity is trained using the generated data and the teacher network, simultaneously. Efficient student networks learned using the proposed Data-Free Learning (DFL) method achieve 92.22% and 74.47% accuracies without any training data on the CIFAR-10 and CIFAR-100 datasets, respectively. Meanwhile, our student network obtains an 80.56% accuracy on the CelebA benchmark.",60014966,Peking University,Beijing,China,"['1712', '1707']",25.5,0.06972222222222223,0.4105555555555556,1,0.12916666666666668,0.029166666666666667,0.34051724137931033
1613,1648,1648,Hilbert-based generative defense for adversarial examples,"Adversarial perturbations of clean images are usually imperceptible for human eyes, but can confidently fool deep neural networks (DNNs) to make incorrect predictions. Such vulnerability of DNNs raises serious security concerns about their practicability in security-sensitive applications. To defend against such adversarial perturbations, recently developed PixelDefend purifies a perturbed image based on PixelCNN in a raster scan order (row/column by row/column). However, such scan mode insufficiently exploits the correlations between pixels, which further limits its robustness performance. Therefore, we propose a more advanced Hilbert curve scan order to model the pixel dependencies in this paper. Hilbert curve could well preserve local consistency when mapping from 2-D image to 1-D vector, thus the local features in neighboring pixels can be more effectively modeled. Moreover, the defensive power can be further improved via ensembles of Hilbert curve with different orientations. Experimental results demonstrate the superiority of our method over the state-of-the-art defenses against various adversarial attacks.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",19.25,0.12063492063492065,0.4571428571428571,1,0.10810810810810811,0.02702702702702703,0.3930635838150289
1614,1649,1649,GEOBIT: A geodesic-based binary descriptor invariant to non-rigid deformations for RGB-D images,"At the core of most three-dimensional alignment and tracking tasks resides the critical problem of point correspondence. In this context, the design of descriptors that efficiently and uniquely identifies keypoints, to be matched, is of central importance. Numerous descriptors have been developed for dealing with affine/perspective warps, but few can also handle non-rigid deformations. In this paper, we introduce a novel binary RGB-D descriptor invariant to isometric deformations. Our method uses geodesic isocurves on smooth textured manifolds. It combines appearance and geometric information from RGB-D images to tackle non-rigid transformations. We used our descriptor to track multiple textured depth maps and demonstrate that it produces reliable feature descriptors even in the presence of strong non-rigid deformations and depth noise. The experiments show that our descriptor outperforms different state-of-the-art descriptors in both precision-recall and recognition rate metrics. We also provide to the community a new dataset composed of annotated RGB-D images of different objects (shirts, cloths, paintings, bags), subjected to strong non-rigid deformations, to evaluate point correspondence algorithms.",60030074,Universidade Federal de Minas Gerais,Belo Horizonte,Brazil,"['1712', '1707']",18.555555555555557,0.15557359307359306,0.5050865800865799,1,0.11682242990654206,0.0,0.425531914893617
1615,1650,1650,Discriminative feature transformation for occluded pedestrian detection,"Despite promising performance achieved by deep con- volutional neural networks for non-occluded pedestrian de- tection, it remains a great challenge to detect partially oc- cluded pedestrians. Compared with non-occluded pedes- trian examples, it is generally more difficult to distinguish occluded pedestrian examples from background in featue space due to the missing of occluded parts. In this paper, we propose a discriminative feature transformation which en- forces feature separability of pedestrian and non-pedestrian examples to handle occlusions for pedestrian detection. Specifically, in feature space it makes pedestrian exam- ples approach the centroid of easily classified non-occluded pedestrian examples and pushes non-pedestrian examples close to the centroid of easily classified non-pedestrian ex- amples. Such a feature transformation partially compen- sates the missing contribution of occluded parts in feature space, therefore improving the performance for occluded pedestrian detection. We implement our approach in the Fast R-CNN framework by adding one transformation net- work branch. We validate the proposed approach on two widely used pedestrian detection datasets: Caltech and CityPersons. Experimental results show that our approach achieves promising performance for both non-occluded and occluded pedestrian detection.",60121156,Horizon Robotics,Haidian,China,"['1712', '1707']",22.75,0.08564814814814814,0.4606481481481482,1,0.1179245283018868,0.0330188679245283,0.37755102040816324
1616,1651,1651,Distillation-based training for multi-exit architectures,"Multi-exit architectures, in which a stack of processing layers is interleaved with early output layers, allow the processing of a test example to stop early and thus save computation time and/or energy. In this work, we propose a new training procedure for multi-exit architectures based on the principle of knowledge distillation. The method encourages early exits to mimic later, more accurate exits, by matching their probability outputs. Experiments on CIFAR100 and ImageNet show that distillation-based training significantly improves the accuracy of early exits while maintaining state-of-the-art accuracy for late ones. The method is particularly beneficial when training data is limited and also allows a straight-forward extension to semi-supervised learning, i.e. make use also of unlabeled data at training time. Moreover, it takes only a few lines to implement and imposes almost no computational overhead at training time, and none at all at test time.",60103776,Institute of Science and Technology Austria,Klosterneuburg,Austria,"['1712', '1707']",20.571428571428573,0.10047155225726656,0.4170763760049474,1,0.09770114942528736,0.017241379310344827,0.29559748427672955
1617,1652,1652,Non-local ConvLSTM for video compression artifact reduction,"Video compression artifact reduction aims to recover high-quality videos from low-quality compressed videos. Most existing approaches use a single neighboring frame or a pair of neighboring frames (preceding and/or following the target frame) for this task. Furthermore, as frames of high quality overall may contain low-quality patches, and high-quality patches may exist in frames of low quality overall, current methods focusing on nearby peak-quality frames (PQFs) may miss high-quality details in low-quality frames. To remedy these shortcomings, in this paper we propose a novel end-to-end deep neural network called non-local ConvLSTM (NL-ConvLSTM in short) that exploits multiple consecutive frames. An approximate non-local strategy is introduced in NL-ConvLSTM to capture global motion patterns and trace the spatiotemporal dependency in a video sequence. This approximate strategy makes the non-local module work in a fast and low space-cost way. Our method uses the preceding and following frames of the target frame to generate a residual, from which a higher quality frame is reconstructed. Experiments on two datasets show that NL-ConvLSTM outperforms the existing methods.",60009860,Fudan University,Shanghai,China,"['1712', '1707']",21.375,0.013253968253968256,0.30301587301587296,1,0.13513513513513514,0.036036036036036036,0.38421052631578945
1618,1653,1653,Symmetric cross entropy for robust learning with noisy labels,"Training accurate deep neural networks (DNNs) in the presence of noisy labels is an important and challenging task. Though a number of approaches have been proposed for learning with noisy labels, many open issues remain. In this paper, we show that DNN learning with Cross Entropy (CE) exhibits overfitting to noisy labels on some classes (''easy' classes), but more surprisingly, it also suffers from significant under learning on some other classes (''hard' classes). Intuitively, CE requires an extra term to facilitate learning of hard classes, and more importantly, this term should be noise tolerant, so as to avoid overfitting to noisy labels. Inspired by the symmetric KL-divergence, we propose the approach of Symmetric cross entropy Learning (SL), boosting CE symmetrically with a noise robust counterpart Reverse Cross Entropy (RCE). Our proposed SL approach simultaneously addresses both the under learning and overfitting problem of CE in the presence of noisy labels. We provide a theoretical analysis of SL and also empirically show, on a range of benchmark and real-world datasets, that SL outperforms state-of-the-art methods. We also show that SL can be easily incorporated into existing methods in order to further enhance their performance.",60026553,University of Melbourne,Parkville,Australia,"['1712', '1707']",24.125,0.1638888888888889,0.5013888888888888,1,0.11203319502074689,0.07468879668049792,0.4017467248908297
1619,1654,1654,PIFu: Pixel-aligned implicit function for high-resolution clothed human digitization,"We introduce Pixel-aligned Implicit Function (PIFu), an implicit representation that locally aligns pixels of 2D images with the global context of their corresponding 3D object. Using PIFu, we propose an end-to-end deep learning method for digitizing highly detailed clothed humans that can infer both 3D surface and texture from a single image, and optionally, multiple input images. Highly intricate shapes, such as hairstyles, clothing, as well as their variations and deformations can be digitized in a unified way. Compared to existing representations used for 3D deep learning, PIFu produces high-resolution surfaces including largely unseen regions such as the back of a person. In particular, it is memory efficient unlike the voxel representation, can handle arbitrary topology, and the resulting surface is spatially aligned with the input image. Furthermore, while previous techniques are designed to process either a single image or multiple views, PIFu extends naturally to arbitrary number of views. We demonstrate high-resolution and robust reconstructions on real world images from the DeepFashion dataset, which contains a variety of challenging clothing types. Our method achieves state-of-the-art performance on a public benchmark and outperforms the prior work for clothed human digitization from a single image.",60029311,University of Southern California,Los Angeles,United States,"['1712', '1707']",24.25,0.04416666666666668,0.3053373015873015,1,0.1282051282051282,0.02564102564102564,0.38073394495412843
1620,1655,1655,Multi-modality latent interaction network for visual question answering,"Exploiting relationships between visual regions and question words have achieved great success in learning multi-modality features for Visual Question Answering (VQA). However, we argue that existing methods mostly model relations between individual visual regions and words, which are not enough to correctly answer the question. From humans' perspective, answering a visual question requires understanding the summarizations of visual and language information. In this paper, we proposed the Multi-modality Latent Interaction module (MLI) to tackle this problem. The proposed module learns the cross-modality relationships between latent visual and language summarizations, which summarize visual regions and question into a small number of latent representations to avoid modeling uninformative individual region-word relations. The cross-modality information between the latent summarizations are propagated to fuse valuable information from both modalities and are used to update the visual and word features. Such MLI modules can be stacked for several stages to model complex and latent relations between the two modalities and achieves highly competitive performance on public VQA benchmarks, VQA v2.0 and TDIUC. In addition, we show that the performance of our methods could be significantly improved by combining with pre-trained language model BERT.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",23.5,0.07547619047619047,0.2538888888888889,1,0.13636363636363635,0.031818181818181815,0.3894230769230769
1621,1656,1656,Deep end-to-end alignment and refinement for time-of-flight RGB-D module,"Recently, it is increasingly popular to equip mobile RGB cameras with Time-of-Flight (ToF) sensors for active depth sensing. However, for off-the-shelf ToF sensors, one must tackle two problems in order to obtain high-quality depth with respect to the RGB camera, namely 1) online calibration and alignment; and 2) complicated error correction for ToF depth sensing. In this work, we propose a framework for jointly alignment and refinement via deep learning. First, a cross-modal optical flow between the RGB image and the ToF amplitude image is estimated for alignment. The aligned depth is then refined via an improved kernel predicting network that performs kernel normalization and applies the bias prior to the dynamic convolution. To enrich our data for end-to-end training, we have also synthesized a dataset using tools from computer graphics. Experimental results demonstrate the effectiveness of our approach, achieving state-of-the-art for ToF refinement.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",20.571428571428573,0.03518518518518518,0.45,1,0.08602150537634409,0.04838709677419355,0.3719512195121951
1622,1657,1657,Scoot: A perceptual metric for facial sketches,"While it is trivial for humans to quickly assess the perceptual similarity between two images, the underlying mechanism are thought to be quite complex. Despite this, the most widely adopted perceptual metrics today, such as SSIM and FSIM, are simple, shallow functions, and fail to consider many factors of human perception. Recently, the facial modeling community has observed that the inclusion of both structure and texture has a significant positive benefit for face sketch synthesis (FSS). But how perceptual are these so-called 'perceptual features'? Which elements are critical for their success? In this paper, we design a perceptual metric, called Structure Co-Occurrence Texture (Scoot), which simultaneously considers the block-level spatial structure and co-occurrence texture statistics. To test the quality of metrics, we propose three novel meta-measures based on various reliable properties. Extensive experiments verify that our Scoot metric exceeds the performance of prior work. Besides, we built the first largest scale (152k judgments) human-perception-based sketch database that can evaluate how well a metric consistent with human perception. Our results suggest that 'spatial structure' and 'co-occurrence texture' are two generally applicable perceptual features in face sketch synthesis.",60023998,Cardiff University,Cardiff,United Kingdom,"['1712', '1707']",23.25,0.0674901185770751,0.371489742141916,1,0.08898305084745763,0.03389830508474576,0.3548387096774194
1623,1658,1658,Learning to paint with model-based deep reinforcement learning,"We show how to teach machines to paint like human painters, who can use a small number of strokes to create fantastic paintings. By employing a neural renderer in model-based Deep Reinforcement Learning (DRL), our agents learn to determine the position and color of each stroke and make long-term plans to decompose texture-rich images into strokes. Experiments demonstrate that excellent visual effects can be achieved using hundreds of strokes. The training process does not require the experience of human painters or stroke tracking data. The code is available at https://github.com/hzwer/ICCV2019-LearningToPaint.",60014966,Peking University,Beijing,China,"['1712', '1707']",18.0,0.19375,0.4125,1,0.1619047619047619,0.047619047619047616,0.36633663366336633
1624,1659,1659,ACMM: Aligned cross-modal memory for few-shot image and sentence matching,"Image and sentence matching has drawn much attention recently, but due to the lack of sufficient pairwise data for training, most previous methods still cannot well associate those challenging pairs of images and sentences containing rarely appeared regions and words, i.e., few-shot content. In this work, we study this challenging scenario as few-shot image and sentence matching, and accordingly propose an Aligned Cross-Modal Memory (ACMM) model to memorize the rarely appeared content. Given a pair of image and sentence, the model first includes an aligned memory controller network to produce two sets of semantically-comparable interface vectors through cross-modal alignment. Then the interface vectors are used by modality-specific read and update operations to alternatively interact with shared memory items. The memory items persistently memorize cross-modal shared semantic representations, which can be addressed out to better enhance the representation of few-shot content. We apply the proposed model to both conventional and few-shot image and sentence matching tasks, and demonstrate its effectiveness by achieving the state-of-the-art performance on two benchmark datasets.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",28.0,0.2179563492063492,0.5401785714285714,1,0.14285714285714285,0.023809523809523808,0.34946236559139787
1625,1660,1660,Sequential adversarial learning for self-supervised deep visual odometry,"We propose a self-supervised learning framework for visual odometry (VO) that incorporates correlation of consecutive frames and takes advantage of adversarial learning. Previous methods tackle self-supervised VO as a local structure from motion (SfM) problem that recovers depth from single image and relative poses from image pairs by minimizing photometric loss between warped and captured images. As single-view depth estimation is an ill-posed problem, and photometric loss is incapable of discriminating distortion artifacts of warped images, the estimated depth is vague and pose is inaccurate. In contrast to previous methods, our framework learns a compact representation of frame-to-frame correlation, which is updated by incorporating sequential information. The updated representation is used for depth estimation. Besides, we tackle VO as a self-supervised image generation task and take advantage of Generative Adversarial Networks (GAN). The generator learns to estimate depth and pose to generate a warped target image. The discriminator evaluates the quality of generated image with high-level structural perception that overcomes the problem of pixel-wise loss in previous methods. Experiments on KITTI and Cityscapes datasets show that our method obtains more accurate depth with details preserved and predicted pose outperforms state-of-the-art self-supervised methods significantly.",60014966,Peking University,Beijing,China,"['1712', '1707']",21.444444444444443,0.01850649350649352,0.292965367965368,1,0.13389121338912133,0.03765690376569038,0.3568075117370892
1626,1661,1661,Learning aberrance repressed correlation filters for real-time UAV tracking,"Traditional framework of discriminative correlation filters (DCF) is often subject to undesired boundary effects. Several approaches to enlarge search regions have been already proposed in the past years to make up for this shortcoming. However, with excessive background information, more background noises are also introduced and the discriminative filter is prone to learn from the ambiance rather than the object. This situation, along with appearance changes of objects caused by full/partial occlusion, illumination variation, and other reasons has made it more likely to have aberrances in the detection process, which could substantially degrade the credibility of its result. Therefore, in this work, a novel approach to repress the aberrances happening during the detection process is proposed, i.e., aberrance repressed correlation filter (ARCF). By enforcing restriction to the rate of alteration in response maps generated in the detection phase, the ARCF tracker can evidently suppress aberrances and is thus more robust and accurate to track objects. Considerable experiments are conducted on different UAV datasets to perform object tracking from an aerial view, i.e., UAV123, UAVDT, and DTB70, with 243 challenging image sequences containing over 90K frames to verify the performance of the ARCF tracker and it has proven itself to have outperformed other 20 state-of-the-art trackers based on DCF and deep-based frameworks with sufficient speed for real-time applications.",60073652,Tongji University,Shanghai,China,"['1712', '1707']",31.0,0.11458333333333336,0.5322916666666666,1,0.10894941634241245,0.0311284046692607,0.3524590163934426
1627,1662,1662,Meta-learning to detect rare objects,"Few-shot learning, i.e., learning novel concepts from few examples, is fundamental to practical visual recognition systems. While most of existing work has focused on few-shot classification, we make a step towards few-shot object detection, a more challenging yet under-explored task. We develop a conceptually simple but powerful meta-learning based framework that simultaneously tackles few-shot classification and few-shot localization in a unified, coherent way. This framework leverages meta-level knowledge about 'model parameter generation' from base classes with abundant data to facilitate the generation of a detector for novel classes. Our key insight is to disentangle the learning of category-agnostic and category-specific components in a CNN based detection model. In particular, we introduce a weight prediction meta-model that enables predicting the parameters of category-specific components from few examples. We systematically benchmark the performance of modern detectors in the small-sample size regime. Experiments in a variety of realistic scenarios, including within-domain, cross-domain, and long-tailed settings, demonstrate the effectiveness and generality of our approach under different notions of novel classes.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",20.75,0.1395833333333333,0.5483630952380952,1,0.0958904109589041,0.0045662100456621,0.3602150537634409
1628,1663,1663,"Progressive-x: Efficient, anytime, multi-model fitting algorithm","The Progressive-X algorithm, Prog-X in short, is proposed for geometric multi-model fitting. The method interleaves sampling and consolidation of the current data interpretation via repetitive hypothesis proposal, fast rejection, and integration of the new hypothesis into the kept instance set by labeling energy minimization. Due to exploring the data progressively, the method has several beneficial properties compared with the state-of-the-art. First, a clear criterion, adopted from RANSAC, controls the termination and stops the algorithm when the probability of finding a new model with a reasonable number of inliers falls below a threshold. Second, Prog-X is an any-time algorithm. Thus, whenever is interrupted, e.g. due to a time limit, the returned instances cover real and, likely, the most dominant ones. The method is superior to the state-of-the-art in terms of accuracy in both synthetic experiments and on publicly available real-world datasets for homography, two-view motion, and motion segmentation.",60024855,Computer and Automation Research Institute Hungarian Academy of Sciences,Budapest,Hungary,"['1712', '1707']",18.375,0.1485645933014354,0.42767145135566187,1,0.07653061224489796,0.03571428571428571,0.3157894736842105
1629,1664,1664,Multi-adversarial faster-RCNN for unrestricted object detection,"Conventional object detection methods essentially suppose that the training and testing data are collected from a restricted target domain with expensive labeling cost. For alleviating the problem of domain dependency and cumbersome labeling, this paper proposes to detect objects in unrestricted environment by leveraging domain knowledge trained from an auxiliary source domain with sufficient labels. Specifically, we propose a multi-adversarial Faster-RCNN (MAF) framework for unrestricted object detection, which inherently addresses domain disparity minimization for domain adaptation in feature representation. The paper merits are in three-fold: 1) With the idea that object detectors often becomes domain incompatible when image distribution resulted domain disparity appears, we propose a hierarchical domain feature alignment module, in which multiple adversarial domain classifier submodules for layer-wise domain feature confusion are designed; 2) An information invariant scale reduction module (SRM) for hierarchical feature map resizing is proposed for promoting the training efficiency of adversarial domain adaptation; 3) In order to improve the domain adaptability, the aggregated proposal features with detection results are feed into a proposed weighted gradient reversal layer (WGRL) for characterizing hard confused domain samples. We evaluate our MAF on unrestricted tasks including Cityscapes, KITTI, Sim10k, etc. and the experiments show the state-of-the-art performance over the existing detectors.",60023380,Chongqing University,Chongqing,China,"['1712', '1707']",33.833333333333336,-0.22242063492063494,0.4331349206349207,1,0.10245901639344263,0.045081967213114756,0.34347826086956523
1630,1665,1665,Learning temporal action proposals with fewer labels,"Temporal action proposals are a common module in action detection pipelines today. Most current methods for training action proposal modules rely on fully supervised approaches that require large amounts of annotated temporal action intervals in long video sequences. The large cost and effort in annotation that this entails motivate us to study the problem of training proposal modules with less supervision. In this work, we propose a semi-supervised learning algorithm specifically designed for training temporal action proposal networks. When only a small number of labels are available, our semi-supervised method generates significantly better proposals than the fully-supervised counterpart and other strong semi-supervised baselines. We validate our method on two challenging action detection video datasets, ActivityNet v1.3 and THUMOS14. We show that our semi-supervised approach consistently matches or outperforms the fully supervised state-of-the-art approaches.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",19.0,0.12953514739229025,0.38010204081632654,1,0.11949685534591195,0.018867924528301886,0.3356643356643357
1631,1666,1666,Very long natural scenery image prediction by outpainting,"Comparing to image inpainting, image outpainting receives less attention due to two challenges in it. The first challenge is how to keep the spatial and content consistency between generated images and original input. The second challenge is how to maintain high quality in generated results, especially for multi-step generations in which generated regions are spatially far away from the initial input. To solve the two problems, we devise some innovative modules, named Skip Horizontal Connection and Recurrent Content Transfer, and integrate them into our designed encoder-decoder structure. By this design, our network can generate highly realistic outpainting prediction effectively and efficiently. Other than that, our method can generate new images with very long sizes while keeping the same style and semantic content as the given input. To test the effectiveness of the proposed architecture, we collect a new scenery dataset with diverse, complicated natural scenes. The experimental results on this dataset have demonstrated the efficacy of our proposed network.",60023932,University of Technology Sydney,Sydney,Australia,"['1712', '1707']",19.875,0.08213636363636362,0.4963712121212122,1,0.12777777777777777,0.03333333333333333,0.29545454545454547
1632,1667,1667,Lifelong GAN: Continual learning for conditional image generation,"Lifelong learning is challenging for deep neural networks due to their susceptibility to catastrophic forgetting. Catastrophic forgetting occurs when a trained network is not able to maintain its ability to accomplish previously learned tasks when it is trained to perform new tasks. We study the problem of lifelong learning for generative models, extending a trained network to new conditional generation tasks without forgetting previous tasks, while assuming access to the training data for the current task only. In contrast to state-of-the-art memory replay based approaches which are limited to label-conditioned image generation tasks, a more generic framework for continual learning of generative models under different conditional image generation settings is proposed in this paper. Lifelong GAN employs knowledge distillation to transfer learned knowledge from previous networks to the new network. This makes it possible to perform image-conditioned generation tasks in a lifelong learning setting. We validate Lifelong GAN for both image-conditioned and label-conditioned generation tasks, and provide qualitative and quantitative results to show the generality and effectiveness of our method.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",24.285714285714285,-0.0016971664698937426,0.4957497048406139,1,0.14871794871794872,0.010256410256410256,0.24861878453038674
1633,1668,1668,Meta R-CNN: Towards general solver for instance-level low-shot learning,"Resembling the rapid learning capability of human, low-shot learning empowers vision systems to understand new concepts by training with few samples. Leading approaches derived from meta-learning on images with a single visual object. Obfuscated by a complex background and multiple objects in one image, they are hard to promote the research of low-shot object detection/segmentation. In this work, we present a flexible and general methodology to achieve these tasks. Our work extends Faster /Mask R-CNN by proposing meta-learning over RoI (Region-of-Interest) features instead of a full image feature. This simple spirit disentangles multi-object information merged with the background, without bells and whistles, enabling Faster /Mask R-CNN turn into a meta-learner to achieve the tasks. Specifically, we introduce a Predictor-head Remodeling Network (PRN) that shares its main backbone with Faster /Mask R-CNN. PRN receives images containing low-shot objects with their bounding boxes or masks to infer their class attentive vectors. The vectors take channel-wise soft-attention on RoI features, remodeling those R-CNN predictor heads to detect or segment the objects consistent with the classes these vectors represent. In our experiments, Meta R-CNN yields the new state of the art in low-shot object detection and improves low-shot object segmentation by Mask R-CNN. Code: Url{https://yanxp.github.io/metarcnn.html}.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",18.272727272727273,0.039143668831168835,0.3222199675324676,1,0.10740740740740741,0.08518518518518518,0.4652173913043478
1634,1669,1669,A structural relationship between TQM practices and organizational performance with reference to selected auto component manufacturing companies," Quality management is a systematic way of guaranteeing that organized activities happen the way they are planned. TQM as long-term commitment to new learning and new philosophy is required of any management that seeks transformation. The objective is to study the TQM practices and their influence on organizational performance in selected auto component manufacturing companies located in the state of Tamilnadu, India and to find out the relationship of TQM practices on commitment and performance of the organization as a whole. TQM practices like management participation, team work, employee empowerment, training and development, process quality management, supplier quality management, employee encouragement and quality culture significantly influences the employee commitment. In turn employee commitment on TQM practices have significant influences on employee performance and quality performance as well.",121926171,GITAM Deemed to be University,Bengaluru,India,['1706'],25.6,0.2037878787878788,0.5265151515151515,0,0.07746478873239436,0.04929577464788732,0.2517985611510791
1635,1670,1670,Weakly supervised object detection with segmentation collaboration,"Weakly supervised object detection aims at learning precise object detectors, given image category labels. In recent prevailing works, this problem is generally formulated as a multiple instance learning module guided by an image classification loss. The object bounding box is assumed to be the one contributing most to the classification among all proposals. However, the region contributing most is also likely to be a crucial part or the supporting context of an object. To obtain a more accurate detector, in this work we propose a novel end-to-end weakly supervised detection approach, where a newly introduced generative adversarial segmentation module interacts with the conventional detection module in a collaborative loop. The collaboration mechanism takes full advantages of the complementary interpretations of the weakly supervised localization task, namely detection and segmentation tasks, forming a more comprehensive solution. Consequently, our method obtains more precise object bounding boxes, rather than parts or irrelevant surroundings. Expectedly, the proposed method achieves an accuracy of 53.7% on the PASCAL VOC 2007 dataset, outperforming the state-of-the-arts and demonstrating its superiority for weakly supervised object detection.",60030904,Institute of Computing Technology Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",22.125,0.09754376058723883,0.5650009410878977,1,0.13043478260869565,0.00966183574879227,0.30456852791878175
1636,1671,1671,Unsupervised high-resolution depth learning from videos with dual networks,"Unsupervised depth learning takes the appearance difference between a target view and a view synthesized from its adjacent frame as supervisory signal. Since the supervisory signal only comes from images themselves, the resolution of training data significantly impacts the performance. High-resolution images contain more fine-grained details and provide more accurate supervisory signal. However, due to the limitation of memory and computation power, the original images are typically down-sampled during training, which suffers heavy loss of details and disparity accuracy. In order to fully explore the information contained in high-resolution data, we propose a simple yet effective dual networks architecture, which can directly take high-resolution images as input and generate high-resolution and high-accuracy depth map efficiently. We also propose a Self-assembled Attention (SA-Attention) module to handle low-texture region. The evaluation on the benchmark KITTI and Make3D datasets demonstrates that our method achieves state-of-the-art results in the monocular depth estimation task.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",21.285714285714285,0.13525641025641028,0.6069597069597069,1,0.11578947368421053,0.021052631578947368,0.31097560975609756
1637,1672,1672,Geometric disentanglement for generative latent shape models,"Representing 3D shapes is a fundamental problem in artificial intelligence, which has numerous applications within computer vision and graphics. One avenue that has recently begun to be explored is the use of latent representations of generative models. However, it remains an open problem to learn a generative model of shapes that is interpretable and easily manipulated, particularly in the absence of supervised labels. In this paper, we propose an unsupervised approach to partitioning the latent space of a variational autoencoder for 3D point clouds in a natural way, using only geometric information, that builds upon prior work utilizing generative adversarial models of point sets. Our method makes use of tools from spectral geometry to separate intrinsic and extrinsic shape information, and then considers several hierarchical disentanglement penalties for dividing the latent space in this manner. We also propose a novel disentanglement penalty that penalizes the predicted change in the latent representation of the output,with respect to the latent variables of the initial shape. We show that the resulting latent representation exhibits intuitive and interpretable behaviour, enabling tasks such as pose transfer that cannot easily be performed by models with an entangled representation.",60016849,University of Toronto,Toronto,Canada,"['1712', '1707']",27.42857142857143,0.03720238095238095,0.4392857142857142,1,0.10952380952380952,0.0,0.26666666666666666
1638,1673,1673,Asynchronous single-photon 3D imaging,"Single-photon avalanche diodes (SPADs) are becoming popular in time-of-flight depth-ranging due to their unique ability to capture individual photons with picosecond timing resolution. However, ambient light (e.g., sunlight) incident on a SPAD-based 3D camera leads to severe non-linear distortions (pileup) in the measured waveform, resulting in large depth errors. We propose asynchronous single-photon 3D imaging, a family of acquisition schemes to mitigate pileup during data acquisition itself. Asynchronous acquisition temporally misaligns SPAD measurement windows and the laser cycles through deterministically predefined or randomized offsets. Our key insight is that pileup distortions can be 'averaged out' by choosing a sequence of offsets that span the entire depth range. We develop a generalized image formation model and perform theoretical analysis to explore the space of asynchronous acquisition schemes and design high-performance schemes. Our simulations and experiments demonstrate an improvement in depth accuracy of up to an order of magnitude as compared to the state-of-the-art, across a wide range of imaging scenarios, including those with high ambient flux.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",23.57142857142857,0.16452380952380952,0.6098809523809524,1,0.10576923076923077,0.038461538461538464,0.372972972972973
1639,1674,1674,Deep floor plan recognition using a multi-task network with room-boundary-guided attention,"This paper presents a new approach to recognize elements in floor plan layouts. Besides walls and rooms, we aim to recognize diverse floor plan elements, such as doors, windows and different types of rooms, in the floor layouts. To this end, we model a hierarchy of floor plan elements and design a deep multi-task neural network with two tasks: One to learn to predict room-boundary elements, and the other to predict rooms with types. More importantly, we formulate the room-boundary-guided attention mechanism in our spatial contextual module to carefully take room-boundary features into account to enhance the room-type predictions. Furthermore, we design a cross-and-within-task weighted loss to balance the multi-label tasks and prepare two new datasets for floor plan recognition. Experimental results demonstrate the superiority and effectiveness of our network over the state-of-the-art methods.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",22.33333333333333,0.10477272727272728,0.5684090909090911,1,0.10857142857142857,0.0,0.348993288590604
1640,1675,1675,Imitation learning for human pose prediction,"Modeling and prediction of human motion dynamics has long been a challenging problem in computer vision, and most existing methods rely on the end-to-end supervised training of various architectures of recurrent neural networks. Inspired by the recent success of deep reinforcement learning methods, in this paper we propose a new reinforcement learning formulation for the problem of human pose prediction, and develop an imitation learning algorithm for predicting future poses under this formulation through a combination of behavioral cloning and generative adversarial imitation learning. Our experiments show that our proposed method outperforms all existing state-of-the-art baseline models by large margins on the task of human pose prediction in both short-term predictions and long-term predictions, while also enjoying huge advantage in training speed.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",40.66666666666666,0.13141074611662848,0.3445951107715813,1,0.09090909090909091,0.0,0.2713178294573643
1641,1676,1676,Joint embedding of 3D Scan and CAD objects,"3D scan geometry and CAD models often contain complementary information towards understanding environments, which could be leveraged through establishing a mapping between the two domains. However, this is a challenging task due to strong, lower-level differences between scan and CAD geometry. We propose a novel approach to learn a joint embedding space between scan and CAD geometry, where semantically similar objects from both domains lie close together. To achieve this, we introduce a new 3D CNN-based approach to learn a joint embedding space representing object similarities across these domains. To learn a shared space where scan objects and CAD models can interlace, we propose a stacked hourglass approach to separate foreground and background from a scan object, and transform it to a complete, CAD-like representation to produce a shared embedding space. This embedding space can then be used for CAD model retrieval; to further enable this task, we introduce a new dataset of ranked scan-CAD similarity annotations, enabling new, fine-grained evaluation of CAD model retrieval to cluttered, noisy, partial scans. Our learned joint embedding outperforms current state of the art for CAD model retrieval by 12% in instance retrieval accuracy.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",27.142857142857146,0.11067493112947656,0.4974517906336088,1,0.13963963963963963,0.07657657657657657,0.33962264150943394
1642,1677,1677,Probabilistic deep ordinal regression based on gaussian processes,"With excellent representation power for complex data, deep neural networks (DNNs) based approaches are state-of-the-art for ordinal regression problem which aims to classify instances into ordinal categories. However, DNNs are not able to capture uncertainties and produce probabilistic interpretations. As a probabilistic model, Gaussian Processes (GPs) on the other hand offers uncertainty information, which is nonetheless lack of scalability for large datasets. This paper adapts traditional GPs regression for ordinal regression problem by using both conjugate and non-conjugate ordinal likelihood. Based on that, it proposes a deep neural network with a GPs layer on the top, which is trained end-to-end by the stochastic gradient descent method for both neural network parameters and GPs parameters. The parameters in the ordinal likelihood function are learned as neural network parameters so that the proposed framework is able to produce fitted likelihood functions for training sets and make probabilistic predictions for test points. Experimental results on three real-world benchmarks - image aesthetics rating, historical image grading and age group estimation - demonstrate that in terms of mean absolute error, the proposed approach outperforms state-of-the-art ordinal regression approaches and provides the confidence for predictions.",60005510,Nanyang Technological University,Singapore City,Singapore,"['1712', '1707']",27.0,0.10845238095238097,0.4994047619047619,1,0.08333333333333333,0.013157894736842105,0.3317307692307692
1643,1678,1678,Resource allocation in HetNets with green energy supply based on deep reinforcement learning,"Heterogeneous network (HetNet) is the main networking form of the fifth-generation mobile communication system. In this paper, we propose a heterogeneous network resource management algorithm based on deep reinforcement learning (DRL). This algorithm uses deep Q-network (DQN) to solve resource allocation problem in heterogeneous network. This algorithm encourages the use of green energy to power the base station as much as possible, minimizing the use of the power grid to power the base station and achieve maximum energy efficiency. The simulation results show that this algorithm has efficient learning ability, can effectively improve the energy efficiency of the network, thereby realize great resource management.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],20.8,-0.025925925925925908,0.6648148148148149,1,0.11382113821138211,0.032520325203252036,0.25210084033613445
1644,1679,1679,An efficient solution to the homography-based relative pose problem with a common reference direction,"In this paper, we propose a novel approach to two-view minimal-case relative pose problems based on homography with a common reference direction. We explore the rank-1 constraint on the difference between the Euclidean homography matrix and the corresponding rotation, and propose an efficient two-step solution for solving both the calibrated and partially calibrated (unknown focal length) problems. We derive new 3.5-point, 3.5-point, 4-point solvers for two cameras such that the two focal lengths are unknown but equal, one of them is unknown, and both are unknown and possibly different, respectively. We present detailed analyses and comparisons with existing 6 and 7-point solvers, including results with smart phone images.",60121156,Horizon Robotics,Haidian,China,"['1712', '1707']",27.0,-0.003525046382189235,0.4569573283858998,1,0.0859375,0.0078125,0.3360655737704918
1645,1680,1680,Learning discriminative model prediction for tracking,"The current strive towards end-to-end trainable computer vision systems imposes major challenges for the task of visual tracking. In contrast to most other vision problems, tracking requires the learning of a robust target-specific appearance model online, during the inference stage. To be end-to-end trainable, the online learning of the target model thus needs to be embedded in the tracking architecture itself. Due to the imposed challenges, the popular Siamese paradigm simply predicts a target feature template, while ignoring the background appearance information during inference. Consequently, the predicted model possesses limited target-background discriminability. We develop an end-to-end tracking architecture, capable of fully exploiting both target and background appearance information for target model prediction. Our architecture is derived from a discriminative learning loss by designing a dedicated optimization process that is capable of predicting a powerful model in only a few iterations. Furthermore, our approach is able to learn key aspects of the discriminative loss itself. The proposed tracker sets a new state-of-the-art on 6 tracking benchmarks, achieving an EAO score of 0.440 on VOT2018, while running at over 40 FPS. The code and models are available at https://github.com/visionml/pytracking.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",18.7,0.13207972582972582,0.4960858585858586,1,0.08296943231441048,0.013100436681222707,0.3397129186602871
1646,1681,1681,Auto-FPN: Automatic network architecture adaptation for object detection beyond classification,"Neural architecture search (NAS) has shown great potential in automating the manual process of designing a good CNN architecture for image classification. In this paper, we study NAS for object detection, a core computer vision task that classifies and localizes object instances in an image. Existing works focus on transferring the searched architecture from classification task (ImageNet) to the detector backbone, while the rest of the architecture of the detector remains unchanged. However, this pipeline is not task-specific or data-oriented network search which cannot guarantee optimal adaptation to any dataset. Therefore, we propose an architecture search framework named Auto-FPN specifically designed for detection beyond simply searching a classification backbone. Specifically, we propose two auto search modules for detection: Auto-fusion to search a better fusion of the multi-level features; Auto-head to search a better structure for classification and bounding-box(bbox) regression. Instead of searching for one repeatable cell structure, we relax the constraint and allow different cells. The search space of both modules covers many popular designs of detectors and allows efficient gradient-based architecture search with resource constraint (2 days for COCO on 8 GPU cards). Extensive experiments on Pascal VOC, COCO, BDD, VisualGenome and ADE demonstrate the effectiveness of the proposed method, e.g. achieving around 5% improvement than FPN in terms of mAP while requiring around 50% fewer parameters on the searched modules.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",22.2,0.36,0.604047619047619,1,0.12222222222222222,0.05925925925925926,0.3657587548638132
1647,1682,1682,AM-LFS: AutoML for loss function search,"Designing an effective loss function plays an important role in visual analysis. Most existing loss function designs rely on hand-crafted heuristics that require domain experts to explore the large design space, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Loss Function Search (AM-LFS) which leverages REINFORCE to search loss functions during the training process. The key contribution of this work is the design of search space which can guarantee the generalization and transferability on different vision tasks by including a bunch of existing prevailing loss functions in a unified formulation. We also propose an efficient optimization framework which can dynamically optimize the parameters of loss function's distribution during training. Extensive experimental results on four benchmark datasets show that, without any tricks, our method outperforms existing hand-crafted loss functions in various computer vision tasks.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",23.0,0.1422077922077922,0.5283549783549784,1,0.14906832298136646,0.037267080745341616,0.32450331125827814
1648,1683,1683,Generating diverse and descriptive image captions using visual paraphrases,"Recently there has been significant progress in image captioning with the help of deep learning. However, captions generated by current state-of-the-art models are still far from satisfactory, despite high scores in terms of conventional metrics such as BLEU and CIDEr. Human-written captions are diverse, informative and precise, but machine-generated captions seem to be simple, vague and dull. In this paper, aimed at improving diversity and descriptiveness characteristics of generated image captions, we propose a model utilizing visual paraphrases (different sentences describing the same image) in captioning datasets. We explore different strategies to select useful visual paraphrase pairs for training by designing a variety of scoring functions. Our model consists of two decoding stages, where a preliminary caption is generated in the first stage and then paraphrased into a more diverse and descriptive caption in the second stage. Extensive experiments are conducted on the benchmark MS COCO dataset, with automatic evaluation and human evaluation results verifying the effectiveness of our model.",60014966,Peking University,Beijing,China,"['1712', '1707']",22.857142857142854,0.05002070393374741,0.39438923395445136,1,0.11170212765957446,0.015957446808510637,0.3595505617977528
1649,1684,1684,Video instance segmentation,"In this paper we present a new computer vision task, named video instance segmentation. The goal of this new task is simultaneous detection, segmentation and tracking of instances in videos. In words, it is the first time that the image instance segmentation problem is extended to the video domain. To facilitate research on this new task, we propose a large-scale benchmark called YouTube-VIS, which consists of 2,883 high-resolution YouTube videos, a 40-category label set and 131k high-quality instance masks. In addition, we propose a novel algorithm called MaskTrack R-CNN for this task. Our new method introduces a new tracking branch to Mask R-CNN to jointly perform the detection, segmentation and tracking tasks simultaneously. Finally, we evaluate the proposed method and several strong baselines on our new dataset. Experimental results clearly demonstrate the advantages of the proposed algorithm and reveal insight for future improvement. We believe the video instance segmentation task will motivate the community along the line of research for video understanding.",60000745,University of Illinois at Urbana-Champaign,Urbana,United States,"['1712', '1707']",18.0,0.12153679653679655,0.4073051948051947,1,0.08854166666666667,0.046875,0.3277777777777778
1650,1685,1685,CamNet: Coarse-to-fine retrieval for camera re-localization,"Camera re-localization is an important but challenging task in applications like robotics and autonomous driving. Recently, retrieval-based methods have been considered as a promising direction as they can be easily generalized to novel scenes. Despite significant progress has been made, we observe that the performance bottleneck of previous methods actually lies in the retrieval module. These methods use the same features for both retrieval and relative pose regression tasks which have potential conflicts in learning. To this end, here we present a coarse-to-fine retrieval-based deep learning framework, which includes three steps, i.e., image-based coarse retrieval, pose-based fine retrieval and precise relative pose regression. With our carefully designed retrieval module, the relative pose regression task can be surprisingly simpler. We design novel retrieval losses with batch hard sampling criterion and two-stage retrieval to locate samples that adapt to the relative pose regression task. Extensive experiments show that our model (CamNet) outperforms the state-of-the-art methods by a large margin on both indoor and outdoor datasets.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",20.375,0.13923809523809527,0.4621428571428571,1,0.10837438423645321,0.009852216748768473,0.30939226519337015
1651,1686,1686,Closed-form optimal two-view triangulation based on angular errors,"In this paper, we study closed-form optimal solutions to two-view triangulation with known internal calibration and pose. By formulating the triangulation problem as L-1 and L-infinity minimization of angular reprojection errors, we derive the exact closed-form solutions that guarantee global optimality under respective cost functions. To the best of our knowledge, we are the first to present such solutions. Since the angular error is rotationally invariant, our solutions can be applied for any type of central cameras, be it perspective, fisheye or omnidirectional. Our methods also require significantly less computation than the existing optimal methods. Experimental results on synthetic and real datasets validate our theoretical derivations.",60016809,Universidad de Zaragoza,Zaragoza,Spain,"['1712', '1707']",17.666666666666668,0.12564102564102564,0.2,1,0.0873015873015873,0.015873015873015872,0.3474576271186441
1652,1687,1687,What synthesis is missing: Depth adaptation integrated with weak supervision for indoor scene parsing,"Scene Parsing is a crucial step to enable autonomous systems to understand and interact with their surroundings. Supervised deep learning methods have made great progress in solving scene parsing problems, however, come at the cost of laborious manual pixel-level annotation. Synthetic data as well as weak supervision have been investigated to alleviate this effort. Nonetheless, synthetically generated data still suffers from severe domain shift while weak labels often lack precision. Moreover, most existing works for weakly supervised scene parsing are limited to salient foreground objects. The aim of this work is hence twofold: Exploit synthetic data where feasible and integrate weak supervision where necessary. More concretely, we address this goal by utilizing depth as transfer domain because its synthetic-to-real discrepancy is much lower than for color. At the same time, we perform weak localization from easily obtainable image level labels and integrate both using a novel contour-based scheme. Our approach is implemented as a teacher-student learning framework to solve the transfer learning problem by generating a pseudo ground truth. Using only depth-based adaptation, this approach already outperforms previous transfer learning approaches on the popular indoor scene parsing SUN RGB-D dataset. Our proposed two-stage integration more than halves the gap towards fully supervised methods when compared to previous state-of-the-art in transfer learning.",60005429,National Taiwan University,Taipei,Taiwan,"['1712', '1707']",19.181818181818183,0.052329192546583865,0.565631469979296,1,0.14682539682539683,0.015873015873015872,0.2826086956521739
1653,1688,1688,An empirical study of spatial attention mechanisms in deep networks,"Attention mechanisms have become a popular component in deep neural networks, yet there has been little examination of how different influencing factors and methods for computing attention from these factors affect performance. Toward a better general understanding of attention mechanisms, we present an empirical study that ablates various spatial attention elements within a generalized attention formulation, encompassing the dominant Transformer attention as well as the prevalent deformable convolution and dynamic convolution modules. Conducted on a variety of applications, the study yields significant findings about spatial attention in deep networks, some of which run counter to conventional understanding. For example, we find that the query and key content comparison in Transformer attention is negligible for self-attention, but vital for encoder-decoder attention. A proper combination of deformable convolution with key content only saliency achieves the best accuracy-efficiency tradeoff in self-attention. Our results suggest that there exists much room for improvement in the design of attention mechanisms.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",25.66666666666667,0.12973214285714288,0.4899404761904762,1,0.08,0.005714285714285714,0.2754491017964072
1654,1689,1689,Graph-based object classification for neuromorphic vision sensing,"Neuromorphic vision sensing (NVS) devices represent visual information as sequences of asynchronous discrete events (a.k.a., 'spikes'') in response to changes in scene reflectance. Unlike conventional active pixel sensing (APS), NVS allows for significantly higher event sampling rates at substantially increased energy efficiency and robustness to illumination changes. However, object classification with NVS streams cannot leverage on state-of-the-art convolutional neural networks (CNNs), since NVS does not produce frame representations. To circumvent this mismatch between sensing and processing with CNNs, we propose a compact graph representation for NVS. We couple this with novel residual graph CNN architectures and show that, when trained on spatio-temporal NVS data for object classification, such residual graph CNNs preserve the spatial and temporal coherence of spike events, while requiring less computation and memory. Finally, to address the absence of large real-world NVS datasets for complex recognition tasks, we present and make available a 100k dataset of NVS recordings of the American sign language letters, acquired with an iniLabs DAVIS240c device under real-world conditions.",60022148,UCL,London,United Kingdom,"['1712', '1707']",27.66666666666667,0.008379120879120879,0.3271062271062271,1,0.09134615384615384,0.0625,0.40932642487046633
1655,1690,1690,Multi-layer filtering webpage classification method based on SVM,"This paper presents a classification method based on web structure strategy and support vector machine, which can be applied to the classification of a large number of web pages. The algorithm designs the initial filter layer to recall the web pages quickly according to the structure of the web pages, and then trains the SVM classifier to do two classifications to improve the accuracy. Experiments show that the classification algorithm is feasible.",60007711,Jilin University,Changchun,China,['1700'],24.0,0.18253968253968253,0.30952380952380953,1,0.12987012987012986,0.012987012987012988,0.19480519480519481
1656,1691,1691,Action assessment by joint relation graphs,"We present a new model to assess the performance of actions from videos, through graph-based joint relation modelling. Previous works mainly focused on the whole scene including the performer's body and background, yet they ignored the detailed joint interactions. This is insufficient for fine-grained, accurate action assessment, because the action quality of each joint is dependent of its neighbouring joints. Therefore, we propose to learn the detailed joint motion based on the joint relations. We build trainable Joint Relation Graphs, and analyze joint motion on them. We propose two novel modules, the Joint Commonality Module and the Joint Difference Module, for joint motion learning. The Joint Commonality Module models the general motion for certain body parts, and the Joint Difference Module models the motion differences within body parts. We evaluate our method on six public Olympic actions for performance assessment. Our method outperforms previous approaches (+0.0912) and the whole-scene analysis (+0.0623) in the Spearman's Rank Correlation. We also demonstrate our model's ability to interpret the action assessment process.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",16.8,0.07087391774891777,0.3745400432900433,1,0.095,0.095,0.39690721649484534
1657,1692,1692,Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection,"Deep autoencoder has been extensively used for anomaly detection. Training on the normal data, the autoencoder is expected to produce higher reconstruction error for the abnormal inputs than the normal ones, which is adopted as a criterion for identifying anomalies. However, this assumption does not always hold in practice. It has been observed that sometimes the autoencoder 'generalizes' so well that it can also reconstruct anomalies well, leading to the miss detection of anomalies. To mitigate this drawback for autoencoder based anomaly detector, we propose to augment the autoencoder with a memory module and develop an improved autoencoder called memory-augmented autoencoder, i.e. MemAE. Given an input, MemAE firstly obtains the encoding from the encoder and then uses it as a query to retrieve the most relevant memory items for reconstruction. At the training stage, the memory contents are updated and are encouraged to represent the prototypical elements of the normal data. At the test stage, the learned memory will be fixed, and the reconstruction is obtained from a few selected memory records of the normal data. The reconstruction will thus tend to be close to a normal sample. Thus the reconstructed errors on anomalies will be strengthened for anomaly detection. MemAE is free of assumptions on the data type and thus general to be applied to different tasks. Experiments on various datasets prove the excellent generalization and high effectiveness of the proposed MemAE.",60031806,University of Western Australia,Perth,Australia,"['1712', '1707']",17.923076923076927,0.17800000000000002,0.5428333333333332,1,0.14285714285714285,0.015444015444015444,0.29961089494163423
1658,1693,1693,Occupancy flow: 4D reconstruction by learning particle dynamics,"Deep learning based 3D reconstruction techniques have recently achieved impressive results. However, while state-of-the-art methods are able to output complex 3D geometry, it is not clear how to extend these results to time-varying topologies. Approaches treating each time step individually lack continuity and exhibit slow inference, while traditional 4D reconstruction methods often utilize a template model or discretize the 4D space at fixed resolution. In this work, we present Occupancy Flow, a novel spatio-temporal representation of time-varying 3D geometry with implicit correspondences. Towards this goal, we learn a temporally and spatially continuous vector field which assigns a motion vector to every point in space and time. In order to perform dense 4D reconstruction from images or sparse point clouds, we combine our method with a continuous 3D representation. Implicitly, our model yields correspondences over time, thus enabling fast inference while providing a sound physical description of the temporal dynamics. We show that our method can be used for interpolation and reconstruction tasks, and demonstrate the accuracy of the learned correspondences. We believe that Occupancy Flow is a promising new 4D representation which will be useful for a variety of spatio-temporal reconstruction tasks.",60116312,ETAS GmbH,Stuttgart,Germany,"['1712', '1707']",21.33333333333333,0.1286096256684492,0.4062197606315253,1,0.12,0.022222222222222223,0.2985781990521327
1659,1694,1694,Unsupervised video interpolation using cycle consistency,"Learning to synthesize high frame rate videos via interpolation requires large quantities of high frame rate training videos, which, however, are scarce, especially at high resolutions. Here, we propose unsupervised techniques to synthesize high frame rate videos directly from low frame rate videos using cycle consistency. For a triplet of consecutive frames, we optimize models to minimize the discrepancy between the center frame and its cycle reconstruction, obtained by interpolating back from interpolated intermediate frames. This simple unsupervised constraint alone achieves results comparable with supervision using the ground truth intermediate frames. We further introduce a pseudo supervised loss term that enforces the interpolated frames to be consistent with predictions of a pre-trained interpolation model. The pseudo supervised loss term, used together with cycle consistency, can effectively adapt a pre-trained model to a new target domain. With no additional data and in a completely unsupervised fashion, our techniques significantly improve pre-trained models on new target domains, increasing PSNR values from 32.84dB to 33.05dB on the Slowflow and from 31.82dB to 32.53dB on the Sintel evaluation datasets.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",25.0,0.15364782276546982,0.4670473644003055,1,0.1407035175879397,0.020100502512562814,0.32642487046632124
1660,1695,1695,Bayesian graph convolution LSTM for skeleton based action recognition,"We propose a framework for recognizing human actions from skeleton data by modeling the underlying dynamic process that generates the motion pattern. We capture three major factors that contribute to the complexity of the motion pattern including spatial dependencies among body joints, temporal dependencies of body poses, and variation among subjects in action execution. We utilize graph convolution to extract structure-aware feature representation from pose data by exploiting the skeleton anatomy. Long short-term memory (LSTM) network is then used to capture the temporal dynamics of the data. Finally, the whole model is extended under the Bayesian framework to a probabilistic model in order to better capture the stochasticity and variation in the data. An adversarial prior is developed to regularize the model parameters to improve the generalization of the model. A Bayesian inference problem is formulated to solve the classification task. We demonstrate the benefit of this framework in several benchmark datasets with recognition under various generalization conditions.",60011048,IBM Research,Yorktown Heights,United States,"['1712', '1707']",19.75,0.07604166666666666,0.33055555555555555,1,0.12,0.017142857142857144,0.2573099415204678
1661,1696,1696,Global anomaly detection based on a deep prediction neural network,"Abnormal event detection in public scenes is very important in recent society. In this paper, a method for global anomaly detection in video surveillance is proposed, which is based on a deep prediction neural network. The deep prediction neural network is built on the Convolutional Neural Network (CNN) and a variant of the Recurrent Neural Network (RNN)-Long Short-Term Memory (LSTM). Especially, the feature of a frame is the output of CNN, which is instead of the hand-crafted feature. First, the feature of a short video clip is obtained through CNN. Second, the predicted feature of the next frame can be gained by LSTM. Finally, the prediction error is introduced to detect that a frame is abnormal or not after the feature of the frame is achieved. Experimental results of global abnormal event detection show the effectiveness of our deep prediction neural network. Comparing with state-of-the-art methods, the model we proposed obtains superior detection results.",60108684,Guangdong University of Finance,Guangzhou,China,['1700'],17.11111111111111,0.098125,0.4031250000000001,1,0.07526881720430108,0.08064516129032258,0.33707865168539325
1662,1697,1697,Beyond human parts: Dual part-aligned representations for person re-identification,"Person re-identification is a challenging task due to various complex factors. Recent studies have attempted to integrate human parsing results or externally defined attributes to help capture human parts or important object regions. On the other hand, there still exist many useful contextual cues that do not fall into the scope of predefined human parts or attributes. In this paper, we address the missed contextual cues by exploiting both the accurate human parts and the coarse non-human parts. In our implementation, we apply a human parsing model to extract the binary human part masks and a self-attention mechanism to capture the soft latent (non-human) part masks. We verify the effectiveness of our approach with new state-of-the-art performance on three challenging benchmarks: Market-1501, DukeMTMC-reID and CUHK03. Our implementation is available at https://github.com/ggjy/P2Net.pytorch.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",18.714285714285715,0.12210743801652893,0.3835399449035812,1,0.09937888198757763,0.018633540372670808,0.3741496598639456
1663,1698,1698,A deep reinforcement learning approach towards computation offloading for mobile edge computing,"In order to improve the quality of service for users and reduce the energy consumption of the cloud computing environment, Mobile Edge Computing (MEC) is a promising paradigm by providing computing resources which is close to the end device in physical distance. Nevertheless, the computation offloading policy to satisfy the requirements of the service provider and consumer at the same time within a MEC system still remains challenging. In this paper, we propose an offloading decision policy with three-level structure for MEC system different from the traditional two-level architecture to formulate the offloading decision optimization problem by minimizing the total cost of energy consumption and delay time. Because the traditional optimization methods could not solve this dynamic system problem efficiently, Reinforcement Learning (RL) has been used in complex control systems in recent years. We design a deep reinforcement learning (DRL) approach to minimize the total cost by applying deep Q-learning algorithm to address the issues of too large system state dimension. The simulation results show that the proposed algorithm has nearly optimal performance than traditional methods.",60021666,Nanjing University of Aeronautics and Astronautics,Nanjing,China,['1700'],29.33333333333333,0.04201680672268907,0.5037114845938376,1,0.10606060606060606,0.06060606060606061,0.28125
1664,1699,1699,"Liquid warping GAN: A unified framework for human motion imitation, appearance transfer and novel view synthesis","We tackle the human motion imitation, appearance transfer, and novel view synthesis within a unified framework, which means that the model once being trained can be used to handle all these tasks. The existing task-specific methods mainly use 2D keypoints (pose) to estimate the human body structure. However, they only expresses the position information with no abilities to characterize the personalized shape of the individual person and model the limbs rotations. In this paper, we propose to use a 3D body mesh recovery module to disentangle the pose and shape, which can not only model the joint location and rotation but also characterize the personalized body shape. To preserve the source information, such as texture, style, color, and face identity, we propose a Liquid Warping GAN with Liquid Warping Block (LWB) that propagates the source information in both image and feature spaces, and synthesizes an image with respect to the reference. Specifically, the source features are extracted by a denoising convolutional auto-encoder for characterizing the source identity well. Furthermore, our proposed method is able to support a more flexible warping from multiple sources. In addition, we build a new dataset, namely Impersonator (iPER) dataset, for the evaluation of human motion imitation, appearance transfer, and novel view synthesis. Extensive experiments demonstrate the effectiveness of our method in several aspects, such as robustness in occlusion case and preserving face identity, shape consistency and clothes details. All codes and datasets are available on https://svip-lab.github.io/project/impersonator.html.",60105232,ShanghaiTech University,Shanghai,China,"['1712', '1707']",24.1,0.07979797979797977,0.35256734006734003,1,0.1099290780141844,0.024822695035460994,0.31785714285714284
1665,1700,1700,PARN: Position-aware relation networks for few-shot learning,"Few-shot learning presents a challenge that a classifier must quickly adapt to new classes that do not appear in the training set, given only a few labeled examples of each new class. This paper proposes a position-aware relation network (PARN) to learn a more flexible and robust metric ability for few-shot learning. Relation networks (RNs), a kind of architectures for relational reasoning, can acquire a deep metric ability for images by just being designed as a simple convolutional neural network (CNN)[23]. However, due to the inherent local connectivity of CNN, the CNN-based relation network (RN) can be sensitive to the spatial position relationship of semantic objects in two compared images. To address this problem, we introduce a deformable feature extractor (DFE) to extract more efficient features, and design a dual correlation attention mechanism (DCA) to deal with its inherent local connectivity. Successfully, our proposed approach extents the potential of RN to be position-aware of semantic objects by introducing only a small number of parameters. We evaluate our approach on two major benchmark datasets, i.e., Omniglot and Mini-Imagenet, and on both of the datasets our approach achieves state-of-the-art performance. It's worth noting that our 5-way 1-shot result on Omniglot even outperforms the previous 5-way 5-shot results.",60024542,South China University of Technology,Guangzhou,China,"['1712', '1707']",25.625,0.12747113997113996,0.5027571634714493,1,0.10196078431372549,0.050980392156862744,0.3625
1666,1701,1701,Recursive visual sound separation using minus-plus net,"Sounds provide rich semantics, complementary to visual data, for many tasks. However, in practice, sounds from multiple sources are often mixed together. In this paper we propose a novel framework, referred to as MinusPlus Network (MP-Net), for the task of visual sound separation. MP-Net separates sounds recursively in the order of average energy, removing the separated sound from the mixture at the end of each prediction, until the mixture becomes empty or contains only noise. In this way, MP-Net could be applied to sound mixtures with arbitrary numbers and types of sounds. Moreover, while MP-Net keeps removing sounds with large energy from the mixture, sounds with small energy could emerge and become clearer, so that the separation is more accurate. Compared to previous methods, MP-Net obtains state-of-the-art results on two large scale datasets, across mixtures with different types and numbers of sounds.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",20.285714285714285,0.1318452380952381,0.4178571428571429,1,0.10497237569060773,0.06629834254143646,0.36363636363636365
1667,1702,1702,A graph-based framework to bridge movies and synopses,"Inspired by the remarkable advances in video analytics, research teams are stepping towards a greater ambition - movie understanding. However, compared to those activity videos in conventional datasets, movies are significantly different. Generally, movies are much longer and consist of much richer temporal structures. More importantly, the interactions among characters play a central role in expressing the underlying story. To facilitate the efforts along this direction, we construct a dataset called Movie Synopses Associations (MSA) over 327 movies, which provides a synopsis for each movie, together with annotated associations between synopsis paragraphs and movie segments. On top of this dataset, we develop a framework to perform matching between movie segments and synopsis paragraphs. This framework integrates different aspects of a movie, including event dynamics and character interactions, and allows them to be matched with parsed paragraphs, based on a graph-based formulation. Our study shows that the proposed framework remarkably improves the matching accuracy over conventional feature-based methods. It also reveals the importance of narrative structures and character interactions in movie understanding. Dataset and code are available at: Https://ycxioooong.github.io/projects/moviesyn.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",17.8,0.2642857142857143,0.4976190476190476,1,0.12560386473429952,0.01932367149758454,0.4146341463414634
1668,1703,1703,Subspace structure-aware spectral clustering for robust subspace clustering,"Subspace clustering is the problem of partitioning data drawn from a union of multiple subspaces. The most popular subspace clustering framework in recent years is the graph clustering-based approach, which performs subspace clustering in two steps: Graph construction and graph clustering. Although both steps are equally important for accurate clustering, the vast majority of work has focused on improving the graph construction step rather than the graph clustering step. In this paper, we propose a novel graph clustering framework for robust subspace clustering. By incorporating a geometry-aware term with the spectral clustering objective, we encourage our framework to be robust to noise and outliers in given affinity matrices. We also develop an efficient expectation-maximization-based algorithm for optimization. Through extensive experiments on four real-world datasets, we demonstrate that the proposed method outperforms existing methods.",60025555,Nippon Telegraph and Telephone Corporation,Tokyo,Japan,"['1712', '1707']",19.0,0.21111111111111114,0.5240740740740739,1,0.1346153846153846,0.00641025641025641,0.2671232876712329
1669,1704,1704,Dual directed capsule network for very low resolution image recognition,"Very low resolution (VLR) image recognition corresponds to classifying images with resolution 16x16 or less. Though it has widespread applicability when objects are captured at a very large stand-off distance (e.g. surveillance scenario) or from wide angle mobile cameras, it has received limited attention. This research presents a novel Dual Directed Capsule Network model, termed as DirectCapsNet, for addressing VLR digit and face recognition. The proposed architecture utilizes a combination of capsule and convolutional layers for learning an effective VLR recognition model. The architecture also incorporates two novel loss functions: (i) the proposed HR-anchor loss and (ii) the proposed targeted reconstruction loss, in order to overcome the challenges of limited information content in VLR images. The proposed losses use high resolution images as auxiliary data during training to 'direct' discriminative feature learning. Multiple experiments for VLR digit classification and VLR face recognition are performed along with comparisons with state-of-the-art algorithms. The proposed DirectCapsNet consistently showcases state-of-the-art results; for example, on the UCCS face database, it shows over 95% face recognition accuracy when 16x16 images are matched with 80x80 images.",60105479,"Indraprastha Institute of Information Technology, Delhi",New Delhi,India,"['1712', '1707']",19.88888888888889,0.019087301587301587,0.3907936507936508,1,0.1036036036036036,0.06756756756756757,0.4368932038834951
1670,1705,1705,SPGNet: Semantic prediction guidance for scene parsing,"Multi-scale context module and single-stage encoder-decoder structure are commonly employed for semantic segmentation. The multi-scale context module refers to the operations to aggregate feature responses from a large spatial extent, while the single-stage encoder-decoder structure encodes the high-level semantic information in the encoder path and recovers the boundary information in the decoder path. In contrast, multi-stage encoder-decoder networks have been widely used in human pose estimation and show superior performance than their single-stage counterpart. However, few efforts have been attempted to bring this effective design to semantic segmentation. In this work, we propose a Semantic Prediction Guidance (SPG) module which learns to re-weight the local features through the guidance from pixel-wise semantic prediction. We find that by carefully re-weighting features across stages, a two-stage encoder-decoder network coupled with our proposed SPG module can significantly outperform its one-stage counterpart with similar parameters and computations. Finally, we report experimental results on the semantic segmentation benchmark Cityscapes, in which our SPGNet attains 81.1% on the test set using only 'fine' annotations.",60012317,University of Oregon,Eugene,United States,"['1712', '1707']",24.0,0.11373015873015872,0.5602380952380952,1,0.1004566210045662,0.0319634703196347,0.3763440860215054
1671,1706,1706,Texture fields: Learning texture representations in function space,"In recent years, substantial progress has been achieved in learning-based reconstruction of 3D objects. At the same time, generative models were proposed that can generate highly realistic images. However, despite this success in these closely related tasks, texture reconstruction of 3D objects has received little attention from the research community and state-of-the-art methods are either limited to comparably low resolution or constrained experimental setups. A major reason for these limitations is that common representations of texture are inefficient or hard to interface for modern deep learning techniques. In this paper, we propose Texture Fields, a novel texture representation which is based on regressing a continuous 3D function parameterized with a neural network. Our approach circumvents limiting factors like shape discretization and parameterization, as the proposed texture representation is independent of the shape representation of the 3D object. We show that Texture Fields are able to represent high frequency texture and naturally blend with modern deep learning techniques. Experimentally, we find that Texture Fields compare favorably to state-of-the-art methods for conditional texture reconstruction of 3D objects and enable learning of probabilistic generative models for texturing unseen 3D models. We believe that Texture Fields will become an important building block for the next generation of generative 3D models.",60116312,ETAS GmbH,Stuttgart,Germany,"['1712', '1707']",22.88888888888889,0.06254658385093168,0.3688198757763976,1,0.10970464135021098,0.016877637130801686,0.32286995515695066
1672,1707,1707,Understanding deep networks via extremal perturbations and smooth masks,"Attribution is the problem of finding which parts of an image are the most responsible for the output of a deep neural network. An important family of attribution methods is based on measuring the effect of perturbations applied to the input image, either via exhaustive search or by finding representative perturbations via optimization. In this paper, we discuss some of the shortcomings of existing approaches to perturbation analysis and address them by introducing the concept of extremal perturbations, which are theoretically grounded and interpretable. We also introduce a number of technical innovations to compute these extremal perturbations, including a new area constraint and a parametric family of smooth perturbations, which allow us to remove all tunable weighing factors from the optimization problem. We analyze the effect of perturbations as a function of their area, demonstrating excellent sensitivity to the spatial properties of the network under stimulation. We also extend perturbation analysis to the intermediate layers of a deep neural network. This application allows us to show how compactly an image can be represented (in terms of the number of channels it requires). We also demonstrate that the consistency with which images of a given class rely on the same intermediate channel correlates well with class accuracy.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",25.75,0.2396694214876033,0.4663223140495869,1,0.12162162162162163,0.0,0.22972972972972974
1673,1708,1708,Textdragon: An end-to-end framework for arbitrary shaped text spotting,"Most existing text spotting methods either focus on horizontal/oriented texts or perform arbitrary shaped text spotting with character-level annotations. In this paper, we propose a novel text spotting framework to detect and recognize text of arbitrary shapes in an end-to-end manner, using only word/line-level annotations for training. Motivated from the name of TextSnake, which is only a detection model, we call the proposed text spotting framework TextDragon. In TextDragon, a text detector is designed to describe the shape of text with a series of quadrangles, which can handle text of arbitrary shapes. To extract arbitrary text regions from feature maps, we propose a new differentiable operator named RoISlide, which is the key to connect arbitrary shaped text detection and recognition. Based on the extracted features through RoISlide, a CNN and CTC based text recognizer is introduced to make the framework free from labeling the location of characters. The proposed method achieves state-of-the-art performance on two curved text benchmarks CTW1500 and Total-Text, and competitive results on the ICDAR 2015 Dataset.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",24.142857142857146,0.0487603305785124,0.7049586776859503,1,0.1407766990291262,0.06796116504854369,0.3279569892473118
1674,1709,1709,Self-supervised monocular depth hints,"Monocular depth estimators can be trained with various forms of self-supervision from binocular-stereo data to circumvent the need for high-quality laser-scans or other ground-truth data. The disadvantage, however, is that the photometric reprojection losses used with self-supervised learning typically have multiple local minima. These plausible-looking alternatives to ground-truth can restrict what a regression network learns, causing it to predict depth maps of limited quality. As one prominent example, depth discontinuities around thin structures are often incorrectly estimated by current state-of-the-art methods. Here, we study the problem of ambiguous reprojections in depth-prediction from stereo-based self-supervision, and introduce Depth Hints to alleviate their effects. Depth Hints are complementary depth-suggestions obtained from simple off-the-shelf stereo algorithms. These hints enhance an existing photometric loss function, and are used to guide a network to learn better weights. They require no additional data, and are assumed to be right only sometimes. We show that using our Depth Hints gives a substantial boost when training several leading self-supervised-from-stereo models, not just our own. Further, combined with other good practices, we produce state-of-the-art depth predictions on the KITTI benchmark.",60022148,UCL,London,United Kingdom,"['1712', '1707']",18.1,0.0943121693121693,0.4797619047619047,1,0.12903225806451613,0.008064516129032258,0.36633663366336633
1675,1710,1710,Universal perturbation attack against image retrieval,"Universal adversarial perturbations (UAPs), a.k.a. input-agnostic perturbations, has been proved to exist and be able to fool cutting-edge deep learning models on most of the data samples. Existing UAP methods mainly focus on attacking image classification models. Nevertheless, little attention has been paid to attacking image retrieval systems. In this paper, we make the first attempt in attacking image retrieval systems. Concretely, image retrieval attack is to make the retrieval system return irrelevant images to the query at the top ranking list. It plays an important role to corrupt the neighbourhood relationships among features in image retrieval attack. To this end, we propose a novel method to generate retrieval-against UAP to break the neighbourhood relationships of image features via degrading the corresponding ranking metric. To expand the attack method to scenarios with varying input sizes or untouchable network parameters, a multi-scale random resizing scheme and a ranking distillation strategy are proposed. We evaluate the proposed method on four widely-used image retrieval datasets, and report a significant performance drop in terms of different metrics, such as mAP and mP@10. Finally, we test our attack methods on the real-world visual search engine, i.e., Google Images, which demonstrates the practical potentials of our methods.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",18.272727272727273,0.06412037037037037,0.5537037037037037,1,0.12133891213389121,0.016736401673640166,0.39737991266375544
1676,1711,1711,Gaussian affinity for max-margin class imbalanced learning,"Real-world object classes appear in imbalanced ratios. This poses a significant challenge for classifiers which get biased towards frequent classes. We hypothesize that improving the generalization capability of a classifier should improve learning on imbalanced datasets. Here, we introduce the first hybrid loss function that jointly performs classification and clustering in a single formulation. Our approach is based on an 'affinity measure' in Euclidean space that leads to the following benefits: (1) direct enforcement of maximum margin constraints on classification boundaries, (2) a tractable way to ensure uniformly spaced and equidistant cluster centers, (3) flexibility to learn multiple class prototypes to support diversity and discriminability in feature space. Our extensive experiments demonstrate the significant performance improvements on visual classification and verification tasks on multiple imbalanced datasets. The proposed loss can easily be plugged in any deep architecture as a differentiable block and demonstrates robustness against different levels of data imbalance and corrupted labels.",60022193,University of Canberra,Canberra,Australia,"['1712', '1707']",21.857142857142854,0.054126984126984135,0.4176190476190476,1,0.13218390804597702,0.0,0.2982456140350877
1677,1712,1712,Research on the construction of sharing service model in fresh e-commerce cold storage,"After analyzing the problem of insufficient utilization of storage location resources in the current fresh e-commerce cold storage, a sharing service model was constructed to apply to the fresh e-commerce cold storage. The idle surplus storage space resources in the cold storage would be shared and rented, thus solving the problem of inadequate utilization of energy resources from the management aspect and optimizing the allocation of resources. The B2C+P2P sharing business model constructed in this paper divides the sharing service into three types according to different users’ needs, which provides enterprises with new methods to revenues.",60022414,Wuhan University of Technology,Wuhan,China,['1700'],32.0,-0.13295454545454544,0.6818181818181818,1,0.1308411214953271,0.04672897196261682,0.30097087378640774
1678,1713,1713,Convolutional approximations to the general non-line-of-sight imaging operator,"Non-line-of-sight (NLOS) imaging aims to reconstruct scenes outside the field of view of an imaging system. A common approach is to measure the so-called light transients, which facilitates reconstructions through ellipsoidal tomography that involves solving a linear least-squares. Unfortunately, the corresponding linear operator is very high-dimensional and lacks structures that facilitate fast solvers, and so, the ensuing optimization is a computationally daunting task. We introduce a computationally tractable framework for solving the ellipsoidal tomography problem. Our main observation is that the Gram of the ellipsoidal tomography operator is convolutional, either exactly under certain idealized imaging conditions, or approximately in practice. This, in turn, allows us to obtain the ellipsoidal tomography solution by using efficient deconvolution procedures to solve a linear least-squares problem involving the Gram operator. The computational tractability of our approach also facilitates the use of various regularizers during the deconvolution procedure. We demonstrate the advantages of our framework in a variety of simulated and real experiments.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",19.75,0.03591269841269842,0.4753968253968253,1,0.11052631578947368,0.015789473684210527,0.3465909090909091
1679,1714,1714,Financing current assets decision in working capital management: An evaluation," It determines the liquidity and the profitability of the business concern. Financing current assets is a challenging task but this is one of the significant aspects of working capital management. It involves a crucial financial decision. There are various approaches available in determining an appropriate mix of financing current assets, but none of the approaches is completely satisfactory and acceptable. The present paper focuses on the real corporate world practices regarding financing current assets decision in working capital management. The main aim is to enlighten the shareholders, creditors, investors, bankers, prospective entrepreneurs, students and academicians relating to financing current assets decision and its implications. The study would reveal how far, the profit available and risk associated with the financing mix and a trade-off between risk and return will result in an acceptable financing strategy for most of business concerns.",60013919,Pondicherry University,Puducherry,India,['1706'],20.0,0.16898148148148148,0.4726851851851853,0,0.11538461538461539,0.0,0.28104575163398693
1680,1715,1715,ClusterSLAM: A SLAM backend for simultaneous rigid body clustering and motion estimation,"We present a practical backend for stereo visual SLAM which can simultaneously discover individual rigid bodies and compute their motions in dynamic environments. While recent factor graph based state optimization algorithms have shown their ability to robustly solve SLAM problems by treating dynamic objects as outliers, the dynamic motions are rarely considered. In this paper, we exploit the consensus of 3D motions among the landmarks extracted from the same rigid body for clustering and estimating static and dynamic objects in a unified manner. Specifically, our algorithm builds a noise-aware motion affinity matrix upon landmarks, and uses agglomerative clustering for distinguishing those rigid bodies. Accompanied by a decoupled factor graph optimization for revising their shape and trajectory, we obtain an iterative scheme to update both cluster assignments and motion estimation reciprocally. Evaluations on both synthetic scenes and KITTI demonstrate the capability of our approach, and further experiments considering online efficiency also show the effectiveness of our method for simultaneous tracking of ego-motion and multiple objects.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",27.33333333333333,0.061538461538461535,0.2878205128205128,1,0.13333333333333333,0.005555555555555556,0.2784090909090909
1681,1716,1716,Compact trilinear interaction for visual question answering,"In Visual Question Answering (VQA), answers have a great correlation with question meaning and visual contents. Thus, to selectively utilize image, question and answer information, we propose a novel trilinear interaction model which simultaneously learns high level associations between these three inputs. In addition, to overcome the interaction complexity, we introduce a multimodal tensor-based PARALIND decomposition which efficiently parameterizes trilinear teraction between the three inputs. Moreover, knowledge distillation is first time applied in Free-form Opened-ended VQA. It is not only for reducing the computational cost and required memory but also for transferring knowledge from trilinear interaction model to bilinear interaction model. The extensive experiments on benchmarking datasets TDIUC, VQA-2.0, and Visual7W show that the proposed compact trilinear interaction model achieves state-of-the-art results when using a single model on all three datasets.",60020661,University of Liverpool,Liverpool,United Kingdom,"['1712', '1707']",21.83333333333333,0.14232142857142854,0.3963690476190476,1,0.11875,0.03125,0.34459459459459457
1682,1717,1717,Dynamic anchor feature selection for single-shot object detection,"The design of anchors is critical to the performance of one-stage detectors. Recently, the anchor refinement module (ARM) has been proposed to adjust the initialization of default anchors, providing the detector a better anchor reference. However, this module brings another problem: All pixels at a feature map have the same receptive field while the anchors associated with each pixel have different positions and sizes. This discordance may lead to a less effective detector. In this paper, we present a dynamic feature selection operation to select new pixels in a feature map for each refined anchor received from the ARM. The pixels are selected based on the new anchor position and size so that the receptive filed of these pixels can fit the anchor areas well, which makes the detector, especially the regression part, much easier to optimize. Furthermore, to enhance the representation ability of selected feature pixels, we design a bidirectional feature fusion module by combining features from early and deep layers. Extensive experiments on both PASCAL VOC and COCO demonstrate the effectiveness of our dynamic anchor feature selection (DAFS) operation. For the case of high IoU threshold, our DAFS can improve the mAP by a large margin.",60118460,Alibaba Group Holding Limited,Yu Hang,China,"['1712', '1707']",22.0,0.11401731601731603,0.3992997835497836,1,0.11160714285714286,0.026785714285714284,0.27927927927927926
1683,1718,1718,Human attention in image captioning: Dataset and analysis,"In this work, we present a novel dataset consisting of eye movements and verbal descriptions recorded synchronously over images. Using this data, we study the differences in human attention during free-viewing and image captioning tasks. We look into the relationship between human atten- tion and language constructs during perception and sen- tence articulation. We also analyse attention deployment mechanisms in the top-down soft attention approach that is argued to mimic human attention in captioning tasks, and investigate whether visual saliency can help image caption- ing. Our study reveals that (1) human attention behaviour differs in free-viewing and image description tasks. Hu- mans tend to fixate on a greater variety of regions under the latter task, (2) there is a strong relationship between de- scribed objects and attended objects (97% of the described objects are being attended), (3) a convolutional neural net- work as feature encoder accounts for human-attended re- gions during image captioning to a great extent (around 78%), (4) soft-attention mechanism differs from human at- tention, both spatially and temporally, and there is low correlation between caption scores and attention consis- tency scores. These indicate a large gap between humans and machines in regards to top-down attention, and (5) by integrating the soft attention model with image saliency, we can significantly improve the model's performance on Flickr30k and MSCOCO benchmarks. The dataset can be found at: Https://github.com/SenHe/ Human-Attention-in-Image-Captioning.",60103653,Aalto University,Espoo,Finland,"['1712', '1707']",28.625,0.14838935574229692,0.28158263305322123,1,0.10526315789473684,0.021052631578947368,0.42696629213483145
1684,1719,1719,Self-guided network for fast image denoising,"During the past years, tremendous advances in image restoration tasks have been achieved using highly complex neural networks. Despite their good restoration performance, the heavy computational burden hinders the deployment of these networks on constrained devices, eg smart phones and consumer electronic products. To tackle this problem, we propose a self-guided network (SGN), which adopts a top-down self-guidance architecture to better exploit image multi-scale information. SGN directly generates multi-resolution inputs with the shuffling operation. Large-scale contextual information extracted at low resolution is gradually propagated into the higher resolution sub-networks to guide the feature extraction processes at these scales. Such a self-guidance strategy enables SGN to efficiently incorporate multi-scale information and extract good local features to recover noisy images. We validate the effectiveness of SGN through extensive experiments. The experimental results demonstrate that SGN greatly improves the memory and runtime efficiency over state-of-the-art efficient methods, without trading off PSNR accuracy.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",18.625,0.1842261904761905,0.4797619047619048,1,0.10582010582010581,0.037037037037037035,0.37575757575757573
1685,1720,1720,Learning rich features at high-speed for single-shot object detection,"Single-stage object detection methods have received significant attention recently due to their characteristic realtime capabilities and high detection accuracies. Generally, most existing single-stage detectors follow two common practices: They employ a network backbone that is pretrained on ImageNet for the classification task and use a top-down feature pyramid representation for handling scale variations. Contrary to common pre-training strategy, recent works have demonstrated the benefits of training from scratch to reduce the task gap between classification and localization, especially at high overlap thresholds. However, detection models trained from scratch require significantly longer training time compared to their typical finetuning based counterparts. We introduce a single-stage detection framework that combines the advantages of both fine-tuning pretrained models and training from scratch. Our framework constitutes a standard network that uses a pre-trained backbone and a parallel light-weight auxiliary network trained from scratch. Further, we argue that the commonly used top-down pyramid representation only focuses on passing high-level semantics from the top layers to bottom layers. We introduce a bi-directional network that efficiently circulates both low-/mid-level and high-level semantic information in the detection framework. Experiments are performed on MS COCO and UAVDT datasets. Compared to the baseline, our detector achieives an absolute gain of 7.4% and 4.2% in average precision (AP) on MS COCO and UAVDT datasets, respectively using VGG backbone. For a 300×300 input on the MS COCO test set, our detector with ResNet backbone surpasses existing single-stage detection methods for single-scale inference achieving 34.3 AP, while operating at an inference time of 19 milliseconds on a single Titan X GPU. Code is avail- able at https://github.com/vaesl/LRF-Net.",60019533,Tianjin University,Tianjin,China,"['1712', '1707']",22.0,0.06591991341991342,0.5054978354978354,1,0.109375,0.053125,0.3835616438356164
1686,1721,1721,Human-aware motion deblurring,"This paper proposes a human-aware deblurring model that disentangles the motion blur between foreground (FG) humans and background (BG). The proposed model is based on a triple-branch encoder-decoder architecture. The first two branches are learned for sharpening FG humans and BG details, respectively; while the third one produces global, harmonious results by comprehensively fusing multi-scale deblurring information from the two domains. The proposed model is further endowed with a supervised, human-aware attention mechanism in an end-to-end fashion. It learns a soft mask that encodes FG human information and explicitly drives the FG/BG decoder-branches to focus on their specific domains. Above designs lead to a fully differentiable motion deblurring network, which can be trained end-to-end. To further benefit the research towards Human-aware Image Deblurring, we introduce a large-scale dataset, named HIDE, which consists of 8,422 blurry and sharp image pairs with 65,784 densely annotated FG human bounding boxes. HIDE is specifically built to span a broad range of scenes, human object sizes, motion patterns, and background complexities. Extensive experiments on public benchmarks and our dataset demonstrate that our model performs favorably against the state-of-the-art motion deblurring methods, especially in capturing semantic details.",60026415,Stony Brook University,Stony Brook,United States,"['1712', '1707']",21.222222222222218,0.016911764705882352,0.28063725490196084,1,0.12096774193548387,0.05241935483870968,0.4351851851851852
1687,1722,1722,Entangled transformer for image captioning,"In image captioning, the typical attention mechanisms are arduous to identify the equivalent visual signals especially when predicting highly abstract words. This phenomenon is known as the semantic gap between vision and language. This problem can be overcome by providing semantic attributes that are homologous to language. Thanks to the inherent recurrent nature and gated operating mechanism, Recurrent Neural Network (RNN) and its variants are the dominating architectures in image captioning. However, when designing elaborate attention mechanisms to integrate visual inputs and semantic attributes, RNN-like variants become unflexible due to their complexities. In this paper, we investigate a Transformer-based sequence modeling framework, built only with attention layers and feedforward layers. To bridge the semantic gap, we introduce EnTangled Attention (ETA) that enables the Transformer to exploit semantic and visual information simultaneously. Furthermore, Gated Bilateral Controller (GBC) is proposed to guide the interactions between the multimodal information. We name our model as ETA-Transformer. Remarkably, ETA-Transformer achieves state-of-the-art performance on the MSCOCO image captioning dataset. The ablation studies validate the improvements of our proposed modules.",60023932,University of Technology Sydney,Sydney,Australia,"['1712', '1707']",15.727272727272727,0.08069444444444446,0.5179166666666667,1,0.11737089201877934,0.07981220657276995,0.4120603015075377
1688,1724,1724,Network optimization under traffic uncertainties based on SDN,"Software Defined Networking (SDN) is an emerging network architecture that separates the control plane from the data plane to simplify and improve network management with a high degree of flexibility. Network optimization under traffic uncertainties is one of the most challenging topics in communication networks to optimize network performance and traffic delivery. Although the traffic optimization technology has been extensively studied in the industry, a traffic optimization solution different from the traditional network is needed in the SDN network, which can utilize global network information and traffic characteristics to control and manage traffic in a better way. In this paper, a Mixed Linear Geometric Programming Traffic Optimization Algorithm (MLGP-TOA) is proposed for the problem of traffic uncertainties in SDN. Aiming at minimizing the maximum link utilization (MLU), the initial problem is transformed into a convex optimization problem by monomial approximation and variable substitution. Then, the inner point method is used to find the global optimal solution, and the optimal split ratio at each node is obtained. Finally, the configuration information is sent to the data plane. The simulation results show that the algorithm can reduce MLU, so that the traffic can fully utilize network resources and avoid congestion.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],24.75,0.13285714285714287,0.4457142857142857,1,0.12162162162162163,0.06756756756756757,0.2681818181818182
1689,1725,1725,Health center needs manager with graduate of profession of public health generalist in Indonesia,"An additional cost of health insurance paid by the government has increased every year. Theoretically, this is due to curative services have been more and more dominant. The one problem might be due to different views between 2 organizations concerning public health. The objective of this paper is offering innovative thought to create the same view between the 2 organizations to strengthen preventive and promotional health services through health centers. One organization has conducted competency examination to Bachelor of Public Health Specialist; if he/she passes the examination, they are granted a Letter of Registration. However, another organization disagrees, because someone will obtain a Letter of Registration if he/she has already passed as a Profession of Public Health. Concerning with the different view, the writers offer an Innovative Thoughts that necessary Profession in Public Health Generalist appointed to be Manager in Health Center, for which Profession of Public Health Generalist Education Program established, where students receive theory in class and practice in the Field Laboratory of Public Health based on Integration of Public Health Scientific Disciplines. The government should also provide the Profession of Public Health Specialist working in the functional position in the Ministry of Health and Provincial/District Health Department. The writers formulate several conclusions to strengthen preventive and promotional health services enhancing community health status as the one factor to develop human resources namely Presidents Joko Widodo’s Vision in the Second Working Cabinet 2019-2024.",124081789,University of Haji Abdul Malik Kamarullah (UHAMKA),Jakarta,Indonesia,['1706'],26.11111111111111,0.06874999999999999,0.29201388888888885,1,0.10344827586206896,0.18007662835249041,0.40551181102362205
1690,1726,1726,Looking to relations for future trajectory forecast,"Inferring relational behavior between road users as well as road users and their surrounding physical space is an important step toward effective modeling and prediction of navigation strategies adopted by participants in road scenes. To this end, we propose a relation-aware framework for future trajectory forecast. Our system aims to infer relational information from the interactions of road users with each other and with the environment. The first module involves visual encoding of spatio-temporal features, which captures human-human and human-space interactions over time. The following module explicitly constructs pair-wise relations from spatio-temporal interactions and identifies more descriptive relations that highly influence future motion of the target road user by considering its past trajectory. The resulting relational features are used to forecast future locations of the target, in the form of heatmaps with an additional guidance of spatial dependencies and consideration of the uncertainty. Extensive evaluations on the public benchmark datasets demonstrate the robustness and efficacy of the proposed framework as observed by performances higher than the state-of-the-art methods.",60104105,"Honda R&amp;D Americas, Inc.",Torrance,United States,"['1712', '1707']",24.0,0.1115625,0.3322619047619048,1,0.09183673469387756,0.0,0.2808988764044944
1691,1727,1727,3D instance segmentation via multi-task metric learning,"We propose a novel method for instance label segmentation of dense 3D voxel grids. We target volumetric scene representations, which have been acquired with depth sensors or multi-view stereo methods and which have been processed with semantic 3D reconstruction or scene completion methods. The main task is to learn shape information about individual object instances in order to accurately separate them, including connected and incompletely scanned objects. We solve the 3D instance-labeling problem with a multi-task learning strategy. The first goal is to learn an abstract feature embedding, which groups voxels with the same instance label close to each other while separating clusters with different instance labels from each other. The second goal is to learn instance information by densely estimating directional information of the instance's center of mass for each voxel. This is particularly useful to find instance boundaries in the clustering post-processing step, as well as, for scoring the segmentation quality for the first goal. Both synthetic and real-world experiments demonstrate the viability and merits of our approach. In fact, it achieves state-of-the-art performance on the ScanNet 3D instance segmentation benchmark.",60092945,King Abdullah University of Science and Technology,Jeddah,Saudi Arabia,"['1712', '1707']",20.33333333333333,0.08472222222222224,0.3006944444444445,1,0.09302325581395349,0.023255813953488372,0.2814070351758794
1692,1728,1728,3D face modeling from diverse raw scan data,"Traditional 3D face models learn a latent representation of faces using linear subspaces from limited scans of a single database. The main roadblock of building a large-scale face model from diverse 3D databases lies in the lack of dense correspondence among raw scans. To address these problems, this paper proposes an innovative framework to jointly learn a nonlinear face model from a diverse set of raw 3D scan databases and establish dense point-to-point correspondence among their scans. Specifically, by treating input scans as unorganized point clouds, we explore the use of PointNet architectures for converting point clouds to identity and expression feature representations, from which the decoder networks recover their 3D face shapes. Further, we propose a weakly supervised learning approach that does not require correspondence label for the scans. We demonstrate the superior dense correspondence and representation power of our proposed method, and its contribution to single-image 3D face reconstruction.",60031707,Michigan State University,East Lansing,United States,"['1712', '1707']",25.16666666666667,0.03872710622710622,0.5388553113553114,1,0.10526315789473684,0.011695906432748537,0.3067484662576687
1693,1729,1729,Explicit shape encoding for real-time instance segmentation,"In this paper, we propose a novel top-down instance segmentation framework based on explicit shape encoding, named textbf{ESE-Seg}. It largely reduces the computational consumption of the instance segmentation by explicitly decoding the multiple object shapes with tensor operations, thus performs the instance segmentation at almost the same speed as the object detection. ESE-Seg is based on a novel shape signature Inner-center Radius (IR), Chebyshev polynomial fitting and the strong modern object detectors. ESE-Seg with YOLOv3 outperforms the Mask R-CNN on Pascal VOC 2012 at mAPr@0.5 while 7 times faster.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",22.25,0.22460317460317455,0.34781746031746025,1,0.07142857142857142,0.14285714285714285,0.3942307692307692
1694,1730,1730,Multinomial distribution learning for effective neural architecture search,"Architectures obtained by Neural Architecture Search (NAS) have achieved highly competitive performance in various computer vision tasks. However, the prohibitive computation demand of forward-backward propagation in deep neural networks and searching algorithms makes it difficult to apply NAS in practice. In this paper, we propose a Multinomial Distribution Learning for extremely effective NAS, which considers the search space as a joint multinomial distribution, i.e., the operation between two nodes is sampled from this distribution, and the optimal network structure is obtained by the operations with the most likely probability in this distribution. Therefore, NAS can be transformed to a multinomial distribution learning problem, i.e., the distribution is optimized to have a high expectation of the performance. Besides, a hypothesis that the performance ranking is consistent in every training epoch is proposed and demonstrated to further accelerate the learning process. Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of our method. On CIFAR-10, the structure searched by our method achieves 2.55% test error, while being 6.0× (only 4 GPU hours on GTX1080Ti) faster compared with state-of-the-art NAS algorithms. On ImageNet, our model achieves 74% top1 accuracy under MobileNet settings (MobileNet V1/V2), while being 1.2× faster with measured GPU latency. Test code with pre-trained models are available at https: //github.com/tanglang96/MDENAS.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",23.11111111111111,0.13083333333333333,0.6191666666666668,1,0.0859375,0.08984375,0.4125
1695,1731,1731,Psychological wellbeing intended for healthy longevity," The estimation of Life Expectancy based on data from World Health Organization (WHO) and World Development Indicators (WDI) 2015, ranked 145/187 for India reflects poor life expectancy. Psychological wellbeing and emotional regulations are linked with better health and prevent illness physiologically. The concept of “Kaayakarpam” healthy longevity research from the siddha philosophy counterparts that longevity potential includes observation of certain lifestyle that help to prevent psychosomatic disease as mentioned in “Theraiyar Pini Anugaa Vidhi” as it makes human body resilient naturally.",60105237,"Vels Institute of Science, Technology &amp; Advanced Studies",Chennai,India,['1706'],27.33333333333333,0.1015873015873016,0.4912698412698413,0,0.11702127659574468,0.1595744680851064,0.41935483870967744
1696,1732,1732,Disentangling propagation and generation for video prediction,"A dynamic scene has two types of elements: Those that move fluidly and can be predicted from previous frames, and those which are disoccluded (exposed) and cannot be extrapolated. Prior approaches to video prediction typically learn either to warp or to hallucinate future pixels, but not both. In this paper, we describe a computational model for high-fidelity video prediction which disentangles motion-specific propagation from motion-agnostic generation. We introduce a confidence-aware warping operator which gates the output of pixel predictions from a flow predictor for non-occluded regions and from a context encoder for occluded regions. Moreover, in contrast to prior works where confidence is jointly learned with flow and appearance using a single network, we compute confidence after a warping step, and employ a separate network to inpaint exposed regions. Empirical results on both synthetic and real datasets show that our disentangling approach provides better occlusion maps and produces both sharper and more realistic predictions compared to strong baselines.",60030162,Columbia University in the City of New York,New York,United States,"['1712', '1707']",26.33333333333333,0.10680272108843536,0.2670918367346939,1,0.13043478260869565,0.0,0.3103448275862069
1697,1733,1733,Operatornet: Recovering 3D shapes from difference operators,"This paper proposes a learning-based framework for reconstructing 3D shapes from functional operators, compactly encoded as small-sized matrices. To this end we introduce a novel neural architecture, called OperatorNet, which takes as input a set of linear operators representing a shape and produces its 3D embedding. We demonstrate that this approach significantly outperforms previous purely geometric methods for the same problem. Furthermore, we introduce a novel functional operator, which encodes the extrinsic or pose-dependent shape information, and thus complements purely intrinsic pose-oblivious operators, such as the classical Laplacian. Coupled with this novel operator, our reconstruction network achieves very high reconstruction accuracy, even in the presence of incomplete information about a shape, given a soft or functional map expressed in a reduced basis. Finally, we demonstrate that the multiplicative functional algebra enjoyed by these operators can be used to synthesize entirely new unseen shapes, in the context of shape interpolation and shape analogy applications.",60028952,Laboratoire d'Informatique de l'Ecole Polytechnique,Palaiseau,France,"['1712', '1707']",25.5,0.13177236652236649,0.4894343434343435,1,0.1340782122905028,0.0111731843575419,0.30409356725146197
1698,1734,1734,Spatial-temporal relation networks for multi-object tracking,"Recent progress in multiple object tracking (MOT) has shown that a robust similarity score is a key to the success of trackers. A good similarity score is expected to reflect multiple cues, e.g. appearance, location, and topology, over a long period of time. However, these cues are heterogeneous, making them hard to be combined in a unified network. As a result, existing methods usually encode them in separate networks or require a complex training approach. In this paper, we present a unified framework for similarity measurement based on spatial-temporal relation network which could simultaneously encode various cues and perform reasoning across both spatial and temporal domains. We also study the feature representation of a tracklet-object pair in depth, showing a proper design of the pair features can well empower the trackers. The resulting approach is named spatial-temporal relation networks (STRN). It runs in a feed-forward way and can be trained in an end-to-end manner. The state-of-the-art accuracy was achieved on all of the MOT15sim17 benchmarks using public detection and online settings.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",17.1,0.0005555555555555573,0.3005555555555555,1,0.11848341232227488,0.014218009478672985,0.30412371134020616
1699,1735,1735,ACNet: Strengthening the kernel skeletons for powerful CNN via asymmetric convolution blocks,"As designing appropriate Convolutional Neural Network (CNN) architecture in the context of a given application usually involves heavy human works or numerous GPU hours, the research community is soliciting the architecture-neutral CNN structures, which can be easily plugged into multiple mature architectures to improve the performance on our real-world applications. We propose Asymmetric Convolution Block (ACB), an architecture-neutral structure as a CNN building block, which uses 1D asymmetric convolutions to strengthen the square convolution kernels. For an off-the-shelf architecture, we replace the standard square-kernel convolutional layers with ACBs to construct an Asymmetric Convolutional Network (ACNet), which can be trained to reach a higher level of accuracy. After training, we equivalently convert the ACNet into the same original architecture, thus requiring no extra computations anymore. We have observed that ACNet can improve the performance of various models on CIFAR and ImageNet by a clear margin. Through further experiments, we attribute the effectiveness of ACB to its capability of enhancing the model's robustness to rotational distortions and strengthening the central skeleton parts of square convolution kernels.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",29.0,0.07696078431372551,0.3465686274509803,1,0.11057692307692307,0.10096153846153846,0.3673469387755102
1700,1736,1736,Teacher guided architecture search,"Much of the recent improvement in neural networks for computer vision has resulted from discovery of new networks architectures. Most prior work has used the performance of candidate models following limited training to automatically guide the search in a feasible way. Could further gains in computational efficiency be achieved by guiding the search via measurements of a high performing network with unknown detailed architecture (e.g. the primate visual system)? As one step toward this goal, we use representational similarity analysis to evaluate the similarity of internal activations of candidate networks with those of a (fixed, high performing) teacher network. We show that adopting this evaluation metric could produce up to an order of magnitude in search efficiency over performance-guided methods. Our approach finds a convolutional cell structure with similar performance as was previously found using other methods but at a total computational cost that is two orders of magnitude lower than Neural Architecture Search (NAS) and more than four times lower than progressive neural architecture search (PNAS). We further show that measurements from only ∼300 neurons from primate visual system provides enough signal to find a network with an Imagenet top-1 error that is significantly lower than that achieved by performance-guided architecture search alone. These results suggest that representational matching can be used to accelerate network architecture search in cases where one has access to some or all of the internal representations of a teacher network of interest, such as the brain's sensory processing networks.",60100145,McGovern Institute,Cambridge,United States,"['1712', '1707']",30.625,0.07660253326919994,0.3831136764470098,1,0.10037174721189591,0.022304832713754646,0.2593984962406015
1701,1737,1737,Improving pedestrian attribute recognition with weakly-supervised multi-scale attribute-specific localization,"Pedestrian attribute recognition has been an emerging research topic in the area of video surveillance. To predict the existence of a particular attribute, it is demanded to localize the regions related to the attribute. However, in this task, the region annotations are not available. How to carve out these attribute-related regions remains challenging. Existing methods applied attribute-agnostic visual attention or heuristic body-part localization mechanisms to enhance the local feature representations, while neglecting to employ attributes to define local feature areas. We propose a flexible Attribute Localization Module (ALM) to adaptively discover the most discriminative regions and learns the regional features for each attribute at multiple levels. Moreover, a feature pyramid architecture is also introduced to enhance the attribute-specific localization at low-levels with high-level semantic guidance. The proposed framework does not require additional region annotations and can be trained end-to-end with multi-level deep supervision. Extensive experiments show that the proposed method achieves state-of-the-art results on three pedestrian attribute datasets, including PETA, RAP, and PA-100K.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",18.11111111111111,0.08787878787878788,0.3060606060606061,1,0.13658536585365855,0.02926829268292683,0.3791208791208791
1702,1738,1738,A2J: Anchor-to-joint regression network for 3D articulated pose estimation from a single depth image,"For 3D hand and body pose estimation task in depth image, a novel anchor-based approach termed Anchor-to-Joint regression network (A2J) with the end-to-end learning ability is proposed. Within A2J, anchor points able to capture global-local spatial context information are densely set on depth image as local regressors for the joints. They contribute to predict the positions of the joints in ensemble way to enhance generalization ability. The proposed 3D articulated pose estimation paradigm is different from the state-of-the-art encoder-decoder based FCN, 3D CNN and point-set based manners. To discover informative anchor points towards certain joint, anchor proposal procedure is also proposed for A2J. Meanwhile 2D CNN (i.e., ResNet- 50) is used as backbone network to drive A2J, without using time-consuming 3D convolutional or deconvolutional layers. The experiments on 3 hand datasets and 2 body datasets verify A2J's superiority. Meanwhile, A2J is of high running speed around 100 FPS on single NVIDIA 1080Ti GPU.",60032083,"University at Buffalo, The State University of New York",Buffalo,United States,"['1712', '1707']",19.125,0.13380952380952382,0.4251190476190476,1,0.10714285714285714,0.061224489795918366,0.42196531791907516
1703,1739,1739,Dynamic multi-scale filters for semantic segmentation,"Multi-scale representation provides an effective way to address scale variation of objects and stuff in semantic segmentation. Previous works construct multi-scale representation by utilizing different filter sizes, expanding filter sizes with dilated filters or pooling grids, and the parameters of these filters are fixed after training. These methods often suffer from heavy computational cost or have more parameters, and are not adaptive to the input image during inference. To address these problems, this paper proposes a Dynamic Multi-scale Network (DMNet) to adaptively capture multi-scale contents for predicting pixel-level semantic labels. DMNet is composed of multiple Dynamic Convolutional Modules (DCMs) arranged in parallel, each of which exploits context-aware filters to estimate semantic representation for a specific scale. The outputs of multiple DCMs are further integrated for final segmentation. We conduct extensive experiments to evaluate our DMNet on three challenging semantic segmentation and scene parsing datasets, PASCAL VOC 2012, Pascal-Context, and ADE20K. DMNet achieves a new record 84.4% mIoU on PASCAL VOC 2012 test set without MS COCO pre-trained and post-processing, and also obtains state-of-the-art performance on Pascal-Context and ADE20K.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",22.25,0.08645276292335116,0.3831105169340463,1,0.11607142857142858,0.08035714285714286,0.425
1704,1740,1740,FW-GAN: Flow-navigated warping GAN for video virtual try-on,"Beyond current image-based virtual try-on systems that have attracted increasing attention, we move a step forward to developing a video virtual try-on system that precisely transfers clothes onto the person and generates visually realistic videos conditioned on arbitrary poses. Besides the challenges in image-based virtual try-on (e.g., clothes fidelity, image synthesis), video virtual try-on further requires spatiotemporal consistency. Directly adopting existing image-based approaches often fails to generate coherent video with natural and realistic textures. In this work, we propose Flow-navigated Warping Generative Adversarial Network (FW-GAN), a novel framework that learns to synthesize the video of virtual try-on based on a person image, the desired clothes image, and a series of target poses. FW-GAN aims to synthesize the coherent and natural video while manipulating the pose and clothes. It consists of: (i) a flow-guided fusion module that warps the past frames to assist synthesis, which is also adopted in the discriminator to help enhance the coherence and quality of the synthesized video; (ii) a warping net that is designed to warp clothes image for the refinement of clothes textures; (iii) a parsing constraint loss that alleviates the problem caused by the misalignment of segmentation maps from images with different poses and various clothes. Experiments on our newly collected dataset show that FW-GAN can synthesize high-quality video of virtual try-on and significantly outperforms other methods both qualitatively and quantitatively.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",32.42857142857143,0.040984848484848485,0.4960606060606061,1,0.15384615384615385,0.038461538461538464,0.34765625
1705,1741,1741,Grounded human-object interaction hotspots from video,"Learning how to interact with objects is an important step towards embodied visual intelligence, but existing techniques suffer from heavy supervision or sensing requirements. We propose an approach to learn human-object interaction 'hotspots' directly from video. Rather than treat affordances as a manually supervised semantic segmentation task, our approach learns about interactions by watching videos of real human behavior and anticipating afforded actions. Given a novel image or video, our model infers a spatial hotspot map indicating where an object would be manipulated in a potential interaction even if the object is currently at rest. Through results with both first and third person video, we show the value of grounding affordances in real human-object interactions. Not only are our weakly supervised hotspots competitive with strongly supervised affordance methods, but they can also anticipate object interaction for novel object categories. Project page: Http://vision.cs.utexas.edu/projects/interaction-hotspots/.",60013372,The University of Texas at Austin,Austin,United States,"['1712', '1707']",20.285714285714285,0.062179487179487174,0.4955128205128205,1,0.15,0.00625,0.34177215189873417
1706,1742,1742,Taxonomy among triplets: Opening the black box," These concepts are commonly and interchangeably used but are conceptually different from each other. It is pivotal to understand their differences in order to manage them. Within each of these concepts, the paper offers an overview of the literature, particularly the definitions, types, characteristics, and management approaches to develop a taxonomy of risk, crisis, and disaster. Sixteen dimensions of difference were identified for the taxonomy. Further distinguishing dimensions are developed. By plotting existing literature against the origin, mitigation, and recovery publication of each of these concepts, an agenda of future research topics is developed.",60016374,Libera Universita Internazionale degli Studi Sociali Guido Carli,Rome,Italy,['1706'],15.833333333333336,0.05416666666666666,0.38333333333333336,0,0.0990990990990991,0.0,0.34545454545454546
1707,1743,1743,Does asset quality matter in relationship between bank capital on lending growth?,"Mostly, loans are important source of income for banks and capital is used to absorb shocks during a bank’s worst periods. Credit risk is a major concern for the banking industry as the ratio of bad loans increases. The purpose of this research examines the effect of bank capital on lending growth with moderation of asset quality of banking sector listed in Indonesia Stock Exchange (IDX). This study used Fixed Effect Model. Data obtained from the company's financial report published in 2009-2018 period. Dependent variable in this research is lending growth proxied with Net Loan Growth. Independent variable used bank capital proxied with Capital Adequacy Ratio (CAR). Moderating Variable in this research used asset quality proxied with Non Performing Loan (NPL). In addition, controlling variable in this study are liquidity level, firm size and bank performance. The results showed that bank capital has a significant positive effect on lending growth, while the bad asset quality mitigates the positive effect of bank capital on lending growth. This results are in line with policies that have been made by Otoritas Jasa Keuangan (OJK) about maintaning capital adequacy ratio and non performing loan.",60069383,Universitas Airlangga,Surabaya,Indonesia,['1706'],17.272727272727273,-0.0505681818181818,0.5017316017316018,1,0.08755760368663594,0.10599078341013825,0.37962962962962965
1708,1744,1744,FAB: A robust facial landmark detection framework for motion-blurred videos,"Recently, facial landmark detection algorithms have achieved remarkable performance on static images. However, these algorithms are neither accurate nor stable in motion-blurred videos. The missing of structure information makes it difficult for state-of-the-art facial landmark detection algorithms to yield good results. In this paper, we propose a framework named FAB that takes advantage of structure consistency in the temporal dimension for facial landmark detection in motion-blurred videos. A structure predictor is proposed to predict the missing face structural information temporally, which serves as a geometry prior. This allows our framework to work as a virtuous circle. On one hand, the geometry prior helps our structure-aware deblurring network generates high quality deblurred images which lead to better landmark detection results. On the other hand, better landmark detection results help structure predictor generate better geometry prior for the next frame. Moreover, it is a flexible video-based framework that can incorporate any static image-based methods to provide a performance boost on video datasets. Extensive experiments on Blurred-300VW, the proposed Real-world Motion Blur (RWMB) datasets and 300VW demonstrate the superior performance to the state-of-the-art methods. Datasets and model will be publicly available at href{https://github.com/KeqiangSun/FAB}{https://github.com/KeqiangSun/FAB}.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",17.272727272727273,0.19934782608695656,0.3883333333333333,1,0.11885245901639344,0.036885245901639344,0.37104072398190047
1709,1745,1745,Agile depth sensing using triangulation light curtains,"Depth sensors like LIDARs and Kinect use a fixed depth acquisition strategy that is independent of the scene of interest. Due to the low spatial and temporal resolution of these sensors, this strategy can undersample parts of the scene that are important (small or fast moving objects), or oversample areas that are not informative for the task at hand (a fixed planar wall). In this paper, we present an approach and system to dynamically and adaptively sample the depths of a scene using the principle of triangulation light curtains. The approach directly detects the presence or absence of objects at specified 3D lines. These 3D lines can be sampled sparsely, non-uniformly, or densely only at specified regions. The depth sampling can be varied in real-time, enabling quick object discovery or detailed exploration of areas of interest. These results are achieved using a novel prototype light curtain system that is based on a 2D rolling shutter camera with higher light efficiency, working range, and faster adaptation than previous work, making it useful broadly for autonomous navigation and exploration.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",25.285714285714285,0.14962121212121213,0.4376893939393939,1,0.08955223880597014,0.014925373134328358,0.27918781725888325
1710,1746,1746,Protocol analysis method based on state machine,"Based network protocol analysis method. By capturing the data flow through the network interface, using data flow management and data stream reorganization technology, multiple data packets are identified as different data streams. Calling Protocol Characteristic Library to Identify Protocol Types Used by Different Data Streams. Complete the functions of network packet content extraction and private protocol identification in high-speed and high-traffic environment.",60007711,Jilin University,Changchun,China,['1700'],15.5,0.005555555555555557,0.4069444444444444,1,0.09722222222222222,0.09722222222222222,0.4117647058823529
1711,1747,1747,C-MIDN: Coupled multiple instance detection network with segmentation guidance for weakly supervised object detection,"Weakly supervised object detection (WSOD) that only needs image-level annotations has obtained much attention recently. By combining convolutional neural network with multiple instance learning method, Multiple Instance Detection Network (MIDN) has become the most popular method to address the WSOD problem and been adopted as the initial model in many works. We argue that MIDN inclines to converge to the most discriminative object parts, which limits the performance of methods based on it. In this paper, we propose a novel Coupled Multiple Instance Detection Network (C-MIDN) to address this problem. Specifically, we use a pair of MIDNs, which work in a complementary manner with proposal removal. The localization information of the MIDNs is further coupled to obtain tighter bounding boxes and localize multiple objects. We also introduce a Segmentation Guided Proposal Removal (SGPR) algorithm to guarantee the MIL constraint after the removal and ensure the robustness of C-MIDN. Through a simple implementation of the C-MIDN with online detector refinement, we obtain 53.6% and 50.3% mAP on the challenging PASCAL VOC 2007 and 2012 benchmarks respectively, which significantly outperform the previous state-of-the-arts.",60030904,Institute of Computing Technology Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",22.625,0.13859649122807016,0.3933583959899749,1,0.12272727272727273,0.08636363636363636,0.3883495145631068
1712,1749,1749,Cross-domain adaptation for animal pose estimation,"In this paper, we are interested in pose estimation of animals. Animals usually exhibit a wide range of variations on poses and there is no available animal pose dataset for training and testing. To address this problem, we build an animal pose dataset to facilitate training and evaluation. Considering the heavy labor needed to label dataset and it is impossible to label data for all concerned animal species, we, therefore, proposed a novel cross-domain adaptation method to transform the animal pose knowledge from labeled animal classes to unlabeled animal classes. We use the modest animal pose dataset to adapt learned knowledge to multiple animals species. Moreover, humans also share skeleton similarities with some animals (especially four-footed mammals). Therefore, the easily available human pose dataset, which is of a much larger scale than our labeled animal dataset, provides important prior knowledge to boost up the performance on animal pose estimation. Experiments show that our proposed method leverages these pieces of prior knowledge well and achieves convincing results on animal pose estimation.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",21.25,0.014583333333333353,0.496875,1,0.12435233160621761,0.010362694300518135,0.2857142857142857
1713,1750,1750,A novel genetic approach applied for power loss reduction and improved bus voltage profile in distribution network system,"This paper presents a network reconfiguration which is a vital analysis process for optimizing and controlling distribution systems. The method is based on genetic algorithm by changing the status of the switches to improve the operational performance. The main objective is to minimize the system power losses and to keep bus voltage profile into limits with radial distribution to provide the consumers with quality electrical energy while minimizing the cost. For this optimization problem, an objective function is developed from an electrical branch to sort the fittest solution. Selection, Crossover and mutation are the necessary three operators in which some improvements are made for the effectiveness of the genetic approach. The method can be successfully applied for loss minimum problem. Numerical example simulated with MATLAB/GUI is demonstrated by 33-bus distribution network and tested using a default mode network. As results, premature convergence is avoided, it shows the validity of the proposed methodology while respecting all the constraints.",60070599,Ecole Normale Superieure de Enseignment Technique de Rabat,Agdal Rabat,Morocco,['1700'],19.625,0.15952380952380954,0.4547619047619048,1,0.13450292397660818,0.017543859649122806,0.24260355029585798
1714,1751,1751,A robust learning approach to domain adaptive object detection,"Domain shift is unavoidable in real-world applications of object detection. For example, in self-driving cars, the target domain consists of unconstrained road environments which cannot all possibly be observed in training data. Similarly, in surveillance applications sufficiently representative training data may be lacking due to privacy regulations. In this paper, we address the domain adaptation problem from the perspective of robust learning and show that the problem may be formulated as training with noisy labels. We propose a robust object detection framework that is resilient to noise in bounding box class labels, locations and size annotations. To adapt to the domain shift, the model is trained on the target domain using a set of noisy object bounding boxes that are obtained by a detection model trained only in the source domain. We evaluate the accuracy of our approach in various source/target domain pairs and demonstrate that the model significantly improves the state-of-the-art on multiple domain adaptation scenarios on the SIM10K, Cityscapes and KITTI datasets.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",23.42857142857143,0.03571428571428571,0.5928571428571429,1,0.109375,0.020833333333333332,0.26256983240223464
1715,1752,1752,TRB: A novel triplet representation for understanding 2D human body,"Human pose and shape are two important components of 2D human body. However, how to efficiently represent both of them in images is still an open question. In this paper, we propose the Triplet Representation for Body (TRB) - - a compact 2D human body representation, with skeleton keypoints capturing human pose information and contour keypoints containing human shape information. TRB not only preserves the flexibility of skeleton keypoint representation, but also contains rich pose and human shape information. Therefore, it promises broader application areas, such as human shape editing and conditional image generation. We further introduce the challenging problem of TRB estimation, where joint learning of human pose and shape is required. We construct several large-scale TRB estimation datasets, based on the popular 2D pose datasets LSP, MPII and COCO. To effectively solve TRB estimation, we propose a two-branch network (TRB-net) with three novel techniques, namely X-structure (Xs), Directional Convolution (DC) and Pairwise mapping (PM), to enforce multi-level message passing for joint feature learning. We evaluate our proposed TRB-net and several leading approaches on our proposed TRB datasets, and demonstrate the superiority of our method through extensive evaluations.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",21.0,0.12375,0.4041666666666667,1,0.10256410256410256,0.10683760683760683,0.42342342342342343
1716,1753,1753,Where is my mirror?,"Mirrors are everywhere in our daily lives. Existing computer vision systems do not consider mirrors, and hence may get confused by the reflected content inside a mirror, resulting in a severe performance degradation. However, separating the real content outside a mirror from the reflected content inside it is non-trivial. The key challenge is that mirrors typically reflect contents similar to their surroundings, making it very difficult to differentiate the two. In this paper, we present a novel method to segment mirrors from an input image. To the best of our knowledge, this is the first work to address the mirror segmentation problem with a computational approach. We make the following contributions. First, we construct a large-scale mirror dataset that contains mirror images with corresponding manually annotated masks. This dataset covers a variety of daily life scenes, and will be made publicly available for future research. Second, we propose a novel network, called MirrorNet, for mirror segmentation, by modeling both semantical and low-level color/texture discontinuities between the contents inside and outside of the mirrors. Third, we conduct extensive experiments to evaluate the proposed method, and show that it outperforms the carefully chosen baselines from the state-of-the-art detection and segmentation methods.",60013983,City University of Hong Kong,Kowloon,Hong Kong,"['1712', '1707']",18.09090909090909,0.037301587301587315,0.3297619047619047,1,0.13025210084033614,0.004201680672268907,0.28125
1717,1754,1754,Semantic-aware knowledge preservation for zero-shot sketch-based image retrieval,"Sketch-based image retrieval (SBIR) is widely recognized as an important vision problem which implies a wide range of real-world applications. Recently, research interests arise in solving this problem under the more realistic and challenging setting of zero-shot learning. In this paper, we investigate this problem from the viewpoint of domain adaptation which we show is critical in improving feature embedding in the zero-shot scenario. Based on a framework which starts with a pre-trained model on ImageNet and fine-tunes it on the training set of SBIR benchmark, we advocate the importance of preserving previously acquired knowledge, e.g., the rich discriminative features learned from ImageNet, to improve the model's transfer ability. For this purpose, we design an approach named Semantic-Aware Knowledge prEservation (SAKE), which fine-tunes the pre-trained model in an economical way and leverages semantic information, e.g., inter-class relationship, to achieve the goal of knowledge preservation. Zero-shot experiments on two extended SBIR datasets, TU-Berlin and Sketchy, verify the superior performance of our approach. Extensive diagnostic experiments validate that knowledge preserved benefits SBIR in zero-shot settings, as a large fraction of the performance gain is from the more properly structured feature embedding for photo images.",60005248,Johns Hopkins University,Baltimore,United States,"['1712', '1707']",27.42857142857143,0.2055803571428572,0.5476190476190477,1,0.10655737704918032,0.045081967213114756,0.3486238532110092
1718,1755,1755,Bilateral adversarial training: Towards fast training of more robust models against adversarial attacks,"In this paper, we study fast training of adversarially robust models. From the analyses of the state-of-the-art defense method, i.e., the multi-step adversarial training∼cite{madry2017towards}, we hypothesize that the gradient magnitude links to the model robustness. Motivated by this, we propose to perturb both the image and the label during training, which we call Bilateral Adversarial Training (BAT). To generate the adversarial label, we derive an closed-form heuristic solution. To generate the adversarial image, we use one-step targeted attack with the target label being the most confusing class. In the experiment, we first show that random start and the most confusing target attack effectively prevent the label leaking and gradient masking problem. Then coupled with the adversarial label part, our model significantly improves the state-of-the-art results. For example, against PGD100 white-box attack with cross-entropy loss, on CIFAR10, we achieve 63.7% versus 47.2%; on SVHN, we achieve 59.1% versus 42.1%. At last, the experiment on the very (computationally) challenging ImageNet dataset further demonstrates the effectiveness of our fast method.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",18.555555555555557,0.15892857142857145,0.5267857142857142,1,0.08520179372197309,0.03587443946188341,0.39901477832512317
1719,1756,1756,Deep single-image portrait relighting,"Conventional physically-based methods for relighting portrait images need to solve an inverse rendering problem, estimating face geometry, reflectance and lighting. However, the inaccurate estimation of face components can cause strong artifacts in relighting, leading to unsatisfactory results. In this work, we apply a physically-based portrait relighting method to generate a large scale, high quality, 'in the wild' portrait relighting dataset (DPR). A deep Convolutional Neural Network (CNN) is then trained using this dataset to generate a relit portrait image by using a source image and a target lighting as input. The training procedure regularizes the generated results, removing the artifacts caused by physically-based relighting methods. A GAN loss is further applied to improve the quality of the relit portrait image. Our trained network can relight portrait images with resolutions as high as 1024 × 1024. We evaluate the proposed method on the proposed DPR datset, Flickr portrait dataset and Multi-PIE dataset both qualitatively and quantitatively. Our experiments demonstrate that the proposed method achieves state-of-the-art results. Please refer to https://zhhoper.github.io/dpr.html for dataset and code.",60020304,University of Maryland,College Park,United States,"['1712', '1707']",17.3,0.1155952380952381,0.4873809523809524,1,0.17452830188679244,0.04716981132075472,0.4321608040201005
1720,1757,1757,Parametric majorization for data-driven energy minimization methods,"Energy minimization methods are a classical tool in a multitude of computer vision applications. While they are interpretable and well-studied, their regularity assumptions are difficult to design by hand. Deep learning techniques on the other hand are purely data-driven, often provide excellent results, but are very difficult to constrain to predefined physical or safety-critical models. A possible combination between the two approaches is to design a parametric energy and train the free parameters in such a way that minimizers of the energy correspond to desired solution on a set of training examples. Unfortunately, such formulations typically lead to bi-level optimization problems, on which common optimization algorithms are difficult to scale to modern requirements in data processing and efficiency. In this work, we present a new strategy to optimize these bi-level problems. We investigate surrogate single-level problems that majorize the target problems and can be implemented with existing tools, leading to efficient algorithms without collapse of the energy function. This framework of strategies enables new avenues to the training of parameterized energy minimization models from large data.",60024260,Universität Siegen,Siegen,Germany,"['1712', '1707']",22.0,0.002981601731601731,0.5427759740259741,1,0.10344827586206896,0.0,0.2931937172774869
1721,1758,1758,Incremental class discovery for semantic segmentation with rgbd sensing,"This work addresses the task of open world semantic segmentation using RGBD sensing to discover new semantic classes over time. Although there are many types of objects in the real-word, current semantic segmentation methods make a closed world assumption and are trained only to segment a limited number of object classes. Towards a more open world approach, we propose a novel method that incrementally learns new classes for image segmentation. The proposed system first segments each RGBD frame using both color and geometric information, and then aggregates that information to build a single segmented dense 3D map of the environment. The segmented 3D map representation is a key component of our approach as it is used to discover new object classes by identifying coherent regions in the 3D map that have no semantic label. The use of coherent region in the 3D map as a primitive element, rather than traditional elements such as surfels or voxels, also significantly reduces the computational complexity and memory use of our method. It thus leads to semi-real-time performance at 10.7 Hz when incrementally updating the dense 3D map at every frame. Through experiments on the NYUDv2 dataset, we demonstrate that the proposed method is able to correctly cluster objects of both known and unseen classes. We also show the quantitative comparison with the state-of-the-art supervised methods, the processing time of each step, and the influences of each component.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",26.0,0.16456168831168833,0.5352056277056276,1,0.09125475285171103,0.011406844106463879,0.2589641434262948
1722,1759,1759,SME-net: Sparse motion estimation for parametric video prediction through reinforcement learning,"This paper leverages a classic prediction technique, known as parametric overlapped block motion compensation (POBMC), in a reinforcement learning framework for video prediction. Learning-based prediction methods with explicit motion models often suffer from having to estimate large numbers of motion parameters with artificial regularization. Inspired by the success of sparse motion-based prediction for video compression, we propose a parametric video prediction on a sparse motion field composed of few critical pixels and their motion vectors. The prediction is achieved by gradually refining the estimate of a future frame in iterative, discrete steps. Along the way, the identification of critical pixels and their motion estimation are addressed by two neural networks trained under a reinforcement learning setting. Our model achieves the state-of-the-art performance on CaltchPed, UCF101 and CIF datasets in one-step and multi-step prediction tests. It shows good generalization results and is able to learn well on small training data.",60012370,National Chiao Tung University Taiwan,Hsinchu,Taiwan,"['1712', '1707']",21.285714285714285,0.07554112554112552,0.4586580086580087,1,0.10674157303370786,0.028089887640449437,0.2926829268292683
1723,1760,1760,Aspect sentiment classification based on sequence to sequence reinforced learning,"The task of aspect sentiment classification (ASC) is a fundamental task in sentiment analysis. Given an aspect and a sentence, the task classifies the sentiment polarity expressed on the target in the sentence. Previous work usually distinguish the sentiment based on one-way LSTM, which are often complicated and need more training time. In this paper, motivated by the BERT from Google AI Language, we propose a novel two-way encoder-decoder framework that automatically extracts appropriate sentiment information according to sequence to sequence reinforced learning. We use reinforcement learning to explore the space of possible extractive targets, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. The experiments on SemEval datasets demonstrate the efficiency and effectiveness of our models.",60005816,South China Normal University,Guangzhou,China,['1700'],20.666666666666668,0.0425925925925926,0.4351851851851852,1,0.13986013986013987,0.04895104895104895,0.29927007299270075
1724,1761,1761,Fast object detection in compressed video,"Object detection in videos has drawn increasing attention since it is more practical in real scenarios. Most of the deep learning methods use CNNs to process each decoded frame in a video stream individually. However, the free of charge yet valuable motion information already embedded in the video compression format is usually overlooked. In this paper, we propose a fast object detection method by taking advantage of this with a novel Motion aided Memory Network (MMNet). The MMNet has two major advantages: 1) It significantly accelerates the procedure of feature extraction for compressed videos. It only need to run a complete recognition network for I-frames, i.e. a few reference frames in a video, and it produces the features for the following P frames (predictive frames) with a light weight memory network, which runs fast; 2) Unlike existing methods that establish an additional network to model motion of frames, we take full advantage of both motion vectors and residual errors that are freely available in video streams. To our best knowledge, the MMNet is the first work that investigates a deep convolutional detector on compressed videos. Our method is evaluated on the large-scale ImageNet VID dataset, and the results show that it is 3x times faster than single image detector R-FCN and 10x times faster than high-performance detector MANet at a minor accuracy loss.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",24.777777777777782,0.1898291925465839,0.4531573498964804,1,0.10196078431372549,0.043137254901960784,0.33064516129032256
1725,1762,1762,Cluster alignment with a teacher for unsupervised domain adaptation,"Deep learning methods have shown promise in unsupervised domain adaptation, which aims to leverage a labeled source domain to learn a classifier for the unlabeled target domain with a different distribution. However, such methods typically learn a domain-invariant representation space to match the marginal distributions of the source and target domains, while ignoring their fine-level structures. In this paper, we propose Cluster Alignment with a Teacher (CAT) for unsupervised domain adaptation, which can effectively incorporate the discriminative clustering structures in both domains for better adaptation. Technically, CAT leverages an implicit ensembling teacher model to reliably discover the class-conditional structure in the feature space for the unlabeled target domain. Then CAT forces the features of both the source and the target domains to form discriminative class-conditional clusters and aligns the corresponding clusters across domains. Empirical results demonstrate that CAT achieves state-of-the-art results in several unsupervised domain adaptation scenarios.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",24.5,0.11481481481481486,0.3888888888888889,1,0.12,0.03428571428571429,0.3416149068322981
1726,1763,1763,Learning compositional representations for few-shot recognition,"One of the key limitations of modern deep learning approaches lies in the amount of data required to train them. Humans, by contrast, can learn to recognize novel categories from just a few examples. Instrumental to this rapid learning ability is the compositional structure of concept representations in the human brain - - something that deep learning models are lacking. In this work, we make a step towards bridging this gap between human and machine learning by introducing a simple regularization technique that allows the learned representation to be decomposable into parts. Our method uses category-level attribute annotations to disentangle the feature space of a network into subspaces corresponding to the attributes. These attributes can be either purely visual, like object parts, or more abstract, like openness and symmetry. We demonstrate the value of compositional representations on three datasets: CUB-200-2011, SUN397, and ImageNet, and show that they require fewer examples to learn classifiers for novel categories.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",22.285714285714285,0.05,0.3257142857142857,1,0.10734463276836158,0.011299435028248588,0.31213872832369943
1727,1764,1764,FSGAN: Subject agnostic face swapping and reenactment,"We present Face Swapping GAN (FSGAN) for face swapping and reenactment. Unlike previous work, FSGAN is subject agnostic and can be applied to pairs of faces without requiring training on those faces. To this end, we describe a number of technical contributions. We derive a novel recurrent neural network (RNN)-based approach for face reenactment which adjusts for both pose and expression variations and can be applied to a single image or a video sequence. For video sequences, we introduce continuous interpolation of the face views based on reenactment, Delaunay Triangulation, and barycentric coordinates. Occluded face regions are handled by a face completion network. Finally, we use a face blending network for seamless blending of the two faces while preserving target skin color and lighting conditions. This network uses a novel Poisson blending loss which combines Poisson optimization with perceptual loss. We compare our approach to existing state-of-the-art systems and show our results to be both qualitatively and quantitatively superior.",60022591,Open University of Israel,Tel Aviv-Yafo,Israel,"['1712', '1707']",17.666666666666668,0.049404761904761896,0.3517857142857143,1,0.12568306010928962,0.03825136612021858,0.3407821229050279
1728,1765,1765,Transferable representation learning in vision-and-language navigation,"Vision-and-Language Navigation (VLN) tasks such as Room-to-Room (R2R) require machine agents to interpret natural language instructions and learn to act in visually realistic environments to achieve navigation goals. The overall task requires competence in several perception problems: Successful agents combine spatio-temporal, vision and language understanding to produce appropriate action sequences. Our approach adapts pre-trained vision and language representations to relevant in-domain tasks making them more effective for VLN. Specifically, the representations are adapted to solve both a cross-modal sequence alignment and sequence coherence task. In the sequence alignment task, the model determines whether an instruction corresponds to a sequence of visual frames. In the sequence coherence task, the model determines whether the perceptual sequences are predictive sequentially in the instruction-conditioned latent space. By transferring the domain-adapted representations, we improve competitive agents in R2R as measured by the success rate weighted by path length (SPL) metric.",60006191,Google LLC,Mountain View,United States,"['1712', '1707']",20.714285714285715,0.26282051282051283,0.38333333333333336,1,0.125,0.03804347826086957,0.36585365853658536
1729,1766,1766,Visualization of convolutional neural networks for monocular depth estimation,"Recently, convolutional neural networks (CNNs) have shown great success on the task of monocular depth estimation. A fundamental yet unanswered question is: How CNNs can infer depth from a single image. Toward answering this question, we consider visualization of inference of a CNN by identifying relevant pixels of an input image to depth estimation. We formulate it as an optimization problem of identifying the smallest number of image pixels from which the CNN can estimate a depth map with the minimum difference from the estimate from the entire image. To cope with a difficulty with optimization through a deep CNN, we propose to use another network to predict those relevant image pixels in a forward computation. In our experiments, we first show the effectiveness of this approach, and then apply it to different depth estimation networks on indoor and outdoor scene datasets. The results provide several findings that help exploration of the above question.",60016648,Riken,Wako,Japan,"['1712', '1707']",22.0,0.1521978021978022,0.4055860805860805,1,0.10650887573964497,0.01775147928994083,0.23076923076923078
1730,1767,1767,Non-local intrinsic decomposition with near-infrared priors,"Intrinsic image decomposition is a highly under-constrained problem that has been extensively studied by computer vision researchers. Previous methods impose additional constraints by exploiting either empirical or data-driven priors. In this paper, we revisit intrinsic image decomposition with the aid of near-infrared (NIR) imagery. We show that NIR band is considerably less sensitive to textures and can be exploited to reduce ambiguity caused by reflectance variation, promoting a simple yet powerful prior for shading smoothness. With this observation, we formulate intrinsic decomposition as an energy minimisation problem. Unlike existing methods, our energy formulation decouples reflectance and shading estimation, into a convex local shading component based on NIR-RGB image pair, and a reflectance component that encourages reflectance homogeneity both locally and globally. We further show the minimisation process can be approached by a series of multi-dimensional kernel convolutions, each within linear time complexity. To validate the proposed algorithm, a NIR-RGB dataset is captured over real-world objects, where our NIR-assisted approach demonstrates clear superiority over RGB methods.",60029470,Commonwealth Scientific and Industrial Research Organization,Melbourne,Australia,"['1712', '1707']",20.625,0.04476190476190476,0.35336734693877553,1,0.14,0.04,0.33695652173913043
1731,1768,1768,Interpolated convolutional networks for 3D point cloud understanding,"Point cloud is an important type of 3D representation. However, directly applying convolutions on point clouds is challenging due to the sparse, irregular and unordered data structure. In this paper, we propose a novel Interpolated Convolution operation, InterpConv, to tackle the point cloud feature learning and understanding problem. The key idea is to utilize a set of discrete kernel weights and interpolate point features to neighboring kernel-weight coordinates by an interpolation function for convolution. A normalization term is introduced to handle neighborhoods of different sparsity levels. Our InterpConv is shown to be permutation and sparsity invariant, and can directly handle irregular inputs. We further design Interpolated Convolutional Neural Networks (InterpCNNs) based on InterpConv layers to handle point cloud recognition tasks including shape classification, object part segmentation and indoor scene semantic parsing. Experiments show that the networks can capture both fine-grained local structures and global shape context information effectively. The proposed approach achieves state-of-the-art performance on public benchmarks including ModelNet40, ShapeNet Parts and S3DIS.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",18.11111111111111,0.13125,0.5118055555555555,1,0.13020833333333334,0.0625,0.3516483516483517
1732,1769,1769,Gravity as a reference for estimating a person's height from video,"Estimating the metric height of a person from monocular imagery without additional assumptions is ill-posed. Existing solutions either require manual calibration of ground plane and camera geometry, special cameras, or reference objects of known size. We focus on motion cues and exploit gravity on earth as an omnipresent reference 'object' to translate acceleration, and subsequently height, measured in image-pixels to values in meters. We require videos of motion as input, where gravity is the only external force. This limitation is different to those of existing solutions that recover a person's height and, therefore, our method opens up new application fields. We show theoretically and empirically that a simple motion trajectory analysis suffices to translate from pixel measurements to the person's metric height, reaching a MAE of up to 3.9 cm on jumping motions, and that this works without camera and ground plane calibration.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",23.83333333333333,0.06594516594516595,0.3703463203463204,1,0.10843373493975904,0.006024096385542169,0.2981366459627329
1733,1770,1770,Research paper on bell curve method of performance management," The organizations that know how to recruit, deploy, develop and retain this most valued asset, will succeed in this world. Performance Management System is one such tool that plays a crucial role in assessing, developing and retaining of the employees. Todays’ organization need to think of Performance Appraisal System that assesses the performance of employees objectively, motivates them to perform better, allows them to develop required knowledge, skills and abilities and most importantly helps the organizations retain the high performers. This paper aims to study Bell Curve Method of Performance Appraisal which is widely used for this purpose, and any alternatives that can help the organizations assess its employees better, thereby helping them develop and retain the high performers.",124082136,PTVA’s Institute of Management,Mumbai,India,['1706'],30.0,0.2381818181818182,0.5527272727272727,0,0.21641791044776118,0.08208955223880597,0.3533834586466165
1734,1771,1771,Uncertainty-aware audiovisual activity recognition using deep bayesian variational inference,"Deep neural networks (DNNs) provide state-of-the-art results for a multitude of applications, but the approaches using DNNs for multimodal audiovisual applications do not consider predictive uncertainty associated with individual modalities. Bayesian deep learning methods provide principled confidence and quantify predictive uncertainty. Our contribution in this work is to propose an uncertainty aware multimodal Bayesian fusion framework for activity recognition. We demonstrate a novel approach that combines deterministic and variational layers to scale Bayesian DNNs to deeper architectures. Our experiments using in- and out-of-distribution samples selected from a subset of Moments-in-Time (MiT) dataset show a more reliable confidence measure as compared to the non-Bayesian baseline and the Monte Carlo dropout (MC dropout) approximate Bayesian inference. We also demonstrate the uncertainty estimates obtained from the proposed framework can identify out-of-distribution data on the UCF101 and MiT datasets. In the multimodal setting, the proposed framework improved precision-recall AUC by 10.2% on the subset of MiT dataset as compared to non-Bayesian baseline.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",22.57142857142857,0.05833333333333333,0.425,1,0.12121212121212122,0.050505050505050504,0.42528735632183906
1735,1772,1772,A comprehensive overhaul of feature distillation,"We investigate the design aspects of feature distillation methods achieving network compression and propose a novel feature distillation method in which the distillation loss is designed to make a synergy among various aspects: Teacher transform, student transform, distillation feature position and distance function. Our proposed distillation loss includes a feature transform with a newly designed margin ReLU, a new distillation feature position, and a partial L2 distance function to skip redundant information giving adverse effects to the compression of student. In ImageNet, our proposed method achieves 21.65% of top-1 error with ResNet50, which outperforms the performance of the teacher network, ResNet152. Our proposed method is evaluated on various tasks such as image classification, object detection and semantic segmentation and achieves a significant performance improvement in all tasks. The code is available at project page.",60121134,NAVER Corporation,Seongnam,South Korea,"['1712', '1707']",26.8,0.08308080808080807,0.4648989898989899,1,0.11409395973154363,0.013422818791946308,0.2751677852348993
1736,1773,1773,What else can fool deep learning? addressing color constancy errors on deep neural network performance,"There is active research targeting local image manipulations that can fool deep neural networks (DNNs) into producing incorrect results. This paper examines a type of global image manipulation that can produce similar adverse effects. Specifically, we explore how strong color casts caused by incorrectly applied computational color constancy - referred to as white balance (WB) in photography - negatively impact the performance of DNNs targeting image segmentation and classification. In addition, we discuss how existing image augmentation methods used to improve the robustness of DNNs are not well suited for modeling WB errors. To address this problem, a novel augmentation method is proposed that can emulate accurate color constancy degradation. We also explore pre-processing training and testing images with a recent WB correction algorithm to reduce the effects of incorrectly white-balanced images. We examine both augmentation and pre-processing strategies on different datasets and demonstrate notable improvements on the CIFAR-10, CIFAR-100, and ADE20K datasets.",60033420,York University,Toronto,Canada,"['1712', '1707']",21.857142857142854,0.075,0.3763888888888889,1,0.14772727272727273,0.03977272727272727,0.3431952662721893
1737,1774,1774,Event-based motion segmentation by motion compensation,"In contrast to traditional cameras, whose pixels have a common exposure time, event-based cameras are novel bio-inspired sensors whose pixels work independently and asynchronously output intensity changes (called 'events'), with microsecond resolution. Since events are caused by the apparent motion of objects, event-based cameras sample visual information based on the scene dynamics and are, therefore, a more natural fit than traditional cameras to acquire motion, especially at high speeds, where traditional cameras suffer from motion blur. However, distinguishing between events caused by different moving objects and by the camera's ego-motion is a challenging task. We present the first per-event segmentation method for splitting a scene into independently moving objects. Our method jointly estimates the event-object associations (i.e., segmentation) and the motion parameters of the objects (or the background) by maximization of an objective function, which builds upon recent results on event-based motion-compensation. We provide a thorough evaluation of our method on a public dataset, outperforming the state-of-the-art by as much as 10%. We also show the first quantitative evaluation of a segmentation algorithm for event cameras, yielding around 90% accuracy at 4 pixels relative displacement.",60108693,Australian Centre for Robotic Vision,Brisbane,Australia,"['1712', '1707']",26.42857142857143,0.10318181818181818,0.3878787878787879,1,0.09243697478991597,0.004201680672268907,0.3767441860465116
1738,1775,1775,Drive&act: A multi-modal dataset for fine-grained driver behavior recognition in autonomous vehicles,"We introduce the novel domain-specific Drive&Act benchmark for fine-grained categorization of driver behavior. Our dataset features twelve hours and over 9.6 million frames of people engaged in distractive activities during both, manual and automated driving. We capture color, infrared, depth and 3D body pose information from six views and densely label the videos with a hierarchical annotation scheme, resulting in 83 categories. The key challenges of our dataset are: (1) recognition of fine-grained behavior inside the vehicle cabin; (2) multi-modal activity recognition, focusing on diverse data streams; and (3) a cross view recognition benchmark, where a model handles data from an unfamiliar domain, as sensor type and placement in the cabin can change between vehicles. Finally, we provide challenging benchmarks by adopting prominent methods for video- and body pose-based action recognition.",60102538,Karlsruhe Institute of Technology,Karlsruhe,Germany,"['1712', '1707']",26.2,0.05,0.7285714285714285,1,0.1165644171779141,0.018404907975460124,0.4
1739,1776,1776,Sym-parameterized dynamic inference for mixed-domain image translation,"Recent advances in image-to-image translation have led to some ways to generate multiple domain images through a single network. However, there is still a limit in creating an image of a target domain without a dataset on it. We propose a method to expand the concept of 'multi-domain' from data to the loss area, and to combine the characteristics of each domain to create an image. First, we introduce a sym-parameter and its learning method that can mix various losses and can synchronize them with input conditions. Then, we propose Sym-parameterized Generative Network (SGN) using it. Through experiments, we confirmed that SGN could mix the characteristics of various data and losses, and it is possible to translate images to any mixed-domain without ground truths, such as 30% Van Gogh and 20% Monet and 40% snowy.",60013682,Seoul National University,Seoul,South Korea,"['1712', '1707']",22.5,0.0642857142857143,0.4775132275132275,1,0.11377245508982035,0.04790419161676647,0.33766233766233766
1740,1777,1777,SCHONA: A scholar persona system based on academic social network,"Recently, social network including academic social network has developed rapidly. It is a challenge to utilize massive academic data including academic social network data and academic achievement data to analyze and mine scholars’ important information such as behavioral characteristics and research interests. In this paper, we present a scholar persona system SCHONA which is composed of two parts, data collection and scholar labels generation. It collects three types of data first and finally generates the labels which can accurately represent scholars by extensively using big data analysis methods such as Word2Vec, K-means and TextRank.",60005816,South China Normal University,Guangzhou,China,['1700'],23.5,0.06944444444444446,0.3277777777777778,1,0.11428571428571428,0.0380952380952381,0.32038834951456313
1741,1778,1778,Probabilistic face embeddings,"Embedding methods have achieved success in face recognition by comparing facial features in a latent semantic space. However, in a fully unconstrained face setting, the facial features learned by the embedding model could be ambiguous or may not even be present in the input face, leading to noisy representations. We propose Probabilistic Face Embeddings (PFEs), which represent each face image as a Gaussian distribution in the latent space. The mean of the distribution estimates the most likely feature values while the variance shows the uncertainty in the feature values. Probabilistic solutions can then be naturally derived for matching and fusing PFEs using the uncertainty information. Empirical evaluation on different baseline models, training datasets and benchmarks show that the proposed method can improve the face recognition performance of deterministic embeddings by converting them into PFEs. The uncertainties estimated by PFEs also serve as good indicators of the potential matching accuracy, which are important for a risk-controlled recognition system.",60031707,Michigan State University,East Lansing,United States,"['1712', '1707']",22.428571428571423,0.1375,0.4528846153846154,1,0.14942528735632185,0.011494252873563218,0.29651162790697677
1742,1779,1779,Asymmetric cross-guided attention network for actor and action video segmentation from natural language query,"Actor and action video segmentation from natural language query aims to selectively segment the actor and its action in a video based on an input textual description. Previous works mostly focus on learning simple correlation between two heterogeneous features of vision and language via dynamic convolution or fully convolutional classification. However, they ignore the linguistic variation of natural language query and have difficulty in modeling global visual context, which leads to unsatisfactory segmentation performance. To address these issues, we propose an asymmetric cross-guided attention network for actor and action video segmentation from natural language query. Specifically, we frame an asymmetric cross-guided attention network, which consists of vision guided language attention to reduce the linguistic variation of input query and language guided vision attention to incorporate query-focused global visual context simultaneously. Moreover, we adopt multi-resolution fusion scheme and weighted loss for foreground and background pixels to obtain further performance improvement. Extensive experiments on Actor-Action Dataset Sentences and J-HMDB Sentences show that our proposed approach notably outperforms state-of-the-art methods.",60114181,Tencent,Shenzhen,China,"['1712', '1707']",23.857142857142854,0.08596491228070176,0.2223057644110276,1,0.12626262626262627,0.030303030303030304,0.23333333333333334
1743,1780,1780,Approximated bilinear modules for temporal modeling,"We consider two less-emphasized temporal properties of video: 1. Temporal cues are fine-grained; 2. Temporal modeling needs reasoning. To tackle both problems at once, we exploit approximated bilinear modules (ABMs) for temporal modeling. There are two main points making the modules effective: Two-layer MLPs can be seen as a constraint approximation of bilinear operations, thus can be used to construct deep ABMs in existing CNNs while reusing pretrained parameters; frame features can be divided into static and dynamic parts because of visual repetition in adjacent frames, which enables temporal modeling to be more efficient. Multiple ABM variants and implementations are investigated, from high performance to high efficiency. Specifically, we show how two-layer subnets in CNNs can be converted to temporal bilinear modules by adding an auxiliary-branch. Besides, we introduce snippet sampling and shifting inference to boost sparse-frame video classification performance. Extensive ablation studies are conducted to show the effectiveness of proposed techniques. Our models can outperform most state-of-the-art methods on Something-Something v1 and v2 datasets without Kinetics pretraining, and are also competitive on other YouTube-like action recognition datasets. Our code is available on https://github.com/zhuxinqimac/abm-pytorch.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",16.727272727272727,0.1974444444444444,0.3925555555555555,1,0.1391304347826087,0.013043478260869565,0.41904761904761906
1744,1781,1781,Fingerspelling recognition in the wild with iterative visual attention,"Sign language recognition is a challenging gesture sequence recognition problem, characterized by quick and highly coarticulated motion. In this paper we focus on recognition of fingerspelling sequences in American Sign Language (ASL) videos collected in the wild, mainly from YouTube and Deaf social media. Most previous work on sign language recognition has focused on controlled settings where the data is recorded in a studio environment and the number of signers is limited. Our work aims to address the challenges of real-life data, reducing the need for detection or segmentation modules commonly used in this domain. We propose an end-to-end model based on an iterative attention mechanism, without explicit hand detection or segmentation. Our approach dynamically focuses on increasingly high-resolution regions of interest. It out-performs prior work by a large margin. We also introduce a newly collected data set of crowdsourced annotations of fingerspelling in the wild, and show that performance can be further improved with this additional data set.",60074721,Toyota Technological Institute at Chicago,Chicago,United States,"['1712', '1707']",19.875,0.10661796536796536,0.37079004329004334,1,0.11413043478260869,0.03260869565217391,0.3045977011494253
1745,1782,1782,Deeppruner: Learning efficient stereo matching via differentiable patchmatch,"Our goal is to significantly speed up the runtime of current state-of-the-art stereo algorithms to enable real-time inference. Towards this goal, we developed a differentiable PatchMatch module that allows us to discard most disparities without requiring full cost volume evaluation. We then exploit this representation to learn which range to prune for each pixel. By progressively reducing the search space and effectively propagating such information, we are able to efficiently compute the cost volume for high likelihood hypotheses and achieve savings in both memory and computation.Finally, an image guided refinement module is exploited to further improve the performance. Since all our components are differentiable, the full network can be trained end-to-end. Our experiments show that our method achieves competitive results on KITTI and SceneFlow datasets while running in real-time at 62ms.",60022195,Massachusetts Institute of Technology,Cambridge,United States,"['1712', '1707']",21.83333333333333,0.26681818181818184,0.5581818181818181,1,0.1337579617834395,0.01910828025477707,0.2907801418439716
1746,1783,1783,Self-similarity grouping: A simple unsupervised cross domain adaptation approach for person re-identification,"Domain adaptation in person re-identification (re-ID) has always been a challenging task. In this work, we explore how to harness the similar natural characteristics existing in the samples from the target domain for learning to conduct person re-ID in an unsupervised manner. Concretely, we propose a Self-similarity Grouping (SSG) approach, which exploits the potential similarity (from the global body to local parts) of unlabeled samples to build multiple clusters from different views automatically. These independent clusters are then assigned with labels, which serve as the pseudo identities to supervise the training process. We repeatedly and alternatively conduct such a grouping and training process until the model is stable. Despite the apparent simplify, our SSG outperforms the state-of-the-arts by more than 4.6% (DukeMTMC→Market1501) and 4.4% (Market1501→DukeMTMC) in mAP, respectively. Upon our SSG, we further introduce a clustering-guided semisupervised approach named SSG ++ to conduct the one-shot domain adaption in an open set setting (i.e. the number of independent identities from the target domain is unknown). Without spending much effort on labeling, our SSG ++ can further promote the mAP upon SSG by 10.7% and 6.9%, respectively. Our Code is available at: Https://github.com/OasisYang/SSG.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",19.1,0.0818181818181818,0.37272727272727263,1,0.0975609756097561,0.04065040650406504,0.4017467248908297
1747,1784,1784,An early warning system of tram safety protection based on multi-information detection,"Aiming at the existing collision accidents with motor vehicles and pedestrians in the operation of tram, a tram safety protection early warning system is proposed, which can automatically analyze and interpret dangerous objects in the direction of moving forward. The system uses ranging sensor (Ultrasonic, Camera, Ranging radar) and infrared video information to obtain the accurate distance between the obstacle and the locomotive. The obstacle type and potential running speed can be obtained by infrared image recognition and classification. According to the direction of the tram, the distance, type and speed of the obstacles, the safety level of the obstacles can be determined. The above analysis and interpretation results are displayed intuitively on the on-board display and reminder unit. Relevant technologies can effectively improve the ability of the tram driver to obtain information, automatically detect obstacles and judge the degree of danger, and improve the safety of the tram.",60016541,Shanghai Polytechnic University,Pudong District,China,['1700'],24.83333333333333,0.075,0.4633333333333334,1,0.14285714285714285,0.023809523809523808,0.22289156626506024
1748,1785,1785,SC-RBAC: A smart contract based RBAC model for DApps,"Blockchain technology with its non-centralized, transparent, trustful, traceable and tamper-resistant features draws more and more attention both in commercial and scientific area. Smart contracts and DApps (Decentralized Applications) are programs naturally running automatically on blockchain. Access control is a principle that regulates the access to critical resources. RBAC (Role based Access Control) is one of access control mechanisms and it involves three parts: user, role and permission, with their relations, corresponding to real business. However, traditional implementation of RBAC relies on centralized server which is in danger of being modified, invaded or a single point of failure. The paper proposes a decentralized and smart contract based RBAC model named SC-RBAC for DApps. It is developed by Ethereum’s Solidity and offers a strong compatibility with different DApps. The features of SC-RBAC associated with flexible interfaces, traceability and security enrich the community of DApps. The results of two experiments are discussed to evaluate the overheads of SC-RBAC model.",60082507,Beijing Wuzi University,Beijing,China,['1700'],17.333333333333332,0.1315873015873016,0.4455555555555555,1,0.08947368421052632,0.11578947368421053,0.4088397790055249
1749,1786,1786,Information entropy based feature pooling for convolutional neural networks,"In convolutional neural networks (CNNs), we propose to estimate the importance of a feature vector at a spatial location in the feature maps by the network's uncertainty on its class prediction, which can be quantified using the information entropy. Based on this idea, we propose the entropy-based feature weighting method for semantics-aware feature pooling which can be readily integrated into various CNN architectures for both training and inference. We demonstrate that such a location-adaptive feature weighting mechanism helps the network to concentrate on semantically important image regions, leading to improvements in the large-scale classification and weakly-supervised semantic segmentation tasks. Furthermore, the generated feature weights can be utilized in visual tasks such as weakly-supervised object localization. We conduct extensive experiments on different datasets and CNN architectures, outperforming recently proposed pooling methods and attention mechanisms in ImageNet classification as well as achieving state-of-the-arts in weakly-supervised semantic segmentation on PASCAL VOC 2012 dataset.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",30.0,0.06666666666666668,0.4648148148148149,1,0.13043478260869565,0.03260869565217391,0.3597560975609756
1750,1787,1787,Adaptive reconstruction network for weakly supervised referring expression grounding,"Weakly supervised referring expression grounding aims at localizing the referential object in an image according to the linguistic query, where the mapping between the referential object and query is unknown in the training stage. To address this problem, we propose a novel end-to-end adaptive reconstruction network (ARN). It builds the correspondence between image region proposal and query in an adaptive manner: Adaptive grounding and collaborative reconstruction. Specifically, we first extract the subject, location and context features to represent the proposals and the query respectively. Then, we design the adaptive grounding module to compute the matching score between each proposal and query by a hierarchical attention model. Finally, based on attention score and proposal features, we reconstruct the input query with a collaborative loss of language reconstruction loss, adaptive reconstruction loss, and attribute classification loss. This adaptive mechanism helps our model to alleviate the variance of different referring expressions. Experiments on four large-scale datasets show ARN outperforms existing state-of-the-art methods by a large margin. Qualitative results demonstrate that the proposed ARN can better handle the situation where multiple objects of a particular category situated together.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.444444444444443,0.049107142857142856,0.41279761904761897,1,0.1152073732718894,0.013824884792626729,0.2731707317073171
1751,1788,1788,Deep meta functionals for shape representation,"We present a new method for 3D shape reconstruction from a single image, in which a deep neural network directly maps an image to a vector of network weights. The network parametrized by these weights represents a 3D shape by classifying every point in the volume as either within or outside the shape. The new representation has virtually unlimited capacity and resolution, and can have an arbitrary topology. Our experiments show that it leads to more accurate shape inference from a 2D projection than the existing methods, including voxel-, silhouette-, and mesh-based methods. The code will be available at: Https: //github.com/gidilittwin/Deep-Meta.",60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,"['1712', '1707']",20.2,0.1364817001180638,0.3733372687918143,1,0.09917355371900827,0.04132231404958678,0.30973451327433627
1752,1789,1789,Different performances of speech and natural gait in identifying anxiety and depression,"Recognition of individual’s emotions using the data of speech and natural gait has been proved effective by previous studies. This study establishes a supervised regression model based on individual’s speech and natural gait data to predict the scores of depression and anxiety. The results show that the performance of the predictive model based on gait features is better than that of speech features. The basic processes are as follows: First, we recruited 88 participants and collected their speech data and natural gait data in laboratory; Second, we required each participant to finish the anxiety and depression scales (PHQ-9, CES-D, T-AI, and GAD-7), to get the anxiety and depression scores as the tagging data for modeling; Third, we extracted 6125 features from each participant’s speech data and 1602 features from the gait data; Finally, we used a variety of machine learning algorithms to train and test the predictive models. The results show that the max Pearson Correlation Coefficient between the predicted scores and the questionnaire scores of the speech-based model is 0.43, and the max Pearson Correlation Coefficient of the gait-based model is 0.73, which is much better than the speech-based model.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],38.2,0.14166666666666666,0.3875000000000001,1,0.10222222222222223,0.057777777777777775,0.3440366972477064
1753,1790,1790,ForkNet: Multi-branch volumetric semantic completion from a single depth image,"We propose a novel model for 3D semantic completion from a single depth image, based on a single encoder and three separate generators used to reconstruct different geometric and semantic representations of the original and completed scene, all sharing the same latent space. To transfer information between the geometric and semantic branches of the network, we introduce paths between them concatenating features at corresponding network layers. Motivated by the limited amount of training samples from real scenes, an interesting attribute of our architecture is the capacity to supplement the existing dataset by generating a new training dataset with high quality, realistic scenes that even includes occlusion and real noise. We build the new dataset by sampling the features directly from latent space which generates a pair of partial volumetric surface and completed volumetric semantic surface. Moreover, we utilize multiple discriminators to increase the accuracy and realism of the reconstructions. We demonstrate the benefits of our approach on standard benchmarks for the two most common completion tasks: Semantic 3D scene completion and 3D object completion.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",29.0,0.09790043290043288,0.3488869902027797,1,0.12299465240641712,0.0,0.2620320855614973
1754,1791,1791,Layout-induced video representation for recognizing agent-in-place actions,"We address scene layout modeling for recognizing agent-in-place actions, which are actions associated with textit{agents} who perform them and the textit{places} where they occur, in the context of outdoor home surveillance. We introduce a novel representation to model the geometry and topology of scene layouts so that a network can generalize from the layouts observed in the training scenes to unseen scenes in the test set. This Layout-Induced Video Representation (LIVR) abstracts away low-level appearance variance and encodes geometric and topological relationships of places to explicitly model scene layout. LIVR partitions the semantic features of a scene into different places to force the network to learn generic place-based feature descriptions which are independent of specific scene layouts; then, LIVR dynamically aggregates features based on connectivities of places in each specific scene to model its layout. We introduce a new Agent-in-Place Action (APA) datasetfootnote{The dataset is pending legal review and will be released upon the acceptance of this paper.} to show that our method allows neural network models to generalize significantly better to unseen scenes.",60025919,Comcast,Philadelphia,United States,"['1712', '1707']",34.8,0.10404040404040404,0.2477272727272727,1,0.13658536585365855,0.04390243902439024,0.3401015228426396
1755,1792,1792,Occlusion-aware networks for 3D human pose estimation in video,"Occlusion is a key problem in 3D human pose estimation from a monocular video. To address this problem, we introduce an occlusion-aware deep-learning framework. By employing estimated 2D confidence heatmaps of keypoints and an optical-flow consistency constraint, we filter out the unreliable estimations of occluded keypoints. When occlusion occurs, we have incomplete 2D keypoints and feed them to our 2D and 3D temporal convolutional networks (2D and 3D TCNs) that enforce temporal smoothness to produce a complete 3D pose. By using incomplete 2D keypoints, instead of complete but incorrect ones, our networks are less affected by the error-prone estimations of occluded keypoints. Training the occlusion-aware 3D TCN requires pairs of a 3D pose and a 2D pose with occlusion labels. As no such a dataset is available, we introduce a ''Cylinder Man Model'' to approximate the occupation of body parts in 3D space. By projecting the model onto a 2D plane in different viewing angles, we obtain and label the occluded keypoints, providing us plenty of training data. In addition, we use this model to create a pose regularization constraint, preferring the 2D estimations of unreliable keypoints to be occluded. Our method outperforms state-of-the-art methods on Human 3.6M and HumanEva-I datasets.",60106365,Yale NUS College,Singapore City,Singapore,"['1712', '1707']",20.1,0.0033333333333333327,0.4166666666666666,1,0.13008130081300814,0.024390243902439025,0.4222222222222222
1756,1793,1793,HistoSegNet: Semantic segmentation of histological tissue type in whole slide images,"In digital pathology, tissue slides are scanned into Whole Slide Images (WSI) and pathologists first screen for diagnostically-relevant Regions of Interest (ROIs) before reviewing them. Screening for ROIs is a tedious and time-consuming visual recognition task which can be exhausting. The cognitive workload could be reduced by developing a visual aid to narrow down the visual search area by highlighting (or segmenting) regions of diagnostic relevance, enabling pathologists to spend more time diagnosing relevant ROIs. In this paper, we propose HistoSegNet, a method for semantic segmentation of histological tissue type (HTT). Using the HTT-annotated Atlas of Digital Pathology (ADP) database, we train a Convolutional Neural Network on the patch annotations, infer Gradient-Weighted Class Activation Maps, average overlapping predictions, and post-process the segmentation with a fully-connected Conditional Random Field. Our method out-performs more complicated weakly-supervised semantic segmentation methods and can generalize to other datasets without retraining.",60016849,University of Toronto,Toronto,Canada,"['1712', '1707']",24.16666666666667,-0.037808641975308636,0.39429012345679015,1,0.13513513513513514,0.10270270270270271,0.46745562130177515
1757,1794,1794,Onion-peel networks for deep video completion,"We propose the onion-peel networks for video completion. Given a set of reference images and a target image with holes, our network fills the hole by referring the contents in the reference images. Our onion-peel network progressively fills the hole from the hole boundary enabling it to exploit richer contextual information for the missing regions every step. Given a sufficient number of recurrences, even a large hole can be inpainted successfully. To attend to the missing information visible in the reference images, we propose an asymmetric attention block that computes similarities between the hole boundary pixels in the target and the non-hole pixels in the references in a non-local manner. With our attention block, our network can have an unlimited spatial-temporal window size and fill the holes with globally coherent contents. In addition, our framework is applicable to the image completion guided by the reference images without any modification, which is difficult to do with the previous methods. We validate that our method produces visually pleasing image and video inpainting results in realistic test cases.",60016912,Yonsei University,Seoul,South Korea,"['1712', '1707']",21.875,0.0626984126984127,0.4087301587301587,1,0.10552763819095477,0.0,0.2804232804232804
1758,1795,1795,Spectral regularization for combating mode collapse in GANs,"Despite excellent progress in recent years, mode collapse remains a major unsolved problem in generative adversarial networks (GANs). In this paper, we present spectral regularization for GANs (SR-GANs), a new and robust method for combating the mode collapse problem in GANs. Theoretical analysis shows that the optimal solution to the discriminator has a strong relationship to the spectral distributions of the weight matrix. Therefore, we monitor the spectral distribution in the discriminator of spectral normalized GANs (SN-GANs), and discover a phenomenon which we refer to as spectral collapse, where a large number of singular values of the weight matrices drop dramatically when mode collapse occurs. We show that there are strong evidence linking mode collapse to spectral collapse; and based on this link, we set out to tackle spectral collapse as a surrogate of mode collapse. We have developed a spectral regularization method where we compensate the spectral distributions of the weight matrices to prevent them from collapsing, which in turn successfully prevents mode collapse in GANs. We provide theoretical explanations for why SR-GANs are more stable and can provide better performances than SN-GANs. We also present extensive experimental results and analysis to show that SR-GANs not only always outperform SN-GANs but also always succeed in combating mode collapse where SN-GANs fail.",60000937,Shenzhen University,Shenzhen,China,"['1712', '1707']",26.5,0.1963061061745272,0.451742993848257,1,0.10441767068273092,0.04819277108433735,0.25957446808510637
1759,1796,1796,Ego-pose estimation and forecasting as real-time PD control,"We propose the use of a proportional-derivative (PD) control based policy learned via reinforcement learning (RL) to estimate and forecast 3D human pose from egocentric videos. The method learns directly from unsegmented egocentric videos and motion capture data consisting of various complex human motions (e.g., crouching, hopping, bending, and motion transitions). We propose a video-conditioned recurrent control technique to forecast physically-valid and stable future motions of arbitrary length. We also introduce a value function based fail-safe mechanism which enables our method to run as a single pass algorithm over the video data. Experiments with both controlled and in-the-wild data show that our approach outperforms previous art in both quantitative metrics and visual quality of the motions, and is also robust enough to transfer directly to real-world scenarios. Additionally, our time analysis shows that the combined use of our pose estimation and forecasting can run at 30 FPS, making it suitable for real-time applications.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",25.5,0.008608058608058612,0.32738095238095244,1,0.11702127659574468,0.010638297872340425,0.3023255813953488
1760,1797,1797,Small steps and giant leaps: Minimal newton solvers for deep learning,"We propose a fast second-order method that can be used as a drop-in replacement for current deep learning solvers. Compared to stochastic gradient descent (SGD), it only requires two additional forward-mode automatic differentiation operations per iteration, which has a computational cost comparable to two standard forward passes and is easy to implement. Our method addresses long-standing issues with current second-order solvers, which invert an approximate Hessian matrix every iteration exactly or by conjugate-gradient methods, procedures that are much slower than a SGD step. Instead, we propose to keep a single estimate of the gradient projected by the inverse Hessian matrix, and update it once per iteration with just two passes over the network. This estimate has the same size and is similar to the momentum variable that is commonly used in {SGD}. No estimate of the Hessian is maintained. We first validate our method, called CurveBall, on small problems with known solutions (noisy Rosenbrock function and degenerate 2-layer linear networks), where current deep learning solvers struggle. We then train several large models on CIFAR and ImageNet, including ResNet and VGG-f networks, where we demonstrate faster convergence with no hyperparameter tuning. We also show our optimiser's generality by testing on a large set of randomly generated architectures.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",22.88888888888889,0.010930735930735931,0.40059523809523817,1,0.10931174089068826,0.048582995951417005,0.33476394849785407
1761,1798,1798,GAN-based projector for faster recovery with convergence guarantees in linear inverse problems,"A Generative Adversarial Network (GAN) with generator G trained to model the prior of images has been shown to perform better than sparsity-based regularizers in ill-posed inverse problems. Here, we propose a new method of deploying a GAN-based prior to solve linear inverse problems using projected gradient descent (PGD). Our method learns a network-based projector for use in the PGD algorithm, eliminating expensive computation of the Jacobian of G. Experiments show that our approach provides a speed-up of 60-80x over earlier GAN-based recovery methods along with better accuracy in compressed sensing. Our main theoretical result is that if the measurement matrix is moderately conditioned on the manifold range(G) and the projector is delta-approximate, then the algorithm is guaranteed to reach O(delta) reconstruction error in O(log(1/delta)) steps in the low noise regime. Additionally, we propose a fast method to design such measurement matrices for a given G. Extensive experiments demonstrate the efficacy of this method by requiring 5-10x fewer measurements than random Gaussian measurement matrices for comparable recovery performance. Because the learning of the GAN and projector is decoupled from the measurement operator, our GAN-based projector and recovery algorithm are applicable without retraining to all linear inverse problems in which the measurement operator is moderately conditioned for range(G), as confirmed by experiments on compressed sensing, super-resolution, and inpainting.",60000745,University of Illinois at Urbana-Champaign,Urbana,United States,"['1712', '1707']",27.125,0.05311942959001782,0.4541889483065954,1,0.13257575757575757,0.07954545454545454,0.328
1762,1799,1799,Linearized multi-sampling for differentiable image transformation,"We propose a novel image sampling method for differentiable image transformation in deep neural networks. The sampling schemes currently used in deep learning, such as Spatial Transformer Networks, rely on bilinear interpolation, which performs poorly under severe scale changes, and more importantly, results in poor gradient propagation. This is due to their strict reliance on direct neighbors. Instead, we propose to generate random auxiliary samples in the vicinity of each pixel in the sampled image, and create a linear approximation with their intensity values. We then use this approximation as a differentiable formula for the transformed image. We demonstrate that our approach produces more representative gradients with a wider basin of convergence for image alignment, which leads to considerable performance improvements when training networks for registration and classification tasks. This is not only true under large downsampling, but also when there are no scale changes. We compare our approach with multi-scale sampling and show that we outperform it. We then demonstrate that our improvements to the sampler are compatible with other tangential improvements to Spatial Transformer Networks and that it further improves their performance.",60003122,University of Victoria,Victoria,Canada,"['1712', '1707']",20.444444444444443,0.034126984126984124,0.5321428571428571,1,0.09313725490196079,0.024509803921568627,0.27722772277227725
1763,1800,1800,Semantics-enhanced adversarial nets for text-to-image synthesis,"This paper presents a new model, Semantics-enhanced Generative Adversarial Network (SEGAN), for fine-grained text-to-image generation. We introduce two modules, a Semantic Consistency Module (SCM) and an Attention Competition Module (ACM), to our SEGAN. The SCM incorporates image-level semantic consistency into the training of the Generative Adversarial Network (GAN), and can diversify the generated images and improve their structural coherence. A Siamese network and two types of semantic similarities are designed to map the synthesized image and the groundtruth image to nearby points in the latent semantic feature space. The ACM constructs adaptive attention weights to differentiate keywords from unimportant words, and improves the stability and accuracy of SEGAN. Extensive experiments demonstrate that our SEGAN significantly outperforms existing state-of-the-art methods in generating photo-realistic images. All source codes and models will be released for comparative study.",60007566,Louisiana State University,Baton Rouge,United States,"['1712', '1707']",19.142857142857142,0.027840909090909083,0.6532196969696971,1,0.12138728323699421,0.1329479768786127,0.4838709677419355
1764,1802,1802,Aggregation via separation: Boosting facial landmark detector with semi-supervised style translation,"Facial landmark detection, or face alignment, is a fundamental task that has been extensively studied. In this paper, we investigate a new perspective of facial landmark detection and demonstrate it leads to further notable improvement. Given that any face images can be factored into space of style that captures lighting, texture and image environment, and a style-invariant structure space, our key idea is to leverage disentangled style and shape space of each individual to augment existing structures via style translation. With these augmented synthetic samples, our semi-supervised model surprisingly outperforms the fully-supervised one by a large margin. Extensive experiments verify the effectiveness of our idea with state-of-the-art results on WFLW, 300W, COFW, and AFLW datasets. Our proposed structure is general and could be assembled into any face alignment frameworks. The code is made publicly available at https://github.com/thesouthfrog/stylealign.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",19.571428571428573,0.1538961038961039,0.4115218115218115,1,0.12048192771084337,0.024096385542168676,0.32051282051282054
1765,1803,1803,Quality of work life of educators in Lebanese French university," This research study highlights the quality of work life of educators under various dimensions. New Challenges can be faced with educator’s nature of job role, work environment, Career Growth and Development, General Well- Being in achieving organizational goals. This study helps the educators to know the level of perception towards QWL and to enhance the same by the educational administrators. Quality of Work Life is the essential concept of favorable situations in a working environment. The Quality of Work Life facilitates employee’s training opportunities, job satisfaction and working conditions. A better Quality of Work Life improves the growth of the employee’s along with the organization growth. The universe of the study includes 4 colleges educators located within the Lebanese French university campus, i.e., college of engineering and sciences, college of education and languages, college of law and international relations and college of administration and economics. A sample of 50 respondents was collected from the universe. The collected data after being coded were analyzed using Statistical Package for Social sciences Research (SPSS) and various statistical tests were applied based on hypotheses and matching variables. It shows Quality of Work Life of Lebanese French University educators is in high level..",60121882,Lebanese French University,Erbil,Iraq,['1706'],19.9,0.08689976689976689,0.2874009324009324,0,0.0945945945945946,0.11261261261261261,0.3794642857142857
1766,1804,1804,Diversity with cooperation: Ensemble methods for few-shot classification,"Few-shot classification consists of learning a predictive model that is able to effectively adapt to a new class, given only a few annotated samples. To solve this challenging problem, meta-learning has become a popular paradigm that advocates the ability to ''learn to adapt''. Recent works have shown, however, that simple learning strategies without meta-learning could be competitive. In this paper, we go a step further and show that by addressing the fundamental high-variance issue of few-shot learning classifiers, it is possible to significantly outperform current meta-learning techniques. Our approach consists of designing an ensemble of deep networks to leverage the variance of the classifiers, and introducing new strategies to encourage the networks to cooperate, while encouraging prediction diversity. Evaluation is conducted on the mini-ImageNet, tiered-ImageNet and CUB datasets, where we show that even a single network obtained by distillation yields state-of-the-art results.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,"['1712', '1707']",23.66666666666667,0.1610186688311688,0.5831574675324676,1,0.15217391304347827,0.016304347826086956,0.34375
1767,1805,1805,Deep comprehensive correlation mining for image clustering,"Recent developed deep unsupervised methods allow us to jointly learn representation and cluster unlabelled data. These deep clustering methods %like DAC start with mainly focus on the correlation among samples, e.g., selecting high precision pairs to gradually tune the feature representation, which neglects other useful correlations. In this paper, we propose a novel clustering framework, named deep comprehensive correlation mining∼(DCCM), for exploring and taking full advantage of various kinds of correlations behind the unlabeled data from three aspects: 1) Instead of only using pair-wise information, pseudo-label supervision is proposed to investigate category information and learn discriminative features. 2) The features' robustness to image transformation of input space is fully explored, which benefits the network learning and significantly improves the performance. 3) The triplet mutual information among features is presented for clustering problem to lift the recently discovered instance-level deep mutual information to a triplet-level formation, which further helps to learn more discriminative features. Extensive experiments on several challenging datasets show that our method achieves good performance, e.g., attaining 62.3% clustering accuracy on CIFAR-10, which is 10.1% higher than the state-of-the-art results.",60031031,Shandong University,Jinan,China,"['1712', '1707']",30.16666666666667,0.12507246376811593,0.4655072463768116,1,0.14414414414414414,0.018018018018018018,0.3761904761904762
1768,1806,1806,Context-aware image matting for simultaneous foreground and alpha estimation,"Natural image matting is an important problem in computer vision and graphics. It is an ill-posed problem when only an input image is available without any external information. While the recent deep learning approaches have shown promising results, they only estimate the alpha matte. This paper presents a context-aware natural image matting method for simultaneous foreground and alpha matte estimation. Our method employs two encoder networks to extract essential information for matting. Particularly, we use a matting encoder to learn local features and a context encoder to obtain more global context information. We concatenate the outputs from these two encoders and feed them into decoder networks to simultaneously estimate the foreground and alpha matte. To train this whole deep neural network, we employ both the standard Laplacian loss and the feature loss: The former helps to achieve high numerical performance while the latter leads to more perceptually plausible results. We also report several data augmentation strategies that greatly improve the network's generalization performance. Our qualitative and quantitative experiments show that our method enables high-quality matting for a single natural image.",60023908,Portland State University,Portland,United States,"['1712', '1707']",18.0,0.1501940035273369,0.3810229276895944,1,0.11442786069651742,0.0,0.24102564102564103
1769,1807,1807,"VideoMem: Constructing, analyzing, predicting short-term and long-term video memorability","Humans share a strong tendency to memorize/forget some of the visual information they encounter. This paper focuses on understanding the intrinsic memorability of visual content. To address this challenge, we introduce a large scale dataset (VideoMem) composed of 10,000 videos with memorability scores. In contrast to previous work on image memorability - where memorability was measured a few minutes after memorization - memory performance is measured twice: A few minutes and again 24-72 hours after memorization. Hence, the dataset comes with short-term and long-term memorability annotations. After an in-depth analysis of the dataset, we investigate various deep neural network-based models for the prediction of video memorability. Our best model using a ranking loss achieves a Spearman's rank correlation of 0.494 (respectively 0.256) for short-term (resp. long-term) memorability prediction, while our model with attention mechanism provides insights of what makes a content memorable. The VideoMem dataset with pre-extracted features is publicly available.",123796187,InterDigital,Rennes,France,"['1712', '1707']",16.77777777777778,0.08435374149659862,0.3663265306122449,1,0.09473684210526316,0.015789473684210527,0.37209302325581395
1770,1808,1808,Situational fusion of visual representation for visual navigation,"A complex visual navigation task puts an agent in different situations which call for a diverse range of visual perception abilities. For example, to 'go to the nearest chair'', the agent might need to identify a chair in a living room using semantics, follow along a hallway using vanishing point cues, and avoid obstacles using depth. Therefore, utilizing the appropriate visual perception abilities based on a situational understanding of the visual environment can empower these navigation models in unseen visual environments. We propose to train an agent to fuse a large set of visual representations that correspond to diverse visual perception abilities. To fully utilize each representation, we develop an action-level representation fusion scheme, which predicts an action candidate from each representation and adaptively consolidate these action candidates into the final action. Furthermore, we employ a data-driven inter-task affinity regularization to reduce redundancies and improve generalization. Our approach leads to a significantly improved performance in novel environments over ImageNet-pretrained baseline and other fusion methods.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",23.42857142857143,0.05079365079365079,0.2488095238095238,1,0.1631578947368421,0.005263157894736842,0.26666666666666666
1771,1809,1809,Towards bridging semantic gap to improve semantic segmentation,"Aggregating multi-level features is essential for capturing multi-scale context information for precise scene semantic segmentation. However, the improvement by directly fusing shallow features and deep features becomes limited as the semantic gap between them increases. To solve this problem, we explore two strategies for robust feature fusion. One is enhancing shallow features using a semantic enhancement module (SeEM) to alleviate the semantic gap between shallow features and deep features. The other strategy is feature attention, which involves discovering complementary information (i.e., boundary information) from low-level features to enhance high-level features for precise segmentation. By embedding these two strategies, we construct a parallel feature pyramid towards improving multi-level feature fusion. A Semantic Enhanced Network called SeENet is constructed with the parallel pyramid to implement precise segmentation. Experiments on three benchmark datasets demonstrate the effectiveness of our method for robust multi-level feature aggregation. As a result, our SeENet has achieved better performance than other state-of-the-art methods for semantic segmentation.",60019533,Tianjin University,Tianjin,China,"['1712', '1707']",17.444444444444443,0.029910714285714287,0.4245535714285714,1,0.10824742268041238,0.020618556701030927,0.36363636363636365
1772,1810,1810,Order-aware generative modeling using the 3D-craft dataset,"In this paper, we study the problem of sequentially building houses in the game of Minecraft, and demonstrate that learning the ordering can make for more effective autoregressive models. Given a partially built house made by a human player, our system tries to place additional blocks in a human-like manner to complete the house. We introduce a new dataset, HouseCraft, for this new task. HouseCraft contains the sequential order in which 2,500 Minecraft houses were built from scratch by humans. The human action sequences enable us to learn an order-aware generative model called Voxel-CNN. In contrast to many generative models where the sequential generation ordering either does not matter (e.g. holistic generation with GANs), or is manually/arbitrarily set by simple rules (e.g. raster-scan order), our focus is on an ordered generation that imitates humans. To evaluate if a generative model can accurately predict human-like actions, we propose several novel quantitative metrics. We demonstrate that our Voxel-CNN model is simple and effective at this creative task, and can serve as a strong baseline for future research in this direction. The HouseCraft dataset and code with baseline models will be made publicly available.",60111190,Facebook Research,Menlo Park,United States,"['1712', '1707']",17.363636363636363,0.18124098124098126,0.4245258709544424,1,0.13656387665198239,0.039647577092511016,0.31627906976744186
1773,1811,1811,Pix2pose: Pixel-wise coordinate regression of objects for 6D pose estimation,"Estimating the 6D pose of objects using only RGB images remains challenging because of problems such as occlusion and symmetries. It is also difficult to construct 3D models with precise texture without expert knowledge or specialized scanning devices. To address these problems, we propose a novel pose estimation method, Pix2Pose, that predicts the 3D coordinates of each object pixel without textured models. An auto-encoder architecture is designed to estimate the 3D coordinates and expected errors per pixel. These pixel-wise predictions are then used in multiple stages to form 2D-3D correspondences to directly compute poses with the PnP algorithm with RANSAC iterations. Our method is robust to occlusion by leveraging recent achievements in generative adversarial training to precisely recover occluded parts. Furthermore, a novel loss function, the transformer loss, is proposed to handle symmetric objects by guiding predictions to the closest symmetric pose. Evaluations on three different benchmark datasets containing symmetric and occluded objects show our method outperforms the state of the art using only RGB images.",60018163,Technische Universitat Wien,Vienna,Austria,"['1712', '1707']",20.75,0.06666666666666668,0.6458333333333334,1,0.125,0.010869565217391304,0.4166666666666667
1774,1812,1812,Speech-based automatic recognition technology for major depression disorder,"Depression is one of the common mental illnesses nowadays. It can greatly harm the physical and mental health of patients and cause huge losses to individuals, families and society. Because of the lack of hardware and social prejudice against depression, there are a large number of misdiagnosis and missed diagnosis in hospitals. It is necessary to find an objective and efficient way to help the identification of depression. Previous studies have demonstrated the potential value of speech in this area. The model based on speech can distinguish patients from normal people to a great extent. On this basis, we hope to further predict the severity of depression through speech. In this paper, a total of 240 subjects were recruited to participate in the experiment. Their depression scores were measured using the PHQ9 scale, and their corresponding speech data were recorded under the self-introduction situation. Then, the effective voice features were extracted and the PCA was conducted for feature dimensionality reduction. Finally, utilizing several classical machine learning method, the depression degree classification models were constructed. This study is an attempt of the interdisciplinary study of psychology and computer science. It is hoped that it will provide new ideas for the related work of mental health monitoring.",60082192,Guangdong Power Grid Corporation,Guangzhou,China,['1700'],15.769230769230768,0.10292678336156597,0.4764916243177113,1,0.10087719298245613,0.008771929824561403,0.26991150442477874
1775,1813,1813,Deep SR-ITM: Joint learning of super-resolution and inverse tone-mapping for 4K UHD HDR applications,"Recent modern displays are now able to render high dynamic range (HDR), high resolution (HR) videos of up to 8K UHD (Ultra High Definition). Consequently, UHD HDR broadcasting and streaming have emerged as high quality premium services. However, due to the lack of original UHD HDR video content, appropriate conversion technologies are urgently needed to transform the legacy low resolution (LR) standard dynamic range (SDR) videos into UHD HDR versions. In this paper, we propose a joint super-resolution (SR) and inverse tone-mapping (ITM) framework, called Deep SR-ITM, which learns the direct mapping from LR SDR video to their HR HDR version. Joint SR and ITM is an intricate task, where high frequency details must be restored for SR, jointly with the local contrast, for ITM. Our network is able to restore fine details by decomposing the input image and focusing on the separate base (low frequency) and detail (high frequency) layers. Moreover, the proposed modulation blocks apply location-variant operations to enhance local contrast. The Deep SR-ITM shows good subjective quality with increased contrast and details, outperforming the previous joint SR-ITM method.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1707']",22.625,0.11703703703703705,0.4098148148148148,1,0.08189655172413793,0.11637931034482758,0.4703196347031963
1776,1814,1814,Fast point R-CNN,"We present a unified, efficient and effective framework for point-cloud based 3D object detection. Our two-stage approach utilizes both voxel representation and raw point cloud data to exploit respective advantages. The first stage network, with voxel representation as input, only consists of light convolutional operations, producing a small number of high-quality initial predictions. Coordinate and indexed convolutional feature of each point in initial prediction are effectively fused with the attention mechanism, preserving both accurate localization and context information. The second stage works on interior points with their fused feature for further refining the prediction. Our method is evaluated on KITTI dataset, in terms of both 3D and Bird's Eye View (BEV) detection, and achieves state-of-the-arts with a 15FPS detection rate.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",20.0,0.1263736263736264,0.4091575091575092,1,0.10810810810810811,0.04054054054054054,0.3382352941176471
1777,1815,1815,SpaceNet MVOI: A multi-view overhead imagery dataset,"Detection and segmentation of objects in overheard imagery is a challenging task. The variable density, random orientation, small size, and instance-to-instance heterogeneity of objects in overhead imagery calls for approaches distinct from existing models designed for natural scene datasets. Though new overhead imagery datasets are being developed, they almost universally comprise a single view taken from directly overhead ('at nadir'), failing to address a critical variable: Look angle. By contrast, views vary in real-world overhead imagery, particularly in dynamic scenarios such as natural disasters where first looks are often over 40 degrees off-nadir. This represents an important challenge to computer vision methods, as changing view angle adds distortions, alters resolution, and changes lighting. At present, the impact of these perturbations for algorithmic detection and segmentation of objects is untested. To address this problem, we present an open source Multi-View Overhead Imagery dataset, termed SpaceNet MVOI, with 27 unique looks from a broad range of viewing angles (-32.5 degrees to 54.0 degrees). Each of these images cover the same 665 square km geographic extent and are annotated with 126,747 building footprint labels, enabling direct assessment of the impact of viewpoint perturbation on model performance. We benchmark multiple leading segmentation and object detection models on: (1) building detection, (2) generalization to unseen viewing angles and resolutions, and (3) sensitivity of building footprint extraction to changes in resolution. We find that state of the art segmentation and object detection models struggle to identify buildings in off-nadir imagery and generalize poorly to unseen views, presenting an important benchmark to explore the broadly relevant challenge of detecting small, heterogeneous target objects in visually dynamic contexts.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",27.0,0.036747835497835515,0.4524332611832612,1,0.09846153846153846,0.018461538461538463,0.391025641025641
1778,1816,1816,"No-frills human-object interaction detection: Factorization, layout encodings, and training techniques","We show that for human-object interaction detection a relatively simple factorized model with appearance and layout encodings constructed from pre-trained object detectors outperforms more sophisticated approaches. Our model includes factors for detection scores, human and object appearance, and coarse (box-pair configuration) and optionally fine-grained layout (human pose). We also develop training techniques that improve learning efficiency by: (1) eliminating a train-inference mismatch; (2) rejecting easy negatives during mini-batch training; and (3) using a ratio of negatives to positives that is two orders of magnitude larger than existing approaches. We conduct a thorough ablation study to understand the importance of different factors and training techniques using the challenging HICO-Det dataset.",60000745,University of Illinois at Urbana-Champaign,Urbana,United States,"['1712', '1707']",27.25,0.10757575757575756,0.59004329004329,1,0.1056338028169014,0.014084507042253521,0.453125
1779,1817,1817,Unsupervised robust disentangling of latent characteristics for image synthesis,"Deep generative models come with the promise to learn an explainable representation for visual objects that allows image sampling, synthesis, and selective modification. The main challenge is to learn to properly model the independent latent characteristics of an object, especially its appearance and pose. We present a novel approach that learns disentangled representations of these characteristics and explains them individually. Training requires only pairs of images depicting the same object appearance, but no pose annotations. We propose an additional classifier that estimates the minimal amount of regularization required to enforce disentanglement. Thus both representations together can completely explain an image while being independent of each other. Previous methods based on adversarial approaches fail to enforce this independence, while methods based on variational approaches lead to uninformative representations. In experiments on diverse object categories, the approach successfully recombines pose and appearance to reconstruct and retarget novel synthesized images. We achieve significant improvements over state-of-the-art methods which utilize the same level of supervision, and reach performances comparable to those of pose-supervised approaches. However, we can handle the vast body of articulated object classes for which no pose models/annotations are available.",60016908,Universität Heidelberg,Heidelberg,Germany,"['1712', '1707']",18.8,0.042857142857142864,0.4190476190476191,1,0.14814814814814814,0.0,0.3106796116504854
1780,1818,1818,Self-training with progressive augmentation for unsupervised cross-domain person re-identification,"Person re-identification (Re-ID) has achieved great improvement with deep learning and a large amount of labelled training data. However, it remains a challenging task for adapting a model trained in a source domain of labelled data to a target domain of only unlabelled data available. In this work, we develop a self-training method with progressive augmentation framework (PAST) to promote the model performance progressively on the target dataset. Specially, our PAST framework consists of two stages, namely, conservative stage and promoting stage. The conservative stage captures the local structure of target-domain data points with triplet-based loss functions, leading to improved feature representations. The promoting stage continuously optimizes the network by appending a changeable classification layer to the last layer of the model, enabling the use of global information about the data distribution. Importantly, we propose a new self-training strategy that progressively augments the model capability by adopting conservative and promoting stages alternately. Furthermore, to improve the reliability of selected triplet samples, we introduce a ranking-based triplet loss in the conservative stage, which is a label-free objective function based on the similarities between data pairs. Experiments demonstrate that the proposed method achieves state-of-the-art person Re-ID performance under the unsupervised cross-domain setting. Code is available at: Tinyurl.com/PASTReID.",60073652,Tongji University,Shanghai,China,"['1712', '1707']",20.5,0.1592818945760122,0.4159536541889482,1,0.12062256809338522,0.01556420233463035,0.3333333333333333
1781,1819,1819,"Adversarial robustness vs. model compression, or both?","It is well known that deep neural networks (DNNs) are vulnerable to adversarial attacks, which are implemented by adding crafted perturbations onto benign examples. Min-max robust optimization based adversarial training can provide a notion of security against adversarial attacks. However, adversarial robustness requires a significantly larger capacity of the network than that for the natural training with only benign examples. This paper proposes a framework of concurrent adversarial training and weight pruning that enables model compression while still preserving the adversarial robustness and essentially tackles the dilemma of adversarial training. Furthermore, this work studies two hypotheses about weight pruning in the conventional setting and finds that weight pruning is essential for reducing the network model size in the adversarial setting; training a small model from scratch even with inherited initialization from the large model cannot achieve neither adversarial robustness nor high standard accuracy. Code is available at https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",24.66666666666667,-0.0014285714285714286,0.42505494505494507,1,0.1165644171779141,0.012269938650306749,0.3067484662576687
1782,1820,1820,Flare in interference-based hyperspectral cameras,"Stray light (flare) is formed inside cameras by internal reflections between optical elements. We point out a flare effect of significant magnitude and implication to snapshot hyperspectral imagers. Recent technologies enable placing interference-based filters on individual pixels in imaging sensors. These filters have narrow transmission bands around custom wavelengths and high transmission efficiency. Cameras using arrays of such filters are compact, robust and fast. However, as opposed to traditional broad-band filters, which often absorb unwanted light, narrow band-pass interference filters reflect non-transmitted light. This is a source of very significant flare which biases hyperspectral measurements. The bias in any pixel depends on spectral content in other pixels. We present a theoretical image formation model for this effect, and quantify it through simulations and experiments. In addition, we test deflaring of signals affected by such flare.",60022403,Technion - Israel Institute of Technology,Haifa,Israel,"['1712', '1707']",13.5,0.10541666666666666,0.4883333333333334,1,0.09937888198757763,0.012422360248447204,0.39215686274509803
1783,1821,1821,Surface normals and shape from water,"In this paper, we introduce a novel method for reconstructing surface normals and depth of dynamic objects in water. Past shape recovery methods have leveraged various visual cues for estimating shape (e.g., depth) or surface normals. Methods that estimate both compute one from the other. We show that these two geometric surface properties can be simultaneously recovered for each pixel when the object is observed underwater. Our key idea is to leverage multi-wavelength near-infrared light absorption along different underwater light paths in conjunction with surface shading. We derive a principled theory for this surface normals and shape from water method and a practical calibration method for determining its imaging parameters values. By construction, the method can be implemented as a one-shot imaging system. We prototype both an off-line and a video-rate imaging system and demonstrate the effectiveness of the method on a number of real-world static and dynamic objects. The results show that the method can recover intricate surface features that are otherwise inaccessible.",60011001,Kyoto University,Kyoto,Japan,"['1712', '1707']",18.222222222222218,0.08409090909090909,0.4871212121212121,1,0.11578947368421053,0.0,0.30337078651685395
1784,1822,1822,EvalNorm: Estimating batch normalization statistics for evaluation,"Batch normalization (BN) has been very effective for deep learning and is widely used. However, when training with small minibatches, models using BN exhibit a significant degradation in performance. In this paper we study this peculiar behavior of BN to gain a better understanding of the problem, and identify a cause. We propose 'EvalNorm' to address the issue by estimating corrected normalization statistics to use for BN during evaluation. EvalNorm supports online estimation of the corrected statistics while the model is being trained, and does not affect the training scheme of the model. As a result, EvalNorm can also be used with existing pre-trained models allowing them to benefit from our method. EvalNorm yields large gains for models trained with smaller batches. Our experiments show that EvalNorm performs 6.18% (absolute) better than vanilla BN for a batchsize of 2 on ImageNet validation set and from 1.5 to 7.0 points (absolute) gain on the COCO object detection benchmark across a variety of setups.",60020304,University of Maryland,College Park,United States,"['1712', '1707']",20.25,0.21993506493506496,0.6185064935064936,1,0.13978494623655913,0.043010752688172046,0.33879781420765026
1785,1823,1823,Fooling network interpretation in image classification,"Deep neural networks have been shown to be fooled rather easily using adversarial attack algorithms. Practical methods such as adversarial patches have been shown to be extremely effective in causing misclassification. However, these patches are highlighted using standard network interpretation algorithms, thus revealing the identity of the adversary. We show that it is possible to create adversarial patches which not only fool the prediction, but also change what we interpret regarding the cause of the prediction. Moreover, we introduce our attack as a controlled setting to measure the accuracy of interpretation algorithms. We show this using extensive experiments for Grad-CAM interpretation that transfers to occluding patch interpretation as well. We believe our algorithms can facilitate developing more robust network interpretation tools that truly explain the network's underlying decision making process.",60024997,"University of Maryland, Baltimore County",Baltimore,United States,"['1712', '1707']",18.571428571428573,0.17037037037037034,0.5962962962962962,1,0.19444444444444445,0.013888888888888888,0.3028169014084507
1786,1824,1824,Floorplan-jigsaw: Jointly estimating scene layout and aligning partial scans,"We present a novel approach to align partial 3D reconstructions which may not have substantial overlap. Using floorplan priors, our method jointly predicts a room layout and estimates the transformations from a set of partial 3D data. Unlike the existing methods relying on feature descriptors to establish correspondences, we exploit the 3D 'box' structure of a typical room layout that meets the Manhattan World property. We first estimate a local layout for each partial scan separately and then combine these local layouts to form a globally aligned layout with loop closure. Without the requirement of feature matching, the proposed method enables some novel applications ranging from large or featureless scene reconstruction and modeling from sparse input. We validate our method quantitatively and qualitatively on real and synthetic scenes of various sizes and complexities. The evaluations and comparisons show superior effectiveness and accuracy of our method.",60006541,The University of Hong Kong,Pokfulam,Hong Kong,"['1712', '1707']",20.714285714285715,0.06904761904761904,0.2970695970695971,1,0.1337579617834395,0.012738853503184714,0.27564102564102566
1787,1825,1825,Analysis and management of risk related to using cloud computing in business: Employee’s perception,"With the recent advancement of the technology and its application to our daily business and social life; precisely the cloud computing system, however it has a risks that might lead to hesitation and lose of enthusiasm of using it. The main objective of this research is to find the risk factors, which may affect the business performance of the companies that use “Cloud Computing”, and understand the consequences and its managements. To the best of my knowledge, this is the first study in Iraq on risk analysis and managements in cloud computing. The objectives achieved by distributing a questionnaire to 30 private companies in Iraq which are using cloud computing to risk managements by interviewed the employees who were responsible on managing “Cloud Computing” in their companies. That leads to recognize the potentials risk, and how much impact we might make to take the right decision in order to manage the risk to help using “Cloud Computing” without fears.",60064180,The University of Jordan,Amman,Jordan,['1706'],31.8,0.21130952380952386,0.3203373015873016,1,0.14204545454545456,0.045454545454545456,0.29545454545454547
1788,1826,1826,Balanced datasets are not enough: Estimating and mitigating gender bias in deep image representations,"In this work, we present a framework to measure and mitigate intrinsic biases with respect to protected variables -such as gender- in visual recognition tasks. We show that trained models significantly amplify the association of target labels with gender beyond what one would expect from biased datasets. Surprisingly, we show that even when datasets are balanced such that each label co-occurs equally with each gender, learned models amplify the association between labels and gender, as much as if data had not been balanced! To mitigate this, we adopt an adversarial approach to remove unwanted features corresponding to protected variables from intermediate representations in a deep neural network - and provide a detailed analysis of its effectiveness. Experiments on two datasets: The COCO dataset (objects), and the imSitu dataset (actions), show reductions in gender bias amplification while maintaining most of the accuracy of the original models.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",36.25,0.21666666666666667,0.4354166666666666,1,0.1402439024390244,0.024390243902439025,0.32098765432098764
1789,1827,1827,Employing deep part-object relationships for salient object detection,"Despite Convolutional Neural Networks (CNNs) based methods have been successful in detecting salient objects, their underlying mechanism that decides the salient intensity of each image part separately cannot avoid inconsistency of parts within the same salient object. This would ultimately result in an incomplete shape of the detected salient object. To solve this problem, we dig into part-object relationships and take the unprecedented attempt to employ these relationships endowed by the Capsule Network (CapsNet) for salient object detection. The entire salient object detection system is built directly on a Two-Stream Part-Object Assignment Network (TSPOANet) consisting of three algorithmic steps. In the first step, the learned deep feature maps of the input image are transformed to a group of primary capsules. In the second step, we feed the primary capsules into two identical streams, within each of which low-level capsules (parts) will be assigned to their familiar high-level capsules (object) via a locally connected routing. In the final step, the two streams are integrated in the form of a fully connected layer, where the relevant parts can be clustered together to form a complete salient object. Experimental results demonstrate the superiority of the proposed salient object detection network over the state-of-the-art methods.",60025578,Xidian University,Xi'an,China,"['1712', '1707']",25.125,0.20441176470588235,0.5254901960784314,1,0.102880658436214,0.04526748971193416,0.32158590308370044
1790,1828,1828,Modelling mental states via computational psychophysiology: Benefits and challenges,"The human psychophysiological processes are complex phenomenon built upon the physical scaffolding of the body. Machine learning approaches facilitate the understanding of numerous physiological processes underlying complex human mental states and behavior, leading to a new research direction named Computational Psychophysiology. Computational Psychophysiology aims to reveal the psychophysiological processes underlying complex human emotion and mental states from a computational perspective, and can be used to predict affective and psychological outcomes based on different physiological features or experimental manipulations. In this paper, we discuss the benefits and challenges in the future of bringing computing technologies into decoding human mental states.",60117749,"College of Biomedical Engineering &amp; Instrument Science, Zhejiang University",Hangzhou,China,['1700'],24.75,-0.05668449197860963,0.2660236822001528,1,0.14150943396226415,0.03773584905660377,0.29245283018867924
1791,1829,1829,Unsupervised collaborative learning of keyframe detection and visual odometry towards monocular deep SLAM,"In this paper we tackle the joint learning problem of keyframe detection and visual odometry towards monocular visual SLAM systems. As an important task in visual SLAM, keyframe selection helps efficient camera relocalization and effective augmentation of visual odometry. To benefit from it, we first present a deep network design for the keyframe selection, which is able to reliably detect keyframes and localize new frames, then an end-to-end unsupervised deep framework further proposed for simultaneously learning the keyframe selection and the visual odometry tasks. As far as we know, it is the first work to jointly optimize these two complementary tasks in a single deep framework. To make the two tasks facilitate each other in the learning, a collaborative optimization loss based on both geometric and visual metrics is proposed. Extensive experiments on publicly available datasets (ie∼KITTI raw dataset and its odometry split) clearly demonstrate the effectiveness of the proposed approach, and new state-of-the-art results are established on the unsupervised depth and pose estimation from monocular videos.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",27.83333333333333,0.0978211788211788,0.35472993672993675,1,0.09895833333333333,0.005208333333333333,0.24175824175824176
1792,1830,1830,DMM-Net: Differentiable mask-matching network for video object segmentation,"In this paper, we propose the differentiable mask-matching network (DMM-Net) for solving the video object segmentation problem where the initial object masks are provided. Relying on the Mask R-CNN backbone, we extract mask proposals per frame and formulate the matching between object templates and proposals as a linear assignment problem where thA heading inside a blocke cost matrix is predicted by a deep convolutional neural network. We propose a differentiable matching layer which unrolls a projected gradient descent algorithm in which the projection step exploits the Dykstra's algorithm. We prove that under mild conditions, the matching is guaranteed to converge to the optimal one. In practice, it achieves similar performance compared to the Hungarian algorithm during inference. Meanwhile, we can back-propagate through it to learn the cost matrix. After matching, a U-Net style architecture is exploited to refine the matched mask per time step. On DAVIS 2017 dataset, DMM-Net achieves the best performance without online learning on the first frames and the 2nd best with it. Without any fine-tuning, DMM-Net performs comparably to state-of-the-art methods on SegTrack v2 dataset. At last, our differentiable matching layer is very simple to implement; we attach the PyTorch code in the supplementary material which is less than 50 lines long.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",20.6,0.19722222222222224,0.2692460317460318,1,0.11952191235059761,0.055776892430278883,0.3318777292576419
1793,1831,1831,"3D scene graph: A structure for unified semantics, 3D space, and camera","A comprehensive semantic understanding of a scene is important for many applications - but in what space should diverse semantic information (e.g., objects, scene categories, material types, 3D shapes, etc.) be grounded and what should be its structure? Aspiring to have one unified structure that hosts diverse types of semantics, we follow the Scene Graph paradigm in 3D, generating a 3D Scene Graph. Given a 3D mesh and registered panoramic images, we construct a graph that spans the entire building and includes semantics on objects (e.g., class, material, shape and other attributes), rooms (e.g., function, illumination type, etc.) and cameras (e.g., location, etc.), as well as the relationships among these entities. However, this process is prohibitively labor heavy if done manually. To alleviate this we devise a semi-automatic framework that employs existing detection methods and enhances them using two main constraints: I. framing of query images sampled on panoramas to maximize the performance of 2D detectors, and II. multi-view consistency enforcement across 2D detections that originate in different camera locations.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",28.33333333333333,0.10595238095238094,0.5619047619047619,1,0.10849056603773585,0.03773584905660377,0.4423076923076923
1794,1832,1832,PRECOG: Prediction conditioned on goals in visual multi-agent settings,"For autonomous vehicles (AVs) to behave appropriately on roads populated by human-driven vehicles, they must be able to reason about the uncertain intentions and decisions of other drivers from rich perceptual information. Towards these capabilities, we present a probabilistic forecasting model of future interactions between a variable number of agents. We perform both standard forecasting and the novel task of conditional forecasting, which reasons about how all agents will likely respond to the goal of a controlled agent (here, the AV). We train models on real and simulated data to forecast vehicle trajectories given past positions and LIDAR. Our evaluation shows that our model is substantially more accurate in multi-agent driving scenarios compared to existing state-of-the-art. Beyond its general ability to perform conditional forecasting queries, we show that our model's predictions of all agents improve when conditioned on knowledge of the AV's goal, further illustrating its capability to model agent interactions.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",25.16666666666667,0.16999999999999996,0.4505555555555556,1,0.12849162011173185,0.0,0.33136094674556216
1795,1833,1833,Exploring overall contextual information for image captioning in human-like cognitive style,"Image captioning is a research hotspot where encoder-decoder models combining convolutional neural network (CNN) and long short-term memory (LSTM) achieve promising results. Despite significant progress, these models generate sentences differently from human cognitive styles. Existing models often generate a complete sentence from the first word to the end, without considering the influence of the following words on the whole sentence generation. In this paper, we explore the utilization of a human-like cognitive style, i.e., building overall cognition for the image to be described and the sentence to be constructed, for enhancing computer image understanding. This paper first proposes a Mutual-aid network structure with Bidirectional LSTMs (MaBi-LSTMs) for acquiring overall contextual information. In the training process, the forward and backward LSTMs encode the succeeding and preceding words into their respective hidden states by simultaneously constructing the whole sentence in a complementary manner. In the captioning process, the LSTM implicitly utilizes the subsequent semantic information contained in its hidden states. In fact, MaBi-LSTMs can generate two sentences in forward and backward directions. To bridge the gap between cross-domain models and generate a sentence with higher quality, we further develop a cross-modal attention mechanism to retouch the two sentences by fusing their salient parts as well as the salient areas of the image. Experimental results on the Microsoft COCO dataset show that the proposed model improves the performance of encoder-decoder models and achieves state-of-the-art results.",60004538,Dalian University of Technology,Dalian,China,"['1712', '1707']",23.2,0.07708333333333332,0.33291666666666664,1,0.11347517730496454,0.03900709219858156,0.3488372093023256
1796,1834,1834,Predicting the future: A jointly learnt model for action anticipation,"Inspired by human neurological structures for action anticipation, we present an action anticipation model that enables the prediction of plausible future actions by forecasting both the visual and temporal future. In contrast to current state-of-the-art methods which first learn a model to predict future video features and then perform action anticipation using these features, the proposed framework jointly learns to perform the two tasks, future visual and temporal representation synthesis, and early action anticipation. The joint learning framework ensures that the predicted future embeddings are informative to the action anticipation task. Furthermore, through extensive experimental evaluations we demonstrate the utility of using both visual and temporal semantics of the scene, and illustrate how this representation synthesis could be achieved through a recurrent Generative Adversarial Network (GAN) framework. Our model outperforms the current state-of-the-art methods on multiple datasets: UCF101, UCF101-24, UT-Interaction and TV Human Interaction.",60011019,Queensland University of Technology QUT,Brisbane,Australia,"['1712', '1707']",28.8,0.060416666666666674,0.16631944444444444,1,0.10795454545454546,0.0625,0.31875
1797,1835,1835,Dynamic points agglomeration for hierarchical point sets learning,"Many previous works on point sets learning achieve excellent performance with hierarchical architecture. Their strategies towards points agglomeration, however, only perform points sampling and grouping in original Euclidean space in a fixed way. These heuristic and task-irrelevant strategies severely limit their ability to adapt to more varied scenarios. To this end, we develop a novel hierarchical point sets learning architecture, with dynamic points agglomeration. By exploiting the relation of points in semantic space, a module based on graph convolution network is designed to learn a soft points cluster agglomeration. We construct a hierarchical architecture that gradually agglomerates points by stacking this learnable and lightweight module. In contrast to fixed points agglomeration strategy, our method can handle more diverse situations robustly and efficiently. Moreover, we propose a parameter sharing scheme for reducing memory usage and computational burden induced by the agglomeration module. Extensive experimental results on several point cloud analytic tasks, including classification and segmentation, well demonstrate the superior performance of our dynamic hierarchical learning framework over current state-of-the-art methods.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",18.777777777777782,0.22401960784313726,0.4431372549019609,1,0.1282051282051282,0.0,0.26737967914438504
1798,1836,1836,Budget-aware adapters for multi-domain learning,"Multi-Domain Learning (MDL) refers to the problem of learning a set of models derived from a common deep architecture, each one specialized to perform a task in a certain domain (e.g., photos, sketches, paintings). This paper tackles MDL with a particular interest in obtaining domain-specific models with an adjustable budget in terms of the number of network parameters and computational complexity. Our intuition is that, as in real applications the number of domains and tasks can be very large, an effective MDL approach should not only focus on accuracy but also on having as few parameters as possible. To implement this idea we derive specialized deep models for each domain by adapting a pre-trained architecture but, differently from other methods, we propose a novel strategy to automatically adjust the computational complexity of the network. To this aim, we introduce Budget-Aware Adapters that select the most relevant feature channels to better handle data from a novel domain. Some constraints on the number of active switches are imposed in order to obtain a network respecting the desired complexity budget. Experimentally, we show that our approach leads to recognition accuracy competitive with state-of-the-art approaches but with much lighter networks both in terms of storage and computation.",60083112,Fondazione Bruno Kessler,Trento,Italy,"['1712', '1707']",29.0,0.12637844611528826,0.5282581453634085,1,0.1092436974789916,0.03361344537815126,0.2857142857142857
1799,1837,1837,Learning an event sequence embedding for dense event-based deep stereo,"Today, a frame-based camera is the sensor of choice for machine vision applications. However, these cameras, originally developed for acquisition of static images rather than for sensing of dynamic uncontrolled visual environments, suffer from high power consumption, data rate, latency and low dynamic range. An event-based image sensor addresses these drawbacks by mimicking a biological retina. Instead of measuring the intensity of every pixel in a fixed time-interval, it reports events of significant pixel intensity changes. Every such event is represented by its position, sign of change, and timestamp, accurate to the microsecond. Asynchronous event sequences require special handling, since traditional algorithms work only with synchronous, spatially gridded data. To address this problem we introduce a new module for event sequence embedding, for use in difference applications. The module builds a representation of an event sequence by firstly aggregating information locally across time, using a novel fully-connected layer for an irregularly sampled continuous domain, and then across discrete spatial domain. Based on this module, we design a deep learning-based stereo method for event-based cameras. The proposed method is the first learning-based stereo method for an event-based camera and the only method that produces dense results. We show that large performance increases on the Multi Vehicle Stereo Event Camera Dataset (MVSEC), which became the standard set for benchmarking of event-based stereo methods.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",20.09090909090909,0.12921782762691855,0.4478581267217631,1,0.10780669144981413,0.026022304832713755,0.350597609561753
1800,1838,1838,DUP-net: Denoiser and upsampler network for 3D adversarial point clouds defense,"Neural networks are vulnerable to adversarial examples, which poses a threat to their application in security sensitive systems. We propose a Denoiser and UPsampler Network (DUP-Net) structure as defenses for 3D adversarial point cloud classification, where the two modules reconstruct surface smoothness by dropping or adding points. In this paper, statistical outlier removal (SOR) and a data-driven upsampling network are considered as denoiser and upsampler respectively. Compared with baseline defenses, DUP-Net has three advantages. First, with DUP-Net as a defense, the target model is more robust to white-box adversarial attacks. Second, the statistical outlier removal provides added robustness since it is a non-differentiable denoising operation. Third, the upsampler network can be trained on a small dataset and defends well against adversarial attacks generated from other point cloud datasets. We conduct various experiments to validate that DUP-Net is very effective as defense in practice. Our best defense eliminates 83.8% of C&W and l2 loss based attack (point shifting), 50.0% of C&W and Hausdorff distance loss based attack (point adding) and 9.0% of saliency map based attack (point dropping) under 200 dropped points on PointNet.",123505400,University of Science and Technology of China,Shenyang,China,"['1712', '1707']",20.33333333333333,0.14625,0.4090277777777777,1,0.09649122807017543,0.06578947368421052,0.43577981651376146
1801,1839,1839,Attention on attention for image captioning,"Attention mechanisms are widely used in current encoder/decoder frameworks of image captioning, where a weighted average on encoded vectors is generated at each time step to guide the caption decoding process. However, the decoder has little idea of whether or how well the attended vector and the given attention query are related, which could make the decoder give misled results. In this paper, we propose an Attention on Attention (AoA) module, which extends the conventional attention mechanisms to determine the relevance between attention results and queries. AoA first generates an information vector and an attention gate using the attention result and the current context, then adds another attention by applying element-wise multiplication to them and finally obtains the attended information, the expected useful knowledge. We apply AoA to both the encoder and the decoder of our image captioning model, which we name as AoA Network (AoANet). Experiments show that AoANet outperforms all previously published methods and achieves a new state-of-the-art performance of 129.8 CIDEr-D score on MS COCO Karpathy offline test split and 129.6 CIDEr-D (C40) score on the official online testing server. Code is available at https://github.com/husthuaan/AoANet.",60072902,Macau University of Science and Technology,Taipa,Macao,"['1712', '1707']",26.857142857142854,0.017095701917130494,0.400834879406308,1,0.11210762331838565,0.053811659192825115,0.3886255924170616
1802,1840,1840,Re-ID driven localization refinement for person search,"Person search aims at localizing and identifying a query person from a gallery of uncropped scene images. Different from person re-identification (re-ID), its performance also depends on the localization accuracy of a pedestrian detector. The state-of-the-art methods train the detector individually, and the detected bounding boxes may be sub-optimal for the following re-ID task. To alleviate this issue, we propose a re-ID driven localization refinement framework for providing the refined detection boxes for person search. Specifically, we develop a differentiable ROI transform layer to effectively transform the bounding boxes from the original images. Thus, the box coordinates can be supervised by the re-ID training other than the original detection task. With this supervision, the detector can generate more reliable bounding boxes, and the downstream re-ID model can produce more discriminative embeddings based on the refined person localizations. Extensive experimental results on the widely used benchmarks demonstrate that our proposed method performs favorably against the state-of-the-art person search methods.",60025761,Huazhong University of Science and Technology,Wuhan,China,"['1712', '1707']",19.75,0.18541666666666667,0.4923611111111112,1,0.11940298507462686,0.014925373134328358,0.3142857142857143
1803,1841,1841,Similarity-preserving knowledge distillation,"Knowledge distillation is a widely applicable technique for training a student neural network under the guidance of a trained teacher network. For example, in neural network compression, a high-capacity teacher is distilled to train a compact student; in privileged learning, a teacher trained with privileged data is distilled to train a student without access to that data. The distillation loss determines how a teacher's knowledge is captured and transferred to the student. In this paper, we propose a new form of knowledge distillation loss that is inspired by the observation that semantically similar inputs tend to elicit similar activation patterns in a trained network. Similarity-preserving knowledge distillation guides the training of a student network such that input pairs that produce similar (dissimilar) activations in the teacher network produce similar (dissimilar) activations in the student network. In contrast to previous distillation methods, the student is not required to mimic the representation space of the teacher, but rather to preserve the pairwise similarities in its own representation space. Experiments on three public datasets demonstrate the potential of our approach.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",25.285714285714285,0.04269972451790633,0.471625344352617,1,0.115,0.0,0.18877551020408162
1804,1842,1842,HACS: Human action clips and segments dataset for recognition and temporal localization,"This paper presents a new large-scale dataset for recognition and temporal localization of human actions collected from Web videos. We refer to it as HACS (Human Action Clips and Segments). We leverage consensus and disagreement among visual classifiers to automatically mine candidate short clips from unlabeled videos, which are subsequently validated by human annotators. The resulting dataset is dubbed HACS Clips. Through a separate process we also collect annotations defining action segment boundaries. This resulting dataset is called HACS Segments. Overall, HACS Clips consists of 1.5M annotated clips sampled from 504K untrimmed videos, and HACS Segments contains 139K action segments densely annotated in 50K untrimmed videos spanning 200 action categories. HACS Clips contains more labeled examples than any existing video benchmark. This renders our dataset both a large-scale action recognition benchmark and an excellent source for spatiotemporal feature learning. In our transfer learning experiments on three target datasets, HACS Clips outperforms Kinetics-600, Moments-In-Time and Sports1M as a pretraining source. On HACS Segments, we evaluate state-of-the-art methods of action proposal generation and action localization, and highlight the new challenges posed by our dense temporal annotations.",60022195,Massachusetts Institute of Technology,Cambridge,United States,"['1712', '1707']",16.727272727272727,0.1373737373737374,0.20883838383838388,1,0.13004484304932734,0.07623318385650224,0.49019607843137253
1805,1843,1843,The logbarrier adversarial attack: Making effective use of decision boundary information,"Adversarial attacks for image classification are small perturbations to images that are designed to cause misclassification by a model. Adversarial attacks formally correspond to an optimization problem: Find a minimum norm image perturbation, constrained to cause misclassification. A number of effective attacks have been developed. However, to date, no gradient-based attacks have used best practices from the optimization literature to solve this constrained minimization problem. We design a new untargeted attack, based on these best practices, using the well-regarded logarithmic barrier method. On average, our attack distance is similar or better than all state-of-the-art attacks on benchmark datasets (MNIST, CIFAR10, ImageNet-1K). In addition, our method performs significantly better on the most challenging images, those which normally require larger perturbations for misclassification. We employ the LogBarrier attack on several adversarially defended models, and show that it adversarially perturbs all images more efficiently than other attacks: The distance needed to perturb all images is significantly smaller with the LogBarrier attack than with other state-of-the-art attacks.",60002494,McGill University,Montreal,Canada,"['1712', '1707']",20.375,0.2545454545454546,0.4607655502392344,1,0.09852216748768473,0.029556650246305417,0.3709677419354839
1806,1844,1844,Learning semantic-specific graph representation for multi-label image recognition,"Recognizing multiple labels of images is a practical and challenging task, and significant progress has been made by searching semantic-aware regions and modeling label dependency. However, current methods cannot locate the semantic regions accurately due to the lack of part-level supervision or semantic guidance. Moreover, they cannot fully explore the mutual interactions among the semantic regions and do not explicitly model the label co-occurrence. To address these issues, we propose a Semantic-Specific Graph Representation Learning (SSGRL) framework that consists of two crucial modules: 1) a semantic decoupling module that incorporates category semantics to guide learning semantic-specific representations and 2) a semantic interaction module that correlates these representations with a graph built on the statistical label co-occurrence and explores their interactions via a graph propagation mechanism. Extensive experiments on public benchmarks show that our SSGRL framework outperforms current state-of-the-art methods by a sizable margin, e.g. with an mAP improvement of 2.5%, 2.6%, 6.7%, and 3.1% on the PASCAL VOC 2007 & 2012, Microsoft-COCO and Visual Genome benchmarks, respectively. Our codes and models are available at https://github.com/HCPLab-SYSU/SSGRL.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",25.0,0.09583333333333333,0.4125,1,0.0945945945945946,0.05855855855855856,0.43414634146341463
1807,1845,1845,Controllable attention for structured layered video decomposition,"The objective of this paper is to be able to separate a video into its natural layers, and to control which of the separated layers to attend to. For example, to be able to separate reflections, transparency or object motion. We make the following three contributions: (i) we introduce a new structured neural network architecture that explicitly incorporates layers (as spatial masks) into its design. This improves separation performance over previous general purpose networks for this task; (ii) we demonstrate that we can augment the architecture to leverage external cues such as audio for controllability and to help disambiguation; and (iii) we experimentally demonstrate the effectiveness of our approach and training procedure with controlled experiments while also showing that the proposed model can be successfully applied to real-word applications such as reflection removal and action recognition in cluttered scenes.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",34.75,0.08797979797979799,0.4347474747474748,1,0.13836477987421383,0.0,0.2611464968152866
1808,1846,1846,Mop moiré patterns using mopnet,"Moiré pattern is a common image quality degradation caused by frequency aliasing between monitors and cameras when taking screen-shot photos. The complex frequency distribution, imbalanced magnitude in colour channels, and diverse appearance attributes of moiré pattern make its removal a challenging problem. In this paper, we propose a Moiré pattern Removal Neural Network (MopNet) to solve this problem. All core components of MopNet are specially designed for unique properties of moire patterns, including the multi-scale feature aggregation addressing complex frequency, the channel-wise target edge predictor to exploit imbalanced magnitude among colour channels, and the attribute-aware classifier to characterize the diverse appearance for better modelling Moiré patterns. Quantitative and qualitative experimental comparison validate the state-of-the-art performance of MopNet.",60014966,Peking University,Beijing,China,"['1712', '1707']",23.4,0.11651785714285713,0.5964285714285715,1,0.09027777777777778,0.05555555555555555,0.3769230769230769
1809,1847,1847,Targeted mismatch adversarial attack: Query with a flower to retrieve the tower,"Access to online visual search engines implies sharing of private user content - the query images. We introduce the concept of targeted mismatch attack for deep learning based retrieval systems to generate an adversarial image to conceal the query image. The generated image looks nothing like the user intended query, but leads to identical or very similar retrieval results. Transferring attacks to fully unseen networks is challenging. We show successful attacks to partially unknown systems, by designing various loss functions for the adversarial image construction. These include loss functions, for example, for unknown global pooling operation or unknown input resolution by the retrieval system. We evaluate the attacks on standard retrieval benchmarks and compare the results retrieved with the original and adversarial image.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,"['1712', '1707']",17.571428571428573,0.10192307692307692,0.4842307692307693,1,0.13432835820895522,0.0,0.3208955223880597
1810,1848,1848,Nanomaterial-based lubricant effect on the vibrations of defective rolling element bearings," J. Mech. Eng. Rob. Res.In a recent advancement to reduce friction and wear between rotating contact surfaces and improve machine reliability, the use of a nanomaterial based lubricant instead of the conventional mineral based-one has been promoted. Currently there is a very limited body of research on this topic due to its recent emerging. An in depth studies and research are in need to investigate the type of improvements gained by using nanomaterial additives, especially on the levels of vibrations and the changes to the diagnosis features within the vibration signal. This paper investigates the effect of the use of a nanomaterial-based lubricant on the levels of vibration from defective rolling element bearings (outer race fault). A bearing test rig with hydraulic loading has been designed to enable the collection of vibration data. A 1 mm outer race defect was seeded in a self-aligning bearing using electrical discharge machining. The level and nature of the vibration signals with 0.1%, 0.2%, 0.3% and 0.5% of copper dioxide (Cu2O) particles of two different sizes (30 nm and 70 nm) were compared. Results show that the energy level of the impact (root mean squared value) drops as a result of introducing the 30 and 70 nm particles with the highest drop reported at a concentration of 0.5% for the 70 nm. The impulsiveness of the signals (Kurtosis levels) are lower for the 70nm compared to the 30 nm and the lowest was recorded at a concentration of 0.2%. The noise associated with adding the nanomaterial is observed to increase and to affect frequency bands above 5 kHz.",60091190,Prince Mohammad Bin Fahd University,Al-Khobar,Saudi Arabia,['1702'],18.928571428571427,-0.06732142857142857,0.42053571428571423,0,0.10423452768729642,0.02280130293159609,0.35353535353535354
1811,1849,1849,Instance-level future motion estimation in a single image based on ordinal regression,"A novel algorithm to estimate instance-level future motion in a single image is proposed in this paper. We first represent the future motion of an instance with its direction, speed, and action classes. Then, we develop a deep neural network that exploits different levels of semantic information to perform the future motion estimation. For effective future motion classification, we adopt ordinal regression. Especially, we develop the cyclic ordinal regression scheme using binary classifiers. Experiments demonstrate that the proposed algorithm provides reliable performance and thus can be used effectively for vision applications, including single and multi object tracking. Furthermore, we release the future motion (FM) dataset, collected from diverse sources and annotated manually, as a benchmark for single-image future motion estimation.",60022417,Chungnam National University,Daejeon,South Korea,"['1712', '1707']",17.142857142857142,0.0938095238095238,0.3474603174603175,1,0.1267605633802817,0.007042253521126761,0.2971014492753623
1812,1850,1850,"Align, attend and locate: Chest x-ray diagnosis via contrast induced attention network with limited supervision","Obstacles facing accurate identification and localization of diseases in chest X-ray images lie in the lack of high-quality images and annotations. In this paper, we propose a Contrast Induced Attention Network (CIA-Net), which exploits the highly structured property of chest X-ray images and localizes diseases via contrastive learning on the aligned positive and negative samples. To force the attention module to focus only on sites of abnormalities, we also introduce a learnable alignment module to adjust all the input images, which eliminates variations of scales, angles, and displacements of X-ray images generated under bad scan conditions. We show that the use of contrastive attention and alignment module allows the model to learn rich identification and localization information using only a small amount of location annotations, resulting in state-of-the-art performance in NIH chest X-ray dataset.",60014966,Peking University,Beijing,China,"['1712', '1707']",33.5,-0.013772727272727242,0.5935454545454546,1,0.10909090909090909,0.04242424242424243,0.36054421768707484
1813,1851,1851,Deep contextual attention for human-object interaction detection,"Human-object interaction detection is an important and relatively new class of visual relationship detection tasks, essential for deeper scene understanding. Most existing approaches decompose the problem into object localization and interaction recognition. Despite showing progress, these approaches only rely on the appearances of humans and objects and overlook the available context information, crucial for capturing subtle interactions between them. We propose a contextual attention framework for human-object interaction detection. Our approach leverages context by learning contextually-aware appearance features for human and object instances. The proposed attention module then adaptively selects relevant instance-centric context information to highlight image regions likely to contain human-object interactions. Experiments are performed on three benchmarks: V-COCO, HICO-DET and HCVRD. Our approach outperforms the state-of-the-art on all datasets. On the V-COCO dataset, our method achieves a relative gain of 4.4% in terms of role mean average precision (mAP role ), compared to the existing best approach.",60103653,Aalto University,Espoo,Finland,"['1712', '1707']",16.555555555555557,0.12753314393939394,0.533877840909091,1,0.10052910052910052,0.042328042328042326,0.38323353293413176
1814,1852,1852,Neural-guided RANSAC: Learning where to sample model hypotheses,"We present Neural-Guided RANSAC (NG-RANSAC), an extension to the classic RANSAC algorithm from robust optimization. NG-RANSAC uses prior information to improve model hypothesis search, increasing the chance of finding outlier-free minimal sets. Previous works use heuristic side-information like hand-crafted descriptor distance to guide hypothesis search. In contrast, we learn hypothesis search in a principled fashion that lets us optimize an arbitrary task loss during training, leading to large improvements on classic computer vision tasks. We present two further extensions to NG-RANSAC. Firstly, using the inlier count itself as training signal allows us to train neural guidance in a self-supervised fashion. Secondly, we combine neural guidance with differentiable RANSAC to build neural networks which focus on certain parts of the input data and make the output predictions as good as possible. We evaluate NG-RANSAC on a wide array of computer vision tasks, namely estimation of epipolar geometry, horizon line estimation and camera re-localization. We achieve superior or competitive results compared to state-of-the-art robust estimators, including very recent, learned ones.",60016908,Universität Heidelberg,Heidelberg,Germany,"['1712', '1707']",18.666666666666668,0.10806878306878304,0.375462962962963,1,0.13023255813953488,0.06046511627906977,0.3333333333333333
1815,1853,1853,Learning to see moving objects in the dark,"Video surveillance systems have wide range of utilities, yet easily suffer from great quality degeneration under dim light circumstances. Industrial solutions mainly use extra near-infrared illuminations, even though it doesn't preserve color and texture information. A variety of researches enhanced low-light videos shot by visible light cameras, while they either relied on task specific preconditions or trained with synthetic datasets. We propose a novel optical system to capture bright and dark videos of the exact same scenes, generating training and groud truth pairs for authentic low-light video dataset. A fully convolutional network with 3D and 2D miscellaneous operations is utilized to learn an enhancement mapping with proper spatial-temporal transformation from raw camera sensor data to bright RGB videos. Experiments show promising results by our method, and it outperforms state-of-the-art low-light image/video enhancement algorithms.",60029311,University of Southern California,Los Angeles,United States,"['1712', '1707']",22.16666666666667,0.23162393162393166,0.4793447293447294,1,0.09815950920245399,0.0,0.33793103448275863
1816,1854,1854,Unsupervised person re-identification by camera-aware similarity consistency learning,"For matching pedestrians across disjoint camera views in surveillance, person re-identification (Re-ID) has made great progress in supervised learning. However, it is infeasible to label data in a number of new scenes when extending a Re-ID system. Thus, studying unsupervised learning for Re-ID is important for saving labelling cost. Yet, cross-camera scene variation is a key challenge for unsupervised Re-ID, such as illumination, background and viewpoint variations, which cause domain shift in the feature space and result in inconsistent pairwise similarity distributions that degrade matching performance. To alleviate the effect of cross-camera scene variation, we propose a Camera-Aware Similarity Consistency Loss to learn consistent pairwise similarity distributions for intra-camera matching and cross-camera matching. To avoid learning ineffective knowledge in consistency learning, we preserve the prior common knowledge of intra-camera matching in the pretrained model as reliable guiding information, which does not suffer from cross-camera scene variation as cross-camera matching. To learn similarity consistency more effectively, we further develop a coarse-to-fine consistency learning scheme to learn consistency globally and locally in two steps. Experiments show that our method outperformed the state-of-the-art unsupervised Re-ID methods.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",22.875,0.14886363636363634,0.4545454545454546,1,0.09504132231404959,0.06198347107438017,0.30392156862745096
1817,1855,1855,K-best transformation synchronization,"In this paper, we introduce the problem of K-best transformation synchronization for the purpose of multiple scan matching. Given noisy pair-wise transformations computed between a subset of depth scan pairs, K-best transformation synchronization seeks to output multiple consistent relative transformations. This problem naturally arises in many geometry reconstruction applications, where the underlying object possesses self-symmetry. For approximately symmetric or even non-symmetric objects, K-best solutions offer an intermediate presentation for recovering the underlying single-best solution. We introduce a simple yet robust iterative algorithm for K-best transformation synchronization, which alternates between transformation propagation and transformation clustering. We present theoretical guarantees on the robust and exact recoveries of our algorithm. Experimental results demonstrate the advantage of our approach against state-of-the-art transformation synchronization techniques on both synthetic and real datasets.",60013372,The University of Texas at Austin,Austin,United States,"['1712', '1707']",18.0,0.07692307692307693,0.2428571428571429,1,0.075,0.03125,0.3188405797101449
1818,1856,1856,Presence-only geographical priors for fine-grained image classification,"Appearance information alone is often not sufficient to accurately differentiate between fine-grained visual categories. Human experts make use of additional cues such as where, and when, a given image was taken in order to inform their final decision. This contextual information is readily available in many online image collections but has been underutilized by existing image classifiers that focus solely on making predictions based on the image contents. We propose an efficient spatio-temporal prior, that when conditioned on a geographical location and time, estimates the probability that a given object category occurs at that location. Our prior is trained from presence-only observation data and jointly models object categories, their spatio-temporal distributions, and photographer biases. Experiments performed on multiple challenging image classification datasets show that combining our prior with the predictions from image classifiers results in a large improvement in final classification performance.",60031581,California Institute of Technology,Pasadena,United States,"['1712', '1707']",23.66666666666667,0.14387755102040814,0.39727891156462586,1,0.1419753086419753,0.0,0.2857142857142857
1819,1857,1857,On the design of black-box adversarial examples by leveraging gradient-free optimization and operator splitting method,"Robust machine learning is currently one of the most prominent topics which could potentially help shaping a future of advanced AI platforms that not only perform well in average cases but also in worst cases or adverse situations. Despite the long-term vision, however, existing studies on black-box adversarial attacks are still restricted to very specific settings of threat models (e.g., single distortion metric and restrictive assumption on target model's feedback to queries) and/or suffer from prohibitively high query complexity. To push for further advances in this field, we introduce a general framework based on an operator splitting method, the alternating direction method of multipliers (ADMM) to devise efficient, robust black-box attacks that work with various distortion metrics and feedback settings without incurring high query complexity. Due to the black-box nature of the threat model, the proposed ADMM solution framework is integrated with zeroth-order (ZO) optimization and Bayesian optimization (BO), and thus is applicable to the gradient-free regime. This results in two new black-box adversarial attack generation methods, ZO-ADMM and BO-ADMM. Our empirical evaluations on image classification datasets show that our proposed approaches have much lower function query complexities compared to state-of-the-art attack methods, but achieve very competitive attack success rates.",60030551,Syracuse University,Syracuse,United States,"['1712', '1707']",33.333333333333336,0.06181523022432114,0.4732423258559622,1,0.08433734939759036,0.040160642570281124,0.3511111111111111
1820,1858,1858,Calibration wizard: A guidance system for camera calibration based on modelling geometric and corner uncertainty,"It is well known that the accuracy of a calibration depends strongly on the choice of camera poses from which images of a calibration object are acquired. We present a system - Calibration Wizard - that interactively guides a user towards taking optimal calibration images. For each new image to be taken, the system computes, from all previously acquired images, the pose that leads to the globally maximum reduction of expected uncertainty on intrinsic parameters and then guides the user towards that pose. We also show how to incorporate uncertainty in corner point position in a novel principled manner, for both, calibration and computation of the next best pose. Synthetic and real-world experiments are performed to demonstrate the effectiveness of Calibration Wizard.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",24.4,0.16287878787878787,0.2568181818181818,1,0.11940298507462686,0.029850746268656716,0.2727272727272727
1821,1859,1859,Self-training and adversarial background regularization for unsupervised domain adaptive one-stage object detection,"Deep learning-based object detectors have shown remarkable improvements. However, supervised learning-based methods perform poorly when the train data and the test data have different distributions. To address the issue, domain adaptation transfers knowledge from the label-sufficient domain (source domain) to the label-scarce domain (target domain). Self-training is one of the powerful ways to achieve domain adaptation since it helps class-wise domain adaptation. Unfortunately, a naive approach that utilizes pseudo-labels as ground-truth degenerates the performance due to incorrect pseudo-labels. In this paper, we introduce a weak self-training (WST) method and adversarial background score regularization (BSR) for domain adaptive one-stage object detection. WST diminishes the adverse effects of inaccurate pseudo-labels to stabilize the learning procedure. BSR helps the network extract discriminative features for target backgrounds to reduce the domain shift. Two components are complementary to each other as BSR enhances discrimination between foregrounds and backgrounds, whereas WST strengthen class-wise discrimination. Experimental results show that our approach effectively improves the performance of the one-stage object detection in unsupervised domain adaptation setting.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1707']",16.8,0.03863636363636363,0.6295454545454545,1,0.091324200913242,0.0273972602739726,0.36649214659685864
1822,1860,1860,Non-local recurrent neural memory for supervised sequence modeling,"Typical methods for supervised sequence modeling are built upon the recurrent neural networks to capture temporal dependencies. One potential limitation of these methods is that they only model explicitly information interactions between adjacent time steps in a sequence, hence the high-order interactions between nonadjacent time steps are not fully exploited. It greatly limits the capability of modeling the long-range temporal dependencies since one-order interactions cannot be maintained for a long term due to information dilution and gradient vanishing. To tackle this limitation, we propose the Non-local Recurrent Neural Memory (NRNM) for supervised sequence modeling, which performs non-local operations to learn full-order interactions within a sliding temporal block and models the global interactions between blocks in a gated recurrent manner. Consequently, our model is able to capture the long-range dependencies. Besides, the latent high-level features contained in high-order interactions can be distilled by our model. We demonstrate the merits of our NRNM approach on two different tasks: Action recognition and sentiment analysis.",60014966,Peking University,Beijing,China,"['1712', '1707']",23.0,0.10583333333333332,0.5349999999999999,1,0.10256410256410256,0.020512820512820513,0.3615819209039548
1823,1861,1861,LADN: Local adversarial disentangling network for facial makeup and de-makeup,"We propose a local adversarial disentangling network (LADN) for facial makeup and de-makeup. Central to our method are multiple and overlapping local adversarial discriminators in a content-style disentangling network for achieving local detail transfer between facial images, with the use of asymmetric loss functions for dramatic makeup styles with high-frequency details. Existing techniques do not demonstrate or fail to transfer high-frequency details in a global adversarial setting, or train a single local discriminator only to ensure image structure consistency and thus work only for relatively simple styles. Unlike others, our proposed local adversarial discriminators can distinguish whether the generated local image details are consistent with the corresponding regions in the given reference image in cross-image style transfer in an unsupervised setting. Incorporating these technical contributions, we achieve not only state-of-the-art results on conventional styles but also novel results involving complex and dramatic styles with high-frequency details covering large areas across multiple facial features. A carefully designed dataset of unpaired before and after makeup images is released at https://georgegu1997.github.io/LADN-project-page.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",28.0,-0.05617283950617285,0.291005291005291,1,0.1111111111111111,0.005050505050505051,0.35714285714285715
1824,1862,1862,Monocular piecewise depth estimation in dynamic scenes by exploiting superpixel relations,"In this paper, we propose a novel and specially designed method for piecewise dense monocular depth estimation in dynamic scenes. We utilize spatial relations between neighboring superpixels to solve the inherent relative scale ambiguity (RSA) problem and smooth the depth map. However, directly estimating spatial relations is an ill-posed problem. Our core idea is to predict spatial relations based on the corresponding motion relations. Given two or more consecutive frames, we first compute semi-dense (CPM) or dense (optical flow) point matches between temporally neighboring images. Then we develop our method in four main stages: Superpixel relations analysis, motion selection, reconstruction, and refinement. The final refinement process helps to improve the quality of the reconstruction at pixel level. Our method does not require per-object segmentation, template priors or training sets, which ensures flexibility in various applications. Extensive experiments on both synthetic and real datasets demonstrate that our method robustly handles different dynamic situations and presents competitive results to the state-of-the-art methods while running much faster than them.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",18.444444444444443,0.14492063492063495,0.3936507936507937,1,0.09900990099009901,0.009900990099009901,0.3368421052631579
1825,1863,1863,The effectiveness of implementing lean manufacturing techniques," It was developed by Motorola in 1986, coinciding with the Japanese asset price bubble which is reflected in its terminology. Jack Welch made it central to his business strategy at General Electric in 1995. Today, it is used in many industrial sectors. The term ""lean manufacturing"" comes from statistics and is used in statistical quality control, which evaluates process capability. Originally, it referred to the ability of manufacturing processes to produce a very high proportion of output within specification. Processes that operate with ""lean manufacturing quality"" over the short term are assumed to produce long-term defect levels below 3.4 defects per million opportunities (DPMO). The primary objective is to study the effectiveness of implementing lean manufacturing techniques and to identify and analyze any related issues and industrial common challenges or problems in lean manufacturing implementation. In this study Descriptive Research design is used. In the case of multiple choice questions the responses are categorized based on the nature and percentage, and is calculated for each category. To find the percentage of the responses in each category Percentage Analysis is used. The percentage is calculated by dividing the number of responses by the total number of respondents. Convenience sampling method has been used in the research work. A well-structured questionnaire have been used to collect the responses from employees. Numerous findings has been derived from this research has helped to provide few suggestions to improve the effectiveness of lean manufacturing techniques.",124081993,Sree Vivekananda Padana Kendram Foundation,Malappuram,India,['1706'],17.214285714285715,0.0708125,0.3845,0,0.11851851851851852,0.037037037037037035,0.3132075471698113
1826,1865,1865,Deep supervised hashing with anchor graph,"Recently, a series of deep supervised hashing methods were proposed for binary code learning. However, due to the high computation cost and the limited hardware's memory, these methods will first select a subset from the training set, and then form a mini-batch data to update the network in each iteration. Therefore, the remaining labeled data cannot be fully utilized and the model cannot directly obtain the binary codes of the entire training set for retrieval. To address these problems, this paper proposes an interesting regularized deep model to seamlessly integrate the advantages of deep hashing and efficient binary code learning by using the anchor graph. As such, the deep features and label matrix can be jointly used to optimize the binary codes, and the network can obtain more discriminative feedback from the linear combinations of the learned bits. Moreover, we also reveal the algorithm mechanism and its computation essence. Experiments on three large-scale datasets indicate that the proposed method achieves better retrieval performance with less training time compared to previous deep hashing methods.",60000937,Shenzhen University,Shenzhen,China,"['1712', '1707']",24.714285714285715,0.08317042606516291,0.3683959899749374,1,0.14285714285714285,0.01020408163265306,0.2604166666666667
1827,1866,1866,High efficiency permanent magnet synchronous motor used in electric vehicle,"The high efficiency permanent magnet synchronous motor used in electric vehicle was designed, combined with the finite element simulation software Ansys Maxwell, the finite element analyze was carried out. The experimental results showed that the designed motor had excellent electrical performance and overload ability under double torque or double power, combined with speed controller based on weak magnetic effect principle, it can ensure the designed motor for reliable using.",60103926,Nanchang Institute of Technology,Nanchang,China,['1700'],34.5,0.1475,0.4275,1,0.14666666666666667,0.05333333333333334,0.16
1828,1867,1867,AMP: Adaptive masked proxies for few-shot segmentation,"Deep learning has thrived by training on large-scale datasets. However, in robotics applications sample efficiency is critical. We propose a novel adaptive masked proxies method that constructs the final segmentation layer weights from few labelled samples. It utilizes multi-resolution average pooling on base embeddings masked with the label to act as a positive proxy for the new class, while fusing it with the previously learned class signatures. Our method is evaluated on PASCAL-5i dataset and outperforms the state-of-the-art in the few-shot semantic segmentation. Unlike previous methods, our approach does not require a second branch to estimate parameters or prototypes, which enables it to be used with 2-stream motion and appearance based segmentation networks. We further propose a novel setup for evaluating continual learning of object segmentation which we name incremental PASCAL (iPASCAL) where our method outperforms the baseline method. Our code is publicly available at https://github.com/MSiam/AdaptiveMaskedProxies.",60030835,University of Alberta,Edmonton,Canada,"['1712', '1707']",18.25,-0.05536130536130535,0.4564102564102565,1,0.13372093023255813,0.005813953488372093,0.36419753086419754
1829,1868,1868,Progressive differentiable architecture search: Bridging the depth gap between search and evaluation,"Recently, differentiable search methods have made major progress in reducing the computational costs of neural architecture search. However, these approaches often report lower accuracy in evaluating the searched architecture or transferring it to another dataset. This is arguably due to the large gap between the architecture depths in search and evaluation scenarios. In this paper, we present an efficient algorithm which allows the depth of searched architectures to grow gradually during the training procedure. This brings two issues, namely, heavier computational overheads and weaker search stability, which we solve using search space approximation and regularization, respectively. With a significantly reduced search time (∼7 hours on a single GPU), our approach achieves state-of-the-art performance on both the proxy dataset (CIFAR10 or CIFAR100) and the target dataset (ImageNet). Code is available at https://github.com/chenxin061/pdarts.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",18.714285714285715,0.09503968253968256,0.3492063492063492,1,0.0949367088607595,0.03164556962025317,0.38311688311688313
1830,1869,1869,Learning object-specific distance from a monocular image,"Environment perception, including object detection and distance estimation, is one of the most crucial tasks for autonomous driving. Many attentions have been paid on the object detection task, but distance estimation only arouse few interests in the computer vision community. Observing that the traditional inverse perspective mapping algorithm performs poorly for objects far away from the camera or on the curved road, in this paper, we address the challenging distance estimation problem by developing the first end-to-end learning-based model to directly predict distances for given objects in the images. Besides the introduction of a learning-based base model, we further design an enhanced model with a keypoint regressor, where a projection loss is defined to enforce a better distance estimation, especially for objects close to the camera. To facilitate the research on this task, we construct the extented KITTI and nuScenes (mini) object detection datasets with a distance for each object. Our experiments demonstrate that our proposed methods outperform alternative approaches (e.g., the traditional IPM, SVR) on object-specific distance estimation, particularly for the challenging cases that objects are on a curved road. Moreover, the performance margin implies the effectiveness of our enhanced method.",60021784,New York University,New York,United States,"['1712', '1707']",27.42857142857143,0.11140350877192982,0.6824561403508772,1,0.10176991150442478,0.02654867256637168,0.3055555555555556
1831,1870,1870,Point-to-point video generation,"While image synthesis achieves tremendous breakthroughs (e.g., generating realistic faces), video generation is less explored and harder to control, which limits its applications in the real world. For instance, video editing requires temporal coherence across multiple clips and thus poses both start and end constraints within a video sequence. We introduce point-to-point video generation that controls the generation process with two control points: The targeted start- and end-frames. The task is challenging since the model not only generates a smooth transition of frames but also plans ahead to ensure that the generated end-frame conforms to the targeted end-frame for videos of various lengths. We propose to maximize the modified variational lower bound of conditional data likelihood under a skip-frame training strategy. Our model can generate end-frame-consistent sequences without loss of quality and diversity. We evaluate our method through extensive experiments on Stochastic Moving MNIST, Weizmann Action, Human3.6M, and BAIR Robot Pushing under a series of scenarios. The qualitative results showcase the effectiveness and merits of point-to-point generation.",60018029,National Tsing Hua University,Hsinchu,Taiwan,"['1712', '1707']",20.875,0.11944444444444445,0.42777777777777776,1,0.1262135922330097,0.04854368932038835,0.3621621621621622
1832,1871,1871,Design of crane virtual simulation teaching assessment system,"With the rapid development of cranes, crane teaching aids cannot follow up with new products in real time, and the teaching cost is high and the space utilization rate is low. In order to solve these problems, we used SolidWorks and 3ds Max to carry out mechanical modeling in the virtual environment. Based on the Unity3D development engine, we designed a virtual simulation teaching evaluation system for cranes, which completed the design of modules for cognitive teaching, maintenance, fault repairing and teaching assessment. The system takes advantage of virtual technology’s features of immersion, interaction and imagination. Therefore, it solves the problem of the slow update of teaching aids in the teaching process of cranes effectively, saves teaching costs greatly, overcomes the traditional teaching boring shortcomings, and improves the efficiency of port machinery education. And It plays an important role in promoting the application of virtual reality technology in education and training.",60022414,Wuhan University of Technology,Wuhan,China,['1700'],25.16666666666667,0.09963636363636362,0.6294545454545455,1,0.0935672514619883,0.03508771929824561,0.27906976744186046
1833,1872,1872,An empirical study of externality and customer satisfaction," Hundreds of studies examine the relationship between the performance of product attributes and customer satisfaction. Instead of conducting an analysis on the influence of attribute performances on customer satisfaction, this study pays close attention to the influences of externality on customer satisfaction in the case of the tourism industry. We examine the externality coming from companion’s behavior on tourist satisfaction in tour groups. The regression results show that companion’s behavior significantly influence tourist satisfaction, no matter the satisfaction is measured from the aspect of tour schedule or tour escort. By encouraging or discouraging some companions customer can enhance tourist satisfaction. In addition, gender and companions will cause different regression results. This reminds us to take consideration of the individual difference when taking actions to enhance satisfaction. These results imply customer satisfaction is not only determined by the performance of product attributes, but also depends on externality. Controlling the influence of externality is an alternative to enhance satisfaction.",60018007,Nanhua University Taiwan,Chiayi,Taiwan,['1706'],17.555555555555557,0.09375,0.71875,0,0.13872832369942195,0.0,0.22413793103448276
1834,1873,1873,Goal-driven sequential data abstraction,"Automatic data abstraction is an important capability for both benchmarking machine intelligence and supporting summarization applications. In the former one asks whether a machine can 'understand' enough about the meaning of input data to produce a meaningful but more compact abstraction. In the latter this capability is exploited for saving space or human time by summarizing the essence of input data. In this paper we study a general reinforcement learning based framework for learning to abstract sequential data in a goal-driven way. The ability to define different abstraction goals uniquely allows different aspects of the input data to be preserved according to the ultimate purpose of the abstraction. Our reinforcement learning objective does not require human-defined examples of ideal abstraction. Importantly our model processes the input sequence holistically without being constrained by the original input order. Our framework is also domain agnostic - we demonstrate applications to sketch, video and text data and achieve promising results in all domains.",60027272,University of Edinburgh,Edinburgh,United Kingdom,"['1712', '1707']",19.875,0.21944444444444444,0.5499999999999999,1,0.14367816091954022,0.0,0.20710059171597633
1835,1874,1874,Local relation networks for image recognition,"The convolution layer has been the dominant feature extractor in computer vision for years. However, the spatial aggregation in convolution is basically a pattern matching process that applies fixed filters which are inefficient at modeling visual elements with varying spatial distributions. This paper presents a new image feature extractor, called the local relation layer, that adaptively determines aggregation weights based on the compositional relationship of local pixel pairs. With this relational approach, it can composite visual elements into higher-level entities in a more efficient manner that benefits semantic inference. A network built with local relation layers, called the Local Relation Network (LR-Net), is found to provide greater modeling capacity than its counterpart built with regular convolution on large-scale recognition tasks such as ImageNet classification.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",24.8,0.10303030303030304,0.18595571095571092,1,0.11188811188811189,0.04195804195804196,0.30656934306569344
1836,1875,1875,Learning an effective equivariant 3D descriptor without supervision,"Establishing correspondences between 3D shapes is a fundamental task in 3D Computer Vision, typically ad- dressed by matching local descriptors. Recently, a few at- tempts at applying the deep learning paradigm to the task have shown promising results. Yet, the only explored way to learn rotation invariant descriptors has been to feed neural networks with highly engineered and invariant representa- tions provided by existing hand-crafted descriptors, a path that goes in the opposite direction of end-to-end learning from raw data so successfully deployed for 2D images. In this paper, we explore the benefits of taking a step back in the direction of end-to-end learning of 3D descrip- tors by disentangling the creation of a robust and distinctive rotation equivariant representation, which can be learned from unoriented input data, and the definition of a good canonical orientation, required only at test time to obtain an invariant descriptor. To this end, we leverage two re- cent innovations: Spherical convolutional neural networks to learn an equivariant descriptor and plane folding de- coders to learn without supervision. The effectiveness of the proposed approach is experimentally validated by out- performing hand-crafted and learned descriptors on a stan- dard benchmark.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1707']",32.33333333333333,0.09375457875457877,0.4608241758241758,1,0.13063063063063063,0.02252252252252252,0.3476190476190476
1837,1876,1876,Compositional video prediction,"We present an approach for pixel-level future prediction given an input image of a scene. We observe that a scene is comprised of distinct entities that undergo motion and present an approach that operationalizes this insight. We implicitly predict future states of independent entities while reasoning about their interactions, and compose future video frames using these predicted states. We overcome the inherent multi-modality of the task using a global trajectory-level latent random variable, and show that this allows us to sample diverse and plausible futures. We empirically validate our approach against alternate representations and ways of incorporating multi-modality. We examine two datasets, one comprising of stacked objects that may fall, and the other containing videos of humans performing activities in a gym, and show that our approach allows realistic stochastic video prediction across these diverse settings. See project website (https://judyye.github.io/CVP/) for video predictions.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",20.428571428571427,0.03154761904761905,0.18630952380952384,1,0.1696969696969697,0.006060606060606061,0.3522012578616352
1838,1877,1877,ClothFlow: A flow-based model for clothed person generation,"We present ClothFlow, an appearance-flow-based generative model to synthesize clothed person for posed-guided person image generation and virtual try-on. By estimating a dense flow between source and target clothing regions, ClothFlow effectively models the geometric changes and naturally transfers the appearance to synthesize novel images as shown in Figure 1. We achieve this with a three-stage framework: 1) Conditioned on a target pose, we first estimate a person semantic layout to provide richer guidance to the generation process. 2) Built on two feature pyramid networks, a cascaded flow estimation network then accurately estimates the appearance matching between corresponding clothing regions. The resulting dense flow warps the source image to flexibly account for deformations. 3) Finally, a generative network takes the warped clothing regions as inputs and renders the target view. We conduct extensive experiments on the DeepFashion dataset for pose-guided person image generation and on the VITON dataset for the virtual try-on task. Strong qualitative and quantitative results validate the effectiveness of our method.",60113057,"Malong Technologies Co., Ltd.",Shenzhen,China,"['1712', '1707']",20.5,0.22291666666666668,0.5291666666666667,1,0.14871794871794872,0.02564102564102564,0.3425414364640884
1839,1878,1878,Joint syntax representation learning and visual cue translation for video captioning,"Video captioning is a challenging task that involves not only visual perception but also syntax representation learning. Recent progress in video captioning has been achieved through visual perception, but syntax representation learning is still under-explored. We propose a novel video captioning approach that takes into account both visual perception and syntax representation learning to generate accurate descriptions of videos. Specifically, we use sentence templates composed of Part-of-Speech (POS) tags to represent the syntax structure of captions, and accordingly, syntax representation learning is performed by directly inferring POS tags from videos. The visual perception is implemented by a mixture model which translates visual cues into lexical words that are conditional on the learned syntactic structure of sentences. Thus, a video captioning task consists of two sub-tasks: Video POS tagging and visual cue translation, which are jointly modeled and trained in an end-to-end fashion. Evaluations on three public benchmark datasets demonstrate that our proposed method achieves substantially better performance than the state-of-the-art methods, which validates the superiority of joint modeling of syntax representation learning and visual perception for video captioning.",60027165,University of Rochester,Rochester,United States,"['1712', '1707']",25.42857142857143,0.10714285714285716,0.275,1,0.11737089201877934,0.014084507042253521,0.3333333333333333
1840,1879,1879,Texturepose: Supervising human mesh estimation with texture consistency,"This work addresses the problem of model-based human pose estimation. Recent approaches have made significant progress towards regressing the parameters of parametric human body models directly from images. Because of the absence of images with 3D shape ground truth, relevant approaches rely on 2D annotations or sophisticated architecture designs. In this work, we advocate that there are more cues we can leverage, which are available for free in natural images, i.e., without getting more annotations, or modifying the network architecture. We propose a natural form of supervision, that capitalizes on the appearance constancy of a person among different frames (or viewpoints). This seemingly insignificant and often overlooked cue goes a long way for model-based pose estimation. The parametric model we employ allows us to compute a texture map for each frame. Assuming that the texture of the person does not change dramatically between frames, we can apply a novel texture consistency loss, which enforces that each point in the texture map has the same texture value across all frames. Since the texture is transferred in this common texture map space, no camera motion computation is necessary, or even an assumption of smoothness among frames. This makes our proposed supervision applicable in a variety of settings, ranging from monocular video, to multi-view images. We benchmark our approach against strong baselines that require the same or even more annotations that we do and we consistently outperform them. Simultaneously, we achieve state-of-the-art results among model-based pose estimation approaches in different benchmarks. The project website with videos, results, and code can be found at https://seas.upenn.edu/∼pavlakos/projects/texturepose.",60006297,University of Pennsylvania,Philadelphia,United States,"['1712', '1707']",20.076923076923077,0.1748263888888889,0.4774305555555555,1,0.1111111111111111,0.00980392156862745,0.30612244897959184
1841,1880,1880,MonoLoco: Monocular 3D pedestrian localization and uncertainty estimation,"We tackle the fundamentally ill-posed problem of 3D human localization from monocular RGB images. Driven by the limitation of neural networks outputting point estimates, we address the ambiguity in the task by predicting confidence intervals through a loss function based on the Laplace distribution. Our architecture is a light-weight feed-forward neural network that predicts 3D locations and corresponding confidence intervals given 2D human poses. The design is particularly well suited for small training data, cross-dataset generalization, and real-time applications. Our experiments show that we (i) outperform state-of-the-art results on KITTI and nuScenes datasets, (ii) even outperform a stereo-based method for far-away pedestrians, and (iii) estimate meaningful confidence intervals. We further share insights on our model of uncertainty in cases of limited observations and out-of-distribution samples.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",20.83333333333333,0.04931972789115646,0.29659863945578235,1,0.09036144578313253,0.018072289156626505,0.4295774647887324
1842,1881,1881,Deceptionnet: Network-driven domain randomization,"We present a novel approach to tackle domain adaptation between synthetic and real data. Instead, of employing 'blind' domain randomization, i.e., augmenting synthetic renderings with random backgrounds or changing illumination and colorization, we leverage the task network as its own adversarial guide toward useful augmentations that maximize the uncertainty of the output. To this end, we design a min-max optimization scheme where a given task competes against a special deception network to minimize the task error subject to the specific constraints enforced by the deceiver. The deception network samples from a family of differentiable pixel-level perturbations and exploits the task architecture to find the most destructive augmentations. Unlike GAN-based approaches that require unlabeled data from the target domain, our method achieves robust mappings that scale well to multiple target distributions from source data alone. We apply our framework to the tasks of digit recognition on enhanced MNIST variants, classification and object pose estimation on the Cropped LineMOD dataset as well as semantic segmentation on the Cityscapes dataset and compare it to a number of domain adaptation approaches, thereby demonstrating similar results with superior generalization capabilities.",60028673,Siemens AG,Munich,Germany,"['1712', '1707']",30.83333333333333,0.06360544217687074,0.4211734693877552,1,0.10628019323671498,0.028985507246376812,0.27
1843,1882,1882,Recover and identify: A generative dual model for cross-resolution person re-identification,"Person re-identification (re-ID) aims at matching images of the same identity across camera views. Due to varying distances between cameras and persons of interest, resolution mismatch can be expected, which would degrade person re-ID performance in real-world scenarios. To overcome this problem, we propose a novel generative adversarial network to address cross-resolution person re-ID, allowing query images with varying resolutions. By advancing adversarial learning techniques, our proposed model learns resolution-invariant image representations while being able to recover the missing details in low-resolution input images. The resulting features can be jointly applied for improving person re-ID performance due to preserving resolution invariance and recovering re-ID oriented discriminative details. Our experiments on five benchmark datasets confirm the effectiveness of our approach and its superiority over the state-of-the-art methods, especially when the input resolutions are unseen during training.",60016969,Academia Sinica Taiwan,Nankang,Taiwan,"['1712', '1707']",22.5,-0.007142857142857141,0.4214285714285714,1,0.14857142857142858,0.017142857142857144,0.40939597315436244
1844,1883,1883,Semi-supervised video salient object detection using pseudo-labels,"Deep learning-based video salient object detection has recently achieved great success with its performance significantly outperforming any other unsupervised methods. However, existing data-driven approaches heavily rely on a large quantity of pixel-wise annotated video frames to deliver such promising results. In this paper, we address the semi-supervised video salient object detection task using pseudo-labels. Specifically, we present an effective video saliency detector that consists of a spatial refinement network and a spatiotemporal module. Based on the same refinement network and motion information in terms of optical flow, we further propose a novel method for generating pixel-level pseudo-labels from sparsely annotated frames. By utilizing the generated pseudo-labels together with a part of manual annotations, our video saliency detector learns spatial and temporal cues for both contrast inference and coherence enhancement, thus producing accurate saliency maps. Experimental results demonstrate that our proposed semi-supervised method even greatly outperforms all the state-of-the-art fully supervised methods across three public benchmarks of VOS, DAVIS, and FBMS.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",22.857142857142854,0.19246031746031747,0.4363095238095238,1,0.12562814070351758,0.010050251256281407,0.37142857142857144
1845,1884,1884,A weakly supervised fine label classifier enhanced by coarse supervision,"Objects are usually organized in a hierarchical structure in which each coarse category (e.g., big cat) corresponds to a superclass of several fine categories (e.g., cheetah, leopard). The objects grouped within the same coarse category, but in different fine categories, usually share a set of global visual features; however, these objects have distinctive local properties that characterize them at a fine level. This paper addresses the challenge of fine image classification in a weakly supervised fashion, whereby a subset of images is tagged by fine labels, while the remaining are tagged by coarse labels. We propose a new deep model that leverages coarse images to improve the classification performance of fine images within the coarse category. Our model is an end to end framework consisting of a Convolutional Neural Network (CNN) which uses both fine and coarse images to tune its parameters. The CNN outputs are then fanned out into two separate branches such that the first branch uses a supervised low rank self expressive layer to project the CNN outputs to the low rank subspaces to capture the global structures for the coarse classification, while the other branch uses a supervised sparse self expressive layer to project them to the sparse subspaces to capture the local structures for the fine classification. Our deep model uses coarse images in conjunction with fine images to jointly explore the low rank and sparse subspaces by sharing the parameters during the training which causes the data points obtained by the CNN to be well-projected to both sparse and low rank subspaces for classification.",60021143,West Virginia University,Morgantown,United States,"['1712', '1707']",37.142857142857146,0.03414141414141413,0.4380639730639731,1,0.11228070175438597,0.028070175438596492,0.2826855123674912
1846,1885,1885,Generating easy-to-understand referring expressions for target identifications,"This paper addresses the generation of referring expressions that not only refer to objects correctly but also let humans find them quickly. As a target becomes relatively less salient, identifying referred objects itself becomes more difficult. However, the existing studies regarded all sentences that refer to objects correctly as equally good, ignoring whether they are easily understood by humans. If the target is not salient, humans utilize relationships with the salient contexts around it to help listeners to comprehend it better. To derive this information from human annotations, our model is designed to extract information from the target and from the environment. Moreover, we regard that sentences that are easily understood are those that are comprehended correctly and quickly by humans. We optimized this by using the time required to locate the referred objects by humans and their accuracies. To evaluate our system, we created a new referring expression dataset whose images were acquired from Grand Theft Auto V (GTA V), limiting targets to persons. Experimental results show the effectiveness of our approach. Our code and dataset are available at https://github.com/mikittt/easy-to-understand-REG.",60025272,University of Tokyo,Tokyo,Japan,"['1712', '1707']",18.1,0.2468686868686869,0.5791919191919191,1,0.1691542288557214,0.029850746268656716,0.3645320197044335
1847,1886,1886,Design and implementation of energy saving monitoring and management system on campus based on internet of things technology,"Campus energy consumption has many kinds with large total amount, which leads to great energy-saving potential. With the rapid development of Internet of Things (IoT) technology and sensor technology, it is possible to achieve large-scale campus energy management. Taking the energy saving monitoring and management platform of Shandong University at Weihai as an example, this paper designs and realizes an energy management system based on IoT. Using distributed acquisition and centralized management technology, an IoT system is established by installing data acquisition terminals in the whole campus, which can transmit real-time data through network and realize data collection, data storage, data organization, data analysis, and data publishing in real time. This paper introduces the architecture design of the platform and its software implementation, describes the key technical segments in detail, and displays some functions of the system. The establishment of the platform improved the efficiency of campus energy use, which provides technical means for upgrading the modernization level of campus energy management.",60108071,"Shandong University, Weihai",Weihai,China,['1700'],27.0,0.174025974025974,0.5753246753246753,1,0.11229946524064172,0.03208556149732621,0.3076923076923077
1848,1887,1887,Expert sample consensus applied to camera re-localization,"Fitting model parameters to a set of noisy data points is a common problem in computer vision. In this work, we fit the 6D camera pose to a set of noisy correspondences between the 2D input image and a known 3D environment. We estimate these correspondences from the image using a neural network. Since the correspondences often contain outliers, we utilize a robust estimator such as Random Sample Consensus (RANSAC) or Differentiable RANSAC (DSAC) to fit the pose parameters. When the problem domain, e.g. the space of all 2D-3D correspondences, is large or ambiguous, a single network does not cover the domain well. Mixture of Experts (MoE) is a popular strategy to divide a problem domain among an ensemble of specialized networks, so called experts, where a gating network decides which expert is responsible for a given input. In this work, we introduce Expert Sample Consensus (ESAC), which integrates DSAC in a MoE. Our main technical contribution is an efficient method to train ESAC jointly and end-to-end. We demonstrate experimentally that ESAC handles two real-world problems better than competing methods, i.e. scalability and ambiguity. We apply ESAC to fitting simple geometric models to synthetic images, and to camera re-localization for difficult, real datasets.",60016908,Universität Heidelberg,Heidelberg,Germany,"['1712', '1707']",16.916666666666664,0.13386243386243388,0.4657407407407407,1,0.09166666666666666,0.06666666666666667,0.3872340425531915
1849,1888,1888,Pro-cam SSfM: Projector-camera system for structure and spectral reflectance from motion,"In this paper, we propose a novel projector-camera system for practical and low-cost acquisition of a dense object 3D model with the spectral reflectance property. In our system, we use a standard RGB camera and leverage an off-the-shelf projector as active illumination for both the 3D reconstruction and the spectral reflectance estimation. We first reconstruct the 3D points while estimating the poses of the camera and the projector, which are alternately moved around the object, by combining multi-view structured light and structure-from-motion (SfM) techniques. We then exploit the projector for multispectral imaging and estimate the spectral reflectance of each 3D point based on a novel spectral reflectance estimation model considering the geometric relationship between the reconstructed 3D points and the estimated projector positions. Experimental results on several real objects demonstrate that our system can precisely acquire a dense 3D model with the full spectral reflectance property using off-the-shelf devices.",60031126,Tokyo Institute of Technology,Tokyo,Japan,"['1712', '1707']",29.8,0.15666666666666668,0.3683333333333333,1,0.0898876404494382,0.0056179775280898875,0.275
1850,1889,1889,Memory-based neighbourhood embedding for visual recognition,"Learning discriminative image feature embeddings is of great importance to visual recognition. To achieve better feature embeddings, most current methods focus on designing different network structures or loss functions, and the estimated feature embeddings are usually only related to the input images. In this paper, we propose Memory-based Neighbourhood Embedding (MNE) to enhance a general CNN feature by considering its neighbourhood. The method aims to solve two critical problems, i.e., how to acquire more relevant neighbours in the network training and how to aggregate the neighbourhood information for a more discriminative embedding. We first augment an episodic memory module into the network, which can provide more relevant neighbours for both training and testing. Then the neighbours are organized in a tree graph with the target instance as the root node. The neighbourhood information is gradually aggregated to the root node in a bottom-up manner, and aggregation weights are supervised by the class relationships between the nodes. We apply MNE on image search and few shot learning tasks. Extensive ablation studies demonstrate the effectiveness of each component, and our method significantly outperforms the state-of-the-art approaches.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.444444444444443,0.2407894736842105,0.5469298245614036,1,0.10328638497652583,0.023474178403755867,0.30049261083743845
1851,1890,1890,The method of urban intelligent address coding based on spatiotemporal semantics,"With the development of science and technology and the progress of society, urban construction in China is also developing rapidly. Intelligent address coding plays an important role in urban planning and design. Therefore, the study of smart urban address coding method can make a great contribution to the construction of a smart city. Based on the analysis of the correlation between urban intelligent address coding method and the development of smart city, this paper discusses a scientific and unified standard urban intelligent address coding method based on spatiotemporal semantics. And based on the theory of spatiotemporal semantic model and address model, an intelligent address model based on spatiotemporal semantics is designed according to the address coding standard published in recent years in China. To solve the problems of non-standard city place name and address coding, difficulty in managing address coding data, and imprecision of address coding, thus the unified standardization and refinement of the urban address code, the intelligent management of the urban address code data and the sharing of the urban address code data are realized.",60006356,Guilin University of Technology,Guilin,China,['1700'],29.5,0.2782312925170068,0.4013605442176871,1,0.08808290155440414,0.025906735751295335,0.21465968586387435
1852,1891,1891,Many task learning with task routing,"Typical multi-task learning (MTL) methods rely on architectural adjustments and a large trainable parameter set to jointly optimize over several tasks. However, when the number of tasks increases so do the complexity of the architectural adjustments and resource requirements. In this paper, we introduce a method which applies a conditional feature-wise transformation over the convolutional activations that enables a model to successfully perform a large number of tasks. To distinguish from regular MTL, we introduce Many Task Learning (MaTL) as a special case of MTL where more than 20 tasks are performed by a single model. Our method dubbed Task Routing (TR) is encapsulated in a layer we call the Task Routing Layer (TRL), which applied in an MaTL scenario successfully fits hundreds of classification tasks in one model. We evaluate on 5 datasets and the Visual Decathlon (VD) challenge against strong baselines and state-of-the-art approaches.",60002483,Universiteit van Amsterdam,Amsterdam,Netherlands,"['1712', '1707']",24.33333333333333,0.26776556776556776,0.450239504085658,1,0.09090909090909091,0.09659090909090909,0.42168674698795183
1853,1892,1892,Continual learning by asymmetric loss approximation with single-side overestimation,"Catastrophic forgetting is a critical challenge in training deep neural networks. Although continual learning has been investigated as a countermeasure to the problem, it often suffers from the requirements of additional network components and the limited scalability to a large number of tasks. We propose a novel approach to continual learning by approximating a true loss function using an asymmetric quadratic function with one of its sides overestimated. Our algorithm is motivated by the empirical observation that the network parameter updates affect the target loss functions asymmetrically. In the proposed continual learning framework, we estimate an asymmetric loss function for the tasks considered in the past through a proper overestimation of its unobserved sides in training new tasks, while deriving the accurate model parameter for the observable sides. In contrast to existing approaches, our method is free from the side effects and achieves the state-of-the-art accuracy that is even close to the upper-bound performance on several challenging benchmark datasets.",60120116,Automation and Systems Research Institute,Seoul,South Korea,"['1712', '1707']",26.5,0.0842300556586271,0.4613790970933828,1,0.1016949152542373,0.0,0.2485207100591716
1854,1893,1893,Depth completion from sparse LiDAR data with depth-normal constraints,"Depth completion aims to recover dense depth maps from sparse depth measurements. It is of increasing importance for autonomous driving and draws increasing attention from the vision community. Most of the current competitive methods directly train a network to learn a mapping from sparse depth inputs to dense depth maps, which has difficulties in utilizing the 3D geometric constraints and handling the practical sensor noises. In this paper, to regularize the depth completion and improve the robustness against noise, we propose a unified CNN framework that 1) models the geometric constraints between depth and surface normal in a diffusion module and 2) predicts the confidence of sparse LiDAR measurements to mitigate the impact of noise. Specifically, our encoder-decoder backbone predicts the surface normal, coarse depth and confidence of LiDAR inputs simultaneously, which are subsequently inputted into our diffusion refinement module to obtain the final completion results. Extensive experiments on KITTI depth completion dataset and NYU-Depth-V2 dataset demonstrate that our method achieves state-of-the-art performance. Further ablation study and analysis give more insights into the proposed components and demonstrate the generalization capability and stability of our model.",60003970,Zhejiang University,Hangzhou,China,"['1712', '1707']",26.42857142857143,0.15,0.5152777777777777,1,0.10849056603773585,0.018867924528301886,0.3
1855,1894,1894,Robust variational bayesian point set registration,"In this work, we propose a hierarchical Bayesian network based point set registration method to solve missing correspondences and various massive outliers. We construct this network first using the finite Student s t latent mixture model (TLMM), in which distributions of latent variables are estimated by a tree-structured variational inference (VI) so that to obtain a tighter lower bound under the Bayesian framework. We then divide the TLMM into two different mixtures with isotropic and anisotropic covariances for correspondences recovering and outliers identification, respectively. Finally, the parameters of mixing proportion and covariances are both taken as latent variables, which benefits explaining of missing correspondences and heteroscedastic outliers. In addition, a cooling schedule is adopted to anneal prior on covariances and scale variables within designed two phases of transformation, it anneal priors on global and local variables to perform a coarse-to- fine registration. In experiments, our method outperforms five state-of-the-art methods in synthetic point set and realistic imaging registrations.",60019218,Yunnan Normal University,Kunming,China,"['1712', '1707']",26.33333333333333,0.03611111111111112,0.3638888888888889,1,0.12365591397849462,0.016129032258064516,0.3522727272727273
1856,1895,1895,Adaptive density map generation for crowd counting,"Crowd counting is an important topic in computer vision due to its practical usage in surveillance systems. The typical design of crowd counting algorithms is divided into two steps. First, the ground-truth density maps of crowd images are generated from the ground-truth dot maps (density map generation), e.g., by convolving with a Gaussian kernel. Second, deep learning models are designed to predict a density map from an input image (density map estimation). Most research efforts have concentrated on the density map estimation problem, while the problem of density map generation has not been adequately explored. In particular, the density map could be considered as an intermediate representation used to train a crowd counting network. In the sense of end-to-end training, the hand-crafted methods used for generating the density maps may not be optimal for the particular network or dataset used. To address this issue, we first show the impact of different density maps and that better ground-truth density maps can be obtained by refining the existing ones using a learned refinement network, which is jointly trained with the counter. Then, we propose an adaptive density map generator, which takes the annotation dot map as input, and learns a density map representation for a counter. The counter and generator are trained jointly within an end-to-end framework. The experiment results on popular counting datasets confirm the effectiveness of the proposed learnable density map representations.",60013983,City University of Hong Kong,Kowloon,Hong Kong,"['1712', '1707']",21.09090909090909,0.20535714285714288,0.4601190476190476,1,0.11636363636363636,0.0036363636363636364,0.26640926640926643
1857,1896,1896,Scaling recurrent models via orthogonal approximations in tensor trains,"Modern deep networks have proven to be very effective for analyzing real world images. However, their application in medical imaging is still in its early stages, primarily due to the large size of three-dimensional images, requiring enormous convolutional or fully connected layers - if we treat an image (and not image patches) as a sample. These issues only compound when the focus moves towards longitudinal analysis of 3D image volumes through recurrent structures, and when a point estimate of model parameters is insufficient in scientific applications where a reliability measure is necessary. Using insights from differential geometry, we adapt the tensor train decomposition to construct networks with significantly fewer parameters, allowing us to train powerful recurrent networks on whole brain image volume sequences. We describe the 'orthogonal' tensor train, and demonstrate its ability to express a standard network layer both theoretically and empirically. We show its ability to effectively reconstruct whole brain volumes with faster convergence and stronger confidence intervals compared to the standard tensor train decomposition. We provide code and show experiments on the ADNI dataset using image sequences to regress on a cognition related outcome.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",26.714285714285715,0.1497278911564626,0.4799319727891157,1,0.10628019323671498,0.004830917874396135,0.28921568627450983
1858,1897,1897,A non-contact and unconstrained sleep health monitoring system,"Clinically, polysomnography (PSG) is used to assess sleep quality by monitoring various parameters, such as Electroencephalogram (EEG), electrocardiogram (ECG), Electrooculography (EOG), Electromyography (EMG), pulse, oxygen saturation, and respiratory rate. However, in order to assess these parameters, PSG requires a variety of sensors that must make direct contact with patients’ bodies, which can affect patients’ quality of sleep during testing. Thus, the use of PSG to assess sleep quality can yield invalid and inaccurate results. To address this gap, this paper proposes a sleep health monitoring system that has no restraints and does not interfere with sleep. This method collects ballistocardiogram (BCG) due to ejection by placing a piezoelectric film sensor under a sleeping cushion and evaluates three indicators: heart rate variability (HRV), respiration, and body movements. The ECG and BCG of 10 subjects were collected synchronously while the subjects were lying flat. Specifically, power-line interference was eliminated by adaptive digital filtering with a minimum mean square. A paired t-test revealed that there were no significant differences between BCG and standard ECG signals in the time-domain, frequency-domain, and nonlinear parameters of HRV. Respiration and body motion were extracted from the BCG in order to effectively monitoring of sleep apnea and nighttime bed-off times. Compared with other non-contact monitoring methods, such as acceleration sensors, coupling electrodes, Doppler radar and camera, the system presented in this paper is superior, as it has high signal quality, strong anti-interference ability, and low cost. Moreover, it does not interfere with normal sleep.",60028265,Lanzhou University,Lanzhou,China,['1700'],22.363636363636363,0.08049019607843136,0.4859313725490197,1,0.09554140127388536,0.06369426751592357,0.4066666666666667
1859,1898,1898,LIP: Local importance-based pooling,"Spatial downsampling layers are favored in convolutional neural networks (CNNs) to downscale feature maps for larger receptive fields and less memory consumption. However, for discriminative tasks, there is a possibility that these layers lose the discriminative details due to improper pooling strategies, which could hinder the learning process and eventually result in suboptimal models. In this paper, we present a unified framework over the existing downsampling layers (e.g., average pooling, max pooling, and strided convolution) from a local importance view. In this framework, we analyze the issues of these widely-used pooling layers and figure out the criteria for designing an effective downsampling layer. According to this analysis, we propose a conceptually simple, general, and effective pooling layer based on local importance modeling, termed as Local Importance-based Pooling (LIP). LIP can automatically enhance discriminative features during the downsampling procedure by learning adaptive importance weights based on inputs. Experiment results show that LIP consistently yields notable gains with different depths and different architectures on ImageNet classification. In the challenging MS COCO dataset, detectors with our LIP-ResNets as backbones obtain a consistent improvement (>=1.4%) over the vanilla ResNets, and especially achieve the current state-of-the-art performance in detecting small objects under the single-scale testing scheme.",60033100,Nanjing University,Nanjing,China,"['1712', '1707']",25.125,0.1299242424242424,0.4408549783549784,1,0.12096774193548387,0.05241935483870968,0.41201716738197425
1860,1899,1899,Learning compositional neural information fusion for human parsing,"This work proposes to combine neural networks with the compositional hierarchy of human bodies for efficient and complete human parsing. We formulate the approach as a neural information fusion framework. Our model assembles the information from three inference processes over the hierarchy: Direct inference (directly predicting each part of a human body using image information), bottom-up inference (assembling knowledge from constituent parts), and top-down inference (leveraging context from parent nodes). The bottom-up and top-down inferences explicitly model the compositional and decompositional relations in human bodies, respectively. In addition, the fusion of multi-source information is conditioned on the inputs, i.e., by estimating and considering the confidence of the sources. The whole model is end-to-end differentiable, explicitly modeling information flows and structures. Our approach is extensively evaluated on four popular datasets, outperforming the state-of-the-arts in all cases, with a fast processing speed of 23fps. Our code and results have been released to help ease future research in this direction.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",19.625,0.1,0.3121794871794872,1,0.08955223880597014,0.0,0.3756906077348066
1861,1900,1900,Multi-stage pathological image classification using semantic segmentation,"Histopathological image analysis is an essential process for the discovery of diseases such as cancer. However, it is challenging to train CNN on whole slide images (WSIs) of gigapixel resolution considering the available memory capacity. Most of the previous works divide high resolution WSIs into small image patches and separately input them into the model to classify it as a tumor or a normal tissue. However, patch-based classification uses only patch-scale local information but ignores the relationship between neighboring patches. If we consider the relationship of neighboring patches and global features, we can improve the classification performance. In this paper, we propose a new model structure combining the patch-based classification model and whole slide-scale segmentation model in order to improve the prediction performance of automatic pathological diagnosis. We extract patch features from the classification model and input them into the segmentation model to obtain a whole slide tumor probability heatmap. The classification model considers patch-scale local features, and the segmentation model can take global information into account. We also propose a new optimization method that retains gradient information and trains the model partially for end-to-end learning with limited GPU memory capacity. We apply our method to the tumor/normal prediction on WSIs and the classification performance is improved compared with the conventional patch-based method.",60025272,University of Tokyo,Tokyo,Japan,"['1712', '1707']",21.3,0.08417158598976779,0.3802617079889808,1,0.125,0.020161290322580645,0.25217391304347825
1862,1901,1901,GSLAM: A general SLAM framework and benchmark,"SLAM technology has recently seen many successes and attracted the attention of high-technological companies. However, how to unify the interface of existing or emerging algorithms, and effectively perform benchmark about the speed, robustness and portability are still problems. In this paper, we propose a novel SLAM platform named GSLAM, which not only provides evaluation functionality, but also supplies useful toolkit for researchers to quickly develop their SLAM systems. Our core contribution is an universal, cross-platform and full open-source SLAM interface for both research and commercial usage, which is aimed to handle interactions with input dataset, SLAM implementation, visualization and applications in an unified framework. Through this platform, users can implement their own functions for better performance with plugin form and further boost the application to practical usage of the SLAM.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",26.0,0.2652777777777778,0.4666666666666666,1,0.10526315789473684,0.013157894736842105,0.3561643835616438
1863,1902,1902,SinGAN: Learning a generative model from a single natural image,"We introduce SinGAN, an unconditional generative model that can be learned from a single natural image. Our model is trained to capture the internal distribution of patches within the image, and is then able to generate high quality, diverse samples that carry the same visual content as the image. SinGAN contains a pyramid of fully convolutional GANs, each responsible for learning the patch distribution at a different scale of the image. This allows generating new samples of arbitrary size and aspect ratio, that have significant variability, yet maintain both the global structure and the fine textures of the training image. In contrast to previous single image GAN schemes, our approach is not limited to texture images, and is not conditional (i.e. it generates samples from noise). User studies confirm that the generated samples are commonly confused to be real images. We illustrate the utility of SinGAN in a wide range of image manipulation tasks.",60022403,Technion - Israel Institute of Technology,Haifa,Israel,"['1712', '1707']",19.25,0.060711038961038966,0.3703820346320347,1,0.10526315789473684,0.005847953216374269,0.2616279069767442
1864,1903,1903,Neighborhood preserving hashing for scalable video retrieval,"In this paper, we propose a Neighborhood Preserving Hashing (NPH) method for scalable video retrieval in an unsupervised manner. Unlike most existing deep video hashing methods which indiscriminately compress an entire video into a binary code, we embed the spatial-temporal neighborhood information into the encoding network such that the neighborhood-relevant visual content of a video can be preferentially encoded into a binary code under the guidance of the neighborhood information. Specifically, we propose a neighborhood attention mechanism which focuses on partial useful content of each input frame conditioned on the neighborhood information. We then integrate the neighborhood attention mechanism into an RNN-based reconstruction scheme to encourage the binary codes to capture the spatial-temporal structure in a video which is consistent with that in the neighborhood. As a consequence, the learned hashing functions can map similar videos to similar binary codes. Extensive experiments on three widely-used benchmark datasets validate the effectiveness of our proposed approach.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",25.66666666666667,0.08636363636363636,0.3371212121212121,1,0.10795454545454546,0.028409090909090908,0.2469879518072289
1865,1904,1904,Unsupervised microvascular image segmentation using an active contours mimicking neural network,"The task of blood vessel segmentation in microscopy images is crucial for many diagnostic and research applications. However, vessels can look vastly different, depending on the transient imaging conditions, and collecting data for supervised training is laborious. We present a novel deep learning method for unsupervised segmentation of blood vessels. The method is inspired by the field of active contours and we introduce a new loss term, which is based on the morphological Active Contours Without Edges (ACWE) optimization method. The role of the morphological operators is played by novel pooling layers that are incorporated to the network's architecture. We demonstrate the challenges that are faced by previous supervised learning solutions, when the imaging conditions shift. Our unsupervised method is able to outperform such previous methods in both the labeled dataset, and when applied to similar but different datasets. Our code, as well as efficient pytorch reimplementations of the baseline methods VesselNN and DeepVess are attached as supplementary.",60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,"['1712', '1707']",19.75,0.03831168831168832,0.4723484848484849,1,0.10227272727272728,0.03409090909090909,0.3181818181818182
1866,1905,1905,Learning filter basis for convolutional neural network compression,"Convolutional neural networks (CNNs) based solutions have achieved state-of-the-art performances for many computer vision tasks, including classification and super-resolution of images. Usually the success of these methods comes with a cost of millions of parameters due to stacking deep convolutional layers. Moreover, quite a large number of filters are also used for a single convolutional layer, which exaggerates the parameter burden of current methods. Thus, in this paper, we try to reduce the number of parameters of CNNs by learning a basis of the filters in convolutional layers. For the forward pass, the learned basis is used to approximate the original filters and then used as parameters for the convolutional layers. We validate our proposed solution for multiple CNN architectures on image classification and image super-resolution benchmarks and compare favorably to the existing state-of-the-art in terms of reduction of parameters and preservation of accuracy. Code is available at https://github.com/ofsoundof/learning-filter-basis.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",21.285714285714285,0.07857142857142857,0.35982142857142857,1,0.09444444444444444,0.016666666666666666,0.3433734939759036
1867,1906,1906,Towards high-resolution salient object detection,"Deep neural network based methods have made a significant breakthrough in salient object detection. However, they are typically limited to input images with low resolutions (400×400 pixels or less). Little effort has been made to train neural networks to directly handle salient object segmentation in high-resolution images. This paper pushes forward high-resolution saliency detection, and contributes a new dataset, named High-Resolution Salient Object Detection (HRSOD) dataset. To our best knowledge, HRSOD is the first high-resolution saliency detection dataset to date. As another contribution, we also propose a novel approach, which incorporates both global semantic information and local high-resolution details, to address this challenging task. More specifically, our approach consists of a Global Semantic Network (GSN), a Local Refinement Network (LRN) and a Global-Local Fusion Network (GLFN). The GSN extracts the global semantic information based on downsampled entire image. Guided by the results of GSN, the LRN focuses on some local regions and progressively produces high-resolution predictions. The GLFN is further proposed to enforce spatial consistency and boost performance. Experiments illustrate that our method outperforms existing state-of-the-art methods on high-resolution saliency datasets by a large margin, and achieves comparable or even better performance than them on some widely used saliency benchmarks.",60076047,Adobe Inc.,San Jose,United States,"['1712', '1707']",18.181818181818183,0.13261104837191792,0.33591191417278377,1,0.1141732283464567,0.09448818897637795,0.4525862068965517
1868,1907,1907,Consensus maximization tree search revisited,"Consensus maximization is widely used for robust fitting in computer vision. However, solving it exactly, i.e., finding the globally optimal solution, is intractable. A∗ tree search, which has been shown to be fixed-parameter tractable, is one of the most efficient exact methods, though it is still limited to small inputs. We make two key contributions towards improving A∗ tree search. First, we show that the consensus maximization tree structure used previously actually contains paths that connect nodes at both adjacent and non-adjacent levels. Crucially, paths connecting non-adjacent levels are redundant for tree search, but they were not avoided previously. We propose a new acceleration strategy that avoids such redundant paths. In the second contribution, we show that the existing branch pruning technique also deteriorates quickly with the problem dimension. We then propose a new branch pruning technique that is less dimension-sensitive to address this issue. Experiments show that both new techniques can significantly accelerate A∗ tree search, making it reasonably efficient on inputs that were previously out of reach. Demo code is available at https://github.com/ZhipengCai/MaxConTreeSearch.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",15.909090909090908,0.08253829503829503,0.3813394938394938,1,0.12135922330097088,0.009708737864077669,0.315
1869,1908,1908,ThunderNet: Towards real-time generic object detection on mobile devices,"Real-time generic object detection on mobile platforms is a crucial but challenging computer vision task. Prior lightweight CNN-based detectors are inclined to use one-stage pipeline. In this paper, we investigate the effectiveness of two-stage detectors in real-time generic detection and propose a lightweight two-stage detector named ThunderNet. In the backbone part, we analyze the drawbacks in previous lightweight backbones and present a lightweight backbone designed for object detection. In the detection part, we exploit an extremely efficient RPN and detection head design. To generate more discriminative feature representation, we design two efficient architecture blocks, Context Enhancement Module and Spatial Attention Module. At last, we investigate the balance between the input resolution, the backbone, and the detection head. Benefit from the highly efficient backbone and detection part design, ThunderNet surpasses previous lightweight one-stage detectors with only 40% of the computational cost on PASCAL VOC and COCO benchmarks. Without bells and whistles, ThunderNet runs at 24.1 fps on an ARM-based device with 19.2 AP on COCO. To the best of our knowledge, this is the first real-time detector reported on ARM platforms. Code will be released for paper reproduction.",60024350,National University of Defense Technology,Changsha,China,"['1712', '1707']",17.0,0.13011111111111112,0.4048888888888889,1,0.09210526315789473,0.07456140350877193,0.38095238095238093
1870,1909,1909,Self-ensembling with GAN-based data augmentation for domain adaptation in semantic segmentation,"Deep learning-based semantic segmentation methods have an intrinsic limitation that training a model requires a large amount of data with pixel-level annotations. To address this challenging issue, many researchers give attention to unsupervised domain adaptation for semantic segmentation. Unsupervised domain adaptation seeks to adapt the model trained on the source domain to the target domain. In this paper, we introduce a self-ensembling technique, one of the successful methods for domain adaptation in classification. However, applying self-ensembling to semantic segmentation is very difficult because heavily-tuned manual data augmentation used in self-ensembling is not useful to reduce the large domain gap in the semantic segmentation. To overcome this limitation, we propose a novel framework consisting of two components, which are complementary to each other. First, we present a data augmentation method based on Generative Adversarial Networks (GANs), which is computationally efficient and effective to facilitate domain alignment. Given those augmented images, we apply self-ensembling to enhance the performance of the segmentation network on the target domain. The proposed method outperforms state-of-the-art semantic segmentation methods on unsupervised domain adaptation benchmarks.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1707']",19.666666666666668,0.17529761904761906,0.5179563492063491,1,0.12903225806451613,0.013824884792626729,0.28426395939086296
1871,1910,1910,Batch dropblock network for person re-identification and beyond,"Since the person re-identification task often suffers from the problem of pose changes and occlusions, some attentive local features are often suppressed when training CNNs. In this paper, we propose the Batch DropBlock (BDB) Network which is a two branch network composed of a conventional ResNet-50 as the global branch and a feature dropping branch.The global branch encodes the global salient representations.Meanwhile, the feature dropping branch consists of an attentive feature learning module called Batch DropBlock, which randomly drops the same region of all input feature maps in a batch to reinforce the attentive feature learning of local regions.The network then concatenates features from both branches and provides a more comprehensive and spatially distributed feature representation. Albeit simple, our method achieves state-of-the-art on person re-identification and it is also applicable to general metric learning tasks. For instance, we achieve 76.4% Rank-1 accuracy on the CUHK03-Detect dataset and 83.0% Recall-1 score on the Stanford Online Products dataset, outperforming the existed works by a large margin (more than 6%).",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",41.75,0.07184873949579833,0.3922268907563025,1,0.0945273631840796,0.05970149253731343,0.34054054054054056
1872,1911,1911,Corporate governance the journey of Indian corporate world," Be it the boardroom fight or the CEO and CFO conievance or the management-auditor hand in glove story, each has lead to some corporate fraud or disruption. In this preocess, the biggest loser has been the investor, who ultimately bears the burnt of the mismanagement or deficit in governance of the corporate affairs. This is a global phenomena and India being a part of the global economy, also suffers from such deficits.There are many regulations in the international scenario. The most important ones are the OECD guidelines, SOX of USA, Cadbury Committee report of UK. In India SEBI has formulated many rules including the listing agreement under clause 49 based on the recommendations of different committees. Through this study an attempt has been made to understand how the framework has evolved over a period of time in India and how many of the large sized accounting frauds have taken place due to poor Corporate governance mechanism in place.",60099680,"Xavier Institute of Management, Bhubaneshwar",Bhubaneswar,India,['1706'],26.5,0.08273809523809524,0.4001984126984127,0,0.05142857142857143,0.06857142857142857,0.3
1873,1912,1912,Photo-realistic monocular gaze redirection using generative adversarial networks,"Gaze redirection is the task of changing the gaze to a desired direction for a given monocular eye patch image. Many applications such as videoconferencing, films, games, and generation of training data for gaze estimation require redirecting the gaze, without distorting the appearance of the area surrounding the eye and while producing photo-realistic images. Existing methods lack the ability to generate perceptually plausible images. In this work, we present a novel method to alleviate this problem by leveraging generative adversarial training to synthesize an eye image conditioned on a target gaze direction. Our method ensures perceptual similarity and consistency of synthesized images to the real images. Furthermore, a gaze estimation loss is used to control the gaze direction accurately. To attain high-quality images, we incorporate perceptual and cycle consistency losses into our architecture. In extensive evaluations we show that the proposed method outperforms state-of-the-art approaches in terms of both image quality and redirection precision. Finally, we show that generated images can bring significant improvement for the gaze estimation task if used to augment real training data.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",19.555555555555557,0.21750000000000005,0.4941666666666668,1,0.15270935960591134,0.0049261083743842365,0.2849740932642487
1874,1913,1913,U4D: Unsupervised 4D dynamic scene understanding,"We introduce the first approach to solve the challenging problem of unsupervised 4D visual scene understanding for complex dynamic scenes with multiple interacting people from multi-view video. Our approach simultaneously estimates a detailed model that includes a per-pixel semantically and temporally coherent reconstruction, together with instance-level segmentation exploiting photo-consistency, semantic and motion information. We further leverage recent advances in 3D pose estimation to constrain the joint semantic instance segmentation and 4D temporally coherent reconstruction. This enables per person semantic instance segmentation of multiple interacting people in complex dynamic scenes. Extensive evaluation of the joint visual scene understanding framework against state-of-the-art methods on challenging indoor and outdoor sequences demonstrates a significant (approx 40%) improvement in semantic segmentation, reconstruction and scene flow accuracy.",60021097,University of Surrey,Guildford,United Kingdom,"['1712', '1707']",24.2,0.13472222222222222,0.4208333333333334,1,0.08904109589041095,0.0,0.30303030303030304
1875,1914,1914,Minimum delay object detection from video,"We consider the problem of detecting objects, as they come into view, from videos in an online fashion. We provide the first real-time solution that is guaranteed to minimize the delay, i.e., the time between when the object comes in view and the declared detection time, subject to acceptable levels of detection accuracy. The method leverages modern CNN-based object detectors that operate on a single frame, to aggregate detection results over frames to provide reliable detection at a rate, specified by the user, in guaranteed minimal delay. To do this, we formulate the problem as a Quickest Detection problem, which provides the aforementioned guarantees. We derive our algorithms from this theory. We show in experiments, that with an overhead of just 50 fps, we can increase the number of correct detections and decrease the overall computational cost compared to running a modern single-frame detector.",60092945,King Abdullah University of Science and Technology,Jeddah,Saudi Arabia,"['1712', '1707']",24.0,0.03898809523809524,0.2601190476190476,1,0.13690476190476192,0.017857142857142856,0.30864197530864196
1876,1915,1915,The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs,"Developing safe human-robot interaction systems is a necessary step towards the widespread integration of autonomous agents in society. A key component of such systems is the ability to reason about the many potential futures (e.g. trajectories) of other agents in the scene. Towards this end, we present the Trajectron, a graph-structured model that predicts many potential future trajectories of multiple agents simultaneously in both highly dynamic and multimodal scenarios (i.e. where the number of agents in the scene is time-varying and there are many possible highly-distinct futures for each agent). It combines tools from recurrent sequence modeling and variational deep generative modeling to produce a distribution of future trajectories for each agent in a scene. We demonstrate the performance of our model on several datasets, obtaining state-of-the-art results on standard trajectory prediction metrics as well as introducing a new metric for comparing models that output distributions.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",20.857142857142858,0.11482683982683982,0.4688672438672439,1,0.06395348837209303,0.011627906976744186,0.3
1877,1916,1916,Domain-adaptive single-view 3D reconstruction,"Single-view 3D shape reconstruction is an important but challenging problem, mainly for two reasons. First, as shape annotation is very expensive to acquire, current methods rely on synthetic data, in which ground-truth 3D annotation is easy to obtain. However, this results in domain adaptation problem when applied to natural images. The second challenge is that there are multiple shapes that can explain a given 2D image. In this paper, we propose a framework to improve over these challenges using adversarial training. On one hand, we impose domain confusion between natural and synthetic image representations to reduce the distribution gap. On the other hand, we impose the reconstruction to be 'realistic' by forcing it to lie on a (learned) manifold of realistic object shapes. Our experiments show that these constraints improve performance by a large margin over baseline reconstruction models. We achieve results competitive with the state of the art with a much simpler architecture.",123285757,Rutgers University,New Jersey,United States,"['1712', '1707']",17.11111111111111,0.1201636904761905,0.455014880952381,1,0.11731843575418995,0.0,0.28160919540229884
1878,1917,1917,Learning two-view correspondences and geometry using order-aware network,"Establishing correspondences between two images requires both local and global spatial context. Given putative correspondences of feature points in two views, in this paper, we propose Order-Aware Network, which infers the probabilities of correspondences being inliers and regresses the relative pose encoded by the essential matrix. Specifically, this proposed network is built hierarchically and comprises three novel operations. First, to capture the local context of sparse correspondences, the network clusters unordered input correspondences by learning a soft assignment matrix. These clusters are in a canonical order and invariant to input permutations. Next, the clusters are spatially correlated to form the global context of correspondences. After that, the context-encoded clusters are recovered back to the original size through a proposed upsampling operator. We intensively experiment on both outdoor and indoor datasets. The accuracy of the two-view geometry and correspondences are significantly improved over the state-of-the-arts.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",16.0,0.07948717948717947,0.2314102564102564,1,0.11560693641618497,0.011560693641618497,0.36645962732919257
1879,1918,1918,FiNet: Compatible and diverse fashion image inpainting,"Visual compatibility is critical for fashion analysis, yet is missing in existing fashion image synthesis systems. In this paper, we propose to explicitly model visual compatibility through fashion image inpainting. We present Fashion Inpainting Networks (FiNet), a two-stage image-to-image generation framework that is able to perform compatible and diverse inpainting. Disentangling the generation of shape and appearance to ensure photorealistic results, our framework consists of a shape generation network and an appearance generation network. More importantly, for each generation network, we introduce two encoders interacting with one another to learn latent codes in a shared compatibility space. The latent representations are jointly optimized with the corresponding generation network to condition the synthesis process, encouraging a diverse set of generated results that are visually compatible with existing fashion garments. In addition, our framework is readily extended to clothing reconstruction and fashion transfer. Extensive experiments on fashion synthesis quantitatively and qualitatively demonstrate the effectiveness of our method.",60113057,"Malong Technologies Co., Ltd.",Shenzhen,China,"['1712', '1707']",19.375,0.1272727272727273,0.34621212121212125,1,0.11731843575418995,0.0223463687150838,0.2832369942196532
1880,1919,1919,Neural re-simulation for generating bounces in single images,"We introduce a method to generate videos of dynamic virtual objects plausibly interacting via collisions with a still image's environment. Given a starting trajectory, physically simulated with the estimated geometry of a single, static input image, we learn to 'correct' this trajectory to a visually plausible one via a neural network. The neural network can then be seen as learning to 'correct' traditional simulation output, generated with incomplete and imprecise world information, to obtain context-specific, visually plausible re-simulated output - a process we call neural re-simulation. We train our system on a set of 50k synthetic scenes where a virtual moving object (ball) has been physically simulated. We demonstrate our approach on both our synthetic dataset and a collection of real-life images depicting everyday scenes, obtaining consistent improvement over baseline alternatives throughout.",60022148,UCL,London,United Kingdom,"['1712', '1707']",26.4,0.16488095238095238,0.3972222222222222,1,0.12578616352201258,0.0,0.3087248322147651
1881,1920,1920,View-LSTM: Novel-view video synthesis through view decomposition,"We tackle the problem of synthesizing a video of multiple moving people as seen from a novel view, given only an input video and depth information or human poses of the novel view as prior. This problem requires a model that learns to transform input features into target features while maintaining temporal consistency. To this end, we learn an invariant feature from the input video that is shared across all viewpoints of the same scene and a view-dependent feature obtained using the target priors. The proposed approach, View-LSTM, is a recurrent neural network structure that accounts for the temporal consistency and target feature approximation constraints. We validate View-LSTM by designing an end-to-end generator for novel-view video synthesis. Experiments on a large multi-view action recognition dataset validate the proposed model.",60083112,Fondazione Bruno Kessler,Trento,Italy,"['1712', '1707']",21.5,0.04489795918367346,0.25051020408163266,1,0.11764705882352941,0.032679738562091505,0.2733812949640288
1882,1921,1921,Optimizing network structure for 3D human pose estimation,"A human pose is naturally represented as a graph where the joints are the nodes and the bones are the edges. So it is natural to apply Graph Convolutional Network (GCN) to estimate 3D poses from 2D poses. In this work, we propose a generic formulation where both GCN and Fully Connected Network (FCN) are its special cases. From this formulation, we discover that GCN has limited representation power when used for estimating 3D poses. We overcome the limitation by introducing Locally Connected Network (LCN) which is naturally implemented by this generic formulation. It notably improves the representation capability over GCN. In addition, since every joint is only connected to a few joints in its neighborhood, it has strong generalization power. The experiments on public datasets show it: (1) outperforms the state-of-the-arts; (2) is less data hungry than alternative models; (3) generalizes well to unseen actions and datasets.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",18.5,0.025148809523809542,0.34255952380952376,1,0.08839779005524862,0.08287292817679558,0.44571428571428573
1883,1922,1922,Global feature guided local pooling,"In deep convolutional neural networks (CNNs), local pooling operation is a key building block to effectively downsize feature maps for reducing computation cost as well as increasing robustness against input variation. There are several types of pooling operation, such as average/max-pooling, from which one has to be manually selected for building CNNs. The optimal pooling type would be dependent on characteristics of features in CNNs and classification tasks, making it hard to find out the proper pooling module in advance. In this paper, we propose a flexible pooling method which adaptively tunes the pooling functionality based on input features without manually fixing it beforehand. In the proposed method, the parameterized pooling form is derived from a probabilistic perspective to flexibly represent various types of pooling and then the parameters are estimated by means of global statistics in the input feature map. Thus, the proposed local pooling guided by global features effectively works in the CNNs trained in an end-to-end manner. The experimental results on image classification tasks demonstrate the effectiveness of the proposed pooling method in various deep CNNs.",60024621,National Institute of Advanced Industrial Science and Technology,Tokyo,Japan,"['1712', '1707']",25.57142857142857,0.06302083333333333,0.3713541666666667,1,0.11822660098522167,0.0049261083743842365,0.3076923076923077
1884,1923,1923,Wasserstein GAN with quadratic transport cost,"Wasserstein GANs are increasingly used in Computer Vision applications as they are easier to train. Previous WGAN variants mainly use the l-1 transport cost to compute the Wasserstein distance between the real and synthetic data distributions. The l-1 transport cost restricts the discriminator to be 1-Lipschitz. However, WGANs with l-1 transport cost were recently shown to not always converge. In this paper, we propose WGAN-QC, a WGAN with quadratic transport cost. Based on the quadratic transport cost, we propose an Optimal Transport Regularizer (OTR) to stabilize the training process of WGAN-QC. We prove that the objective of the discriminator during each generator update computes the exact quadratic Wasserstein distance between real and synthetic data distributions. We also prove that WGAN-QC converges to a local equilibrium point with finite discriminator updates per generator update. We show experimentally on a Dirac distribution that WGAN-QC converges, when many of the l-1 cost WGANs fail to [22]. Qualitative and quantitative results on the CelebA, CelebA-HQ, LSUN and the ImageNet dog datasets show that WGAN-QC is better than state-of-art GAN methods. WGAN-QC has much faster runtime than other WGAN variants.",60026415,Stony Brook University,Stony Brook,United States,"['1712', '1707']",16.81818181818182,0.09464285714285714,0.2839285714285714,1,0.07555555555555556,0.15555555555555556,0.38164251207729466
1885,1924,1924,Seq-SG2SL: Inferring semantic layout from scene graph through sequence to sequence learning,"Generating semantic layout from scene graph is a crucial intermediate task connecting text to image. We present a conceptually simple, flexible and general framework using sequence to sequence (seq-to-seq) learning for this task. The framework, called Seq-SG2SL, derives sequence proxies for the two modality and a Transformer-based seq-to-seq model learns to transduce one into the other. A scene graph is decomposed into a sequence of semantic fragments (SF), one for each relationship. A semantic layout is represented as the consequence from a series of brick-action code segments (BACS), dictating the position and scale of each object bounding box in the layout. Viewing the two building blocks, SF and BACS, as corresponding terms in two different vocabularies, a seq-to-seq model is fittingly used to translate. A new metric, semantic layout evaluation understudy (SLEU), is devised to evaluate the task of semantic layout prediction inspired by BLEU. SLEU defines relationships within a layout as unigrams and looks at the spatial distribution for n-grams. Unlike the binary precision of BLEU, SLEU allows for some tolerances spatially through thresholding the Jaccard Index and is consequently more adapted to the task. Experimental results on the challenging Visual Genome dataset show improvement over a non-sequential approach based on graph convolution.",60118460,Alibaba Group Holding Limited,Yu Hang,China,"['1712', '1707']",20.4,0.1384469696969697,0.4738906926406927,1,0.09411764705882353,0.06274509803921569,0.34763948497854075
1886,1925,1925,Seeing motion in the dark,"Deep learning has recently been applied with impressive results to extreme low-light imaging. Despite the success of single-image processing, extreme low-light video processing is still intractable due to the difficulty of collecting raw video data with corresponding ground truth. Collecting long-exposure ground truth, as was done for single-image processing, is not feasible for dynamic scenes. In this paper, we present deep processing of very dark raw videos: On the order of one lux of illuminance. To support this line of work, we collect a new dataset of raw low-light videos, in which high-resolution raw data is captured at video rate. At this level of darkness, the signal-to-noise ratio is extremely low (negative if measured in dB) and the traditional image processing pipeline generally breaks down. A new method is presented to address this challenging problem. By carefully designing a learning-based pipeline and introducing a new loss function to encourage temporal stability, we train a siamese network on static raw videos, for which ground truth is available, such that the network generalizes to videos of dynamic scenes at test time. Experimental results demonstrate that the presented approach outperforms state-of-the-art models for burst processing, per-frame processing, and blind temporal consistency.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",22.0,0.014990287490287487,0.5017255487567989,1,0.092,0.004,0.3333333333333333
1887,1926,1926,Large-scale tag-based font retrieval with generative feature learning,"Font selection is one of the most important steps in a design workflow. Traditional methods rely on ordered lists which require significant domain knowledge and are often difficult to use even for trained professionals. In this paper, we address the problem of large-scale tag-based font retrieval which aims to bring semantics to the font selection process and enable people without expert knowledge to use fonts effectively. We collect a large-scale font tagging dataset of high-quality professional fonts. The dataset contains nearly 20,000 fonts, 2,000 tags, and hundreds of thousands of font-tag relations. We propose a novel generative feature learning algorithm that leverages the unique characteristics of fonts. The key idea is that font images are synthetic and can therefore be controlled by the learning algorithm. We design an integrated rendering and learning process so that the visual feature from one image can be used to reconstruct another image with different text. The resulting feature captures important font design details while is robust to nuisance factors such as text. We propose a novel attention mechanism to re-weight the visual feature for joint visual-text modeling. We combine the feature and the attention mechanism in a novel recognition-retrieval model. Experimental results show that our method significantly outperforms the state-of-the-art for the important problem of large-scale tag-based font retrieval.",60027165,University of Rochester,Rochester,United States,"['1712', '1707']",17.916666666666668,0.17916666666666667,0.6555555555555556,1,0.12890625,0.0,0.2826086956521739
1888,1927,1927,Fast and practical neural architecture search,"In this paper, we propose a fast and practical neural architecture search (FPNAS) framework for automatic network design. FPNAS aims to discover extremely efficient networks with less than 300M FLOPs. Different from previous NAS methods, our approach searches for the whole network architecture to guarantee block diversity instead of stacking a set of similar blocks repeatedly. We model the search process as a bi-level optimization problem and propose an approximation solution. On CIFAR-10, our approach is capable of design networks with comparable performance to state-of-the-arts while using orders of magnitude less computational resource with only 20 GPU hours. Experimental results on ImageNet and ADE20K datasets further demonstrate transferability of the searched networks.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",18.666666666666668,0.006250000000000006,0.4666666666666666,1,0.09022556390977443,0.06766917293233082,0.34146341463414637
1889,1928,1928,Adaptive context network for scene parsing,"Recent works attempt to improve scene parsing performance by exploring different levels of contexts, and typically train a well-designed convolutional network to exploit useful contexts across all pixels equally. However, in this paper, we find that the context demands are varying from different pixels or regions in each image. Based on this observation, we propose an Adaptive Context Network (ACNet) to capture the pixel-aware contexts by a competitive fusion of global context and local context according to different per-pixel demands. Specifically, when given a pixel, the global context demand is measured by the similarity between the global feature and its local feature, whose reverse value can also be used to measure the local context demand. We model the two demanding measurements by the proposed global context module and local context module, respectively, to generate their adaptive contextual features. Furthermore, we import multiple such modules to build several adaptive context blocks in different levels of network to obtain a coarse-to-fine result. Finally, comprehensive experimental evaluations demonstrate the effectiveness of the proposed ACNet, and new state-of-the-arts performances are achieved on all four public datasets, i.e. Cityscapes, ADE20K, PASCAL Context, and COCO Stuff.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",23.75,0.015404040404040403,0.2467171717171717,1,0.1206896551724138,0.05172413793103448,0.33796296296296297
1890,1929,1929,Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution,"In natural images, information is conveyed at different frequencies where higher frequencies are usually encoded with fine details and lower frequencies are usually encoded with global structures. Similarly, the output feature maps of a convolution layer can also be seen as a mixture of information at different frequencies. In this work, we propose to factorize the mixed feature maps by their frequencies, and design a novel Octave Convolution (OctConv) operation to store and process feature maps that vary spatially 'slower' at a lower spatial resolution reducing both memory and computation cost. Unlike existing multi-scale methods, OctConv is formulated as a single, generic, plug-and-play convolutional unit that can be used as a direct replacement of (vanilla) convolutions without any adjustments in the network architecture. It is also orthogonal and complementary to methods that suggest better topologies or reduce channel-wise redundancy like group or depth-wise convolutions. We experimentally show that by simply replacing convolutions with OctConv, we can consistently boost accuracy for both image and video recognition tasks, while reducing memory and computational cost. An OctConv-equipped ResNet-152 can achieve 82.9% top-1 classification accuracy on ImageNet with merely 22.2 GFLOPs.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",26.714285714285715,0.035846560846560835,0.35396825396825393,1,0.12162162162162163,0.03153153153153153,0.3397129186602871
1891,1930,1930,Distinit: Learning video representations without a single labeled video,"Video recognition models have progressed significantly over the past few years, evolving from shallow classifiers trained on hand-crafted features to deep spatiotemporal networks. However, labeled video data required to train such models has not been able to keep up with the ever increasing depth and sophistication of these networks. In this work we propose an alternative approach to learning video representations that requires no semantically labeled videos, and instead leverages the years of effort in collecting and labeling large and clean still-image datasets. We do so by using state-of-the-art models pre-trained on image datasets as 'teachers' to train video models in a distillation framework. We demonstrate that our method learns truly spatiotemporal features, despite being trained only using supervision from still-image networks. Moreover, it learns good representations across different input modalities, using completely uncurated raw video data sources and with different 2D teacher models. Our method obtains strong transfer performance, outperforming standard techniques for bootstrapping video architectures with image based models by 16%. We believe that our approach opens up new approaches for learning spatiotemporal representations from unlabeled video data.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",22.5,0.10064148814148816,0.5126660376660376,1,0.16037735849056603,0.0,0.39593908629441626
1892,1931,1931,AMASS: Archive of motion capture as surface shapes,"Large datasets are the cornerstone of recent advances in computer vision using deep learning. In contrast, existing human motion capture (mocap) datasets are small and the motions limited, hampering progress on learning models of human motion. While there are many different datasets available, they each use a different parameterization of the body, making it difficult to integrate them into a single meta dataset. To address this, we introduce AMASS, a large and varied database of human motion that unifies 15 different optical marker-based mocap datasets by representing them within a common framework and parameterization. We achieve this using a new method, MoSh++, that converts mocap data into realistic 3D human meshes represented by a rigged body model. Here we use SMPL [Loper et al., 2015], which is widely used and provides a standard skeletal representation as well as a fully rigged surface mesh. The method works for arbitrary marker sets, while recovering soft-tissue dynamics and realistic hand motion. We evaluate MoSh++ and tune its hyperparameters using a new dataset of 4D body scans that are jointly recorded with markerbased mocap. The consistent representation of AMASS makes it readily useful for animation, visualization, and generating training data for deep learning. Our dataset is significantly richer than previous human motion collections, having more than 40 hours of motion data, spanning over 300 subjects, more than 11000 motions, and will be publicly available to the research community.",60033420,York University,Toronto,Canada,"['1712', '1707']",23.4,0.07941494779730074,0.3715208810797046,1,0.12222222222222222,0.040740740740740744,0.37735849056603776
1893,1932,1932,Evaluation of augmented reality occlusion scheme based on analytic hierarchy process,"In this paper, the metrics of virtual and real occlusion effects are proposed for different augmented reality scenarios, and seven occlusion schemes are proposed correspondingly. In order to evaluate the adaptability of various virtual and real occlusion schemes in different scenarios, the augmented reality scenes with label information are used to construct the evaluation model of the virtual and real occlusion schemes by analytic hierarchy process. The two-step experimental calculation is carried out to find the most suitable occlusion scheme in the scene.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],27.66666666666667,0.19444444444444448,0.4722222222222222,1,0.0989010989010989,0.0,0.19101123595505617
1894,1934,1934,Role of stakeholders in preserving biodiversity in Bangladesh: A study on tanguar haor," Tanguar Haor has been declared ecologically critical area for 20 years. This study aims to examine the role of relevant stakeholders in conserving the countries’ second RAMSAR site. This paper also attempted to understand the causes of loss of biodiversity of Tanguar Haor as well as its solution. Mixed methods (qualitative and quantitative) research has employed for this study applying purposive sampling strategy. Study findings reveal that indiscriminate harvesting of mother fishes, use of agrochemicals, deforestation, hunting migratory birds, increasing trace metal, mixing silt soil with water are the major contributor to loss of biodiversity in Tanguar Haor. With the support of the Swedish Development Corporation (SDC) and International Union for Conservation of Nature (IUCN), the government of Bangladesh has conducted a big budgeted project to preserve biodiversity of Tanguar Haor, however there found lack of coordination among peoples’ representatives, government agencies, and IUCN. Hence, the study findings will hopefully contribute to identify the irregularities in performing the role of different stakeholders that will lead taking further initiatives to preserve biodiversity of Tanguar Haor in Bangladesh.",60011268,Shahjalal University of Science and Technology,Sylhet,Bangladesh,['1706'],25.285714285714285,0.051388888888888894,0.4055555555555556,0,0.12376237623762376,0.11386138613861387,0.43283582089552236
1895,1935,1935,Use of IoT at Bosch manufacturing in Bangalore," This report has been developed as a guiding framework and conducted a series of research activities, including in-person workshops, virtual working group sessions, interviews of key thought leaders, and a survey of employ of Bosch manufacturing plant. Types of IoT application, IoT suite and IoT cloud-enabled software and the methods of IoT which is considered by the Bosch manufacturing process. Where Just in Time (JIT), Kaizon, Pokea-Yoke and Kanban are the major method of manufacturing process and to understand the impact of it by using chi square, which is focused more in this research and the use of IoT at bosch manufacturing in Bangalore.",122429542,Ramaiah Institute of Management,Bengaluru,India,['1706'],35.0,0.165625,0.575,0,0.07258064516129033,0.11290322580645161,0.4188034188034188
1896,1936,1936,Make a face: Towards arbitrary high fidelity face manipulation,"Recent studies have shown remarkable success in face manipulation task with the advance of GANs and VAEs paradigms, but the outputs are sometimes limited to low-resolution and lack of diversity. In this work, we propose Additive Focal Variational Auto-encoder (AF-VAE), a novel approach that can arbitrarily manipulate high-resolution face images using a simple yet effective model and only weak supervision of reconstruction and KL divergence losses. First, a novel additive Gaussian Mixture assumption is introduced with an unsupervised clustering mechanism in the structural latent space, which endows better disentanglement and boosts multi-modal representation with external memory. Second, to improve the perceptual quality of synthesized results, two simple strategies in architecture design are further tailored and discussed on the behavior of Human Visual System (HVS) for the first time, allowing for fine control over the model complexity and sample quality. Human opinion studies and new state-of-the-art Inception Score (IS) / Frechet Inception Distance (FID) demonstrate the superiority of our approach over existing algorithms, advancing both the fidelity and extremity of face manipulation task.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",34.4,0.12650484436198722,0.3715883323026179,1,0.08571428571428572,0.08095238095238096,0.36082474226804123
1897,1937,1937,Defending against universal perturbations with shared adversarial training,"Classifiers such as deep neural networks have been shown to be vulnerable against adversarial perturbations on problems with high-dimensional input space. While adversarial training improves the robustness of image classifiers against such adversarial perturbations, it leaves them sensitive to perturbations on a non-negligible fraction of the inputs. In this work, we show that adversarial training is more effective in preventing universal perturbations, where the same perturbation needs to fool a classifier on many inputs. Moreover, we investigate the trade-off between robustness against universal perturbations and performance on unperturbed data and propose an extension of adversarial training that handles this trade-off more gracefully. We present results for image classification and semantic segmentation to showcase that universal perturbations that fool a model hardened with adversarial training become clearly perceptible and show patterns of the target scene.",60025641,Universität Freiburg im Breisgau,Freiburg im Breisgau,Germany,"['1712', '1707']",26.8,0.12,0.3738888888888888,1,0.10596026490066225,0.0,0.2867132867132867
1898,1938,1938,Co-mining: Deep face recognition with noisy labels,"Face recognition has achieved significant progress with the growing scale of collected datasets, which empowers us to train strong convolutional neural networks (CNNs). While a variety of CNN architectures and loss functions have been devised recently, we still have a limited understanding of how to train the CNN models with the label noise inherent in existing face recognition datasets. To address this issue, this paper develops a novel co-mining strategy to effectively train on the datasets with noisy labels. Specifically, we simultaneously use the loss values as the cue to detect noisy labels, exchange the high-confidence clean faces to alleviate the errors accumulated issue caused by the sample-selection bias, and re-weight the predicted clean faces to make them dominate the discriminative model training in a mini-batch fashion. Extensive experiments by training on three popular datasets (textit{i.e.}, CASIA-WebFace, MS-Celeb-1M and VggFace2) and testing on several benchmarks, including LFW, AgeDB, CFP, CALFW, CPLFW, RFW, and MegaFace, have demonstrated the effectiveness of our new approach over the state-of-the-art alternatives.",120499086,JD AI Research,Beijing,China,"['1712', '1707']",33.2,0.2551456119637938,0.5353699330972058,1,0.12149532710280374,0.07476635514018691,0.4205128205128205
1899,1939,1939,An advanced membrane evolutionary algorithm for constrained engineering design problems,"The main goal of this paper is to propose an advanced dynamic membrane algorithm (ADMA-PSO/GA) based on the particle swarm optimization (PSO) and genetic algorithm (GA) for solving the constrained problems in engineering design. The proposed algorithm combines membrane computing with the particle swarm optimization and genetic algorithm. In the PSO phase, the worst solutions are enhanced by the global-local best inertia weight and acceleration coefficients. In the second phase, crossover and mutation operators have been used to further improve the balance between the exploration and exploitation ability in PSO. The constraints are handled using a parameter-free penalty function. Several well-known engineering design problems have been used to measure the performance of the proposed algorithm in this paper. The simulation results show that the proposed algorithm is superior to the state-of-the-art algorithms.",60002210,Shandong Normal University,Jinan,China,['1700'],18.857142857142858,0.14074074074074072,0.4222222222222222,1,0.10429447852760736,0.03680981595092025,0.2857142857142857
1900,1940,1940,Foreground-aware pyramid reconstruction for alignment-free occluded person re-identification,"Re-identifying a person across multiple disjoint camera views is important for intelligent video surveillance, smart retailing and many other applications. However, existing person re-identification methods are challenged by the ubiquitous occlusion over persons and suffer performance degradation. This paper proposes a novel occlusion-robust and alignment-free model for occluded person ReID and extends its application to realistic and crowded scenarios. The proposed model first leverages the fully convolution network (FCN) and pyramid pooling to extract spatial pyramid features. Then an alignment-free matching approach namely Foreground-aware Pyramid Reconstruction (FPR) is developed to accurately compute matching scores between occluded persons, regardless of their different scales and sizes. FPR uses the error from robust reconstruction over spatial pyramid features to measure similarities between two persons. More importantly, we design a occlusion-sensitive foreground probability generator that focuses more on clean human body parts to robustify the similarity computation with less contamination from occlusion. The FPR is easily embedded into any end-to-end person ReID models. The effectiveness of the proposed method is clearly demonstrated by the experimental results (Rank-1 accuracy) on three occluded person datasets: Partial REID (78.30%), Partial iLIDS (68.08%), Occluded REID (81.00%), and three benchmark person datasets: Market1501 (95.42%), DukeMTMC (88.64%), CUHK03 (76.08%).",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",22.11111111111111,0.21542207792207796,0.486417748917749,1,0.08812260536398467,0.034482758620689655,0.4732510288065844
1901,1941,1941,Creativity inspired zero-shot learning,"Zero-shot learning (ZSL) aims at understanding unseen categories with no training examples from class-level descriptions. To improve the discriminative power of zero-shot learning, we model the visual learning process of unseen categories with an inspiration from the psychology of human creativity for producing novel art. We relate ZSL to human creativity by observing that zero-shot learning is about recognizing the unseen and creativity is about creating a likable unseen. We introduce a learning signal inspired by creativity literature that explores the unseen space with hallucinated class-descriptions and encourages careful deviation of their visual feature generations from seen classes while allowing knowledge transfer from seen to unseen classes. Empirically, we show consistent improvement over the state of the art of several percents on the largest available benchmarks on the challenging task or generalized ZSL from a noisy text that we focus on, using the CUB and NABirds datasets. We also show the advantage of our loss on Attribute-based ZSL on three additional datasets (AwA2, aPY, and SUN). Code is available at https://github.com/mhelhoseiny/CIZSL.",60092945,King Abdullah University of Science and Technology,Jeddah,Saudi Arabia,"['1712', '1707']",24.42857142857143,0.1708333333333333,0.3208333333333333,1,0.11557788944723618,0.04522613065326633,0.31746031746031744
1902,1942,1942,Mixture-kernel graph attention network for situation recognition,"Understanding images beyond salient actions involves reasoning about scene context, objects, and the roles they play in the captured event. Situation recognition has recently been introduced as the task of jointly reasoning about the verbs (actions) and a set of semantic-role and entity (noun) pairs in the form of action frames. Labeling an image with an action frame requires an assignment of values (nouns) to the roles based on the observed image content. Among the inherent challenges are the rich conditional structured dependencies between the output role assignments and the overall semantic sparsity. In this paper, we propose a novel mixture-kernel attention graph neural network (GNN) architecture designed to address these challenges. Our GNN enables dynamic graph structure during training and inference, through the use of a graph attention mechanism, and context-aware interactions between role pairs. We illustrate the efficacy of our model and design choices by conducting experiments on imSitu benchmark dataset, with accuracy improvements of up to 10% over the state-of-the-art.",60010365,The University of British Columbia,Vancouver,Canada,"['1712', '1707']",23.285714285714285,0.09583333333333333,0.22777777777777775,1,0.07614213197969544,0.04060913705583756,0.3621621621621622
1903,1943,1943,SRM: A style-based recalibration module for convolutional neural networks,"Following the advance of style transfer with Convolutional Neural Networks (CNNs), the role of styles in CNNs has drawn growing attention from a broader perspective. In this paper, we aim to fully leverage the potential of styles to improve the performance of CNNs in general vision tasks. We propose a Style-based Recalibration Module (SRM), a simple yet effective architectural unit, which adaptively recalibrates intermediate feature maps by exploiting their styles. SRM first extracts the style information from each channel of the feature maps by style pooling, then estimates per-channel recalibration weight via channel-independent style integration. By incorporating the relative importance of individual styles into feature maps, SRM effectively enhances the representational ability of a CNN. The proposed module is directly fed into existing CNN architectures with negligible overhead. We conduct comprehensive experiments on general image recognition as well as tasks related to styles, which verify the benefit of SRM over recent approaches such as Squeeze-and-Excitation (SE). To explain the inherent difference between SRM and SE, we provide an in-depth comparison of their representational properties.",60121105,Lunit Inc.,Seoul,South Korea,"['1712', '1707']",21.75,0.11785714285714287,0.4528911564625851,1,0.10576923076923077,0.07692307692307693,0.3826530612244898
1904,1944,1944,Learning motion in feature space: Locally-consistent deformable convolution networks for fine-grained action detection,"Fine-grained action detection is an important task with numerous applications in robotics and human-computer interaction. Existing methods typically utilize a two-stage approach including extraction of local spatio-temporal features followed by temporal modeling to capture long-term dependencies. While most recent papers have focused on the latter (long-temporal modeling), here, we focus on producing features capable of modeling fine-grained motion more efficiently. We propose a novel locally-consistent deformable convolution, which utilizes the change in receptive fields and enforces a local coherency constraint to capture motion information effectively. Our model jointly learns spatio-temporal features (instead of using independent spatial and temporal streams). The temporal component is learned from the feature space instead of pixel space, e.g. optical flow. The produced features can be flexibly used in conjunction with other long-temporal modeling networks, e.g. ST-CNN, DilatedTCN, and ED-TCN. Overall, our proposed approach robustly outperforms the original long-temporal models on two fine-grained action datasets: 50 Salads and GTEA, achieving F1 scores of 80.22% and 75.39% respectively.",60011048,IBM Research,Yorktown Heights,United States,"['1712', '1707']",16.1,0.13796296296296295,0.3333333333333333,1,0.11737089201877934,0.028169014084507043,0.43315508021390375
1905,1945,1945,PIE: A large-scale dataset and models for pedestrian intention estimation and trajectory prediction,"Pedestrian behavior anticipation is a key challenge in the design of assistive and autonomous driving systems suitable for urban environments. An intelligent system should be able to understand the intentions or underlying motives of pedestrians and to predict their forthcoming actions. To date, only a few public datasets were proposed for the purpose of studying pedestrian behavior prediction in the context of intelligent driving. To this end, we propose a novel large-scale dataset designed for pedestrian intention estimation (PIE). We conducted a large-scale human experiment to establish human reference data for pedestrian intention in traffic scenes. We propose models for estimating pedestrian crossing intention and predicting their future trajectory. Our intention estimation model achieves 79% accuracy and our trajectory prediction algorithm outperforms state-of-the-art by 26% on the proposed dataset. We further show that combining pedestrian intention with observed motion improves trajectory prediction. The dataset and models are available at http://data.nvision2.eecs.yorku.ca/PIE-dataset/.",60033420,York University,Toronto,Canada,"['1712', '1707']",16.666666666666664,0.21666666666666665,0.4844444444444444,1,0.10919540229885058,0.005747126436781609,0.32934131736526945
1906,1946,1946,Graphx-convolution for point cloud deformation in 2D-to-3D conversion,"In this paper, we present a novel deep method to reconstruct a point cloud of an object from a single still image. Prior arts in the field struggle to reconstruct an accurate and scalable 3D model due to either the inefficient and expensive 3D representations, the dependency between the output and number of model parameters or the lack of a suitable computing operation. We propose to overcome these by deforming a random point cloud to the object shape through two steps: Feature blending and deformation. In the first step, the global and point-specific shape features extracted from a 2D object image are blended with the encoded feature of a randomly generated point cloud, and then this mixture is sent to the deformation step to produce the final representative point set of the object. In the deformation process, we introduce a new layer termed as GraphX that considers the inter-relationship between points like common graph convolutions but operates on unordered sets. Moreover, with a simple trick, the proposed model can generate an arbitrary-sized point cloud, which is the first deep method to do so. Extensive experiments verify that we outperform existing models and halve the state-of-the-art distance score in single image 3D reconstruction.",60016912,Yonsei University,Seoul,South Korea,"['1712', '1707']",28.857142857142854,-0.024074675324675318,0.3999296536796537,1,0.10434782608695652,0.004347826086956522,0.23853211009174313
1907,1947,1947,Attract or distract: Exploit the margin of open set,"Open set domain adaptation aims to diminish the domain shift across domains, with partially shared classes. There exist unknown target samples out of the knowledge of source domain. Compared to the close set setting, how to separate the unknown (unshared) class from the known (shared) ones plays the key role. Whereas, previous methods did not emphasize the semantic structure of the open set data, which may introduce bias into the domain alignment and confuse the classifier around the decision boundary. In this paper, we exploit the semantic structure of open set data from two aspects: 1) Semantic Categorical Alignment, which aims to achieve good separability of target known classes by categorically aligning the centroid of target with the source. 2) Semantic Contrastive Mapping, which aims to push the unknown class away from the decision boundary. Empirically, we demonstrate that our method performs favourably against the state-of-the-art methods on representative benchmarks, e.g. Digits and Office-31 datasets.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",19.375,0.02121212121212121,0.4969696969696968,1,0.11956521739130435,0.03804347826086957,0.329608938547486
1908,1948,1948,A novel unsupervised camera-aware domain adaptation framework for person re-identification,"Unsupervised cross-domain person re-identification (Re-ID) faces two key issues. One is the data distribution discrepancy between source and target domains, and the other is the lack of discriminative information in target domain. From the perspective of representation learning, this paper proposes a novel end-to-end deep domain adaptation framework to address them. For the first issue, we highlight the presence of camera-level sub-domains as a unique characteristic in person Re-ID, and develop a 'camera-aware' domain adaptation method via adversarial learning. With this method, the learned representation reduces distribution discrepancy not only between source and target domains but also across all cameras. For the second issue, we exploit the temporal continuity in each camera of target domain to create discriminative information. This is implemented by dynamically generating online triplets within each batch, in order to maximally take advantage of the steadily improved representation in training process. Together, the above two methods give rise to a new unsupervised domain adaptation framework for person Re-ID. Extensive experiments and ablation studies conducted on benchmark datasets demonstrate its superiority and interesting properties.",60033100,Nanjing University,Nanjing,China,"['1712', '1707']",19.555555555555557,0.0951048951048951,0.4971445221445221,1,0.08755760368663594,0.027649769585253458,0.28061224489795916
1909,1949,1949,STM: Spatiotemporal and motion encoding for action recognition,"Spatiotemporal and motion features are two complementary and crucial information for video action recognition. Recent state-of-the-art methods adopt a 3D CNN stream to learn spatiotemporal features and another flow stream to learn motion features. In this work, we aim to efficiently encode these two features in a unified 2D framework. To this end, we first propose a STM block, which contains a Channel-wise SpatioTemporal Module (CSTM) to present the spatiotemporal features and a Channel-wise Motion Module (CMM) to efficiently encode motion features. We then replace original residual blocks in the ResNet architecture with STM blcoks to form a simple yet effective STM network by introducing very limited extra computation cost. Extensive experiments demonstrate that the proposed STM network outperforms the state-of-the-art methods on both temporal-related datasets (i.e., Something-Something v1 & v2 and Jester) and scene-related datasets (i.e., Kinetics-400, UCF-101, and HMDB-51) with the help of encoding spatiotemporal and motion features together.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",25.16666666666667,0.11201298701298702,0.3826839826839828,1,0.0979381443298969,0.08762886597938144,0.4418604651162791
1910,1950,1950,Deep metric learning with tuplet margin loss,"Deep metric learning, in which the loss function plays a key role, has proven to be extremely useful in visual recognition tasks. However, existing deep metric learning loss functions such as contrastive loss and triplet loss usually rely on delicately selected samples (pairs or triplets) for fast convergence. In this paper, we propose a new deep metric learning loss function, tuplet margin loss, using randomly selected samples from each mini-batch. Specifically, the proposed tuplet margin loss implicitly up-weights hard samples and down-weights easy samples, while a slack margin in angular space is introduced to mitigate the problem of overfitting on the hardest sample. Furthermore, we address the problem of intra-pair variation by disentangling class-specific information to improve the generalizability of tuplet margin loss. Experimental results on three widely used deep metric learning datasets, CARS196, CUB200-2011, and Stanford Online Products, demonstrate significant improvements over existing deep metric learning methods.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",24.66666666666667,0.005422647527910686,0.4870813397129187,1,0.09392265193370165,0.03314917127071823,0.3727810650887574
1911,1951,1951,BAE-NET: Branched autoencoder for shape co-segmentation,"We treat shape co-segmentation as a representation learning problem and introduce BAE-NET, a branched autoencoder network, for the task. The unsupervised BAE-NET is trained with a collection of un-segmented shapes, using a shape reconstruction loss, without any ground-truth labels. Specifically, the network takes an input shape and encodes it using a convolutional neural network, whereas the decoder concatenates the resulting feature code with a point coordinate and outputs a value indicating whether the point is inside/outside the shape. Importantly, the decoder is branched: Each branch learns a compact representation for one commonly recurring part of the shape collection, e.g., airplane wings. By complementing the shape reconstruction loss with a label loss, BAE-NET is easily tuned for one-shot learning. We show unsupervised, weakly supervised, and one-shot learning results by BAE-NET, demonstrating that using only a couple of exemplars, our network can generally outperform state-of-the-art supervised methods trained on hundreds of segmented shapes. Code is available at https://github.com/czq142857/BAE-NET.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",22.285714285714285,0.08690476190476193,0.6940476190476191,1,0.12254901960784313,0.04411764705882353,0.38333333333333336
1912,1952,1952,Neural 3D morphable models: Spiral convolutional networks for 3D shape representation learning and generation,"Generative models for 3D geometric data arise in many important applications in 3D computer vision and graphics. In this paper, we focus on 3D deformable shapes that share a common topological structure, such as human faces and bodies. Morphable Models and their variants, despite their linear formulation, have been widely used for shape representation, while most of the recently proposed nonlinear approaches resort to intermediate representations, such as 3D voxel grids or 2D views. In this work, we introduce a novel graph convolutional operator, acting directly on the 3D mesh, that explicitly models the inductive bias of the fixed underlying graph. This is achieved by enforcing consistent local orderings of the vertices of the graph, through the spiral operator, thus breaking the permutation invariance property that is adopted by all the prior work on Graph Neural Networks. Our operator comes by construction with desirable properties (anisotropic, topology-aware, lightweight, easy-to-optimise), and by using it as a building block for traditional deep generative architectures, we demonstrate state-of-the-art results on a variety of 3D shape datasets compared to the linear Morphable Model and other graph convolutional operators.",60015150,Imperial College London,London,United Kingdom,"['1712', '1707']",30.66666666666667,0.07361111111111113,0.3680555555555556,1,0.09090909090909091,0.03636363636363636,0.3317307692307692
1913,1953,1953,Enhancing adversarial example transferability with an intermediate level attack,"Neural networks are vulnerable to adversarial examples, malicious inputs crafted to fool trained models. Adversarial examples often exhibit black-box transfer, meaning that adversarial examples for one model can fool another model. However, adversarial examples are typically overfit to exploit the particular architecture and feature representation of a source model, resulting in sub-optimal black-box transfer attacks to other target models. We introduce the Intermediate Level Attack (ILA), which attempts to fine-tune an existing adversarial example for greater black-box transferability by increasing its perturbation on a pre-specified layer of the source model, improving upon state-of-the-art methods. We show that we can select a layer of the source model to perturb without any knowledge of the target models while achieving high transferability. Additionally, we provide some explanatory insights regarding our method and the effect of optimizing for adversarial examples using intermediate feature maps.",60007776,Cornell University,Ithaca,United States,"['1712', '1707']",23.33333333333333,0.0058333333333333345,0.4580555555555555,1,0.1329479768786127,0.023121387283236993,0.36774193548387096
1914,1954,1954,Zero-shot grounding of objects from natural language queries,"A phrase grounding system localizes a particular object in an image referred to by a natural language query. In previous work, the phrases were restricted to have nouns that were encountered in training, we extend the task to Zero-Shot Grounding(ZSG) which can include novel, 'unseen' nouns. Current phrase grounding systems use an explicit object detection network in a 2-stage framework where one stage generates sparse proposals and the other stage evaluates them. In the ZSG setting, generating appropriate proposals itself becomes an obstacle as the proposal generator is trained on the entities common in the detection and grounding datasets. We propose a new single-stage model called ZSGNet which combines the detector network and the grounding system and predicts classification scores and regression parameters. Evaluation of ZSG system brings additional subtleties due to the influence of the relationship between the query and learned categories; we define four distinct conditions that incorporate different levels of difficulty. We also introduce new datasets, sub-sampled from Flickr30k Entities and Visual Genome, that enable evaluations for the four conditions. Our experiments show that ZSGNet achieves state-of-the-art performance on Flickr30k and ReferIt under the usual 'seen' settings and performs significantly better than baseline in the zero-shot setting.",60029311,University of Southern California,Los Angeles,United States,"['1712', '1707']",25.0,0.058181818181818175,0.3739393939393939,1,0.14102564102564102,0.05128205128205128,0.35
1915,1955,1955,Convex shape prior for multi-object segmentation using a single level set function,"Many objects in real world have convex shapes. It is a difficult task to have representations for convex shapes with good and fast numerical solutions. This paper proposes a method to incorporate convex shape prior for multi-object segmentation using level set method. The relationship between the convexity of the segmented objects and the signed distance function corresponding to their union is analyzed theoretically. This result is combined with Gaussian mixture method for the multiple objects segmentation with convexity shape prior. Alternating direction method of multiplier (ADMM) is adopted to solve the proposed model. Special boundary conditions are also imposed to obtain efficient algorithms for 4th order partial differential equations in one step of ADMM algorithm. In addition, our method only needs one level set function regardless of the number of objects. So the increase in the number of objects does not result in the increase of model and algorithm complexity. Various numerical experiments are illustrated to show the performance and advantages of the proposed method.",60104686,Beijing Computational Science Research Center,Beijing,China,"['1712', '1707']",16.5,0.12232142857142855,0.4544642857142857,1,0.10555555555555556,0.027777777777777776,0.2696629213483146
1916,1956,1956,"Watch, listen and tell: Multi-modal weakly supervised dense event captioning","Multi-modal learning, particularly among imaging and linguistic modalities, has made amazing strides in many high-level fundamental visual understanding problems, ranging from language grounding to dense event captioning. However, much of the research has been limited to approaches that either do not take audio corresponding to video into account at all, or those that model the audio-visual correlations in service of sound or sound source localization. In this paper, we present the evidence, that audio signals can carry surprising amount of information when it comes to high-level visual-lingual tasks. Specifically, we focus on the problem of weakly-supervised dense event captioning in videos and show that audio on its own can nearly rival performance of a state-of-the-art visual model and, combined with video, can improve on the state-of-the-art performance. Extensive experiments on the ActivityNet Captions dataset show that our proposed multi-modal approach outperforms state-of-the-art unimodal methods, as well as validate specific feature representation and architecture design choices.",60010365,The University of British Columbia,Vancouver,Canada,"['1712', '1707']",31.0,0.23095238095238094,0.3334077380952381,1,0.12807881773399016,0.0049261083743842365,0.2982456140350877
1917,1957,1957,Jointly aligning millions of images with deep penalised reconstruction congealing,"Extrapolating fine-grained pixel-level correspondences in a fully unsupervised manner from a large set of misaligned images can benefit several computer vision and graphics problems, e.g. co-segmentation, super-resolution, image edit propagation, structure-from-motion, and 3D reconstruction. Several joint image alignment and congealing techniques have been proposed to tackle this problem, but robustness to initialisation, ability to scale to large datasets, and alignment accuracy seem to hamper their wide applicability. To overcome these limitations, we propose an unsupervised joint alignment method leveraging a densely fused spatial transformer network to estimate the warping parameters for each image and a low-capacity auto-encoder whose reconstruction error is used as an auxiliary measure of joint alignment. Experimental results on digits from multiple versions of MNIST (i.e., original, perturbed, affNIST and infiMNIST) and faces from LFW, show that our approach is capable of aligning millions of images with high accuracy and robustness to different levels and types of perturbation. Moreover, qualitative and quantitative results suggest that the proposed method outperforms state-of-the-art approaches both in terms of alignment quality and robustness to initialisation.",120459061,Onfido,London,United Kingdom,"['1712', '1707']",29.0,0.10577922077922076,0.35883116883116883,1,0.10138248847926268,0.018433179723502304,0.3469387755102041
1918,1958,1958,STGAT: Modeling spatial-temporal interactions for human trajectory prediction,"Human trajectory prediction is challenging and critical in various applications (e.g., autonomous vehicles and social robots). Because of the continuity and foresight of the pedestrian movements, the moving pedestrians in crowded spaces will consider both spatial and temporal interactions to avoid future collisions. However, most of the existing methods ignore the temporal correlations of interactions with other pedestrians involved in a scene. In this work, we propose a Spatial-Temporal Graph Attention network (STGAT), based on a sequence-to-sequence architecture to predict future trajectories of pedestrians. Besides the spatial interactions captured by the graph attention mechanism at each time-step, we adopt an extra LSTM to encode the temporal correlations of interactions. Through comparisons with state-of-the-art methods, our model achieves superior performance on two publicly available crowd datasets (ETH and UCY) and produces more 'socially' plausible trajectories for pedestrians.",60030904,Institute of Computing Technology Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",22.66666666666667,0.2272222222222222,0.4461111111111112,1,0.0935672514619883,0.04093567251461988,0.4166666666666667
1919,1959,1959,Resource constrained neural network architecture search: Will a submodularity assumption help?,"The design of neural network architectures is frequently either based on human expertise using trial/error and empirical feedback or tackled via large scale reinforcement learning strategies performed over distinct discrete architecture choices. In the latter case, the optimization is often non-differentiable and also not very amenable to derivative-free optimization methods. Most methods in use today require sizable computational resources. And if we want networks that additionally satisfy resource constraints, the above challenges are exacerbated because the search must now balance accuracy with certain budget constraints on resources. We formulate this problem as the optimization of a set function - we find that the empirical behavior of this set function often (but not always) satisfies marginal gain and monotonicity principles - properties central to the idea of submodularity. Based on this observation, we adapt algorithms within discrete optimization to obtain heuristic schemes for neural network architecture search, where we have resource constraints on the architecture. This simple scheme when applied on CIFAR-100 and ImageNet, identifies resource-constrained architectures with quantifiably better performance than current state-of-the-art models designed for mobile devices. Specifically, we find high-performing architectures with fewer parameters and computations by a search method that is much faster.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",24.5,0.13447802197802194,0.2917925824175825,1,0.10526315789473684,0.008771929824561403,0.3018867924528302
1920,1960,1960,A model based on a fuzzy petri net for scenario evolution of unconventional emergencies,"Improving the response precision of unconventional-emergency management has been difficult. As a new type of decision-making model, “scenario–response” can help solve this problem. From the perspective of scenario evolution, this research designed the system structure of event scenario evolution as a hierarchical network structure of hazard factors, key hazard-affected bodies, and derivative events. In addition, a model for scenario evolution based on a fuzzy Petri net was constructed. Taking as an example an earthquake scenario evolution based on a fuzzy Petri net. A population (P) from the key hazard-affected objects was selected as the sample object, and the scenario evolution path of P by constructing a reasoning tree based on the fuzzy reasoning algorithm can be obtained to solve the response sequence of P. The feasibility of this model was verified by the example of an earthquake.",60064143,Nanjing University of Information Science and Technology,Nanjing,China,['1700'],19.571428571428573,-0.060606060606060615,0.5757575757575758,1,0.1165644171779141,0.018404907975460124,0.24183006535947713
1921,1961,1961,Deep reinforcement active learning for human-in-the-loop person re-identification,"Most existing person re-identification(Re-ID) approaches achieve superior results based on the assumption that a large amount of pre-labelled data is usually available and can be put into training phrase all at once. However, this assumption is not applicable to most real-world deployment of the Re-ID task. In this work, we propose an alternative reinforcement learning based human-in-the-loop model which releases the restriction of pre-labelling and keeps model upgrading with progressively collected data. The goal is to minimize human annotation efforts while maximizing Re-ID performance. It works in an iteratively updating framework by refining the RL policy and CNN parameters alternately. In particular, we formulate a Deep Reinforcement Active Learning (DRAL) method to guide an agent (a model in a reinforcement learning process) in selecting training samples on-the-fly by a human user/annotator. The reinforcement learning reward is the uncertainty value of each human selected sample. A binary feedback (positive or negative) labelled by the human annotator is used to select the samples of which are used to fine-tune a pre-trained CNN Re-ID model. Extensive experiments demonstrate the superiority of our DRAL method for deep reinforcement learning based human-in-the-loop person Re-ID when compared to existing unsupervised and transfer learning models as well as active learning models.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",22.66666666666667,0.12597402597402596,0.3965113318054495,1,0.11787072243346007,0.060836501901140684,0.30666666666666664
1922,1962,1962,Prior guided dropout for robust visual localization in dynamic environments,"Camera localization from monocular images has been a long-standing problem, but its robustness in dynamic environments is still not adequately addressed. Compared with classic geometric approaches, modern CNN-based methods (e.g. PoseNet) have manifested the reliability against illumination or viewpoint variations, but they still have the following limitations. First, foreground moving objects are not explicitly handled, which results in poor performance and instability in dynamic environments. Second, the output for each image is a point estimate without uncertainty quantification. In this paper, we propose a framework which can be generally applied to existing CNN-based pose regressors to improve their robustness in dynamic environments. The key idea is a prior guided dropout module coupled with a self-attention module which can guide CNNs to ignore foreground objects during both training and inference. Additionally, the dropout module enables the pose regressor to output multiple hypotheses from which the uncertainty of pose estimates can be quantified and leveraged in the following uncertainty-aware pose-graph optimization to improve the robustness further. We achieve an average accuracy of 9.98m/3.63° on RobotCar dataset, which outperforms the state-of-the-art method by 62.97%/47.08%. The source code of our implementation is available at https://github.com/zju3dv/RVL-dynamic.",60003970,Zhejiang University,Hangzhou,China,"['1712', '1707']",19.1,0.019444444444444445,0.2907407407407408,1,0.12987012987012986,0.021645021645021644,0.31797235023041476
1923,1963,1963,DDSL: Deep differentiable simplex layer for learning geometric signals,"We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for geometric deep learning. The DDSL is a differentiable layer compatible with deep neural networks for bridging simplex mesh-based geometry representations (point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images (e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to perform differentiable, efficient, anti- aliased rasterization of simplex-based signals. We present a complete theoretical framework for the process as well as an efficient backpropagation algorithm. Compared to previous differentiable renderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees and dimensions. In particular, we explore its applications to 2D shapes and illustrate two applications of this method: (1) mesh editing and optimization guided by neural network outputs, and (2) using DDSL for a differentiable rasterization loss to facilitate end-to-end training of polygon generators. We are able to validate the effectiveness of gradient-based shape optimization with the example of airfoil optimization, and using the differentiable rasterization loss to facilitate end-to-end training, we surpass state of the art for polygonal image segmentation given ground-truth bounding boxes.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",25.42857142857143,-0.02083333333333333,0.3687500000000001,1,0.09691629955947137,0.05726872246696035,0.4258373205741627
1924,1964,1964,SSAP: Single-shot instance segmentation with affinity pyramid,"Recently, proposal-free instance segmentation has received increasing attention due to its concise and efficient pipeline. Generally, proposal-free methods generate instance-agnostic semantic segmentation labels and instance-aware features to group pixels into different object instances. However, previous methods mostly employ separate modules for these two sub-tasks and require multiple passes for inference. We argue that treating these two sub-tasks separately is suboptimal. In fact, employing multiple separate modules significantly reduces the potential for application. The mutual benefits between the two complementary sub-tasks are also unexplored. To this end, this work proposes a single-shot proposal-free instance segmentation method that requires only one single pass for prediction. Our method is based on a pixel-pair affinity pyramid, which computes the probability that two pixels belong to the same instance in a hierarchical manner. The affinity pyramid can also be jointly learned with the semantic class labeling and achieve mutual benefits. Moreover, incorporating with the learned affinity pyramid, a novel cascaded graph partition module is presented to sequentially generate instances from coarse to fine. Unlike previous time-consuming graph partition methods, this module achieves 5× speedup and 9% relative improvement on Average-Precision (AP). Our approach achieves new state of the art on the challenging Cityscapes dataset.",60121156,Horizon Robotics,Haidian,China,"['1712', '1707']",16.583333333333336,0.07741341991341992,0.4413582251082252,1,0.10121457489878542,0.016194331983805668,0.3542600896860987
1925,1965,1965,Towards interpretable object detection by unfolding latent structures,"This paper first proposes a method of formulating model interpretability in visual understanding tasks based on the idea of unfolding latent structures. It then presents a case study in object detection using popular two-stage region-based convolutional network (i.e., R-CNN) detection systems. The proposed method focuses on weakly-supervised extractive rationale generation, that is learning to unfold latent discriminative part configurations of object instances automatically and simultaneously in detection without using any supervision for part configurations. It utilizes a top-down hierarchical and compositional grammar model embedded in a directed acyclic AND-OR Graph (AOG) to explore and unfold the space of latent part configurations of regions of interest (RoIs). It presents an AOGParsing operator that seamlessly integrates with the RoIPooling/RoIAlign operator widely used in R-CNN and is trained end-to-end. In object detection, a bounding box is interpreted by the best parse tree derived from the AOG on-the-fly, which is treated as the qualitatively extractive rationale generated for interpreting detection. In experiments, Faster R-CNN is used to test the proposed method on the PASCAL VOC 2007 and the COCO 2017 object detection datasets. The experimental results show that the proposed method can compute promising latent structures without hurting the performance. The code and pretrained models are available at https://github.com/iVMCL/iRCNN.",60004923,NC State University,Raleigh,United States,"['1712', '1707']",22.777777777777782,0.2833333333333334,0.3703703703703704,1,0.15139442231075698,0.07569721115537849,0.3656387665198238
1926,1966,1966,Attributing fake images to GANs: Learning and analyzing GAN fingerprints,"Recent advances in Generative Adversarial Networks (GANs) have shown increasing success in generating photorealistic images. But they also raise challenges to visual forensics and model attribution. We present the first study of learning GAN fingerprints towards image attribution and using them to classify an image as real or GAN-generated. For GAN-generated images, we further identify their sources. Our experiments show that (1) GANs carry distinct model fingerprints and leave stable fingerprints in their generated images, which support image attribution; (2) even minor differences in GAN training can result in different fingerprints, which enables fine-grained model authentication; (3) fingerprints persist across different image frequencies and patches and are not biased by GAN artifacts; (4) fingerprint finetuning is effective in immunizing against five types of adversarial image perturbations; and (5) comparisons also show our learned fingerprints consistently outperform several baselines in a variety of setups.",60117087,CISPA - Helmholtz Center for Information Security,Saarbrücken,Germany,"['1712', '1707']",28.6,0.13214285714285715,0.29523809523809524,1,0.15028901734104047,0.04046242774566474,0.4550898203592814
1927,1967,1967,An internal learning approach to video inpainting,"We propose a novel video inpainting algorithm that simultaneously hallucinates missing appearance and motion (optical flow) information, building upon the recent 'Deep Image Prior' (DIP) that exploits convolutional network architectures to enforce plausible texture in static images. In extending DIP to video we make two important contributions. First, we show that coherent video inpainting is possible without a priori training. We take a generative approach to inpainting based on internal (within-video) learning without reliance upon an external corpus of visual data to train a one-size-fits-all model for the large space of general videos. Second, we show that such a framework can jointly generate both appearance and flow, whilst exploiting these complementary modalities to ensure mutual consistency. We show that leveraging appearance statistics specific to each video achieves visually plausible results whilst handling the challenging problem of long-term consistency.",60021097,University of Surrey,Guildford,United Kingdom,"['1712', '1707']",23.0,0.16071428571428573,0.4143452380952381,1,0.1566265060240964,0.012048192771084338,0.3032258064516129
1928,1968,1968,End-to-end hand mesh recovery from a monocular RGB image,"In this paper, we present a HAnd Mesh Recovery (HAMR) framework to tackle the problem of reconstructing the full 3D mesh of a human hand from a single RGB image. In contrast to existing research on 2D or 3D hand pose estimation from RGB or/and depth image data, HAMR can provide a more expressive and useful mesh representation for monocular hand image understanding. In particular, the mesh representation is achieved by parameterizing a generic 3D hand model with shape and relative 3D joint angles. By utilizing this mesh representation, we can easily compute the 3D joint locations via linear interpolations between the vertexes of the mesh, while obtain the 2D joint locations with a projection of the 3D joints. To this end, a differentiable re-projection loss can be defined in terms of the derived representations and the ground-truth labels, thus making our framework end-to-end trainable. Qualitative experiments show that our framework is capable of recovering appealing 3D hand mesh even in the presence of severe occlusions. Quantitatively, our approach also outperforms the state-of-the-art methods for both 2D and 3D hand pose estimation from a monocular RGB image on several benchmark datasets.",60013789,Beihang University,Beijing,China,"['1712', '1707']",27.285714285714285,0.22704081632653064,0.3164965986394558,1,0.09375,0.026785714285714284,0.3317307692307692
1929,1969,1969,Domain adaptation for structured output via discriminative patch representations,"Predicting structured outputs such as semantic segmentation relies on expensive per-pixel annotations to learn supervised models like convolutional neural networks. However, models trained on one data domain may not generalize well to other domains without annotations for model finetuning. To avoid the labor-intensive process of annotation, we develop a domain adaptation method to adapt the source data to the unlabeled target domain. We propose to learn discriminative feature representations of patches in the source domain by discovering multiple modes of patch-wise output distribution through the construction of a clustered space. With such representations as guidance, we use an adversarial learning scheme to push the feature representations of target patches in the clustered space closer to the distributions of source patches. In addition, we show that our framework is complementary to existing domain adaptation techniques and achieves consistent improvements on semantic segmentation. Extensive ablations and results are demonstrated on numerous benchmark datasets with various settings, such as synthetic-to-real and cross-city scenarios.",60030612,"University of California, San Diego",San Diego,United States,"['1712', '1707']",22.857142857142854,-0.0375,0.4158333333333333,1,0.10326086956521739,0.0,0.31976744186046513
1930,1970,1970,Spatiotemporal feature residual propagation for action prediction,"Recognizing actions from limited preliminary video observations has seen considerable recent progress. Typically, however, such progress has been had without explicitly modeling fine-grained motion evolution as a potentially valuable information source. In this study, we address this task by investigating how action patterns evolve over time in a spatial feature space. There are three key components to our system. First, we work with intermediate-layer ConvNet features, which allow for abstraction from raw data, while retaining spatial layout, which is sacrificed in approaches that rely on vectorized global representations. Second, instead of propagating features per se, we propagate their residuals across time, which allows for a compact representation that reduces redundancy while retaining essential information about evolution over time. Third, we employ a Kalman filter to combat error build-up and unify across prediction start times. Extensive experimental results on the JHMDB21, UCF101 and BIT datasets show that our approach leads to a new state-of-the-art in action prediction.",60033420,York University,Toronto,Canada,"['1712', '1707']",19.5,0.01763884263884264,0.3514226514226514,1,0.13297872340425532,0.026595744680851064,0.3181818181818182
1931,1971,1971,Face-to-parameter translation for game character auto-creation,"Character customization system is an important component in Role-Playing Games (RPGs), where players are allowed to edit the facial appearance of their in-game characters with their own preferences rather than using default templates. This paper proposes a method for automatically creating in-game characters of players according to an input face photo. We formulate the above 'artistic creation' process under a facial similarity measurement and parameter searching paradigm by solving an optimization problem over a large set of physically meaningful facial parameters. To effectively minimize the distance between the created face and the real one, two loss functions, i.e. a 'discriminative loss' and a 'facial content loss', are specifically designed. As the rendering process of a game engine is not differentiable, a generative network is further introduced as an 'imitator' to imitate the physical behavior of the game engine so that the proposed method can be implemented under a neural style transfer framework and the parameters can be optimized by gradient descent. Experimental results demonstrate that our method achieves a high degree of generation similarity between the input face photo and the created in-game character in terms of both global appearance and local details. Our method has been deployed in a new game last year and has now been used by players over 1 million times.",60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,"['1712', '1707']",26.875,0.08886881234707324,0.3666365518539432,1,0.09795918367346938,0.012244897959183673,0.28205128205128205
1932,1972,1972,Guided super-resolution as pixel-to-pixel transformation,"Guided super-resolution is a unifying framework for several computer vision tasks where the inputs are a low-resolution source image of some target quantity (e.g., perspective depth acquired with a time-of-flight camera) and a high-resolution guide image from a different domain (e.g., a grey-scale image from a conventional camera); and the target output is a high-resolution version of the source (in our example, a high-res depth map). The standard way of looking at this problem is to formulate it as a super-resolution task, i.e., the source image is upsampled to the target resolution, while transferring the missing high-frequency details from the guide. Here, we propose to turn that interpretation on its head and instead see it as a pixel-to-pixel mapping of the guide image to the domain of the source image. The pixel-wise mapping is parametrised as a multi-layer perceptron, whose weights are learned by minimising the discrepancies between the source image and the downsampled target image. Importantly, our formulation makes it possible to regularise only the mapping function, while avoiding regularisation of the outputs; thus producing crisp, natural-looking images. The proposed method is unsupervised, using only the specific source and guide images to fit the mapping. We evaluate our method on two different tasks, super-resolution of depth maps and of tree height maps. In both cases, we clearly outperform recent baselines in quantitative comparisons, while delivering visually much sharper outputs.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",28.75,0.06294642857142857,0.4613839285714286,1,0.08532423208191127,0.0,0.32950191570881227
1933,1973,1973,AWSD: Adaptive weighted spatiotemporal distillation for video representation,"We propose an Adaptive Weighted Spatiotemporal Distillation (AWSD) technique for video representation by encoding the appearance and dynamics of the videos into a single RGB image map. This is obtained by adaptively dividing the videos into small segments and comparing two consecutive segments. This allows using pre-trained models on still images for video classification while successfully capturing the spatiotemporal variations in the videos. The adaptive segment selection enables effective encoding of the essential discriminative information of untrimmed videos. Based on Gaussian Scale Mixture, we compute the weights by extracting the mutual information between two consecutive segments. Unlike pooling-based methods, our AWSD gives more importance to the frames that characterize actions or events thanks to its adaptive segment length selection. We conducted extensive experimental analysis to evaluate the effectiveness of our proposed method and compared our results against those of recent state-of-the-art methods on four benchmark datatsets, including UCF101, HMDB51, ActivityNet v1.3, and Maryland. The obtained results on these benchmark datatsets showed that our method significantly outperforms earlier works and sets the new state-of-the-art performance in video classification. Code is available at the project webpage: Https://mohammadt68.github.io/AWSD/.",60103653,Aalto University,Espoo,Finland,"['1712', '1707']",20.555555555555557,0.19570964749536174,0.4697974644403216,1,0.12385321100917432,0.045871559633027525,0.424390243902439
1934,1974,1974,RIO: 3D object instance re-localization in changing indoor environments,"In this work, we introduce the task of 3D object instance re-localization (RIO): Given one or multiple objects in an RGB-D scan, we want to estimate their corresponding 6DoF poses in another 3D scan of the same environment taken at a later point in time. We consider RIO a particularly important task in 3D vision since it enables a wide range of practical applications, including AI-assistants or robots that are asked to find a specific object in a 3D scene. To address this problem, we first introduce 3RScan, a novel dataset and benchmark, which features 1482 RGB-D scans of 478 environments across multiple time steps. Each scene includes several objects whose positions change over time, together with ground truth annotations of object instances and their respective 6DoF mappings among re-scans. Automatically finding 6DoF object poses leads to a particular challenging feature matching task due to varying partial observations and changes in the surrounding context. To this end, we introduce a new data-driven approach that efficiently finds matching features using a fully-convolutional 3D correspondence network operating on multiple spatial scales. Combined with a 6DoF pose optimization, our method outperforms state-of-the-art baselines on our newly-established benchmark, achieving an accuracy of 30.58%.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",28.42857142857143,0.07050189393939395,0.2841382575757576,1,0.11983471074380166,0.012396694214876033,0.38636363636363635
1935,1975,1975,Deep joint-semantics reconstructing hashing for large-scale unsupervised cross-modal retrieval,"Cross-modal hashing encodes the multimedia data into a common binary hash space in which the correlations among the samples from different modalities can be effectively measured. Deep cross-modal hashing further improves the retrieval performance as the deep neural networks can generate more semantic relevant features and hash codes. In this paper, we study the unsupervised deep cross-modal hash coding and propose Deep Joint-Semantics Reconstructing Hashing (DJSRH), which has the following two main advantages. First, to learn binary codes that preserve the neighborhood structure of the original data, DJSRH constructs a novel joint-semantics affinity matrix which elaborately integrates the original neighborhood information from different modalities and accordingly is capable to capture the latent intrinsic semantic affinity for the input multi-modal instances. Second, DJSRH later trains the networks to generate binary codes that maximally reconstruct above joint-semantics relations via the proposed reconstructing framework, which is more competent for the batch-wise training as it reconstructs the specific similarity value unlike the common Laplacian constraint merely preserving the similarity order. Extensive experiments demonstrate the significant improvement by DJSRH in various cross-modal retrieval tasks.",60014966,Peking University,Beijing,China,"['1712', '1707']",29.83333333333333,0.1255747126436782,0.474712643678161,1,0.10900473933649289,0.037914691943127965,0.3316062176165803
1936,1976,1976,G3raphGround: Graph-based language grounding,"In this paper we present an end-to-end framework for grounding of phrases in images. In contrast to previous works, our model, which we call GraphGround, uses graphs to formulate more complex, non-sequential dependencies among proposal image regions and phrases. We capture intra-modal dependencies using a separate graph neural network for each modality (visual and lingual), and then use conditional message-passing in another graph neural network to fuse their outputs and capture cross-modal relationships. This final representation results in grounding decisions. The framework supports many-to-many matching and is able to ground single phrase to multiple image regions and vice versa. We validate our design choices through a series of ablation studies and illustrate state-of-the-art performance on Flickr30k and ReferIt Game benchmark datasets.",60010365,The University of British Columbia,Vancouver,Canada,"['1712', '1707']",20.166666666666668,0.006190476190476202,0.33059523809523805,1,0.10256410256410256,0.02564102564102564,0.3656716417910448
1937,1977,1977,Fast video object segmentation via dynamic targeting network,"We propose a new model for fast and accurate video object segmentation. It consists of two convolutional neural networks, a Dynamic Targeting Network (DTN) and a Mask Refinement Network (MRN). DTN locates the object by dynamically focusing on regions of interest surrounding the target object. The target region is predicted by DTN via two sub-streams, Box Propagation (BP) and Box Re-identification (BR). The BP stream is faster but less effective at objects with large deformation or occlusion. The BR stream performs better in difficult scenarios at a higher computation cost. We propose a Decision Module (DM) to adaptively determine which sub-stream to use for each frame. Finally, MRN is exploited to predict segmentation within the target region. Experimental results on two public datasets demonstrate that the proposed model significantly outperforms existing methods without online training in both accuracy and efficiency, and is comparable to online training-based methods in accuracy with an order of magnitude faster speed.",60076047,Adobe Inc.,San Jose,United States,"['1712', '1707']",17.333333333333332,0.15064162028447742,0.5351035868893012,1,0.09090909090909091,0.11764705882352941,0.4022346368715084
1938,1978,1978,XRAI: Better attributions through regions,"Saliency methods can aid understanding of deep neural networks. Recent years have witnessed many improvements to saliency methods, as well as new ways for evaluating them. In this paper, we 1) present a novel region-based attribution method, XRAI, that builds upon integrated gradients (Sundararajan et al. 2017), 2) introduce evaluation methods for empirically assessing the quality of image-based saliency maps (Performance Information Curves (PICs)), and 3) contribute an axiom-based sanity check for attribution methods. Through empirical experiments and example results, we show that XRAI produces better results than other saliency methods for common models and the ImageNet dataset.",60006191,Google LLC,Mountain View,United States,"['1712', '1707']",19.6,0.09113636363636364,0.3179545454545455,1,0.128,0.08,0.5546218487394958
1939,1979,1979,MVSCRF: Learning multi-view stereo with conditional random fields,"We present a deep-learning architecture for multi-view stereo with conditional random fields (MVSCRF). Given an arbitrary number of input images, we first use a U-shape neural network to extract deep features incorporating both global and local information, and then build a 3D cost volume for the reference camera. Unlike previous learning based methods, we explicitly constraint the smoothness of depth maps by using conditional random fields (CRFs) after the stage of cost volume regularization. The CRFs module is implemented as recurrent neural networks so that the whole pipeline can be trained end-to-end. Our results show that the proposed pipeline outperforms previous state-of-the-arts on large-scale DTU dataset. We also achieve comparable results with state-of-the-art learning based methods on outdoor Tanks and Temples dataset without fine-tuning, which demonstrates our method's generalization ability.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",21.66666666666667,-0.08939393939393939,0.27878787878787875,1,0.11695906432748537,0.029239766081871343,0.36551724137931035
1940,1981,1981,AFD-net: Aggregated feature difference learning for cross-spectral image patch matching,"Image patch matching across different spectral domains is more challenging than in a single spectral domain. We consider the reason is twofold: 1. the weaker discriminative feature learned by conventional methods; 2. the significant appearance difference between two images domains. To tackle these problems, we propose an aggregated feature difference learning network (AFD-Net). Unlike other methods that merely rely on the high-level features, we find the feature differences in other levels also provide useful learning information. Thus, the multi-level feature differences are aggregated to enhance the discrimination. To make features invariant across different domains, we introduce a domain invariant feature extraction network based on instance normalization (IN). In order to optimize the AFD-Net, we borrow the large margin cosine loss which can minimize intra-class distance and maximize inter-class distance between matching and non-matching samples. Extensive experiments show that AFD-Net largely outperforms the state-of-the-arts on the cross-spectral dataset, meanwhile, demonstrates a considerable generalizability on a single spectral dataset.",60025578,Xidian University,Xi'an,China,"['1712', '1707']",15.7,0.07299107142857145,0.4531994047619048,1,0.11274509803921569,0.03431372549019608,0.3651685393258427
1941,1982,1982,Revisiting radial distortion absolute pose,"To model radial distortion there are two main approaches; either the image points are undistorted such that they correspond to pinhole projections, or the pinhole projections are distorted such that they align with the image measurements. Depending on the application, either of the two approaches can be more suitable. For example, distortion models are commonly used in Structure-from-Motion since they simplify measuring the reprojection error in images. Surprisingly, all previous minimal solvers for pose estimation with radial distortion use undistortion models. In this paper we aim to fill this gap in the literature by proposing the first minimal solvers which can jointly estimate distortion models together with camera pose. We present a general approach which can handle rational models of arbitrary degree for both distortion and undistortion.",60026532,Microsoft Corporation,Redmond,United States,"['1712', '1707']",21.166666666666668,0.10357142857142856,0.4559523809523808,1,0.11971830985915492,0.0,0.2463768115942029
1942,1983,1983,A study on factors effecting the employees attrition in hotel industry with reference Hyderabad,"The hotel industry is experiencing many issues along with the economic slump impact on the footfall. The present study has been emphasized on the factors effecting the employees’ attrition in hotel industry. The study has considered the 4 and 5 stars rated employees as the sample respondents in Hyderabad district of Telangana state. The study mainly focused on the factors effecting the attrition and the measures to control. The study applied the simple random methodology to determine the sample size and collected the primary data. The structure equation model has been applied to know the effect of factors on the attrition of employees and the result stated that the long working hours are significantly influencing followed by the low job profile. The factor analysis has been applied for the suggestive measures and the result stated that the management should decrease the working hours and they should offer the incentives with recognition for the employees, so that the service quality level will be improved in the hotel industry. This paper is useful to the hotel industry management, employees and other related sectors.",60079446,K L Deemed to be University,Vaddeswaram,India,['1706'],22.625,0.09743589743589744,0.3646520146520145,1,0.13020833333333334,0.010416666666666666,0.234375
1943,1984,1984,On the efficacy of knowledge distillation,"In this paper, we present a thorough evaluation of the efficacy of knowledge distillation and its dependence on student and teacher architectures. Starting with the observation that more accurate teachers often don't make good teachers, we attempt to tease apart the factors that affect knowledge distillation performance. We find crucially that larger models do not often make better teachers. We show that this is a consequence of mismatched capacity, and that small students are unable to mimic large teachers. We find typical ways of circumventing this (such as performing a sequence of knowledge distillation steps) to be ineffective. Finally, we show that this effect can be mitigated by stopping the teacher's training early. Our results generalize across datasets and models.",60007776,Cornell University,Ithaca,United States,"['1712', '1707']",17.142857142857142,0.09984126984126984,0.4974603174603175,1,0.14074074074074075,0.0,0.28888888888888886
1944,1985,1985,AdvIT: Adversarial frames identifier based on temporal consistency in videos,"Deep neural networks (DNNs) have been widely applied in various applications, including autonomous driving and surveillance systems. However, DNNs are found to be vulnerable to adversarial examples, which are carefully crafted inputs aiming to mislead a learner to make incorrect predictions. While several defense and detection approaches are proposed for static image classification, many security-critical tasks use videos as their input and require efficient processing. In this paper, we propose an efficient and effective method advIT to detect adversarial frames within videos against different types of attacks based on temporal consistency property of videos. In particular, we apply optical flow estimation to the target and previous frames to generate pseudo frames and evaluate the consistency of the learner output between these pseudo frames and target. High inconsistency indicates that the target frame is adversarial. We conduct extensive experiments on various learning tasks including video semantic segmentation, human pose estimation, object detection, and action recognition, and demonstrate that we can achieve above 95% adversarial frame detection rate. To consider adaptive attackers, we show that even if an adversary has access to the detector and performs a strong adaptive attack based on the state of the art expectation of transformation method, the detection rate stays almost the same. We also tested the transferability among different optical flow estimators and show that it is hard for attackers to attack one and transfer the perturbation to others. In addition, as efficiency is important in video analysis, we show that advIT can achieve real-time detection in about 0.03 - 0.4 seconds.",60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,"['1712', '1707']",25.6,0.08756944444444444,0.4780555555555554,1,0.12195121951219512,0.003484320557491289,0.29328621908127206
1945,1986,1986,Online hyper-parameter learning for auto-augmentation strategy,"Data augmentation is critical to the success of modern deep learning techniques. In this paper, we propose Online Hyper-parameter Learning for Auto-Augmentation (OHL-Auto-Aug), an economical solution that learns the augmentation policy distribution along with network training. Unlike previous methods on auto-augmentation that search augmentation strategies in an offline manner, our method formulates the augmentation policy as a parameterized probability distribution, thus allowing its parameters to be optimized jointly with network parameters. Our proposed OHL-Auto-Aug eliminates the need of re-training and dramatically reduces the cost of the overall search process, while establishes significantly accuracy improvements over baseline models. On both CIFAR-10 and ImageNet, our method achieves remarkable on search accuracy, 60x faster on CIFAR-10 and 24x faster on ImageNet, while maintaining competitive accuracies.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",24.4,0.1953703703703704,0.4657407407407407,1,0.0718954248366013,0.0915032679738562,0.40145985401459855
1946,1987,1987,Floor-SP: Inverse CAD for floorplans by sequential room-wise shortest path,"This paper proposes a new approach for automated floorplan reconstruction from RGBD scans, a major milestone in indoor mapping research. The approach, dubbed Floor-SP, formulates a novel optimization problem, where room-wise coordinate descent sequentially solves shortest path problems to optimize the floorplan graph structure. The objective function consists of data terms guided by deep neural networks, consistency terms encouraging adjacent rooms to share corners and walls, and the model complexity term. The approach does not require corner/edge primitive extraction unlike most other methods. We have evaluated our system on production-quality RGBD scans of 527 apartments or houses, including many units with non-Manhattan structures. Qualitative and quantitative evaluations demonstrate a significant performance boost over the current state-of-the-art. Please refer to our project website http://jcchen.me/floor-sp/ for code and data.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",18.142857142857142,0.16098484848484848,0.4560606060606061,1,0.09554140127388536,0.025477707006369428,0.4195804195804196
1947,1988,1988,Deformable surface tracking by graph matching,"This paper addresses the problem of deformable surface tracking from monocular images. Specifically, we propose a graph-based approach that effectively explores the structure information of the surface to enhance tracking performance. Our approach solves simultaneously for feature correspondence, outlier rejection and shape reconstruction by optimizing a single objective function, which is defined by means of pairwise projection errors between graph structures instead of unary projection errors between matched points. Furthermore, an efficient matching algorithm is developed based on soft matching relaxation. For evaluation, our approach is extensively compared to state-of-the-art algorithms on a standard dataset of occluded surfaces, as well as a newly compiled dataset of different surfaces with rich, weak or repetitive texture. Experimental results reveal that our approach achieves robust tracking results for surfaces with different types of texture, and outperforms other algorithms in both accuracy and efficiency.",60026415,Stony Brook University,Stony Brook,United States,"['1712', '1707']",23.33333333333333,0.039329004329004325,0.4101443001443002,1,0.10493827160493827,0.0,0.33116883116883117
1948,1989,1989,Diverse image synthesis from semantic layouts via conditional IMLE,"Most existing methods for conditional image synthesis are only able to generate a single plausible image for any given input, or at best a fixed number of plausible images. In this paper, we focus on the problem of generating images from semantic segmentation maps and present a simple new method that can generate an arbitrary number of images with diverse appearance for the same semantic layout. Unlike most existing approaches which adopt the GAN framework, our method is based on the recently introduced Implicit Maximum Likelihood Estimation (IMLE) framework. Compared to the leading approach, our method is able to generate more diverse images while producing fewer artifacts despite using the same architecture. The learned latent space also has sensible structure despite the lack of supervision that encourages such behaviour.",60033100,Nanjing University,Nanjing,China,"['1712', '1707']",25.8,0.2402597402597403,0.41452494873547496,1,0.1357142857142857,0.04285714285714286,0.2642857142857143
1949,1990,1990,Bayesian adaptive superpixel segmentation,"Superpixels provide a useful intermediate image representation. Existing superpixel methods, however, suffer from at least some of the following drawbacks: 1) topology is handled heuristically; 2) the number of superpixels is either predefined or estimated at a prohibitive cost; 3) lack of adaptiveness. As a remedy, we propose a novel probabilistic model, self-coined Bayesian Adaptive Superpixel Segmentation (BASS), together with an efficient inference. BASS is a Bayesian nonparametric mixture model that also respects topology and favors spatial coherence. The optimizationbased and topology-aware inference is parallelizable and implemented in GPU. Quantitatively, BASS achieves results that are either better than the state-of-the-art or close to it, depending on the performance index and/or dataset. Qualitatively, we argue it achieves the best results; we demonstrate this by not only subjective visual inspection but also objective quantitative performance evaluation of the downstream application of face detection. Our code is available at https://github.com/uzielroy/BASS.",60027161,Ben-Gurion University of the Negev,Beer Sheba,Israel,"['1712', '1707']",18.375,0.1208333333333333,0.3583333333333333,1,0.08791208791208792,0.04945054945054945,0.3793103448275862
1950,1991,1991,End-to-end learning for graph decomposition,"Deep neural networks provide powerful tools for pattern recognition, while classical graph algorithms are widely used to solve combinatorial problems. In computer vision, many tasks combine elements of both pattern recognition and graph reasoning. In this paper, we study how to connect deep networks with graph decomposition into an end-to-end trainable framework. More specifically, the minimum cost multicut problem is first converted to an unconstrained binary cubic formulation where cycle consistency constraints are incorporated into the objective function. The new optimization problem can be viewed as a Conditional Random Field (CRF) in which the random variables are associated with the binary edge labels. Cycle constraints are introduced into the CRF as high-order potentials. A standard Convolutional Neural Network (CNN) provides the front-end features for the fully differentiable CRF. The parameters of both parts are optimized in an end-to-end manner. The efficacy of the proposed learning algorithm is demonstrated via experiments on clustering MNIST images and on the challenging task of real-world multi-people pose estimation.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",18.222222222222218,0.0775974025974026,0.4348484848484849,1,0.09644670050761421,0.06091370558375635,0.35359116022099446
1951,1992,1992,Pareto meets huber: Efficiently avoiding poor minima in robust estimation,"Robust cost optimization is the task of fitting parameters to data points containing outliers. In particular, we focus on large-scale computer vision problems, such as bundle adjustment, where Non-Linear Least Square (NLLS) solvers are the current workhorse. In this context, NLLS-based state of the art algorithms have been designed either to quickly improve the target objective and find a local minimum close to the initial value of the parameters, or to have a strong ability to escape poor local minima. In this paper, we propose a novel algorithm relying on multi-objective optimization which allows to match those two properties. We experimentally demonstrate that our algorithm has an ability to escape poor local minima that is on par with the best performing algorithms with a faster decrease of the target objective.",60102125,Université de Bordeaux,Bordeaux,France,"['1712', '1707']",26.0,0.08431372549019607,0.3215686274509804,1,0.09271523178807947,0.026490066225165563,0.27972027972027974
1952,1993,1993,Tex2shape: Detailed full human body geometry from a single image,"We present a simple yet effective method to infer detailed full human body shape from only a single photograph. Our model can infer full-body shape including face, hair, and clothing including wrinkles at interactive frame-rates. Results feature details even on parts that are occluded in the input image. Our main idea is to turn shape regression into an aligned image-to-image translation problem. The input to our method is a partial texture map of the visible region obtained from off-the-shelf methods. From a partial texture, we estimate detailed normal and vector displacement maps, which can be applied to a low-resolution smooth body model to add detail and clothing. Despite being trained purely with synthetic data, our model generalizes well to real-world photographs. Numerous results demonstrate the versatility and robustness of our method.",60007902,Technische Universität Braunschweig,Braunschweig,Germany,"['1712', '1707']",16.375,0.1505952380952381,0.47529761904761897,1,0.1125,0.0,0.2708333333333333
1953,1994,1994,ACE: Adapting to changing environments for semantic segmentation,"Deep neural networks exhibit exceptional accuracy when they are trained and tested on the same data distributions. However, neural classifiers are often extremely brittle when confronted with domain shift - -changes in the input distribution that occur over time. We present ACE, a framework for semantic segmentation that dynamically adapts to changing environments over time. By aligning the distribution of labeled training data from the original source domain with the distribution of incoming data in a shifted domain, ACE synthesizes labeled training data for environments as it sees them. This stylized data is then used to update a segmentation model so that it performs well in new environments. To avoid forgetting knowledge from past environments, we introduce a memory that stores feature statistics from previously seen domains. These statistics can be used to replay images in any of the previously observed domains, thus preventing catastrophic forgetting. In addition to standard batch training using stochastic gradient decent (SGD), we also experiment with fast adaptation methods based on adaptive meta-learning. Extensive experiments are conducted on two datasets from SYNTHIA, the results demonstrate the effectiveness of the proposed approach when adapting to a number of tasks.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",21.444444444444443,0.05974025974025975,0.4223484848484849,1,0.17370892018779344,0.023474178403755867,0.3175355450236967
1954,1995,1995,Mask-shadowGAN: Learning to remove shadows from unpaired data,"This paper presents a new method for shadow removal using unpaired data, enabling us to avoid tedious annotations and obtain more diverse training samples. However, directly employing adversarial learning and cycle-consistency constraints is insufficient to learn the underlying relationship between the shadow and shadow-free domains, since the mapping between shadow and shadow-free images is not simply one-to-one. To address the problem, we formulate Mask-ShadowGAN, a new deep framework that automatically learns to produce a shadow mask from the input shadow image and then takes the mask to guide the shadow generation via re-formulated cycle-consistency constraints. Particularly, the framework simultaneously learns to produce shadow masks and learns to remove shadows, to maximize the overall performance. Also, we prepared an unpaired dataset for shadow removal and demonstrated the effectiveness of Mask-ShadowGAN on various experiments, even it was trained on unpaired data.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",27.8,0.05393939393939393,0.43995670995671005,1,0.13450292397660818,0.023391812865497075,0.3137254901960784
1955,1996,1996,Sharpen focus: Learning with attention separability and consistency,"Recent developments in gradient-based attention modeling have seen attention maps emerge as a powerful tool for interpreting convolutional neural networks. Despite good localization for an individual class of interest, these techniques produce attention maps with substantially overlapping responses among different classes, leading to the problem of visual confusion and the need for discriminative attention. In this paper, we address this problem by means of a new framework that makes class-discriminative attention a principled part of the learning process. Our key innovations include new learning objectives for attention separability and cross-layer consistency, which result in improved attention discriminability and reduced visual confusion. Extensive experiments on image classification benchmarks show the effectiveness of our approach in terms of improved classification accuracy, including CIFAR-100 (+3.33%), Caltech-256 (+1.64%), ImageNet (+0.92%), CUB-200-2011 (+4.8%) and PASCAL VOC2012 (+5.73%).",60119141,Rutgers University–New Brunswick,New Brunswick,United States,"['1712', '1707']",26.4,0.11570247933884295,0.4629476584022038,1,0.08928571428571429,0.07142857142857142,0.4125
1956,1997,1997,Stochastic attraction-repulsion embedding for large scale image localization,"This paper tackles the problem of large-scale image-based localization (IBL) where the spatial location of a query image is determined by finding out the most similar reference images in a large database. For solving this problem, a critical task is to learn discriminative image representation that captures informative information relevant for localization. We propose a novel representation learning method having higher location-discriminating power. It provides the following contributions: 1) we represent a place (location) as a set of exemplar images depicting the same landmarks and aim to maximize similarities among intra-place images while minimizing similarities among inter-place images; 2) we model a similarity measure as a probability distribution on L-2-metric distances between intra-place and inter-place image representations; 3) we propose a new Stochastic Attraction and Repulsion Embedding (SARE) loss function minimizing the KL divergence between the learned and the actual probability distributions; 4) we give theoretical comparisons between SARE, triplet ranking and contrastive losses. It provides insights into why SARE is better by analyzing gradients. Our SARE loss is easy to implement and pluggable to any CNN. Experiments show that our proposed method improves the localization performance on standard benchmarks by a large margin. Demonstrating the broad applicability of our method, we obtained the third place out of 209 teams in the 2018 Google Landmark Retrieval Challenge. Our code and model are available at https://github.com/Liumouliu/deepIBL.",60108693,Australian Centre for Robotic Vision,Brisbane,Australia,"['1712', '1707']",25.0,0.17282046657046654,0.3823623136123136,1,0.1169811320754717,0.05660377358490566,0.38735177865612647
1957,1998,1998,Copy-and-paste networks for deep video inpainting,"We present a novel deep learning based algorithm for video inpainting. Video inpainting is a process of completing corrupted or missing regions in videos. Video inpainting has additional challenges compared to image inpainting due to the extra temporal information as well as the need for maintaining the temporal coherency. We propose a novel DNN-based framework called the Copy-and-Paste Networks for video inpainting that takes advantage of additional information in other frames of the video. The network is trained to copy corresponding contents in reference frames and paste them to fill the holes in the target frame. Our network also includes an alignment network that computes homographies between frames for the alignment, enabling the network to take information from more distant frames for robustness. Our method produces visually pleasing and temporally coherent results while running faster than the state-of-the-art optimization-based method. In addition, we extend our framework for enhancing over/under exposed frames in videos. Using this enhancement technique, we were able to significantly improve the lane detection accuracy on road videos.",60016912,Yonsei University,Seoul,South Korea,"['1712', '1707']",18.88888888888889,0.11041666666666666,0.3625,1,0.14646464646464646,0.020202020202020204,0.3021978021978022
1958,2000,2000,Proximal mean-field for neural network quantization,"Compressing large Neural Networks (NN) by quantizing the parameters, while maintaining the performance is highly desirable due to reduced memory and time complexity. In this work, we cast NN quantization as a discrete labelling problem, and by examining relaxations, we design an efficient iterative optimization procedure that involves stochastic gradient descent followed by a projection. We prove that our simple projected gradient descent approach is, in fact, equivalent to a proximal version of the well-known mean-field method. These findings would allow the decades-old and theoretically grounded research on MRF optimization to be used to design better network quantization schemes. Our experiments on standard classification datasets (MNIST, CIFAR10/100, TinyImageNet) with convolutional and residual architectures show that our algorithm obtains fully-quantized networks with accuracies very close to the floating-point reference networks.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",25.8,0.11866071428571427,0.3250892857142857,1,0.1346153846153846,0.04487179487179487,0.3561643835616438
1959,2001,2001,View confusion feature learning for person re-identification,"Person re-identification is an important task in video surveillance that aims to associate people across camera views at different locations and time. View variability is always a challenging problem seriously degrading person re-identification performance. Most of the existing methods either focus on how to learn view invariant feature or how to combine viewwise features. In this paper, we mainly focus on how to learn view-independent features by getting rid of view specific information through a view confusion learning mechanism. Specifically, we propose an end-to-end trainable framework, called View Confusion Feature Learning (VCFL), for person Re-ID across cameras. To the best of our knowledge, VCFL is originally proposed to learn view-independent identity-wise features, and it's a kind of combination of view-generic and view-specific methods. Furthermore, we extract sift-guided features by using bag-of-words model to help supervise the training of deep networks and enhance the view invariance of features. In experiments, our approach is validated on three benchmark datasets including CUHK01, CUHK03, and MARKET1501, which show the superiority of the proposed method over several state-of-the-art approaches.",60023380,Chongqing University,Chongqing,China,"['1712', '1707']",21.75,0.2673611111111111,0.5479166666666667,1,0.10964912280701754,0.04824561403508772,0.3877551020408163
1960,2002,2002,Learning shape templates with structured implicit functions,"Template 3D shapes are useful for many tasks in graphics and vision, including fitting observation data, analyzing shape collections, and transferring shape attributes. Because of the variety of geometry and topology of real-world shapes, previous methods generally use a library of hand-made templates. In this paper, we investigate learning a general shape template from data. To allow for widely varying geometry and topology, we choose an implicit surface representation based on composition of local shape elements. While long known to computer graphics, this representation has not yet been explored in the context of machine learning for vision. We show that structured implicit functions are suitable for learning and allow a network to smoothly and simultaneously fit multiple classes of shapes. The learned shape template supports applications such as shape exploration, correspondence, abstraction, interpolation, and semantic segmentation from an RGB image.",60003269,Princeton University,Princeton,United States,"['1712', '1707']",20.0,0.1738095238095238,0.3654761904761905,1,0.12345679012345678,0.012345679012345678,0.2848101265822785
1961,2003,2003,Learning propagation for arbitrarily-structured data,"Processing an input signal that contains arbitrary structures, e.g., superpixels and point clouds, remains a big challenge in computer vision. Linear diffusion, an effective model for image processing, has been recently integrated with deep learning algorithms. In this paper, we propose to learn pairwise relations among data points in a global fashion to improve semantic segmentation with arbitrarily-structured data, through spatial generalized propagation networks (SGPN). The network propagates information on a group of graphs, which represent the arbitrarily-structured data, through a learned, linear diffusion process. The module is flexible to be embedded and jointly trained with many types of networks, e.g., CNNs. We experiment with semantic segmentation networks, where we use our propagation module to jointly train on different data - images, superpixels, and point clouds. We show that SGPN consistently improves the performance of both pixel and point cloud segmentation, compared to networks that do not contain this module. Our method suggests an effective way to model the global pairwise relations for arbitrarily-structured data.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",20.625,0.16818181818181818,0.3909090909090909,1,0.12690355329949238,0.01015228426395939,0.3507853403141361
1962,2004,2004,Order-preserving wasserstein discriminant analysis,"Supervised dimensionality reduction for sequence data projects the observations in sequences onto a low-dimensional subspace to better separate different sequence classes. It is typically more challenging than conventional dimensionality reduction for static data, because measuring the separability of sequences involves non-linear procedures to manipulate the temporal structures. This paper presents a linear method, namely Order-preserving Wasserstein Discriminant Analysis (OWDA), which learns the projection by maximizing the inter-class distance and minimizing the intra-class scatter. For each class, OWDA extracts the order-preserving Wasserstein barycenter and constructs the intra-class scatter as the dispersion of the training sequences around the barycenter. The inter-class distance is measured as the order-preserving Wasserstein distance between the corresponding barycenters. OWDA is able to concentrate on the distinctive differences among classes by lifting the geometric relations with temporal constraints. Experiments show that OWDA achieves competitive results on three 3D action recognition datasets.",60025256,Institute of Software Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.428571428571427,0.3071428571428572,0.5727678571428572,1,0.11494252873563218,0.05172413793103448,0.3717948717948718
1963,2006,2006,FDA: Feature disruptive attack,"Though Deep Neural Networks (DNN) show excellent performance across various computer vision tasks, several works show their vulnerability to adversarial samples, i.e., image samples with imperceptible noise engineered to manipulate the network's prediction. Adversarial sample generation methods range from simple to complex optimization techniques. Majority of these methods generate adversaries through optimization objectives that are tied to the pre-softmax or softmax output of the network. In this work we, (i) show the drawbacks of such attacks, (ii) propose two new evaluation metrics: Old Label New Rank (OLNR) and New Label Old Rank (NLOR) in order to quantify the extent of damage made by an attack, and (iii) propose a new attack FDA: Feature Disruptive attack, to address the drawbacks of existing attacks. FDA works by generating image perturbation that disrupts features at each layer of the network and causes deep-features to be highly corrupt. This allows FDA adversaries to severely reduce the performance of deep networks. We experimentally validate that FDA generates stronger adversaries than other state-of-the-art methods for Image classification, even in the presence of various defense measures. More importantly, we show that FDA disrupts feature-representation based tasks even without access to the task-specific network or methodology.",60120917,"Preferred Networks, Inc.",Tokyo,Japan,"['1712', '1707']",24.75,0.0008893280632410992,0.5021880293619424,1,0.10245901639344263,0.08196721311475409,0.41739130434782606
1964,2007,2007,Few-shot adaptive gaze estimation,"Inter-personal anatomical differences limit the accuracy of person-independent gaze estimation networks. Yet there is a need to lower gaze errors further to enable applications requiring higher quality. Further gains can be achieved by personalizing gaze networks, ideally with few calibration samples. However, over-parameterized neural networks are not amenable to learning from few examples as they can quickly over-fit. We embrace these challenges and propose a novel framework for Few-shot Adaptive GaZE Estimation (Faze) for learning person-specific gaze networks with very few (≤ 9) calibration samples. Faze learns a rotation-aware latent representation of gaze via a disentangling encoder-decoder architecture along with a highly adaptable gaze estimator trained using meta-learning. It is capable of adapting to any new person to yield significant performance gains with as few as 3 samples, yielding state-of-the-art performance of 3.18-deg on GazeCapture, a 19% improvement over prior art. We open-source our code at https://github.com/NVlabs/few-shot-gaze.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",18.375,0.09297979797979798,0.41996969696969694,1,0.11052631578947368,0.042105263157894736,0.4036144578313253
1965,2008,2008,Linearly converging quasi branch and bound algorithms for global rigid registration,"In recent years, several branch-and-bound (BnB) algorithms have been proposed to globally optimize rigid registration problems. In this paper, we suggest a general framework to improve upon the BnB approach, which we name emph{Quasi BnB}. Quasi BnB replaces the linear lower bounds used in BnB algorithms with quadratic quasi-lower bounds which are based on the quadratic behavior of the energy in the vicinity of the global minimum. While quasi-lower bounds are not truly lower bounds, the Quasi-BnB algorithm is globally optimal. In fact we prove that it exhibits linear convergence - it achieves epsilon accuracy in O(log(1/epsilon)) time while the time complexity of other rigid registration BnB algorithms is polynomial in 1/epsilon. Our experiments verify that Quasi-BnB is significantly more efficient than state-of-the-art BnB algorithms, especially for problems where high accuracy is desired.",60008724,Duke University,Durham,United States,"['1712', '1707']",22.16666666666667,0.05850000000000001,0.3165,1,0.08187134502923976,0.07602339181286549,0.38064516129032255
1966,2009,2009,Fashion retrieval via graph reasoning networks on a similarity pyramid,"Matching clothing images from customers and online shopping stores has rich applications in E-commerce. Existing algorithms encoded an image as a global feature vector and performed retrieval with the global representation. However, discriminative local information on clothes are submerged in this global representation, resulting in sub-optimal performance. To address this issue, we propose a novel Graph Reasoning Network (GRNet) on a Similarity Pyramid, which learns similarities between a query and a gallery cloth by using both global and local representations in multiple scales. The similarity pyramid is represented by a Graph of similarity, where nodes represent similarities between clothing components at different scales, and the final matching score is obtained by message passing along edges. In GRNet, graph reasoning is solved by training a graph convolutional network, enabling to align salient clothing components to improve clothing retrieval. To facilitate future researches, we introduce a new benchmark FindFashion, containing rich annotations of bounding boxes, views, occlusions, and cropping. Extensive experiments show that GRNet obtains new state-of-the-art results on two challenging benchmarks, e.g. pushing the top-1, top-20, and top-50 accuracies on DeepFashion to 26%, 64%, and 75% (i.e. 4%, 10%, and 10% absolute improvements), outperforming competitors with large margins. On FindFashion, GRNet achieves considerable improvements on all empirical settings.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",18.818181818181817,0.10685064935064932,0.3672997835497835,1,0.1124031007751938,0.05426356589147287,0.484
1967,2010,2010,PuppetGAN: Cross-domain image manipulation by demonstration,"In this work we propose a model that can manipulate individual visual attributes of objects in a real scene using examples of how respective attribute manipulations affect the output of a simulation. As an example, we train our model to manipulate the expression of a human face using nonphotorealistic 3D renders of a face with varied expression. Our model manages to preserve all other visual attributes of a real face, such as head orientation, even though this and other attributes are not labeled in either real or synthetic domain. Since our model learns to manipulate a specific property in isolation using only 'synthetic demonstrations' of such manipulations without explicitly provided labels, it can be applied to shape, texture, lighting, and other properties that are difficult to measure or represent as real-valued vectors. We measure the degree to which our model preserves other attributes of a real image when a single specific attribute is manipulated. We use digit datasets to analyze how discrepancy in attribute distributions affects the performance of our model, and demonstrate results in a far more difficult setting: Learning to manipulate real human faces using nonphotorealistic 3D renders.",60019674,Boston University,Boston,United States,"['1712', '1707']",31.66666666666667,-0.007142857142857141,0.3922619047619048,1,0.14354066985645933,0.0,0.27184466019417475
1968,2011,2011,Deep meta metric learning,"In this paper, we present a deep meta metric learning (DMML) approach for visual recognition. Unlike most existing deep metric learning methods formulating the learning process by an overall objective, our DMML formulates the metric learning in a meta way, and proves that softmax and triplet loss are consistent in the meta space. Specifically, we sample some subsets from the original training set and learn metrics across different subsets. In each sampled sub-task, we split the training data into a support set as well as a query set, and learn the set-based distance, instead of sample-based one, to verify the query cell from multiple support cells. In addition, we introduce hard sample mining for set-based distance to encourage the intra-class compactness. Experimental results on three visual recognition applications including person re-identification, vehicle re-identification and face verification show that the proposed DMML method outperforms most existing approaches.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",24.33333333333333,0.10833333333333334,0.27760416666666665,1,0.11797752808988764,0.02247191011235955,0.31097560975609756
1969,2012,2012,Frame-to-frame aggregation of active regions in web videos for weakly supervised semantic segmentation,"When a deep neural network is trained on data with only image-level labeling, the regions activated in each image tend to identify only a small region of the target object. We propose a method of using videos automatically harvested from the web to identify a larger region of the target object by using temporal information, which is not present in the static image. The temporal variations in a video allow different regions of the target object to be activated. We obtain an activated region in each frame of a video, and then aggregate the regions from successive frames into a single image, using a warping technique based on optical flow. The resulting localization maps cover more of the target object, and can then be used as proxy ground-truth to train a segmentation network. This simple approach outperforms existing methods under the same level of supervision, and even approaches relying on extra annotations. Based on VGG-16 and ResNet 101 backbones, our method achieves the mIoU of 65.0 and 67.4, respectively, on PASCAL VOC 2012 test images, which represents a new state-of-the-art.",60013682,Seoul National University,Seoul,South Korea,"['1712', '1707']",25.714285714285715,0.05432900432900433,0.4433982683982683,1,0.14009661835748793,0.014492753623188406,0.30456852791878175
1970,2013,2013,Lambda-net: Reconstruct hyperspectral images from a snapshot measurement,"We propose the λ-net, which reconstructs hyperspectral images (e.g., with 24 spectral channels) from a single shot measurement. This task is usually termed snapshot compressive-spectral imaging (SCI), which enjoys low cost, low bandwidth and high-speed sensing rate via capturing the three-dimensional (3D) signal i.e., (x, y, λ), using a 2D snapshot. Though proposed more than a decade ago, the poor quality and low-speed of reconstruction algorithms preclude wide applications of SCI. To address this challenge, in this paper, we develop a dual-stage generative model to reconstruct the desired 3D signal in SCI, dubbed λ-net. Results on both simulation and real datasets demonstrate the significant advantages of λ-net, which leads to >4dB improvement in PSNR for real-mask-in-the-loop simulation data compared to the current state-of-the-art. Furthermore, λ-net can finish the reconstruction task within sub-seconds instead of hours taken by the most recently proposed DeSCI algorithm, thus speeding up the reconstruction >1000 times.",60109024,"Facebook, Inc.",Menlo Park,United States,"['1712', '1707']",25.0,0.06279761904761905,0.4074404761904762,1,0.09767441860465116,0.05116279069767442,0.46408839779005523
1971,2014,2014,Scalable place recognition under appearance change for autonomous driving,"A major challenge in place recognition for autonomous driving is to be robust against appearance changes due to short-term (e.g., weather, lighting) and long-term (seasons, vegetation growth, etc.) environmental variations. A promising solution is to continuously accumulate images to maintain an adequate sample of the conditions and incorporate new changes into the place recognition decision. However, this demands a place recognition technique that is scalable on an ever growing dataset. To this end, we propose a novel place recognition technique that can be efficiently retrained and compressed, such that the recognition of new queries can exploit all available data (including recent changes) without suffering from visible growth in computational cost. Underpinning our method is a novel temporal image matching technique based on Hidden Markov Models. Our experiments show that, compared to state-of-the-art techniques, our method has much greater potential for large-scale place recognition for autonomous driving.",60020661,University of Liverpool,Liverpool,United Kingdom,"['1712', '1707']",24.33333333333333,0.16263528138528138,0.5000541125541126,1,0.09444444444444444,0.016666666666666666,0.30357142857142855
1972,2015,2015,Towards unsupervised image captioning with shared multimodal embeddings,"Understanding images without explicit supervision has become an important problem in computer vision. In this paper, we address image captioning by generating language descriptions of scenes without learning from annotated pairs of images and their captions. The core component of our approach is a shared latent space that is structured by visual concepts. In this space, the two modalities should be indistinguishable. A language model is first trained to encode sentences into semantically structured embeddings. Image features that are translated into this embedding space can be decoded into descriptions through the same language model, similarly to sentence embeddings. This translation is learned from weakly paired images and text using a loss robust to noisy assignments and a conditional adversarial component. Our approach allows to exploit large text corpora outside the annotated distributions of image/caption data. Our experiments show that the proposed domain alignment learns a semantically meaningful representation which outperforms previous work.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",16.88888888888889,0.08226190476190477,0.3628571428571428,1,0.15060240963855423,0.0,0.31097560975609756
1973,2016,2016,Structured modeling of joint deep feature and prediction refinement for salient object detection,"Recent saliency models extensively explore to incorporate multi-scale contextual information from Convolutional Neural Networks (CNNs). Besides direct fusion strategies, many approaches introduce message-passing to enhance CNN features or predictions. However, the messages are mainly transmitted in two ways, by feature-to-feature passing, and by prediction-to-prediction passing. In this paper, we add message-passing between features and predictions and propose a deep unified CRF saliency model. We design a novel cascade CRFs architecture with CNN to jointly refine deep features and predictions at each scale and progressively compute a final refined saliency map. We formulate the CRF graphical model that involves message-passing of feature-feature, feature-prediction, and prediction-prediction, from the coarse scale to the finer scale, to update the features and the corresponding predictions. Also, we formulate the mean-field updates for joint end-to-end model training with CNN through back propagation. The proposed deep unified CRF saliency model is evaluated over six datasets and shows highly competitive performance among the state of the arts.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",19.875,0.07722222222222222,0.421388888888889,1,0.10628019323671498,0.03864734299516908,0.40782122905027934
1974,2017,2017,Noise flow: Noise modeling with conditional normalizing flows,"Modeling and synthesizing image noise is an important aspect in many computer vision applications. The long-standing additive white Gaussian and heteroscedastic (signal-dependent) noise models widely used in the literature provide only a coarse approximation of real sensor noise. This paper introduces Noise Flow, a powerful and accurate noise model based on recent normalizing flow architectures. Noise Flow combines well-established basic parametric noise models (e.g., signal-dependent noise) with the flexibility and expressiveness of normalizing flow networks. The result is a single, comprehensive, compact noise model containing fewer than 2500 parameters yet able to represent multiple cameras and gain factors. Noise Flow dramatically outperforms existing noise models, with 0.42 nats/pixel improvement over the camera-calibrated noise level functions, which translates to 52% improvement in the likelihood of sampled noise. Noise Flow represents the first serious attempt to go beyond simple parametric models to one that leverages the power of deep learning and data-driven noise distributions.",60033420,York University,Toronto,Canada,"['1712', '1707']",21.714285714285715,0.11362433862433866,0.4613756613756614,1,0.10326086956521739,0.04891304347826087,0.38235294117647056
1975,2018,2018,TAPA-MVS: Textureless-aware patchmatch multi-view stereo,"One of the most successful approaches in Multi-View Stereo estimates a depth map and a normal map for each view via PatchMatch-based optimization and fuses them into a consistent 3D points cloud. This approach relies on photo-consistency to evaluate the goodness of a depth estimate. It generally produces very accurate results; however, the reconstructed model often lacks completeness, especially in correspondence of broad untextured areas where the photo-consistency metrics are unreliable. Assuming the untextured areas piecewise planar, in this paper we generate novel PatchMatch hypotheses so to expand reliable depth estimates in neighboring untextured regions. At the same time, we modify the photo-consistency measure such to favor standard or novel PatchMatch depth hypotheses depending on the textureness of the considered area. We also propose a depth refinement step to filter wrong estimates and to fill the gaps on both the depth maps and normal maps while preserving the discontinuities. The effectiveness of our new methods has been tested against several state of the art algorithms in the publicly available ETH3D dataset containing a wide variety of high and low-resolution images.",60023256,Politecnico di Milano,Milan,Italy,"['1712', '1707']",25.714285714285715,0.14049242424242425,0.4975210437710437,1,0.10784313725490197,0.029411764705882353,0.296875
1976,2019,2019,Calibration of axial fisheye cameras through generic virtual central models,"Fisheye cameras are notoriously hard to calibrate using traditional plane-based methods. This paper proposes a new calibration method for large field of view cameras. Similarly to planar calibration, it relies on multiple images of a planar calibration grid with dense correspondences, typically obtained using structured light. By relying on the grids themselves instead of the distorted image plane, we can build a rectilinear Generic Virtual Central (GVC) camera. Instead of relying on a single GVC camera, our method proposes a selection of multiple GVC cameras which can cover any field of view and be trivially aligned to provide a very accurate generic central model. We demonstrate that this approach can directly model axial cameras, assuming the distortion center is located on the camera axis. Experimental validation is provided on both synthetic and real fisheye cameras featuring up to a 280deg field of view. To our knowledge, this is one of the only practical methods to calibrate axial cameras.",60009507,University of Montreal,Montreal,Canada,"['1712', '1707']",19.75,0.052044372294372296,0.3756201298701299,1,0.13636363636363635,0.03977272727272727,0.3103448275862069
1977,2020,2020,Business performance and competitive advantage: Multi perspective analysis of SMEs in Bali," This research was conducted with 100 owners of SMEs of wood craft in Bali. The data were collected through interview, observation, questionnaire, and documentation, then analyzed using the following techniques: (1) descriptive statistic; and (2) structure equation models. The results of the analysis show that: (1) the business performance and competitiveness of SMEs are categorized as fair; (2) Human resource competency has a positive and significant effect on market orientation and business performance of SMEs; (3) business performance has a positive and significant effect on the competitiveness of SMEs; (4) market orientation has a positive and significant effect on the business performance and competitiveness of SMEs. The relevant suggestions for this study are (1) improving HR managerial skills by participating in training; (2) improving product quality by minimizing costs through innovation; (3) Empowering the government to play a role in helping SMEs to open market access.",60111193,Politeknik Negeri Bali,Tuban,Indonesia,['1706'],36.75,0.1082167832167832,0.673951048951049,0,0.07734806629834254,0.011049723756906077,0.3888888888888889
1978,2021,2021,A closed-form solution to universal style transfer,"Universal style transfer tries to explicitly minimize the losses in feature space, thus it does not require training on any pre-defined styles. It usually uses different layers of VGG network as the encoders and trains several decoders to invert the features into images. Therefore, the effect of style transfer is achieved by feature transform. Although plenty of methods have been proposed, a theoretical analysis of feature transform is still missing. In this paper, we first propose a novel interpretation by treating it as the optimal transport problem. Then, we demonstrate the relations of our formulation with former works like Adaptive Instance Normalization (AdaIN) and Whitening and Coloring Transform (WCT). Finally, we derive a closed-form solution named Optimal Style Transfer (OST) under our formulation by additionally considering the content loss of Gatys. Comparatively, our solution can preserve better structure and achieve visually pleasing results. It is simple yet effective and we demonstrate its advantages both quantitatively and qualitatively. Besides, we hope our theoretical analysis can inspire future works in neural style transfer.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",17.1,0.05,0.2884672619047619,1,0.11557788944723618,0.07035175879396985,0.3435897435897436
1979,2022,2022,Boosting few-shot visual learning with self-supervision,"Few-shot learning and self-supervised learning address different facets of the same problem: How to train a model with little or no labeled data. Few-shot learning aims for optimization methods and models that can learn efficiently to recognize patterns in the low data regime. Self-supervised learning focuses instead on unlabeled data and looks into it for the supervisory signal to feed high capacity deep neural networks. In this work we exploit the complementarity of these two domains and propose an approach for improving few-shot learning through self-supervision. We use self-supervision as an auxiliary task in a few-shot learning pipeline, enabling feature extractors to learn richer and more transferable visual representations while still using few annotated samples. Through self-supervision, our approach can be naturally extended towards using diverse unlabeled data from other datasets in the few-shot setting. We report consistent improvements across an array of architectures, datasets and self-supervision techniques. We provide the implementation code at: Https://github.com/valeoai/BF3S.",60105097,Laboratoire d'Informatique Gaspard Monge,Marne-la-Vallee,France,"['1712', '1707']",19.375,0.04145833333333334,0.3408333333333333,1,0.13227513227513227,0.0,0.3352941176470588
1980,2023,2023,Discrete laplace operator estimation for dynamic 3D reconstruction,"We present a general paradigm for dynamic 3D reconstruction from multiple independent and uncontrolled image sources having arbitrary temporal sampling density and distribution. Our graph-theoretic formulation models the spatio-temporal relationships among our observations in terms of the joint estimation of their 3D geometry and its discrete Laplace operator. Towards this end, we define a tri-convex optimization framework that leverages the geometric properties and dependencies found among a Euclidean shape-space and the discrete Laplace operator describing its local and global topology. We present a reconstructability analysis, experiments on motion capture data and multi-view image datasets, as well as explore applications to geometry-based event segmentation and data association.",60027392,Stevens Institute of Technology,Hoboken,United States,"['1712', '1707']",26.5,-0.005555555555555554,0.15462962962962962,1,0.072,0.024,0.30973451327433627
1981,2025,2025,Efficient and accurate arbitrary-shaped text detection with pixel aggregation network,"Scene text detection, an important step of scene text reading systems, has witnessed rapid development with convolutional neural networks. Nonetheless, two main challenges still exist and hamper its deployment to real-world applications. The first problem is the trade-off between speed and accuracy. The second one is to model the arbitrary-shaped text instance. Recently, some methods have been proposed to tackle arbitrary-shaped text detection, but they rarely take the speed of the entire pipeline into consideration, which may fall short in practical applications. In this paper, we propose an efficient and accurate arbitrary-shaped text detector, termed Pixel Aggregation Network (PAN), which is equipped with a low computational-cost segmentation head and a learnable post-processing. More specifically, the segmentation head is made up of Feature Pyramid Enhancement Module (FPEM) and Feature Fusion Module (FFM). FPEM is a cascadable U-shaped module, which can introduce multi-level information to guide the better segmentation. FFM can gather the features given by the FPEMs of different depths into a final feature for segmentation. The learnable post-processing is implemented by Pixel Aggregation (PA), which can precisely aggregate text pixels by predicted similarity vectors. Experiments on several standard benchmarks validate the superiority of the proposed PAN. It is worth noting that our method can achieve a competitive F-measure of 79.9% at 84.2 FPS on CTW1500.",60073652,Tongji University,Shanghai,China,"['1712', '1707']",17.916666666666668,0.1787037037037037,0.4541666666666666,1,0.11481481481481481,0.07777777777777778,0.3870967741935484
1982,2026,2026,Accelerate learning of deep hashing with gradient attention,"Recent years have witnessed the success of learning to hash in fast large-scale image retrieval. As deep learning has shown its superior performance on many computer vision applications, recent designs of learning-based hashing models have been moving from shallow ones to deep architectures. However, based on our analysis, we find that gradient descent based algorithms used in deep hashing models would potentially cause hash codes of a pair of training instances to be updated towards the directions of each other simultaneously during optimization. In the worst case, the paired hash codes switch their directions after update, and consequently, their corresponding distance in the Hamming space remain unchanged. This makes the overall learning process highly inefficient. To address this issue, we propose a new deep hashing model integrated with a novel gradient attention mechanism. Extensive experimental results on three benchmark datasets show that our proposed algorithm is able to accelerate the learning process and obtain competitive retrieval performance compared with state-of-the-art deep hashing models.",60005510,Nanyang Technological University,Singapore City,Singapore,"['1712', '1707']",23.285714285714285,0.0541919191919192,0.4632323232323233,1,0.12834224598930483,0.0053475935828877,0.2937853107344633
1983,2027,2027,"SILCO: Show a few images, localize the common object","Few-shot learning is a nascent research topic, motivated by the fact that traditional deep learning requires tremendous amounts of data. In this work, we propose a new task along this research direction, we call few-shot common-localization. Given a few weakly-supervised support images, we aim to localize the common object in the query image without any box annotation. This task differs from standard few-shot settings, since we aim to address the localization problem, rather than the global classification problem. To tackle this new problem, we propose a network that aims to get the most out of the support and query images. To that end, we introduce a spatial similarity module that searches the spatial commonality among the given images. We furthermore introduce a feature reweighting module to balance the influence of different support images through graph convolutional networks. To evaluate few-shot common-localization, we repurpose and reorganize the well-known Pascal VOC and MS-COCO datasets, as well as a video dataset from ImageNet VID. Experiments on the new settings for few-shot common-localization shows the importance of searching for spatial similarity and feature reweighting, outperforming baselines from related tasks.",60002483,Universiteit van Amsterdam,Amsterdam,Netherlands,"['1712', '1707']",20.555555555555557,0.05710955710955711,0.43181818181818177,1,0.1277533039647577,0.030837004405286344,0.3073170731707317
1984,2028,2028,Canonical surface mapping via geometric cycle consistency,"We explore the task of Canonical Surface Mapping (CSM). Specifically, given an image, we learn to map pixels on the object to their corresponding locations on an abstract 3D model of the category. But how do we learn such a mapping? A supervised approach would require extensive manual labeling which is not scalable beyond a few hand-picked categories. Our key insight is that the CSM task (pixel to 3D), when combined with 3D projection (3D to pixel), completes a cycle. Hence, we can exploit a geometric cycle consistency loss, thereby allowing us to forgo the dense manual supervision. Our approach allows us to train a CSM model for a diverse set of classes, without sparse or dense keypoint annotation, by leveraging only foreground mask labels for training. We show that our predictions also allow us to infer dense correspondence between two images, and compare the performance of our approach against several methods that predict correspondence by leveraging varying amount of supervision.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",23.0,-0.03333333333333333,0.4888888888888889,1,0.12365591397849462,0.04838709677419355,0.32608695652173914
1985,2029,2029,Controlling neural networks via energy dissipation,"The last decade has shown a tremendous success in solving various computer vision problems with the help of deep learning techniques. Lately, many works have demonstrated that learning-based approaches with suitable network architectures even exhibit superior performance for the solution of (ill-posed) image reconstruction problems such as deblurring, super-resolution, or medical image reconstruction. The drawback of purely learning-based methods, however, is that they cannot provide provable guarantees for the trained network to follow a given data formation process during inference. In this work we propose energy dissipating networks that iteratively compute a descent direction with respect to a given cost function or energy at the currently estimated reconstruction. Therefore, an adaptive step size rule such as a line-search, along with a suitable number of iterations can guarantee the reconstruction to follow a given data formation model encoded in the energy to arbitrary precision, and hence control the model's behavior even during test time. We prove that under standard assumptions, descent using the direction predicted by the network converges (linearly) to the global minimum of the energy. We illustrate the effectiveness of the proposed approach in experiments on single image super resolution and computed tomography (CT) reconstruction, and further illustrate extensions to convex feasibility problems.",60024260,Universität Siegen,Siegen,Germany,"['1712', '1707']",29.142857142857146,0.1671201814058957,0.44512471655328795,1,0.12552301255230125,0.008368200836820083,0.26200873362445415
1986,2030,2030,Reciprocal multi-layer subspace learning for multi-view clustering,"Multi-view clustering is a long-standing important research topic, however, remains challenging when handling high-dimensional data and simultaneously exploring the consistency and complementarity of different views. In this work, we present a novel Reciprocal Multi-layer Subspace Learning (RMSL) algorithm for multi-view clustering, which is composed of two main components: Hierarchical Self-Representative Layers (HSRL), and Backward Encoding Networks (BEN). Specifically, HSRL constructs reciprocal multi-layer subspace representations linked with a latent representation to hierarchically recover the underlying low-dimensional subspaces in which the high-dimensional data lie; BEN explores complex relationships among different views and implicitly enforces the subspaces of all views to be consistent with each other and more separable. The latent representation flexibly encodes complementary information from multiple views and depicts data more comprehensively. Our model can be efficiently optimized by an alternating optimization scheme. Extensive experiments on benchmark datasets show the superiority of RMSL over other state-of-the-art clustering methods.",60019533,Tianjin University,Tianjin,China,"['1712', '1707']",24.5,0.1261904761904762,0.4476190476190477,1,0.08900523560209424,0.07853403141361257,0.41317365269461076
1987,2031,2031,Remote heart rate measurement from highly compressed facial videos: An end-to-end deep learning solution with video enhancement,"Remote photoplethysmography (rPPG), which aims at measuring heart activities without any contact, has great potential in many applications (e.g., remote healthcare). Existing rPPG approaches rely on analyzing very fine details of facial videos, which are prone to be affected by video compression. Here we propose a two-stage, end-to-end method using hidden rPPG information enhancement and attention networks, which is the first attempt to counter video compression loss and recover rPPG signals from highly compressed videos. The method includes two parts: 1) a Spatio-Temporal Video Enhancement Network (STVEN) for video enhancement, and 2) an rPPG network (rPPGNet) for rPPG signal recovery. The rPPGNet can work on its own for robust rPPG measurement, and the STVEN network can be added and jointly trained to further boost the performance especially on highly compressed videos. Comprehensive experiments are performed on two benchmark datasets to show that, 1) the proposed method not only achieves superior performance on compressed videos with high-quality videos pair, 2) it also generalizes well on novel data with only compressed videos available, which implies the promising potential for real-world applications.",60018308,Xi'an Jiaotong University,Xi'an,China,"['1712', '1707']",29.83333333333333,0.21605263157894736,0.6214035087719301,1,0.12669683257918551,0.04524886877828054,0.41626794258373206
1988,2032,2032,PR product: A substitute for inner product in neural networks,"In this paper, we analyze the inner product of weight vector w and data vector x in neural networks from the perspective of vector orthogonal decomposition and prove that the direction gradient of w decreases with the angle between them close to 0 or π. We propose the Projection and Rejection Product (PR Product) to make the direction gradient of w independent of the angle and consistently larger than the one in standard inner product while keeping the forward propagation identical. As a reliable substitute for standard inner product, the PR Product can be applied into many existing deep learning modules, so we develop the PR Product version of fully connected layer, convolutional layer and LSTM layer. In static image classification, the experiments on CIFAR10 and CIFAR100 datasets demonstrate that the PR Product can robustly enhance the ability of various state-of-the-art classification networks. On the task of image captioning, even without any bells and whistles, our PR Product version of captioning model can compete or outperform the state-of-the-art models on MS COCO dataset. Code has been made available at: Https://github.com/wzn0828/PR-Product.",60000937,Shenzhen University,Shenzhen,China,"['1712', '1707']",30.0,0.11666666666666665,0.31875,1,0.09134615384615384,0.11057692307692307,0.30808080808080807
1989,2033,2033,Customer classification-based pre-sale multi-value-chain collaborative mechanism verification,"During the automobile pre-sale service, understanding customer preferences and segmenting customer purchasing power can provide a foundation for automobile dealers’ vehicle allocation strategy to manufacturers. It can improve the service ability of dealers and increase marketing revenue. This paper comes up with a verification method based on customer segmentation for multi-value-chain collaborative mechanism. First, we studied the process and inner accounting mechanism of the automobile marketing value chain and production value chain. We can explore the value-added of customer segmentation in each value chain and examine the extent to which customer segmentation results affect the value-added. Then, we construct a colored Petri net model for the value chain of each accounting unit. The sales service is mapped to transition. The sales resource management department is mapped to the place. The sales resource is mapped to the Token in the place. And we simulate the value-added process of the automobile marketing value chain and production value chain. Finally, we offer differentiated sales service processes for different categories of customers based on customer segmentation and design a multi-value-chain collaborative mechanism. On the CPN Tools simulation platform, we simulate the value-added quantitative effects in multi-value-chain collaborative state. We verified the correctness of the collaborative mechanism. In the simulation experiment, we monitored the number of automobile sales, the number of backlogs. The simulation result shows that the multi-value-chain collaborative mechanism based on customer segmentation designed in this paper can effectively increase the number of automobile sales by dealers and manufacturers. It provides a quantifiable basis for the optimization solutions of multi-value-chain.",60025256,Institute of Software Chinese Academy of Sciences,Beijing,China,['1700'],16.0625,0.14166666666666666,0.4833333333333334,1,0.1157556270096463,0.012861736334405145,0.2775800711743772
1990,2034,2034,The sound of motions,"Sounds originate from object motions and vibrations of surrounding air. Inspired by the fact that humans is capable of interpreting sound sources from how objects move visually, we propose a novel system that explicitly captures such motion cues for the task of sound localization and separation. Our system is composed of an end-to-end learnable model called Deep Dense Trajectory (DDT), and a curriculum learning scheme. It exploits the inherent coherence of audio-visual signals from a large quantities of unlabeled videos. Quantitative and qualitative evaluations show that comparing to previous models that rely on visual appearance cues, our motion based system improves performance in separating musical instrument sounds. Furthermore, it separates sound components from duets of the same category of instruments, a challenging problem that has not been addressed before.",60141075,MIT-IBM Watson AI Lab,Cambridge,United States,"['1712', '1707']",21.5,0.14981684981684978,0.3246336996336996,1,0.12162162162162163,0.02702702702702703,0.352112676056338
1991,2035,2035,A delay metric for video object detection: What average precision fails to tell,"Average precision (AP) is a widely used metric to evaluate detection accuracy of image and video object detectors. In this paper, we analyze the object detection from video and point out that mAP alone is not sufficient to capture the temporal nature of video object detection. To tackle this problem, we propose a comprehensive metric, Average Delay (AD), to measure and compare detection delay. To facilitate delay evaluation, we carefully select a subset of ImageNet VID, which we name as ImageNet VIDT with an emphasis on complex trajectories. By extensively evaluating a wide range of detectors on VIDT, we show that most methods drastically increase the detection delay but still preserve mAP well. In other words, mAP is not sensitive enough to reflect the temporal characteristics of a video object detector. Our results suggest that video object detection methods should be evaluated with a delay metric, particularly for latency-critical applications such as autonomous vehicle perception.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",22.142857142857146,-0.0005952380952381009,0.5101190476190477,1,0.10734463276836158,0.05084745762711865,0.2914285714285714
1992,2036,2036,Learning to reconstruct 3D human pose and shape via model-fitting in the loop,"Model-based human pose estimation is currently approached through two different paradigms. Optimization-based methods fit a parametric body model to 2D observations in an iterative manner, leading to accurate image-model alignments, but are often slow and sensitive to the initialization. In contrast, regression-based methods, that use a deep network to directly estimate the model parameters from pixels, tend to provide reasonable, but not pixel accurate, results while requiring huge amounts of supervision. In this work, instead of investigating which approach is better, our key insight is that the two paradigms can form a strong collaboration. A reasonable, directly regressed estimate from the network can initialize the iterative optimization making the fitting faster and more accurate. Similarly, a pixel accurate fit from iterative optimization can act as strong supervision for the network. This is the core of our proposed approach SPIN (SMPL oPtimization IN the loop). The deep network initializes an iterative optimization routine that fits the body model to 2D joints within the training loop, and the fitted estimate is subsequently used to supervise the network. Our approach is self-improving by nature, since better network estimates can lead the optimization to better solutions, while more accurate optimization fits provide better supervision for the network. We demonstrate the effectiveness of our approach in different settings, where 3D ground truth is scarce, or not available, and we consistently outperform the state-of-the-art model-based pose estimation approaches by significant margins. The project website with videos, results, and code can be found at https://seas.upenn.edu/∼nkolot/projects/spin.",60030569,Max Planck Institute for Intelligent Systems,Tubingen,Germany,"['1712', '1707']",22.54545454545455,0.23976190476190484,0.5316666666666667,1,0.12416107382550336,0.016778523489932886,0.2978723404255319
1993,2037,2037,Hierarchical self-attention network for action localization in videos,"This paper presents a novel Hierarchical Self-Attention Network (HISAN) to generate spatial-temporal tubes for action localization in videos. The essence of HISAN is to combine the two-stream convolutional neural network (CNN) with hierarchical bidirectional self-attention mechanism, which comprises of two levels of bidirectional self-attention to efficaciously capture both of the long-term temporal dependency information and spatial context information to render more precise action localization. Also, a sequence rescoring (SR) algorithm is employed to resolve the dilemma of inconsistent detection scores incurred by occlusion or background clutter. Moreover, a new fusion scheme is invoked, which integrates not only the appearance and motion information from the two-stream network, but also the motion saliency to mitigate the effect of camera motion. Simulations reveal that the new approach achieves competitive performance as the state-of-the-art works in terms of action localization and recognition accuracy on the widespread UCF101-24 and J-HMDB datasets.",60027709,National Taiwan University of Science and Technology,Taipei,Taiwan,"['1712', '1707']",29.2,0.18409090909090908,0.4386363636363637,1,0.07526881720430108,0.06989247311827956,0.30864197530864196
1994,2038,2038,Knowledge distillation via route constrained optimization,"Distillation-based learning boosts the performance of the miniaturized neural network based on the hypothesis that the representation of a teacher model can be used as structured and relatively weak supervision, and thus would be easily learned by a miniaturized model. However, we find that the representation of a converged heavy model is still a strong constraint for training a small student model, which leads to a higher lower bound of congruence loss. In this work, we consider the knowledge distillation from the perspective of curriculum learning by teacher's routing. Instead of supervising the student model with a converged teacher model, we supervised it with some anchor points selected from the route in parameter space that the teacher model passed by, as we called route constrained optimization (RCO). We experimentally demonstrate this simple operation greatly reduces the lower bound of congruence loss for knowledge distillation, hint and mimicking learning. On close-set classification tasks like CIFAR and ImageNet, RCO improves knowledge distillation by 2.14% and 1.5% respectively. For the sake of evaluating the generalization, we also test RCO on the open-set face recognition task MegaFace. RCO achieves 84.3% accuracy on one-to-million task with only 0.8 M parameters, which push the SOTA by a large margin.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",25.375,0.1171626984126984,0.5522817460317461,1,0.13924050632911392,0.0379746835443038,0.2775330396475771
1995,2039,2039,Using Herzberg theory to develop the employees’ performance of Rafhan maize industry," The current paper applies Herzberg two-factor theory for improving the employees’ performance. Seven point Likert scale is used for survey purpose. Descriptive statistics, Reliability test, Pearson correlation, Analysis Of Variance (ANOVA), t test and multiple regression techniques are used for data analysis. Convenience non-probability sampling and random probability sampling are applied in this study. The results have shown that motivators (advancement, achievement, work itself, recognition and growth) and hygiene factors (company policy, work security, relationship with supervision, working condition, money and relationship with peers) of Herzberg two-factor theory are positively effects on employees’ performance. This study provide much knowledge about Herzberg theory that create benefits to individual as well as for organization. This study suggested that motivators (advancement, achievement, work itself, recognition and growth) and hygiene factors (company policy, work security, relationship with supervision, working condition, money and relationship with peers) should be employed in Rafhan industry properly.",60064058,Quaid-i-Azam University,Islamabad,Pakistan,['1706'],21.285714285714285,-0.010389610389610384,0.3064935064935065,0,0.06770833333333333,0.046875,0.372972972972973
1996,2040,2040,Convolutional sequence generation for skeleton-based action synthesis,"In this work, we aim to generate long actions represented as sequences of skeletons. The generated sequences must demonstrate continuous, meaningful human actions, while maintaining coherence among body parts. Instead of generating skeletons sequentially following an autoregressive model, we propose a framework that generates the entire sequence altogether by transforming from a sequence of latent vectors sampled from a Gaussian process (GP). This framework, named Convolutional Sequence Generation Network (CSGN), jointly models structures in temporal and spatial dimensions. It captures the temporal structure at multiple scales through the GP prior and the temporal convolutions; and establishes the spatial connection between the latent vectors and the skeleton graphs via a novel graph refining scheme. It is noteworthy that CSGN allows bidirectional transforms between the latent and the observed spaces, thus enabling semantic manipulation of the action sequences in various forms. We conducted empirical studies on multiple datasets, including a set of high-quality dancing sequences collected by us. The results show that our framework can produce long action sequences that are coherent across time steps and among body parts.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",22.125,0.08571428571428573,0.25892857142857145,1,0.125,0.05,0.3787878787878788
1997,2041,2041,Mixed high-order attention network for person re-identification,"Attention has become more attractive in person re-identification (ReID) as it is capable of biasing the allocation of available resources towards the most informative parts of an input signal. However, state-of-the-art works concentrate only on coarse or first-order attention design, e.g. spatial and channels attention, while rarely exploring higher-order attention mechanism. We take a step towards addressing this problem. In this paper, we first propose the High-Order Attention (HOA) module to model and utilize the complex and high-order statistics information in attention mechanism, so as to capture the subtle differences among pedestrians and to produce the discriminative attention proposals. Then, rethinking person ReID as a zero-shot learning problem, we propose the Mixed High-Order Attention Network (MHN) to further enhance the discrimination and richness of attention knowledge in an explicit manner. Extensive experiments have been conducted to validate the superiority of our MHN for person ReID over a wide variety of state-of-the-art methods on three large-scale datasets, including Market-1501, DukeMTMC-ReID and CUHK03-NP. Code is available at http://www.bhchen.cn.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,"['1712', '1707']",20.75,0.16354166666666664,0.5197916666666667,1,0.08256880733944955,0.05045871559633028,0.3769633507853403
1998,2042,2042,Neural inter-frame compression for video coding,"While there are many deep learning based approaches for single image compression, the field of end-to-end learned video coding has remained much less explored. Therefore, in this work we present an inter-frame compression approach for neural video coding that can seamlessly build up on different existing neural image codecs. Our end-to-end solution performs temporal prediction by optical flow based motion compensation in pixel space. The key insight is that we can increase both decoding efficiency and reconstruction quality by encoding the required information into a latent representation that directly decodes into motion and blending coefficients. In order to account for remaining prediction errors, residual information between the original image and the interpolated frame is needed. We propose to compute residuals directly in latent space instead of in pixel space as this allows to reuse the same image compression network for both key frames and intermediate frames. Our extended evaluation on different datasets and resolutions shows that the rate-distortion performance of our approach is competitive with existing state-of-the-art codecs.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",24.0,0.066921768707483,0.4397108843537415,1,0.12244897959183673,0.0,0.2808988764044944
1999,2043,2043,Dynamic kernel distillation for efficient pose estimation in videos,"Existing video-based human pose estimation methods extensively apply large networks onto every frame in the video to localize body joints, which suffer high computational cost and hardly meet the low-latency requirement in realistic applications. To address this issue, we propose a novel Dynamic Kernel Distillation (DKD) model to facilitate small networks for estimating human poses in videos, thus significantly lifting the efficiency. In particular, DKD introduces a light-weight distillator to online distill pose kernels via leveraging temporal cues from the previous frame in a one-shot feed-forward manner. Then, DKD simplifies body joint localization into a matching procedure between the pose kernels and the current frame, which can be efficiently computed via simple convolution. In this way, DKD fast transfers pose knowledge from one frame to provide compact guidance for body joint localization in the following frame, which enables utilization of small networks in video-based pose estimation. To facilitate the training process, DKD exploits a temporally adversarial training strategy that introduces a temporal discriminator to help generate temporally coherent pose kernels and pose estimation results within a long range. Experiments on Penn Action and Sub-JHMDB benchmarks demonstrate outperforming efficiency of DKD, specifically, 10x flops reduction and 2x speedup over previous best model, and its state-of-the-art accuracy.",60120916,Snap Inc.,Santa Monica,United States,"['1712', '1707']",29.285714285714285,0.07761904761904763,0.35647186147186144,1,0.13414634146341464,0.04878048780487805,0.34513274336283184
2000,2044,2044,Deep reinforcement learning for joint channel selection and power allocation in cognitive internet of things,"With the development of wireless communication technology and the lack of spectrum resources, it is very meaningful to study the dynamic spectrum allocation in the cognitive Internet of Things. In this paper, the system model is firstly established. In an underlay mode, considering the interference between primary and secondary users, jointing channel selection and power allocation, aiming to maximize the spectrum efficiency of all secondary users. Different from the traditional heuristic algorithm, the underlay-cognitive-radio-deep-Q-network frame-work (UCRDQN) based on deep reinforcement learning, is proposed to find the optimal solution efficiently. The simulation results show that the UCRDQN algorithm can achieve higher spectrum efficiency and is more stable and efficient than other algorithms.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],22.2,0.11041666666666666,0.4479166666666667,1,0.08759124087591241,0.029197080291970802,0.24
2001,2045,2045,Efficient segmentation: Learning downsampling near semantic boundaries,"Many automated processes such as auto-piloting rely on a good semantic segmentation as a critical component. To speed up performance, it is common to downsample the input frame. However, this comes at the cost of missed small objects and reduced accuracy at semantic boundaries. To address this problem, we propose a new content-adaptive downsampling technique that learns to favor sampling locations near semantic boundaries of target classes. Cost-performance analysis shows that our method consistently outperforms the uniform sampling improving balance between accuracy and computational efficiency. Our adaptive sampling gives segmentation with better quality of boundaries and more reliable support for smaller-size objects.",60109024,"Facebook, Inc.",Menlo Park,United States,"['1712', '1707']",17.0,0.19421487603305784,0.4913223140495868,1,0.13445378151260504,0.0,0.2972972972972973
2002,2046,2046,Attentional neural fields for crowd counting,"Crowd counting has recently generated huge popularity in computer vision, and is extremely challenging due to the huge scale variations of objects. In this paper, we propose the Attentional Neural Field (ANF) for crowd counting via density estimation. Within the encoder-decoder network, we introduce conditional random fields (CRFs) to aggregate multi-scale features, which can build more informative representations. To better model pair-wise potentials in CRFs, we incorperate non-local attention mechanism implemented as inter- and intra-layer attentions to expand the receptive field to the entire image respectively within the same layer and across different layers, which captures long-range dependencies to conquer huge scale variations. The CRFs coupled with the attention mechanism are seamlessly integrated into the encoder-decoder network, establishing an ANF that can be optimized end-to-end by back propagation. We conduct extensive experiments on four public datasets, including ShanghaiTech, WorldEXPO 10, UCF-CC-50 and UCF-QNRF. The results show that our ANF achieves high counting performance, surpassing most previous methods.",60013789,Beihang University,Beijing,China,"['1712', '1707']",22.428571428571423,0.13341666666666668,0.4490833333333332,1,0.11442786069651742,0.05970149253731343,0.41899441340782123
2003,2047,2047,Stochastic filter groups for multi-task cnns: Learning specialist and generalist convolution kernels,"The performance of multi-task learning in Convolutional Neural Networks (CNNs) hinges on the design of feature sharing between tasks within the architecture. The number of possible sharing patterns are combinatorial in the depth of the network and the number of tasks, and thus hand-crafting an architecture, purely based on the human intuitions of task relationships can be time-consuming and suboptimal. In this paper, we present a probabilistic approach to learning task-specific and shared representations in CNNs for multi-task learning. Specifically, we propose 'stochastic filter groups' (SFG), a mechanism to assign convolution kernels in each layer to 'specialist' and 'generalist' groups, which are specific to and shared across different tasks, respectively. The SFG modules determine the connectivity between layers and the structures of task-specific and shared representations in the network. We employ variational inference to learn the posterior distribution over the possible grouping of kernels and network parameters. Experiments demonstrate the proposed method generalises across multiple tasks and shows improved performance over baseline methods.",60022148,UCL,London,United Kingdom,"['1712', '1707']",23.285714285714285,0.023809523809523808,0.3805555555555556,1,0.08040201005025126,0.020100502512562814,0.3804347826086957
2004,2048,2048,Generative adversarial training for weakly supervised cloud matting,"The detection and removal of cloud in remote sensing images are essential for earth observation applications. Most previous methods consider cloud detection as a pixel-wise semantic segmentation process (cloud v.s. background), which inevitably leads to a category-ambiguity problem when dealing with semi-transparent clouds. We re-examine the cloud detection under a totally different point of view, i.e. to formulate it as a mixed energy separation process between foreground and background images, which can be equivalently implemented under an image matting paradigm with a clear physical significance. We further propose a generative adversarial framework where the training of our model neither requires any pixel-wise ground truth reference nor any additional user interactions. Our model consists of three networks, a cloud generator G, a cloud discriminator D, and a cloud matting network F, where G and D aim to generate realistic and physically meaningful cloud images by adversarial training, and F learns to predict the cloud reflectance and attenuation. Experimental results on a global set of satellite images demonstrate that our method, without ever using any pixel-wise ground truth during training, achieves comparable and even higher accuracy over other fully supervised methods, including some recent popular cloud detectors and some well-known semantic segmentation frameworks.",60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,"['1712', '1707']",25.125,0.1013888888888889,0.4056216931216932,1,0.09829059829059829,0.021367521367521368,0.2702702702702703
2005,2049,2049,Few-shot learning with global class representations,"In this paper, we propose to tackle the challenging few-shot learning (FSL) problem by learning global class representations using both base and novel class training samples. In each training episode, an episodic class mean computed from a support set is registered with the global representation via a registration module. This produces a registered global class representation for computing the classification loss using a query set. Though following a similar episodic training pipeline as existing meta learning based approaches, our method differs significantly in that novel class training samples are involved in the training from the beginning. To compensate for the lack of novel class training samples, an effective sample synthesis strategy is developed to avoid overfitting. Importantly, by joint base-novel class training, our approach can be easily extended to a more practical yet challenging FSL setting, i.e., generalized FSL, where the label space of test data is extended to both base and novel classes. Extensive experiments show that our approach is effective for both of the two FSL settings.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",24.142857142857146,0.11643518518518517,0.5905092592592593,1,0.1256544502617801,0.020942408376963352,0.26737967914438504
2006,2050,2050,Temporal attentive alignment for large-scale video domain adaptation,"Although various image-based domain adaptation (DA) techniques have been proposed in recent years, domain shift in videos is still not well-explored. Most previous works only evaluate performance on small-scale datasets which are saturated. Therefore, we first propose two large-scale video DA datasets with much larger domain discrepancy: UCF-HMDB-full and Kinetics-Gameplay. Second, we investigate different DA integration methods for videos, and show that simultaneously aligning and learning temporal dynamics achieves effective alignment even without sophisticated DA methods. Finally, we propose Temporal Attentive Adversarial Adaptation Network (TA3N), which explicitly attends to the temporal dynamics using domain discrepancy for more effective domain alignment, achieving state-of-the-art performance on four video DA datasets (e.g. 7.9% accuracy gain over 'Source only' from 73.9% to 81.8% on 'HMDB - > UCF', and 10.3% gain on 'Kinetics - > Gameplay'). The code and data are released at http://github.com/cmhungsteve/TA3N.",60107909,Sony Interactive Entertainment LLC,San Mateo,United States,"['1712', '1707']",20.0,0.19895833333333332,0.6156250000000001,1,0.09473684210526316,0.08421052631578947,0.5029239766081871
2007,2051,2051,Joint demosaicking and denoising by fine-tuning of bursts of raw images,"Demosaicking and denoising are the first steps of any camera image processing pipeline and are key for obtaining high quality RGB images. A promising current research trend aims at solving these two problems jointly using convolutional neural networks. Due to the unavailability of ground truth data these networks cannot be currently trained using real RAW images. Instead, they resort to simulated data. In this paper we present a method to learn demosaicking directly from mosaicked images, without requiring ground truth RGB data. We apply this to learn joint demosaicking and denoising only from RAW images, thus enabling the use of real data. In addition we show that for this application fine-tuning a network to a specific burst improves the quality of restoration for both demosaicking and denoising.",60004981,École Normale Supérieure Paris-Saclay,Cachan,France,"['1712', '1707']",18.142857142857142,0.014862637362637371,0.4662271062271062,1,0.18571428571428572,0.007142857142857143,0.3333333333333333
2008,2052,2052,Learning to assemble neural module tree networks for visual grounding,"Visual grounding, a task to ground (i.e., localize) natural language in images, essentially requires composite visual reasoning. However, existing methods over-simplify the composite nature of language into a monolithic sentence embedding or a coarse composition of subject-predicate-object triplet. In this paper, we propose to ground natural language in an intuitive, explainable, and composite fashion as it should be. In particular, we develop a novel modular network called Neural Module Tree network (NMTree) that regularizes the visual grounding along the dependency parsing tree of the sentence, where each node is a neural module that calculates visual attention according to its linguistic feature, and the grounding score is accumulated in a bottom-up direction where as needed. NMTree disentangles the visual grounding from the composite reasoning, allowing the former to only focus on primitive and easy-to-generalize patterns. To reduce the impact of parsing errors, we train the modules and their assembly end-to-end by using the Gumbel-Softmax approximation and its straight-through gradient estimator, accounting for the discrete nature of module assembly. Overall, the proposed NMTree consistently outperforms the state-of-the-arts on several benchmarks. Qualitative results show explainable grounding score calculation in great detail.",60005510,Nanyang Technological University,Singapore City,Singapore,"['1712', '1707']",23.5,0.0892156862745098,0.2372549019607843,1,0.12083333333333333,0.03333333333333333,0.32710280373831774
2009,2053,2053,Co-segmentation inspired attention networks for video-based person re-identification,"Person re-identification (Re-ID) is an important real-world surveillance problem that entails associating a person's identity over a network of cameras. Video-based Re-ID approaches have gained significant attention recently since a video, and not just an image, is often available. In this work, we propose a novel Co-segmentation inspired video Re-ID deep architecture and formulate a Co-segmentation based Attention Module (COSAM) that activates a common set of salient features across multiple frames of a video via mutual consensus in an unsupervised manner. As opposed to most of the prior work, our approach is able to attend to person accessories along with the person. Our plug-and-play and interpretable COSAM module applied on two deep architectures (ResNet50, SE-ResNet50) outperform the state-of-the-art methods on three benchmark datasets.",60025757,Indian Institute of Technology Madras,Chennai,India,"['1712', '1707']",24.6,0.17045454545454544,0.45,1,0.07738095238095238,0.07738095238095238,0.35
2010,2054,2054,Recursive cascaded networks for unsupervised medical image registration,"We present recursive cascaded networks, a general architecture that enables learning deep cascades, for deformable image registration. The proposed architecture is simple in design and can be built on any base network. The moving image is warped successively by each cascade and finally aligned to the fixed image; this procedure is recursive in a way that every cascade learns to perform a progressive deformation for the current warped image. The entire system is end-to-end and jointly trained in an unsupervised manner. In addition, enabled by the recursive architecture, one cascade can be iteratively applied for multiple times during testing, which approaches a better fit between each of the image pairs. We evaluate our method on 3D medical images, where deformable registration is most commonly applied. We demonstrate that recursive cascaded networks achieve consistent, significant gains and outperform state-of-the-art methods. The performance reveals an increasing trend as long as more cascades are trained, while the limit is not observed. Code is available at https://github.com/zsyzzsoft/Recursive-Cascaded-Networks.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",18.11111111111111,0.09625,0.44035714285714295,1,0.14136125654450263,0.005235602094240838,0.25136612021857924
2011,2055,2055,Be your own teacher: Improve the performance of convolutional neural networks via self distillation,"Convolutional neural networks have been widely deployed in various application scenarios. In order to extend the applications' boundaries to some accuracy-crucial domains, researchers have been investigating approaches to boost accuracy through either deeper or wider network structures, which brings with them the exponential increment of the computational and storage cost, delaying the responding time. In this paper, we propose a general training framework named self distillation, which notably enhances the performance (accuracy) of convolutional neural networks through shrinking the size of the network rather than aggrandizing it. Different from traditional knowledge distillation - a knowledge transformation methodology among networks, which forces student neural networks to approximate the softmax layer outputs of pre-trained teacher neural networks, the proposed self distillation framework distills knowledge within network itself. The networks are firstly divided into several sections. Then the knowledge in the deeper portion of the networks is squeezed into the shallow ones. Experiments further prove the generalization of the proposed self distillation framework: Enhancement of accuracy at average level is 2.65%, varying from 0.61% in ResNeXt as minimum to 4.07% in VGG19 as maximum. In addition, it can also provide flexibility of depth-wise scalable inference on resource-limited edge devices. Our codes have been released on github.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",22.555555555555557,-0.015277777777777776,0.4652777777777778,1,0.11016949152542373,0.01694915254237288,0.35526315789473684
2012,2056,2056,Live face de-identification in video,"We propose a method for face de-identification that enables fully automatic video modification at high frame rates. The goal is to maximally decorrelate the identity, while having the perception (pose, illumination and expression) fixed. We achieve this by a novel feed-forward encoder-decoder network architecture that is conditioned on the high-level representation of a person's facial image. The network is global, in the sense that it does not need to be retrained for a given video or for a given identity, and it creates natural looking image sequences with little distortion in time.",60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,"['1712', '1707']",23.0,0.02875,0.2733333333333334,1,0.11711711711711711,0.0,0.23300970873786409
2013,2057,2057,Diagnosis of depression based on short text,"Depression has become a serious global disease which can harm to mental health. Diagnosis of depression is a complicated process, and needs a great deal of specialist knowledge. A person’s social network behavior can reflect his/her real psychological. The traditional process of diagnosing depression requires not only close coordination of depressed people but also too much professional knowledge. And depressed people maybe have fewer and fewer social activities. In this paper, machine learning is used to diagnosis whether a person has depression. We use a SVM algorithm to create the depression diagnosis model based on short text. And we validate this model using a data set of Sina Micro-blog users’ Micro-blog content and depression label data gotten by certificate of diagnosis. Our work makes three important contributions. Firstly, we show how to diagnosis depression based on short text published on the social network. Secondly, we build diagnosis model of depression based on SVM. And last and thirdly, we give the experimental results that validate our method, the accuracy of whether or not depression can reach 93.47%.",60024350,National University of Defense Technology,Changsha,China,['1700'],14.666666666666664,0.04083333333333333,0.3608333333333333,1,0.12807881773399016,0.019704433497536946,0.26262626262626265
2014,2058,2058,Learning fixed points in generative adversarial networks: From image-to-image translation to disease detection and localization,"Generative adversarial networks (GANs) have ushered in a revolution in image-to-image translation. The development and proliferation of GANs raises an interesting question: Can we train a GAN to remove an object, if present, from an image while otherwise preserving the image? Specifically, can a GAN ''virtually heal'' anyone by turning his medical image, with an unknown health status (diseased or healthy), into a healthy one, so that diseased regions could be revealed by subtracting those two images? Such a task requires a GAN to identify a minimal subset of target pixels for domain translation, an ability that we call fixed-point translation, which no GAN is equipped with yet. Therefore, we propose a new GAN, called Fixed-Point GAN, trained by (1) supervising same-domain translation through a conditional identity loss, and (2) regularizing cross-domain translation through revised adversarial, domain classification, and cycle consistency loss. Based on fixed-point translation, we further derive a novel framework for disease detection and localization using only image-level annotation. Qualitative and quantitative evaluations demonstrate that the proposed method outperforms the state of the art in multi-domain image-to-image translation and that it surpasses predominant weakly-supervised localization methods in both disease detection and localization. Implementation is available at https://github.com/jlianglab/Fixed-Point-GAN.",60005558,Mayo Clinic,Rochester,United States,"['1712', '1707']",33.166666666666664,0.04545454545454546,0.5038961038961038,1,0.13127413127413126,0.02702702702702703,0.3702127659574468
2015,2059,2059,View-consistent 4D light field superpixel segmentation,"Many 4D light field processing applications rely on superpixel segmentations, for which occlusion-aware view consistency is important. Yet, existing methods often enforce consistency by propagating clusters from a central view only, which can lead to inconsistent superpixels for non-central views. Our proposed approach combines an occlusion-aware angular segmentation in horizontal and vertical EPI spaces with an occlusion-aware clustering and propagation step across all views. Qualitative video demonstrations show that this helps to remove flickering and inconsistent boundary shapes versus the state-of-the-art approach, and quantitative metrics reflect these findings with improved boundary accuracy and view consistency scores.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1707']",24.0,0.26,0.6900000000000001,1,0.11016949152542373,0.00847457627118644,0.375
2016,2060,2060,InstaBoost: Boosting instance segmentation via probability map guided copy-pasting,"Instance segmentation requires a large number of training samples to achieve satisfactory performance and benefits from proper data augmentation. To enlarge the training set and increase the diversity, previous methods have investigated using data annotation from other domain (e.g. bbox, point) in a weakly supervised mechanism. In this paper, we present a simple, efficient and effective method to augment the training set using the existing instance mask annotations. Exploiting the pixel redundancy of the background, we are able to improve the performance of Mask R-CNN for 1.7 mAP on COCO dataset and 3.3 mAP on Pascal VOC dataset by simply introducing random jittering to objects. Furthermore, we propose a location probability map based approach to explore the feasible locations that objects can be placed based on local appearance similarity. With the guidance of such map, we boost the performance of R101-Mask R-CNN on instance segmentation from 35.7 mAP to 37.9 mAP without modifying the backbone or network structure. Our method is simple to implement and does not increase the computational complexity. It can be integrated into the training pipeline of any instance segmentation model without affecting the training and inference efficiency. Our code and models have been released at https://github.com/GothicAi/InstaBoost.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",20.0,0.010544217687074824,0.3708333333333333,1,0.13963963963963963,0.04504504504504504,0.3167420814479638
2017,2061,2061,A neural network for detailed human depth estimation from a single image,"This paper presents a neural network to estimate a detailed depth map of the foreground human in a single RGB image. The result captures geometry details such as cloth wrinkles, which are important in visualization applications. To achieve this goal, we separate the depth map into a smooth base shape and a residual detail shape and design a network with two branches to regress them respectively. We design a training strategy to ensure both base and detail shapes can be faithfully learned by the corresponding network branches. Furthermore, we introduce a novel network layer to fuse a rough depth map and surface normals to further improve the final result. Quantitative comparison with fused 'ground truth' captured by real depth cameras and qualitative examples on unconstrained Internet images demonstrate the strength of the proposed method.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",22.33333333333333,-0.028571428571428574,0.5664835164835165,1,0.12413793103448276,0.0,0.2222222222222222
2018,2062,2062,Shadow removal via shadow image decomposition,"We propose a novel deep learning method for shadow removal. Inspired by physical models of shadow formation, we use a linear illumination transformation to model the shadow effects in the image that allows the shadow image to be expressed as a combination of the shadow-free image, the shadow parameters, and a matte layer. We use two deep networks, namely SP-Net and M-Net, to predict the shadow parameters and the shadow matte respectively. This system allows us to remove the shadow effects on the images. We train and test our framework on the most challenging shadow removal dataset (ISTD). Compared to the state-of-the-art method, our model achieves a 40% error reduction in terms of root mean square error (RMSE) for the shadow area, reducing RMSE from 13.3 to 7.9. Moreover, we create an augmented ISTD dataset based on an image decomposition system by modifying the shadow parameters to generate new synthetic shadow images. Training our model on this new augmented ISTD dataset further lowers the RMSE on the shadow area to 7.4.",60026415,Stony Brook University,Stony Brook,United States,"['1712', '1707']",21.375,0.09602272727272727,0.4639448051948052,1,0.12254901960784313,0.04411764705882353,0.3125
2019,2063,2063,Joint learning of semantic alignment and object landmark detection,"Convolutional neural networks (CNNs) based approaches for semantic alignment and object landmark detection have improved their performance significantly. Current efforts for the two tasks focus on addressing the lack of massive training data through weakly- or unsupervised learning frameworks. In this paper, we present a joint learning approach for obtaining dense correspondences and discovering object landmarks from semantically similar images. Based on the key insight that the two tasks can mutually provide supervisions to each other, our networks accomplish this through a joint loss function that alternatively imposes a consistency constraint between the two tasks, thereby boosting the performance and addressing the lack of training data in a principled manner. To the best of our knowledge, this is the first attempt to address the lack of training data for the two tasks through the joint learning. To further improve the robustness of our framework, we introduce a probabilistic learning formulation that allows only reliable matches to be used in the joint learning process. With the proposed method, state-of-the-art performance is attained on several benchmarks for semantic matching and landmark detection.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",25.714285714285715,0.0625,0.4944444444444444,1,0.11940298507462686,0.004975124378109453,0.26153846153846155
2020,2064,2064,Mobile offloading in vehicular networks: A reward-based incentive caching scheme,"The massive growth of mobile vehicles arises immense mobile traffic demand on the current cellular communication system. To cope with this challenge, a new transmission pattern that vehicle nodes cache some data contents in advance and provide data access for future requests via direct contacts has become an appealing solution for data offloading. However due to the limited resources, the fact that vehicle nodes might not be willing to assist data caching and transfer is plausible. Therefore in this paper, we build a reward-based caching-offloading framework, which efficiently offload cellular traffic by exploiting the storage capability and contact opportunity among vehicle nodes. The whole framework is divided into request phase and caching phase, an auction mechanism which comprises the bidding strategy, the response-for-bids strategy, and the prediction method is designed in the former phase and the optimal caching decision can be derived by solving a 0–1 knapsack problem in the latter phase. We conduct simulations on time-evolving topology traces, which validates the feasibility and efficiency of the proposed offloading paradigm.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],28.33333333333333,0.10642393320964748,0.43195732838589984,1,0.12371134020618557,0.0,0.24456521739130435
2021,2065,2065,An improved spectral clustering algorithm based on cell-like P system,"When using spectral clustering algorithm to perform clustering, there are some shortcomings, such as slow convergence rate, and the clustering result is easily affected by the initial center. In order to improve this problem, this paper proposes an improved spectral clustering algorithm based on cell-like P system, called SCBK-CP algorithm. Its main idea is to use the bisecting k-means algorithm instead of k-means algorithm and construct a cell-like P system as the framework of the bisecting k-means algorithm to improve the spectral clustering algorithm. The maximum parallelism of the P system improves the efficiency of the bisecting k-means algorithm. The algorithm proposed in this paper improves the clustering effect of spectral clustering, and also provides a new idea for the application of membrane computing. The SCBK-CP algorithm uses three UCI datasets and an artificial dataset for experiments and further comparison with traditional spectral clustering algorithms. Experimental results verify the advantages of the SCBK-CP algorithm.",60002210,Shandong Normal University,Jinan,China,['1700'],22.0,-0.014876033057851241,0.4792011019283747,1,0.12972972972972974,0.05405405405405406,0.281437125748503
2022,2066,2066,Universal semi-supervised semantic segmentation,"In recent years, the need for semantic segmentation has arisen across several different applications and environments. However, the expense and redundancy of annotation often limits the quantity of labels available for training in any domain, while deployment is easier if a single model works well across domains. In this paper, we pose the novel problem of universal semi-supervised semantic segmentation and propose a solution framework, to meet the dual needs of lower annotation and deployment costs. In contrast to counterpoints such as fine tuning, joint training or unsupervised domain adaptation, universal semi-supervised segmentation ensures that across all domains: (i) a single model is deployed, (ii) unlabeled data is used, (iii) performance is improved, (iv) only a few labels are needed and (v) label spaces may differ. To address this, we minimize supervised as well as within and cross-domain unsupervised losses, introducing a novel feature alignment objective based on pixel-aware entropy regularization for the latter. We demonstrate quantitative advantages over other approaches on several combinations of segmentation datasets across different geographies (Germany, England, India) and environments (outdoors, indoors), as well as qualitative insights on the aligned representations.",60030612,"University of California, San Diego",San Diego,United States,"['1712', '1707']",31.0,-0.022288359788359788,0.32519841269841265,1,0.09523809523809523,0.017316017316017316,0.35874439461883406
2023,2067,2067,New convex relaxations for MRF inference with unknown graphs,"Treating graph structures of Markov random fields as unknown and estimating them jointly with labels have been shown to be useful for modeling human activity recognition and other related tasks. We propose two novel relaxations for solving this problem. The first is a linear programming (LP) relaxation, which is provably tighter than the existing LP relaxation. The second is a non-convex quadratic programming (QP) relaxation, which admits an efficient concave-convex procedure (CCCP). The CCCP algorithm is initialized by solving a convex QP relaxation of the problem, which is obtained by modifying the diagonal of the matrix that specifies the non-convex QP relaxation. We show that our convex QP relaxation is optimal in the sense that it minimizes the L1 norm of the diagonal modification vector. While the convex QP relaxation is not as tight as the existing and the new LP relaxations, when used in conjunction with the CCCP algorithm for the non-convex QP relaxation, it provides accurate solutions. We demonstrate the efficacy of our new relaxations for both synthetic data and human activity recognition.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",21.875,0.05744724025974026,0.3772794913419913,1,0.09405940594059406,0.09405940594059406,0.33505154639175255
2024,2068,2068,Multi-view image fusion,"We present an end-to-end learned system for fusing multiple misaligned photographs of the same scene into a chosen target view. We demonstrate three use cases: 1) color transfer for inferring color for a monochrome view, 2) HDR fusion for merging misaligned bracketed exposures, and 3) detail transfer for reprojecting a high definition image to the point of view of an affordable VR180-camera. While the system can be trained end-to-end, it consists of three distinct steps: Feature extraction, image warping and fusion. We present a novel cascaded feature extraction method that enables us to synergetically learn optical flow at different resolution levels. We show that this significantly improves the network's ability to learn large disparities. Finally, we demonstrate that our alignment architecture outperforms a state-of-the art optical flow network on the image warping task when both systems are trained in an identical manner.",60007592,Universitat Politècnica de Catalunya,Barcelona,Spain,"['1712', '1707']",23.66666666666667,0.1049285714285714,0.3868571428571429,1,0.13450292397660818,0.005847953216374269,0.3270440251572327
2025,2069,2069,Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data,"We propose to harness the potential of simulation for semantic segmentation of real-world self-driving scenes in a domain generalization fashion. The segmentation network is trained without any information about target domains and tested on the unseen target domains. To this end, we propose a new approach of domain randomization and pyramid consistency to learn a model with high generalizability. First, we propose to randomize the synthetic images with styles of real images in terms of visual appearances using auxiliary datasets, in order to effectively learn domain-invariant representations. Second, we further enforce pyramid consistency across different 'stylized' images and within an image, in order to learn domain-invariant and scale-invariant features, respectively. Extensive experiments are conducted on generalization from GTA and SYNTHIA to Cityscapes, BDDS, and Mapillary; and our method achieves superior results over the state-of-the-art techniques. Remarkably, our generalization results are on par with or even better than those obtained by state-of-the-art simulation-to-real domain adaptation methods, which access the target domain data at training time.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",23.42857142857143,0.23545454545454544,0.5008008658008658,1,0.08571428571428572,0.01904761904761905,0.3333333333333333
2026,2070,2070,Accelerate CNN via recursive bayesian pruning,"Channel Pruning, widely used for accelerating Convolutional Neural Networks, is an NP-hard problem due to the inter-layer dependency of channel redundancy. Existing methods generally ignored the above dependency for computation simplicity. To solve the problem, under the Bayesian framework, we here propose a layer-wise Recursive Bayesian Pruning method (RBP). A new dropout-based measurement of redundancy, which facilitate the computation of posterior assuming inter-layer dependency, is introduced. Specifically, we model the noise across layers as a Markov chain and target its posterior to reflect the inter-layer dependency. Considering the closed form solution for posterior is intractable, we derive a sparsity-inducing Dirac-like prior which regularizes the distribution of the designed noise to automatically approximate the posterior. Compared with the existing methods, no additional overhead is required when the inter-layer dependency assumed. The redundant channels can be simply identified by tiny dropout noise and directly pruned layer by layer. Experiments on popular CNN architectures have shown that the proposed method outperforms several state-of-the-arts. Particularly, we achieve up to 5.0x, 2.2x and 1.7x FLOPs reduction with little accuracy loss on the large scale dataset ILSVRC2012 for VGG16, ResNet50 and MobileNetV2, respectively.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",18.7,0.00860088985088984,0.34714405964405964,1,0.13135593220338984,0.0635593220338983,0.36792452830188677
2027,2071,2071,UprightNet: Geometry-aware camera orientation estimation from single images,"We introduce UprightNet, a learning-based approach for estimating 2DoF camera orientation from a single RGB image of an indoor scene. Unlike recent methods that leverage deep learning to perform black-box regression from image to orientation parameters, we propose an end-to-end framework that incorporates explicit geometric reasoning. In particular, we design a network that predicts two representations of scene geometry, in both the local camera and global reference coordinate systems, and solves for the camera orientation as the rotation that best aligns these two predictions via a differentiable least squares module. This network can be trained end-to-end, and can be supervised with both ground truth camera poses and intermediate representations of surface geometry. We evaluate UprightNet on the single-image camera orientation task on synthetic and real datasets, and show significant improvements over prior state-of-the-art approaches.",60104837,Cornell Tech,New York,United States,"['1712', '1707']",26.8,0.12456709956709955,0.2793290043290044,1,0.10240963855421686,0.012048192771084338,0.3082191780821918
2028,2072,2072,Deep blind hyperspectral image fusion,"Hyperspectral image fusion (HIF) reconstructs high spatial resolution hyperspectral images from low spatial resolution hyperspectral images and high spatial resolution multispectral images. Previous works usually assume that the linear mapping between the point spread functions of the hyperspectral camera and the spectral response functions of the conventional camera is known. This is unrealistic in many scenarios. We propose a method for blind HIF problem based on deep learning, where the estimation of the observation model and fusion process are optimized iteratively and alternatingly during the super-resolution reconstruction. In addition, the proposed framework enforces simultaneous spatial and spectral accuracy. Using three public datasets, the experimental results demonstrate that the proposed algorithm outperforms existing blind and non-blind methods.",60030162,Columbia University in the City of New York,New York,United States,"['1712', '1707']",19.33333333333333,-0.08765567765567764,0.4502930402930404,1,0.0916030534351145,0.022900763358778626,0.33070866141732286
2029,2073,2073,Structured prediction helps 3D human motion modelling,"Human motion prediction is a challenging and important task in many computer vision application domains. Existing work only implicitly models the spatial structure of the human skeleton. In this paper, we propose a novel approach that decomposes the prediction into individual joints by means of a structured prediction layer that explicitly models the joint dependencies. This is implemented via a hierarchy of small-sized neural networks connected analogously to the kinematic chains in the human body as well as a joint-wise decomposition in the loss function. The proposed layer is agnostic to the underlying network and can be used with existing architectures for motion modelling. Prior work typically leverages the H3.6M dataset. We show that some state-of-the-art techniques do not perform well when trained and tested on AMASS, a recently released dataset 14 times the size of H3.6M. Our experiments indicate that the proposed layer increases the performance of motion forecasting irrespective of the base network, joint-angle representation, and prediction horizon. We furthermore show that the layer also improves motion predictions qualitatively. We make code and models publicly available at https://ait.ethz.ch/projects/2019/spl.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",18.0,0.06410256410256407,0.4884615384615385,1,0.11650485436893204,0.019417475728155338,0.30612244897959184
2030,2074,2074,Joint optimization for cooperative image captioning,"When describing images with natural language, descriptions can be made more informative if tuned for downstream tasks. This can be achieved by training two networks: A 'speaker' that generates sentences given an image and a 'listener' that uses them to perform a task. Unfortunately, training multiple networks jointly to communicate, faces two major challenges. First, the descriptions generated by a speaker network are discrete and stochastic, making optimization very hard and inefficient. Second, joint training usually causes the vocabulary used during communication to drift and diverge from natural language. To address these challenges, we present an effective optimization technique based on partial-sampling from a multinomial distribution combined with straight-through gradient updates, which we name PSST for Partial-Sampling Straight-Through. We then show that the generated descriptions can be kept close to natural by constraining them to be similar to human descriptions. Together, this approach creates descriptions that are both more discriminative and more natural than previous approaches. Evaluations on the COCO benchmark show that PSST improve the recall@10 from 60% to 86% maintaining comparable language naturalness. Human evaluations show that it also increases naturalness while keeping the discriminative power of generated captions.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",19.1,0.07583333333333334,0.37270833333333336,1,0.16444444444444445,0.02666666666666667,0.35023041474654376
2031,2075,2075,Study and analysis of impact factors on the level of maturity of the Moroccan aerospace ecosystem and their effects on the local supply chain," Indeed, we have seen the birth of an industrial platform made up of several capabilities and industrial capacities that have been able to respond to a first request for subcontracting at lower cost in the manufacture of the elementary part to complex subsets for the (OEM) Original Equipment Manufacturer tier 1 and tier 2. Through a benchmark model of the cluster performance that we had built, we are able to verify these influential parameters across a benchmark and define the level of maturity of an industrial ecosystem in a global supply chain compared to its competing countries. The goal is to deduce the success factors that would maximize the performance of an industrial cluster, in particular the technological and, the entrepreneurial spin-offs.",60025457,Hassan II University of Casablanca,Casablanca,Morocco,['1706'],41.0,0.20916666666666667,0.39666666666666667,0,0.08208955223880597,0.029850746268656716,0.22137404580152673
2032,2076,2076,Leveraging long-range temporal relationships between proposals for video object detection,"Single-frame object detectors perform well on videos sometimes, even without temporal context. However, challenges such as occlusion, motion blur, and rare poses of objects are hard to resolve without temporal awareness. Thus, there is a strong need to improve video object detection by considering long-range temporal dependencies. In this paper, we present a light-weight modification to a single-frame detector that accounts for arbitrary long dependencies in a video. It improves the accuracy of a single-frame detector significantly with negligible compute overhead. The key component of our approach is a novel temporal relation module, operating on object proposals, that learns the similarities between proposals from different frames and selects proposals from past and/or future to support current proposals. Our final 'causal' model, without any offline post-processing steps, runs at a similar speed as a single-frame detector and achieves state-of-the-art video object detection on ImageNet VID dataset.",60025111,The University of North Carolina at Chapel Hill,Chapel Hill,United States,"['1712', '1707']",20.714285714285715,0.02777777777777777,0.5549999999999999,1,0.07065217391304347,0.010869565217391304,0.3496932515337423
2033,2077,2077,Deep self-learning from noisy labels,"ConvNets achieve good results when training from clean data, but learning from noisy labels significantly degrades performances and remains challenging. Unlike previous works constrained by many conditions, making them infeasible to real noisy cases, this work presents a novel deep self-learning framework to train a robust network on the real noisy datasets without extra supervision. The proposed approach has several appealing benefits. (1) Different from most existing work, it does not rely on any assumption on the distribution of the noisy labels, making it robust to real noises. (2) It does not need extra clean supervision or accessorial network to help training. (3) A self-learning framework is proposed to train the network in an iterative end-to-end manner, which is effective and efficient. Extensive experiments in challenging benchmarks such as Clothing1M and Food101-N show that our approach outperforms its counterparts in all empirical settings.",60006541,The University of Hong Kong,Pokfulam,Hong Kong,"['1712', '1707']",20.428571428571427,0.24734848484848485,0.4715909090909091,1,0.13450292397660818,0.017543859649122806,0.3333333333333333
2034,2079,2079,Deep parametric indoor lighting estimation,"We present a method to estimate lighting from a single image of an indoor scene. Previous work has used an environment map representation that does not account for the localized nature of indoor lighting. Instead, we represent lighting as a set of discrete 3D lights with geometric and photometric parameters. We train a deep neural network to regress these parameters from a single image, on a dataset of environment maps annotated with depth. We propose a differentiable layer to convert these parameters to an environment map to compute our loss; this bypasses the challenge of establishing correspondences between estimated and ground truth lights. We demonstrate, via quantitative and qualitative evaluations, that our representation and training scheme lead to more accurate results compared to previous work, while allowing for more realistic 3D object compositing with spatially-varying lighting.",60032619,Université Laval,Quebec,Canada,"['1712', '1707']",22.66666666666667,0.10904761904761906,0.31285714285714283,1,0.12666666666666668,0.0,0.2702702702702703
2035,2080,2080,Sequence level semantics aggregation for video object detection,"Video objection detection (VID) has been a rising research direction in recent years. A central issue of VID is the appearance degradation of video frames caused by fast motion. This problem is essentially ill-posed for a single frame. Therefore, aggregating features from other frames becomes a natural choice. Existing methods rely heavily on optical FLow or recurrent neural networks for feature aggregation. However, these methods emphasize more on the temporally nearby frames. In this work, we argue that aggregating features in the full-sequence level will lead to more discriminative and robust features for video object detection. To achieve this goal, we devise a novel Sequence Level Semantics Aggregation (SELSA) module. We further demonstrate the close relationship between the proposed method and the classic spectral clustering method, providing a novel view for understanding the VID problem. We test the proposed method on the ImageNet VID and the EPIC KITCHENS dataset and achieve new state-of-the-art results. Our method does not need complicated postprocessing methods such as Seq-NMS or Tubelet rescoring, which keeps the pipeline simple and clean.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",15.909090909090908,0.06518157768157769,0.4426467051467051,1,0.1201923076923077,0.07211538461538461,0.3622448979591837
2036,2081,2081,Deep multi-model fusion for single-image dehazing,"This paper presents a deep multi-model fusion network to attentively integrate multiple models to separate layers and boost the performance in single-image dehazing. To do so, we first formulate the attentional feature integration module to maximize the integration of the convolutional neural network (CNN) features at different CNN layers and generate the attentional multi-level integrated features (AMLIF). Then, from the AMLIF, we further predict a haze-free result for an atmospheric scattering model, as well as for four haze-layer separation models, and then fuse the results together to produce the final haze-free image. To evaluate the effectiveness of our method, we compare our network with several state-of-the-art methods on two widely-used dehazing benchmark datasets, as well as on two sets of real-world hazy images. Experimental results demonstrate clear quantitative and qualitative improvements of our method over the state-of-the-arts.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",27.4,0.07727272727272727,0.4106060606060607,1,0.09392265193370165,0.022099447513812154,0.3464052287581699
2037,2082,2082,Unconstrained foreground object search,"Many people search for foreground objects to use when editing images. While existing methods can retrieve candidates to aid in this, they are constrained to returning objects that belong to a pre-specified semantic class. We instead propose a novel problem of unconstrained foreground object (UFO) search and introduce a solution that supports efficient search by encoding the background image in the same latent space as the candidate foreground objects. A key contribution of our work is a cost-free, scalable approach for creating a large-scale training dataset with a variety of foreground objects of differing semantic categories per image location. Quantitative and human-perception experiments with two diverse datasets demonstrate the advantage of our UFO search solution over related baselines.",60013372,The University of Texas at Austin,Austin,United States,"['1712', '1707']",23.6,0.125,0.50625,1,0.11851851851851852,0.014814814814814815,0.2992125984251969
2038,2083,2083,Moment matching for multi-source domain adaptation,"Conventional unsupervised domain adaptation (UDA) assumes that training data are sampled from a single domain. This neglects the more practical scenario where training data are collected from multiple sources, requiring multi-source domain adaptation. We make three major contributions towards addressing this problem. First, we collect and annotate by far the largest UDA dataset, called DomainNet, which contains six domains and about 0.6 million images distributed among 345 categories, addressing the gap in data availability for multi-source UDA research. Second, we propose a new deep learning approach, Moment Matching for Multi-Source Domain Adaptation (M3SDA), which aims to transfer knowledge learned from multiple labeled source domains to an unlabeled target domain by dynamically aligning moments of their feature distributions. Third, we provide new theoretical insights specifically for moment matching approaches in both single and multiple source domain adaptation. Extensive experiments are conducted to demonstrate the power of our new dataset in benchmarking state-of-the-art multi-source domain adaptation methods, as well as the advantage of our proposed model. Dataset and Code are available at http://ai.bu.edu/M3SDA/.",60121156,Horizon Robotics,Haidian,China,"['1712', '1707']",21.375,0.07557245386192753,0.3008430166324903,1,0.11650485436893204,0.06310679611650485,0.40512820512820513
2039,2084,2084,Fast-deepKCF without boundary effect,"In recent years, correlation filter based trackers (CF trackers) have received much attention because of their top performance. Most CF trackers, however, suffer from low frame-per-second (fps) in pursuit of higher localization accuracy by relaxing the boundary effect or exploiting the high-dimensional deep features. In order to achieve real-time tracking speed while maintaining high localization accuracy, in this paper, we propose a novel CF tracker, fdKCF∗which casts aside the popular acceleration tool, i.e., fast Fourier transform, employed by all existing CF trackers, and exploits the inherent high-overlap among real (i.e., noncyclic) and dense samples to efficiently construct the kernel matrix. Our fdKCF∗ enjoys the following three advantages. (i) It is efficiently trained in kernel space and spatial domain without the boundary effect. (ii) Its fps is almost independent of the number of feature channels. Therefore, it is almost real-time, i.e., 24 fps on OTB-2015, even though the high-dimensional deep features are employed. (iii) Its localization accuracy is state-of-the-art. Extensive experiments on four public benchmarks, OTB-2013, OTB-2015, VOT2016, and VOT2017, show that the proposed fdKCF∗ achieves the state-of-the-art localization performance with remarkably faster speed than C-COT and ECO.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.777777777777782,0.19764705882352945,0.3979411764705882,1,0.078125,0.05078125,0.45614035087719296
2040,2085,2085,Towards multi-pose guided virtual try-on network,"Virtual try-on systems under arbitrary human poses have significant application potential, yet also raise extensive challenges, such as self-occlusions, heavy misalignment among different poses, and complex clothes textures. Existing virtual try-on methods can only transfer clothes given a fixed human pose, and still show unsatisfactory performances, often failing to preserve person identity or texture details, and with limited pose diversity. This paper makes the first attempt towards a multi-pose guided virtual try-on system, which enables clothes to transfer onto a person with diverse poses. Given an input person image, a desired clothes image, and a desired pose, the proposed Multi-pose Guided Virtual Try-On Network (MG-VTON) generates a new person image after fitting the desired clothes into the person and manipulating the pose. MG-VTON is constructed with three stages: 1) a conditional human parsing network is proposed that matches both the desired pose and the desired clothes shape; 2) a deep Warping Generative Adversarial Network (Warp-GAN) that warps the desired clothes appearance into the synthesized human parsing map and alleviates the misalignment problem between the input human pose and the desired one; 3) a refinement render network recovers the texture details of clothes and removes artifacts, based on multi-pose composition masks. Extensive experiments on commonly-used datasets and our newly-collected largest virtual try-on benchmark demonstrate that our MG-VTON significantly outperforms all state-of-the-art methods both qualitatively and quantitatively, showing promising virtual try-on performances.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",38.333333333333336,0.054997176736307184,0.4368435911914173,1,0.15488215488215487,0.04713804713804714,0.3745173745173745
2041,2086,2086,Learning to reconstruct 3D manhattan wireframes from a single image,"From a single view of an urban environment, we propose a method to effectively exploit the global structural regularities for obtaining a compact, accurate, and intuitive 3D wireframe representation. Our method trains a single convolutional neural network to simultaneously detect salient junctions and straight lines, as well as predict their 3D depth and vanishing points. Compared with state-of-the-art learning-based wireframe detection methods, our network is much simpler and more unified, leading to better 2D wireframe detection. With a global structural prior (such as Manhattan assumption), our method further reconstructs a full 3D wireframe model, a compact vector representation suitable for a variety of high-level vision tasks such as AR and CAD. We conduct extensive evaluations of our method on a large new synthetic dataset of urban scenes as well as real images. Our code and datasets will be published along with the paper.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",23.83333333333333,0.1685360094451004,0.35356158992522624,1,0.08875739644970414,0.01775147928994083,0.31446540880503143
2042,2087,2087,Prior-aware neural network for partially-supervised multi-organ segmentation,"Accurate multi-organ abdominal CT segmentation is essential to many clinical applications such as computer-aided intervention. As data annotation requires massive human labor from experienced radiologists, it is common that training data is usually partially-labeled. However, these background labels can be misleading in multi-organ segmentation since the ''background'' usually contains some other organs of interest. To address the background ambiguity in these partially-labeled datasets, we propose Prior-aware Neural Network (PaNN) via explicitly incorporating anatomical priors on abdominal organ sizes, guiding the training process with domain-specific knowledge. More specifically, PaNN assumes that the average organ size distributions in the abdomen should approximate their empirical distributions, a prior statistics obtained from the fully-labeled dataset. As our objective is difficult to be directly optimized using stochastic gradient descent, it is reformulated as a min-max form and optimized via the stochastic primal-dual gradient algorithm. PaNN achieves state-of-the-art performance on the MICCAI2015 challenge ''Multi-Atlas Labeling Beyond the Cranial Vault'', a competition on organ segmentation in the abdomen. We report an average Dice score of 84.97%, surpassing the prior art by a large margin of 3.27%. Code and models will be made publicly available.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",20.777777777777782,0.03866459627329193,0.41899585921325055,1,0.10204081632653061,0.05714285714285714,0.37089201877934275
2043,2088,2088,Robust motion segmentation from pairwise matches,"In this paper we consider the problem of motion segmentation, where only pairwise correspondences are assumed as input without prior knowledge about tracks. The problem is formulated as a two-step process. First, motion segmentation is performed on image pairs independently. Secondly, we combine independent pairwise segmentation results in a robust way into the final globally consistent segmentation. Our approach is inspired by the success of averaging methods. We demonstrate in simulated as well as in real experiments that our method is very effective in reducing the errors in the pairwise motion segmentation and can cope with large number of mismatches.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,"['1712', '1707']",16.666666666666664,0.1812987012987013,0.4033549783549784,1,0.12612612612612611,0.0,0.24770642201834864
2044,2089,2089,Beyond cartesian representations for local descriptors,"The dominant approach for learning local patch descriptors relies on small image regions whose scale must be properly estimated a priori by a keypoint detector. In other words, if two patches are not in correspondence, their descriptors will not match. A strategy often used to alleviate this problem is to 'pool' the pixel-wise features over log-polar regions, rather than regularly spaced ones. By contrast, we propose to extract the 'support region' directly with a log-polar sampling scheme. We show that this provides us with a better representation by simultaneously oversampling the immediate neighbourhood of the point and undersampling regions far away from it. We demonstrate that this representation is particularly amenable to learning descriptors with deep networks. Our models can match descriptors across a much wider range of scales than was possible before, and also leverage much larger support regions without suffering from occlusions. We report state-of-the-art results on three different datasets.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",19.0,0.05178571428571428,0.4394230769230769,1,0.12154696132596685,0.0,0.32335329341317365
2045,2090,2090,What would you expect? anticipating egocentric actions with rolling-unrolling LSTMS and modality attention,"Egocentric action anticipation consists in understanding which objects the camera wearer will interact with in the near future and which actions they will perform. We tackle the problem proposing an architecture able to anticipate actions at multiple temporal scales using two LSTMs to 1) summarize the past, and 2) formulate predictions about the future. The input video is processed considering three complimentary modalities: Appearance (RGB), motion (optical flow) and objects (object-based features). Modality-specific predictions are fused using a novel Modality ATTention (MATT) mechanism which learns to weigh modalities in an adaptive fashion. Extensive evaluations on two large-scale benchmark datasets show that our method outperforms prior art by up to +7% on the challenging EPIC-Kitchens dataset including more than 2500 actions, and generalizes to EGTEA Gaze+. Our approach is also shown to generalize to the tasks of early action recognition and action recognition. Our method is ranked first in the public leaderboard of the EPIC-Kitchens egocentric action anticipation challenge 2019. Please see the project web page for code and additional details: Http://iplab.dmi.unict.it/rulstm.",60010146,Università degli Studi di Catania,Catania,Italy,"['1712', '1707']",21.375,0.13333333333333336,0.2754629629629629,1,0.12682926829268293,0.05365853658536585,0.39593908629441626
2046,2091,2091,Unsupervised procedure learning via joint dynamic summarization,"We address the problem of unsupervised procedure learning from unconstrained instructional videos. Our goal is to produce a summary of the procedure key-steps and their ordering needed to perform a given task, as well as localization of the key-steps in videos. We develop a collaborative sequential subset selection framework, where we build a dynamic model on videos by learning states and transitions between them, where states correspond to different subactivities, including background and procedure steps. To extract procedure key-steps, we develop an optimization framework that finds a sequence of a small number of states that well represents all videos and is compatible with the state transition model. Given that our proposed optimization is non-convex and NP-hard, we develop a fast greedy algorithm whose complexity is linear in the length of the videos and the number of states of the dynamic model, hence, scales to large datasets. Under appropriate conditions on the transition model, our proposed formulation is approximately submodular, hence, comes with performance guarantees. We also present ProceL, a new multimodal dataset of 47.3 hours of videos and their transcripts from diverse tasks, for procedure learning evaluation. By extensive experiments, we show that our framework significantly improves the state of the art performance.",60028628,Northeastern University,Boston,United States,"['1712', '1707']",25.375,0.06463744588744587,0.42706529581529584,1,0.09787234042553192,0.00851063829787234,0.29777777777777775
2047,2092,2092,DSConv: Efficient convolution operator,"Quantization is a popular way of increasing the speed and lowering the memory usage of Convolution Neural Networks (CNNs). When labelled training data is available, network weights and activations have successfully been quantized down to 1-bit. The same cannot be said about the scenario when labelled training data is not available, e.g. when quantizing a pre-trained model, where current approaches show, at best, no loss of accuracy at 8-bit quantizations. We introduce DSConv, a flexible quantized convolution operator that replaces single-precision operations with their far less expensive integer counterparts, while maintaining the probability distributions over both the kernel weights and the outputs. We test our model as a plug-and-play replacement for standard convolution on most popular neural network architectures, ResNet, DenseNet, GoogLeNet, AlexNet and VGG-Net and demonstrate state-of-the-art results, with less than 1% loss of accuracy, without retraining, using only 4-bit quantization. We also show how a distillation-based adaptation stage with unlabelled data can improve results even further.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",22.57142857142857,0.1624183006535948,0.4998366013071896,1,0.12,0.06,0.3879781420765027
2048,2093,2093,GANalyze: Toward visual definitions of cognitive image properties,"We introduce a framework that uses Generative Adversarial Networks (GANs) to study cognitive properties like memorability. These attributes are of interest because we do not have a concrete visual definition of what they entail. What does it look like for a dog to be more memorable? GANs allow us to generate a manifold of natural-looking images with fine-grained differences in their visual attributes. By navigating this manifold in directions that increase memorability, we can visualize what it looks like for a particular generated image to become more memorable. The resulting ''visual definitions' surface image properties (like ''object size') that may underlie memorability. Through behavioral experiments, we verify that our method indeed discovers image manipulations that causally affect human memory performance. We further demonstrate that the same framework can be used to analyze image aesthetics and emotional valence. ganalyze.csail.mit.edu.",60025063,KU Leuven,3000 Leuven,Belgium,"['1712', '1707']",17.25,0.17820512820512818,0.3852564102564103,1,0.15950920245398773,0.012269938650306749,0.3057324840764331
2049,2094,2094,Unsupervised multi-task feature learning on point clouds,"We introduce an unsupervised multi-task model to jointly learn point and shape features on point clouds. We define three unsupervised tasks including clustering, reconstruction, and self-supervised classification to train a multi-scale graph-based encoder. We evaluate our model on shape classification and segmentation benchmarks. The results suggest that it outperforms prior state-of-the-art unsupervised models: In the ModelNet40 classification task, it achieves an accuracy of 89.1% and in ShapeNet segmentation task, it achieves an mIoU of 68.2 and accuracy of 88.6%.",124082229,Autodesk AI Lab,San Francisco,United States,"['1712', '1707']",19.75,0.0,0.0,1,0.125,0.019230769230769232,0.4111111111111111
2050,2095,2095,Explaining neural networks semantically and quantitatively,"This paper presents a method to pursue a semantic and quantitative explanation for the knowledge encoded in a convolutional neural network (CNN). The estimation of the specific rationale of each prediction made by the CNN presents a key issue of understanding neural networks, and it is of significant values in real applications. In this study, we propose to distill knowledge from the CNN into an explainable additive model, which explains the CNN prediction quantitatively. We discuss the problem of the biased interpretation of CNN predictions. To overcome the biased interpretation, we develop prior losses to guide the learning of the explainable additive model. Experimental results have demonstrated the effectiveness of our method.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",18.666666666666668,0.1125,0.45,1,0.11290322580645161,0.04032258064516129,0.28225806451612906
2051,2096,2096,Modeling inter and intra-class relations in the triplet loss for zero-shot learning,"Recognizing visual unseen classes, i.e. for which no training data is available, is known as Zero Shot Learning (ZSL). Some of the best performing methods apply the triplet loss to seen classes to learn a mapping between visual representations of images and attribute vectors that constitute class prototypes. They nevertheless make several implicit assumptions that limit their performance on real use cases, particularly with fine-grained datasets comprising a large number of classes. We identify three of these assumptions and put forward corresponding novel contributions to address them. Our approach consists in taking into account both inter-class and intra-class relations, respectively by being more permissive with confusions between similar classes, and by penalizing visual samples which are atypical to their class. The approach is tested on four datasets, including the large-scale ImageNet, and exhibits performances significantly above recent methods, even generative methods based on more restrictive hypotheses.",60106189,"CEA, Institut LIST",Palaiseau,France,"['1712', '1707']",20.857142857142858,0.1863095238095238,0.23824404761904766,1,0.12352941176470589,0.029411764705882353,0.34355828220858897
2052,2097,2097,Maximum-margin hamming hashing,"Deep hashing enables computation and memory efficient image search through end-to-end learning of feature representations and binary codes. While linear scan over binary hash codes is more efficient than over the high-dimensional representations, its linear-time complexity is still unacceptable for very large databases. Hamming space retrieval enables constant-time search through hash lookups, where for each query, there is a Hamming ball centered at the query and the data points within the ball are returned as relevant. Since inside the Hamming ball implies retrievable while outside irretrievable, it is crucial to explicitly characterize the Hamming ball. The main idea of this work is to directly embody the Hamming radius into the loss functions, leading to Maximum-Margin Hamming Hashing (MMHH), a new model specifically optimized for Hamming space retrieval. We introduce a max-margin t-distribution loss, where the t-distribution concentrates more similar data points to be within the Hamming ball, and the margin characterizes the Hamming radius such that less penalization is applied to similar data points within the Hamming ball. The loss function also introduces robustness to data noise, where the similarity supervision may be inaccurate in practical problems. The model is trained end-to-end using a new semi-batch optimization algorithm tailored to extremely imbalanced data. Our method yields state-of-the-art results on four datasets and shows superior performance on noisy data.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",24.222222222222218,0.1544881588999236,0.5186019862490451,1,0.07835820895522388,0.05223880597014925,0.31092436974789917
2053,2098,2098,Analyzing the variety loss in the context of probabilistic trajectory prediction,"Trajectory or behavior prediction of traffic agents is an important component of autonomous driving and robot planning in general. It can be framed as a probabilistic future sequence generation problem and recent literature has studied the applicability of generative models in this context. The variety or Minimum over N (MoN) loss, which tries to minimize the error between the ground truth and the closest of N output predictions, has been used in these recent learning models to improve the diversity of predictions. In this work, we present a proof to show that the MoN loss does not lead to the ground truth probability density function, but approximately to its square root instead. We validate this finding with extensive experiments on both simulated toy as well as real world datasets. We also propose multiple solutions to compensate for the dilation to show improvement of log likelihood of the ground truth samples in the corrected probability density function.",60031514,Universität Göttingen,Gottingen,Germany,"['1712', '1707']",26.0,0.04583333333333334,0.3715277777777777,1,0.09523809523809523,0.011904761904761904,0.20833333333333334
2054,2099,2099,Adversarial learning with margin-based triplet embedding regularization,"The Deep neural networks (DNNs) have achieved great success on a variety of computer vision tasks, however, they are highly vulnerable to adversarial attacks. To address this problem, we propose to improve the local smoothness of the representation space, by integrating a margin-based triplet embedding regularization term into the classification objective, so that the obtained models learn to resist adversarial examples. The regularization term consists of two steps optimizations which find potential perturbations and punish them by a large margin in an iterative way. Experimental results on MNIST, CASIA-WebFace, VGGFace2 and MS-Celeb-1M reveal that our approach increases the robustness of the network against both feature and label adversarial attacks in simple object classification and deep face recognition.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,"['1712', '1707']",29.25,0.08311688311688313,0.39415584415584415,1,0.11678832116788321,0.051094890510948905,0.3153846153846154
2055,2100,2100,GLAMpoints: Greedily learned accurate match points,"We introduce a novel CNN-based feature point detector - Greedily Learned Accurate Match Points (GLAMpoints) - learned in a semi-supervised manner. Our detector extracts repeatable, stable interest points with a dense coverage, specifically designed to maximize the correct matching in a specific domain, which is in contrast to conventional techniques that optimize indirect metrics. In this paper, we apply our method on challenging retinal slitlamp images, for which classical detectors yield unsatisfactory results due to low image quality and insufficient amount of low-level features. We show that GLAMpoints significantly outperforms classical detectors as well as state-of-the-art CNN-based methods in matching and registration quality for retinal images.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",26.5,0.1119047619047619,0.4072751322751321,1,0.10687022900763359,0.04580152671755725,0.358974358974359
2056,2101,2101,Few-shot image recognition with knowledge transfer,"Human can well recognize images of novel categories just after browsing few examples of these categories. One possible reason is that they have some external discriminative visual information about these categories from their prior knowledge. Inspired from this, we propose a novel Knowledge Transfer Network architecture (KTN) for few-shot image recognition. The proposed KTN model jointly incorporates visual feature learning, knowledge inferring and classifier learning into one unified framework for their optimal compatibility. First, the visual classifiers for novel categories are learned based on the convolutional neural network with the cosine similarity optimization. To fully explore the prior knowledge, a semantic-visual mapping network is then developed to conduct knowledge inference, which enables to infer the classifiers for novel categories from base categories. Finally, we design an adaptive fusion scheme to infer the desired classifiers by effectively integrating the above knowledge and visual information. Extensive experiments are conducted on two widely-used Mini-ImageNet and ImageNet Few-Shot benchmarks to evaluate the effectiveness of the proposed method. The results compared with the state-of-the-art approaches show the encouraging performance of the proposed method, especially on 1-shot and 2-shot tasks.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.444444444444443,-0.00277777777777778,0.34259259259259256,1,0.12844036697247707,0.04128440366972477,0.32673267326732675
2057,2102,2102,Object-aware instance labeling for weakly supervised object detection,"Weakly supervised object detection (WSOD), where a detector is trained with only image-level annotations, is attracting more and more attention. As a method to obtain a well-performing detector, the detector and the instance labels are updated iteratively. In this study, for more efficient iterative updating, we focus on the instance labeling problem, a problem of which label should be annotated to each region based on the last localization result. Instead of simply labeling the top-scoring region and its highly overlapping regions as positive and others as negative, we propose more effective instance labeling methods as follows. First, to solve the problem that regions covering only some parts of the object tend to be labeled as positive, we find regions covering the whole object focusing on the context classification loss. Second, considering the situation where the other objects contained in the image can be labeled as negative, we impose a spatial restriction on regions labeled as negative. Using these instance labeling methods, we train the detector on the PASCAL VOC 2007 and 2012 and obtain significantly improved results compared with other state-of-the-art approaches.",60025272,University of Tokyo,Tokyo,Japan,"['1712', '1707']",26.0,0.11429752066115705,0.5017296340023614,1,0.14883720930232558,0.013953488372093023,0.33004926108374383
2058,2103,2103,Spatio-temporal filter adaptive network for video deblurring,"Video deblurring is a challenging task due to the spatially variant blur caused by camera shake, object motions, and depth variations, etc. Existing methods usually estimate optical flow in the blurry video to align consecutive frames or approximate blur kernels. However, they tend to generate artifacts or cannot effectively remove blur when the estimated optical flow is not accurate. To overcome the limitation of separate optical flow estimation, we propose a Spatio-Temporal Filter Adaptive Network (STFAN) for the alignment and deblurring in a unified framework. The proposed STFAN takes both blurry and restored images of the previous frame as well as blurry image of the current frame as input, and dynamically generates the spatially adaptive filters for the alignment and deblurring. We then propose the new Filter Adaptive Convolutional (FAC) layer to align the deblurred features of the previous frame with the current frame and remove the spatially variant blur from the features of the current frame. Finally, we develop a reconstruction network which takes the fusion of two transformed features to restore the clear frames. Both quantitative and qualitative evaluation results on the benchmark datasets and real-world videos demonstrate that the proposed algorithm performs favorably against state-of-the-art methods in terms of accuracy, speed as well as model size.",60019616,Harbin Institute of Technology,Harbin,China,"['1712', '1707']",26.125,0.002002164502164498,0.5021103896103897,1,0.12083333333333333,0.041666666666666664,0.3173913043478261
2059,2104,2104,DF2Net: A dense-fine-finer network for detailed 3D face reconstruction,"Reconstructing the detailed geometric structure from a single face image is a challenging problem due to its ill-posed nature and the fine 3D structures to be recovered. This paper proposes a deep Dense-Fine-Finer Network (DF2Net) to address this challenging problem. DF2Net decomposes the reconstruction process into three stages, each of which is processed by an elaborately-designed network, namely D-Net, F-Net, and Fr-Net. D-Net exploits a U-net architecture to map the input image to a dense depth image. F-Net refines the output of D-Net by integrating features from depth and RGB domains, whose output is further enhanced by Fr-Net with a novel multi-resolution hypercolumn architecture. In addition, we introduce three types of data to train these networks, including 3D model synthetic data, 2D image reconstructed data, and fine facial images. We elaborately exploit different datasets (or combination) together with well-designed losses to train different networks. Qualitative evaluation indicates that our DF2Net can effectively reconstruct subtle facial details such as small crow's feet and wrinkles. Our DF2Net achieves performance superior or comparable to state-of-the-art algorithms in qualitative and quantitative analyses on real-world images and the BU-3DFE dataset. Code and the collected 70K image-depth data will be publicly available.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",19.6,0.1826785714285714,0.5469642857142858,1,0.11196911196911197,0.05791505791505792,0.39545454545454545
2060,2105,2105,Towards latent attribute discovery from triplet similarities,"This paper addresses the task of learning latent attributes from triplet similarity comparisons. Consider, for instance, the three shoes in Fig. 1(a). They can be compared according to color, comfort, size, or shape resulting in different rankings. Most approaches for embedding learning either make a simplifying assumption - that all inputs are comparable under a single criterion, or require expensive attribute supervision. We introduce Latent Similarity Networks (LSNs): A simple and effective technique to discover the underlying latent notions of similarity in data without any explicit attribute supervision. LSNs can be trained with standard triplet supervision and learn several latent embeddings that can be used to compare images under multiple notions of similarity. LSNs achieve state-of-the-art performance on UT-Zappos-50k Shoes and Celeb-A Faces datasets and also demonstrate the ability to uncover meaningful latent attributes.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",16.75,0.10285714285714284,0.3671428571428572,1,0.14814814814814814,0.06172839506172839,0.35064935064935066
2061,2106,2106,Indian tax structure – An analytical perspective," Taxation is an instrumental tool to procure resources for the government to enable it to formulate policy schemes for the overall development of the economy. Income tax plays an important role as a source of revenue and an effective measure of removal of economic disparity. Different objectives of taxation, each one of them desirable by itself, can pull in different directions. The state should formulate a comprehensive and cohesive tax system which can balance the different objectives in view of its own requirements and goals. The present paper is an attempt to study the present tax structure in India and the recent reforms undertaken.",124081894,Arumugam Pillai Seethai Ammal College Tiruppattur,Sivaganga,India,['1706'],21.0,0.1636363636363636,0.4590909090909092,0,0.10714285714285714,0.017857142857142856,0.18018018018018017
2062,2107,2107,Motion guided attention for video salient object detection,"Video salient object detection aims at discovering the most visually distinctive objects in a video. How to effectively take object motion into consideration during video salient object detection is a critical issue. Existing state-of-the-art methods either do not explicitly model and harvest motion cues or ignore spatial contexts within optical flow images. In this paper, we develop a multi-task motion guided video salient object detection network, which learns to accomplish two sub-tasks using two sub-networks, one sub-network for salient object detection in still images and the other for motion saliency detection in optical flow images. We further introduce a series of novel motion guided attention modules, which utilize the motion saliency sub-network to attend and enhance the sub-network for still images. These two sub-networks learn to adapt to each other by end-to-end training. Experimental results demonstrate that the proposed method significantly outperforms existing state-of-the-art algorithms on a wide range of benchmarks. We hope our simple and effective approach will serve as a solid baseline and help ease future research in video salient object detection. Code and models will be made available.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",20.11111111111111,0.14833333333333334,0.4538095238095238,1,0.125,0.004464285714285714,0.29381443298969073
2063,2108,2108,Adaptive activation thresholding: Dynamic routing type behavior for interpretability in convolutional neural networks,"There is a growing interest in strategies that can help us understand or interpret neural networks - that is, not merely provide a prediction, but also offer additional context explaining why and how. While many current methods offer tools to perform this analysis for a given (trained) network post-hoc, recent results (especially on capsule networks) suggest that when classes map to a few high level ''concepts'' in the preceding layers of the network, the behavior of the network is easier to interpret or explain. Such training may be accomplished via dynamic/EM routing where the network ''routes'' for individual classes (or subsets of images) are dynamic and involve few nodes even if the full network may not be sparse. In this paper, we show how a simple modification of the SGD scheme can help provide dynamic/EM routing type behavior in convolutional neural networks. Through extensive experiments, we evaluate the effect of this idea for interpretability where we obtain promising results, while also showing that no compromise in attainable accuracy is involved. Further, we show that the minor modification is seemingly ad-hoc, the new algorithm can be analyzed by an approximate method which provably matches known rates for SGD.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",32.83333333333333,0.047318181818181815,0.4225844155844156,1,0.1452991452991453,0.01282051282051282,0.25225225225225223
2064,2109,2109,XR-EgoPose: Egocentric 3D human pose from an HMD camera,"We present a new solution to egocentric 3D body pose estimation from monocular images captured from a downward looking fish-eye camera installed on the rim of a head mounted virtual reality device. This unusual viewpoint, just 2 cm.∼away from the user's face, leads to images with unique visual appearance, characterized by severe self-occlusions and strong perspective distortions that result in a drastic difference in resolution between lower and upper body. Our contribution is two-fold. Firstly, we propose a new encoder-decoder architecture with a novel dual branch decoder designed specifically to account for the varying uncertainty in the 2D joint locations. Our quantitative evaluation, both on synthetic and real-world datasets, shows that our strategy leads to substantial improvements in accuracy over state of the art egocentric pose estimation approaches. Our second contribution is a new large-scale photorealistic synthetic dataset - xR-EgoPose - offering 383K frames of high quality renderings of people with a diversity of skin tones, body shapes, clothing, in a variety of backgrounds and lighting conditions, performing a range of actions. Our experiments show that the high variability in our new synthetic training corpus leads to good generalization to real world footage and to state of the art results on real world datasets with ground truth. Moreover, an evaluation on the Human3.6M benchmark shows that the performance of our method is on par with top performing approaches on the more classic problem of 3D human pose from a third person viewpoint.",60022148,UCL,London,United Kingdom,"['1712', '1707']",30.25,0.1995661157024793,0.3832506887052341,1,0.07913669064748201,0.017985611510791366,0.29389312977099236
2065,2110,2110,Pushing the frontiers of unconstrained crowd counting: New dataset and benchmark method,"In this work, we propose a novel crowd counting network that progressively generates crowd density maps via residual error estimation. The proposed method uses VGG16 as the backbone network and employs density map generated by the final layer as a coarse prediction to refine and generate finer density maps in a progressive fashion using residual learning. Additionally, the residual learning is guided by an uncertainty-based confidence weighting mechanism that permits the flow of only high-confidence residuals in the refinement path. The proposed Confidence Guided Deep Residual Counting Network (CG-DRCN) is evaluated on recent complex datasets, and it achieves significant improvements in errors. Furthermore, we introduce a new large scale unconstrained crowd counting dataset (JHU-CROWD) that is ∼2.8 larger than the most recent crowd counting datasets in terms of the number of images. It contains 4,250 images with 1.11 million annotations. In comparison to existing datasets, the proposed dataset is collected under a variety of diverse scenarios and environmental conditions. Specifically, the dataset includes several images with weather-based degradations and illumination variations in addition to many distractor images, making it a very challenging dataset. Additionally, the dataset consists of rich annotations at both image-level and head-level. Several recent methods are evaluated and compared on this dataset.",60005248,Johns Hopkins University,Baltimore,United States,"['1712', '1707']",20.5,0.13614718614718616,0.5032287157287157,1,0.11618257261410789,0.04564315352697095,0.41409691629955947
2066,2111,2111,Fully convolutional geometric features,"Extracting geometric features from 3D scans or point clouds is the first step in applications such as registration, reconstruction, and tracking. State-of-the-art methods require computing low-level features as input or extracting patch-based features with limited receptive field. In this work, we present fully-convolutional geometric features, computed in a single pass by a 3D fully-convolutional network. We also present new metric learning losses that dramatically improve performance. Fully-convolutional geometric features are compact, capture broad spatial context, and scale to large scenes. We experimentally validate our approach on both indoor and outdoor datasets. Fully-convolutional geometric features achieve state-of-the-art accuracy without requiring prepossessing, are compact (32 dimensions), and are 290 times faster than the most accurate prior method.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",16.42857142857143,0.11694555444555445,0.301494338994339,1,0.08974358974358974,0.0,0.3939393939393939
2067,2112,2112,Learning to collocate neural modules for image captioning,"We do not speak word by word from scratch; our brain quickly structures a pattern like textsc{sth do sth at someplace} and then fill in the detailed description. To render existing encoder-decoder image captioners such human-like reasoning, we propose a novel framework: Learning to Collocate Neural Modules (CNM), to generate the ''inner pattern'' connecting visual encoder and language decoder. Unlike the widely-used neural module networks in visual Q&A, where the language (ie, question) is fully observable, CNM for captioning is more challenging as the language is being generated and thus is partially observable. To this end, we make the following technical contributions for CNM training: 1) compact module design - - one for function words and three for visual content words (eg, noun, adjective, and verb), 2) soft module fusion and multi-step module execution, robustifying the visual reasoning in partial observation, 3) a linguistic loss for module controller being faithful to part-of-speech collocations (eg, adjective is before noun). Extensive experiments on the challenging MS-COCO image captioning benchmark validate the effectiveness of our CNM image captioner. In particular, CNM achieves a new state-of-the-art 127.9 CIDEr-D on Karpathy split and a single-model 126.0 c40 on the official server. CNM is also robust to few training samples, eg, by training only one sentence per image, CNM can halve the performance loss compared to a strong baseline.",60078616,School of Computer Science and Engineering,Singapore City,Singapore,"['1712', '1707']",31.857142857142854,0.1204216073781291,0.3748353096179182,1,0.07586206896551724,0.07241379310344828,0.40298507462686567
2068,2113,2113,Total denoising: Unsupervised learning of 3D point cloud cleaning,"We show that denoising of 3D point clouds can be learned unsupervised, directly from noisy 3D point cloud data only. This is achieved by extending recent ideas from learning of unsupervised image denoisers to unstructured 3D point clouds. Unsupervised image denoisers operate under the assumption that a noisy pixel observation is a random realization of a distribution around a clean pixel value, which allows appropriate learning on this distribution to eventually converge to the correct value. Regrettably, this assumption is not valid for unstructured points: 3D point clouds are subject to total noise, i.e. deviations in all coordinates, with no reliable pixel grid. Thus, an observation can be the realization of an entire manifold of clean 3D points, which makes the quality of a naïve extension of unsupervised image denoisers to 3D point clouds unfortunately only little better than mean filtering. To overcome this, and to enable effective and unsupervised 3D point cloud denoising, we introduce a spatial prior term, that steers converges to the unique closest out of the many possible modes on the manifold. Our results demonstrate unsupervised denoising performance similar to that of supervised learning with clean data when given enough training examples - whereby we do not need any pairs of noisy and clean training data.",60022148,UCL,London,United Kingdom,"['1712', '1707']",26.25,0.125,0.6106884057971014,1,0.13596491228070176,0.021929824561403508,0.2925764192139738
2069,2114,2114,M3D-RPN: Monocular 3D region proposal network for object detection,"Understanding the world in 3D is a critical component of urban autonomous driving. Generally, the combination of expensive LiDAR sensors and stereo RGB imaging has been paramount for successful 3D object detection algorithms, whereas monocular image-only methods experience drastically reduced performance. We propose to reduce the gap by reformulating the monocular 3D detection problem as a standalone 3D region proposal network. We leverage the geometric relationship of 2D and 3D perspectives, allowing 3D boxes to utilize well-known and powerful convolutional features generated in the image-space. To help address the strenuous 3D parameter estimations, we further design depth-aware convolutional layers which enable location specific feature development and in consequence improved 3D scene understanding. Compared to prior work in monocular 3D detection, our method consists of only the proposed 3D region proposal network rather than relying on external networks, data, or multiple stages. M3D-RPN is able to significantly improve the performance of both monocular 3D Object Detection and Bird's Eye View tasks within the KITTI urban autonomous driving dataset, while efficiently using a shared multi-class model.",60031707,Michigan State University,East Lansing,United States,"['1712', '1707']",24.857142857142854,0.1338235294117647,0.5044117647058823,1,0.12376237623762376,0.06435643564356436,0.37894736842105264
2070,2115,2115,PointAE: Point auto-encoder for 3D statistical shape and texture modelling,"The outcome of standard statistical shape modelling is a vector space representation of objects. Any convex combination of vectors of a set of object class examples generates a real and valid example. In this paper, we propose a Point Auto-Encoder (PointAE) with skip-connection, attention blocks for 3D statistical shape modelling directly on 3D points. The proposed PointAE is able to refine the correspondence with a correspondence refinement block. The data with refined correspondence can be fed to the PointAE again and bootstrap the constructed statistical models. Instead of two seperate models, PointAE can simultaneously model the shape and texture variation. The extensive evaluation in three open-sourced datasets demonstrates that the proposed method achieves better performance in representation ability of the shape variations.",123669615,Inception Institute of Artificial Intelligence,Abu Dhabi,United Arab Emirates,"['1712', '1707']",17.428571428571427,0.21428571428571427,0.39404761904761904,1,0.10714285714285714,0.05,0.3208955223880597
2071,2116,2116,QUARCH: A new quasi-affine reconstruction stratum from vague relative camera orientation knowledge,"We present a new quasi-affine reconstruction of a scene and its application to camera self-calibration. We refer to this reconstruction as QUARCH (QUasi-Affine Reconstruction with respect to Camera centers and the Hodographs of horopters). A QUARCH can be obtained by solving a semidefinite programming problem when, (i) the images have been captured by a moving camera with constant intrinsic parameters, and (ii) a vague knowledge of the relative orientation (under or over 120 degrees) between camera pairs is available. The resulting reconstruction comes close enough to an affine one allowing thus an easy upgrade of the QUARCH to its affine and metric counterparts. We also present a constrained Levenberg-Marquardt method for nonlinear optimization subject to Linear Matrix Inequality (LMI) constraints so as to ensure that the QUARCH LMIs are satisfied during optimization. Experiments with synthetic and real data show the benefits of QUARCH in reliably obtaining a metric reconstruction.",60103368,Université de Strasbourg,Strasbourg,France,"['1712', '1707']",24.83333333333333,0.0835858585858586,0.3878787878787879,1,0.08571428571428572,0.07428571428571429,0.33532934131736525
2072,2117,2117,Conditional coupled generative adversarial networks for zero-shot domain adaptation,"Machine learning models trained in one domain perform poorly in the other domains due to the existence of domain shift. Domain adaptation techniques solve this problem by training transferable models from the label-rich source domain to the label-scarce target domain. Unfortunately, a majority of the existing domain adaptation techniques rely on the availability of the target-domain data, and thus limit their applications to a small community across few computer vision problems. In this paper, we tackle the challenging zero-shot domain adaptation (ZSDA) problem, where the target-domain data is non-available in the training stage. For this purpose, we propose conditional coupled generative adversarial networks (CoCoGAN) by extending the coupled generative adversarial networks (CoGAN) into a conditioning model. Compared with the existing state of the arts, our proposed CoCoGAN is able to capture the joint distribution of dual-domain samples in two different tasks, i.e. the relevant task (RT) and an irrelevant task (IRT). We train the CoCoGAN with both source-domain samples in RT and the dual-domain samples in IRT to complete the domain adaptation. While the former provide the high-level concepts of the non-available target-domain data, the latter carry the sharing correlation between the two domains in RT and IRT. To train the CoCoGAN in the absence of the target-domain data for RT, we propose a new supervisory signal, i.e. the alignment between representations across tasks. Extensive experiments carried out demonstrate that our proposed CoCoGAN outperforms existing state of the arts in image classifications.",60000937,Shenzhen University,Shenzhen,China,"['1712', '1707']",20.166666666666668,-0.028008021390374317,0.4801693404634581,1,0.08389261744966443,0.0436241610738255,0.3722627737226277
2073,2118,2118,Surface networks via general covers,"Developing deep learning techniques for geometric data is an active and fruitful research area. This paper tackles the problem of sphere-type surface learning by developing a novel surface-to-image representation. Using this representation we are able to quickly adapt successful CNN models to the surface setting. The surface-image representation is based on a covering map from the image domain to the surface. Namely, the map wraps around the surface several times, making sure that every part of the surface is well represented in the image. Differently from previous surface-to-image representations, we provide a low distortion coverage of all surface parts in a single image. Specifically, for the use case of learning spherical signals, our representation provides a low distortion alternative to several popular spherical parameterizations used in deep learning. We have used the surface-to-image representation to apply standard CNN architectures to 3D models including spherical signals. We show that our method achieves state of the art or comparable results on the tasks of shape retrieval, shape classification and semantic shape segmentation.",60017563,Weizmann Institute of Science Israel,Rehovot,Israel,"['1712', '1707']",18.88888888888889,0.1444940476190476,0.4278025793650794,1,0.1044776119402985,0.009950248756218905,0.2648648648648649
2074,2119,2119,Early prediction of student success based on data mining and artificial neural network,"This paper presents an overview of the research related to the prediction of the success of the participants in the Technical Drawing course. In order to determine the student’s success, a data mining model was created supported by artificial intelligence. The proposed model gives an overview of the input data on the basis of which it is possible to determine the success of the student’s using artificial neural networks. The results of the prediction give a presentation of the performance of students at the beginning of the course, which gives professors enough time to influence the students and encourage them.",60068809,University of Kragujevac,Kragujevac,Serbia,['1700'],25.0,-0.03333333333333333,0.4444444444444444,1,0.12962962962962962,0.018518518518518517,0.22727272727272727
2075,2120,2120,Language-agnostic visual-semantic embeddings,"This paper proposes a framework for training language-invariant cross-modal retrieval models. We also introduce a novel character-based word-embedding approach, allowing the model to project similar words across languages into the same word-embedding space. In addition, by performing cross-modal retrieval at the character level, the storage requirements for a text encoder decrease substantially, allowing for lighter and more scalable retrieval architectures. The proposed language-invariant textual encoder based on characters is virtually unaffected in terms of storage requirements when novel languages are added to the system. Our contributions include new methods for building character-level-based word-embeddings, an improved loss function, and a novel cross-language alignment module that not only makes the architecture language-invariant, but also presents better predictive performance. We show that our models outperform the current state-of-the-art in both single and multi-language scenarios. This work can be seen as the basis of a new path on retrieval research, now allowing for the effective use of captions in multiple-language scenarios. Code is available at url{https://github.com/jwehrmann/lavse}.",60015760,Pontificia Universidade Catolica do Rio Grande do Sul,Porto Alegre,Brazil,"['1712', '1707']",20.25,0.17927489177489178,0.445698051948052,1,0.10138248847926268,0.009216589861751152,0.3770491803278688
2076,2121,2121,Self-supervised moving vehicle tracking with stereo sound,"Humans are able to localize objects in the environment using both visual and auditory cues, integrating information from multiple modalities into a common reference frame. We introduce a system that can leverage unlabeled audiovisual data to learn to localize objects (moving vehicles) in a visual reference frame, purely using stereo sound at inference time. Since it is labor-intensive to manually annotate the correspondences between audio and object bounding boxes, we achieve this goal by using the co-occurrence of visual and audio streams in unlabeled videos as a form of self-supervision, without resorting to the collection of ground truth annotations. In particular, we propose a framework that consists of a vision ''teacher'' network and a stereo-sound ''student'' network. During training, knowledge embodied in a well-established visual vehicle detection model is transferred to the audio domain using unlabeled videos as a bridge. At test time, the stereo-sound student network can work independently to perform object localization using just stereo audio and camera meta-data, without any visual input. Experimental results on a newly collected Auditory Vehicles Tracking dataset verify that our proposed approach outperforms several baseline approaches. We also demonstrate that our cross-modal auditory localization approach can assist in the visual localization of moving vehicles under poor lighting conditions.",60141075,MIT-IBM Watson AI Lab,Cambridge,United States,"['1712', '1707']",25.75,0.04807741278329514,0.23163992869875225,1,0.12903225806451613,0.008064516129032258,0.30701754385964913
2077,2122,2122,Moving indoor: Unsupervised video depth learning in challenging environments,"Recently unsupervised learning of depth from videos has made remarkable progress and the results are comparable to fully supervised methods in outdoor scenes like KITTI. However, there still exist great challenges when directly applying this technology in indoor environments, e.g., large areas of non-texture regions like white wall, more complex ego-motion of handheld camera, transparent glasses and shiny objects. To overcome these problems, we propose a new optical-flow based training paradigm which reduces the difficulty of unsupervised learning by providing a clearer training target and handles the non-texture regions. Our experimental evaluation demonstrates that the result of our method is comparable to fully supervised methods on the NYU Depth V2 benchmark. To the best of our knowledge, this is the first quantitative result of purely unsupervised learning method reported on indoor datasets.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",26.4,0.28961038961038965,0.4204961704961704,1,0.09868421052631579,0.039473684210526314,0.3402777777777778
2078,2123,2123,A dataset of multi-illumination images in the wild,"Collections of images under a single, uncontrolled illumination have enabled the rapid advancement of core computer vision tasks like classification, detection, and segmentation. But even with modern learning techniques, many inverse problems involving lighting and material understanding remain too severely ill-posed to be solved with single-illumination datasets. The data simply does not contain the necessary supervisory signals. Multi-illumination datasets are notoriously hard to capture, so the data is typically collected at small scale, in controlled environments, either using multiple light sources, or robotic gantries. This leads to image collections that are not representative of the variety and complexity of real world scenes. We introduce a new multi-illumination dataset of more than 1000 real scenes, each captured in high dynamic range and high resolution, under 25 lighting conditions. We demonstrate the richness of this dataset by training state-of-the-art models for three challenging applications: Single-image illumination estimation, image relighting, and mixed-illuminant white balance.",60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,"['1712', '1707']",21.571428571428577,0.10383008658008656,0.425715367965368,1,0.07936507936507936,0.0,0.3567251461988304
2079,2124,2124,Through-wall human mesh recovery using radio signals,"This paper presents RF-Avatar, a neural network model that can estimate 3D meshes of the human body in the presence of occlusions, baggy clothes, and bad lighting conditions. We leverage that radio frequency (RF) signals in the WiFi range traverse clothes and occlusions and bounce off the human body. Our model parses such radio signals and recovers 3D body meshes. Our meshes are dynamic and smoothly track the movements of the corresponding people. Further, our model works both in single and multi-person scenarios. Inferring body meshes from radio signals is a highly under-constrained problem. Our model deals with this challenge using: 1) a combination of strong and weak supervision, 2) a multi-headed self-attention mechanism that attends differently to temporal information in the radio signal, and 3) an adversarially trained temporal discriminator that imposes a prior on the dynamics of human motion. Our results show that RF-Avatar accurately recovers dynamic 3D meshes in the presence of occlusions, baggy clothes, bad lighting conditions, and even through walls.",60006320,MIT Computer Science &amp; Artificial Intelligence Laboratory,Cambridge,United States,"['1712', '1707']",20.625,-0.026652661064425744,0.4007422969187675,1,0.1,0.04,0.3776595744680851
2080,2126,2126,Character-level attention convolutional neural networks for short-text classification,This paper proposes a character-level attention convolutional neural networks model (ACNN) for short-text classification task. The model is implemented on the deep learning framework which named tensorflow. The model can achieve better short-text classification result. Experimental datasets are from three different categories and scales. ACNN model are compared with traditional model such as LSTM and CNN. The experimental results show that ACNN model significantly improves the short-text classification results.,60007711,Jilin University,Changchun,China,['1700'],11.5,0.134375,0.553125,1,0.09411764705882353,0.047058823529411764,0.38961038961038963
2081,2127,2127,FrameNet: Learning local canonical frames of 3D surfaces from a single RGB image,"In this work, we introduce the novel problem of identifying dense canonical 3D coordinate frames from a single RGB image. We observe that each pixel in an image corresponds to a surface in the underlying 3D geometry, where a canonical frame can be identified as represented by three orthogonal axes, one along its normal direction and two in its tangent plane. We propose an algorithm to predict these axes from RGB. Our first insight is that canonical frames computed automatically with recently introduced direction field synthesis methods can provide training data for the task. Our second insight is that networks designed for surface normal prediction provide better results when trained jointly to predict canonical frames, and even better when trained to also predict 2D projections of canonical frames. We conjecture this is because projections of canonical tangent directions often align with local gradients in images, and because those directions are tightly linked to 3Dcanonical frames through projective geometry and orthogonality constraints. In our experiments, we find that our method predicts 3D canonical frames that can be used in applications ranging from surface normal estimation, feature matching, and augmented reality.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",27.0,0.1318181818181818,0.36666666666666653,1,0.14705882352941177,0.00980392156862745,0.27450980392156865
2082,2128,2128,Selectivity or invariance: Boundary-aware salient object detection,"Typically, a salient object detection (SOD) model faces opposite requirements in processing object interiors and boundaries. The features of interiors should be invariant to strong appearance change so as to pop-out the salient object as a whole, while the features of boundaries should be selective to slight appearance change to distinguish salient objects and background. To address this selectivity-invariance dilemma, we propose a novel boundary-aware network with successive dilation for image-based SOD. In this network, the feature selectivity at boundaries is enhanced by incorporating a boundary localization stream, while the feature invariance at interiors is guaranteed with a complex interior perception stream. Moreover, a transition compensation stream is adopted to amend the probable failures in transitional regions between interiors and boundaries. In particular, an integrated successive dilation module is proposed to enhance the feature invariance at interiors and transitional regions. Extensive experiments on six datasets show that the proposed approach outperforms 16 state-of-the-art methods.",60014966,Peking University,Beijing,China,"['1712', '1707']",22.0,0.020833333333333325,0.3583333333333334,1,0.10869565217391304,0.010869565217391304,0.3352941176470588
2083,2129,2129,Few-shot generalization for single-image 3D reconstruction via priors,"Recent work on single-view 3D reconstruction shows impressive results, but has been restricted to a few fixed categories where extensive training data is available. The problem of generalizing these models to new classes with limited training data is largely open. To address this problem, we present a new model architecture that reframes single-view 3D reconstruction as learnt, category agnostic refinement of a provided, category-specific prior. The provided prior shape for a novel class can be obtained from as few as one 3D shape from this class. Our model can start reconstructing objects from the novel class using this prior without seeing any training image for this class and without any retraining. Our model outperforms category-agnostic baselines and remains competitive with more sophisticated baselines that finetune on the novel categories. Additionally, our network is capable of improving the reconstruction given multiple views despite not being trained on task of multi-view reconstruction.",60007776,Cornell University,Ithaca,United States,"['1712', '1707']",21.428571428571427,0.13164730006835276,0.3071200729095466,1,0.12790697674418605,0.005813953488372093,0.2654320987654321
2084,2130,2130,Free-form image inpainting with gated convolution,"We present a generative image inpainting system to complete images with free-form mask and guidance. The system is based on gated convolutions learned from millions of images without additional labelling efforts. The proposed gated convolution solves the issue of vanilla convolution that treats all input pixels as valid ones, generalizes partial convolution by providing a learnable dynamic feature selection mechanism for each channel at each spatial location across all layers. Moreover, as free-form masks may appear anywhere in images with any shape, global and local GANs designed for a single rectangular mask are not applicable. Thus, we also present a patch-based GAN loss, named SN-PatchGAN, by applying spectral-normalized discriminator on dense image patches. SN-PatchGAN is simple in formulation, fast and stable in training. Results on automatic image inpainting and user-guided extension demonstrate that our system generates higher-quality and more flexible results than previous methods. Our system helps user quickly remove distracting objects, modify image layouts, clear watermarks and edit faces. Code, demo and models are available at: Url{https://github.com/JiahuiYu/generative-inpainting}.",60000745,University of Illinois at Urbana-Champaign,Urbana,United States,"['1712', '1707']",18.666666666666668,0.08634920634920636,0.2658730158730159,1,0.11848341232227488,0.023696682464454975,0.37305699481865284
2085,2131,2131,Learning similarity conditions without explicit supervision,"Many real-world tasks require models to compare images along multiple similarity conditions (e.g. similarity in color, category or shape). Existing methods often reason about these complex similarity relationships by learning condition-aware embeddings. While such embeddings aid models in learning different notions of similarity, they also limit their capability to generalize to unseen categories since they require explicit labels at test time. To address this deficiency, we propose an approach that jointly learns representations for the different similarity conditions and their contributions as a latent variable without explicit supervision. Comprehensive experiments across three datasets, Polyvore-Outfits, Maryland-Polyvore and UT-Zappos50k, demonstrate the effectiveness of our approach: Our model outperforms the state-of-the-art methods, even those that are strongly supervised with pre-defined similarity conditions, on fill-in-the-blank, outfit compatibility prediction and triplet prediction tasks. Finally, we show that our model learns different visually-relevant semantic sub-spaces that allow it to generalize well to unseen categories.",60019674,Boston University,Boston,United States,"['1712', '1707']",21.142857142857142,0.07037037037037036,0.5481481481481482,1,0.10256410256410256,0.03076923076923077,0.375
2086,2132,2132,Learning the model update for siamese trackers,"Siamese approaches address the visual tracking problem by extracting an appearance template from the current frame, which is used to localize the target in the next frame. In general, this template is linearly combined with the accumulated template from the previous frame, resulting in an exponential decay of information over time. While such an approach to updating has led to improved results, its simplicity limits the potential gain likely to be obtained by learning to update. Therefore, we propose to replace the handcrafted update function with a method which learns to update. We use a convolutional neural network, called UpdateNet, which given the initial template, the accumulated template and the template of the current frame aims to estimate the optimal template for the next frame. The UpdateNet is compact and can easily be integrated into existing Siamese trackers. We demonstrate the generality of the proposed approach by applying it to two Siamese trackers, SiamFC and DaSiamRPN. Extensive experiments on VOT2016, VOT2018, LaSOT, and TrackingNet datasets demonstrate that our UpdateNet effectively predicts the new target template, outperforming the standard linear update. On the large-scale TrackingNet dataset, our UpdateNet improves the results of DaSiamRPN with an absolute gain of 3.9% in terms of success score.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",22.555555555555557,0.08627946127946129,0.4048821548821549,1,0.14847161572052403,0.05240174672489083,0.32599118942731276
2087,2133,2133,Universal adversarial perturbation via prior driven uncertainty approximation,"Deep learning models have shown their vulnerabilities to universal adversarial perturbations (UAP), which are quasi-imperceptible. Compared to the conventional supervised UAPs that suffer from the knowledge of training data, the data-independent unsupervised UAPs are more applicable. Existing unsupervised methods fail to take advantage of the model uncertainty to produce robust perturbations. In this paper, we propose a new unsupervised universal adversarial perturbation method, termed as Prior Driven Uncertainty Approximation (PD-UA), to generate a robust UAP by fully exploiting the model uncertainty at each network layer. Specifically, a Monte Carlo sampling method is deployed to activate more neurons to increase the model uncertainty for a better adversarial perturbation. Thereafter, a textural bias prior to revealing a statistical uncertainty is proposed, which helps to improve the attacking performance. The UAP is crafted by the stochastic gradient descent algorithm with a boosted momentum optimizer, and a Laplacian pyramid frequency model is finally used to maintain the statistical uncertainty. Extensive experiments demonstrate that our method achieves well attacking performances on the ImageNet validation set, and significantly improves the fooling rate compared with the state-of-the-art methods.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",22.625,0.09775046382189237,0.3728586889301175,1,0.14418604651162792,0.07441860465116279,0.3448275862068966
2088,2134,2134,Hiding video in audio via reversible generative models,"We present a method for hiding video content inside audio files while preserving the perceptual fidelity of the cover audio. This is a form of cross-modal steganography and is particularly challenging due to the high bitrate of video. Our scheme uses recent advances in flow-based generative models, which enable mapping audio to latent codes such that nearby codes correspond to perceptually similar signals. We show that compressed video data can be concealed in the latent codes of audio sequences while preserving the fidelity of both the hidden video and the cover audio. We can embed 128x128 video inside same-duration audio, or higher-resolution video inside longer audio sequences. Quantitative experiments show that our approach outperforms relevant baselines in steganographic capacity and fidelity.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",20.166666666666668,0.08537037037037037,0.4775925925925926,1,0.12408759124087591,0.0,0.3023255813953488
2089,2135,2135,Matching user accounts across social networks based on LDA model,Identifying users across social networks has received more and more attention in recent years. In this paper we propose a model that combines ATM and DTM. The model uses the ATM model to study the user’s potential behavior information and extract user’s topic preferences. Then it analyzes the trend of user topic preferences changing with time through the DTM. The purpose of this paper is to improve the accuracy of account identification across social networks. The experimental results show that the model performs well on Chinese text or mixed text in Chinese and English because it obtains higher accuracy and F1 scores.,60002210,Shandong Normal University,Jinan,China,['1700'],17.0,0.11805555555555555,0.29444444444444445,1,0.10909090909090909,0.05454545454545454,0.2767857142857143
2090,2136,2136,A camera that CNNs: Towards embedded neural networks on pixel processor arrays,"We present a convolutional neural network implementation for pixel processor array (PPA) sensors. PPA hardware consists of a fine-grained array of general-purpose processing elements, each capable of light capture, data storage, program execution, and communication with neighboring elements. This allows images to be stored and manipulated directly at the point of light capture, rather than having to transfer images to external processing hardware. Our CNN approach divides this array up into 4x4 blocks of processing elements, essentially trading-off image resolution for increased local memory capacity per 4x4 'pixel'. We implement parallel operations for image addition, subtraction and bit-shifting images in this 4x4 block format. Using these components we formulate how to perform ternary weight convolutions upon these images, compactly store results of such convolutions, perform max-pooling, and transfer the resulting sub-sampled data to an attached micro-controller. We train ternary weight filter CNNs for digit recognition and a simple tracking task, and demonstrate inference of these networks upon the SCAMP5 PPA system. This work represents a first step towards embedding neural network processing capability directly onto the focal plane of a sensor.",60020650,University of Bristol,Bristol,United Kingdom,"['1712', '1707']",22.625,0.11153846153846156,0.3223443223443224,1,0.11467889908256881,0.027522935779816515,0.37438423645320196
2091,2137,2137,CARAFE: Content-aware reassembly of features,"Feature upsampling is a key operation in a number of modern convolutional network architectures, e.g. feature pyramids. Its design is critical for dense prediction tasks such as object detection and semantic/instance segmentation. In this work, we propose Content-Aware ReAssembly of FEatures (CARAFE), a universal, lightweight and highly effective operator to fulfill this goal. CARAFE has several appealing properties: (1) Large field of view. Unlike previous works (e.g. bilinear interpolation) that only exploit subpixel neighborhood, CARAFE can aggregate contextual information within a large receptive field. (2) Content-aware handling. Instead of using a fixed kernel for all samples (e.g. deconvolution), CARAFE enables instance-specific content-aware handling, which generates adaptive kernels on-the-fly. (3) Lightweight and fast to compute. CARAFE introduces little computational overhead and can be readily integrated into modern network architectures. We conduct comprehensive evaluations on standard benchmarks in object detection, instance/semantic segmentation and inpainting. CARAFE shows consistent and substantial gains across all the tasks (1.2% AP, 1.3% AP, 1.8% mIoU, 1.1dB respectively) with negligible computational overhead. It has great potential to serve as a strong building block for future research. Code and models are available at https://github.com/open-mmlab/mmdetection.",60005510,Nanyang Technological University,Singapore City,Singapore,"['1712', '1707']",11.5625,0.1233745421245421,0.4762362637362638,1,0.06995884773662552,0.06172839506172839,0.4698275862068966
2092,2138,2138,DenseRaC: Joint 3D pose and shape estimation by dense render-and-compare,"We present DenseRaC, a novel end-to-end framework for jointly estimating 3D human pose and body shape from a monocular RGB image. Our two-step framework takes the body pixel-to-surface correspondence map (i.e., IUV map) as proxy representation and then performs estimation of parameterized human pose and shape. Specifically, given an estimated IUV map, we develop a deep neural network optimizing 3D body reconstruction losses and further integrating a render-and-compare scheme to minimize differences between the input and the rendered output, i.e., dense body landmarks, body part masks, and adversarial priors. To boost learning, we further construct a large-scale synthetic dataset (MOCA) utilizing web-crawled Mocap sequences, 3D scans and animations. The generated data covers diversified camera views, human actions and body shapes, and is paired with full ground truth. Our model jointly learns to represent the 3D human body from hybrid datasets, mitigating the problem of unpaired training data. Our experiments show that DenseRaC obtains superior performance against state of the art on public benchmarks of various human-related tasks.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",23.857142857142854,0.08749999999999998,0.3180555555555556,1,0.12796208530805686,0.03317535545023697,0.42408376963350786
2093,2139,2139,See-through-text grouping for referring image segmentation,"Motivated by the conventional grouping techniques to image segmentation, we develop their DNN counterpart to tackle the referring variant. The proposed method is driven by a convolutional-recurrent neural network (ConvRNN) that iteratively carries out top-down processing of bottom-up segmentation cues. Given a natural language referring expression, our method learns to predict its relevance to each pixel and derives a See-through-Text Embedding Pixelwise (STEP) heatmap, which reveals segmentation cues of pixel level via the learned visual-textual co-embedding. The ConvRNN performs a top-down approximation by converting the STEP heatmap into a refined one, whereas the improvement is expected from training the network with a classification loss from the ground truth. With the refined heatmap, we update the textual representation of the referring expression by re-evaluating its attention distribution and then compute a new STEP heatmap as the next input to the ConvRNN. Boosting by such collaborative learning, the framework can progressively and simultaneously yield the desired referring segmentation and reasonable attention distribution over the referring sentence. Our method is general and does not rely on, say, the outcomes of object detection from other DNN models, while achieving state-of-the-art performance in all of the four datasets in the experiments.",60018029,National Tsing Hua University,Hsinchu,Taiwan,"['1712', '1707']",28.0,0.01316738816738817,0.3985209235209235,1,0.13333333333333333,0.029166666666666667,0.3287037037037037
2094,2140,2140,"Person search with joint detection, segmentation and re-identification","Person search is a new and challenging task proposed in recent years. It aims to jointly handle person detection and person re-identification in an end-to-end deep learning neural network. In this paper, we propose a new multi-task framework, which jointly learn person detection, person instance segmentation and person re-identification. In this framework, a segmentation branch is added into the person search pipeline to generate a high-quality segmentation mask for each person instance. Then, the segmentation feature maps are concatenated with corresponding convolution feature maps in the re-identification branch, which results as a self-attention mechanism, provides more discriminative feature for person re-identification. The experimental results on the public dataset PRW demonstrate the effectiveness of the framework.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],19.166666666666668,0.1715909090909091,0.44071969696969704,1,0.0821917808219178,0.00684931506849315,0.296875
2095,2141,2141,Digging into self-supervised monocular depth estimation,"Per-pixel ground-truth depth data is challenging to acquire at scale. To overcome this limitation, self-supervised learning has emerged as a promising alternative for training models to perform monocular depth estimation. In this paper, we propose a set of improvements, which together result in both quantitatively and qualitatively improved depth maps compared to competing self-supervised methods. Research on self-supervised monocular training usually explores increasingly complex architectures, loss functions, and image formation models, all of which have recently helped to close the gap with fully-supervised methods. We show that a surprisingly simple model, and associated design choices, lead to superior predictions. In particular, we propose (i) a minimum reprojection loss, designed to robustly handle occlusions, (ii) a full-resolution multi-scale sampling method that reduces visual artifacts, and (iii) an auto-masking loss to ignore training pixels that violate camera motion assumptions. We demonstrate the effectiveness of each component in isolation, and show high quality, state-of-the-art results on the KITTI benchmark.",60031581,California Institute of Technology,Pasadena,United States,"['1712', '1707']",22.285714285714285,0.11766666666666666,0.453047619047619,1,0.13526570048309178,0.004830917874396135,0.39344262295081966
2096,2142,2142,HowTo100M: Learning a text-video embedding by watching hundred million narrated video clips,"Learning text-video embeddings usually requires a dataset of video clips with manually provided captions. However, such datasets are expensive and time consuming to create and therefore difficult to obtain on a large scale. In this work, we propose instead to learn such embeddings from video data with readily available natural language annotations in the form of automatically transcribed narrations. The contributions of this work are three-fold. First, we introduce HowTo100M: A large-scale dataset of 136 million video clips sourced from 1.22M narrated instructional web videos depicting humans performing and describing over 23k different visual tasks. Our data collection procedure is fast, scalable and does not require any additional manual annotation. Second, we demonstrate that a text-video embedding trained on this data leads to state-of-the-art results for text-to-video retrieval and action localization on instructional video datasets such as YouCook2 or CrossTask. Finally, we show that this embedding transfers well to other domains: Fine-tuning on generic Youtube videos (MSR-VTT dataset) and movies (LSMDC dataset) outperforms models trained on these datasets alone. Our dataset, code and models are publicly available.",60013373,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,"['1712', '1707']",19.666666666666668,0.015225563909774434,0.42562656641603996,1,0.1031390134529148,0.03587443946188341,0.40703517587939697
2097,2143,2143,ShapeMask: Learning to segment novel objects by refining shape priors,"Instance segmentation aims to detect and segment individual objects in a scene. Most existing methods rely on precise mask annotations of every category. However, it is difficult and costly to segment objects in novel categories because a large number of mask annotations is required. We introduce ShapeMask, which learns the intermediate concept of object shape to address the problem of generalization in instance segmentation to novel categories. ShapeMask starts with a bounding box detection and gradually refines it by first estimating the shape of the detected object through a collection of shape priors. Next, ShapeMask refines the coarse shape into an instance level mask by learning instance embeddings. The shape priors provide a strong cue for object-like prediction, and the instance embeddings model the instance specific appearance information. ShapeMask significantly outperforms the state-of-the-art by 6.4 and 3.8 AP when learning across categories, and obtains competitive performance in the fully supervised setting. It is also robust to inaccurate detections, decreased model capacity, and small training data. Moreover, it runs efficiently with 150ms inference time on a GPU and trains within 11 hours on TPUs. With a larger backbone model, ShapeMask increases the gap with state-of-the-art to 9.4 and 6.2 AP across categories. Code will be publicly available at: Https://sites.google.com/view/shapemask/home.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",17.333333333333332,0.09484126984126982,0.513015873015873,1,0.10245901639344263,0.036885245901639344,0.3620689655172414
2098,2144,2144,Transformable bottleneck networks,"We propose a novel approach to performing fine-grained 3D manipulation of image content via a convolutional neural network, which we call the Transformable Bottleneck Network (TBN). It applies given spatial transformations directly to a volumetric bottleneck within our encoder-bottleneck-decoder architecture. Multi-view supervision encourages the network to learn to spatially disentangle the feature space within the bottleneck. The resulting spatial structure can be manipulated with arbitrary spatial transformations. We demonstrate the efficacy of TBNs for novel view synthesis, achieving state-of-the-art results on a challenging benchmark. We demonstrate that the bottlenecks produced by networks trained for this task contain meaningful spatial structure that allows us to intuitively perform a variety of image manipulations in 3D, well beyond the rigid transformations seen during training. These manipulations include non-uniform scaling, non-rigid warping, and combining content from different images. Finally, we extract explicit 3D structure from the bottleneck, performing impressive 3D reconstruction from a single input image.",60120916,Snap Inc.,Santa Monica,United States,"['1712', '1707']",19.0,0.24107142857142855,0.6642857142857143,1,0.12834224598930483,0.0427807486631016,0.33136094674556216
2099,2145,2145,COCO-GAN: Generation by parts via conditional coordinating,"Humans can only interact with part of the surrounding environment due to biological restrictions. Therefore, we learn to reason the spatial relationships across a series of observations to piece together the surrounding environment. Inspired by such behavior and the fact that machines also have computational constraints, we propose COnditional COordinate GAN (COCO-GAN) of which the generator generates images by parts based on their spatial coordinates as the condition. On the other hand, the discriminator learns to justify realism across multiple assembled patches by global coherence, local appearance, and edge-crossing continuity. Despite the full images are never manipulated during training, we show that COCO-GAN can produce state-of-the-art-quality full images during inference. We further demonstrate a variety of novel applications enabled by our coordinate-aware framework. First, we perform extrapolation to the learned coordinate manifold and generate off-the-boundary patches. Combining with the originally generated full image, COCO-GAN can produce images that are larger than training samples, which we called 'beyond-boundary generation'. We then showcase panorama generation within a cylindrical coordinate system that inherently preserves horizontally cyclic topology. On the computation side, COCO-GAN has a built-in divide-and-conquer paradigm that reduces memory requisition during training and inference, provides high-parallelism, and can generate parts of images on-demand.",60018029,National Tsing Hua University,Hsinchu,Taiwan,"['1712', '1707']",20.1,0.10178571428571427,0.4273809523809523,1,0.13688212927756654,0.04182509505703422,0.36283185840707965
2100,2146,2146,Expectation-maximization attention networks for semantic segmentation,"Self-attention mechanism has been widely used for various tasks. It is designed to compute the representation of each position by a weighted sum of the features at all positions. Thus, it can capture long-range relations for computer vision tasks. However, it is computationally consuming. Since the attention maps are computed w.r.t all other positions. In this paper, we formulate the attention mechanism into an expectation-maximization manner and iteratively estimate a much more compact set of bases upon which the attention maps are computed. By a weighted summation upon these bases, the resulting representation is low-rank and deprecates noisy information from the input. The proposed Expectation-Maximization Attention (EMA) module is robust to the variance of input and is also friendly in memory and computation. Moreover, we set up the bases maintenance and normalization methods to stabilize its training procedure. We conduct extensive experiments on popular semantic segmentation benchmarks including PASCAL VOC, PASCAL Context, and COCO Stuff, on which we set new records.",60014966,Peking University,Beijing,China,"['1712', '1707']",16.1,0.17329545454545453,0.4953598484848485,1,0.08900523560209424,0.04712041884816754,0.3370165745856354
2101,2147,2147,DeCaFA: Deep convolutional cascade for face alignment in the wild,"Face Alignment is an active computer vision domain, that consists in localizing a number of facial landmarks that vary across datasets. State-of-the-art face alignment methods either consist in end-to-end regression, or in refining the shape in a cascaded manner, starting from an initial guess. In this paper, we introduce an end-to-end deep convolutional cascade (DeCaFA) architecture for face alignment. Face Alignment is an active computer vision domain, that consists in localizing a number of facial landmarks that vary across datasets. State-of-the-art face alignment methods either consist in end-to-end regression, or in refining the shape in a cascaded manner, starting from an initial guess. In this paper, we introduce DeCaFA, an end-to-end deep convolutional cascade architecture for face alignment. DeCaFA uses fully-convolutional stages to keep full spatial resolution throughout the cascade. Between each cascade stage, DeCaFA uses multiple chained transfer layers with spatial softmax to produce landmark-wise attention maps for each of several landmark alignment tasks. Weighted intermediate supervision, as well as efficient feature fusion between the stages allow to learn to progressively refine the attention maps in an end-to-end manner. We show experimentally that DeCaFA significantly outperforms existing approaches on 300W, CelebA and WFLW databases. In addition, we show that DeCaFA can learn fine alignment with reasonable accuracy from very few images using coarsely annotated data.",60001422,Sorbonne Universite,Paris,France,"['1712', '1707']",19.63636363636364,0.048157894736842115,0.3028947368421053,1,0.11870503597122302,0.025179856115107913,0.33884297520661155
2102,2148,2148,Discriminative feature learning with consistent attention regularization for person re-identification,"Person re-identification (Re-ID) has undergone a rapid development with the blooming of deep neural network. Most methods are very easily affected by target misalignment and background clutter in the training process. In this paper, we propose a simple yet effective feedforward attention network to address the two mentioned problems, in which a novel consistent attention regularizer and an improved triplet loss are designed to learn foreground attentive features for person Re-ID. Specifically, the consistent attention regularizer aims to keep the deduced foreground masks similar from the low-level, mid-level and high-level feature maps. As a result, the network will focus on the foreground regions at the lower layers, which is benefit to learn discriminative features from the foreground regions at the higher layers. Last but not least, the improved triplet loss is introduced to enhance the feature learning capability, which can jointly minimize the intra-class distance and maximize the inter-class distance in each triplet unit. Experimental results on the Market1501, DukeMTMC-reID and CUHK03 datasets have shown that our method outperforms most of the state-of-the-art approaches.",60018308,Xi'an Jiaotong University,Xi'an,China,"['1712', '1707']",24.857142857142854,0.25452380952380954,0.4802721088435375,1,0.09722222222222222,0.041666666666666664,0.3072916666666667
2103,2149,2149,Single-stage multi-person pose machines,"Multi-person pose estimation is a challenging problem. Existing methods are mostly two-stage based-one stage for proposal generation and the other for allocating poses to corresponding persons. However, such two-stage methods generally suffer low efficiency. In this work, we present the first emph{single-stage} model, Single-stage multi-person Pose Machine (SPM), to simplify the pipeline and lift the efficiency for multi-person pose estimation. To achieve this, we propose a novel Structured Pose Representation (SPR) that unifies person instance and body joint position representations. Based on SPR, we develop the SPM model that can directly predict structured poses for multiple persons in a single stage, and thus offer a more compact pipeline and attractive efficiency advantage over two-stage methods. In particular, SPR introduces the root joints to indicate different person instances and human body joint positions are encoded into their displacements w.r.t.∼the roots. To better predict long-range displacements for some joints, SPR is further extended to hierarchical representations. Based on SPR, SPM can efficiently perform multi-person poses estimation by simultaneously predicting root joints (location of instances) and body joint displacements via CNNs. Moreover, to demonstrate the generality of SPM, we also apply it to multi-person 3D pose estimation. Comprehensive experiments on benchmarks MPII, extended PASCAL-Person-Part, MSCOCO and CMU Panoptic clearly demonstrate the state-of-the-art efficiency of SPM for multi-person 2D/3D pose estimation, together with outstanding accuracy.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",20.09090909090909,0.1885119047619048,0.4457142857142856,1,0.10689655172413794,0.07241379310344828,0.43359375
2104,2150,2150,IL2M: Class incremental learning with dual memory,"This paper presents a class incremental learning (IL) method which exploits fine tuning and a dual memory to reduce the negative effect of catastrophic forgetting in image recognition. First, we simplify the current fine tuning based approaches which use a combination of classification and distillation losses to compensate for the limited availability of past data. We find that the distillation term actually hurts performance when a memory is allowed. Then, we modify the usual class IL memory component. Similar to existing works, a first memory stores exemplar images of past classes. A second memory is introduced here to store past class statistics obtained when they were initially learned. The intuition here is that classes are best modeled when all their data are available and that their initial statistics are useful across different incremental states. A prediction bias towards newly learned classes appears during inference because the dataset is imbalanced in their favor. The challenge is to make predictions of new and past classes more comparable. To do this, scores of past classes are rectified by leveraging contents from both memories. The method has negligible added cost, both in terms of memory and of inference complexity. Experiments with three large public datasets show that the proposed approach is more effective than a range of competitive state-of-the-art methods.",60007816,Commissariat a L'Energie Atomique CEA,Gif-sur-Yvette,France,"['1712', '1707']",18.0,0.11203164651440514,0.3142707866845797,1,0.1078838174273859,0.008298755186721992,0.2297872340425532
2105,2151,2151,CAMEL: A weakly supervised learning framework for histopathology image segmentation,"Histopathology image analysis plays a critical role in cancer diagnosis and treatment. To automatically segment the cancerous regions, fully supervised segmentation algorithms require labor-intensive and time-consuming labeling at the pixel level. In this research, we propose CAMEL, a weakly supervised learning framework for histopathology image segmentation using only image-level labels. Using multiple instance learning (MIL)-based label enrichment, CAMEL splits the image into latticed instances and automatically generates instance-level labels. After label enrichment, the instance-level labels are further assigned to the corresponding pixels, producing the approximate pixel-level labels and making fully supervised training of segmentation models possible. CAMEL achieves comparable performance with the fully supervised approaches in both instance-level classification and pixel-level segmentation on CAMELYON16 and a colorectal adenoma dataset. Moreover, the generality of the automatic labeling methodology may benefit future weakly supervised learning studies for histopathology image analysis.",60088468,China PLA General Hospital,Beijing,China,"['1712', '1707']",19.714285714285715,-0.12777777777777774,0.5861111111111111,1,0.13609467455621302,0.029585798816568046,0.4064516129032258
2106,2152,2152,MMAct: A large-scale dataset for cross modal human action understanding,"Unlike vision modalities, body-worn sensors or passive sensing can avoid the failure of action understanding in vision related challenges, e.g. occlusion and appearance variation. However, a standard large-scale dataset does not exist, in which different types of modalities across vision and sensors are integrated. To address the disadvantage of vision-based modalities and push towards multi/cross modal action understanding, this paper introduces a new large-scale dataset recorded from 20 distinct subjects with seven different types of modalities: RGB videos, keypoints, acceleration, gyroscope, orientation, Wi-Fi and pressure signal. The dataset consists of more than 36k video clips for 37 action classes covering a wide range of daily life activities such as desktop-related and check-in-based ones in four different distinct scenarios. On the basis of our dataset, we propose a novel multi modality distillation model with attention mechanism to realize an adaptive knowledge transfer from sensor-based modalities to vision-based modalities. The proposed model significantly improves performance of action recognition compared to models trained with only RGB information. The experimental results confirm the effectiveness of our model on cross-subject, -view, -scene and -session evaluation criteria. We believe that this new large-scale multimodal dataset will contribute the community of multimodal based action understanding.",60118460,Alibaba Group Holding Limited,Yu Hang,China,"['1712', '1707']",22.0,0.08777548209366391,0.37200413223140494,1,0.11382113821138211,0.02032520325203252,0.37104072398190047
2107,2153,2153,Bilinear attention networks for person retrieval,"This paper investigates a novel Bilinear attention (Bi-attention) block, which discovers and uses second order statistical information in an input feature map, for the purpose of person retrieval. The Bi-attention block uses bilinear pooling to model the local pairwise feature interactions along each channel, while preserving the spatial structural information. We propose an Attention in Attention (AiA) mechanism to build inter-dependency among the second order local and global features with the intent to make better use of, or pay more attention to, such higher order statistical relationships. The proposed network, equipped with the proposed Bi-attention is referred to as Bilinear ATtention network (BAT-net). Our approach outperforms current state-of-the-art by a considerable margin across the standard benchmark datasets (e.g., CUHK03, Market-1501, DukeMTMC-reID and MSMT17).",60108057,CSIRO Data61,Sydney,Australia,"['1712', '1707']",24.6,0.1125,0.2375,1,0.09815950920245399,0.05521472392638037,0.4
2108,2154,2154,Indices matter: Learning to index for deep image matting,"We show that existing upsampling operators can be unified using the notion of the index function. This notion is inspired by an observation in the decoding process of deep image matting where indices-guided unpooling can often recover boundary details considerably better than other upsampling operators such as bilinear interpolation. By viewing the indices as a function of the feature map, we introduce the concept of 'learning to index', and present a novel index-guided encoder-decoder framework where indices are self-learned adaptively from data and are used to guide the pooling and upsampling operators, without extra training supervision. At the core of this framework is a flexible network module, termed IndexNet, which dynamically generates indices conditioned on the feature map. Due to its flexibility, IndexNet can be used as a plug-in applying to almost all off-the-shelf convolutional networks that have coupled downsampling and upsampling stages. We demonstrate the effectiveness of IndexNet on the task of natural image matting where the quality of learned indices can be visually observed from predicted alpha mattes. Results on the Composition-1k matting dataset show that our model built on MobileNetv2 exhibits at least 16.1% improvement over the seminal VGG-16 based deep matting baseline, with less training data and lower model capacity. Code and models have been made available at: Https://tinyurl.com/IndexNetV1.",60119391,Huawei Noah's Ark Lab,Hong Kong,Hong Kong,"['1712', '1707']",26.625,0.021794871794871797,0.3012820512820513,1,0.14634146341463414,0.032520325203252036,0.30042918454935624
2109,2155,2155,Deep mesh reconstruction from single rgb images via topology modification networks,"Reconstructing the 3D mesh of a general object from a single image is now possible thanks to the latest advances of deep learning technologies. However, due to the nontrivial difficulty of generating a feasible mesh structure, the state-of-the-art approaches often simplify the problem by learning the displacements of a template mesh that deforms it to the target surface. Though reconstructing a 3D shape with complex topology can be achieved by deforming multiple mesh patches, it remains difficult to stitch the results to ensure a high meshing quality. In this paper, we present an end-to-end single-view mesh reconstruction framework that is able to generate high-quality meshes with complex topologies from a single genus-0 template mesh. The key to our approach is a novel progressive shaping framework that alternates between mesh deformation and topology modification. While a deformation network predicts the per-vertex translations that reduce the gap between the reconstructed mesh and the ground truth, a novel topology modification network is employed to prune the error-prone faces, enabling the evolution of topology. By iterating over the two procedures, one can progressively modify the mesh topology while achieving higher reconstruction accuracy. Moreover, a boundary refinement network is designed to refine the boundary conditions to further improve the visual quality of the reconstructed mesh. Extensive experiments demonstrate that our approach outperforms the current state-of-the-art methods both qualitatively and quantitatively, especially for the shapes with complex topologies.",60108865,"The Chinese University of Hong Kong, Shenzhen",Shenzhen,China,"['1712', '1707']",25.777777777777782,-0.00034161490683229736,0.4739958592132506,1,0.10948905109489052,0.0036496350364963502,0.256
2110,2156,2156,Convex relaxations for consensus and non-minimal problems in 3D vision,"In this paper, we formulate a generic non-minimal solver using the existing tools of Polynomials Optimization Problems (POP) from computational algebraic geometry. The proposed method exploits the well known Shor's or Lasserre's relaxations, whose theoretical aspects are also discussed. Notably, we further exploit the POP formulation of non-minimal solver also for the generic consensus maximization problems in 3D vision. Our framework is simple and straightforward to implement, which is also supported by three diverse applications in 3D vision, namely rigid body transformation estimation, Non-Rigid Structure-from-Motion (NRSfM), and camera autocalibration. In all three cases, both non-minimal and consensus maximization are tested, which are also compared against the state-of-the-art methods. Our results are competitive to the compared methods, and are also coherent with our theoretical analysis. The main contribution of this paper is the claim that a good approximate solution for many polynomial problems involved in 3D vision can be obtained using the existing theory of numerical computational algebra. This claim leads us to reason about why many relaxed methods in 3D vision behave so well? And also allows us to offer a generic relaxed solver in a rather straightforward way. We further show that the convex relaxation of these polynomials can easily be used for maximizing consensus in a deterministic manner. We support our claim using several experiments for aforementioned three diverse problems in 3D vision.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",22.5,0.16750000000000004,0.3486904761904762,1,0.10740740740740741,0.02962962962962963,0.3373015873015873
2111,2157,2157,DynamoNet: Dynamic action and motion network,"In this paper, we are interested in self-supervised learning the motion cues in videos using dynamic motion filters for a better motion representation to finally boost human action recognition in particular. Thus far, the vision community has focused on spatio-temporal approaches using standard filters, rather we here propose dynamic filters that adaptively learn the video-specific internal motion representation by predicting the short-term future frames. We name this new motion representation, as dynamic motion representation (DMR) and is embedded inside of 3D convolutional network as a new layer, which captures the visual appearance and motion dynamics throughout entire video clip via end-to-end network learning. Simultaneously, we utilize these motion representation to enrich video classification. We have designed the frame prediction task as an auxiliary task to empower the classification problem. With these overall objectives, to this end, we introduce a novel unified spatio-temporal 3D-CNN architecture (DynamoNet) that jointly optimizes the video classification and learning motion representation by predicting future frames as a multi-task learning problem. We conduct experiments on challenging human action datasets: Kinetics 400, UCF101, HMDB51. The experiments using the proposed DynamoNet show promising results on all the datasets.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",23.625,0.09519104084321477,0.3268445322793149,1,0.10434782608695652,0.030434782608695653,0.33962264150943394
2112,2158,2158,LAP-net: Level-aware progressive network for image dehazing,"In this paper, we propose a level-aware progressive network (LAP-Net) for single image dehazing. Unlike previous multi-stage algorithms that generally learn in a coarse-to-fine fashion, each stage of LAP-Net learns different levels of haze with different supervision. Then the network can progressively learn the gradually aggravating haze. With this design, each stage can focus on a region with specific haze level and restore clear details. To effectively fuse the results of varying haze levels at different stages, we develop an adaptive integration strategy to yield the final dehazed image. This strategy is achieved by a hierarchical integration scheme, which is in cooperation with the memory network and the domain knowledge of dehazing to highlight the best-restored regions of each stage. Extensive experiments on both real-world images and two dehazing benchmarks validate the effectiveness of our proposed method.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",19.571428571428573,0.046536796536796536,0.4838744588744588,1,0.12574850299401197,0.023952095808383235,0.31125827814569534
2113,2159,2159,Usability testing of a smartphone telecare application for informal caregivers,"Independent living of the elderly has its risks that can be decreased with the use of telecare systems. Smartphone telecare applications such as TeleStiki, are intended primarily for informal carers of independently living elders. The application is aimed at improving quality of life of both the elderly and their caregivers by reducing the caregiver burden and extending the time elders stay at home, while also increasing their safety. The aim of usability testing was to evaluate if users perceive the tested smartphone application as high in usability and user experience. The testing was also aimed at evaluating whether the use of application affects their attitude towards the use of telecare applications for informal care of their elderly relatives in general. In this study Task Completion, User Experience Questionnaire and System Usability Scale, as well as the Think-Aloud protocol has been performed. Results showed the application scores above average in usability and user experience. Findings gained in the qualitative study can be used as guidelines for future re-designs of the application and for improvement of usability in similar applications.",60068809,University of Kragujevac,Kragujevac,Serbia,['1700'],22.25,0.005454545454545457,0.365,1,0.10824742268041238,0.05670103092783505,0.29473684210526313
2114,2160,2160,SegSort: Segmentation by discriminative sorting of segments,"Almost all existing deep learning approaches for semantic segmentation tackle this task as a pixel-wise classification problem. Yet humans understand a scene not in terms of pixels, but by decomposing it into perceptual groups and structures that are the basic building blocks of recognition. This motivates us to propose an end-to-end pixel-wise metric learning approach that mimics this process. In our approach, the optimal visual representation determines the right segmentation within individual images and associates segments with the same semantic classes across images. The core visual learning problem is therefore to maximize the similarity within segments and minimize the similarity between segments. Given a model trained this way, inference is performed consistently by extracting pixel-wise embeddings and clustering, with the semantic label determined by the majority vote of its nearest neighbors from an annotated set. As a result, we present the SegSort, as a first attempt using deep learning for unsupervised semantic segmentation, achieving 76% performance of its supervised counterpart. When supervision is available, SegSort shows consistent improvements over conventional approaches based on pixel-wise softmax training. Additionally, our approach produces more precise boundaries and consistent region predictions. The proposed SegSort further produces an interpretable result, as each choice of label can be easily understood from the retrieved nearest segments.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",20.9,0.15137844611528825,0.3399749373433584,1,0.10743801652892562,0.012396694214876033,0.3217391304347826
2115,2161,2161,Skyscapes - fine-grained semantic understanding of aerial scenes,"Understanding the complex urban infrastructure with centimeter-level accuracy is essential for many applications from autonomous driving to mapping, infrastructure monitoring, and urban management. Aerial images provide valuable information over a large area instantaneously; nevertheless, no current dataset captures the complexity of aerial scenes at the level of granularity required by real-world applications. To address this, we introduce SkyScapes, an aerial image dataset with highly-accurate, fine-grained annotations for pixel-level semantic labeling. SkyScapes provides annotations for 31 semantic categories ranging from large structures, such as buildings, roads and vegetation, to fine details, such as 12 (sub-)categories of lane markings. We have defined two main tasks on this dataset: Dense semantic segmentation and multi-class lane-marking prediction. We carry out extensive experiments to evaluate state-of-the-art segmentation methods on SkyScapes. Existing methods struggle to deal with the wide range of classes, object sizes, scales, and fine details present. We therefore propose a novel multi-task model, which incorporates semantic edge detection and is better tuned for feature extraction from a wide range of scales. This model achieves notable improvements over the baselines in region outlines and level of detail on both tasks.",60028453,"Fraunhofer Institute for Optronics, System Technologies and Image Exploitation IOSB",Karlsruhe,Germany,"['1712', '1707']",20.666666666666668,0.14142857142857146,0.3811904761904762,1,0.08547008547008547,0.01282051282051282,0.3925233644859813
2116,2162,2162,Scene graph prediction with limited labels,"Visual knowledge bases such as Visual Genome power numerous applications in computer vision, including visual question answering and captioning, but suffer from sparse, incomplete relationships. All scene graph models to date are limited to training on a small set of visual relationships that have thousands of training labels each. Hiring human annotators is expensive, and using textual knowledge base completion methods are incompatible with visual data. In this paper, we introduce a semi-supervised method that assigns probabilistic relationship labels to a large number of unlabeled images using few labeled examples. We analyze visual relationships to suggest two types of image-agnostic features that are used to generate noisy heuristics, whose outputs are aggregated using a factor graph-based generative model. With as few as 10 labeled examples per relationship, the generative model creates enough training data to train any existing state-of-the-art scene graph model. We demonstrate that our method outperforms all baseline approaches on scene graph prediction by5.16 recall@100 for PREDCLS. In our limited label setting, we define a complexity metric for relationships that serves as an indicator (R2 = 0.778) for conditions under which our method succeeds over transfer learning, the de-facto approach for training with limited labels.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",24.625,-0.0625,0.2428571428571429,1,0.11739130434782609,0.0391304347826087,0.3623853211009174
2117,2163,2163,Deep appearance maps,"We propose a deep representation of appearance, i.e. the relation of color, surface orientation, viewer position, material and illumination. Previous approaches have used deep learning to extract classic appearance representations relating to reflectance model parameters (e.g. Phong) or illumination (e.g. HDR environment maps). We suggest to directly represent appearance itself as a network we call a deep appearance map (DAM). This is a 4D generalization over 2D reflectance maps, which held the view direction fixed. First, we show how a DAM can be learned from images or video frames and later be used to synthesize appearance, given new surface orientations and viewer positions. Second, we demonstrate how another network can be used to map from an image or video frames to a DAM network to reproduce this appearance, without using a lengthy optimization such as stochastic gradient descent (learning-to-learn). Finally, we show the example of an appearance estimation-and-segmentation task, mapping from an image showing multiple materials to multiple deep appearance maps.",60117087,CISPA - Helmholtz Center for Information Security,Saarbrücken,Germany,"['1712', '1707']",16.1,0.03664772727272728,0.30132575757575764,1,0.13846153846153847,0.015384615384615385,0.3368421052631579
2118,2164,2164,Group-wise deep object co-segmentation with co-attention recurrent neural network,"Effective feature representations which should not only express the images individual properties, but also reflect the interaction among group images are essentially crucial for real-world co-segmentation. This paper proposes a novel end-to-end deep learning approach for group-wise object co-segmentation with a recurrent network architecture. Specifically, the semantic features extracted from a pre-trained CNN of each image are first processed by single image representation branch to learn the unique properties. Meanwhile, a specially designed Co-Attention Recurrent Unit (CARU) recurrently explores all images to generate the final group representation by using the co-attention between images, and simultaneously suppresses noisy information. The group feature which contains synergetic information is broadcasted to each individual image and fused with multi-scale fine-resolution features to facilitate the inferring of co-segmentation. Moreover, we propose a groupwise training objective to utilize the co-object similarity and figure-ground distinctness as the additional supervision. The whole modules are collaboratively optimized in an end-to-end manner, further improving the robustness of the approach. Comprehensive experiments on three benchmarks can demonstrate the superiority of our approach in comparison with the state-of-the-art methods.",60033100,Nanjing University,Nanjing,China,"['1712', '1707']",22.125,0.1221938775510204,0.5799319727891158,1,0.1038961038961039,0.021645021645021644,0.32642487046632124
2119,2165,2165,Generative modeling for small-data object detection,"This paper explores object detection in the small data regime, where only a limited number of annotated bounding boxes are available due to data rarity and annotation expense. This is a common challenge today with machine learning being applied to many new tasks where obtaining training data is more challenging, e.g. in medical images with rare diseases that doctors sometimes only see once in their life-time. In this work we explore this problem from a generative modeling perspective by learning to generate new images with associated bounding boxes, and using these for training an object detector. We show that simply training previously proposed generative models does not yield satisfactory performance due to them optimizing for image realism rather than object detection accuracy. To this end we develop a new model with a novel unrolling mechanism that jointly optimizes the generative model and a detector such that the generated images improve the performance of the detector. We show this method outperforms the state of the art on two challenging datasets, disease detection and small data pedestrian detection, improving the average precision on NIH Chest X-ray by a relative 20% and localization accuracy by a relative 50%.",60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,"['1712', '1707']",27.857142857142854,0.06962481962481963,0.4700126262626263,1,0.12735849056603774,0.014150943396226415,0.22966507177033493
2120,2166,2166,Advanced human centric 5G-IoT in a smart city: Requirements and challenges,"The concept of a smart city (SC) is developed on advanced information-communication technologies (ICT). The role of new 5G mobile wireless systems and Internet of Things (IoT) is discussed as essential for a successful SC infrastructure for interconnecting citizens in physical and virtual worlds. IoT-based smart cities can provide various kinds of services for citizens, including smart home, smart energy and meter systems, vehicular traffic and transportation, environmental pollution, smart health. The services are transforming cities by improving infrastructure and efficiency of the everyday activities. The huge development of smart devices, novel communication, computing and control technologies have paved the way for 5G-IoT advancement. At the same time the final goal is to provide efficient human-centric communication. In this article smart cities infrastructure evolution is presented. Moreover, an overview of the role of 5G-IoT including up-to-date development is described. Later, we continue with human-centric 5G-IoT in SC. Finally, in order to give future research directions several challenges are highlighted.",60068815,University of Belgrade,Belgrade,Serbia,['1700'],15.9,0.14028925619834712,0.5226092089728454,1,0.08333333333333333,0.029411764705882353,0.4
2121,2167,2167,Grouped spatial-temporal aggregation for efficient action recognition,"Temporal reasoning is an important aspect of video analysis. 3D CNN shows good performance by exploring spatial-temporal features jointly in an unconstrained way, but it also increases the computational cost a lot. Previous works try to reduce the complexity by decoupling the spatial and temporal filters. In this paper, we propose a novel decomposition method that decomposes the feature channels into spatial and temporal groups in parallel. This decomposition can make two groups focus on static and dynamic cues separately. We call this grouped spatial-temporal aggregation (GST). This decomposition is more parameter-efficient and enables us to quantitatively analyze the contributions of spatial and temporal features in different layers. We verify our model on several action recognition tasks that require temporal reasoning and show its effectiveness.",60005248,Johns Hopkins University,Baltimore,United States,"['1712', '1707']",15.625,0.20333333333333334,0.4033333333333333,1,0.1258741258741259,0.013986013986013986,0.291970802919708
2122,2168,2168,Drop to adapt: Learning discriminative features for unsupervised domain adaptation,"Recent works on domain adaptation exploit adversarial training to obtain domain-invariant feature representations from the joint learning of feature extractor and domain discriminator networks. However, domain adversarial methods render suboptimal performances since they attempt to match the distributions among the domains without considering the task at hand. We propose Drop to Adapt (DTA), which leverages adversarial dropout to learn strongly discriminative features by enforcing the cluster assumption. Accordingly, we design objective functions to support robust domain adaptation. We demonstrate efficacy of the proposed method on various experiments and achieve consistent improvements in both image classification and semantic segmentation tasks. Our source code is available at https://github.com/postBG/DTA.pytorch.",60013682,Seoul National University,Seoul,South Korea,"['1712', '1707']",17.666666666666668,0.1805555555555556,0.37222222222222223,1,0.15126050420168066,0.01680672268907563,0.3445378151260504
2123,2169,2169,Clustering method for low voltage substation-area users based on edge computing architecture,"Measurement and monitoring of data in power networks are of great value. A hierarchical clustering analysis method based on edge computing architecture for low-voltage power consumption data is proposed. Based on edge computing architecture, edge nodes are used to collect data and cluster locally, a cloud computing platform is used to aggregate and optimize clustering results. The algorithm flow and optimization strategy are described. The simulation results show that the method has certain advantages in improving computational efficiency and reducing time delay.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],16.4,0.3380952380952381,0.4404761904761905,1,0.16483516483516483,0.0,0.24719101123595505
2124,2170,2170,End-to-end cad model retrieval and 9DOF alignment in 3D scans,"We present a novel, end-to-end approach to align CAD models to an 3D scan of a scene, enabling transformation of a noisy, incomplete 3D scan to a compact, CAD reconstruction with clean, complete object geometry. Our main contribution lies in formulating a differentiable Procrustes alignment that is paired with a symmetry-aware dense object correspondence prediction. To simultaneously align CAD models to all the objects of a scanned scene, our approach detects object locations, then predicts symmetry-aware dense object correspondences between scan and CAD geometry in a unified object space, as well as a nearest neighbor CAD model, both of which are then used to inform a differentiable Procrustes alignment. Our approach operates in a fully-convolutional fashion, enabling alignment of CAD models to the objects of a scan in a single forward pass. This enables our method to outperform state-of-the-art approaches by 19.04% for CAD model alignment to scans, with approximately 250x faster runtime than previous data-driven approaches.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",31.4,-0.000680272108843539,0.34489795918367344,1,0.08333333333333333,0.046875,0.3390804597701149
2125,2171,2171,Learning meshes for dense visual SLAM,"Estimating motion and surrounding geometry of a moving camera remains a challenging inference problem. From an information theoretic point of view, estimates should get better as more information is included, such as is done in dense SLAM, but this is strongly dependent on the validity of the underlying models. In the present paper, we use triangular meshes as both compact and dense geometry representation. To allow for simple and fast usage, we propose a view-based formulation for which we predict the in-plane vertex coordinates directly from images and then employ the remaining vertex depth components as free variables. Flexible and continuous integration of information is achieved through the use of a residual based inference technique. This so-called factor graph encodes all information as mapping from free variables to residuals, the squared sum of which is minimised during inference. We propose the use of different types of learnable residuals, which are trained end-to-end to increase their suitability as information bearing models and to enable accurate and reliable estimation. Detailed evaluation of all components is provided on both synthetic and real data which confirms the practicability of the presented approach.",60015150,Imperial College London,London,United Kingdom,"['1712', '1707']",23.5,0.2688888888888889,0.5649206349206349,1,0.14084507042253522,0.0,0.2413793103448276
2126,2173,2173,Sentiment analysis of social networks’ comments to predict stock return,"Financial intelligence has become a research hotspot in recent years with the development of behavioral finance which introduces the social emotion and behavior factors in the decision-making. The data mining technology is widely used in the research on financial intelligence. This paper collected the investors’ comments from Social Network Sites (SNS) by crawler technology and segmented each piece of comment into words by Chinese text processing technology to build a financial sentiment lexicon. Applying the sentiment lexicon, a sentiment computing model based on SO-PMI algorithm was designed to compute the sentiment indices of the investors. Finally, the paper made an empirical analysis through linear regression between the return of the stock and its investors’ sentiment index. The result proved that the sentiment indices based on the investors’ comments are better to measure the investors’ sentiment and can be used to predict the stock return.",60116864,School of Management Fudan University,Shanghai,China,['1700'],24.0,0.05151515151515152,0.21666666666666667,1,0.12345679012345678,0.037037037037037035,0.2468354430379747
2127,2174,2174,Cultural psychology analysis on ancient chinese archive,"With the developing of big data analysis technology and the digitization of ancient Chinese books, we are able to do more thoroughly psychology-related analysis on Chinese history, culture and people. It is an opportunity that we can have a glance at Chinese behavioral and psychological variation from 2000 years ago to the beginning of the nineteenth century. We aim at figuring out the change of the mental process of Chinese people through the past 2000 years and how the mind and behavior are shaped by the specific culture at each stage, based on the analysis of behavior and psychology, with the usage of big data and artificial intelligence techniques. In this paper, we construct the Ancient Chinese Archive (ACA), beginning with twenty-five official dynastic history books. The timeline begins with the pre-Qin period and ends with Qing dynastic. Our selection contains about 27 million Chinese characters (except punctuations). For better observation of the variation tendencies through every period, we merge some books into one period and divide all the dynasties into 9 parts. In each period, we count the frequency of some keywords such as Xiào (孝, filial piety), Lǐ (禮/礼, proper rite), etc., which represent Chinese social morality and culture ethics. We analyze the change process of the word frequency through time and areas and try to find out the explanation of these trends.",60027363,University of Chinese Academy of Sciences,Beijing,China,['1700'],25.0,0.029166666666666667,0.2083333333333333,1,0.06818181818181818,0.03787878787878788,0.2980392156862745
2128,2175,2175,Two-stream action recognition-oriented video super-resolution,"We study the video super-resolution (SR) problem for facilitating video analytics tasks, e.g. action recognition, instead of for visual quality. The popular action recognition methods based on convolutional networks, exemplified by two-stream networks, are not directly applicable on video of low spatial resolution. This can be remedied by performing video SR prior to recognition, which motivates us to improve the SR procedure for recognition accuracy. Tailored for two-stream action recognition networks, we propose two video SR methods for the spatial and temporal streams respectively. On the one hand, we observe that regions with action are more important to recognition, and we propose an optical-flow guided weighted mean-squared-error loss for our spatial-oriented SR (SoSR) network to emphasize the reconstruction of moving objects. On the other hand, we observe that existing video SR methods incur temporal discontinuity between frames, which also worsens the recognition accuracy, and we propose a siamese network for our temporal-oriented SR (ToSR) training that emphasizes the temporal continuity between consecutive frames. We perform experiments using two state-of-the-art action recognition networks and two well-known datasets - UCF101 and HMDB51. Results demonstrate the effectiveness of our proposed SoSR and ToSR in improving recognition accuracy.",60019118,University of Science and Technology of China,Hefei,China,"['1712', '1707']",21.555555555555557,0.13035714285714284,0.2910714285714286,1,0.12345679012345678,0.053497942386831275,0.38181818181818183
2129,2176,2176,A robust optimization model for closed-loop supply chain network under uncertain returns,"An effective closed-loop supply chain (CLSC) is increasingly important for corporate sustainable development, where used products are returned, remanufactured and/or recycled. Optimized planning of CLSC network is required and is influenced by uncertainties of recovery. So, this study seeks to establish a robust optimal model for CLSC network, considering both uncertainties in quantity and quality of returned products. After the general framework of CLSC is discussed, the measurements for uncertain quantity and quality of returned products are formulated mathematically, respectively as a number of discrete scenarios and Quality Index. A mixed integral linear programming (MILP) model for a CLSC network design is established and then translated into a robust optimization model based on regret value, to determine facilities’ locations and quantity of flows between facilities in the network. A numerical example is given, and the simulation results show that the operation strategies of the CLSC are relatively stable under different recycling scenarios. Therefore, the optimization model for CLSC network has good robustness.",60025761,Huazhong University of Science and Technology,Wuhan,China,['1700'],23.142857142857146,0.19444444444444445,0.4277777777777778,1,0.10810810810810811,0.05405405405405406,0.34972677595628415
2130,2177,2177,Language-conditioned graph networks for relational reasoning,"Solving grounded language tasks often requires reasoning about relationships between objects in the context of a given task. For example, to answer the question 'What color is the mug on the plate?' we must check the color of the specific mug that satisfies the 'on' relationship with respect to the plate. Recent work has proposed various methods capable of complex relational reasoning. However, most of their power is in the inference structure, while the scene is represented with simple local appearance features. In this paper, we take an alternate approach and build contextualized representations for objects in a visual scene to support relational reasoning. We propose a general framework of Language-Conditioned Graph Networks (LCGN), where each node represents an object, and is described by a context-aware representation from related objects through iterative message passing conditioned on the textual input. E.g., conditioning on the 'on' relationship to the plate, the object 'mug' gathers messages from the object 'plate' to update its representation to 'mug on the plate', which can be easily consumed by a simple classifier for answer prediction. We experimentally show that our LCGN approach effectively supports relational reasoning and improves performance across several tasks and datasets. Our code is available at http://ronghanghu.com/lcgn.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",22.555555555555557,0.1101851851851852,0.3457010582010582,1,0.125,0.025,0.31896551724137934
2131,2178,2178,Application of data envelopment analysis for measuring financial efficiency of district central cooperative banks,Agriculture being the primary sector of Indian economy now a day’s drawn more attention and emphasised has given for the overall development. Efficient credit facilities are essential for the improvement of this sector. Cooperative bank play a vital role in providing the forward as well as backward linkage of agricultural credit to be routed. The study focused to measure the efficiency of District Co-operative banks of Odisha using DEA approach. The efficiency score are calculated under BCC Mode of DEA which is based on the assumption of variable return to scale and DCCBS are ranked accordingly. The findings indicated that majority of DCCB’s are efficient where as others found to be inefficient.,60079572,Siksha O Anusandhan (Deemed to be University),Bhubaneswar,India,['1706'],18.666666666666668,0.2,0.34,1,0.11475409836065574,0.06557377049180328,0.2459016393442623
2132,2179,2179,Context-aware feature and label fusion for facial action unit intensity estimation with partially labeled data,"Facial action unit (AU) intensity estimation is a fundamental task for facial behaviour analysis. Most previous methods use a whole face image as input for intensity prediction. Considering that AUs are defined according to their corresponding local appearance, a few patch-based methods utilize image features of local patches. However, fusion of local features is always performed via straightforward feature concatenation or summation. Besides, these methods require fully annotated databases for model learning, which is expensive to acquire. In this paper, we propose a novel weakly supervised patch-based deep model on basis of two types of attention mechanisms for joint intensity estimation of multiple AUs. The model consists of a feature fusion module and a label fusion module. And we augment attention mechanisms of these two modules with a learnable task-related context, as one patch may play different roles in analyzing different AUs and each AU has its own temporal evolution rule. The context-aware feature fusion module is used to capture spatial relationships among local patches while the context-aware label fusion module is used to capture the temporal dynamics of AUs. The latter enables the model to be trained on a partially annotated database. Experimental evaluations on two benchmark expression databases demonstrate the superior performance of the proposed method.",60025534,Rensselaer Polytechnic Institute,Troy,United States,"['1712', '1707']",18.90909090909091,0.05362318840579711,0.3115942028985507,1,0.12236286919831224,0.008438818565400843,0.28634361233480177
2133,2180,2180,Variational uncalibrated photometric stereo under general lighting,"Photometric stereo (PS) techniques nowadays remain constrained to an ideal laboratory setup where modeling and calibration of lighting is amenable. To eliminate such restrictions, we propose an efficient principled variational approach to uncalibrated PS under general illumination. To this end, the Lambertian reflectance model is approximated through a spherical harmonic expansion, which preserves the spatial invariance of the lighting. The joint recovery of shape, reflectance and illumination is then formulated as a single variational problem. There the shape estimation is carried out directly in terms of the underlying perspective depth map, thus implicitly ensuring integrability and bypassing the need for a subsequent normal integration. To tackle the resulting nonconvex problem numerically, we undertake a two-phase procedure to initialize a balloon-like perspective depth map, followed by a 'lagged' block coordinate descent scheme. The experiments validate efficiency and robustness of this approach. Across a variety of evaluations, we are able to reduce the mean angular error consistently by a factor of 2-3 compared to the state-of-the-art.",60122535,"GREYC - Groupe de Recherche en Informatique, Image, Automatique et Instrumentation de Caen",Caen,France,"['1712', '1707']",20.5,0.16055194805194806,0.4978896103896104,1,0.09693877551020408,0.015306122448979591,0.2677595628415301
2134,2181,2181,WSOD2: Learning bottom-up and top-down objectness distillation for weakly-supervised object detection,"We study on weakly-supervised object detection (WSOD) which plays a vital role in relieving human involvement from object-level annotations. Predominant works integrate region proposal mechanisms with convolutional neural networks (CNN). Although CNN is proficient in extracting discriminative local features, grand challenges still exist to measure the likelihood of a bounding box containing a complete object (i.e., 'objectness'). In this paper, we propose a novel WSOD framework with Objectness Distillation (i.e., WSOD2) by designing a tailored training mechanism for weakly-supervised object detection. Multiple regression targets are specifically determined by jointly considering bottom-up (BU) and top-down (TD) objectness from low-level measurement and CNN confidences with an adaptive linear combination. As bounding box regression can facilitate a region proposal learning to approach its regression target with high objectness during training, deep objectness representation learned from bottom-up evidences can be gradually distilled into CNN by optimization. We explore different adaptive training curves for BU/TD objectness, and show that the proposed WSOD2 can achieve state-of-the-art results.",60021726,Microsoft Research,Redmond,United States,"['1712', '1707']",23.0,0.09555555555555556,0.38222222222222224,1,0.14285714285714285,0.05714285714285714,0.40106951871657753
2135,2182,2182,InGAN: Capturing and retargeting the 'DNA' of a natural image,"Generative Adversarial Networks (GANs) typically learn a distribution of images in a large image dataset, and are then able to generate new images from this distribution. However, each natural image has its own internal statistics, captured by its unique distribution of patches. In this paper we propose an ''Internal GAN'' (InGAN) - an image-specific GAN - which trains on a single input image and learns its internal distribution of patches. It is then able to synthesize a plethora of new natural images of significantly different sizes, shapes and aspect-ratios - all with the same internal patch-distribution (same ''DNA'') as the input image. In particular, despite large changes in global size/shape of the image, all elements inside the image maintain their local size/shape. InGAN is fully unsupervised, requiring no additional data other than the input image itself. Once trained on the input image, it can remap the input to any size or shape in a single feedforward pass, while preserving the same internal patch distribution. InGAN provides a unified framework for a variety of tasks, bridging the gap between textures and natural images.",60017563,Weizmann Institute of Science Israel,Rehovot,Israel,"['1712', '1707']",22.75,0.1003126503126503,0.32696809363476026,1,0.07142857142857142,0.026785714285714284,0.34285714285714286
2136,2183,2183,UM-adapt: Unsupervised multi-task adaptation using adversarial cross-task distillation,"Aiming towards human-level generalization, there is a need to explore adaptable representation learning methods with greater transferability. Most existing approaches independently address task-transferability and cross-domain adaptation, resulting in limited generalization. In this paper, we propose UM-Adapt - a unified framework to effectively perform unsupervised domain adaptation for spatially-structured prediction tasks, simultaneously maintaining a balanced performance across individual tasks in a multi-task setting. To realize this, we propose two novel regularization strategies; a) Contour-based content regularization (CCR) and b) exploitation of inter-task coherency using a cross-task distillation module. Furthermore, avoiding a conventional ad-hoc domain discriminator, we re-utilize the cross-task distillation loss as output of an energy function to adversarially minimize the input domain discrepancy. Through extensive experiments, we demonstrate superior generalizability of the learned representations simultaneously for multiple tasks under domain-shifts from synthetic to natural environments. UM-Adapt yields state-of-the-art transfer learning results on ImageNet classification and comparable performance on PASCAL VOC 2007 detection task, even with a smaller backbone-net. Moreover, the resulting semi-supervised framework outperforms the current fully-supervised multi-task learning state-of-the-art on both NYUD and Cityscapes dataset.",60014097,"Indian Institute of Science, Bengaluru",Bengaluru,India,"['1712', '1707']",22.0,0.16813186813186812,0.4121794871794873,1,0.10121457489878542,0.032388663967611336,0.3869346733668342
2137,2184,2184,On the over-smoothing problem of CNN based disparity estimation,"Currently, most deep learning based disparity estimation methods have the problem of over-smoothing at boundaries, which is unfavorable for some applications such as point cloud segmentation, mapping, etc. To address this problem, we first analyze the potential causes and observe that the estimated disparity at edge boundary pixels usually follows multimodal distributions, causing over-smoothing estimation. Based on this observation, we propose a single-modal weighted average operation on the probability distribution during inference, which can alleviate the problem effectively. To integrate the constraint of this inference method into training stage, we further analyze the characteristics of different loss functions and found that using cross entropy with gaussian distribution consistently further improves the performance. For quantitative evaluation, we propose a novel metric that measures the disparity error in the local structure of edge boundaries. Experiments on various datasets using various networks show our method's effectiveness and general applicability. Code will be available at https://github.com/chenchr/otosp.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",21.714285714285715,0.08235294117647059,0.4519607843137255,1,0.13068181818181818,0.005681818181818182,0.29069767441860467
2138,2185,2185,Deep multiple-attribute-perceived network for real-world texture recognition,"Texture recognition is a challenging visual task as multiple perceptual attributes may be perceived from the same texture image when combined with different spatial context. Some recent works building upon Convolutional Neural Network (CNN) incorporate feature encoding with orderless aggregating to provide invariance to spatial layouts. However, these existing methods ignore visual texture attributes, which are important cues for describing the real-world texture images, resulting in incomplete description and inaccurate recognition. To address this problem, we propose a novel deep Multiple-Attribute-Perceived Network (MAP-Net) by progressively learning visual texture attributes in a mutually reinforced manner. Specifically, a multi-branch network architecture is devised, in which cascaded global contexts are learned by introducing similarity constraint at each branch, and leveraged as guidance of spatial feature encoding at next branch through an attribute transfer scheme. To enhance the modeling capability of spatial transformation, a deformable pooling strategy is introduced to augment the spatial sampling with adaptive offsets to the global context, leading to perceive new visual attributes. An attribute fusion module is then introduced to jointly utilize the perceived visual attributes and the abstracted semantic concepts at each branch. Experimental results on the five most challenging texture recognition datasets have demonstrated the superiority of the proposed model against the state-of-the-arts.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",25.75,0.11244019138755984,0.30155502392344496,1,0.13580246913580246,0.0411522633744856,0.31718061674008813
2139,2186,2186,DPOD: 6D pose object detector and refiner,"In this paper we present a novel deep learning method for 3D object detection and 6D pose estimation from RGB images. Our method, named DPOD (Dense Pose Object Detector), estimates dense multi-class 2D-3D correspondence maps between an input image and available 3D models. Given the correspondences, a 6DoF pose is computed via PnP and RANSAC. An additional RGB pose refinement of the initial pose estimates is performed using a custom deep learning-based refinement scheme. Our results and comparison to a vast number of related works demonstrate that a large number of correspondences is beneficial for obtaining high-quality 6D poses both before and after refinement. Unlike other methods that mainly use real data for training and do not train on synthetic renderings, we perform evaluation on both synthetic and real training data demonstrating superior results before and after refinement when compared to all recent detectors. While being precise, the presented approach is still real-time capable.",60028673,Siemens AG,Munich,Germany,"['1712', '1707']",22.0,0.1472470238095238,0.4179315476190477,1,0.10795454545454546,0.03409090909090909,0.3630952380952381
2140,2187,2187,Spatialsense: An adversarially crowdsourced benchmark for spatial relation recognition,"Understanding the spatial relations between objects in images is a surprisingly challenging task. A chair may be 'behind' a person even if it appears to the left of the person in the image (depending on which way the person is facing). Two students that appear close to each other in the image may not in fact be 'next to' each other if there is a third student between them. We introduce SpatialSense, a dataset specializing in spatial relation recognition which captures a broad spectrum of such challenges, allowing for proper benchmarking of computer vision techniques. SpatialSense is constructed through adversarial crowdsourcing, in which human annotators are tasked with finding spatial relations that are difficult to predict using simple cues such as 2D spatial configuration or language priors. Adversarial crowdsourcing significantly reduces dataset bias and samples more interesting relations in the long tail compared to existing datasets. On SpatialSense, state-of-the-art recognition models perform comparably to simple baselines, suggesting that they rely on straightforward cues instead of fully reasoning about this complex task. The SpatialSense benchmark provides a path forward to advancing the spatial reasoning capabilities of computer vision systems. The dataset and code are available at https://github.com/princeton-vl/SpatialSense.",60003269,Princeton University,Princeton,United States,"['1712', '1707']",21.777777777777782,0.055113636363636365,0.4148538961038961,1,0.12162162162162163,0.02252252252252252,0.3333333333333333
2141,2188,2188,An improved CNN-based pneumoconiosis diagnosis method on X-ray chest film,"Pneumoconiosis is one of the most serious occupational diseases in China, which seriously endangers the health of most workers in dust environments. The diagnosis of pneumoconiosis is very complex and cumbersome, which relies mostly on doctor’s medical knowledge and clinical reading experiences of X-ray chest film. Traditional image processing approach has helped doctors to reduce the misdiagnosis but with lower accuracy. An improved CNN-based pneumoconiosis diagnosis method on X-ray chest films is proposed to predict pneumoconiosis disease. The CNN structure is decomposed from 5 × 5 convolution kernel into two 3 × 3 convolution kernels to optimize the execution. Compared with GoogLeNet, the proposed GoogLeNet-CF achieves higher accuracy and gives a good result in the diagnosis of pneumoconiosis disease.",60025761,Huazhong University of Science and Technology,Wuhan,China,['1700'],19.83333333333333,0.13933333333333334,0.5203333333333333,1,0.0948905109489051,0.058394160583941604,0.34615384615384615
2142,2189,2189,Attention bridging network for knowledge transfer,"The attention of a deep neural network obtained by back-propagating gradients can effectively explain the decision of the network. They can further be used to explicitly access to the network response to a specific pattern. Considering objects of the same category but from different domains share similar visual patterns, we propose to treat the network attention as a bridge to connect objects across domains. In this paper, we use knowledge from the source domain to guide the network's response to categories shared with the target domain. With weights sharing and domain adversary training, this knowledge can be successfully transferred by regularizing the network's response to the same category in the target domain. Specifically, we transfer the foreground prior from a simple single-label dataset to another complex multi-label dataset, leading to improvement of attention maps. Experiments about the weakly-supervised semantic segmentation task show the effectiveness of our method. Besides, we further explore and validate that the proposed method is able to improve the generalization ability of a classification network in domain adaptation and domain generalization settings.",60028628,Northeastern University,Boston,United States,"['1712', '1707']",21.875,0.10333333333333332,0.39380952380952383,1,0.1306532663316583,0.005025125628140704,0.23036649214659685
2143,2190,2190,A decoupled 3D facial shape model by adversarial training,"Data-driven generative 3D face models are used to compactly encode facial shape data into meaningful parametric representations. A desirable property of these models is their ability to effectively decouple natural sources of variation, in particular identity and expression. While factorized representations have been proposed for that purpose, they are still limited in the variability they can capture and may present modeling artifacts when applied to tasks such as expression transfer. In this work, we explore a new direction with Generative Adversarial Networks and show that they contribute to better face modeling performances, especially in decoupling natural factors, while also achieving more diverse samples. To train the model we introduce a novel architecture that combines a 3D generator with a 2D discriminator that leverages conventional CNNs, where the two components are bridged by a geometry mapping layer. We further present a training scheme, based on auxiliary classifiers, to explicitly disentangle identity and expression attributes. Through quantitative and qualitative results on standard face datasets, we illustrate the benefits of our model and demonstrate that it outperforms competing state of the art methods in terms of decoupling and diversity.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,"['1712', '1707']",26.57142857142857,0.1405143875732111,0.3757575757575757,1,0.1323529411764706,0.0196078431372549,0.2871287128712871
2144,2191,2191,Fog concentration grade judgment for meter reading based on SVM,"Robot reading energy meter devices automatically is a basic task for smart grid. Unfortunately, the predicted accuracy is influenced by environment dramatically. In order to solve the problem, we propose a method which can metric fog concentration in environment before meter reading. Moreover, based on the characteristics of image and fog influence, joint features and SVM are used to discriminate the concentration level of foggy image. Specially, Contrast feature and DFT feature are extracted as joint features to describe the foggy image and SVM is used to study and train the joint feature. Finally the fog concentration level is discriminated naturally. The experimental results demonstrate the effectiveness of proposed method in term of judging the meter image with five level.",60019533,Tianjin University,Tianjin,China,['1700'],17.142857142857142,0.03877551020408164,0.5913265306122449,1,0.13636363636363635,0.022727272727272728,0.24242424242424243
2145,2192,2192,Switchable whitening for deep representation learning,"Normalization methods are essential components in convolutional neural networks (CNNs). They either standardize or whiten data using statistics estimated in predefined sets of pixels. Unlike existing works that design normalization techniques for specific tasks, we propose Switchable Whitening (SW), which provides a general form unifying different whitening methods as well as standardization methods. SW learns to switch among these operations in an end-to-end manner. It has several advantages. First, SW adaptively selects appropriate whitening or standardization statistics for different tasks (see Fig.1), making it well suited for a wide range of tasks without manual design. Second, by integrating benefits of different normalizers, SW shows consistent improvements over its counterparts in various challenging benchmarks. Third, SW serves as a useful tool for understanding the characteristics of whitening and standardization techniques. We show that SW outperforms other alternatives on image classification (CIFAR-10/100, ImageNet), semantic segmentation (ADE20K, Cityscapes), domain adaptation (GTA5, Cityscapes), and image style transfer (COCO). For example, without bells and whistles, we achieve state-of-the-art performance with 45.33% mIoU on the ADE20K dataset.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",17.1,0.09558823529411764,0.3578431372549021,1,0.09417040358744394,0.08968609865470852,0.5165876777251185
2146,2193,2193,Implementation of marriage by indigenous law to yei tribe communities," Marriage is a sacred thing in determining a life partner so it must be decided together in the male family. In the implementation of Yei tribal marriages using traditional processions, national law processions, and religious law processions. The Yei tribe has a very thick history and traditional traditions and highly respects their customary law. the process of implementing Yei tribal marriages still uses customary processions combined with religious law so that there is a mixture of the implementation of marriages within the Yei tribal community. The purpose of this study is to study and analyze the implementation of marriage according to customary law in the Yei tribal community. The method used in this legal research is empirical juridical research methods using primary data and secondary data analyzed by descriptive analysis. The results showed that the process of implementing marriages according to customary law in the Yei tribal community is through marriage/application, the marriage process is carried out in a customary manner and then proceed with religion and state, after that it is closed with a custom event / traditional party",60112726,Universitas Musamus Merauke,Merauke,Indonesia,['1706'],25.857142857142854,0.005384615384615383,0.4005769230769231,0,0.10362694300518134,0.031088082901554404,0.21578947368421053
2147,2194,2194,AutoDispNet: Improving disparity estimation with AutoML,"Much research work in computer vision is being spent on optimizing existing network architectures to obtain a few more percentage points on benchmarks. Recent AutoML approaches promise to relieve us from this effort. However, they are mainly designed for comparatively small-scale classification tasks. In this work, we show how to use and extend existing AutoML techniques to efficiently optimize large-scale U-Net-like encoder-decoder architectures. In particular, we leverage gradient-based neural architecture search and Bayesian optimization for hyperparameter search. The resulting optimization does not require a large-scale compute cluster. We show results on disparity estimation that clearly outperform the manually optimized baseline and reach state-of-the-art performance.",60025641,Universität Freiburg im Breisgau,Freiburg im Breisgau,Germany,"['1712', '1707']",14.857142857142858,0.10416666666666666,0.275,1,0.15671641791044777,0.022388059701492536,0.3508771929824561
2148,2195,2195,Label-PEnet: Sequential label propagation and enhancement networks for weakly supervised instance segmentation,"Weakly-supervised instance segmentation aims to detect and segment object instances precisely, given image-level labels only. Unlike previous methods which are composed of multiple offline stages, we propose Sequential Label Propagation and Enhancement Networks (referred as Label-PEnet) that progressively transforms image-level labels to pixel-wise labels in a coarse-to-fine manner. We design four cascaded modules including multi-label classification, object detection, instance refinement and instance segmentation, which are implemented sequentially by sharing the same backbone. The cascaded pipeline is trained alternatively with a curriculum learning strategy that generalizes labels from high level images to low-level pixels gradually with increasing accuracy. In addition, we design a proposal calibration module to explore the ability of classification networks to find key pixels that identify object parts, which serves as a post validation strategy running in the inverse order. We evaluate the efficiency of our Label-PEnet in mining instance masks on standard benchmarks: PASCAL VOC 2007 and 2012. Experimental results show that Label-PEnet outperforms the state-of-art algorithms by a clear margin, and obtains comparable performance even with fully supervised approaches.",60113057,"Malong Technologies Co., Ltd.",Shenzhen,China,"['1712', '1707']",24.714285714285715,0.059333333333333335,0.4415000000000001,1,0.14285714285714285,0.059907834101382486,0.39267015706806285
2149,2196,2196,Performance-improved UCD-based hybrid precoding for millimeter-wave massive MIMO single user systems,"Hybrid precoding scheme can significantly reduce the number of radio frequency (RF) chains and the huge energy consumption in mmWave massive MIMO systems. Most existing hybrid precoding papers are based on singular value decomposition (SVD) or geometric mean decomposition (GMD). The GMD-based hybrid precoding scheme can avoid the complicated bit allocations in SVD-based method, because it decomposes the channel into several identical SNR subchannels. However, the GMD-based method will suffer from considerable capacity loss at low SNR in mmWave systems. To overcome this shortcoming, we can combine the hybrid precoding structure with uniform channel decomposition (UCD). In this paper, we propose the UCD-based hybrid precoding for mmWave massive MIMO single user systems. Simulation results verify that the proposed UCD-based hybrid precoding scheme outperforms the conventional SVD-based and GMD-based hybrid precoding schemes, because it achieves much higher spectral efficiency and lower bit error rate (BER) at low SNR systems.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],21.142857142857142,0.0427295918367347,0.5774234693877551,1,0.1358695652173913,0.07608695652173914,0.4117647058823529
2150,2197,2197,Global supply chain strategy in the cooperation of Russia and Tajikistan in the field of security in the early 21st century,"The article is devoted to the cooperation of the Russian Federation and the Republic of Tajikistan in the sphere of security in the period from 2000 to 2017. It explores the relations of the two states in the political and military-technical spheres in the context of Eurasian integration processes. Some economic, cultural and humanitarian aspects of cooperation are also considered, complementing the security policy with elements of ""soft power"". Particular attention is paid to bilateral meetings and political decisions of the presidents of Russia and Tajikistan. In addition, the influence of the Afghan factor on the situation in Tajikistan is revealed and Russia's policy on its neutralization is disclosed to ensure regional security.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],22.6,0.08095238095238096,0.16904761904761906,1,0.05555555555555555,0.06349206349206349,0.29838709677419356
2151,2198,2198,Learning to find common objects across few image collections,"Given a collection of bags where each bag is a set of images, our goal is to select one image from each bag such that the selected images are from the same object class. We model the selection as an energy minimization problem with unary and pairwise potential functions. Inspired by recent few-shot learning algorithms, we propose an approach to learn the potential functions directly from the data. Furthermore, we propose a fast greedy inference algorithm for energy minimization. We evaluate our approach on few-shot common object recognition as well as object co-localization tasks. Our experiments show that learning the pairwise and unary terms greatly improves the performance of the model over several well-known methods for these tasks. The proposed greedy optimization algorithm achieves performance comparable to state-of-the-art structured inference algorithms while being ∼10 times faster.",60019647,Georgia Institute of Technology,Atlanta,United States,"['1712', '1707']",19.428571428571427,0.08,0.5125,1,0.10625,0.0125,0.2534246575342466
2152,2199,2199,Patchwork: A patch-wise attention network for efficient object detection and segmentation in video streams,"Recent advances in single-frame object detection and segmentation techniques have motivated a wide range of works to extend these methods to process video streams. In this paper, we explore the idea of hard attention aimed for latency-sensitive applications. Instead of reasoning about every frame separately, our method selects and only processes a small sub-window of the frame. Our technique then makes predictions for the full frame based on the sub-windows from previous frames and the update from the current sub-window. The latency reduction by this hard attention mechanism comes at the cost of degraded accuracy. We made two contributions to address this. First, we propose a specialized memory cell that recovers lost context when processing sub-windows. Secondly, we adopt a Q-learning-based policy training strategy that enables our approach to intelligently select the sub-windows such that the staleness in the memory hurts the performance the least. Our experiments suggest that our approach reduces the latency by approximately four times without significantly sacrificing the accuracy on the ImageNet VID video object detection dataset and the DAVIS video object segmentation dataset. We further demonstrate that we can reinvest the saved computation into other parts of the network, and thus resulting in an accuracy increase at a comparable computational cost as the original system and beating other recently proposed state-of-the-art methods in the low latency range.",60006191,Google LLC,Mountain View,United States,"['1712', '1707']",22.2,0.004545454545454547,0.4731060606060607,1,0.11494252873563218,0.007662835249042145,0.25316455696202533
2153,2200,2200,Soft rasterizer: A differentiable renderer for image-based 3D reasoning,"Rendering bridges the gap between 2D vision and 3D scenes by simulating the physical process of image formation. By inverting such renderer, one can think of a learning approach to infer 3D information from 2D images. However, standard graphics renderers involve a fundamental discretization step called rasterization, which prevents the rendering process to be differentiable, hence able to be learned. Unlike the state-of-the-art differentiable renderers, which only approximate the rendering gradient in the back propagation, we propose a truly differentiable rendering framework that is able to (1) directly render colorized mesh using differentiable functions and (2) back-propagate efficient supervision signals to mesh vertices and their attributes from various forms of image representations, including silhouette, shading and color images. The key to our framework is a novel formulation that views rendering as an aggregation function that fuses the probabilistic contributions of all mesh triangles with respect to the rendered pixels. Such formulation enables our framework to flow gradients to the occluded and far-range vertices, which cannot be achieved by the previous state-of-the-arts. We show that by using the proposed renderer, one can achieve significant improvement in 3D unsupervised single-view reconstruction both qualitatively and quantitatively. Experiments also demonstrate that our approach is able to handle the challenging tasks in image-based shape fitting, which remain nontrivial to existing differentiable renderers. Code is available at https://github.com/ShichenLiu/SoftRas.",60029311,University of Southern California,Los Angeles,United States,"['1712', '1707']",24.66666666666667,0.1560185185185185,0.5255291005291006,1,0.14232209737827714,0.003745318352059925,0.3413654618473896
2154,2201,2201,Dual student: Breaking the limits of the teacher in semi-supervised learning,"Recently, consistency-based methods have achieved state-of-the-art results in semi-supervised learning (SSL). These methods always involve two roles, an explicit or implicit teacher model and a student model, and penalize predictions under different perturbations by a consistency constraint. However, the weights of these two roles are tightly coupled since the teacher is essentially an exponential moving average (EMA) of the student. In this work, we show that the coupled EMA teacher causes a performance bottleneck. To address this problem, we introduce Dual Student, which replaces the teacher with another student. We also define a novel concept, stable sample, following which a stabilization constraint is designed for our structure to be trainable. Further, we discuss two variants of our method, which produce even higher performance. Extensive experiments show that our method improves the classification performance significantly on several main SSL benchmarks. Specifically, it reduces the error rate of the 13-layer CNN from 16.84% to 12.39% on CIFAR-10 with 1k labels and from 34.10% to 31.56% on CIFAR-100 with 10k labels. In addition, our method also achieves a clear improvement in domain adaptation.",60013983,City University of Hong Kong,Kowloon,Hong Kong,"['1712', '1707']",18.0,0.015674603174603174,0.3321428571428572,1,0.09049773755656108,0.027149321266968326,0.3744075829383886
2155,2202,2202,CDPN: Coordinates-based disentangled pose network for real-time RGB-based 6-DoF object pose estimation,"6-DoF object pose estimation from a single RGB image is a fundamental and long-standing problem in computer vision. Current leading approaches solve it by training deep networks to either regress both rotation and translation from image directly or to construct 2D-3D correspondences and further solve them via PnP indirectly. We argue that rotation and translation should be treated differently for their significant difference. In this work, we propose a novel 6-DoF pose estimation approach: Coordinates-based Disentangled Pose Network (CDPN), which disentangles the pose to predict rotation and translation separately to achieve highly accurate and robust pose estimation. Our method is flexible, efficient, highly accurate and can deal with texture-less and occluded objects. Extensive experiments on LINEMOD and Occlusion datasets are conducted and demonstrate the superiority of our approach. Concretely, our approach significantly exceeds the state-of-the- art RGB-based methods on commonly used metrics.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",20.285714285714285,0.10989010989010987,0.5126373626373627,1,0.1301775147928994,0.03550295857988166,0.31210191082802546
2156,2203,2203,CFSNet: Toward a controllable feature space for image restoration,"Deep learning methods have witnessed the great progress in image restoration with specific metrics (e.g., PSNR, SSIM). However, the perceptual quality of the restored image is relatively subjective, and it is necessary for users to control the reconstruction result according to personal preferences or image characteristics, which cannot be done using existing deterministic networks. This motivates us to exquisitely design a unified interactive framework for general image restoration tasks. Under this framework, users can control continuous transition of different objectives, e.g., the perception-distortion trade-off of image super-resolution, the trade-off between noise reduction and detail preservation. We achieve this goal by controlling the latent features of the designed network. To be specific, our proposed framework, named Controllable Feature Space Network (CFSNet), is entangled by two branches based on different objectives. Our framework can adaptively learn the coupling coefficients of different layers and channels, which provides finer control of the restored image quality. Experiments on several typical image restoration tasks fully validate the effective benefits of the proposed method. Code is available at https://github.com/qibao77/CFSNet.",60027165,University of Rochester,Rochester,United States,"['1712', '1707']",19.11111111111111,0.16770833333333332,0.4812499999999999,1,0.13043478260869565,0.033816425120772944,0.38308457711442784
2157,2204,2204,HEMlets pose: Learning part-centric heatmap triplets for accurate 3D human pose estimation,"Estimating 3D human pose from a single image is a challenging task. This work attempts to address the uncertainty of lifting the detected 2D joints to the 3D space by introducing an intermediate state - Part-Centric Heatmap Triplets (HEMlets), which shortens the gap between the 2D observation and the 3D interpretation. The HEMlets utilize three joint-heatmaps to represent the relative depth information of the end-joints for each skeletal body part. In our approach, a Convolutional Network(ConvNet) is first trained to predict HEMlests from the input image, followed by a volumetric joint-heatmap regression. We leverage on the integral operation to extract the joint locations from the volumetric heatmaps, guaranteeing end-to-end learning. Despite the simplicity of the network design, the quantitative comparisons show a significant performance improvement over the best-of-grade method (by 20% on Human3.6M). The proposed method naturally supports training with 'in-the-wild'' images, where only weakly-annotated relative depth information of skeletal joints is available. This further improves the generalization ability of our model, as validated by qualitative comparisons on outdoor images.",60108865,"The Chinese University of Hong Kong, Shenzhen",Shenzhen,China,"['1712', '1707']",21.25,0.14123376623376627,0.43841991341991343,1,0.0967741935483871,0.041474654377880185,0.3711340206185567
2158,2205,2205,Semi-supervised monocular 3D face reconstruction with end-to-end shape-preserved domain transfer,"Monocular face reconstruction is a challenging task in computer vision, which aims to recover 3D face geometry from a single RGB face image. Recently, deep learning based methods have achieved great improvements on monocular face reconstruction. However, for deep learning-based methods to reach optimal performance, it is paramount to have large-scale training images with ground-truth 3D face geometry, which is generally difficult for human to annotate. To tackle this problem, we propose a semi-supervised monocular reconstruction method, which jointly optimizes a shape-preserved domain-transfer CycleGAN and a shape estimation network. The framework is semi-supervised trained with 3D rendered images with ground-truth shapes and in-the-wild face images without any extra annotation. The CycleGAN network transforms all realistic images to have the rendered style and is end-to-end trained within the overall framework. This is the key difference compared with existing CycleGAN-based learning methods, which just used CycleGAN as a separate training sample generator. Novel landmark consistency loss and edge-aware shape estimation loss are proposed for our two networks to jointly solve the challenging face reconstruction problem. Extensive experiments on public face reconstruction datasets demonstrate the effectiveness of our overall method as well as the individual components.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",21.444444444444443,0.08720238095238095,0.4436011904761905,1,0.10504201680672269,0.012605042016806723,0.319047619047619
2159,2206,2206,Local supports global: Deep camera relocalization with sequence enhancement,"We propose to leverage the local information in a image sequence to support global camera relocalization. In contrast to previous methods that regress global poses from single images, we exploit the spatial-temporal consistency in sequential images to alleviate uncertainty due to visual ambiguities by incorporating a visual odometry (VO) component. Specifically, we introduce two effective steps called content-augmented pose estimation and motion-based refinement. The content-augmentation step focuses on alleviating the uncertainty of pose estimation by augmenting the observation based on the co-visibility in local maps built by the VO stream. Besides, the motion-based refinement is formulated as a pose graph, where the camera poses are further optimized by adopting relative poses provided by the VO component as additional motion constraints. Thus, the global consistency can be guaranteed. Experiments on the public indoor 7-Scenes and outdoor Oxford RobotCar benchmark datasets demonstrate that benefited from local information inherent in the sequence, our approach outperforms state-of-the-art methods, especially in some challenging cases, e.g., insufficient texture, highly repetitive textures, similar appearances, and over-exposure.",60014966,Peking University,Beijing,China,"['1712', '1707']",24.142857142857146,0.0256265664160401,0.25119047619047624,1,0.12380952380952381,0.023809523809523808,0.3684210526315789
2160,2207,2207,Uncertainty modeling of contextual-connections between tracklets for unconstrained video-based face recognition,"Unconstrained video-based face recognition is a challenging problem due to significant within-video variations caused by pose, occlusion and blur. To tackle this problem, an effective idea is to propagate the identity from high-quality faces to low-quality ones through contextual connections, which are constructed based on context such as body appearance. However, previous methods have often propagated erroneous information due to lack of uncertainty modeling of the noisy contextual connections. In this paper, we propose the Uncertainty-Gated Graph (UGG), which conducts graph-based identity propagation between tracklets, which are represented by nodes in a graph. UGG explicitly models the uncertainty of the contextual connections by adaptively updating the weights of the edge gates according to the identity distributions of the nodes during inference. UGG is a generic graphical model that can be applied at only inference time or with end-to-end training. We demonstrate the effectiveness of UGG with state-of-the-art results in the recently released challenging Cast Search in Movies and IARPA Janus Surveillance Video Benchmark dataset.",60113260,"Academia Sinica, Research Center for Information Technology Innovation",Taipei,Taiwan,"['1712', '1707']",23.42857142857143,0.08819444444444445,0.5784722222222222,1,0.09405940594059406,0.06435643564356436,0.36666666666666664
2161,2208,2208,Micro-baseline structured light,"We propose Micro-baseline Structured Light (MSL), a novel 3D imaging approach designed for small form-factor devices such as cell-phones and miniature robots. MSL operates with small projector-camera baseline and low-cost projection hardware, and can recover scene depths with computationally lightweight algorithms. The main observation is that a small baseline leads to small disparities, enabling a first-order approximation of the non-linear SL image formation model. This leads to the key theoretical result of the paper: The MSL equation, a linearized version of SL image formation. MSL equation is under-constrained due to two unknowns (depth and albedo) at each pixel, but can be efficiently solved using a local least squares approach. We analyze the performance of MSL in terms of various system parameters such as projected pattern and baseline, and provide guidelines for optimizing performance. Armed with these insights, we build a prototype to experimentally examine the theory and its practicality.",60120916,Snap Inc.,Santa Monica,United States,"['1712', '1707']",21.285714285714285,-0.05055555555555556,0.4272222222222222,1,0.10326086956521739,0.04891304347826087,0.39880952380952384
2162,2209,2209,Learning relationships for multi-view 3D object recognition,"Recognizing 3D object has attracted plenty of attention recently, and view-based methods have achieved best results until now. However, previous view-based methods ignore the region-to-region and view-to-view relationships between different view images, which are crucial for multi-view 3D object representation. To tackle this problem, we propose a Relation Network to effectively connect corresponding regions from different viewpoints, and therefore reinforce the information of individual view image. In addition, the Relation Network exploits the inter-relationships over a group of views, and integrates those views to obtain a discriminative 3D object representation. Systematic experiments conducted on ModelNet dataset demonstrate the effectiveness of our proposed methods for both 3D object recognition and retrieval tasks.",60014966,Peking University,Beijing,China,"['1712', '1707']",22.2,0.17916666666666667,0.5145833333333333,1,0.1366906474820144,0.03597122302158273,0.42276422764227645
2163,2210,2210,AttentionRNN: A structured spatial attention mechanism,"Visual attention mechanisms have proven to be integrally important constituent components of many modern deep neural architectures. They provide an efficient and effective way to utilize visual information selectively, which has shown to be especially valuable in multi-modal learning tasks. However, all prior attention frameworks lack the ability to explicitly model structural dependencies among attention variables, making it difficult to predict consistent attention masks. In this paper we develop a novel structured spatial attention mechanism which is end-to-end trainable and can be integrated with any feed-forward convolutional neural network. This proposed AttentionRNN layer explicitly enforces structure over the spatial attention variables by sequentially predicting attention values in the spatial mask in a bi-directional raster-scan and inverse raster-scan order. As a result, each attention value depends not only on local image or contextual information, but also on the previously predicted attention values. Our experiments show consistent quantitative and qualitative improvements on a variety of recognition tasks and datasets; including image categorization, question answering and image generation.",60010365,The University of British Columbia,Vancouver,Canada,"['1712', '1707']",23.57142857142857,0.10222222222222224,0.4444444444444445,1,0.09326424870466321,0.0,0.2849162011173184
2164,2211,2211,Quadratic Padé approximation: Numerical aspects and applications," A. C. WeidemanPadé approximation is a useful tool for extracting singularity information from a power series. A linear Padé approximant is a rational function and can provide estimates of pole and zero locations in the complex plane. A quadratic Padé approximant has square root singularities and can, therefore, provide additional information such as estimates of branch point locations. In this paper, we discuss numerical aspects of computing quadratic Padé approximants as well as some applications. Two algorithms for computing the coefficients in the approximant are discussed: a direct method involving the solution of a linear system (well-known in the mathematics community) and a recursive method (well-known in the physics community). We compare the accuracy of these two methods when implemented in floating-point arithmetic and discuss their pros and cons. In addition, we extend Luke’s perturbation analysis of linear Padé approximation to the quadratic case and identify the problem of spurious branch points in the quadratic approximant, which can cause a significant loss of accuracy. A possible remedy for this problem is suggested by noting that these troublesome points can be identified by the recursive method mentioned above. Another complication with the quadratic approximant arises in choosing the appropriate branch. One possibility, which is to base this choice on the linear approximant, is discussed in connection with an example due to Stahl. It is also known that the quadratic method is capable of providing reasonable approximations on secondary sheets of the Riemann surface, a fact we illustrate here by means of an example. Two concluding applications show the superiority of the quadratic approximant over its linear counterpart: one involving a special function (the Lambert W-function) and the other a nonlinear PDE (the continuation of a solution of the inviscid Burgers equation into the complex plane).",60010818,University of Kent,Canterbury,United Kingdom,"['1706', '1703']",21.071428571428573,0.0051339285714285705,0.4872767857142857,0,0.10479041916167664,0.04790419161676647,0.2883435582822086
2165,2212,2212,From strings to things: Knowledge-enabled VQA model that can read and reason,"Text present in images are not merely strings, they provide useful cues about the image. Despite their utility in better image understanding, scene texts are not used in traditional visual question answering (VQA) models. In this work, we present a VQA model which can read scene texts and perform reasoning on a knowledge graph to arrive at an accurate answer. Our proposed model has three mutually interacting modules: I. proposal module to get word and visual content proposals from the image, ii. fusion module to fuse these proposals, question and knowledge base to mine relevant facts, and represent these facts as multi-relational graph, iii. reasoning module to perform a novel gated graph neural network based reasoning on this graph. The performance of our knowledge-enabled VQA model is evaluated on our newly introduced dataset, viz. text-KVQA. To the best of our knowledge, this is the first dataset which identifies the need for bridging text recognition with knowledge graph based reasoning. Through extensive experiments, we show that our proposed method outperforms traditional VQA as well as question-answering over knowledge base-based methods on text-KVQA.",60104343,Indian Institute of Technology Jodhpur,Jodhpur,India,"['1712', '1707']",16.454545454545453,0.15227272727272728,0.4034090909090908,1,0.12962962962962962,0.041666666666666664,0.3284313725490196
2166,2213,2213,How do neural networks see depth in single images?,"Deep neural networks have lead to a breakthrough in depth estimation from single images. Recent work shows that the quality of these estimations is rapidly increasing. It is clear that neural networks can see depth in single images. However, to the best of our knowledge, no work currently exists that analyzes what these networks have learned. In this work we take four previously published networks and investigate what depth cues they exploit. We find that all networks ignore the apparent size of known obstacles in favor of their vertical position in the image. The use of the vertical position requires the camera pose to be known; however, we find that these networks only partially recognize changes in camera pitch and roll angles. Small changes in camera pitch are shown to disturb the estimated distance towards obstacles. The use of the vertical image position allows the networks to estimate depth towards arbitrary obstacles - even those not appearing in the training set - but may depend on features that are not universally present.",60006288,Delft University of Technology,Delft,Netherlands,"['1712', '1707']",19.11111111111111,0.014145658263305327,0.2928571428571428,1,0.16216216216216217,0.0,0.2594594594594595
2167,2214,2214,A random-based approach to social influence maximization,"The problem of influence maximization is to find a small subset of nodes (seed nodes) as influential as the global optimum in a social network. Despite researchers have achieved fruitful research result which can be applied widely, a key limitation still remains, and that is this work is generally too time consuming to find seeds and difficult to be apply into the large-scale social network. In this paper, we propose a new random-based algorithm which combines “random selection” and “the optimal neighbor”, which idea both greatly reduces the computational complexity and achieves the desired effect. Our algorithm is able to avoid overlapped information and thus determine high-quality seed set for the influence maximization problem. Our empirical study with real-world social networks under independent cascade model (ICM) demonstrates that our algorithm significantly outperforms the common used algorithms in terms of efficiency and scalability, with almost no compromise of effectiveness.",60002210,Shandong Normal University,Jinan,China,['1700'],29.6,0.07125668449197861,0.4664438502673796,1,0.12643678160919541,0.017241379310344827,0.25301204819277107
2168,2215,2215,Enriched feature guided refinement network for object detection,"We propose a single-stage detection framework that jointly tackles the problem of multi-scale object detection and class imbalance. Rather than designing deeper networks, we introduce a simple yet effective feature enrichment scheme to produce multi-scale contextual features. We further introduce a cascaded refinement scheme which first instills multi-scale contextual features into the prediction layers of the single-stage detector in order to enrich their discriminative power for multi-scale detection. Second, the cascaded refinement scheme counters the class imbalance problem by refining the anchors and enriched features to improve classification and regression. Experiments are performed on two benchmarks: PASCAL VOC and MS COCO. For a 320×320 input on the MS COCO test-dev, our detector achieves state-of-the-art single-stage detection accuracy with a COCO AP of 33.2 in the case of single-scale inference, while operating at 21 milliseconds on a Titan XP GPU. For a 512×512 input on the MS COCO test-dev, our approach obtains an absolute gain of 1.6% in terms of COCO AP, compared to the best reported single-stage results[5]. Source code and models are available at: Https://github.com/Ranchentx/EFGRNet.",60019533,Tianjin University,Tianjin,China,"['1712', '1707']",22.0,0.30625,0.44880952380952377,1,0.09009009009009009,0.07657657657657657,0.41919191919191917
2169,2216,2216,Monocular neural image based rendering with continuous view control,"We propose a method to produce a continuous stream of novel views under fine-grained (e.g., 1 degree step-size) camera control at interactive rates. A novel learning pipeline determines the output pixels directly from the source color. Injecting geometric transformations, including perspective projection, 3D rotation and translation into the network forces implicit reasoning about the underlying geometry. The latent 3D geometry representation is compact and meaningful under 3D transformation, being able to produce geometrically accurate views for both single objects and natural scenes. Our experiments show that both proposed components, the transforming encoder-decoder and depth-guided appearance mapping, lead to significantly improved generalization beyond the training views and in consequence to more accurate view synthesis under continuous 6-DoF camera control. Finally, we show that our method outperforms state-of-the-art baseline methods on public datasets.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",21.83333333333333,0.2548701298701299,0.5316017316017315,1,0.10625,0.0,0.3424657534246575
2170,2217,2217,Skeleton-aware 3D human shape reconstruction from point clouds,"This work addresses the problem of 3D human shape reconstruction from point clouds. Considering that human shapes are of high dimensions and with large articulations, we adopt the state-of-the-art parametric human body model, SMPL, to reduce the dimension of learning space and generate smooth and valid reconstruction. However, SMPL parameters, especially pose parameters, are not easy to learn because of ambiguity and locality of the pose representation. Thus, we propose to incorporate skeleton awareness into the deep learning based regression of SMPL parameters for 3D human shape reconstruction. Our basic idea is to use the state-of-the-art technique PointNet++ to extract point features, and then map point features to skeleton joint features and finally to SMPL parameters for the reconstruction from point clouds. Particularly, we develop an end-to-end framework, where we propose a graph aggregation module to augment PointNet++ by extracting better point features, an attention module to better map unordered point features into ordered skeleton joint features, and a skeleton graph module to extract better joint features for SMPL parameter regression. The entire framework network is first trained in an end-to-end manner on synthesized dataset, and then online fine-tuned on unseen dataset with unsupervised loss to bridges gaps between training and testing. The experiments on multiple datasets show that our method is on par with the state-of-the-art solution.",60019578,Monash University,Melbourne,Australia,"['1712', '1707']",27.25,0.13022556390977444,0.4220300751879699,1,0.09363295880149813,0.026217228464419477,0.28451882845188287
2171,2218,2218,Sequential latent spaces for modeling the intention during diverse image captioning,"Diverse and accurate vision+language modeling is an important goal to retain creative freedom and maintain user engagement. However, adequately capturing the intricacies of diversity in language models is challenging. Recent works commonly resort to latent variable models augmented with more or less supervision from object detectors or part-of-speech tags. In common to all those methods is the fact that the latent variable either only initializes the sentence generation process or is identical across the steps of generation. Both methods offer no fine-grained control. To address this concern, we propose Seq-CVAE which learns a latent space for every word. We encourage this temporal latent space to capture the 'intention' about how to complete the sentence by mimicking a representation which summarizes the future. We illustrate the efficacy of the proposed approach on the challenging MSCOCO dataset, significantly improving diversity metrics compared to baselines while performing on par w.r.t. sentence quality.",60019647,Georgia Institute of Technology,Atlanta,United States,"['1712', '1707']",16.555555555555557,0.18944444444444444,0.6122222222222222,1,0.13450292397660818,0.04678362573099415,0.2962962962962963
2172,2219,2219,DUAL-GLOW: Conditional flow-based generative model for modality transfer,"Positron emission tomography (PET) imaging is an imaging modality for diagnosing a number of neurological diseases. In contrast to Magnetic Resonance Imaging (MRI), PET is costly and involves injecting a radioactive substance into the patient. Motivated by developments in modality transfer in vision, we study the generation of certain types of PET images from MRI data. We derive new flow-based generative models which we show perform well in this small sample size regime (much smaller than dataset sizes available in standard vision tasks). Our formulation, DUAL-GLOW, is based on two invertible networks and a relation network that maps the latent spaces to each other. We discuss how given the prior distribution, learning the conditional distribution of PET given the MRI image reduces to obtaining the conditional distribution between the two latent codes w.r.t. the two image types. We also extend our framework to leverage ''side'' information (or attributes) when available. By controlling the PET generation through ''conditioning'' on age, our model is also able to capture brain FDG-PET (hypometabolism) changes, as a function of age. We present experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset with 826 subjects, and obtain good performance in PET image synthesis, qualitatively and quantitatively better than recent works.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",20.4,0.17683209647495365,0.362569573283859,1,0.104,0.084,0.39166666666666666
2173,2220,2220,Self-supervised representation learning from multi-domain data,"We present an information-theoretically motivated constraint for self-supervised representation learning from multiple related domains. In contrast to previous self-supervised learning methods, our approach learns from multiple domains, which has the benefit of decreasing the build-in bias of individual domain, as well as leveraging information and allowing knowledge transfer across multiple domains. The proposed mutual information constraints encourage neural network to extract common invariant information across domains and to preserve peculiar information of each domain simultaneously. We adopt tractable upper and lower bounds of mutual information to make the proposed constraints solvable. The learned representation is more unbiased and robust toward the input images. Extensive experimental results on both multi-domain and large-scale datasets demonstrate the necessity and advantage of multi-domain self-supervised learning with mutual information constraints. Representations learned in our framework on state-of-the-art methods achieve improved performance than those learned on a single domain.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",20.428571428571427,0.0047619047619047615,0.2241758241758242,1,0.12571428571428572,0.0,0.29411764705882354
2174,2221,2221,AGSS-VOS: Attention guided single-shot video object segmentation,"Most video object segmentation approaches process objects separately. This incurs high computational cost when multiple objects exist. In this paper, we propose AGSS-VOS to segment multiple objects in one feed-forward path via instance-agnostic and instance-specific modules. Information from the two modules is fused via an attention-guided decoder to simultaneously segment all object instances in one path. The whole framework is end-to-end trainable with instance IoU loss. Experimental results on Youtube- VOS and DAVIS-2017 dataset demonstrate that AGSS-VOS achieves competitive results in terms of both accuracy and efficiency.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",14.5,0.16,0.30666666666666664,1,0.10909090909090909,0.05454545454545454,0.39361702127659576
2175,2223,2223,Solving vision problems via filtering,"We propose a new, filtering approach for solving a large number of regularized inverse problems commonly found in computer vision. Traditionally, such problems are solved by finding the solution to the system of equations that expresses the first-order optimality conditions of the problem. This can be slow if the system of equations is dense due to the use of nonlocal regularization, necessitating iterative solvers such as successive over-relaxation or conjugate gradients. In this paper, we show that similar solutions can be obtained more easily via filtering, obviating the need to solve a potentially dense system of equations using slow iterative methods. Our filtered solutions are very similar to the true ones, but often up to 10 times faster to compute.",60028333,University of New South Wales (UNSW) Australia,Sydney,Australia,"['1712', '1707']",24.0,0.043498763141620274,0.532960729746444,1,0.11851851851851852,0.0,0.31297709923664124
2176,2224,2224,"FAMNet: Joint learning of feature, affinity and multi-dimensional assignment for online multiple object tracking","Data association-based multiple object tracking (MOT) involves multiple separated modules processed or optimized differently, which results in complex method design and requires non-trivial tuning of parameters. In this paper, we present an end-to-end model, named FAMNet, where Feature extraction, Affinity estimation and Multi-dimensional assignment are refined in a single network. All layers in FAMNet are designed differentiable thus can be optimized jointly to learn the discriminative features and higher-order affinity model for robust MOT, which is supervised by the loss directly from the assignment ground truth. In addition, we integrate single object tracking technique and a dedicated target management scheme into the FAMNet-based tracking system to further recover false negatives and inhibit noisy target candidates generated by the external detector. The proposed method is evaluated on a diverse set of benchmarks including MOT2015, MOT2017, KITTI-Car and UA-DETRAC, and achieves promising performance on all of them in comparison with state-of-the-arts.",60030398,Temple University,Philadelphia,United States,"['1712', '1707']",29.8,-0.04523809523809525,0.29404761904761906,1,0.12105263157894737,0.06842105263157895,0.3795180722891566
2177,2225,2225,NOTE-RCNN: Noise tolerant ensemble RCNN for semi-supervised object detection,"The labeling cost of large number of bounding boxes is one of the main challenges for training modern object detectors. To reduce the dependence on expensive bounding box annotations, we propose a new semi-supervised object detection formulation, in which a few seed box level annotations and a large scale of image level annotations are used to train the detector. We adopt a training-mining framework, which is widely used in weakly supervised object detection tasks. However, the mining process inherently introduces various kinds of labelling noises: False negatives, false positives and inaccurate boundaries, which can be harmful for training the standard object detectors (e.g. Faster RCNN). We propose a novel NOise Tolerant Ensemble RCNN (NOTE-RCNN) object detector to handle such noisy labels. Comparing to standard Faster RCNN, it contains three highlights: An ensemble of two classification heads and a distillation head to avoid overfitting on noisy labels and improve the mining precision, masking the negative sample loss in box predictor to avoid the harm of false negative labels, and training box regression head only on seed annotations to eliminate the harm from inaccurate boundaries of mined bounding boxes. We evaluate the methods on ILSVRC 2013 and MSCOCO 2017 dataset; we observe that the detection accuracy consistently improves as we iterate between mining and training steps, and state-of-the-art performance is achieved.",60029311,University of Southern California,Los Angeles,United States,"['1712', '1707']",27.375,-0.08966991341991344,0.4310010822510823,1,0.10980392156862745,0.03137254901960784,0.3401639344262295
2178,2226,2226,Not all parts are created equal: 3D pose estimation by modeling bi-directional dependencies of body parts,"Not all the human body parts have the same degree of freedom (DOF) due to the physiological structure. For example, the limbs may move more flexibly and freely than the torso does. Most of the existing 3D pose estimation methods, despite the very promising results achieved, treat the body joints equally and consequently often lead to larger reconstruction errors on the limbs. In this paper, we propose a progressive approach that explicitly accounts for the distinct DOFs among the body parts. We model parts with higher DOFs like the elbows, as dependent components of the corresponding parts with lower DOFs like the torso, of which the 3D locations can be more reliably estimated. Meanwhile, the high-DOF parts may, in turn, impose a constraint on where the low-DOF ones lie. As a result, parts with different DOFs supervise one another, yielding physically constrained and plausible pose-estimation results. To further facilitate the prediction of the high-DOF parts, we introduce a pose-attribution estimation, where the relative location of a limb joint with respect to the torso, which has the least DOF of a human body, is explicitly estimated and further fed to the joint-estimation module. The proposed approach achieves very promising results, outperforming the state of the art on several benchmarks.",60027392,Stevens Institute of Technology,Hoboken,United States,"['1712', '1707']",23.11111111111111,0.1384090909090909,0.38603896103896107,1,0.09716599190283401,0.008097165991902834,0.3276595744680851
2179,2227,2227,Is this the right place? geometric-semantic pose verification for indoor visual localization,"Visual localization in large and complex indoor scenes, dominated by weakly textured rooms and repeating geometric patterns, is a challenging problem with high practical relevance for applications such as Augmented Reality and robotics. To handle the ambiguities arising in this scenario, a common strategy is, first, to generate multiple estimates for the camera pose from which a given query image was taken. The pose with the largest geometric consistency with the query image, e.g., in the form of an inlier count, is then selected in a second stage. While a significant amount of research has concentrated on the first stage, there has been considerably less work on the second stage. In this paper, we thus focus on pose verification. We show that combining different modalities, namely appearance, geometry, and semantics, considerably boosts pose verification and consequently pose accuracy. We develop multiple hand-crafted as well as a trainable approach to join into the geometric-semantic verification and show significant improvements over state-of-the-art on a very challenging indoor dataset.",60031126,Tokyo Institute of Technology,Tokyo,Japan,"['1712', '1707']",23.714285714285715,0.08663095238095238,0.426345238095238,1,0.10152284263959391,0.01015228426395939,0.27807486631016043
2180,2228,2228,Unsupervised 3D reconstruction networks,"In this paper, we propose 3D unsupervised reconstruction networks (3D-URN), which reconstruct the 3D structures of instances in a given object category from their 2D feature points under an orthographic camera model. 3D-URN consists of a 3D shape reconstructor and a rotation estimator, which are trained in a fully-unsupervised manner incorporating the proposed unsupervised loss functions. The role of the 3D shape reconstructor is to reconstruct the 3D shape of an instance from its 2D feature points, and the rotation estimator infers the camera pose. After training, 3D-URN can infer the 3D structure of an unseen instance in the same category, which is not possible in the conventional schemes of non-rigid structure from motion and structure from category. The experimental result shows the state-of-the-art performance, which demonstrates the effectiveness of the proposed method.",60120116,Automation and Systems Research Institute,Seoul,South Korea,"['1712', '1707']",26.6,-0.010714285714285713,0.4705357142857143,1,0.10429447852760736,0.024539877300613498,0.29931972789115646
2181,2229,2229,Automatic and robust skull registration based on discrete uniformization,"Skull registration plays a fundamental role in forensic science and is crucial for craniofacial reconstruction. The complicated topology, lack of anatomical features, and low quality reconstructed mesh make skull registration challenging. In this work, we propose an automatic skull registration method based on the discrete uniformization theory, which can handle complicated topologies and is robust to low quality meshes. We apply dynamic Yamabe flow to realize discrete uniformization, which modifies the mesh combinatorial structure during the flow and conformally maps the multiply connected skull surface onto a planar disk with circular holes. The 3D surfaces can be registered by matching their planar images using harmonic maps. This method is rigorous with theoretic guarantee, automatic without user intervention, and robust to low mesh quality. Our experimental results demonstrate the efficiency and efficacy of the method.",60030434,Qingdao University,Qingdao,China,"['1712', '1707']",19.142857142857142,-0.04,0.5466666666666666,1,0.12162162162162163,0.006756756756756757,0.23648648648648649
2182,2230,2230,Geometry normalization networks for accurate scene text detection,"Large geometry (e.g., orientation) variances are the key challenges in the scene text detection. In this work, we first conduct experiments to investigate the capacity of networks for learning geometry variances on detecting scene texts, and find that networks can handle only limited text geometry variances. Then, we put forward a novel Geometry Normalization Module (GNM) with multiple branches, each of which is composed of one Scale Normalization Unit and one Orientation Normalization Unit, to normalize each text instance to one desired canonical geometry range through at least one branch. The GNM is general and readily plugged into existing convolutional neural network based text detectors to construct end-to-end Geometry Normalization Networks (GNNets). Moreover, we propose a geometry-aware training scheme to effectively train the GNNets by sampling and augmenting text instances from a uniform geometry variance distribution. Finally, experiments on popular benchmarks of ICDAR 2015 and ICDAR 2017 MLT validate that our method outperforms all the state-of-the-art approaches remarkably by obtaining one-forward test F-scores of 88.52 and 74.54 respectively.",60025761,Huazhong University of Science and Technology,Wuhan,China,"['1712', '1707']",28.0,0.16377551020408165,0.5610544217687075,1,0.10784313725490197,0.09803921568627451,0.3882978723404255
2183,2231,2231,No fear of the dark: Image retrieval under varying illumination conditions,"Image retrieval under varying illumination conditions, such as day and night images, is addressed by image preprocessing, both hand-crafted and learned. Prior to extracting image descriptors by a convolutional neural network, images are photometrically normalised in order to reduce the descriptor sensitivity to illumination changes. We propose a learnable normalisation based on the U-Net architecture, which is trained on a combination of single-camera multi-exposure images and a newly constructed collection of similar views of landmarks during day and night. We experimentally show that both hand-crafted normalisation based on local histogram equalisation and the learnable normalisation outperform standard approaches in varying illumination conditions, while staying on par with the state-of-the-art methods on daylight illumination benchmarks, such as Oxford or Paris datasets.",60013323,Ceské vysoké ucení technické v Praze,Prague,Czech Republic,"['1712', '1707']",30.0,0.029545454545454545,0.2818181818181818,1,0.10884353741496598,0.02040816326530612,0.35877862595419846
2184,2233,2233,Correlation congruence for knowledge distillation,"Most teacher-student frameworks based on knowledge distillation (KD) depend on a strong congruent constraint on instance level. However, they usually ignore the correlation between multiple instances, which is also valuable for knowledge transfer. In this work, we propose a new framework named correlation congruence for knowledge distillation (CCKD), which transfers not only the instance-level information but also the correlation between instances. Furthermore, a generalized kernel method based on Taylor series expansion is proposed to better capture the correlation between instances. Empirical experiments and ablation studies on image classification tasks (including CIFAR-100, ImageNet-1K) and metric learning tasks (including ReID and Face Recognition) show that the proposed CCKD substantially outperforms the original KD and other SOTA KD-based methods. The CCKD can be easily deployed in the majority of the teacher-student framework such as KD and hint-based learning methods.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",22.66666666666667,0.1752525252525253,0.4996843434343434,1,0.11377245508982035,0.08383233532934131,0.38461538461538464
2185,2234,2234,Market analysis of financial institutions and entrepreneurship in India,"The purpose of this research is to investigate early-s.tage ease/difficulties faced by Start-Ups /MSME in India. The research is based in Bengaluru, Karnataka, India, five major banks located in the city were approached. The amount of support offered by banks to open a business bank account was investigated through interaction with representatives. It was found that banks offered several services at low charges and minimum requirements to ease the burden on new businesses. However, financial institutions do not offer early-stage funding, this made the new businesses struggle to gain initial working capital.",60011664,University of Wollongong,Wollongong,Australia,['1706'],18.4,0.04190340909090909,0.2761363636363636,1,0.1388888888888889,0.05555555555555555,0.3431372549019608
2186,2235,2235,Semantic stereo matching with pyramid cost volumes,"The accuracy of stereo matching has been greatly improved by using deep learning with convolutional neural networks. To further capture the details of disparity maps, in this paper, we propose a novel semantic stereo network named SSPCV-Net, which includes newly designed pyramid cost volumes for describing semantic and spatial information on multiple levels. The semantic features are inferred by a semantic segmentation subnetwork while the spatial features are derived by hierarchical spatial pooling. In the end, we design a 3D multi-cost aggregation module to integrate the extracted multilevel features and perform regression for accurate disparity maps. We conduct comprehensive experiments and comparisons with some recent stereo matching networks on Scene Flow, KITTI 2015 and 2012, and Cityscapes benchmark datasets, and the results show that the proposed SSPCV-Net significantly promotes the state-of-the-art stereo-matching performance.",60029306,Wuhan University,Wuhan,China,"['1712', '1707']",26.6,0.21392045454545452,0.4828598484848485,1,0.12578616352201258,0.050314465408805034,0.3724137931034483
2187,2236,2236,Normalized wasserstein for mixture distributions with applications in adversarial learning and domain adaptation,"Understanding proper distance measures between distributions is at the core of several learning tasks such as generative models, domain adaptation, clustering, etc. In this work, we focus on mixture distributions that arise naturally in several application domains where the data contains different sub-populations. For mixture distributions, established distance measures such as the Wasserstein distance do not take into account imbalanced mixture proportions. Thus, even if two mixture distributions have identical mixture components but different mixture proportions, the Wasserstein distance between them will be large. This often leads to undesired results in distance-based learning methods for mixture distributions. In this paper, we resolve this issue by introducing the Normalized Wasserstein measure. The key idea is to introduce mixture proportions as optimization variables, effectively normalizing mixture proportions in the Wasserstein formulation. Using the proposed normalized Wasserstein measure leads to significant performance gains for mixture distributions with imbalanced mixture proportions compared to the vanilla Wasserstein distance. We demonstrate the effectiveness of the proposed measure in GANs, domain adaptation and adversarial clustering in several benchmark datasets.",124081444,University of Maryland,Salisbury,United States,"['1712', '1707']",19.11111111111111,0.09910714285714284,0.4502976190476191,1,0.09743589743589744,0.035897435897435895,0.3717277486910995
2188,2237,2237,Attentional feature-pair relation networks for accurate face recognition,"Human face recognition is one of the most important research areas in biometrics. However, the robust face recognition under a drastic change of the facial pose, expression, and illumination is a big challenging problem for its practical application. Such variations make face recognition more difficult. In this paper, we propose a novel face recognition method, called Attentional Feature-pair Relation Network (AFRN), which represents the face by the relevant pairs of local appearance block features with their attention scores. The AFRN represents the face by all possible pairs of the 9x9 local appearance block features, the importance of each pair is considered by the attention map that is obtained from the low-rank bilinear pooling, and each pair is weighted by its corresponding attention score. To increase the accuracy, we select top-K pairs of local appearance block features as relevant facial information and drop the remaining irrelevant. The weighted top-K pairs are propagated to extract the joint feature-pair relation by using bilinear attention network. In experiments, we show the effectiveness of the proposed AFRN and achieve the outstanding performance in the 1:1 face verification and 1:N face identification tasks compared to existing state-of-the-art methods on the challenging LFW, YTF, CALFW, CPLFW, CFP, AgeDB, IJB-A, IJB-B, and IJB-C datasets.",60121136,Kakao Corp.,Jeju,South Korea,"['1712', '1707']",25.75,0.14210526315789473,0.5460526315789473,1,0.08914728682170543,0.07364341085271318,0.3644067796610169
2189,2238,2238,Unsupervised neural quantization for compressed-domain similarity search,"We tackle the problem of unsupervised visual descriptors compression, which is a key ingredient of large-scale image retrieval systems. While the deep learning machinery has benefited literally all computer vision pipelines, the existing state-of-the-art compression methods employ shallow architectures, and we aim to close this gap by our paper. In more detail, we introduce a DNN architecture for the unsupervised compressed-domain retrieval, based on multi-codebook quantization. The proposed architecture is designed to incorporate both fast data encoding and efficient distances computation via lookup tables. We demonstrate the exceptional advantage of our scheme over existing quantization approaches on several datasets of visual descriptors via outperforming the previous state-of-the-art by a large margin.",60020513,National Research University Higher School of Economics,Moscow,Russian Federation,"['1712', '1707']",22.2,0.09826839826839827,0.4177489177489178,1,0.11510791366906475,0.007194244604316547,0.30578512396694213
2190,2239,2239,Person search by text attribute query as zero-shot learning,"Existing person search methods predominantly assume the availability of at least one-shot imagery sample of the queried person. This assumption is limited in circumstances where only a brief textual (or verbal) description of the target person is available. In this work, we present a deep learning method for attribute text description based person search without any query imagery. Whilst conventional cross-modality matching methods, such as global visual-textual embedding based zero-shot learning and local individual attribute recognition, are functionally applicable, they are limited by several assumptions invalid to person search in deployment scale, data quality, and/or category name semantics. We overcome these issues by formulating an Attribute-Image Hierarchical Matching (AIHM) model. It is able to more reliably match text attribute descriptions with noisy surveillance person images by jointly learning global category-level and local attribute-level textual-visual embedding as well as matching. Extensive evaluations demonstrate the superiority of our AIHM model over a wide variety of state-of-the-art methods on three publicly available attribute labelled surveillance person search benchmarks: Market-1501, DukeMTMC, and PA100K.",60022109,"Queen Mary, University of London",London,United Kingdom,"['1712', '1707']",24.142857142857146,0.053061224489795916,0.30164399092970523,1,0.0761904761904762,0.03333333333333333,0.31216931216931215
2191,2240,2240,GLoSH: Global-local spherical harmonics for intrinsic image decomposition,"Traditional intrinsic image decomposition focuses on decomposing images into reflectance and shading, leaving surfaces normals and lighting entangled in shading. In this work, we propose a Global-Local Spherical Harmonics (GLoSH) lighting model to improve the lighting component, and jointly predict reflectance and surface normals. The global SH models the holistic lighting while local SH account for the spatial variation of lighting. Also, a novel non-negative lighting constraint is proposed to encourage the estimated SH to be physically meaningful. To seamlessly reflect the GLoSH model, we design a coarse-to-fine network structure. The coarse network predicts global SH, reflectance and normals, and the fine network predicts their local residuals. Lacking labels for reflectance and lighting, we apply synthetic data for model pre-training and fine-tune the model with real data in a self-supervised way. Compared to the state-of-the-art methods only targeting normals or reflectance and shading, our method recovers all components and achieves consistently better results on three real datasets, IIW, SAW and NYUv2.",60020304,University of Maryland,College Park,United States,"['1712', '1707']",20.125,0.1474358974358974,0.3423076923076923,1,0.10891089108910891,0.04455445544554455,0.36813186813186816
2192,2241,2241,Siamese networks: The tale of two manifolds,"Siamese networks are non-linear deep models that have found their ways into a broad set of problems in learning theory, thanks to their embedding capabilities. In this paper, we study Siamese networks from a new perspective and question the validity of their training procedure. We show that in the majority of cases, the objective of a Siamese network is endowed with an invariance property. Neglecting the invariance property leads to a hindrance in training the Siamese networks. To alleviate this issue, we propose two Riemannian structures and generalize a well-established accelerated stochastic gradient descent method to take into account the proposed Riemannian structures. Our empirical evaluations suggest that by making use of the Riemannian geometry, we achieve state-of-the-art results against several algorithms for the challenging problem of fine-grained image classification.",60108057,CSIRO Data61,Sydney,Australia,"['1712', '1707']",21.66666666666667,0.12485795454545455,0.32088068181818186,1,0.13071895424836602,0.0,0.2624113475177305
2193,2242,2242,Laplace landmark localization,"Landmark localization in images and videos is a classic problem solved in various ways. Nowadays, with deep networks prevailing throughout machine learning, there are revamped interests in pushing facial landmark detectors to handle more challenging data. Most efforts use network objectives based on L1 or L2 norms, which have several disadvantages. First of all, the generated heatmaps translate to the locations of landmarks (i.e. confidence maps) from which predicted landmark locations (i.e. the means) get penalized without accounting for the spread: A high- scatter corresponds to low confidence and vice-versa. For this, we introduce a LaplaceKL objective that penalizes for low confidence. Another issue is a dependency on labeled data, which are expensive to obtain and susceptible to error. To address both issues, we propose an adversarial training framework that leverages unlabeled data to improve model performance. Our method claims state-of-the-art on all of the 300W benchmarks and ranks second-to-best on the Annotated Facial Landmarks in the Wild (AFLW) dataset. Furthermore, our model is robust with a reduced size: 1/8 the number of channels (i.e. 0.0398 MB) is comparable to the state-of-the-art in real-time on CPU. Thus, this work is of high practical value to real-life application.",60120916,Snap Inc.,Santa Monica,United States,"['1712', '1707']",15.153846153846152,0.1080392156862745,0.3694117647058824,1,0.0967741935483871,0.03225806451612903,0.42358078602620086
2194,2243,2243,Sparse and imperceivable adversarial attacks,"Neural networks have been proven to be vulnerable to a variety of adversarial attacks. From a safety perspective, highly sparse adversarial attacks are particularly dangerous. On the other hand the pixelwise perturbations of sparse attacks are typically large and thus can be potentially detected. We propose a new black-box technique to craft adversarial examples aiming at minimizing l-0-distance to the original image. Extensive experiments show that our attack is better or competitive to the state of the art. Moreover, we can integrate additional bounds on the componentwise perturbation. Allowing pixels to change only in region of high variation and avoiding changes along axis-aligned edges makes our adversarial examples almost non-perceivable. Moreover, we adapt the Projected Gradient Descent attack to the l-0-norm integrating componentwise constraints. This allows us to do adversarial training to enhance the robustness of classifiers against sparse and imperceivable adversarial manipulations.",60017246,Universität Tübingen,Tubingen,Germany,"['1712', '1707']",15.888888888888891,0.026720779220779232,0.6101208513708513,1,0.11801242236024845,0.018633540372670808,0.38064516129032255
2195,2244,2244,Reaching consensus for SDN multi-controller networks,"Multiple SDN controllers architecture has been proposed to improve scalability and to avoid single point of failure. In order to resolve consistent network state among SDN multi-controllers, an efficient consensus mechanism to synchronize the control state of each controller is required. Raft is a consensus algorithm used in the OpenDayLight (ODL) Clustering. However, Raft algorithm may suffer from the leader election timeout and the system loading may fall on a certain controller. Thus, we propose a High Performance Paxos-based Consensus algorithm (HPPC) and implement it in the ODL Clustering to maintain a consistent global network state. The proposed HPPC simplifies the original Paxos protocols and guarantees that execution among interference commands when committing the client requests simultaneously. Since HPPC has no leader and every controller can commit requests concurrently, it has lower average consensus time than Raft. Meanwhile, experiment results show that HPPC is 25.2% faster at retrieving data and 66.3% faster at storing data via REST API comparing with Raft.",60005244,"Southeast University, Nanjing",Nanjing,China,['1700'],20.125,0.07111904761904761,0.3275714285714285,1,0.125,0.10326086956521739,0.3888888888888889
2196,2245,2245,Co-separating sounds of visual objects,"Learning how objects sound from video is challenging, since they often heavily overlap in a single audio channel. Current methods for visually-guided audio source separation sidestep the issue by training with artificially mixed video clips, but this puts unwieldy restrictions on training data collection and may even prevent learning the properties of 'true' mixed sounds. We introduce a co-separation training paradigm that permits learning object-level sounds from unlabeled multi-source videos. Our novel training objective requires that the deep neural network's separated audio for similar-looking objects be consistently identifiable, while simultaneously reproducing accurate video-level audio tracks for each source training pair. Our approach disentangles sounds in realistic test videos, even in cases where an object was not observed individually during training. We obtain state-of-the-art results on visually-guided audio source separation and audio denoising for the MUSIC, AudioSet, and AV-Bench datasets.",60013372,The University of Texas at Austin,Austin,United States,"['1712', '1707']",23.16666666666667,0.1175170068027211,0.4307823129251701,1,0.13068181818181818,0.022727272727272728,0.3660130718954248
2197,2247,2247,FaceForensics++: Learning to detect manipulated facial images,"The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. To standardize the evaluation of detection methods, we propose an automated benchmark for facial manipulation detection. In particular, the benchmark is based on Deep-Fakes, Face2Face, FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. Based on this data, we performed a thorough analysis of data-driven forgery detectors. We show that the use of additional domain-specific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",21.0,0.09087301587301587,0.517063492063492,1,0.09417040358744394,0.017937219730941704,0.3033175355450237
2198,2248,2248,Nocaps: Novel object captioning at scale,"Image captioning models have achieved impressive results on datasets containing limited visual concepts and large amounts of paired image-caption training data. However, if these models are to ever function in the wild, a much larger variety of visual concepts must be learned, ideally from less supervision. To encourage the development of image captioning models that can learn visual concepts from alternative data sources, such as object detection datasets, we present the first large-scale benchmark for this task. Dubbed 'nocaps', for novel object captioning at scale, our benchmark consists of 166,100 human-generated captions describing 15,100 images from the Open Images validation and test sets. The associated training data consists of COCO image-caption pairs, plus Open Images image-level labels and object bounding boxes. Since Open Images contains many more classes than COCO, nearly 400 object classes seen in test images have no or very few associated training captions (hence, nocaps). We extend existing novel object captioning models to establish strong baselines for this benchmark and provide analysis to guide future work.",60025778,"University of Michigan, Ann Arbor",Ann Arbor,United States,"['1712', '1707']",24.142857142857146,0.15906926406926405,0.3754437229437229,1,0.125,0.03,0.42328042328042326
2199,2249,2249,Attpool: Towards hierarchical feature representation in graph convolutional networks via attention mechanism,"Graph convolutional networks (GCNs) are potentially short of the ability to learn hierarchical representation for graph embedding, which holds them back in the graph classification task. Here, we propose AttPool, which is a novel graph pooling module based on attention mechanism, to remedy the problem. It is able to select nodes that are significant for graph representation adaptively, and generate hierarchical features via aggregating the attention-weighted information in nodes. Additionally, we devise a hierarchical prediction architecture to sufficiently leverage the hierarchical representation and facilitate the model learning. The AttPool module together with the entire training structure can be integrated into existing GCNs, and is trained in an end-to-end fashion conveniently. The experimental results on several graph-classification benchmark datasets with various scales demonstrate the effectiveness of our method.",60014966,Peking University,Beijing,China,"['1712', '1707']",21.166666666666668,0.121875,0.415625,1,0.11333333333333333,0.02666666666666667,0.2746478873239437
2200,2250,2250,AutoGAN: Neural architecture search for generative adversarial networks,"Neural architecture search (NAS) has witnessed prevailing success in image classification and (very recently) segmentation tasks. In this paper, we present the first preliminary study on introducing the NAS algorithm to generative adversarial networks (GANs), dubbed AutoGAN. The marriage of NAS and GANs faces its unique challenges. We define the search space for the generator architectural variations and use an RNN controller to guide the search, with parameter sharing and dynamic-resetting to accelerate the process. Inception score is adopted as the reward, and a multi-level search strategy is introduced to perform NAS in a progressive way. Experiments validate the effectiveness of AutoGAN on the task of unconditional image generation. Specifically, our discovered architectures achieve highly competitive performance compared to current state-of-the-art hand-crafted GANs, e.g., setting new state-of-the-art FID scores of 12.42 on CIFAR-10, and 31.01 on STL-10, respectively. We also conclude with a discussion of the current limitations and future potential of AutoGAN. The code is available at https://github.com/TAMU-VITA/AutoGAN.",60141075,MIT-IBM Watson AI Lab,Cambridge,United States,"['1712', '1707']",17.666666666666668,0.1247202797202797,0.3906060606060606,1,0.10945273631840796,0.04975124378109453,0.3945945945945946
2201,2251,2251,Transductive learning for zero-shot object detection,"Zero-shot object detection (ZSD) is a relatively unexplored research problem as compared to the conventional zero-shot recognition task. ZSD aims to detect previously unseen objects during inference. Existing ZSD works suffer from two critical issues: (a) large domain-shift between the source (seen) and target (unseen) domains since the two distributions are highly mismatched. (b) the learned model is biased against unseen classes, therefore in generalized ZSD settings, where both seen and unseen objects co-occur during inference, the learned model tends to misclassify unseen to seen categories. This brings up an important question: How effectively can a transductive setting address the aforementioned problems? To the best of our knowledge, we are the first to propose a transductive zero-shot object detection approach that convincingly reduces the domain-shift and model-bias against unseen classes. Our approach is based on a self-learning mechanism that uses a novel hybrid pseudo-labeling technique. It progressively updates learned model parameters by associating unlabeled data samples to their corresponding classes. During this process, our technique makes sure that knowledge that was previously acquired on the source domain is not forgotten. We report significant 'relative' improvements of 34.9% and 77.1% in terms of mAP and recall rates over the previous best inductive models on MSCOCO dataset.",60008950,Australian National University,Canberra,Australia,"['1712', '1707']",22.777777777777782,0.18981203007518802,0.4801545530492898,1,0.12598425196850394,0.01968503937007874,0.3617021276595745
2202,2252,2252,Few-shot learning with embedded class models and shot-free meta training,"We propose a method for learning embeddings for few-shot learning that is suitable for use with any number of shots (shot-free). Rather than fixing the class prototypes to be the Euclidean average of sample embeddings, we allow them to live in a higher-dimensional space (embedded class models) and learn the prototypes along with the model parameters. The class representation function is defined implicitly, which allows us to deal with a variable number of shots per class with a simple constant-size architecture. The class embedding encompasses metric learning, that facilitates adding new classes without crowding the class representation space. Despite being general and not tuned to the benchmark, our approach achieves state-of-the-art performance on the standard few-shot benchmark datasets.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",23.6,0.10324675324675324,0.42309833024118737,1,0.10884353741496598,0.0,0.31297709923664124
2203,2253,2253,Photo-realistic facial details synthesis from single image,"We present a single-image 3D face synthesis technique that can handle challenging facial expressions while recovering fine geometric details. Our technique employs expression analysis for proxy face geometry generation and combines supervised and unsupervised learning for facial detail synthesis. On proxy generation, we conduct emotion prediction to determine a new expression-informed proxy. On detail synthesis, we present a Deep Facial Detail Net (DFDN) based on Conditional Generative Adversarial Net (CGAN) that employs both geometry and appearance loss functions. For geometry, we capture 366 high-quality 3D scans from 122 different subjects under 3 facial expressions. For appearance, we use additional 163K in-the-wild face images and apply image-based rendering to accommodate lighting variations. Comprehensive experiments demonstrate that our framework can produce high-quality 3D faces with realistic details under challenging facial expressions.",60105232,ShanghaiTech University,Shanghai,China,"['1712', '1707']",18.428571428571427,0.10748106060606062,0.26799242424242425,1,0.16352201257861634,0.06918238993710692,0.4166666666666667
2204,2254,2254,Equivariant multi-view networks,"Several popular approaches to 3D vision tasks process multiple views of the input independently with deep neural networks pre-trained on natural images, where view permutation invariance is achieved through a single round of pooling over all views. We argue that this operation discards important information and leads to subpar global descriptors. In this paper, we propose a group convolutional approach to multiple view aggregation where convolutions are performed over a discrete subgroup of the rotation group, enabling, thus, joint reasoning over all views in an equivariant (instead of invariant) fashion, up to the very last layer. We further develop this idea to operate on smaller discrete homogeneous spaces of the rotation group, where a polar view representation is used to maintain equivariance with only a fraction of the number of input views. We set the new state of the art in several large scale 3D shape retrieval tasks, and show additional applications to panoramic scene classification.",60102562,School of Engineering and Applied Science,Philadelphia,United States,"['1712', '1707']",31.2,0.05767828662565504,0.350477329687856,1,0.11560693641618497,0.0,0.2631578947368421
2205,2255,2255,Sparsemask: Differentiable connectivity learning for dense image prediction,"In this paper, we aim at automatically searching an efficient network architecture for dense image prediction. Particularly, we follow the encoder-decoder style and focus on designing a connectivity structure for the decoder. To achieve that, we design a densely connected network with learnable connections, named Fully Dense Network, which contains a large set of possible final connectivity structures. We then employ gradient descent to search the optimal connectivity from the dense connections. The search process is guided by a novel loss function, which pushes the weight of each connection to be binary and the connections to be sparse. The discovered connectivity achieves competitive results on two segmentation datasets, while runs more than three times faster and requires less than half parameters compared to the state-of-the-art methods. An extensive experiment shows that the discovered connectivity is compatible with various backbones and generalizes well to other dense image prediction tasks.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",21.142857142857142,0.04226190476190477,0.4703571428571429,1,0.11764705882352941,0.01764705882352941,0.2777777777777778
2206,2256,2256,Guessing smart: Biased sampling for efficient black-box adversarial attacks,"We consider adversarial examples for image classification in the black-box decision-based setting. Here, an attacker cannot access confidence scores, but only the final label. Most attacks for this scenario are either unreliable or inefficient. Focusing on the latter, we show that a specific class of attacks, Boundary Attacks, can be reinterpreted as a biased sampling framework that gains efficiency from domain knowledge. We identify three such biases, image frequency, regional masks and surrogate gradients, and evaluate their performance against an ImageNet classifier. We show that the combination of these biases outperforms the state of the art by a wide margin. We also showcase an efficient way to attack the Google Cloud Vision API, where we craft convincing perturbations with just a few hundred queries. Finally, the methods we propose have also been found to work very well against strong defenses: Our targeted attack won second place in the NeurIPS 2018 Adversarial Vision Challenge.",60113040,Fortiss GmbH,Munich,Germany,"['1712', '1707']",19.125,0.10256410256410256,0.5121794871794871,1,0.12429378531073447,0.05084745762711865,0.3352601156069364
2207,2257,2257,FreiHAND: A dataset for markerless capture of hand pose and shape from single rgb images,"Estimating 3D hand pose from single RGB images is a highly ambiguous problem that relies on an unbiased training dataset. In this paper, we analyze cross-dataset generalization when training on existing datasets. We find that approaches perform well on the datasets they are trained on, but do not generalize to other datasets or in-the-wild scenarios. As a consequence, we introduce the first large-scale, multi-view hand dataset that is accompanied by both 3D hand pose and shape annotations. For annotating this real-world dataset, we propose an iterative, semi-automated 'human-in-the-loop' approach, which includes hand fitting optimization to infer both the 3D pose and shape for each sample. We show that methods trained on our dataset consistently perform well when tested on other datasets. Moreover, the dataset allows us to train a network that predicts the full articulated hand shape from a single RGB image. The evaluation set can serve as a benchmark for articulated hand shape estimation.",60025641,Universität Freiburg im Breisgau,Freiburg im Breisgau,Germany,"['1712', '1707']",19.375,0.12412698412698416,0.3724338624338624,1,0.13471502590673576,0.0,0.32558139534883723
2208,2258,2258,Discretization of Laplace-Beltrami operator based on cotangent scheme and its applications,"Laplace-Beltrami operator (LBO) is the basis of describing geometric partial differential equation. It also plays an important role in computational geometry, computer graphics and image processing, such as surface parameterization, shape analysis, matching and interpolation. Due to the different application fields of Laplace-Beltrami operator need to meet the mathematical properties of different, has produced many discretization methods but cannot replace each other discretization method, different discretization method can reduce the time complexity, at the same time can improve an inefficient algorithm. In this article, We are mainly aimed at discretization based on the Laplace-Beltrami cotangent operator. We improve the original discretization method and apply it to non-rigid 3D shape retrieval tasks. Experimental results shows the effectiveness of our discretization method.",60002210,Shandong Normal University,Jinan,China,['1700'],20.0,0.08511904761904764,0.4613095238095238,1,0.1103448275862069,0.04827586206896552,0.3357664233576642
2209,2259,2259,MIC: Mining interclass characteristics for improved metric learning,"Metric learning seeks to embed images of objects such that class-defined relations are captured by the embedding space. However, variability in images is not just due to different depicted object classes, but also depends on other latent characteristics such as viewpoint or illumination. In addition to these structured properties, random noise further obstructs the visual relations of interest. The common approach to metric learning is to enforce a representation that is invariant under all factors but the ones of interest. In contrast, we propose to explicitly learn the latent characteristics that are shared by and go across object classes. We can then directly explain away structured visual variability, rather than assuming it to be unknown random noise. We propose a novel surrogate task to learn visual characteristics shared across classes with a separate encoder. This encoder is trained jointly with the encoder for class information by reducing their mutual information. On five standard image retrieval benchmarks the approach significantly improves upon the state-of-the-art. Code is available at https://github.com/Confusezius/metric-learning-mining-interclass-characteristics.",60016908,Universität Heidelberg,Heidelberg,Germany,"['1712', '1707']",16.8,-0.04558823529411765,0.3897058823529412,1,0.1099476439790576,0.0,0.2864864864864865
2210,2260,2260,Graph convolutional networks for temporal action localization,"Most state-of-the-art action localization systems process each action proposal individually, without explicitly exploiting their relations during learning. However, the relations between proposals actually play an important role in action localization, since a meaningful action always consists of multiple proposals in a video. In this paper, we propose to exploit the proposal-proposal relations using GraphConvolutional Networks (GCNs). First, we construct an action proposal graph, where each proposal is represented as a node and their relations between two proposals as an edge. Here, we use two types of relations, one for capturing the context information for each proposal and the other one for characterizing the correlations between distinct actions. Then we apply the GCNs over the graph to model the relations among different proposals and learn powerful representations for the action classification and localization. Experimental results show that our approach significantly outperforms the state-of-the-art on THUMOS14(49.1% versus 42.8%). Moreover, augmentation experiments on ActivityNet also verify the efficacy of modeling action proposal relationships.",60141075,MIT-IBM Watson AI Lab,Cambridge,United States,"['1712', '1707']",20.0,0.165,0.35416666666666663,1,0.09693877551020408,0.02040816326530612,0.3641304347826087
2211,2261,2261,ViSiL: Fine-grained spatio-temporal video similarity learning,"In this paper we introduce ViSiL, a Video Similarity Learning architecture that considers fine-grained Spatio-Temporal relations between pairs of videos - such relations are typically lost in previous video retrieval approaches that embed the whole frame or even the whole video into a vector descriptor before the similarity estimation. By contrast, our Convolutional Neural Network (CNN)-based approach is trained to calculate video-to-video similarity from refined frame-to-frame similarity matrices, so as to consider both intra- and inter-frame relations. In the proposed method, pairwise frame similarity is estimated by applying Tensor Dot (TD) followed by Chamfer Similarity (CS) on regional CNN frame features - this avoids feature aggregation before the similarity calculation between frames. Subsequently, the similarity matrix between all video frames is fed to a four-layer CNN, and then summarized using Chamfer Similarity (CS) into a video-to-video similarity score - this avoids feature aggregation before the similarity calculation between videos and captures the temporal similarity patterns between matching frame sequences. We train the proposed network using a triplet loss scheme and evaluate it on five public benchmark datasets on four different video retrieval problems where we demonstrate large improvements in comparison to the state of the art. The implementation of ViSiL is publicly available.",60026208,Center For Research And Technology - Hellas,Thessaloniki,Greece,"['1712', '1707']",33.833333333333336,0.0680952380952381,0.35119047619047616,1,0.09504132231404959,0.08264462809917356,0.3794642857142857
2212,2262,2262,MONET: Multiview semi-supervised keypoint detection via epipolar divergence,"This paper presents MONET - -an end-to-end semi-supervised learning framework for a keypoint detector using multiview image streams. In particular, we consider general subjects such as non-human species where attaining a large scale annotated dataset is challenging. While multiview geometry can be used to self-supervise the unlabeled data, integrating the geometry into learning a keypoint detector is challenging due to representation mismatch. We address this mismatch by formulating a new differentiable representation of the epipolar constraint called epipolar divergence - -a generalized distance from the epipolar lines to the corresponding keypoint distribution. Epipolar divergence characterizes when two view keypoint distributions produce zero reprojection error. We design a twin network that minimizes the epipolar divergence through stereo rectification that can significantly alleviate computational complexity and sampling aliasing in training. We demonstrate that our framework can localize customized keypoints of diverse species, e.g., humans, dogs, and monkeys.",123974342,University of Minnesota,Saint Paul,United States,"['1712', '1707']",20.714285714285715,0.20192400192400195,0.6073833573833574,1,0.16071428571428573,0.03571428571428571,0.3924050632911392
2213,2263,2263,Single-network whole-body pose estimation,"We present the first single-network approach for 2D∼whole-body pose estimation, which entails simultaneous localization of body, face, hands, and feet keypoints. Due to the bottom-up formulation, our method maintains constant real-time performance regardless of the number of people in the image. The network is trained in a single stage using multi-task learning, through an improved architecture which can handle scale differences between body/foot and face/hand keypoints. Our approach considerably improves upon OpenPose∼cite{cao2018openpose}, the only work so far capable of whole-body pose estimation, both in terms of speed and global accuracy. Unlike OpenPose, our method does not need to run an additional network for each hand and face candidate, making it substantially faster for multi-person scenarios. This work directly results in a reduction of computational complexity for applications that require 2D whole-body information (e.g., VR/AR, re-targeting). In addition, it yields higher accuracy, especially for occluded, blurry, and low resolution faces and hands. For code, trained models, and validation benchmarks, visit our project page: Https://github.com/CMU-Perceptual-Computing-Lab/openpose-train.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",20.375,0.05739795918367348,0.4504251700680272,1,0.08256880733944955,0.022935779816513763,0.3939393939393939
2214,2264,2264,Improved techniques for training adaptive deep networks,"Adaptive inference is a promising technique to improve the computational efficiency of deep models at test time. In contrast to static models which use the same computation graph for all instances, adaptive networks can dynamically adjust their structure conditioned on each input. While existing research on adaptive inference mainly focuses on designing more advanced architectures, this paper investigates how to train such networks more effectively. Specifically, we consider a typical adaptive deep network with multiple intermediate classifiers. We present three techniques to improve its training efficacy from two aspects: 1) a Gradient Equilibrium algorithm to resolve the conflict of learning of different classifiers; 2) an Inline Subnetwork Collaboration approach and a One-for-all Knowledge Distillation algorithm to enhance the collaboration among classifiers. On multiple datasets (CIFAR-10, CIFAR-100 and ImageNet), we show that the proposed approach consistently leads to further improved efficiency on top of state-of-the-art adaptive deep networks.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",24.5,0.1725,0.41541666666666666,1,0.10919540229885058,0.04597701149425287,0.34146341463414637
2215,2265,2265,Learning robust facial landmark detection via hierarchical structured ensemble,"Heatmap regression-based models have significantly advanced the progress of facial landmark detection. However, the lack of structural constraints always generates inaccurate heatmaps resulting in poor landmark detection performance. While hierarchical structure modeling methods have been proposed to tackle this issue, they all heavily rely on manually designed tree structures. The designed hierarchical structure is likely to be completely corrupted due to the missing or inaccurate prediction of landmarks. To the best of our knowledge, in the context of deep learning, no work before has investigated how to automatically model proper structures for facial landmarks, by discovering their inherent relations. In this paper, we propose a novel Hierarchical Structured Landmark Ensemble (HSLE) model for learning robust facial landmark detection, by using it as the structural constraints. Different from existing approaches of manually designing structures, our proposed HSLE model is constructed automatically via discovering the most robust patterns so HSLE has the ability to robustly depict both local and holistic landmark structures simultaneously. Our proposed HSLE can be readily plugged into any existing facial landmark detection baselines for further performance improvement. Extensive experimental results demonstrate our approach significantly outperforms the baseline by a large margin to achieve a state-of-the-art performance.",60025761,Huazhong University of Science and Technology,Wuhan,China,"['1712', '1707']",22.0,0.08540372670807453,0.3679089026915113,1,0.1288888888888889,0.04,0.31336405529953915
2216,2266,2266,On boosting single-frame 3D human pose estimation via monocular videos,"The premise of training an accurate 3D human pose estimation network is the possession of huge amount of richly annotated training data. Nonetheless, manually obtaining rich and accurate annotations is, even not impossible, tedious and slow. In this paper, we propose to exploit monocular videos to complement the training dataset for the single-image 3D human pose estimation tasks. At the beginning, a baseline model is trained with a small set of annotations. By fixing some reliable estimations produced by the resulting model, our method automatically collects the annotations across the entire video as solving the 3D trajectory completion problem. Then, the baseline model is further trained with the collected annotations to learn the new poses. We evaluate our method on the broadly-adopted Human3.6M and MPI-INF-3DHP datasets. As illustrated in experiments, given only a small set of annotations, our method successfully makes the model to learn new poses from unlabelled monocular videos, promoting the accuracies of the baseline model by about 10%. By contrast with previous approaches, our method does not rely on either multi-view imagery or any explicit 2D keypoint annotations.",60018308,Xi'an Jiaotong University,Xi'an,China,"['1712', '1707']",20.11111111111111,0.09681020733652314,0.5903907496012759,1,0.11374407582938388,0.018957345971563982,0.3316831683168317
2217,2267,2267,Sampling-free epistemic uncertainty estimation using approximated variance propagation,"We present a sampling-free approach for computing the epistemic uncertainty of a neural network. Epistemic uncertainty is an important quantity for the deployment of deep neural networks in safety-critical applications, since it represents how much one can trust predictions on new data. Recently promising works were proposed using noise injection combined with Monte-Carlo sampling at inference time to estimate this quantity (e.g. Monte-Carlo dropout). Our main contribution is an approximation of the epistemic uncertainty estimated by these methods that does not require sampling, thus notably reducing the computational overhead. We apply our approach to large-scale visual tasks (ie, semantic segmentation and depth regression) to demonstrate the advantages of our method compared to sampling-based approaches in terms of quality of the uncertainty estimates as well as of computational overhead.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",21.33333333333333,0.17811447811447814,0.3764309764309764,1,0.125,0.019736842105263157,0.28368794326241137
2218,2268,2268,Semi-supervised pedestrian instance synthesis and detection with mutual reinforcement,"We propose a GAN-based scene-specific instance synthesis and classification model for semi-supervised pedestrian detection. Instead of collecting unreliable detections from unlabeled data, we adopt a class-conditional GAN for synthesizing pedestrian instances to alleviate the problem of insufficient labeled data. With the help of a base detector, we integrate pedestrian instance synthesis and detection by including a post-refinement classifier (PRC) into a minimax game. A generator and the PRC can mutually reinforce each other by synthesizing high-fidelity pedestrian instances and providing more accurate categorical information. Both of them compete with a class-conditional discriminator and a class-specific discriminator, such that the four fundamental networks in our model can be jointly trained. In our experiments, we validate that the proposed model significantly improves the performance of the base detector and achieves state-of-the-art results on multiple benchmarks. As shown in Figure 1, the result indicates the possibility of using inexpensively synthesized instances for improving semi-supervised detection models.",60024542,South China University of Technology,Guangzhou,China,"['1712', '1707']",21.857142857142854,-0.09444444444444446,0.587037037037037,1,0.13089005235602094,0.02617801047120419,0.32934131736526945
2219,2269,2269,Variational adversarial active learning,"Active learning aims to develop label-efficient algorithms by sampling the most representative queries to be labeled by an oracle. We describe a pool-based semi-supervised active learning algorithm that implicitly learns this sampling mechanism in an adversarial manner. Our method learns a latent space using a variational autoencoder (VAE) and an adversarial network trained to discriminate between unlabeled and labeled data. The mini-max game between the VAE and the adversarial network is played such that while the VAE tries to trick the adversarial network into predicting that all data points are from the labeled pool, the adversarial network learns how to discriminate between dissimilarities in the latent space. We extensively evaluate our method on various image classification and semantic segmentation benchmark datasets and establish a new state of the art on CIFAR10/100, Caltech-256, ImageNet, Cityscapes, and BDD100K. Our results demonstrate that our adversarial approach learns an effective low dimensional latent space in large-scale settings and provides for a computationally efficient sampling method. Our code is available at url{https://github.com/sinhasam/vaal}.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",23.857142857142854,0.07247474747474747,0.4823232323232323,1,0.12307692307692308,0.06666666666666667,0.3655913978494624
2220,2270,2270,Dynamic graph attention for referring expression comprehension,"Referring expression comprehension aims to locate the object instance described by a natural language referring expression in an image. This task is compositional and inherently requires visual reasoning on top of the relationships among the objects in the image. Meanwhile, the visual reasoning process is guided by the linguistic structure of the referring expression. However, existing approaches treat the objects in isolation or only explore the first-order relationships between objects without being aligned with the potential complexity of the expression. Thus it is hard for them to adapt to the grounding of complex referring expressions. In this paper, we explore the problem of referring expression comprehension from the perspective of language-driven visual reasoning, and propose a dynamic graph attention network to perform multi-step reasoning by modeling both the relationships among the objects in the image and the linguistic structure of the expression. In particular, we construct a graph for the image with the nodes and edges corresponding to the objects and their relationships respectively, propose a differential analyzer to predict a language-guided visual reasoning process, and perform stepwise reasoning on top of the graph to update the compound object representation at every node. Experimental results demonstrate that the proposed method can not only significantly surpass all existing state-of-the-art algorithms across three common benchmark datasets, but also generate interpretable visual evidences for stepwise locating the objects referred to in complex language descriptions.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1707']",28.875,0.03409090909090909,0.378030303030303,1,0.14559386973180077,0.0,0.2550607287449393
2221,2271,2271,Joint acne image grading and counting via label distribution learning,"Accurate grading of skin disease severity plays a crucial role in precise treatment for patients. Acne vulgaris, the most common skin disease in adolescence, can be graded by evidence-based lesion counting as well as experience-based global estimation in the medical field. However, due to the appearance similarity of acne with close severity, it is challenging to count and grade acne accurately. In this paper, we address the problem of acne image analysis via Label Distribution Learning (LDL) considering the ambiguous information among acne severity. Based on the professional grading criterion, we generate two acne label distributions considering the relationship between the similar number of lesions and severity of acne, respectively. We also propose a unified framework for joint acne image grading and counting, which is optimized by the multi-task learning loss. In addition, we further build the ACNE04 dataset with annotations of acne severity and lesion number of each image for evaluation. Experiments demonstrate that our proposed framework performs favorably against state-of-the-art methods. We make the code and dataset publicly available at https://github.com/xpwu95/ldl.",60121696,Beijing Tsinghua Changgung Hospital,Beijing,China,"['1712', '1707']",19.222222222222218,0.1516666666666667,0.4627777777777778,1,0.1024390243902439,0.07317073170731707,0.27692307692307694
2222,2272,2272,Cascaded context pyramid for full-resolution 3D semantic scene completion,"Semantic Scene Completion (SSC) aims to simultaneously predict the volumetric occupancy and semantic category of a 3D scene. It helps intelligent devices to understand and interact with the surrounding scenes. Due to the high-memory requirement, current methods only produce low-resolution completion predictions, and generally lose the object details. Furthermore, they also ignore the multi-scale spatial contexts, which play a vital role for the 3D inference. To address these issues, in this work we propose a novel deep learning framework, named Cascaded Context Pyramid Network (CCPNet), to jointly infer the occupancy and semantic labels of a volumetric 3D scene from a single depth image. The proposed CCPNet improves the labeling coherence with a cascaded context pyramid. Meanwhile, based on the low-level features, it progressively restores the fine-structures of objects with Guided Residual Refinement (GRR) modules. Our proposed framework has three outstanding advantages: (1) it explicitly models the 3D spatial context for performance improvement; (2) full-resolution 3D volumes are produced with structure-preserving details; (3) light-weight models with low-memory requirements are captured with a good extensibility. Extensive experiments demonstrate that in spite of taking a single-view depth map, our proposed framework can generate high-quality SSC results, and outperforms state-of-the-art approaches on both the synthetic SUNCG and real NYU datasets.",60016521,Sichuan University,Chengdu,China,"['1712', '1707']",22.88888888888889,0.05025510204081634,0.5784013605442176,1,0.10780669144981413,0.06319702602230483,0.46887966804979253
2223,2273,2273,Polarimetric relative pose estimation,"In this paper we consider the problem of relative pose estimation from two images with per-pixel polarimetric information. Using these additional measurements we derive a simple minimal solver for the essential matrix which only requires two point correspondences. The polarization constraints allow us to pointwise recover the 3D surface normal up to a two-fold ambiguity for the diffuse reflection. Since this ambiguity exists per point, there is a combinatorial explosion of possibilities. However, since our solver only requires two point correspondences, we only need to consider 16 configurations when solving for the relative pose. Once the relative orientation is recovered, we show that it is trivial to resolve the ambiguity for the remaining points. For robustness, we also propose a joint optimization between the relative pose and the refractive index to handle the refractive distortion. In experiments, on both synthetic and real data, we demonstrate that by leveraging the additional information available from polarization cameras, we can improve over classical methods which only rely on the 2D-point locations to estimate the geometry. Finally, we demonstrate the practical applicability of our approach by integrating it into a state-of-the-art global Structure-from-Motion pipeline.",60026532,Microsoft Corporation,Redmond,United States,"['1712', '1707']",21.11111111111111,0.03823529411764706,0.4474789915966386,1,0.125,0.0,0.25
2224,2274,2274,Deep depth from aberration map,"Passive and convenient depth estimation from single-shot image is still an open problem. Existing depth from defocus methods require multiple input images or special hardware customization. Recent deep monocular depth estimation is also limited to an image with sufficient contextual information. In this work, we propose a novel method which realizes a single-shot deep depth measurement based on physical depth cue using only an off-the-shelf camera and lens. When a defocused image is taken by a camera, it contains various types of aberrations corresponding to distances from the image sensor and positions in the image plane. We call these minute and complexly compound aberrations as Aberration Map (A-Map) and we found that A-Map can be utilized as reliable physical depth cue. Additionally, our deep network named A-Map Analysis Network (AMA-Net) is also proposed, which can effectively learn and estimate depth via A-Map. To evaluate validity and robustness of our approach, we have conducted extensive experiments using both real outdoor scenes and simulated images. The qualitative result shows the accuracy and availability of the method in comparison with a state-of-the-art deep context-based method.",60023499,"University of Hyogo, Kobe",Kobe,Japan,"['1712', '1707']",20.222222222222218,0.04621848739495798,0.3931372549019608,1,0.11061946902654868,0.061946902654867256,0.315
2225,2275,2275,Seeing what a GAN cannot generate,"Despite the success of Generative Adversarial Networks (GANs), mode collapse remains a serious issue during GAN training. To date, little work has focused on understanding and quantifying which modes have been dropped by a model. In this work, we visualize mode collapse at both the distribution level and the instance level. First, we deploy a semantic segmentation network to compare the distribution of segmented objects in the generated images with the target distribution in the training set. Differences in statistics reveal object classes that are omitted by a GAN. Second, given the identified omitted object classes, we visualize the GAN's omissions directly. In particular, we compare specific differences between individual photos and their approximate inversions by a GAN. To this end, we relax the problem of inversion and solve the tractable problem of inverting a GAN layer instead of the entire generator. Finally, we use this framework to analyze several recent GANs trained on multiple datasets and identify their typical failure cases.",60141075,MIT-IBM Watson AI Lab,Cambridge,United States,"['1712', '1707']",18.0,-0.04296875,0.3520833333333333,1,0.11475409836065574,0.04371584699453552,0.31693989071038253
2226,2276,2276,Video compression with rate-distortion autoencoders,"In this paper we present a a deep generative model for lossy video compression. We employ a model that consists of a 3D autoencoder with a discrete latent space and an autoregressive prior used for entropy coding. Both autoencoder and prior are trained jointly to minimize a rate-distortion loss, which is closely related to the ELBO used in variational autoencoders. Despite its simplicity, we find that our method outperforms the state-of-the-art learned video compression networks based on motion compensation or interpolation. We systematically evaluate various design choices, such as the use of frame-based or spatio-temporal autoencoders, and the type of autoregressive prior. In addition, we present three extensions of the basic method that demonstrate the benefits over classical approaches to compression. First, we introduce emph{semantic compression}, where the model is trained to allocate more bits to objects of interest. Second, we study emph{adaptive compression}, where the model is adapted to a domain with limited variability, eg videos taken from an autonomous car, to achieve superior compression on that domain. Finally, we introduce emph{multimodal compression}, where we demonstrate the effectiveness of our model in joint compression of multiple modalities captured by non-standard imaging sensors, such as quad cameras. We believe that this opens up novel video compression applications, which have not been feasible with classical codecs.",117642090,Qualcomm Research Netherlands,Amsterdam,Netherlands,"['1712', '1707']",21.5,0.08469387755102041,0.28577097505668936,1,0.10894941634241245,0.007782101167315175,0.3172690763052209
2227,2277,2277,Unsupervised out-of-distribution detection by maximum classifier discrepancy,"Since deep learning models have been implemented in many commercial applications, it is important to detect out-of-distribution (OOD) inputs correctly to maintain the performance of the models, ensure the quality of the collected data, and prevent the applications from being used for other-than-intended purposes. In this work, we propose a two-head deep convolutional neural network (CNN) and maximize the discrepancy between the two classifiers to detect OOD inputs. We train a two-head CNN consisting of one common feature extractor and two classifiers which have different decision boundaries but can classify in-distribution (ID) samples correctly. Unlike previous methods, we also utilize unlabeled data for unsupervised training and we use these unlabeled data to maximize the discrepancy between the decision boundaries of two classifiers to push OOD samples outside the manifold of the in-distribution (ID) samples, which enables us to detect OOD samples that are far from the support of the ID samples. Overall, our approach significantly outperforms other state-of-the-art methods on several OOD detection benchmarks and two cases of real-world simulation.",60025272,University of Tokyo,Tokyo,Japan,"['1712', '1707']",34.0,0.05595238095238096,0.41904761904761895,1,0.102803738317757,0.04672897196261682,0.3631578947368421
2228,2278,2278,SegEQA: Video segmentation based visual attention for embodied question answering,"Embodied Question Answering (EQA) is a newly defined research area where an agent is required to answer the user's questions by exploring the real world environment. It has attracted increasing research interests due to its broad applications in automatic driving system, in-home robots, and personal assistants. Most of the existing methods perform poorly in terms of answering and navigation accuracy due to the absence of local details and vulnerability to the ambiguity caused by complicated vision conditions. To tackle these problems, we propose a segmentation based visual attention mechanism for Embodied Question Answering. Firstly, We extract the local semantic features by introducing a novel high-speed video segmentation framework. Then by the guide of extracted semantic features, a bottom-up visual attention mechanism is proposed for the Visual Question Answering (VQA) sub-task. Further, a feature fusion strategy is proposed to guide the training of the navigator without much additional computational cost. The ablation experiments show that our method boosts the performance of VQA module by 4.2% (68.99% vs 64.73%) and leads to 3.6% (48.59% vs 44.98%) overall improvement in EQA accuracy.",60010080,Nanjing University of Science and Technology,Nanjing,China,"['1712', '1707']",22.375,0.00980861244019139,0.2763357256778309,1,0.09722222222222222,0.037037037037037035,0.40865384615384615
2229,2279,2279,Semi-physical simulation of fuel loss for unmanned aerial vehicle,"There are errors in the simulation of UAV (Unmanned Aerial Vehicle) fuel gauge. To solve this problem, by analyzing the fuel consumption factors of UAV, a flight fuel consumption calculation model is established, which makes the data generated by the simulator closer to the real environment. At the same time, the semi-physical simulation of computer simulation is realized, which effectively compensates for the disadvantage of the great difference between computer simulation and real environment.",60007711,Jilin University,Changchun,China,['1700'],24.66666666666667,0.36,0.4550000000000001,1,0.08139534883720931,0.05813953488372093,0.30952380952380953
2230,2280,2280,Optimizing the f-measure for threshold-free salient object detection,"Current CNN-based solutions to salient object detection (SOD) mainly rely on the optimization of cross-entropy loss (CELoss). Then the quality of detected saliency maps is often evaluated in terms of F-measure. In this paper, we investigate an interesting issue: Can we consistently use the F-measure formulation in both training and evaluation for SOD? By reformulating the standard F-measure we propose the relaxed F-measure which is differentiable w.r.t the posterior and can be easily appended to the back of CNNs as the loss function. Compared to the conventional cross-entropy loss of which the gradients decrease dramatically in the saturated area, our loss function, named FLoss, holds considerable gradients even when the activation approaches the target. Consequently, the FLoss can continuously force the network to produce polarized activations. Comprehensive benchmarks on several popular datasets show that FLoss outperforms the state-of-the-art with a considerable margin. More specifically, due to the polarized predictions, our method is able to obtain high-quality saliency maps without carefully tuning the optimal threshold, showing significant advantages in real-world applications.",60018038,Nankai University,Tianjin,China,"['1712', '1707']",24.285714285714285,0.18571428571428567,0.4616946778711485,1,0.12093023255813953,0.046511627906976744,0.3769633507853403
2231,2281,2281,Zero-shot anticipation for instructional activities,"How can we teach a robot to predict what will happen next for an activity it has never seen before? We address the problem of zero-shot anticipation by presenting a hierarchical model that generalizes instructional knowledge from large-scale text-corpora and transfers the knowledge to the visual domain. Given a portion of an instructional video, our model predicts coherent and plausible actions multiple steps into the future, all in rich natural language. To demonstrate the anticipation capabilities of our model, we introduce the Tasty Videos dataset, a collection of 2511 recipes for zero-shot learning, recognition and anticipation.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",32.0,0.184375,0.309375,1,0.13274336283185842,0.017699115044247787,0.2857142857142857
2232,2282,2282,Sales-forecast-based auto parts multiple-value chain collaboration mechanism and verification,"Auto parts in the after-sales service flow across parts supplier, manufacturer, and transit store as well as service provider. The accurate and timely demand for auto parts plays a key role in the value-added process of the parts multiple-value chains. This paper presents a collaboration mechanism and evaluation method for auto parts multiple-value chains based on sales prediction. First, we study the composition of inner value chain of independent accounting unit, and discuss factors of value increment of the inner value chain. Moreover, dominated elements are selected as main factors for future value. Second, a colored petri nets model is created for each independent accounting unit all over the multiple-value-chains, of which value-added process maps to Transition, repository to Place and auto parts to Place’s Token. Such model is utilized to simulate the value-added process over the multiple-value chains. Finally, a collaboration mechanism for multiple-value chains is designed based on the prediction amount for auto parts. By means of randomly generating a sequence of custom’s arrival and Monte Carlo method, we use CPN Tools to simulate the value-added process over the multiple-value chains. Experiments show that the offered auto parts collaboration mechanism can fully utilize existed resources in the multiple-value chains, gets maximized rise in value, and further seek the fundamental path to value increment. The model implemented in this paper is able to provide some quantification references for the multiple-value chains.",60025256,Institute of Software Chinese Academy of Sciences,Beijing,China,['1700'],21.09090909090909,0.05444444444444445,0.4088888888888889,1,0.09824561403508772,0.02456140350877193,0.33976833976833976
2233,2283,2283,SSF-DAN: Separated semantic feature based domain adaptation network for semantic segmentation,"Despite the great success achieved by supervised fully convolutional models in semantic segmentation, training the models requires a large amount of labor-intensive work to generate pixel-level annotations. Recent works exploit synthetic data to train the model for semantic segmentation, but the domain adaptation between real and synthetic images remains a challenging problem. In this work, we propose a Separated Semantic Feature based domain adaptation network, named SSF-DAN, for semantic segmentation. First, a Semantic-wise Separable Discriminator (SS-D) is designed to independently adapt semantic features across the target and source domains, which addresses the inconsistent adaptation issue in the class-wise adversarial learning. In SS-D, a progressive confidence strategy is included to achieve a more reliable separation. Then, an efficient Class-wise Adversarial loss Reweighting module (CA-R) is introduced to balance the class-wise adversarial learning process, which leads the generator to focus more on poorly adapted classes. The presented framework demonstrates robust performance, superior to state-of-the-art methods on benchmark datasets.",60009860,Fudan University,Shanghai,China,"['1712', '1707']",22.285714285714285,0.2970238095238095,0.4739087301587301,1,0.11274509803921569,0.06862745098039216,0.38202247191011235
2234,2284,2284,Multi-agent reinforcement learning based frame sampling for effective untrimmed video recognition,"Video Recognition has drawn great research interest and great progress has been made. A suitable frame sampling strategy can improve the accuracy and efficiency of recognition. However, mainstream solutions generally adopt hand-crafted frame sampling strategies for recognition. It could degrade the performance, especially in untrimmed videos, due to the variation of frame-level saliency. To this end, we concentrate on improving untrimmed video classification via developing a learning-based frame sampling strategy. We intuitively formulate the frame sampling procedure as multiple parallel Markov decision processes, each of which aims at picking out a frame/clip by gradually adjusting an initial sampling. Then we propose to solve the problems with multi-agent reinforcement learning (MARL). Our MARL framework is composed of a novel RNN-based context-aware observation network which jointly models context information among nearby agents and historical states of a specific agent, a policy network which generates the probability distribution over a predefined action space at each step and a classification network for reward calculation as well as final recognition. Extensive experimental results show that our MARL-based scheme remarkably outperforms hand-crafted strategies with various 2D and 3D baseline methods. Our single RGB model achieves a comparable performance of ActivityNet v1.3 champion submission with multi-modal multi-model fusion and new state-of-the-art results on YouTube Birds and YouTube Cars.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",21.1,0.16262816131237184,0.4211665527455001,1,0.11673151750972763,0.042801556420233464,0.33624454148471616
2235,2285,2285,Sampling wisely: Deep image embedding by top-k precision optimization,"Deep image embedding aims at learning a convolutional neural network (CNN) based mapping function that maps an image to a feature vector. The embedding quality is usually evaluated by the performance in image search tasks. Since very few users bother to open the second page search results, top-k precision mostly dominates the user experience and thus is one of the crucial evaluation metrics for the embedding quality. Despite being extensively studied, existing algorithms are usually based on heuristic observation without theoretical guarantee. Consequently, gradient descent direction on the training loss is mostly inconsistent with the direction of optimizing the concerned evaluation metric. This inconsistency certainly misleads the training direction and degrades the performance. In contrast to existing works, in this paper, we propose a novel deep image embedding algorithm with end-to-end optimization to top-k precision, the evaluation metric that is closely related to user experience. Specially, our loss function is constructed with wisely selected ''misplaced' images along the top k nearest neighbor decision boundary, so that the gradient descent update directly promotes the concerned metric, top-k precision. Further more, our theoretical analysis on the upper bounding and consistency properties of the proposed loss supports that minimizing our proposed loss is equivalent to maximizing top-k precision. Experiments show that our proposed algorithm outperforms all compared state-of-the-art deep image embedding algorithms on three benchmark datasets.",60019616,Harbin Institute of Technology,Harbin,China,"['1712', '1707']",22.3,0.10047619047619047,0.3919246031746033,1,0.12030075187969924,0.007518796992481203,0.30364372469635625
2236,2286,2286,Unsupervised pre-training of image features on non-curated data,"Pre-training general-purpose visual features with convolutional neural networks without relying on annotations is a challenging and important task. Most recent efforts in unsupervised feature learning have focused on either small or highly curated datasets like ImageNet, whereas using uncurated raw datasets was found to decrease the feature quality when evaluated on a transfer task. Our goal is to bridge the performance gap between unsupervised methods trained on curated data, which are costly to obtain, and massive raw datasets that are easily available. To that effect, we propose a new unsupervised approach which leverages self-supervision and clustering to capture complementary statistics from large-scale data. We validate our approach on 96 million images from YFCC100M, achieving state-of-the-art results among unsupervised methods on standard benchmarks, which confirms the potential of unsupervised learning when only uncurated data are available. We also show that pre-training a supervised VGG-16 with our method achieves 74.9% top-1 classification accuracy on the validation set of ImageNet, which is an improvement of +0.8% over the same network trained from scratch. Our code is available at https://github.com/facebookresearch/DeeperCluster.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,"['1712', '1707']",25.142857142857146,0.12137917637917635,0.5218123543123543,1,0.1291866028708134,0.023923444976076555,0.33505154639175255
2237,2287,2287,Biological data migration method based on IPFS system,"IPFS (Interplanetary File System) is a peer to peer distributed file system with fast downloading speed and high security. IPFS adopts the storage method of equal-size fragmentation and DHT-based resource search. Through investigation, it is found that the current IPFS system lacks the strategy of resource migration. Therefore, in order to improve the efficiency of its search and further improve the download speed of biological data, This paper adopts the sharding and uploading method based on the characteristics of biological data and propose the migration algorithm based on routing table and the migration algorithm based on biological historical access table. The experimental and analytical results show that the proposed method is effective.",60106769,Neusoft Corporation,Shenyang,China,['1700'],22.4,0.15142857142857144,0.4628571428571429,1,0.1349206349206349,0.05555555555555555,0.2540983606557377
2238,2288,2288,Physical adversarial textures that fool visual object tracking,"We present a method for creating inconspicuous-looking textures that, when displayed as posters in the physical world, cause visual object tracking systems to become confused. As a target being visually tracked moves in front of such a poster, its adversarial texture makes the tracker lock onto it, thus allowing the target to evade. This adversarial attack evaluates several optimization strategies for fooling seldom-targeted regression models: Non-targeted, targeted, and a newly-coined family of guided adversarial losses. Also, while we use the Expectation Over Transformation (EOT) algorithm to generate physical adversaries that fool tracking models when imaged under diverse conditions, we compare the impacts of different scene variables to find practical attack setups with high resulting adversarial strength and convergence speed. We further showcase that textures optimized using simulated scenes can confuse real-world tracking systems for cameras and robots.",119688123,Element AI,Montreal,Canada,"['1712', '1707']",27.4,-0.02181818181818182,0.2841558441558441,1,0.19631901840490798,0.018404907975460124,0.4117647058823529
2239,2289,2289,HBONet: Harmonious bottleneck on two orthogonal dimensions,"MobileNets, a class of top-performing convolutional neural network architectures in terms of accuracy and efficiency trade-off, are increasingly used in many resource-aware vision applications. In this paper, we present Harmonious Bottleneck on two Orthogonal dimensions (HBO), a novel architecture unit, specially tailored to boost the accuracy of extremely lightweight MobileNets at the level of less than 40 MFLOPs. Unlike existing bottleneck designs that mainly focus on exploring the interdependencies among the channels of either groupwise or depthwise convolutional features, our HBO improves bottleneck representation while maintaining similar complexity via jointly encoding the feature interdependencies across both spatial and channel dimensions. It has two reciprocal components, namely spatial contraction-expansion and channel expansion-contraction, nested in a bilaterally symmetric structure. The combination of two interdependent transformations performing on orthogonal dimensions of feature maps enhances the representation and generalization ability of our proposed module, guaranteeing compelling performance with limited computational resource and power. By replacing the original bottlenecks in MobileNetV2 backbone with HBO modules, we construct HBONets which are evaluated on ImageNet classification, PASCAL VOC object detection and Market-1501 person re-identification. Extensive experiments show that with the severe constraint of computational budget our models outperform MobileNetV2 counterparts by remarkable margins of at most 6.6%, 6.3% and 5.0% on the above benchmarks respectively. Code and pretrained models are available at https://github.com/d-li14/HBONet.",60033010,Intel Corporation,Santa Clara,United States,"['1712', '1707']",27.0,0.1866071428571429,0.4092261904761904,1,0.08695652173913043,0.05138339920948617,0.3950617283950617
2240,2290,2290,Free-form video inpainting with 3D gated convolution and temporal patchGAN,"Free-form video inpainting is a very challenging task that could be widely used for video editing such as text removal. Existing patch-based methods could not handle non-repetitive structures such as faces, while directly applying image-based inpainting models to videos will result in temporal inconsistency (see this https://www.youtube.com/watch?v=BuTYfo4bO2I&list=PLnEeMdoBDCISRm0EZYFcQuaJ5ITUaaEIb&index=1). In this paper, we introduce a deep learning based free-form video inpainting model, with proposed 3D gated convolutions to tackle the uncertainty of free-form masks and a novel Temporal PatchGAN loss to enhance temporal consistency. In addition, we collect videos and design a free-form mask generation algorithm to build the free-form video inpainting (FVI) dataset for training and evaluation of video inpainting models. We demonstrate the benefits of these components and experiments on both the FaceForensics and our FVI dataset suggest that our method is superior to existing ones. Related source code, full-resolution result videos and the FVI dataset could be found on Github: Https://github.com/amjltc295/Free-Form-Video-Inpainting.",60005429,National Taiwan University,Taipei,Taiwan,"['1712', '1707']",25.33333333333333,0.16875,0.5625,1,0.16666666666666666,0.03225806451612903,0.43258426966292135
2241,2291,2291,Self-supervised representation learning via neighborhood-relational encoding,"In this paper, we propose a novel self-supervised representation learning by taking advantage of a neighborhood-relational encoding (NRE) among the training data. Conventional unsupervised learning methods only focused on training deep networks to understand the primitive characteristics of the visual data, mainly to be able to reconstruct the data from a latent space. They often neglected the relation among the samples, which can serve as an important metric for self-supervision. Different from the previous work, NRE aims at preserving the local neighborhood structure on the data manifold. Therefore, it is less sensitive to outliers. We integrate our NRE component with an encoder-decoder structure for learning to represent samples considering their local neighborhood information. Such discriminative and unsupervised representation learning scheme is adaptable to different computer vision tasks due to its independence from intense annotation requirements. We evaluate our proposed method for different tasks, including classification, detection, and segmentation based on the learned latent representations. In addition, we adopt the auto-encoding capability of our proposed method for applications like defense against adversarial example attacks and video anomaly detection. Results confirm the performance of our method is better or at least comparable with the state-of-the-art for each specific application, but with a generic and self-supervised approach.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",20.4,0.03803854875283447,0.4388321995464852,1,0.11475409836065574,0.01639344262295082,0.27876106194690264
2242,2292,2292,An alarm system for segmentation algorithm based on shape model,"It is usually hard for a learning system to predict correctly on rare events that never occur in the training data, and there is no exception for segmentation algorithms. Meanwhile, manual inspection of each case to locate the failures becomes infeasible due to the trend of large data scale and limited human resource. Therefore, we build an alarm system that will set off alerts when the segmentation result is possibly unsatisfactory, assuming no corresponding ground truth mask is provided. One plausible solution is to project the segmentation results into a low dimensional feature space; then learn classifiers/regressors to predict their qualities. Motivated by this, in this paper, we learn a feature space using the shape information which is a strong prior shared among different datasets and robust to the appearance variation of input data. The shape feature is captured using a Variational Auto-Encoder (VAE) network that trained with only the ground truth masks. During testing, the segmentation results with bad shapes shall not fit the shape prior well, resulting in large loss values. Thus, the VAE is able to evaluate the quality of segmentation result on unseen data, without using ground truth. Finally, we learn a regressor in the one-dimensional feature space to predict the qualities of segmentation results. Our alarm system is evaluated on several recent state-of-art segmentation algorithms for 3D medical segmentation tasks. Compared with other standard quality assessment methods, our system consistently provides more reliable prediction on the qualities of segmentation results.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",22.272727272727273,0.0538003663003663,0.4275641025641026,1,0.11743772241992882,0.017793594306049824,0.25461254612546125
2243,2293,2293,Cost-aware fine-grained recognition for iots based on sequential fixations,"We consider the problem of fine-grained classification on an edge camera device that has limited power. The edge device must sparingly interact with the cloud to minimize communication bits to conserve power, and the cloud upon receiving the edge inputs returns a classification label. To deal with fine-grained classification, we adopt the perspective of sequential fixation with a foveated field-of-view to model cloud-edge interactions. We propose a novel deep reinforcement learning-based foveation model, DRIFT, that sequentially generates and recognizes mixed-acuity images. Training of DRIFT requires only image-level category labels and encourages fixations to contain task-relevant information, while maintaining data efficiency. Specifically, we train a foveation actor network with a novel Deep Deterministic Policy Gradient by Conditioned Critic and Coaching(DDPGC3) algorithm. In addition, we propose to shape the reward to provide informative feedback after each fixation to better guide RL training. We demonstrate the effectiveness of DRIFT on this task by evaluating on five fine-grained classification benchmark datasets, and show that the proposed approach achieves state-of-the-art performance with over 3X reduction in transmitted pixels.",60019674,Boston University,Boston,United States,"['1712', '1707']",21.625,0.08571428571428573,0.4885714285714286,1,0.1527777777777778,0.032407407407407406,0.359375
2244,2294,2294,Occlusion robust face recognition based on mask learning with pairwise differential siamese network,"Deep Convolutional Neural Networks (CNNs) have been pushing the frontier of face recognition over past years. However, existing CNN models are far less accurate when handling partially occluded faces. These general face models generalize poorly for occlusions on variable facial areas. Inspired by the fact that human visual system explicitly ignores the occlusion and only focuses on the non-occluded facial areas, we propose a mask learning strategy to find and discard corrupted feature elements from recognition. A mask dictionary is firstly established by exploiting the differences between the top conv features of occluded and occlusion-free face pairs using innovatively designed pairwise differential siamese network (PDSN). Each item of this dictionary captures the correspondence between occluded facial areas and corrupted feature elements, which is named Feature Discarding Mask (FDM). When dealing with a face image with random partial occlusions, we generate its FDM by combining relevant dictionary items and then multiply it with the original features to eliminate those corrupted feature elements from recognition. Comprehensive experiments on both synthesized and realistic occluded face datasets show that the proposed algorithm significantly outperforms the state-of-the-art systems.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",22.875,0.06666666666666668,0.4309027777777778,1,0.13744075829383887,0.037914691943127965,0.3781094527363184

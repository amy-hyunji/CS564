,Unnamed: 0,title,abstract,affiliation_code,affiliation_name,affiliation_city,affiliation_country,category,average_length,polarity,subjectivity,passive_active
0,0,Online unsupervised learning of the 3D kinematic structure of arbitrary rigid bodies,"This work addresses the problem of 3D kinematic structure learning of arbitrary articulated rigid bodies from RGB-D data sequences. Typically, this problem is addressed by offline methods that process a batch of frames, assuming that complete point trajectories are available. However, this approach is not feasible when considering scenarios that require continuity and fluidity, for instance, human-robot interaction. In contrast, we propose to tackle this problem in an online unsupervised fashion, by recursively maintaining the metric distance of the scene's 3D structure, while achieving real-time performance. The influence of noise is mitigated by building a similarity measure based on a linear embedding representation and incorporating this representation into the original metric distance. The kinematic structure is then estimated based on a combination of implicit motion and spatial properties. The proposed approach achieves competitive performance both quantitatively and qualitatively in terms of estimation accuracy, even compared to offline methods.",60015150,Imperial College London,London,United Kingdom,"['1712', '1707']",21.142857142857142,0.12166666666666667,0.53,1
1,1,Accurate monocular 3D object detection via color-embedded 3D reconstruction for autonomous driving,"In this paper, we propose a monocular 3D object detection framework in the domain of autonomous driving. Unlike previous image-based methods which focus on RGB feature extracted from 2D images, our method solves this problem in the reconstructed 3D space in order to exploit 3D contexts explicitly. To this end, we first leverage a stand-alone module to transform the input data from 2D image plane to 3D point clouds space for a better input representation, then we perform the 3D detection using PointNet backbone net to obtain objects' 3D locations, dimensions and orientations. To enhance the discriminative capability of point clouds, we propose a multi-modal feature fusion module to embed the complementary RGB cue into the generated point clouds representation. We argue that it is more effective to infer the 3D bounding boxes from the generated 3D scene space (i.e., X,Y, Z space) compared to the image plane (i.e., R,G,B image plane). Evaluation on the challenging KITTI dataset shows that our approach boosts the performance of state-of-the-art monocular approach by a large margin.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",28.833333333333332,0.31084656084656087,0.4920634920634921,1
2,2,Content and style disentanglement for artistic style transfer,"Artists rarely paint in a single style throughout their career. More often they change styles or develop variations of it. In addition, artworks in different styles and even within one style depict real content differently: While Picasso's Blue Period displays a vase in a blueish tone but as a whole, his Cubist works deconstruct the object. To produce artistically convincing stylizations, style transfer models must be able to reflect these changes and variations. Recently many works have aimed to improve the style transfer task, but neglected to address the described observations. We present a novel approach which captures particularities of style and the variations within and separates style and content. This is achieved by introducing two novel losses: A fixpoint triplet style loss to learn subtle variations within one style or between different styles and a disentanglement loss to ensure that the stylization is not conditioned on the real input photo. In addition the paper proposes various evaluation methods to measure the importance of both losses on the validity, quality and variability of final stylizations. We provide qualitative results to demonstrate the performance of our approach.",60016908,Universität Heidelberg,Heidelberg,Germany,"['1712', '1707']",20.666666666666668,0.14677871148459384,0.5081932773109242,1
4,4,Enhancing low light videos by exploring high sensitivity camera noise,"Enhancing low light videos, which consists of denoising and brightness adjustment, is an intriguing but knotty problem. Under low light condition, due to high sensitivity camera setting, commonly negligible noises become obvious and severely deteriorate the captured videos. To recover high quality videos, a mass of image/video denoising/enhancing algorithms are proposed, most of which follow a set of simple assumptions about the statistic characters of camera noise, e.g., independent and identically distributed(i.i.d.), white, additive, Gaussian, Poisson or mixture noises. However, the practical noise under high sensitivity setting in real captured videos is complex and inaccurate to model with these assumptions. In this paper, we explore the physical origins of the practical high sensitivity noise in digital cameras, model them mathematically, and propose to enhance the low light videos based on the noise model by using an LSTM-based neural network. Specifically, we generate the training data with the proposed noise model and train the network with the dark noisy video as input and clear-bright video as output. Extensive comparisons on both synthetic and real captured low light videos with the state-of-the-art methods are conducted to demonstrate the effectiveness of the proposed method.",60033100,Nanjing University,Nanjing,China,"['1712', '1707']",27.285714285714285,0.09160714285714286,0.38547619047619053,1
5,5,Bayes-factor-vae: Hierarchical bayesian deep auto-encoder models for factor disentanglement,"We propose a family of novel hierarchical Bayesian deep auto-encoder models capable of identifying disentangled factors of variability in data. While many recent attempts at factor disentanglement have focused on sophisticated learning objectives within the VAE framework, their choice of a standard normal as the latent factor prior is both suboptimal and detrimental to performance. Our key observation is that the disentangled latent variables responsible for major sources of variability, the relevant factors, can be more appropriately modeled using long-tail distributions. The typical Gaussian priors are, on the other hand, better suited for modeling of nuisance factors. Motivated by this, we extend the VAE to a hierarchical Bayesian model by introducing hyper-priors on the variances of Gaussian latent priors, mimicking an infinite mixture, while maintaining tractable learning and inference of the traditional VAEs. This analysis signifies the importance of partitioning and treating in a different manner the latent dimensions corresponding to relevant factors and nuisances. Our proposed models, dubbed Bayes-Factor-VAEs, are shown to outperform existing methods both quantitatively and qualitatively in terms of latent disentanglement across several challenging benchmark tasks.",123285757,Rutgers University,New Jersey,United States,"['1712', '1707']",25.714285714285715,0.18731060606060607,0.5352272727272727,1
6,6,Bidirectional one-shot unsupervised domain mapping,"We study the problem of mapping between a domain A, in which there is a single training sample and a domain B, for which we have a richer training set. The method we present is able to perform this mapping in both directions. For example, we can transfer all MNIST images to the visual domain captured by a single SVHN image and transform the SVHN image to the domain of the MNIST images. Our method is based on employing one encoder and one decoder for each domain, without utilizing weight sharing. The autoencoder of the single sample domain is trained to match both this sample and the latent space of domain B. Our results demonstrate convincing mapping between domains, where either the source or the target domain are defined by a single sample, far surpassing existing solutions. Our code is made publicly available at https://github.com/tomercohen11/BiOST.",60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,"['1712', '1707']",20.714285714285715,0.12142857142857144,0.38821428571428573,1
7,7,Domain adaptation for semantic segmentation with maximum squares loss,"Deep neural networks for semantic segmentation always require a large number of samples with pixel-level labels, which becomes the major difficulty in their real-world applications. To reduce the labeling cost, unsupervised domain adaptation (UDA) approaches are proposed to transfer knowledge from labeled synthesized datasets to unlabeled real-world datasets. Recently, some semi-supervised learning methods have been applied to UDA and achieved state-of-the-art performance. One of the most popular approaches in semi-supervised learning is the entropy minimization method. However, when applying the entropy minimization to UDA for semantic segmentation, the gradient of the entropy is biased towards samples that are easy to transfer. To balance the gradient of well-classified target samples, we propose the maximum squares loss. Our maximum squares loss prevents the training process being dominated by easy-to-transfer samples in the target domain. Besides, we introduce the image-wise weighting ratio to alleviate the class imbalance in the unlabeled target domain. Both synthetic-to-real and cross-city adaptation experiments demonstrate the effectiveness of our proposed approach. The code is released at https://github. com/ZJULearning/MaxSquareLoss.",60118080,School of Computer and Computing Science,Hangzhou,China,"['1712', '1707']",15.363636363636363,0.25858843537414966,0.5445578231292517,1
8,8,Enhancing 2d representation via adjacent views for 3D shape retrieval,"Multi-view shape descriptors obtained from various 2D images are commonly adopted in 3D shape retrieval. One major challenge is that significant shape information are discarded during 2D view rendering through projection. In this paper, we propose a convolutional neural network based method, CenterNet, to enhance each individual 2D view using its neighboring ones. By exploiting cross-view correlations, CenterNet learns how adjacent views can be maximally incorporated for an enhanced 2D representation to effectively describe shapes. We observe that a very small amount of, e.g., six, enhanced 2D views, are already sufficient for a panoramic shape description. Thus, by simply aggregating features from six enhanced 2D views, we arrive at a highly compact yet discriminative shape descriptor. The proposed shape descriptor significantly outperforms state-of-the-art 3D shape retrieval methods on the ModelNet and ShapeNetCore55 benchmarks, and also exhibits robustness against object occlusion.",60013789,Beihang University,Beijing,China,"['1712', '1707']",20.0,0.09475,0.5867142857142857,1
9,9,Design of searchable algorithm for biological databased on homomorphic encryption,"With the rapid development of biotechnology, researchers are able to obtain large number of genome data sets. However, biological data often involves high privacy and data security issues. Thus when storing, transferring or analyzing these data, a safe and effective method is highly needed. This paper aims to propose a practical scheme using searchable homomorphic encryption. We combined the inverted index mechanism with the interactive operation on the homomorphic encrypted ciphertext data files, so as to realize the management and protection of biological data.",60106769,Neusoft Corporation,Shenyang,China,['1700'],16.8,0.3557142857142857,0.5722619047619047,1
10,10,Language features matter: Effective language representations for vision-language tasks,"Shouldn't language and vision features be treated equally in vision-language (VL) tasks? Many VL approaches treat the language component as an afterthought, using simple language models that are either built upon fixed word embeddings trained on text-only data or are learned from scratch. We conclude that language features deserve more attention, which has been informed by experiments which compare different word embeddings, language models, and embedding augmentation steps on five common VL tasks: Image-sentence retrieval, image captioning, visual question answering, phrase grounding, and text-to-clip retrieval. Our experiments provide some striking results; an average embedding language model outperforms a LSTM on retrieval-style tasks; state-of-the-art representations such as BERT perform relatively poorly on vision-language tasks. From this comprehensive set of experiments we can propose a set of best practices for incorporating the language component of vision-language tasks. To further elevate language features, we also show that knowledge in vision-language problems can be transferred across tasks to gain performance with multi-task training. This multi-task training is applied to a new Graph Oriented Vision-Language Embedding (GrOVLE), which we adapt from Word2Vec using WordNet and an original visual-language graph built from Visual Genome, providing a ready-to-use vision-language embedding: Http://ai.bu.edu/grovle.",60019674,Boston University,Boston,United States,"['1712', '1707']",32.33333333333333,0.13302139037433156,0.43598166539343003,1
11,11,Escaping plato's cave: 3D shape from adversarial rendering,"We introduce PlatonicGAN to discover the 3D structure of an object class from an unstructured collection of 2D images, i.e., where no relation between photos is known, except that they are showing instances of the same category. The key idea is to train a deep neural network to generate 3D shapes which, when rendered to images, are indistinguishable from ground truth images (for a discriminator) under various camera poses. Discriminating 2D images instead of 3D shapes allows tapping into unstructured 2D photo collections instead of relying on curated (e.g., aligned, annotated, etc.) 3D data sets. To establish constraints between 2D image observation and their 3D interpretation, we suggest a family of rendering layers that are effectively differentiable. This family includes visual hull, absorption-only (akin to x-ray), and emission-absorption. We can successfully reconstruct 3D shapes from unstructured 2D images and extensively evaluate PlatonicGAN on a range of synthetic and real data sets achieving consistent improvements over baseline methods. We further show that PlatonicGAN can be combined with 3D supervision to improve on and in some cases even surpass the quality of 3D-supervised methods.",60022148,UCL,London,United Kingdom,"['1712', '1707']",26.0,0.16363636363636364,0.46893939393939393,1
12,12,AVT: Unsupervised learning of transformation equivariant representations by autoencoding variational transformations,"The learning of Transformation-Equivariant Representations (TERs), which is introduced by Hinton et al. cite{hinton2011transforming}, has been considered as a principle to reveal visual structures under various transformations. It contains the celebrated Convolutional Neural Networks (CNNs) as a special case that only equivary to the translations. In contrast, we seek to train TERs for a generic class of transformations and train them in an {em unsupervised} fashion. To this end, we present a novel principled method by Autoencoding Variational Transformations (AVT), compared with the conventional approach to autoencoding data. Formally, given transformed images, the AVT seeks to train the networks by maximizing the mutual information between the transformations and representations. This ensures the resultant TERs of individual images contain the {em intrinsic} information about their visual structures that would equivary {em extricably} under various transformations in a generalized {em nonlinear} case. Technically, we show that the resultant optimization problem can be efficiently solved by maximizing a variational lower-bound of the mutual information. This variational approach introduces a transformation decoder to approximate the intractable posterior of transformations, resulting in an autoencoding architecture with a pair of the representation encoder and the transformation decoder. Experiments demonstrate the proposed AVT model sets a new record for the performances on unsupervised tasks, greatly closing the performance gap to the supervised models.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",21.6,0.07337662337662337,0.39887445887445877,1
13,13,The impact of demography on psychological capital: An empirical study in the retail sector," Psychological capital is a central concept of positive psychology consisting of psychological resources of Self-Efficacy, Hope, Optimism and Resilience. Psychological capital leads to developing the positive behavior and attitude of an individual in the organization. The main objective of the study was to examine which factor of psychological capital influences employees in the retail sector and, secondly, study the correlation between the demographic profile of the respondents and the psychological capital. Around 100 employees were selected in the retail sector and a random sample was used to select the sample size of the population. SPSS 23.00 was used to analyze the data. The result of the study reveals that there is positive significant relationships between work experience, age group, education on psychological capital and designation have no significant relationship with psychological capital.",60026146,"Gandhi Institute of Technology and Management, Visakhapatnam",Visakhapatnam,India,['1706'],22.166666666666668,0.029776936026936027,0.314983164983165,0
14,14,Learning implicit generative models by matching perceptual features,"Perceptual features (PFs) have been used with great success in tasks such as transfer learning, style transfer, and super-resolution. However, the efficacy of PFs as key source of information for learning generative models is not well studied. We investigate here the use of PFs in the context of learning implicit generative models through moment matching (MM). More specifically, we propose a new effective MM approach that learns implicit generative models by performing mean and covariance matching of features extracted from pretrained ConvNets. Our proposed approach improves upon existing MM methods by: (1) breaking away from the problematic min/max game of adversarial learning; (2) avoiding online learning of kernel functions; and (3) being efficient with respect to both number of used moments and required minibatch size. Our experimental results demonstrate that, due to the expressiveness of PFs from pretrained deep ConvNets, our method achieves state-of-the-art results for challenging benchmarks.",60017366,IBM Thomas J. Watson Research Center,Yorktown Heights,United States,"['1712', '1707']",24.666666666666668,0.0963474025974026,0.590503246753247,1
15,15,Improving classification performance of neuro-fuzzy classifier by imputing missing data,"In medical data classification, if the size of data sets is small and if it contains multiple missing attribute values, in such cases improving classification performance is an important issue. The foremost objective of machine learning research is to improve the classification performance of the classifiers. The number of training instances provided for training must be sufficient in size. In the proposed algorithm, we substitute missing attribute values with attribute available domain values and generate additional training tuples that are in addition to original training tuples. These additional, plus original training samples provide sufficient data samples for learning. The neuro-fuzzy classifier trained on this dataset. The classification performance on test data for the neurofuzzy classifier is obtained using the k-fold cross-validation method. The proposed method attains around 2.8% and 3.61% improvement in classification accuracy for this classifier.",60026146,"Gandhi Institute of Technology and Management, Visakhapatnam",Visakhapatnam,India,"['1701', '1712', '1710', '1708', '1705']",17.125,0.08181818181818182,0.3636363636363636,1
16,16,Adversarial defense via learning to generate diverse attacks,"With the remarkable success of deep learning, Deep Neural Networks (DNNs) have been applied as dominant tools to various machine learning domains. Despite this success, however, it has been found that DNNs are surprisingly vulnerable to malicious attacks; adding a small, perceptually indistinguishable perturbations to the data can easily degrade classification performance. Adversarial training is an effective defense strategy to train a robust classifier. In this work, we propose to utilize the generator to learn how to create adversarial examples. Unlike the existing approaches that create a one-shot perturbation by a deterministic generator, we propose a recursive and stochastic generator that produces much stronger and diverse perturbations that comprehensively reveal the vulnerability of the target classifier. Our experiment results on MNIST and CIFAR-10 datasets show that the classifier adversarially trained with our method yields more robust performance over various white-box and black-box attacks.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,"['1712', '1707']",23.833333333333332,0.17948717948717946,0.44487179487179485,1
17,17,S2GAN: Share aging factors across ages and share aging trends among individuals,"Generally, we human follow the roughly common aging trends, e.g., the wrinkles only tend to be more, longer or deeper. However, the aging process of each individual is more dominated by his/her personalized factors, including the invariant factors such as identity and mole, as well as the personalized aging patterns, e.g., one may age by graying hair while another may age by receding hairline. Following this biological principle, in this work, we propose an effective and efficient method to simulate natural aging. Specifically, a personalized aging basis is established for each individual to depict his/her own aging factors. Then different ages share this basis, being derived through age-specific transforms. The age-specific transforms represent the aging trends which are shared among all individuals. The proposed method can achieve continuous face aging with favorable aging accuracy, identity preservation, and fidelity. Furthermore, befitted from the effective design, a unique model is capable of all ages and the prediction time is significantly saved.",60030904,Institute of Computing Technology Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",19.875,0.2088235294117647,0.5808823529411766,1
18,18,Reinforcement learning based signal quality aware handover scheme for LEO satellite communication networks,"With the increasing of Low Earth Orbit (LEO) satellites emission, utilizing existing LEO satellite network systems have lower CAPEX/OPEX than deploying fixed terrestrial network systems in the remote area. Due to the high mobility of LEO satellites, mobility management mechanisms such as handover schemes are the key issue should be settled on leveraging the merits of LEO satellites telecommunications (e.g. lower propagation delay than GEO satellites). In traditional handover schemes, choosing which one is the next-hop satellite for one user is only determined by evaluating some specific criteria in the current state, not guaranteeing long-term and global optimization. To solve this problem, we use the cumulative signal quality that involves the remaining service time and signal quality and propose a Q-Learning based handover scheme. The simulation results show that the proposed scheme improves the overall signal quality and reduce the average handover number of users compared with other handover schemes.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],25.0,-0.015,0.39156250000000004,1
19,19,Discriminatively learned convex models for set based face recognition,"Majority of the image set based face recognition methods use a generatively learned model for each person that is learned independently by ignoring the other persons in the gallery set. In contrast to these methods, this paper introduces a novel method that searches for discriminative convex models that best fit to an individual's face images but at the same time are as far as possible from the images of other persons in the gallery. We learn discriminative convex models for both affine and convex hulls of image sets. During testing, distances from the query set images to these models are computed efficiently by using simple matrix multiplications, and the query set is assigned to the person in the gallery whose image set is closest to the query images. The proposed method significantly outperforms other methods using generative convex models in terms of both accuracy and testing time, and achieves the state-of-the-art results on four of the five tested datasets. Especially, the accuracy improvement is significant on the challenging PaSC, COX and ESOGU video datasets.",60029016,Eskişehir Osmangazi Üniversitesi,Eskisehir,Turkey,"['1712', '1707']",29.0,0.16710526315789476,0.5780075187969924,1
20,20,Machine learning in short video APP user activity prediction,"In order to improve the accuracy and reduce the cost of forecasting, this paper uses machine learning related technology to solve this problem in the user activity prediction model of short video industry. Continuous use of short video APP by active users is a sufficient and necessary condition for its success. The prediction of user activity has a direct guiding effect on the subsequent user loss warning. Based on the analysis of the impact on user activity, this paper extracts the characteristics according to registration log, startup log, shooting log and behavior log, and proposes a prediction algorithm based on model fusion for user activity. Based on the experimental data, the results show that the predicted AUC value reached 0.9514.",60007711,Jilin University,Changchun,China,['1700'],24.0,0.040740740740740744,0.3833333333333333,1
21,21,Face video deblurring using 3D facial priors,"Existing face deblurring methods only consider single frames and do not account for facial structure and identity information. These methods struggle to deblur face videos that exhibit significant pose variations and misalignment. In this paper we propose a novel face video deblurring network capitalizing on 3D facial priors. The model consists of two main branches: I) a face video deblurring sub-network based on an encoder-decoder architecture, and ii) a 3D face reconstruction and rendering branch for predicting 3D priors of salient facial structures and identity knowledge. These structures encourage the deblurring branch to generate sharp faces with detailed structures. Our method not only uses low-level information (i.e., image intensity), but also middle-level information (i.e., 3D facial structure) and high-level knowledge (i.e., identity content) to further explore spatial constraints of facial components from blurry face frames. Extensive experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",21.285714285714285,0.05634920634920635,0.41039682539682537,1
22,22,A study on the awareness level among consumers towards environment friendly cars with reference to Indore, Green automobiles are those that are having a more environment friendly manifestation. Indian automobile industry in the current scenario is engaged in the process of providing the type of vehicles that are having the green concept promoting technology. This paper is an empirical study of the awareness level among the consumers towards the green automobiles. This paper would help proclaim a picture of the present mental setup of the masses which would help the automobile industry visualize the acceptability of the green automobiles. This paper would also help how far the different technology is preferred among the consumers.,60115094,"Prestige Institute of Management And Research, Indore",Indore,India,['1706'],19.8,0.014583333333333335,0.375,0
23,23,Shape reconstruction using differentiable projections and deep priors,"We investigate the problem of reconstructing shapes from noisy and incomplete projections in the presence of viewpoint uncertainities. The problem is cast as an optimization over the shape given measurements obtained by a projection operator and a prior. We present differentiable projection operators for a number of reconstruction problems which when combined with the deep image prior or shape prior allows efficient inference through gradient descent. We apply our method on a variety of reconstruction problems, such as tomographic reconstruction from a few samples, visual hull reconstruction incorporating view uncertainties, and 3D shape reconstruction from noisy depth maps. Experimental results show that our approach is effective for such shape reconstruction problems, without requiring any task-specific training.",60014313,University of Massachusetts Amherst,Amherst MA,United States,"['1712', '1707']",23.2,0.045454545454545456,0.24545454545454548,1
24,24,Retail investors awareness towards equity investment - With reference to Bhopal city," This is done with the help of mutual fund investors or through the retail investors. The retail Investors in India are very few as compared to the other investors who are investing through other financial services. This paper works on the behavior pattern of the retail investors with special reference to Bhopal. The investment by these investors at time is overshadowed by the level of understanding they have about financial securities and their experiences with the stock market. The retail investors have some apprehensions regarding the working of stock market and the feeling lurks in their mind, that whatever theory says, the stock market may not work as per the fundamental analysis or even on the basis of technical analysis, which though is very explicit, yet may not reflect the true picture. The general perception by the retail investors is the market works on random events or there are certain stock giants who make the market. Keeping this in mind the research is conducted by taking into consideration five factors, which include retail investors’ predictive skills, purchase price of the stock as a reference point for trading, experiences with National Stock Exchange, preference of short term investment and sticking on to looser stock and selling the winners. The study supports the given factors which reflect the behavior of these investors.",105949077,SIRT,Bhopal,India,['1706'],27.625,0.01241758241758242,0.3363736263736264,0
25,25,Analysis of influencing factors of PV based ensemble modeling for PV power and application in prediction,"According to the volatility and intermittent characteristics of photovoltaic power generation. Integrating PV power to the grid have an impact on the stability and safety. To address this challenge, the work learns the effect of support vector machine (SVM) and several algorithms on forecast. An algorithm model for improving the prediction accuracy of training data for multiple groups of factors has been proposed. The model consists of gradient boosting decision tree (GBDT), Particle Swarm Optimization (PSO) and SVM. Finally, according to the integrated algorithm, assigning weak learners’ weights and integrating become strong learners. The GBDT algorithm is able to find the factors with high correlation coefficient in the data to establish the model, avoiding of using the empirical method to select the factors. The PSO algorithm finds the optimal parameters of the SVM algorithm and the optimal weight of the weak learner. Compared with BP and traditional SVM, the model established by the data without determining the weather type can obtain better prediction accuracy.",60017080,China Jiliang University,Hangzhou,China,['1700'],18.22222222222222,0.08575757575757575,0.4998484848484848,1
26,26,POD: Practical object detection with scale-sensitive network,"Scale-sensitive object detection remains a challenging task, where most of the existing methods not learn it explicitly and not robust to scale variance. In addition, the most existing methods are less efficient during training or slow during inference, which are not friendly to real-time application. In this paper, we propose a practical object detection with scale-sensitive network.Our method first predicts a global continuous scale ,which shared by all position, for each convolution filter of each network stage. To effectively learn the scale, we average the spatial features and distill the scale from channels. For fast-deployment, we propose a scale decomposition method that transfers the robust fractional scale into combinations of fixed integral scales for each convolution filter, which exploit the dilated convolution. We demonstrate it on one-stage and two-stage algorithm under almost different configure. For practical application, training of our method is of efficiency and simplicity which gets rid of complex data sampling or optimize strategy. During testing, the proposed method requires no extra operation and is very friendly to hardware acceleration like TensorRT and TVM.On the COCO test-dev, our model could achieve a 41.5mAP on one-stage detector and 42.1 mAP on two-stage detectors based on ResNet-101, outperforming baselines by 2.4 and 2.1 respectively without extra FLOPS.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",25.875,0.10784313725490197,0.3911764705882353,1
27,27,Explaining the ambiguity of object detection and 6D pose from visual data,"3D object detection and pose estimation from a single image are two inherently ambiguous problems. Oftentimes, objects appear similar from different viewpoints due to shape symmetries, occlusion and repetitive textures. This ambiguity in both detection and pose estimation means that an object instance can be perfectly described by several different poses and even classes. In this work we propose to explicitly deal with these ambiguities. For each object instance we predict multiple 6D pose outcomes to estimate the specific pose distribution generated by symmetries and repetitive textures. The distribution collapses to a single outcome when the visual appearance uniquely identifies just one valid pose. We show the benefits of our approach which provides not only a better explanation for pose ambiguity, but also a higher accuracy in terms of pose estimation.",60092530,"Huawei Technologies Co., Ltd.",Shenzhen,China,"['1712', '1707']",18.714285714285715,0.07983193277310925,0.4134453781512605,1
28,28,USIP: Unsupervised stable interest point detection from 3D point clouds,"In this paper, we propose the USIP detector: An Unsupervised Stable Interest Point detector that can detect highly repeatable and accurately localized keypoints from 3D point clouds under arbitrary transformations without the need for any ground truth training data. Our USIP detector consists of a feature proposal network that learns stable keypoints from input 3D point clouds and their respective transformed pairs from randomly generated transformations. We provide degeneracy analysis and suggest solutions to prevent it. We encourage high repeatability and accurate localization of the keypoints with a probabilistic chamfer loss that minimizes the distances between the detected keypoints from the training point cloud pairs. Extensive experimental results of repeatability tests on several simulated and real-world 3D point cloud datasets from Lidar, RGB-D and CAD models show that our USIP detector significantly outperforms existing hand-crafted and deep learning-based 3D keypoint detectors. Our code is available at the project website. https://github.com/lijx10/USIP.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",21.428571428571427,0.10730769230769231,0.45807692307692316,1
29,29,HiPPI: Higher-order projected power iterations for scalable multi-matching,"The matching of multiple objects (e.g. shapes or images) is a fundamental problem in vision and graphics. In order to robustly handle ambiguities, noise and repetitive patterns in challenging real-world settings, it is essential to take geometric consistency between points into account. Computationally, the multi-matching problem is difficult. It can be phrased as simultaneously solving multiple (NP-hard) quadratic assignment problems (QAPs) that are coupled via cycle-consistency constraints. The main limitations of existing multi-matching methods are that they either ignore geometric consistency and thus have limited robustness, or they are restricted to small-scale problems due to their (relatively) high computational cost. We address these shortcomings by introducing a Higher-order Projected Power Iteration method, which is (i) efficient and scales to tens of thousands of points, (ii) straightforward to implement, (iii) able to incorporate geometric consistency, (iv) guarantees cycle-consistent multi-matchings, and (iv) comes with theoretical convergence guarantees. Experimentally we show that our approach is superior to existing methods.",60022085,Högskolan i Halmstad,Halmstad,Sweden,"['1712', '1707']",19.5,0.10368253968253968,0.42274603174603176,1
30,30,Unsupervised deep learning for structured shape matching,"We present a novel method for computing correspondences across 3D shapes using unsupervised learning. Our method computes a non-linear transformation of given descriptor functions, while optimizing for global structural properties of the resulting maps, such as their bijectivity or approximate isometry. To this end, we use the functional maps framework, and build upon the recent FMNet architecture for descriptor learning. Unlike that approach, however, we show that learning can be done in a purely emph{unsupervised setting}, without having access to any ground truth correspondences. This results in a very general shape matching method that we call SURFMNet for Spectral Unsupervised FMNet, and which can be used to establish correspondences within 3D shape collections without any prior information. We demonstrate on a wide range of challenging benchmarks, that our approach leads to state-of-the-art results compared to the existing unsupervised methods and achieves results that are comparable even to the supervised learning techniques. Moreover, our framework is an order of magnitude faster, and does not rely on geodesic distance computation or expensive post-processing.",60028952,Laboratoire d'Informatique de l'Ecole Polytechnique,Palaiseau,France,"['1712', '1707']",24.428571428571427,-0.020064935064935067,0.41818181818181815,1
31,31,Gaze360: Physically unconstrained gaze estimation in the wild,"Understanding where people are looking is an informative social cue. In this work, we present Gaze360, a large-scale remote gaze-tracking dataset and method for robust 3D gaze estimation in unconstrained images. Our dataset consists of 238 subjects in indoor and outdoor environments with labelled 3D gaze across a wide range of head poses and distances. It is the largest publicly available dataset of its kind by both subject and variety, made possible by a simple and efficient collection method. Our proposed 3D gaze model extends existing models to include temporal information and to directly output an estimate of gaze uncertainty. We demonstrate the benefits of our model via an ablation study, and show its generalization performance via a cross-dataset evaluation against other recent gaze benchmark datasets. We furthermore propose a simple self-supervised approach to improve cross-dataset domain adaptation. Finally, we demonstrate an application of our model for estimating customer attention in a supermarket setting. Our dataset and models will be made available at http://gaze360.csail.mit.edu.",60022195,Massachusetts Institute of Technology,Cambridge,United States,"['1712', '1707']",18.22222222222222,0.06944444444444443,0.4292857142857143,1
32,32,Customer evaluation-based automobile after-sale service multi-value-chain collaborative mechanism verification,"In the automotive after-sales service cycle, according to the historical information of the service received by the customer during the period of warranty services of repair, replacement and refund, the customer’s willingness to choose the out-of-warranty service is evaluated, and differentiated collaborative services are provided, which can effectively improve the service quality. This paper proposes a collaborative mechanism design and verification method of automobile after-sales service multi-value-chain based on customer evaluation. First, it studies the composition of the service value chain during the warranty period, outside of the warranty period, and the insurance service, explores the source of income and gain factors of each value process to discover the appropriate service business and proving the ability of customer assessment for value creation in the value process. Then, establish a colored Petri Net model for each service value chain, the resources required for after-sales service are mapped to Token in Place and Place and the income is mapped to Transition, which can simulate the gain process of a single service-value-chain. Finally, based on the customer evaluation level, the design provides a differentiated automobile after-sales collaborative service multi-value-chain mechanism, generates the random customer sequence. And the gain effect of multi-value-chain in collaborative status is simulated and operated on the CPN Tools which is a running platform based on colored Petri Net. The results show that the above-mentioned mechanism makes the expenses of important customers relatively reduced, and the income of service providers and insurers increased which is conducive to maintain the ability of auto service providers to extend after-sales service. In addition, it provides a quantitative basis for collaborative optimization of service multi-value-chain.",60025256,Institute of Software Chinese Academy of Sciences,Beijing,China,['1700'],33.875,0.09821428571428574,0.36646825396825394,1
33,33,Multi-scale attentive residual network for single image deraining,"Removing rain streaks from a single image is extremely challenging since the appearance of rain streaks in shapes, scales and densities is ever changing. Therefore, we propose a novel end-to-end two- stage multi-scale attentive residual network that is both location-aware and density-aware, in order to preferably remove various rain streaks. Specifically, in the first stage, a multi-scale progressive attention sub- network is designed to automatically locate the distribution of diverse rain streaks and further to guide the following deraining. Then the second stage with the guidance of the attention map generated in the former stage aims to efficiently remove various rain streaks. To aggregate the characteristics of rain streaks with different scales and densities, we construct a multi-scale residual sub-network in which dilated convolution and residual learning are used to combine these features. As a result, these two sub-networks make up the whole network, and accomplish the process of joint detection and removal of diverse rain streaks fairly well. Extensive experiments on both synthetic and real-world rainy images demonstrate that our proposed method significantly outperforms several recent state-of-the-art approaches.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],25.571428571428573,0.1384453781512605,0.43564425770308124,1
34,34,Adaptive wing loss for robust face alignment via heatmap regression,"Heatmap regression with a deep network has become one of the mainstream approaches to localize facial landmarks. However, the loss function for heatmap regression is rarely studied. In this paper, we analyze the ideal loss function properties for heatmap regression in face alignment problems. Then we propose a novel loss function, named Adaptive Wing loss, that is able to adapt its shape to different types of ground truth heatmap pixels. This adaptability penalizes loss more on foreground pixels while less on background pixels. To address the imbalance between foreground and background pixels, we also propose Weighted Loss Map, which assigns high weights on foreground and difficult background pixels to help training process focus more on pixels that are crucial to landmark localization. To further improve face alignment accuracy, we introduce boundary prediction and CoordConv with boundary coordinates. Extensive experiments on different benchmarks, including COFW, 300W and WFLW, show our approach outperforms the state-of-the-art by a significant margin on various evaluation metrics. Besides, the Adaptive Wing loss also helps other heatmap regression tasks.",60013402,Oregon State University,Corvallis,United States,"['1712', '1707']",19.11111111111111,0.13574074074074077,0.5730555555555555,1
35,35,LayoutVAE: Stochastic scene layout generation from a label set,"Recently there is an increasing interest in scene generation within the research community. However, models used for generating scene layouts from textual description largely ignore plausible visual variations within the structure dictated by the text. We propose LayoutVAE, a variational autoencoder based framework for generating stochastic scene layouts. LayoutVAE is a versatile modeling framework that allows for generating full image layouts given a label set, or per label layouts for an existing image given a new label. In addition, it is also capable of detecting unusual layouts, potentially providing a way to evaluate layout generation problem. Extensive experiments on MNIST-Layouts and challenging COCO 2017 Panoptic dataset verifies the effectiveness of our proposed framework.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",18.833333333333332,0.1909681227863046,0.5378591105863832,1
36,36,Progressive reconstruction of visual structure for image inpainting,"Inpainting methods aim to restore missing parts of corrupted images and play a critical role in many computer vision applications, such as object removal and image restoration. Although existing methods perform well on images with small holes, restoring large holes remains elusive. To address this issue, this paper proposes a Progressive Reconstruction of Visual Structure (PRVS) network that progressively reconstructs the structures and the associated visual feature. Specifically, we design a novel Visual Structure Reconstruction (VSR) layer to entangle reconstructions of the visual structure and visual feature, which benefits each other by sharing parameters. We repeatedly stack four VSR layers in both encoding and decoding stages of a U-Net like architecture to form the generator of a generative adversarial network (GAN) for restoring images with either small or large holes. We prove the generalization error upper bound of the PRVS network is O(1sqrt(N)), which theoretically guarantees its performance. Extensive empirical evaluations and comparisons on Places2, Paris Street View and CelebA datasets validate the strengths of the proposed approach and demonstrate that the model outperforms current state-of-the-art methods. The source code package is available at https://github.com/jingyuanli001/PRVS-Image-Inpainting.",60029306,Wuhan University,Wuhan,China,"['1712', '1707']",23.125,0.030178571428571426,0.2607738095238095,1
37,37,Personalized fashion design,"Fashion recommendation is the task of suggesting a fashion item that fits well with a given item. In this work, we propose to automatically synthesis new items for recommendation. We jointly consider the two key issues for the task, i.e., compatibility and personalization. We propose a personalized fashion design framework with the help of generative adversarial training. A convolutional network is first used to map the query image into a latent vector representation. This latent representation, together with another vector which characterizes user's style preference, are taken as the input to the generator network to generate the target item image. Two discriminator networks are built to guide the generation process. One is the classic real/fake discriminator. The other is a matching network which simultaneously models the compatibility between fashion items and learns users' preference representations. The performance of the proposed method is evaluated on thousands of outfits composited by online users. The experiments show that the items generated by our model are quite realistic. They have better visual quality and higher matching degree than those generated by alternative methods.",60005465,University of Electronic Science and Technology of China,Chengdu,China,"['1712', '1707']",14.916666666666666,0.1494107744107744,0.406986531986532,1
38,38,Semi-supervised domain adaptation via minimax entropy,"Contemporary domain adaptation methods are very effective at aligning feature distributions of source and target domains without any target supervision. However, we show that these techniques perform poorly when even a few labeled examples are available in the target domain. To address this semi-supervised domain adaptation (SSDA) setting, we propose a novel Minimax Entropy (MME) approach that adversarially optimizes an adaptive few-shot model. Our base model consists of a feature encoding network, followed by a classification layer that computes the features' similarity to estimated prototypes (representatives of each class). Adaptation is achieved by alternately maximizing the conditional entropy of unlabeled target data with respect to the classifier and minimizing it with respect to the feature encoder. We empirically demonstrate the superiority of our method over many baselines, including conventional feature alignment and few-shot methods, setting a new state of the art for SSDA. Our code is available at url{http://cs-people.bu.edu/keisaito/research/MME.html}.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",21.285714285714285,0.07834776334776335,0.4231962481962482,1
39,39,Metric learning with HORDE: High-order regularizer for deep embeddings,"Learning an effective similarity measure between image representations is key to the success of recent advances in visual search tasks (e.g. verification or zero-shot learning). Although the metric learning part is well addressed, this metric is usually computed over the average of the extracted deep features. This representation is then trained to be discriminative. However, these deep features tend to be scattered across the feature space. Consequently, the representations are not robust to outliers, object occlusions, background variations, etc. In this paper, we tackle this scattering problem with a distribution-aware regularization named HORDE. This regularizer enforces visually-close images to have deep features with the same distribution which are well localized in the feature space. We provide a theoretical analysis supporting this regularization effect. We also show the effectiveness of our approach by obtaining state-of-the-art results on 4 well-known datasets (Cub-200-2011, Cars-196, Stanford Online Products and Inshop Clothes Retrieval).",60126116,Equipes Traitement de l'Information et Systèmes,Cergy-Pontoise,France,"['1712', '1707']",14.8,0.05769230769230768,0.33653846153846145,1
40,40,Order batch optimization based on improved K-means algorithm,"Aiming at the shortcomings of the K-Means algorithm in the traditional K-Means algorithm, the DBSCAN algorithm is used to divide the order set according to the density, and obtain the batch number K value and the initial cluster center point. Based on this, the improved K-Means algorithm is used for optimization. Based on the real environment and instance data, the established batch assignment batch model is simulated. The experimental results show that the density-based K-Means clustering algorithm can effectively shorten the picking time and improve the warehouse logistics operation.",60022414,Wuhan University of Technology,Wuhan,China,['1700'],22.25,0.13333333333333333,0.3916666666666666,1
41,41,Fully convolutional pixel adaptive image denoiser,"We propose a new image denoising algorithm, dubbed as Fully Convolutional Adaptive Image DEnoiser (FC-AIDE), that can learn from an offline supervised training set with a fully convolutional neural network as well as adaptively fine-tune the supervised model for each given noisy image. We significantly extend the framework of the recently proposed Neural AIDE, which formulates the denoiser to be context-based pixelwise mappings and utilizes the unbiased estimator of MSE for such denoisers. The two main contributions we make are; 1) implementing a novel fully convolutional architecture that boosts the base supervised model, and 2) introducing regularization methods for the adaptive fine-tuning such that a stronger and more robust adaptivity can be attained. As a result, FC-AIDE is shown to possess many desirable features; it outperforms the recent CNN-based state-of-the-art denoisers on all of the benchmark datasets we tested, and gets particularly strong for various challenging scenarios, e.g., with mismatched image/noise characteristics or with scarce supervised training data. The source code our algorithm is available at href{https://github.com/csm9493/FC-AIDE-Keras}{textcolor{magenta}{https://github.com/csm9493/FC-AIDE-Keras}}.",60007511,Sungkyunkwan University,Jongno-gu,South Korea,"['1712', '1707']",33.4,0.15795454545454546,0.5568722943722945,1
42,42,Fast image restoration with multi-bin trainable linear units,"Tremendous advances in image restoration tasks such as denoising and super-resolution have been achieved using neural networks. Such approaches generally employ very deep architectures, large number of parameters, large receptive fields and high nonlinear modeling capacity. In order to obtain efficient and fast image restoration networks one should improve upon the above mentioned requirements. In this paper we propose a novel activation function, the multi-bin trainable linear unit (MTLU), for increasing the nonlinear modeling capacity together with lighter and shallower networks. We validate the proposed fast image restoration networks for image denoising (FDnet) and super-resolution (FSRnet) on standard benchmarks. We achieve large improvements in both memory and runtime over current state-of-the-art for comparable or better PSNR accuracies.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",19.5,0.13907936507936508,0.46971428571428564,1
43,43,Human mesh recovery from monocular images via a skeleton-disentangled representation,"We describe an end-to-end method for recovering 3D human body mesh from single images and monocular videos. Different from the existing methods try to obtain all the complex 3D pose, shape, and camera parameters from one coupling feature, we propose a skeleton-disentangling based framework, which divides this task into multi-level spatial and temporal granularity in a decoupling manner. In spatial, we propose an effective and pluggable 'disentangling the skeleton from the details' (DSD) module. It reduces the complexity and decouples the skeleton, which lays a good foundation for temporal modeling. In temporal, the self-attention based temporal convolution network is proposed to efficiently exploit the short and long-term temporal cues. Furthermore, an unsupervised adversarial training strategy, temporal shuffles and order recovery, is designed to promote the learning of motion dynamics. The proposed method outperforms the state-of-the-art 3D human mesh recovery methods by 15.4% MPJPE and 23.8% PA-MPJPE on Human3.6M. State-of-the-art results are also achieved on the 3D pose in the wild (3DPW) dataset without any fine-tuning. Especially, ablation studies demonstrate that skeleton-disentangled representation is crucial for better temporal modeling and generalization.",60019616,Harbin Institute of Technology,Harbin,China,"['1712', '1707']",20.0,0.12738095238095237,0.5011904761904762,1
44,44,Disentangled image matting,"Most previous image matting methods require a roughly-specificed trimap as input, and estimate fractional alpha values for all pixels that are in the unknown region of the trimap. In this paper, we argue that directly estimating the alpha matte from a coarse trimap is a major limitation of previous methods, as this practice tries to address two difficult and inherently different problems at the same time: Identifying true blending pixels inside the trimap region, and estimate accurate alpha values for them. We propose AdaMatting, a new end-to-end matting framework that disentangles this problem into two sub-tasks: Trimap adaptation and alpha estimation. Trimap adaptation is a pixel-wise classification problem that infers the global structure of the input image by identifying definite foreground, background, and semi-transparent image regions. Alpha estimation is a regression problem that calculates the opacity value of each blended pixel. Our method separately handles these two sub-tasks within a single deep convolutional neural network (CNN). Extensive experiments show that AdaMatting has additional structure awareness and trimap fault-tolerance. Our method achieves the state-of-the-art performance on Adobe Composition-1k dataset both qualitatively and quantitatively. It is also the current best-performing method on the alphamatting.com online evaluation for all commonly-used metrics.",60014966,Peking University,Beijing,China,"['1712', '1707']",22.0,0.022205086580086585,0.4271915584415584,1
45,45,Weakly aligned cross-modal learning for multispectral pedestrian detection,"Multispectral pedestrian detection has shown great advantages under poor illumination conditions, since the thermal modality provides complementary information for the color image. However, real multispectral data suffers from the position shift problem, i.e. the color-thermal image pairs are not strictly aligned, making one object has different positions in different modalities. In deep learning based methods, this problem makes it difficult to fuse the feature maps from both modalities and puzzles the CNN training. In this paper, we propose a novel Aligned Region CNN (AR-CNN) to handle the weakly aligned multispectral data in an end-to-end way. Firstly, we design a Region Feature Alignment (RFA) module to capture the position shift and adaptively align the region features of the two modalities. Secondly, we present a new multimodal fusion method, which performs feature re-weighting to select more reliable features and suppress the useless ones. Besides, we propose a novel RoI jitter strategy to improve the robustness to unexpected shift patterns of different devices and system settings. Finally, since our method depends on a new kind of labelling: Bounding boxes that match each modality, we manually relabel the KAIST dataset by locating bounding boxes in both modalities and building their relationships, providing a new KAIST-Paired Annotation. Extensive experimental validations on existing datasets are performed, demonstrating the effectiveness and robustness of the proposed method. Code and data are available at https://github.com/luzhang16/AR-CNN.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.545454545454547,0.04278656126482214,0.5480566534914362,1
46,46,3D-RelNet: Joint object and relational network for 3D prediction,"We propose an approach to predict the 3D shape and pose for the objects present in a scene. Existing learning based methods that pursue this goal make independent predictions per object, and do not leverage the relationships amongst them. We argue that reasoning about these relationships is crucial, and present an approach to incorporate these in a 3D prediction framework. In addition to independent per-object predictions, we predict pairwise relations in the form of relative 3D pose, and demonstrate that these can be easily incorporated to improve object level estimates. We report performance across different datasets (SUNCG, NYUv2), and show that our approach significantly improves over independent prediction approaches while also outperforming alternate implicit reasoning methods.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",23.2,0.07348484848484849,0.3348484848484849,1
47,47,Hierarchical shot detector,"Single shot detector simultaneously predicts object categories and regression offsets of the default boxes. Despite of high efficiency, this structure has some inappropriate designs: (1) The classification result of the default box is improperly assigned to that of the regressed box during inference, (2) Only regression once is not good enough for accurate object detection. To solve the first problem, a novel reg-offset-cls (ROC) module is proposed. It contains three hierarchical steps: Box regression, the feature sampling location predication, and the regressed box classification with the features of offset locations. To further solve the second problem, a hierarchical shot detector (HSD) is proposed, which stacks two ROC modules and one feature enhanced module. The second ROC treats the regressed boxes and the feature sampling locations of features in the first ROC as the inputs. Meanwhile, the feature enhanced module injected between two ROCs aims to extract the local and non-local context. Experiments on the MS COCO and PASCAL VOC datasets demonstrate the superiority of proposed HSD. Without the bells or whistles, HSD outperforms all one-stage methods at real-time speed.",60022020,The University of Warwick,Coventry,United Kingdom,"['1712', '1707']",19.88888888888889,-0.008571428571428572,0.4349450549450549,1
48,48,Extreme view synthesis,"We present Extreme View Synthesis, a solution for novel view extrapolation that works even when the number of input images is small - -as few as two. In this context, occlusions and depth uncertainty are two of the most pressing issues, and worsen as the degree of extrapolation increases. We follow the traditional paradigm of performing depth-based warping and refinement, with a few key improvements. First, we estimate a depth probability volume, rather than just a single depth value for each pixel of the novel view. This allows us to leverage depth uncertainty in challenging regions, such as depth discontinuities. After using it to get an initial estimate of the novel view, we explicitly combine learned image priors and the depth uncertainty to synthesize a refined image with less artifacts. Our method is the first to show visually pleasing results for baseline magnifications of up to 30x.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",21.0,0.030431547619047622,0.39360119047619047,1
49,49,Financial performance ranking of nationalized banks through integrated AHM-GRA-DEA method, In this work AHM methodology is applied to determine weightages of CAMEL ratios and after obtaining weightages Grey Relation analysis is applied to get Grey Relation coefficient and then these two are applied in Data Envelop Analysis to obtain ranks.,60023544,Andhra University,Visakhapatnam,India,['1706'],41.0,-0.05,0.1,0
50,50,Efficient learning on point clouds with basis point sets,"With an increased availability of 3D scanning technology, point clouds are moving into the focus of computer vision as a rich representation of everyday scenes. However, they are hard to handle for machine learning algorithms due to the unordered structure. One common approach is to apply voxelization, which dramatically increases the amount of data stored and at the same time loses details through discretization. Recently, deep learning models with hand-tailored architectures were proposed to handle point clouds directly and achieve input permutation invariance. However, these architectures use an increased number of parameters and are computationally inefficient. In this work we propose basis point sets as a highly efficient and fully general way to process point clouds with machine learning algorithms. Basis point sets are a residual representation that can be computed efficiently and can be used with standard neural network architectures. Using the proposed representation as the input to a relatively simple network allows us to match the performance of PointNet on a shape classification task while using three order of magnitudes less floating point operations. In a second experiment, we show how proposed representation can be used for obtaining high resolution meshes from noisy 3D scans. Here, our network achieves performance comparable to the state-of-the-art computationally intense multi-step frameworks, in one network pass that can be done in less than 1ms.",60030569,Max Planck Institute for Intelligent Systems,Tubingen,Germany,"['1712', '1707']",22.2,-0.028055555555555556,0.38123015873015864,1
51,51,Joint neural collaborative filtering with basic side information,"Nowadays, deep neural network has been greatly developed and widely used in many areas. However, the research of the deep neural network on recommendation system is inadequate. Most research focuses on analyzing the textual descriptions of items and comments of users, making use of the neural network to get feature vectors from texts or pictures. In this paper, we directly adopt the deep neural network to better fit the non-linear relationship of users and items and effectively integrate some side information (basic information and statistical information) into the neural network. Utilizing deep neural network, we explore the impact of some basic information on neural collaborative filtering. To the best of our knowledge, it is the first time to combine the basic information, statistical information and rating matrix by the deep neural network. Finally, we use the benchmark data set (MovieLens) to demonstrate the effectiveness of the proposed deep neural network model with side information.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],22.0,0.1925,0.4104166666666667,1
52,52,Unsupervised learning of landmarks by descriptor vector exchange,"Equivariance to random image transformations is an effective method to learn landmarks of object categories, such as the eyes and the nose in faces, without manual supervision. However, this method does not explicitly guarantee that the learned landmarks are consistent with changes between different instances of the same object, such as different facial identities. In this paper, we develop a new perspective on the equivariance approach by noting that dense landmark detectors can be interpreted as local image descriptors equipped with invariance to intra-category variations. We then propose a direct method to enforce such an invariance in the standard equivariant loss. We do so by exchanging descriptor vectors between images of different object instances prior to matching them geometrically. In this manner, the same vectors must work regardless of the specific object identity considered. We use this approach to learn vectors that can simultaneously be interpreted as local descriptors and dense landmarks, combining the advantages of both. Experiments on standard benchmarks show that this approach can match, and in some cases surpass state-of-the-art performance amongst existing methods that learn landmarks without supervision. Code is available at www.robots.ox.ac.uk/∼vgg/research/DVE/.",60027272,University of Edinburgh,Edinburgh,United Kingdom,"['1712', '1707']",20.77777777777778,0.04696969696969697,0.3085497835497836,1
53,53,"Gendered sensitivity of the Cameroonian social planer towards households inequality: An (α, β) – Decomposition"," This is allowed by the multilevel (α, β) - decomposition of the α - Gini which integrate in its functional form a parameter of inequality aversion of the decision maker being related either to within-group inequality (α) or between-group inequality (β). Analysis are carried out by sex groups on data from the third and the fourth Cameroonian Survey on households. It’s appear that the overall inequality index decrease between 2001 and 2007. The Cameroonian social planer appears sensitive to both within group and between group households’ inequalities following decomposition by sex.",60070928,Université de Yaoundé I,Yaounde,Cameroon,['1706'],23.0,0.019047619047619046,0.20952380952380953,0
54,54,Estimating the fundamental matrix without point correspondences with application to transmission imaging,"We present a general method to estimate the fundamental matrix from a pair of images under perspective projection without the need for image point correspondences. Our method is particularly well-suited for transmission imaging, where state-of-the-art feature detection and matching approaches generally do not perform well. Estimation of the fundamental matrix plays a central role in auto-calibration methods for reflection imaging. Such methods are currently not applicable to transmission imaging. Furthermore, our method extends an existing technique proposed for reflection imaging which potentially avoids the outlier-prone feature matching step from an orthographic projection model to a perspective model. Our method exploits the idea that under a linear attenuation model line integrals along corresponding epipolar lines are equal if we compute their derivatives in orthogonal direction to their common epipolar plane. We use the fundamental matrix to parametrize this equality. Our method estimates the matrix by formulating a non-convex optimization problem, minimizing an error in our measurement of this equality. We believe this technique will enable the application of the large body of work on image-based camera pose estimation to transmission imaging leading to more accurate and more general motion compensation and auto-calibration algorithms, particularly in medical X-ray and Computed Tomography imaging.",60000765,Friedrich-Alexander-Universität Erlangen-Nürnberg,Erlangen,Germany,"['1712', '1707']",22.22222222222222,0.09724702380952381,0.42470238095238094,1
55,55,Weakly supervised energy-based learning for action segmentation,"This paper is about labeling video frames with action classes under weak supervision in training, where we have access to a temporal ordering of actions, but their start and end frames in training videos are unknown. Following prior work, we use an HMM grounded on a Gated Recurrent Unit (GRU) for frame labeling. Our key contribution is a new constrained discriminative forward loss (CDFL) that we use for training the HMM and GRU under weak supervision. While prior work typically estimates the loss on a single, inferred video segmentation, our CDFL discriminates between the energy of all valid and invalid frame labelings of a training video. A valid frame labeling satisfies the ground-truth temporal ordering of actions, whereas an invalid one violates the ground truth. We specify an efficient recursive algorithm for computing the CDFL in terms of the logadd function of the segmentation energy. Our evaluation on action segmentation and alignment gives superior results to those of the state of the art on the benchmark Breakfast Action, Hollywood Extended, and 50Salads datasets.",60013402,Oregon State University,Corvallis,United States,"['1712', '1707']",24.714285714285715,0.003447742733457019,0.37991651205936916,1
56,56,Distill knowledge from NRSfM for weakly supervised 3D pose learning,"We propose to learn a 3D pose estimator by distilling knowledge from Non-Rigid Structure from Motion (NRSfM). Our method uses solely 2D landmark annotations. No 3D data, multi-view/temporal footage, or object specific prior is required. This alleviates the data bottleneck, which is one of the major concern for supervised methods. The challenge for using NRSfM as teacher is that they often make poor depth reconstruction when the 2D projections have strong ambiguity. Directly using those wrong depth as hard target would negatively impact the student. Instead, we propose a novel loss that ties depth prediction to the cost function used in NRSfM. This gives the student pose estimator freedom to reduce depth error by associating with image features. Validated on H3.6M dataset, our learned 3D pose estimation network achieves more accurate reconstruction compared to NRSfM methods. It also outperforms other weakly supervised methods, in spite of using significantly less supervision.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",15.0,-0.04732142857142858,0.4571428571428572,1
57,57,Fair loss: Margin-aware reinforcement learning for deep face recognition,"Recently, large-margin softmax loss methods, such as angular softmax loss (SphereFace), large margin cosine loss (CosFace), and additive angular margin loss (ArcFace), have demonstrated impressive performance on deep face recognition. These methods incorporate a fixed additive margin to all the classes, ignoring the class imbalance problem. However, imbalanced problem widely exists in various real-world face datasets, in which samples from some classes are in a higher number than others. We argue that the number of a class would influence its demand for the additive margin. In this paper, we introduce a new margin-aware reinforcement learning based loss function, namely fair loss, in which each class will learn an appropriate adaptive margin by Deep Q-learning. Specifically, we train an agent to learn a margin adaptive strategy for each class, and make the additive margins for different classes more reasonable. Our method has better performance than present large-margin loss functions on three benchmarks, Labeled Face in the Wild (LFW), Youtube Faces (YTF) and MegaFace, which demonstrates that our method could learn better face representation on imbalanced face datasets.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,"['1712', '1707']",25.142857142857142,0.2300324675324675,0.4766558441558442,1
58,58,A low-frequency broadband triboelectric energy harvester based on cantilever beam with a groove,"This paper introduces a contact separation triboelectric energy harvester (TEH) using a cantilever beam with a groove to work at low-frequency. The designed TEH exhibits broadband behavior which is induced in the cantilever motion due to contact between two triboelectric surfaces. The open-circuit peak output voltage and output power of this fabricated prototype are 64 V and 5.4 μW at low resonant frequency of 13 Hz, respectively, when it matches an optimal loading resistance of 1.2 MΩ under the excitation of 0.9 g acceleration. Moreover, an operating frequency bandwidth of 9.2 Hz for the TEH device can be obtained at an acceleration level of 1.1 g.",60103926,Nanchang Institute of Technology,Nanchang,China,['1700'],26.5,-0.03125,0.38125000000000003,1
59,59,Monocular 3D human pose estimation by generation and ordinal ranking,"Monocular 3D human-pose estimation from static images is a challenging problem, due to the curse of dimensionality and the ill-posed nature of lifting 2D-to-3D. In this paper, we propose a Deep Conditional Variational Autoencoder based model that synthesizes diverse anatomically plausible 3D-pose samples conditioned on the estimated 2D-pose. We show that CVAE-based 3D-pose sample set is consistent with the 2D-pose and helps tackling the inherent ambiguity in 2D-to-3D lifting. We propose two strategies for obtaining the final 3D pose- (a) depth-ordering/ordinal relations to score and weight-average the candidate 3D-poses, referred to as OrdinalScore, and (b) with supervision from an Oracle. We report close to state-of-the-art results on two benchmark datasets using OrdinalScore, and state-of-the-art results using the Oracle. We also show that our pipeline yields competitive results without paired image-to-3D annotations. The training and evaluation code is available at https://github.com/ssfootball04/generative-pose.",60014153,"Indian Institute of Technology, Bombay",Mumbai,India,"['1712', '1707']",20.0,0.253125,0.603125,1
60,60,Towards adversarially robust object detection,"Object detection is an important vision task and has emerged as an indispensable component in many vision system, rendering its robustness as an increasingly important performance factor for practical applications. While object detection models have been demonstrated to be vulnerable against adversarial attacks by many recent works, very few efforts have been devoted to improving their robustness. In this work, we take an initial attempt towards this direction. We first revisit and systematically analyze object detectors and many recently developed attacks from the perspective of model robustness. We then present a multi-task learning perspective of object detection and identify an asymmetric role of task losses. We further develop an adversarial training approach which can leverage the multiple sources of attacks for improving the robustness of detection models. Extensive experiments on PASCAL-VOC and MS-COCO verified the effectiveness of the proposed approach.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",20.0,0.14312500000000003,0.42166666666666663,1
61,61,Saliency-guided attention network for image-sentence matching,"This paper studies the task of matching image and sentence, where learning appropriate representations to bridge the semantic gap between image contents and language appears to be the main challenge. Unlike previous approaches that predominantly deploy symmetrical architecture to represent both modalities, we introduce a Saliency-guided Attention Network (SAN) that is characterized by building an asymmetrical link between vision and language to efficiently learn a fine-grained cross-modal correlation. The proposed SAN mainly includes three components: Saliency detector, Saliency-weighted Visual Attention (SVA) module, and Saliency-guided Textual Attention (STA) module. Concretely, the saliency detector provides the visual saliency information to drive both two attention modules. Taking advantage of the saliency information, SVA is able to learn more discriminative visual features. By fusing the visual information from SVA and intra-modal information as a multi-modal guidance, STA affords us powerful textual representations that are synchronized with visual clues. Extensive experiments demonstrate SAN can improve the state-of-the-art results on the benchmark Flickr30K and MSCOCO datasets by a large margin.",60022020,The University of Warwick,Coventry,United Kingdom,"['1712', '1707']",23.428571428571427,0.1553968253968254,0.30134920634920637,1
62,62,SVD: A large-scale short video dataset for near-duplicate video retrieval,"With the explosive growth of video data in real applications, near-duplicate video retrieval (NDVR) has become indispensable and challenging, especially for short videos. However, all existing NDVR datasets are introduced for long videos. Furthermore, most of them are small-scale and lack of diversity due to the high cost of collecting and labeling near-duplicate videos. In this paper, we introduce a large-scale short video dataset, called SVD, for the NDVR task. SVD contains over 500,000 short videos and over 30,000 labeled videos of near-duplicates. We use multiple video mining techniques to construct positive/negative pairs. Furthermore, we design temporal and spatial transformations to mimic user-attack behavior in real applications for constructing more difficult variants of SVD. Experiments show that existing state-of-the-art NDVR methods, including real-value based and hashing based methods, fail to achieve satisfactory performance on this challenging dataset. The release of SVD dataset will foster research and system engineering in the NDVR area. The SVD dataset is available at https://svdbase.github.io.",60033100,Nanjing University,Nanjing,China,"['1712', '1707']",15.9,0.1213888888888889,0.5230555555555556,1
63,63,A method of vehicle fault diagnosis supporting multi-value-chain collaboration,"To improve the collaborative efficiency of multi-value-chain in vehicle maintenance, we designed a case-based vehicle fault diagnosis method by analyzing the traditional diagnosis methods of vehicle fault and collecting user’s actual requirements. In this paper, we summarized corpus of vehicle fault descriptions, analyzed user’s language features and extracted proper nouns in vehicle field as an extended dictionary to improve the accuracy of text segmentation. We also built a database of vehicle maintenance cases and a vehicle structure tree to support this diagnosis method. Then using vectorization method to process fault description corpus and trained the semantic vectorization model with both statistics and topics. After that, we used vector distance algorithm to compute semantic similarity and return the optimal case in database. Finally, we located the exact position of current fault in vehicle structure tree. The experimental result shows that the accuracy of vehicle fault diagnosis achieved 86.7% by this method. The accuracy of vehicle fault locating is also achieved 81.8%. This case-based vehicle fault diagnosis system can be used for online fault consultation. It can also expand the collaborative business mode of vehicle service value chain and improve the quality and efficiency of vehicle maintenance service.",60088567,Beijing Information Science &amp; Technology University,Beijing,China,['1700'],19.6,0.049999999999999996,0.42857142857142855,1
64,64,Hyperspectral image reconstruction using deep external and internal learning,"To solve the low spatial and/or temporal resolution problem which the conventional hypelrspectral cameras often suffer from, coded snapshot hyperspectral imaging systems have attracted more attention recently. Recovering a hyperspectral image (HSI) from its corresponding coded image is an ill-posed inverse problem, and learning accurate prior of HSI is essential to solve this inverse problem. In this paper, we present an effective convolutional neural network (CNN) based method for coded HSI reconstruction, which learns the deep prior from the external dataset as well as the internal information of input coded image with spatial-spectral constraint. Our method can effectively exploit spatial-spectral correlation and sufficiently represent the variety nature of HSIs. Experimental results show our method outperforms the state-of-the-art methods under both comprehensive quantitative metrics and perceptive quality.",60016835,Beijing Institute of Technology,Beijing,China,"['1712', '1707']",25.2,0.13714285714285715,0.32269841269841265,1
65,65,DiscoNet: Shapes learning on disconnected manifolds for 3D editing,"Editing 3D models is a very challenging task, as it requires complex interactions with the 3D shape to reach the targeted design, while preserving the global consistency and plausibility of the shape. In this work, we present an intelligent and user-friendly 3D editing tool, where the edited model is constrained to lie onto a learned manifold of realistic shapes. Due to the topological variability of real 3D models, they often lie close to a disconnected manifold, which cannot be learned with a common learning algorithm. Therefore, our tool is based on a new deep learning model, DiscoNet, which extends 3D surface autoencoders in two ways. Firstly, our deep learning model uses several autoencoders to automatically learn each connected component of a disconnected manifold, without any supervision. Secondly, each autoencoder infers the output 3D surface by deforming a pre-learned 3D template specific to each connected component. Both advances translate into improved 3D synthesis, thus enhancing the quality of our 3D editing tool.",60001422,Sorbonne Universite,Paris,France,"['1712', '1707']",23.0,0.09237689393939394,0.3450757575757576,1
66,66,"Identity from here, pose from there: Self-supervised disentanglement and generation of objects using unlabeled videos","We propose a novel approach that disentangles the identity and pose of objects for image generation. Our model takes as input an ID image and a pose image, and generates an output image with the identity of the ID image and the pose of the pose image. Unlike most previous unsupervised work which rely on cyclic constraints, which can often be brittle, we instead propose to learn this in a self-supervised way. Specifically, we leverage unlabeled videos to automatically construct pseudo ground-truth targets to directly supervise our model. To enforce disentanglement, we propose a novel disentanglement loss, and to improve realism, we propose a pixel-verification loss in which the generated image's pixels must trace back to the ID input. We conduct extensive experiments on both synthetic and real images to demonstrate improved realism, diversity, and ID/pose disentanglement compared to existing methods.",60014439,"University of California, Davis",Davis,United States,"['1712', '1707']",23.5,0.10555555555555556,0.2833333333333333,1
67,67,Research on factors affecting employee productivity in Shanghai,"With the development of social economy, all industries are constantly reforming and innovating. In the process of enterprise development, human resource has become the key resource for enterprise survival and development. Employee retention has been paid attention by the top management of the enterprise today and is generally aware of the complexity and importance of employee management. The main purpose of this study was to determine the significant impact of factors on Employee Retention in the manufacturing sector. For the study, the researcher got 112 questionnaires from the online questionnaire survey, but there have 1 questionnaire was invalid data, therefore, there are 111 valid questionnaire data. The delivery of the questionnaires was carried out by physical ""delivery and collection"" of data to the manufacturing industries in Shanghai, China, such as: Shanghai automotive group co., LTD., bright food (group) co., Shanghai pharmaceutical group co. Therefore, this study includes an analysis of the main three influence factors that, in the opinion of the researcher, directly affect the productivity of employees. These factors are: working environment, welfare measures and rewards & recognition.",109606759,Limkokwing University of Creative Technology,Cyberjaya,Malaysia,['1706'],22.375,0.17628205128205127,0.43342490842490844,1
68,68,Progressive sparse local attention for video object detection,"Transferring image-based object detectors to the domain of videos remains a challenging problem. Previous efforts mostly exploit optical flow to propagate features across frames, aiming to achieve a good trade-off between accuracy and efficiency. However, introducing an extra model to estimate optical flow can significantly increase the overall model size. The gap between optical flow and high-level features can also hinder it from establishing spatial correspondence accurately. Instead of relying on optical flow, this paper proposes a novel module called Progressive Sparse Local Attention (PSLA), which establishes the spatial correspondence between features across frames in a local region with progressively sparser stride and uses the correspondence to propagate features. Based on PSLA, Recursive Feature Updating (RFU) and Dense Feature Transforming (DenseFT) are proposed to model temporal appearance and enrich feature representation respectively in a novel video object detection framework. Experiments on ImageNet VID show that our method achieves the best accuracy compared to existing methods with smaller model size and acceptable runtime speed.",60121156,Horizon Robotics,Haidian,China,"['1712', '1707']",23.285714285714285,0.25448717948717947,0.36730769230769234,1
69,69,Elaborate monocular point and line SLAM with robust initialization,"This paper presents a monocular indirect SLAM system which performs robust initialization and accurate localization. For initialization, we utilize a matrix factorization-based method. Matrix factorization-based methods require that extracted feature points must be tracked in all used frames. Since consistent tracking is difficult in challenging environments, a geometric interpolation that utilizes epipolar geometry is proposed. For localization, 3D lines are utilized. We propose the use of Plücker line coordinates to represent geometric information of lines. We also propose orthonormal representation of Plücker line coordinates and Jacobians of lines for better optimization. Experimental results show that the proposed initialization generates consistent and robust map in linear time with fast convergence even in challenging scenes. And localization using proposed line representations is faster, more accurate and memory efficient than other state-of-the-art methods.",60094234,Handong Global University,Pohang,South Korea,"['1712', '1707']",14.444444444444445,0.24791666666666667,0.5951388888888889,1
70,70,Pose-guided feature alignment for occluded person re-identification,"Persons are often occluded by various obstacles in person retrieval scenarios. Previous person re-identification (re-id) methods, either overlook this issue or resolve it based on an extreme assumption. To alleviate the occlusion problem, we propose to detect the occluded regions, and explicitly exclude those regions during feature generation and matching. In this paper, we introduce a novel method named Pose-Guided Feature Alignment (PGFA), exploiting pose landmarks to disentangle the useful information from the occlusion noise. During the feature constructing stage, our method utilizes human landmarks to generate attention maps. The generated attention maps indicate if a specific body part is occluded and guide our model to attend to the non-occluded regions. During matching, we explicitly partition the global feature into parts and use the pose landmarks to indicate which partial features belonging to the target person. Only the visible regions are utilized for the retrieval. Besides, we construct a large-scale dataset for the Occluded Person Re-ID problem, namely Occluded-DukeMTMC, which is by far the largest dataset for the Occlusion Person Re-ID. Extensive experiments are conducted on our constructed occluded re-id dataset, two partial re-id datasets, and two commonly used holistic re-id datasets. Our method largely outperforms existing person re-id methods on three occlusion datasets, while remains top performance on two holistic datasets.",60023932,University of Technology Sydney,Sydney,Australia,"['1712', '1707']",19.272727272727273,0.017038690476190478,0.39084821428571426,1
71,71,Reflective decoding network for image captioning,"State-of-the-art image captioning methods mostly focus on improving visual features, less attention has been paid to utilizing the inherent properties of language to boost captioning performance. In this paper, we show that vocabulary coherence between words and syntactic paradigm of sentences are also important to generate high-quality image caption. Following the conventional encoder-decoder framework, we propose the Reflective Decoding Network (RDN) for image captioning, which enhances both the long-sequence dependency and position perception of words in a caption decoder. Our model learns to collaboratively attend on both visual and textual features and meanwhile perceive each word's relative position in the sentence to maximize the information delivered in the generated caption. We evaluate the effectiveness of our RDN on the COCO image captioning datasets and achieve superior performance over the previous methods. Further experiments reveal that our approach is particularly advantageous for hard cases with complex scenes to describe by captions.",60008592,Hong Kong University of Science and Technology,Hong Kong,Hong Kong,"['1712', '1707']",25.0,0.049914965986394555,0.34753401360544217,1
72,72,The latent semantic power of labels: Improving image classification via natural language semantic,"In order to address the problem that numerical labels are difficult to optimize, one-hot encoding is introduced into image classification tasks, and has been widely used in current models based on CNNs. However, one-hot encoding neglects the textual semantics of class labels, which closely relate to image characteristics and contain latent connections between images. Inspired by distributional similarity based representations in Natural Language Processing society, we propose a framework by introducing Word2Vec into classic CNN models to improve image classification performance. By mining the latent semantic power of classes labels, word vector representations participate in the classification model instead of the traditional one-hot encoding. In the evaluation experiments implemented on data sets of CIFAR-10 and CIFAR-100, a series of representative CNNs have been tested as the feature extraction component for our framework. Experimental results show that the proposed method has revealed compelling ability to improve the classification accuracy.",60006019,China University of Geosciences,Wuhan,China,['1700'],24.666666666666668,0.008333333333333328,0.5145833333333333,1
73,73,News recommendation model based on improved label propagation algorithm,"Facing the ever-expanding scale of news information, how to filter and redundant information in complex and diverse data to accurately recommend information to users has become an important challenge. News recommendations have become a powerful tool for dealing with information overload. Scholars have done a lot of research on personalized news recommendation. However, due to the sparseness of user data, the traditional collaborative filtering algorithm is not only too time-consuming but also less accurate. Therefore, aiming at the characteristics of academic social networks, we propose a news recommendation model based on community detection, which builds a friend relationship community by using the users friend relationship and coherent neighborhood propinquity algorithm, and then integrates the collaborative filtering algorithm to recommend news to users. Through verification on the dataset of the academic social network SCHOLAT, we can prove that the recommendation model can achieve good accuracy while improving recommendation efficiency.",60073525,Guangdong College of Pharmacy,Guangzhou,China,['1700'],24.666666666666668,0.1234375,0.4682291666666667,1
74,74,Unpaired image-to-speech synthesis with multimodal information bottleneck,"Deep generative models have led to significant advances in cross-modal generation such as text-to-image synthesis. Training these models typically requires paired data with direct correspondence between modalities. We introduce the novel problem of translating instances from one modality to another without paired data by leveraging an intermediate modality shared by the two other modalities. To demonstrate this, we take the problem of translating images to speech. In this case, one could leverage disjoint datasets with one shared modality, e.g., image-text pairs and text-speech pairs, with text as the shared modality. We call this problem ''skip-modal generation'' because the shared modality is skipped during the generation process. We propose a multimodal information bottleneck approach that learns the correspondence between modalities from unpaired data (image and speech) by leveraging the shared modality (text). We address fundamental challenges of skip-modal generation: 1) learning multimodal representations using a single model, 2) bridging the domain gap between two unrelated datasets, and 3) learning the correspondence between modalities from unpaired data. We show qualitative results on image-to-speech synthesis; this is the first time such results have been reported in the literature. We also show that our approach improves performance on traditional cross-modal generation, suggesting that it improves data efficiency in solving individual tasks.",60032083,"University at Buffalo, The State University of New York",Buffalo,United States,"['1712', '1707']",20.7,0.0329004329004329,0.4770562770562771,1
76,76,Addressing model vulnerability to distributional shifts over image transformation sets,"We are concerned with the vulnerability of computer vision models to distributional shifts. We formulate a combinatorial optimization problem that allows evaluating the regions in the image space where a given model is more vulnerable, in terms of image transformations applied to the input, and face it with standard search algorithms. We further embed this idea in a training procedure, where we define new data augmentation rules according to the image transformations that the current model is most vulnerable to, over iterations. An empirical evaluation on classification and semantic segmentation problems suggests that the devised algorithm allows to train models that are more robust against content-preserving image manipulations and, in general, against distributional shifts.",60102151,Istituto Italiano di Tecnologia,Genoa,Italy,"['1712', '1707']",28.5,0.07148760330578513,0.40495867768595045,1
77,77,Resolving 3D human pose ambiguities with 3D scene constraints,"To understand and analyze human behavior, we need to capture humans moving in, and interacting with, the world. Most existing methods perform 3D human pose estimation without explicitly considering the scene. We observe however that the world constrains the body and vice-versa. To motivate this, we show that current 3D human pose estimation methods produce results that are not consistent with the 3D scene. Our key contribution is to exploit static 3D scene structure to better estimate human pose from monocular images. The method enforces Proximal Relationships with Object eXclusion and is called PROX. To test this, we collect a new dataset composed of 12 different 3D scenes and RGB sequences of 20 subjects moving in and interacting with the scenes. We represent human pose using the 3D human body model SMPL-X and extend SMPLify-X to estimate body pose using scene constraints. We make use of the 3D scene information by formulating two main constraints. The inter-penetration constraint penalizes intersection between the body model and the surrounding 3D scene. The contact constraint encourages specific parts of the body to be in contact with scene surfaces if they are close enough in distance and orientation. For quantitative evaluation we capture a separate dataset with 180 RGB frames in which the ground-truth body pose is estimated using a motion capture system. We show quantitatively that introducing scene constraints significantly reduces 3D joint error and vertex error. Our code and data are available for research at https://prox.is.tue.mpg.de.",60030569,Max Planck Institute for Intelligent Systems,Tubingen,Germany,"['1712', '1707']",17.428571428571427,0.12910685805422645,0.3914673046251993,1
78,78,Selective sparse sampling for fine-grained image recognition,"Fine-grained recognition poses the unique challenge of capturing subtle inter-class differences under considerable intra-class variances (e.g., beaks for bird species). Conventional approaches crop local regions and learn detailed representation from those regions, but suffer from the fixed number of parts and missing of surrounding context. In this paper, we propose a simple yet effective framework, called Selective Sparse Sampling, to capture diverse and fine-grained details. The framework is implemented using Convolutional Neural Networks, referred to as Selective Sparse Sampling Networks (S3Ns). With image-level supervision, S3Ns collect peaks, i.e., local maximums, from class response maps to estimate informative, receptive fields and learn a set of sparse attention for capturing fine-detailed visual evidence as well as preserving context. The evidence is selectively sampled to extract discriminative and complementary features, which significantly enrich the learned representation and guide the network to discover more subtle cues. Extensive experiments and ablation studies show that the proposed method consistently outperforms the state-of-the-art methods on challenging benchmarks including CUB-200-2011, FGVC-Aircraft, and Stanford Cars.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",23.714285714285715,0.1216931216931217,0.4401455026455026,1
80,80,Spatio-temporal fusion based convolutional sequence learning for lip reading,"Current state-of-the-art approaches for lip reading are based on sequence-to-sequence architectures that are designed for natural machine translation and audio speech recognition. Hence, these methods do not fully exploit the characteristics of the lip dynamics, causing two main drawbacks. First, the short-range temporal dependencies, which are critical to the mapping from lip images to visemes, receives no extra attention. Second, local spatial information is discarded in the existing sequence models due to the use of global average pooling (GAP). To well solve these drawbacks, we propose a Temporal Focal block to sufficiently describe short-range dependencies and a Spatio-Temporal Fusion Module (STFM) to maintain the local spatial information and to reduce the feature dimensions as well. From the experiment results, it is demonstrated that our method achieves comparable performance with the state-of-the-art approach using much less training data and much lighter Convolutional Feature Extractor. The training time is reduced by 12 days due to the convolutional structure and the local self-attention mechanism.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",23.0,0.009374999999999998,0.23645833333333335,1
81,81,OmniMVS: End-to-end learning for omnidirectional stereo matching,"In this paper, we propose a novel end-to-end deep neural network model for omnidirectional depth estimation from a wide-baseline multi-view stereo setup. The images captured with ultra wide field-of-view (FOV) cameras on an omnidirectional rig are processed by the feature extraction module, and then the deep feature maps are warped onto the concentric spheres swept through all candidate depths using the calibrated camera parameters. The 3D encoder-decoder block takes the aligned feature volume to produce the omnidirectional depth estimate with regularization on uncertain regions utilizing the global context information. In addition, we present large-scale synthetic datasets for training and testing omnidirectional multi-view stereo algorithms. Our datasets consist of 11K ground-truth depth maps and 45K fisheye images in four orthogonal directions with various objects and environments. Experimental results show that the proposed method generates excellent results in both synthetic and real-world environments, and it outperforms the prior art and the omnidirectional versions of the state-of-the-art conventional stereo algorithms.",60024872,Hanyang University,Seoul,South Korea,"['1712', '1707']",26.166666666666668,0.08571428571428572,0.34571428571428575,1
82,82,Dilated convolutional neural networks for sequential manifold-valued data,"Efforts are underway to study ways via which the power of deep neural networks can be extended to non-standard data types such as structured data (e.g., graphs) or manifold-valued data (e.g., unit vectors or special matrices). Often, sizable empirical improvements are possible when the geometry of such data spaces are incorporated into the design of the model, architecture, and algorithms. Motivated by neuroimaging applications, we study formulations where the data are {em sequential manifold-valued measurements}. This case is common in brain imaging, where the samples correspond to symmetric positive definite matrices or orientation distribution functions. Instead of a recurrent model which poses computational/technical issues, and inspired by recent results showing the viability of dilated convolutional models for sequence prediction, we develop a dilated convolutional neural network architecture for this task. On the technical side, we show how the modules needed in our network can be derived while explicitly taking the Riemannian manifold structure into account. We show how the operations needed can leverage known results for calculating the weighted Fr'{e}chet Mean (wFM). Finally, we present scientific results for group difference analysis in Alzheimer's disease (AD) where the groups are derived using AD pathology load: Here the model finds several brain fiber bundles that are related to AD even when the subjects are all still cognitively healthy.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",27.0,0.03574472402597403,0.4096489448051948,1
83,83,Restoration of non-rigidly distorted underwater images using a combination of compressive sensing and local polynomial image representations,"Images of static scenes submerged beneath a wavy water surface exhibit severe non-rigid distortions. The physics of water flow suggests that water surfaces possess spatio-temporal smoothness and temporal periodicity. Hence they possess a sparse representation in the 3D discrete Fourier (DFT) basis. Motivated by this, we pose the task of restoration of such video sequences as a compressed sensing (CS) problem. We begin by tracking a few salient feature points across the frames of a video sequence of the submerged scene. Using these point trajectories, we show that the motion fields at all other (non-tracked) points can be effectively estimated using a typical CS solver. This by itself is a novel contribution in the field of non-rigid motion estimation. We show that this method outperforms state of the art algorithms for underwater image restoration. We further consider a simple optical flow algorithm based on local polynomial expansion of the image frames (PEOF). Surprisingly, we demonstrate that PEOF is more efficient and often outperforms all the state of the art methods in terms of numerical measures. Finally, we demonstrate that a two-stage approach consisting of the CS step followed by PEOF much more accurately preserves the image structure and improves the (visual as well as numerical) video quality as compared to just the PEOF stage. The source code, datasets and supplemental material can be accessed at cite{GitRepo}, cite{ProjectPage}.",60014153,"Indian Institute of Technology, Bombay",Mumbai,India,"['1712', '1707']",18.916666666666668,0.18055555555555552,0.4776984126984127,1
85,85,Wavelet domain style transfer for an effective perception-distortion tradeoff in single image super-resolution,"In single image super-resolution (SISR), given a low-resolution (LR) image, one wishes to find a high-resolution (HR) version of it which is both accurate and photorealistic. Recently, it has been shown that there exists a fundamental tradeoff between low distortion and high perceptual quality, and the generative adversarial network (GAN) is demonstrated to approach the perception-distortion (PD) bound effectively. In this paper, we propose a novel method based on wavelet domain style transfer (WDST), which achieves a better PD tradeoff than the GAN based methods. Specifically, we propose to use 2D stationary wavelet transform (SWT) to decompose one image into low-frequency and high-frequency sub-bands. For the low-frequency sub-band, we improve its objective quality through an enhancement network. For the high-frequency sub-band, we propose to use WDST to effectively improve its perceptual quality. By feat of the perfect reconstruction property of wavelets, these sub-bands can be re-combined to obtain an image which has simultaneously high objective and perceptual quality. The numerical results on various datasets show that our method achieves the best trade-off between the distortion and perceptual quality among the existing state-of-the-art SISR methods.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1707']",23.0,0.3106122448979592,0.4698299319727891,1
86,86,Conditional recurrent flow: Conditional generation of longitudinal samples with applications to neuroimaging,"We develop a conditional generative model for longitudinal image datasets based on sequential invertible neural networks. Longitudinal image acquisitions are common in various scientific and biomedical studies where often each image sequence sample may also come together with various secondary (fixed or temporally dependent) measurements. The key goal is not only to estimate the parameters of a deep generative model for the given longitudinal data, but also to enable evaluation of how the temporal course of the generated longitudinal samples are influenced as a function of induced changes in the (secondary) temporal measurements (or events). Our proposed formulation incorporates recurrent subnetworks and temporal context gating, which provides a smooth transition in a temporal sequence of generated data that can be easily informed or modulated by secondary temporal conditioning variables. We show that the formulation works well despite the smaller sample sizes common in these applications. Our model is validated on two video datasets and a longitudinal Alzheimer's disease (AD) dataset for both quantitative and qualitative evaluations of the generated samples. Further, using our generated longitudinal image samples, we show that we can capture the pathological progressions in the brain that turn out to be consistent with the existing literature, and could facilitate various types of downstream statistical analysis.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",29.714285714285715,-0.018627450980392157,0.5049019607843137,1
87,87,Digital stocks using blockchain technology the possible future of stocks?," It trends in the news almost daily, with glowing reviews of the many benefits of an alternative and international currency. This paper explains the innovative aspect of the technological platform used to transfer Bitcoin from one party to another. This technology is called the Blockchain. The Blockchain eschews a bank or other intermediary and allows parties to transfer funds directly to one another, using a peer-to-peer system. This disruptive technology has done for money transfers what email did for sending mail — by removing the need for a trusted third party just as email removed the need for using the post office to send mail. This technology mainly used for peer-to-peer money transfers, can also be extended to accomplish other forms of transfers. Blockchain technology can be used to buy and sell stocks. Real world stocks can be tokenized into digital stocks which can be easily transferred using peer-to-peer. These digital stocks act similar to digital currency whose price is real time and fluctuates. Stocks exchanged completely peer-to-peer could resolve many of the issues facing the stock market today, including high frequency trading and short sales.",60113794,BMS Institute of Technology and Management,Bengaluru,India,['1706'],18.7,0.1305,0.3278333333333333,0
88,88,Computer-aided diagnosis of ophthalmic diseases using OCT based on deep learning: A review,"Deep learning can effectively extract the hidden features of images and has developed rapidly in medical image recognition in recent years. Ophthalmic diseases are one of the critical factors affecting the healthy living. At the same time, optical coherence tomography (OCT) has the characteristics of non-invasive and high-resolution and has become the mainstream imaging technology in the clinical diagnosis of Ophthalmic diseases. Therefore, computer-aided diagnosis of ophthalmic diseases using OCT based on deep learning has caused a wide range of research craze. In this paper, we review the imaging methods and applications of OCT, the OCT public dataset. And we introduce in detail the computer-aided diagnosis system of multiple ophthalmic diseases using OCT in recent years, including age-related macular degeneration, glaucoma, diabetic macular edema and so on, and an overview of the main challenges faced by deep learning in OCT imaging.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1700'],23.5,0.06874999999999999,0.33489583333333334,1
89,89,Employee competencies as the predictors of the performance management system: An empirical study in IT enabled service companies around Hyderabad," A survey of 900 employees working in IT Enabled Service companies around Hyderabad Metro consisting of 550 men and 350 women employees using a structured questionnaire was carried out. The study empirically measured the effect of four independent variables, the employee competencies– personal competencies, knowledge level competencies, job-related competencies and communication and interpersonal competencies on a dependent variable performance management system in IT Enabled Services companies. The reliability of the survey instrument and internal consistencies were measured using reliability statistic Cronbach alpha and the Cronbach alpha values ranged between 0.70 to 0.86 for men and 0.67 to 0.82 for women. The results of the multiple regression analysis reveal statistically significant differences indicating that four independent variables are significant predictors of performance management system. Statistically significant gender differences were observed and men and women employees are significantly influencing performance management system in IT Enabled companies, however there are no statistically significant different among the different age groups of employees.",60056514,"Shri Ramdeobaba College of Engineering and Management, Nagpur",Nagpur,India,['1706'],31.8,0.15192307692307694,0.4788461538461538,0
90,90,Pointflow: 3D point cloud generation with continuous normalizing flows,"As 3D point clouds become the representation of choice for multiple vision and graphics applications, the ability to synthesize or reconstruct high-resolution, high-fidelity point clouds becomes crucial. Despite the recent success of deep learning models in discriminative tasks of point clouds, generating point clouds remains challenging. This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions. Specifically, we learn a two-level hierarchy of distributions where the first level is the distribution of shapes and the second level is the distribution of points given a shape. This formulation allows us to both sample shapes and sample an arbitrary number of points from a shape. Our generative model, named PointFlow, learns each level of the distribution with a continuous normalizing flow. The invertibility of normalizing flows enables the computation of the likelihood during training and allows us to train our model in the variational inference framework. Empirically, we demonstrate that PointFlow achieves state-of-the-art performance in point cloud generation. We additionally show that our model can faithfully reconstruct point clouds and learn useful representations in an unsupervised manner. The code is available at https://github.com/stevenygd/PointFlow.",60104837,Cornell Tech,New York,United States,"['1712', '1707']",19.1,0.14583333333333334,0.34027777777777785,1
91,91,Temporal recurrent networks for online action detection,"Most work on temporal action detection is formulated as an offline problem, in which the start and end times of actions are determined after the entire video is fully observed. However, important real-time applications including surveillance and driver assistance systems require identifying actions as soon as each video frame arrives, based only on current and historical observations. In this paper, we propose a novel framework, the Temporal Recurrent Network (TRN), to model greater temporal context of each frame by simultaneously performing online action detection and anticipation of the immediate future. At each moment in time, our approach makes use of both accumulated historical evidence and predicted future information to better recognize the action that is currently occurring, and integrates both of these into a unified end-to-end architecture. We evaluate our approach on two popular online action detection datasets, HDD and TVSeries, as well as another widely used dataset, THUMOS'14. The results show that TRN significantly outperforms the state-of-the-art.",60104105,"Honda R&amp;D Americas, Inc.",Torrance,United States,"['1712', '1707']",26.333333333333332,0.16710526315789476,0.40789473684210525,1
92,92,Video classification with channel-separated convolutional networks,"Group convolution has been shown to offer great computational savings in various 2D convolutional architectures for image classification. It is natural to ask: 1) if group convolution can help to alleviate the high computational cost of video classification networks; 2) what factors matter the most in 3D group convolutional networks; and 3) what are good computation/accuracy trade-offs with 3D group convolutional networks. This paper studies the effects of different design choices in 3D group convolutional networks for video classification. We empirically demonstrate that the amount of channel interactions plays an important role in the accuracy of 3D group convolutional networks. Our experiments suggest two main findings. First, it is a good practice to factorize 3D convolutions by separating channel interactions and spatiotemporal interactions as this leads to improved accuracy and lower computational cost. Second, 3D channel-separated convolutions provide a form of regularization, yielding lower training accuracy but higher test accuracy compared to 3D convolutions. These two empirical findings lead us to design an architecture - Channel-Separated Convolutional Network (CSN) - which is simple, efficient, yet accurate. On Sports1M and Kinetics, our CSNs are comparable with or better than the state-of-the-art while being 2-3 times more efficient.",60111190,Facebook Research,Menlo Park,United States,"['1712', '1707']",21.77777777777778,0.2961403508771929,0.46563909774436085,1
93,93,A lower bound for Edge-congestion of an embedding,"In network theory, the problem of simulating one architecture into another architecture is converted into a graph embedding problem. In this paper, we have extended our work in [1] and give algorithms to compute optimal edge-congestion of embedding hypercubes, folded hypercubes, crossed cubes and circulant networks into hypertrees thereby proving that the edge-congestion bound obtained in [1] is sharp.",60117285,"SRM Institute of Science and Technology, Ramapuram Campus",Chennai,India,"['1706', '1703']",29.5,-0.125,0.75,1
94,94,HoloGAN: Unsupervised learning of 3D representations from natural images,"We propose a novel generative adversarial network (GAN) for the task of unsupervised learning of 3D representations from natural images. Most generative models rely on 2D kernels to generate images and make few assumptions about the 3D world. These models therefore tend to create blurry images or artefacts in tasks that require a strong 3D understanding, such as novel-view synthesis. HoloGAN instead learns a 3D representation of the world, and to render this representation in a realistic manner. Unlike other GANs, HoloGAN provides explicit control over the pose of generated objects through rigid-body transformations of the learnt 3D features. Our experiments show that using explicit 3D features enables HoloGAN to disentangle 3D pose and identity, which is further decomposed into shape and appearance, while still being able to generate images with similar or higher visual quality than other generative models. HoloGAN can be trained end-to-end from unlabelled 2D images only. Particularly, we do not require pose labels, 3D shapes, or multiple views of the same objects. This shows that HoloGAN is the first generative model that learns 3D representations from natural images in an entirely unsupervised manner.",60030480,University of Bath,Bath,United Kingdom,"['1712', '1707']",20.77777777777778,0.08833333333333335,0.40791666666666665,1
95,95,Spectral feature transformation for person re-identification,"With the surge of deep learning techniques, the field of person re-identification has witnessed rapid progress in recent years. Deep learning based methods focus on learning a discriminative feature space where data points are clustered compactly according to their corresponding identities. Most existing methods process data points individually or only involves a fraction of samples while building a similarity structure. They ignore dense informative connections among samples more or less. The lack of holistic observation eventually leads to inferior performance. To relieve the issue, we propose to formulate the whole data batch as a similarity graph. Inspired by spectral clustering, a novel module termed Spectral Feature Transformation is developed to facilitate the optimization of group-wise similarities. It adds no burden to the inference and can be applied to various scenarios. As a natural extension, we further derive a lightweight re-ranking method named Local Blurring Re-ranking which makes the underlying clustering structure around the probe set more compact. Empirical studies on four public benchmarks show the superiority of the proposed method. Code is available at https://github.com/LuckyDC/SFT-REID.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",15.909090909090908,0.13137254901960788,0.3696078431372549,1
96,96,Talking with hands 16.2M: A large-scale dataset of synchronized body-finger motion and audio for conversational motion analysis and synthesis,"We present a 16.2-million frame (50-hour) multimodal dataset of two-person face-to-face spontaneous conversations. Our dataset features synchronized body and finger motion as well as audio data. To the best of our knowledge, it represents the largest motion capture and audio dataset of natural conversations to date. The statistical analysis verifies strong intraperson and interperson covariance of arm, hand, and speech features, potentially enabling new directions on data-driven social behavior analysis, prediction, and synthesis. As an illustration, we propose a novel real-time finger motion synthesis method: A temporal neural network innovatively trained with an inverse kinematics (IK) loss, which adds skeletal structural information to the generative model. Our qualitative user study shows that the finger motion generated by our method is perceived as natural and conversation enhancing, while the quantitative ablation study demonstrates the effectiveness of IK loss.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",22.833333333333332,0.2903030303030303,0.5254545454545456,1
97,97,Holistic++ scene understanding: Single-view 3D holistic scene parsing and human pose estimation with human-object interaction and physical commonsense,"We propose a new 3D holistic++ scene understanding problem, which jointly tackles two tasks from a single-view image: (i) holistic scene parsing and reconstruction - -3D estimations of object bounding boxes, camera pose, and room layout, and (ii) 3D human pose estimation. The intuition behind is to leverage the coupled nature of these two tasks to improve the granularity and performance of scene understanding. We propose to exploit two critical and essential connections between these two tasks: (i) human-object interaction (HOI) to model the fine-grained relations between agents and objects in the scene, and (ii) physical commonsense to model the physical plausibility of the reconstructed scene. The optimal configuration of the 3D scene, represented by a parse graph, is inferred using Markov chain Monte Carlo (MCMC), which efficiently traverses through the non-differentiable joint solution space. Experimental results demonstrate that the proposed algorithm significantly improves the performance of the two tasks on three datasets, showing an improved generalization ability.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",31.6,-0.11714876033057851,0.5377508854781583,1
98,98,AdvPattern: Physical-world attacks on deep person re-identification via adversarially transformable patterns,"Person re-identification (re-ID) is the task of matching person images across camera views, which plays an important role in surveillance and security applications. Inspired by great progress of deep learning, deep re-ID models began to be popular and gained state-of-the-art performance. However, recent works found that deep neural networks (DNNs) are vulnerable to adversarial examples, posing potential threats to DNNs based applications. This phenomenon throws a serious question about whether deep re-ID based systems are vulnerable to adversarial attacks. In this paper, we take the first attempt to implement robust physical-world attacks against deep re-ID. We propose a novel attack algorithm, called advPattern, for generating adversarial patterns on clothes, which learns the variations of image pairs across cameras to pull closer the image features from the same camera, while pushing features from different cameras farther. By wearing our crafted 'invisible cloak', an adversary can evade person search, or impersonate a target person to fool deep re-ID models in physical world. We evaluate the effectiveness of our transformable patterns on adversaries' clothes with Market1501 and our established PRCS dataset. The experimental results show that the rank-1 accuracy of re-ID models for matching the adversary decreases from 87.9% to 27.1% under Evading Attack. Furthermore, the adversary can impersonate a target person with 47.1% rank-1 accuracy and 67.9% mAP under Impersonation Attack. The results demonstrate that deep re-ID systems are vulnerable to our physical attacks.",60029306,Wuhan University,Wuhan,China,"['1712', '1707']",21.09090909090909,0.014393939393939409,0.4823051948051948,1
99,99,Physics-based rendering for improving robustness to rain,"To improve the robustness to rain, we present a physically-based rain rendering pipeline for realistically inserting rain into clear weather images. Our rendering relies on a physical particle simulator, an estimation of the scene lighting and an accurate rain photometric modeling to augment images with arbitrary amount of realistic rain or fog. We validate our rendering with a user study, proving our rain is judged 40% more realistic that state-of-the-art. Using our generated weather augmented Kitti and Cityscapes dataset, we conduct a thorough evaluation of deep object detection and semantic segmentation algorithms and show that their performance decreases in degraded weather, on the order of 15% for object detection and 60% for semantic segmentation. Furthermore, we show refining existing networks with our augmented images improves the robustness of both object detection and semantic segmentation algorithms. We experiment on nuScenes and measure an improvement of 15% for object detection and 35% for semantic segmentation compared to original rainy performance. Augmented databases and code are available on the project page.",60032619,Université Laval,Quebec,Canada,"['1712', '1707']",24.0,0.1825757575757576,0.4069264069264069,1
100,100,SENSE: A shared encoder network for scene-flow estimation,"We introduce a compact network for holistic scene flow estimation, called SENSE, which shares common encoder features among four closely-related tasks: Optical flow estimation, disparity estimation from stereo, occlusion estimation, and semantic segmentation. Our key insight is that sharing features makes the network more compact, induces better feature representations, and can better exploit interactions among these tasks to handle partially labeled data. With a shared encoder, we can flexibly add decoders for different tasks during training. This modular design leads to a compact and efficient model at inference time. Exploiting the interactions among these tasks allows us to introduce distillation and self-supervised losses in addition to supervised losses, which can better handle partially labeled real-world data. SENSE achieves state-of-the-art results on several optical flow benchmarks and runs as fast as networks specifically designed for optical flow. It also compares favorably against the state of the art on stereo and scene flow, while consuming much less memory.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",22.285714285714285,0.12777777777777774,0.4472222222222222,1
101,101,Visualizing the invisible: Occluded vehicle segmentation and recovery,"In this paper, we propose a novel iterative multi-task framework to complete the segmentation mask of an occluded vehicle and recover the appearance of its invisible parts. In particular, firstly, to improve the quality of the segmentation completion, we present two coupled discriminators that introduce an auxiliary 3D model pool for sampling authentic silhouettes as adversarial samples. In addition, we propose a two-path structure with a shared network to enhance the appearance recovery capability. By iteratively performing the segmentation completion and the appearance recovery, the results will be progressively refined. To evaluate our method, we present a dataset, Occluded Vehicle dataset, containing synthetic and real-world occluded vehicle images. Based on this dataset, we conduct comparison experiments and demonstrate that our model outperforms the state-of-the-arts in both tasks of recovering segmentation mask and appearance for occluded vehicles. Moreover, we also demonstrate that our appearance recovery approach can benefit the occluded vehicle tracking in real-world videos.",60024542,South China University of Technology,Guangzhou,China,"['1712', '1707']",22.0,0.16944444444444443,0.30277777777777776,1
102,102,EMPNet: Neural localisation and mapping using embedded memory points,"Continuously estimating an agent's state space and a representation of its surroundings has proven vital towards full autonomy. A shared common ground among systems which successfully achieve this feat is the integration of previously encountered observations into the current state being estimated. This necessitates the use of a memory module for incorporating previously visited states whilst simultaneously offering an internal representation of the observed environment. In this work we develop a memory module which contains rigidly aligned point-embeddings that represent a coherent scene structure acquired from an RGB-D sequence of observations. The point-embeddings are extracted using modern convolutional neural network architectures, and alignment is performed by computing a dense correspondence matrix between a new observation and the current embeddings residing in the memory module. The whole framework is end-to-end trainable, resulting in a recurrent joint optimisation of the point-embeddings contained in the memory. This process amplifies the shared information across states, providing increased robustness and accuracy. We show significant improvement of our method across a set of experiments performed on the synthetic VIZDoom environment and a real world Active Vision Dataset.",60019578,Monash University,Melbourne,Australia,"['1712', '1707']",22.625,0.1277935606060606,0.4476799242424242,1
103,103,Autofocus: Efficient multi-scale inference,"This paper describes AutoFocus, an efficient multi-scale inference algorithm for deep-learning based object detectors. Instead of processing an entire image pyramid, AutoFocus adopts a coarse to fine approach and only processes regions which are likely to contain small objects at finer scales. This is achieved by predicting category agnostic segmentation maps for small objects at coarser scales, called FocusPixels. FocusPixels can be predicted with high recall, and in many cases, they only cover a small fraction of the entire image. To make efficient use of FocusPixels, an algorithm is proposed which generates compact rectangular FocusChips which enclose FocusPixels. The detector is only applied inside FocusChips, which reduces computation while processing finer scales. Different types of error can arise when detections from FocusChips of multiple scales are combined, hence techniques to correct them are proposed. AutoFocus obtains an mAP of 47.9% (68.3% at 50% overlap) on the COCO test-dev set while processing 6.4 images per second on a Titan X (Pascal) GPU. This is 2.5X faster than our multi-scale baseline detector and matches its mAP. The number of pixels processed in the pyramid can be reduced by 5X with a 1% drop in mAP. AutoFocus obtains more than 10% mAP gain compared to RetinaNet but runs at the same speed with the same ResNet-101 backbone.",60020304,University of Maryland,College Park,United States,"['1712', '1707']",19.454545454545453,0.04350877192982456,0.5178947368421053,1
104,104,Collect and select: Semantic alignment metric learning for few-shot learning,"Few-shot learning aims to learn latent patterns from few training examples and has shown promises in practice. However, directly calculating the distances between the query image and support image in existing methods may cause ambiguity because dominant objects can locate anywhere on images. To address this issue, this paper proposes a Semantic Alignment Metric Learning (SAML) method for few-shot learning that aligns the semantically relevant dominant objects through a ''collect-and-select'' strategy. Specifically, we first calculate a relation matrix (RM) to ''collect' the distances of each local region pairs of the 3D tensor extracted from a query image and the mean tensor of the support images. Then, the attention technique is adapted to ''select' the semantically relevant pairs and put more weights on them. Afterwards, a multi-layer perceptron (MLP) is utilized to map the reweighted RMs to their corresponding similarity scores. Theoretical analysis demonstrates the generalization ability of SAML and gives a theoretical guarantee. Empirical results demonstrate that semantic alignment is achieved. Extensive experiments on benchmark datasets validate the strengths of the proposed approach and demonstrate that SAML significantly outperforms the current state-of-the-art methods. The source code is available at https://github.com/haofusheng/SAML.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",19.0,0.13416666666666668,0.4086111111111111,1
105,105,End-to-end wireframe parsing,"We present a conceptually simple yet effective algorithm to detect wireframes in a given image. Compared to the previous methods which first predict an intermediate heat map and then extract straight lines with heuristic algorithms, our method is end-to-end trainable and can directly output a vectorized wireframe that contains semantically meaningful and geometrically salient junctions and lines. To better understand the quality of the outputs, we propose a new metric for wireframe evaluation that penalizes overlapped line segments and incorrect line connectivities. We conduct extensive experiments and show that our method significantly outperforms the previous state-of-the-art wireframe and line extraction algorithms. We hope our simple approach can be served as a baseline for future wireframe parsing studies. Code has been made publicly available at https://github.com/zhou13/lcnn.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",20.833333333333332,0.17050189393939394,0.3855519480519481,1
106,106,Specifying object attributes and relations in interactive scene generation,"We introduce a method for the generation of images from an input scene graph. The method separates between a layout embedding and an appearance embedding. The dual embedding leads to generated images that better match the scene graph, have higher visual quality, and support more complex scene graphs. In addition, the embedding scheme supports multiple and diverse output images per scene graph, which can be further controlled by the user. We demonstrate two modes of per-object control: (i) importing elements from other images, and (ii) navigation in the object space by selecting an appearance archetype. Our code is publicly available at https://www.github.com/ashual/scene-generation.",60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,"['1712', '1707']",17.0,0.0475,0.4175,1
107,107,Second-order non-local attention networks for person re-identification,"Recent efforts have shown promising results for person re-identification by designing part-based architectures to allow a neural network to learn discriminative representations from semantically coherent parts. Some efforts use soft attention to reallocate distant outliers to their most similar parts, while others adjust part granularity to incorporate more distant positions for learning the relationships. Others seek to generalize part-based methods by introducing a dropout mechanism on consecutive regions of the feature map to enhance distant region relationships. However, only few prior efforts model the distant or non-local positions of the feature map directly for the person re-ID task. In this paper, we propose a novel attention mechanism to directly model long-range relationships via second-order feature statistics. When combined with a generalized DropBlock module, our method performs equally to or better than state-of-the-art results for mainstream person re-identification datasets, including Market1501, CUHK03, and DukeMTMC-reID.",60021508,University of Notre Dame,Notre Dame,United States,"['1712', '1707']",23.833333333333332,0.11176470588235293,0.4117647058823529,1
108,108,Differentiable kernel evolution,"This paper proposes a differentiable kernel evolution (DKE) algorithm to find a better layer-operator for the convolutional neural network. Unlike most of the other neural architecture searching (NAS) technologies, we consider the searching space in a fundamental scope: Kernel space, which encodes the assembly of basic multiply-accumulate (MAC) operations into a conv-kernel. We first deduce a strict form of the generalized convolutional operator by some necessary constraints and construct a continuous searching space for its extra freedom-of-degree, namely, the connection of each MAC. Then a novel unsupervised greedy evolution algorithm called textit{gradient agreement guided searching} (GAGS) is proposed to learn the optimal location for each MAC in the spatially continuous searching space. We leverage DKE on multiple kinds of tasks such as object classification, face/object detection, large-scale fine-grained and recognition, with various kinds of backbone architecture. Not to mention the consistent performance gain, we found the proposed DKE can further act as an auto-dilated operator, which makes it easy to boost the performance of miniaturized neural networks in multiple tasks.",60120944,SenseTime Group Limited,Hong Kong,Hong Kong,"['1712', '1707']",28.333333333333332,0.12916666666666668,0.39404761904761904,1
109,109,Domain intersection and domain difference,"We present a method for recovering the shared content between two visual domains as well as the content that is unique to each domain. This allows us to map from one domain to the other, in a way in which the content that is specific for the first domain is removed and the content that is specific for the second is imported from any image in the second domain. In addition, our method enables generation of images from the intersection of the two domains as well as their union, despite having no such samples during training. The method is shown analytically to contain all the sufficient and necessary constraints. It also outperforms the literature methods in an extensive set of experiments.",60005681,Tel Aviv University,Tel Aviv-Yafo,Israel,"['1712', '1707']",24.2,0.041666666666666664,0.3159722222222222,1
110,110,Why does a visual question have different answers?,"Visual question answering is the task of returning the answer to a question about an image. A challenge is that different people often provide different answers to the same visual question. To our knowledge, this is the first work that aims to understand why. We propose a taxonomy of nine plausible reasons, and create two labelled datasets consisting of ∼45,000 visual questions indicating which reasons led to answer differences. We then propose a novel problem of predicting directly from a visual question which reasons will cause answer differences as well as a novel algorithm for this purpose. Experiments demonstrate the advantage of our approach over several related baselines on two diverse datasets. We publicly share the datasets and code at https://vizwiz.org.",60027550,"University of California, Los Angeles",Los Angeles,United States,"['1712', '1707']",17.285714285714285,0.06538461538461539,0.2326923076923077,1
111,111,Entrepreneurship and financial institutions market analysis,"Entrepreneurship challenges become on the rise across the world. The study was conducted in the State of California studying the requirements of financial institutions towards entrepreneurs. The researcher conducted this study at banks located at the county of San Diego, California through actual interaction and observation. The main objective of the study was to study the amount of support provided by banks to new entrepreneurs. The outcome of this study has revealed that banks showed a significant level of support towards entrepreneurships. However, entrepreneurs still were faced with endearing challenges of lack of financial support from banks in the United States and all were revealed through the subjective seven main questions in this study.",60110955,American University in the Emirates,Dubai,United Arab Emirates,['1706'],19.0,0.1494107744107744,0.2995791245791246,1
112,112,CapsuleVOS: Semi-supervised video object segmentation using capsule routing,"In this work we propose a capsule-based approach for semi-supervised video object segmentation. Current video object segmentation methods are frame-based and often require optical flow to capture temporal consistency across frames which can be difficult to compute. To this end, we propose a video based capsule network, CapsuleVOS, which can segment several frames at once conditioned on a reference frame and segmentation mask. This conditioning is performed through a novel routing algorithm for attention-based efficient capsule selection. We address two challenging issues in video object segmentation: 1) segmentation of small objects and 2) occlusion of objects across time. The issue of segmenting small objects is addressed with a zooming module which allows the network to process small spatial regions of the video. Apart from this, the framework utilizes a novel memory module based on recurrent networks which helps in tracking objects when they move out of frame or are occluded. The network is trained end-to-end and we demonstrate its effectiveness on two benchmark video object segmentation datasets; it outperforms current offline approaches on the Youtube-VOS dataset while having a run-time that is almost twice as fast as competing methods. The code is publicly available at https://github.com/KevinDuarte/CapsuleVOS.",60022144,University of Central Florida,Orlando,United States,"['1712', '1707']",21.77777777777778,-0.015000000000000003,0.5,1
114,114,Stacked cross refinement network for edge-aware salient object detection,"Salient object detection is a fundamental computer vision task. The majority of existing algorithms focus on aggregating multi-level features of pre-trained convolutional neural networks. Moreover, some researchers attempt to utilize edge information for auxiliary training. However, existing edge-aware models design unidirectional frameworks which only use edge features to improve the segmentation features. Motivated by the logical interrelations between binary segmentation and edge maps, we propose a novel Stacked Cross Refinement Network (SCRN) for salient object detection in this paper. Our framework aims to simultaneously refine multi-level features of salient object detection and edge detection by stacking Cross Refinement Unit (CRU). According to the logical interrelations, the CRU designs two direction-specific integration operations, and bidirectionally passes messages between the two tasks. Incorporating the refined edge-preserving features with the typical U-Net, our model detects salient objects accurately. Extensive experiments conducted on six benchmark datasets demonstrate that our method outperforms existing state-of-the-art algorithms in both accuracy and efficiency. Besides, the attribute-based performance on the SOC dataset show that the proposed model ranks first in the majority of challenging scenes. Code can be found at https://github.com/wuzhe71/SCAN.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",16.545454545454547,0.12037037037037039,0.40740740740740744,1
115,115,Effect of student learning model on emotional intelligence," In this study, an increase in emotional intelligence was developed using learning models. The research model used was quasi-experiment with the design of the pretest post-test two treatment design. Emotional intelligence plays a role in realizing educational goals, this is expected to increase conducive learning. In learning emotional intelligence is not very popular but is a basis for assessing students 'abilities and for understanding students' feelings. Emotional intelligence is expected to be a determining factor in the bridge to achieve learning outcomes. It is expected that teachers of Physical Education in using Emotional intelligence can use Inquiry learning models.",60112726,Universitas Musamus Merauke,Merauke,Indonesia,['1706'],16.666666666666664,-0.015064102564102564,0.48626373626373637,0
117,117,DensePoint: Learning densely contextual representation for efficient point cloud processing,"Point cloud processing is very challenging, as the diverse shapes formed by irregular points are often indistinguishable. A thorough grasp of the elusive shape requires sufficiently contextual semantic information, yet few works devote to this. Here we propose DensePoint, a general architecture to learn densely contextual representation for point cloud processing. Technically, it extends regular grid CNN to irregular point configuration by generalizing a convolution operator, which holds the permutation invariance of points, and achieves efficient inductive learning of local patterns. Architecturally, it finds inspiration from dense connection mode, to repeatedly aggregate multi-level and multi-scale semantics in a deep hierarchy. As a result, densely contextual information along with rich semantics, can be acquired by DensePoint in an organic manner, making it highly effective. Extensive experiments on challenging benchmarks across four tasks, as well as thorough model analysis, verify DensePoint achieves the state of the arts.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.714285714285715,0.17954545454545456,0.46002331002331,1
118,118,Scene text visual question answering,"Current visual question answering datasets do not consider the rich semantic information conveyed by text within an image. In this work, we present a new dataset, ST-VQA, that aims to highlight the importance of exploiting high-level semantic information present in images as textual cues in the Visual Question Answering process. We use this dataset to define a series of tasks of increasing difficulty for which reading the scene text in the context provided by the visual information is necessary to reason and generate an appropriate answer. We propose a new evaluation metric for these tasks to account both for reasoning errors as well as shortcomings of the text recognition module. In addition we put forward a series of baseline methods, which provide further insight to the newly released dataset, and set the scene for further research.",60104040,Centre de Visió per Computador,Cerdanyola del Valles,Spain,"['1712', '1707']",27.2,0.09172077922077919,0.35811688311688306,1
119,119,Universally slimmable networks and improved training techniques,"Slimmable networks are a family of neural networks that can instantly adjust the runtime width. The width can be chosen from a predefined widths set to adaptively optimize accuracy-efficiency trade-offs at runtime. In this work, we propose a systematic approach to train universally slimmable networks (US-Nets), extending slimmable networks to execute at arbitrary width, and generalizing to networks both with and without batch normalization layers. We further propose two improved training techniques for US-Nets, named the sandwich rule and inplace distillation, to enhance training process and boost testing accuracy. We show improved performance of universally slimmable MobileNet v1 and MobileNet v2 on ImageNet classification task, compared with individually trained ones and 4-switch slimmable network baselines. We also evaluate the proposed US-Nets and improved training techniques on tasks of image super-resolution and deep reinforcement learning. Extensive ablation experiments on these representative tasks demonstrate the effectiveness of our proposed methods. Our discovery opens up the possibility to directly evaluate FLOPs-Accuracy spectrum of network architectures. Code and models are available at: Url{https://github.com/JiahuiYu/slimmable-networks}.",60000745,University of Illinois at Urbana-Champaign,Urbana,United States,"['1712', '1707']",18.77777777777778,0.04,0.37,1
120,120,Deep residual learning in the JPEG transform domain,We introduce a general method of performing Residual Network inference and learning in the JPEG transform domain that allows the network to consume compressed images as input. Our formulation leverages the linearity of the JPEG transform to redefine convolution and batch normalization with a tune-able numerical approximation for ReLu. The result is mathematically equivalent to the spatial domain network up to the ReLu approximation accuracy. A formulation for image classification and a model conversion algorithm for spatial domain networks are given as examples of the method. We show that the sparsity of the JPEG format allows for faster processing of images with little to no penalty in the network accuracy.,60020304,University of Maryland,College Park,United States,"['1712', '1707']",22.0,-0.04583333333333333,0.3333333333333333,1
121,121,Task-driven modular networks for zero-shot compositional learning,"One of the hallmarks of human intelligence is the ability to compose learned knowledge into novel concepts which can be recognized without a single training example. In contrast, current state-of-the-art methods require hundreds of training examples for each possible category to build reliable and accurate classifiers. To alleviate this striking difference in efficiency, we propose a task-driven modular architecture for compositional reasoning and sample efficient learning. Our architecture consists of a set of neural network modules, which are small fully connected layers operating in semantic concept space. These modules are configured through a gating function conditioned on the task to produce features representing the compatibility between the input image and the concept under consideration. This enables us to express tasks as a combination of sub-tasks and to generalize to unseen categories by reweighting a set of small modules. Furthermore, the network can be trained efficiently as it is fully differentiable and its modules operate on small sub-spaces. We focus our study on the problem of compositional zero-shot classification of object-attribute categories. We show in our experiments that current evaluation metrics are flawed as they only consider unseen object-attribute pairs. When extending the evaluation to the generalized setting which accounts also for pairs seen during training, we discover that naive baseline methods perform similarly or better than current approaches. However, our modular network is able to outperform all existing approaches on two widely-used benchmark datasets.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",21.272727272727273,0.017410714285714293,0.5607886904761905,1
122,122,LPD-Net: 3D point cloud learning for large-scale place recognition and environment analysis,"Point cloud based place recognition is still an open issue due to the difficulty in extracting local features from the raw 3D point cloud and generating the global descriptor, and it's even harder in the large-scale dynamic environments. In this paper, we develop a novel deep neural network, named LPD-Net (Large-scale Place Description Network), which can extract discriminative and generalizable global descriptors from the raw 3D point cloud. Two modules, the adaptive local feature extraction module and the graph-based neighborhood aggregation module, are proposed, which contribute to extract the local structures and reveal the spatial distribution of local features in the large-scale point cloud, with an end-to-end manner. We implement the proposed global descriptor in solving point cloud based retrieval tasks to achieve the large-scale place recognition. Comparison results show that our LPD-Net is much better than PointNetVLAD and reaches the state-of-the-art. We also compare our LPD-Net with the vision-based solutions to show the robustness of our approach to different weather and light conditions.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",27.333333333333332,0.012556561085972851,0.24498491704374062,1
123,123,Transferable semi-supervised 3D object detection from RGB-D data,"We investigate the direction of training a 3D object detector for new object classes from only 2D bounding box labels of these new classes, while simultaneously transferring information from 3D bounding box labels of the existing classes. To this end, we propose a transferable semi-supervised 3D object detection model that learns a 3D object detector network from training data with two disjoint sets of object classes - a set of strong classes with both 2D and 3D box labels, and another set of weak classes with only 2D box labels. In particular, we suggest a relaxed reprojection loss, box prior loss and a Box-to-Point Cloud Fit network that allow us to effectively transfer useful 3D information from the strong classes to the weak classes during training, and consequently, enable the network to detect 3D objects in the weak classes during inference. Experimental results show that our proposed algorithm outperforms baseline approaches and achieves promising results compared to fully-supervised approaches on the SUN-RGBD and KITTI datasets. Furthermore, we show that our Box-to-Point Cloud Fit network improves performances of the fully-supervised approaches on both datasets.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",36.6,0.1282976827094474,0.5343582887700534,1
124,124,Random convolutional neural network based on distributed computing with decentralized architecture,"In recent years, deep learning has made great progress in image classification and detection. Popular deep learning algorithms rely on deep networks and multiple rounds of back-propagations. In this paper, we propose two approaches to accelerate deep networks. One is expanding the width of every layer. We reference to the Extreme Learning Machine, setting big number of convolution kernels to extract features in parallel. It can obtain multiscale features and improve network efficiency. The other is freezing part of layers. It can reduce back-propagations and speed up the training procedure. From the above, it is a random convolution architecture that network is proposed for image classification. In our architecture, every combination of random convolutions extracts distinct features. Apparently, we need a lot of experiments to choose the best combination. However, centralized computing may limit the number of combinations. Therefore, a decentralized architecture is used to enable the use of multiple combinations.",60023462,Waseda University,Tokyo,Japan,['1700'],11.615384615384615,0.07894736842105263,0.3697368421052631,1
125,125,Implicit surface representations as layers in neural networks,"Implicit shape representations, such as Level Sets, provide a very elegant formulation for performing computations involving curves and surfaces. However, including implicit representations into canonical Neural Network formulations is far from straightforward. This has consequently restricted existing approaches to shape inference, to significantly less effective representations, perhaps most commonly voxels occupancy maps or sparse point clouds. To overcome this limitation we propose a novel formulation that permits the use of implicit representations of curves and surfaces, of arbitrary topology, as individual layers in Neural Network architectures with end-to-end trainability. Specifically, we propose to represent the output as an oriented level set of a continuous and discretised embedding function. We investigate the benefits of our approach on the task of 3D shape prediction from a single image; and demonstrate its ability to produce a more accurate reconstruction compared to voxel-based representations. We further show that our model is flexible and can be applied to a variety of shape inference problems.",60031004,University of Queensland,Brisbane,Australia,"['1712', '1707']",22.714285714285715,0.17763605442176872,0.542091836734694,1
126,126,Adatransform: Adaptive data transformation,"Data augmentation is widely used to increase data variance in training deep neural networks. However, previous methods require either comprehensive domain knowledge or high computational cost. Can we learn data transformation automatically and efficiently with limited domain knowledge? Furthermore, can we leverage data transformation to improve not only network training but also network testing? In this work, we propose adaptive data transformation to achieve the two goals. The AdaTransform can increase data variance in training and decrease data variance in testing. Experiments on different tasks prove that it can improve generalization performance.",60023004,University of Delaware,Newark,United States,"['1712', '1707']",18.4,-0.025442176870748297,0.4642176870748299,1
127,127,SANet: Scene agnostic network for camera localization,"This paper presents a scene agnostic neural architecture for camera localization, where model parameters and scenes are independent from each other.Despite recent advancement in learning based methods, most approaches require training for each scene one by one, not applicable for online applications such as SLAM and robotic navigation, where a model must be built on-the-fly.Our approach learns to build a hierarchical scene representation and predicts a dense scene coordinate map of a query RGB image on-the-fly given an arbitrary scene. The 6D camera pose of the query image can be estimated with the predicted scene coordinate map. Additionally, the dense prediction can be used for other online robotic and AR applications such as obstacle avoidance. We demonstrate the effectiveness and efficiency of our method on both indoor and outdoor benchmarks, achieving state-of-the-art performance.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",33.25,0.008333333333333338,0.3611111111111111,1
128,128,Micro heater with low temperature coefficient of resistance for ICF target,"A micro heater with low temperature coefficient of resistance (TCR) at liquid hydrogen temperature was designed and fabricated by micro fabrication technology. The NiCr heater annealed in N2 at 250 °C for 9 min achieves a smallest TCR of 9.36 ppm/K at 20 K. The crystal structures of NiCr film annealed in nitrogen were analyzed by scanning electron microscope (SEM) and X-ray diffraction (XRD). The crystallization of NiCr film improved with the annealing temperature increasing. The fabricated micro heater applied in the temperature control test achieves the accuracy of ±0.5 mK, which is qualified for the temperature control accuracy requirement of the ignition target of inertial confinement fusion (ICF).",60103926,Nanchang Institute of Technology,Nanchang,China,['1700'],21.8,0.0,0.6,1
129,129,Differentiable learning-to-group channels via groupable convolutional neural networks,"Group convolution, which divides the channels of ConvNets into groups, has achieved impressive improvement over the regular convolution operation. However, existing models, eg ResNext, still suffers from the sub-optimal performance due to manually defining the number of groups as a constant over all of the layers. Toward addressing this issue, we present Groupable ConvNet (GroupNet) built by using a novel dynamic grouping convolution (DGConv) operation, which is able to learn the number of groups in an end-to-end manner. The proposed approach has several appealing benefits. (1) DGConv provides a unified convolution representation and covers many existing convolution operations such as regular dense convolution, group convolution, and depthwise convolution. (2) DGConv is a differentiable and flexible operation which learns to perform various convolutions from training data. (3) GroupNet trained with DGConv learns different number of groups for different convolution layers. Extensive experiments demonstrate that GroupNet outperforms its counterparts such as ResNet and ResNeXt in terms of accuracy and computational complexity. We also present introspection and reproducibility study, for the first time, showing the learning dynamics of training group numbers.",60006541,The University of Hong Kong,Pokfulam,Hong Kong,"['1712', '1707']",19.77777777777778,0.10124999999999999,0.38602564102564096,1
130,130,Deep non-rigid structure from motion,"Current non-rigid structure from motion (NRSfM) algorithms are mainly limited with respect to: (i) the number of images, and (ii) the type of shape variability they can handle. This has hampered the practical utility of NRSfM for many applications within vision. In this paper we propose a novel deep neural network to recover camera poses and 3D points solely from an ensemble of 2D image coordinates. The proposed neural network is mathematically interpretable as a multi-layer block sparse dictionary learning problem, and can handle problems of unprecedented scale and shape complexity. Extensive experiments demonstrate the impressive performance of our approach where we exhibit superior precision and robustness against all available state-of-the-art works in the order of magnitude. We further propose a quality measure (based on the network weights) which circumvents the need for 3D ground-truth to ascertain the confidence we have in the reconstruction.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1707']",24.0,0.1982142857142857,0.5396825396825397,1
131,131,The moderating role of external environment on the relationship between resource isolating mechanism and sustainable competitive advantage," The operations of the firm are affected by the striking advances in globalization such as shifts in technology, stiff competition among business entities and new entrances within an industry. The firms including commercial banks in Kenya should therefore, have the ability to predict future trends in the external environment for survival. The main purpose of this study was to establish the moderating role of external environment on the relationship between resource isolating mechanism and sustain competitive advantage among commercial banks in Kenya. Descriptive and explanatory research design was employed in the study. The research targeted all the commercial banks in Kenya. Purposive sampling was used to select a sample of 160 respondents from the key departments of Finance, Sales and Marketing, Strategy and Operations of all the forty (40) commercial banks’ headquarters in Nairobi, Kenya. The data collection instrument used was semi-structured questionnaire. The variable characteristics were summarized using descriptive statistics. Agreement to the most frequent responses to the statements on the study variables ranged between moderate and high extent. Based on results of hypotheses testing, external environment have no moderating effect on the relationship between resource isolating mechanism and sustainable competitive advantage.",60057297,Kenyatta University,Nairobi,Kenya,['1706'],19.4,0.06046024151287308,0.35015151515151516,0
132,132,Meter detection of substation scene based on deep learning,"Automatic detection of the substation meters based on deep learning is of great importance. Meters are important equipment for monitoring substations safety. A large number of meters in the substation need to be detected and recognized, which is labor-intensive and time-consuming. Aiming at solving low detection accuracy problem in the existing methods, an efficient and accurate method based on YOLO for meter detection is proposed. First, we build a dataset of substation meters with 1432 images as the training set and 615 images as the test set. We use data augmentation strategy to solve the problem of data shortage and class-imbalance. Second, according to the characteristics of the meter image, feature pyramid is used to train the model to effectively improve the recognition performance. Finally, we use the training warm-up method to reduce the over-fitting of the training model. Experiments results show that, compared with other methods, our method can achieve better performance on several benchmarks. The detection recall improves from 88.03% to 96.08% and mAP improves from 89.64% to 93.84% on the premise of ensuring real-time performance.",60019533,Tianjin University,Tianjin,China,['1700'],17.8,0.23379120879120882,0.5015567765567766,1
133,133,Convolutional character networks,"Recent progress has been made on developing a unified framework for joint text detection and recognition in natural images, but existing joint models were mostly built on two-stage framework by involving ROI pooling, which can degrade the performance on recognition task. In this work, we propose convolutional character networks, referred as CharNet, which is an one-stage model that can process two tasks simultaneously in one pass. CharNet directly outputs bounding boxes of words and characters, with corresponding character labels. We utilize character as basic element, allowing us to overcome the main difficulty of existing approaches that attempted to optimize text detection jointly with a RNN-based recognition branch. In addition, we develop an iterative character detection approach able to transform the ability of character detection learned from synthetic data to real-world images. These technical improvements result in a simple, compact, yet powerful one-stage model that works reliably on multi-orientation and curved text. We evaluate CharNet on three standard benchmarks, where it consistently outperforms the state-of-the-art approaches [25, 24] by a large margin, e.g., with improvements of 65.33%->71.08% (with generic lexicon) on ICDAR 2015, and 54.0%->69.23% on Total-Text, on end-to-end text recognition. Code is available at: Https://github.com/MalongTech/research-charnet.",60113057,"Malong Technologies Co., Ltd.",Shenzhen,China,"['1712', '1707']",24.375,0.16873015873015873,0.34460317460317463,1
134,134,Learnable triangulation of human pose,"We present two novel solutions for multi-view 3D human pose estimation based on new learnable triangulation methods that combine 3D information from multiple 2D views. The first (baseline) solution is a basic differentiable algebraic triangulation with an addition of confidence weights estimated from the input images. The second, more complex, solution is based on volumetric aggregation of 2D feature maps from the 2D backbone followed by refinement via 3D convolutions that produce final 3D joint heatmaps. Crucially, both of the approaches are end-to-end differentiable, which allows us to directly optimize the target metric. We demonstrate transferability of the solutions across datasets and considerably improve the multi-view state of the art on the Human3.6M dataset.",60107405,Skolkovo Institute of Science and Technology,Moscow,Russian Federation,"['1712', '1707']",22.8,0.06048951048951049,0.36637529137529146,1
135,135,Bayesian relational memory for semantic visual navigation,"We introduce a new memory architecture, Bayesian Relational Memory (BRM), to improve the generalization ability for semantic visual navigation agents in unseen environments, where an agent is given a semantic target to navigate towards. BRM takes the form of a probabilistic relation graph over semantic entities (e.g., room types), which allows (1) capturing the layout prior from training environments, i.e., prior knowledge, (2) estimating posterior layout at test time, i.e., memory update, and (3) efficient planning for navigation, altogether. We develop a BRM agent consisting of a BRM module for producing sub-goals and a goal-conditioned locomotion module for control. When testing in unseen environments, the BRM agent outperforms baselines that do not explicitly utilize the probabilistic relational memory structure.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",29.75,0.03409090909090909,0.11363636363636363,1
136,136,Vision-infused deep audio inpainting,"Multi-modality perception is essential to develop interactive intelligence. In this work, we consider a new task of visual information-infused audio inpainting, i.e., synthesizing missing audio segments that correspond to their accompanying videos. We identify two key aspects for a successful inpainter: (1) It is desirable to operate on spectrograms instead of raw audios. Recent advances in deep semantic image inpainting could be leveraged to go beyond the limitations of traditional audio inpainting. (2) To synthesize visually indicated audio, a visual-audio joint feature space needs to be learned with synchronization of audio and video. To facilitate a large-scale study, we collect a new multi-modality instrument-playing dataset called MUSIC-Extra-Solo (MUSICES) by enriching MUSIC dataset. Extensive experiments demonstrate that our framework is capable of inpainting realistic and varying audio segments with or without visual contexts. More importantly, our synthesized audio segments are coherent with their video counterparts, showing the effectiveness of our proposed Vision-Infused Audio Inpainter (VIAI).",60006541,The University of Hong Kong,Pokfulam,Hong Kong,"['1712', '1707']",19.25,0.08043123543123543,0.46686480186480184,1
137,137,Enforcing geometric constraints of virtual normal for depth prediction,"Monocular depth prediction plays a crucial role in understanding 3D scene geometry. Although recent methods have achieved impressive progress in evaluation metrics such as the pixel-wise relative error, most methods neglect the geometric constraints in the 3D space. In this work, we show the importance of the high-order 3D geometric constraints for depth prediction. By designing a loss term that enforces one simple type of geometric constraints, namely, virtual normal directions determined by randomly sampled three points in the reconstructed 3D space, we can considerably improve the depth prediction accuracy. Furthermore, we can not only predict accurate depth but also achieve high-quality other 3D information from the depth without retraining new parameters, Significantly, the byproduct of this predicted depth being sufficiently accurate is that we are now able to recover good 3D structures of the scene such as the point cloud and surface normal directly from the depth, eliminating the necessity of training new sub-models as was previously done. Experiments on two challenging benchmarks: NYU Depth-V2 and KITTI demonstrate the effectiveness of our method and state-of-the-art performance.",60009512,The University of Adelaide,Adelaide,Australia,"['1712', '1707']",29.5,0.1815025252525253,0.5656069624819625,1
138,138,ACFNet: Attentional class feature network for semantic segmentation,"Recent works have made great progress in semantic segmentation by exploiting richer context, most of which are designed from a spatial perspective. In contrast to previous works, we present the concept of class center which extracts the global context from a categorical perspective. This class-level context describes the overall representation of each class in an image. We further propose a novel module, named Attentional Class Feature (ACF) module, to calculate and adaptively combine different class centers according to each pixel. Based on the ACF module, we introduce a coarse-to-fine segmentation network, called Attentional Class Feature Network (ACFNet), which can be composed of an ACF module and any off-the-shell segmentation network (base network). In this paper, we use two types of base networks to evaluate the effectiveness of ACFNet. We achieve new state-of-the-art performance of 81.85% mIoU on Cityscapes dataset with only finely annotated data used for training.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",21.0,-0.0009090909090909223,0.45474747474747473,1
139,139,Learning local RGB-to-CAD correspondences for object pose estimation,"We consider the problem of 3D object pose estimation. While much recent work has focused on the RGB domain, the reliance on accurately annotated images limits generalizability and scalability. On the other hand, the easily available object CAD models are rich sources of data, providing a large number of synthetically rendered images. In this paper, we solve this key problem of existing methods requiring expensive 3D pose annotations by proposing a new method that matches RGB images to CAD models for object pose estimation. Our key innovations compared to existing work include removing the need for either real-world textures for CAD models or explicit 3D pose annotations for RGB images. We achieve this through a series of objectives that learn how to select keypoints and enforce viewpoint and modality invariance across RGB images and CAD model renderings. Our experiments demonstrate that the proposed method can reliably estimate object pose in RGB images and generalize to object instances not seen during training.",60028673,Siemens AG,Munich,Germany,"['1712', '1707']",23.0,0.09006493506493506,0.5991450216450216,1
140,140,Attention-based autism spectrum disorder screening with privileged modality,"This paper presents a novel framework for automatic and quantitative screening of autism spectrum disorder (ASD). It is motivated to address two issues in the current clinical settings: 1) short of clinical resources with the prevalence of ASD (1.7% in the United States), and 2) subjectivity of ASD screening. This work differentiates itself with three unique features: First, it proposes an ASD screening with privileged modality framework that integrates information from two behavioral modalities during training and improves the performance on each single modality at testing. The proposed framework does not require overlap in subjects between the modalities. Second, it develops the first computational model to classify people with ASD using a photo-taking task where subjects freely explore their environment in a more ecological setting. Photo-taking reveals attentional preference of subjects, differentiating people with ASD from healthy people, and is also easy to implement in real-world clinical settings without requiring advanced diagnostic instruments. Third, this study for the first time takes advantage of the temporal information in eye movements while viewing images, encoding more detailed behavioral differences between ASD people and healthy controls. Experiments show that our ASD screening models can achieve superior performance, outperforming the previous state-of-the-art methods by a considerable margin. Moreover, our framework using diverse modalities demonstrates performance improvement on both the photo-taking and image-viewing tasks, providing a general paradigm that takes in multiple sources of behavioral data for a more accurate ASD screening. The framework is also applicable to various scenarios where one-to-one pairwise relationship is difficult to obtain across different modalities.",123974342,University of Minnesota,Saint Paul,United States,"['1712', '1707']",25.6,0.22036564625850338,0.49098639455782306,1
141,141,3D scene reconstruction with multi-layer depth and epipolar transformers,"We tackle the problem of automatically reconstructing a complete 3D model of a scene from a single RGB image. This challenging task requires inferring the shape of both visible and occluded surfaces. Our approach utilizes viewer-centered, multi-layer representation of scene geometry adapted from recent methods for single object shape completion. To improve the accuracy of view-centered representations for complex scenes, we introduce a novel 'Epipolar Feature Transformer' that transfers convolutional network features from an input view to other virtual camera viewpoints, and thus better covers the 3D scene geometry. Unlike existing approaches that first detect and localize objects in 3D, and then infer object shape using category-specific models, our approach is fully convolutional, end-to-end differentiable, and avoids the resolution and memory limitations of voxel representations. We demonstrate the advantages of multi-layer depth representations and epipolar feature transformers on the reconstruction of a large database of indoor scenes.",60019647,Georgia Institute of Technology,Atlanta,United States,"['1712', '1707']",24.5,0.09964285714285716,0.41154761904761905,1
142,142,Algebraic characterization of essential matrices and their averaging in multiview settings,"Essential matrix averaging, i.e., the task of recovering camera locations and orientations in calibrated, multiview settings, is a first step in global approaches to Euclidean structure from motion. A common approach to essential matrix averaging is to separately solve for camera orientations and subsequently for camera positions. This paper presents a novel approach that solves simultaneously for both camera orientations and positions. We offer a complete characterization of the algebraic conditions that enable a unique Euclidean reconstruction of n cameras from a collection of (n-2) essential matrices. We next use these conditions to formulate essential matrix averaging as a constrained optimization problem, allowing us to recover a consistent set of essential matrices given a (possibly partial) set of measured essential matrices computed independently for pairs of images. We finally use the recovered essential matrices to determine the global positions and orientations of the n cameras. We test our method on common SfM datasets, demonstrating high accuracy while maintaining efficiency and robustness, compared to existing methods.",60017563,Weizmann Institute of Science Israel,Rehovot,Israel,"['1712', '1707']",23.571428571428573,0.020714285714285716,0.338015873015873,1
143,143,Geostyle: Discovering fashion trends and events,"Understanding fashion styles and trends is of great potential interest to retailers and consumers alike. The photos people upload to social media are a historical and public data source of how people dress across the world and at different times. While we now have tools to automatically recognize the clothing and style attributes of what people are wearing in these photographs, we lack the ability to analyze spatial and temporal trends in these attributes or make predictions about the future. In this paper we address this need by providing an automatic framework that analyzes large corpora of street imagery to (a) discover and forecast long-term trends of various fashion attributes as well as automatically discovered styles, and (b) identify spatio-temporally localized events that affect what people wear. We show that our framework makes long term trend forecasts that are > 20% more accurate than prior art, and identifies hundreds of socially meaningful events that impact fashion across the globe.",60007776,Cornell University,Ithaca,United States,"['1712', '1707']",31.8,0.17125850340136056,0.39787414965986395,1
144,144,Delving deep into hybrid annotations for 3D human recovery in the wild,"Though much progress has been achieved in single-image 3D human recovery, estimating 3D model for in-the-wild images remains a formidable challenge. The reason lies in the fact that obtaining high-quality 3D annotations for in-the-wild images is an extremely hard task that consumes enormous amount of resources and manpower. To tackle this problem, previous methods adopt a hybrid training strategy that exploits multiple heterogeneous types of annotations including 3D and 2D while leaving the efficacy of each annotation not thoroughly investigated. In this work, we aim to perform a comprehensive study on cost and effectiveness trade-off between different annotations. Specifically, we focus on the challenging task of in-the-wild 3D human recovery from single images when paired 3D annotations are not fully available. Through extensive experiments, we obtain several observations: 1) 3D annotations are efficient, whereas traditional 2D annotations such as 2D keypoints and body part segmentation are less competent in guiding 3D human recovery. 2) Dense Correspondence such as DensePose is effective. When there are no paired in-the-wild 3D annotations available, the model exploiting dense correspondence can achieve 92% of the performance compared to a model trained with paired 3D data. We show that incorporating dense correspondence into in-the-wild 3D human recovery is promising and competitive due to its high efficiency and relatively low annotating cost. Our model trained with dense correspondence can serve as a strong reference for future research.",60012708,Stanford University,Palo Alto,United States,"['1712', '1707']",23.0,0.09185374149659864,0.3933078231292516,1
145,145,Customizing student networks from heterogeneous teachers via adaptive knowledge amalgamation,"A massive number of well-trained deep networks have been released by developers online. These networks may focus on different tasks and in many cases are optimized for different datasets. In this paper, we study how to exploit such heterogeneous pre-trained networks, known as teachers, so as to train a customized student network that tackles a set of selective tasks defined by the user. We assume no human annotations are available, and each teacher may be either single- or multi-task. To this end, we introduce a dual-step strategy that first extracts the task-specific knowledge from the heterogeneous teachers sharing the same sub-task, and then amalgamates the extracted knowledge to build the student network. To facilitate the training, we employ a selective learning scheme where, for each unlabelled sample, the student learns adaptively from only the teacher with the least prediction ambiguity. We evaluate the proposed approach on several datasets and the experimental results demonstrate that the student, learned by such adaptive knowledge amalgamation, achieves performances even better than those of the teachers.",60003970,Zhejiang University,Hangzhou,China,"['1712', '1707']",24.428571428571427,0.08109243697478992,0.44544817927170877,1
146,146,Chinese street view text: Large-scale chinese text reading with partially supervised learning,"Most existing text reading benchmarks make it difficult to evaluate the performance of more advanced deep learning models in large vocabularies due to the limited amount of training data. To address this issue, we introduce a new large-scale text reading benchmark dataset named Chinese Street View Text (C-SVT) with 430,000 street view images, which is at least 14 times as large as the existing Chinese text reading benchmarks. To recognize Chinese text in the wild while keeping large-scale datasets labeling cost-effective, we propose to annotate one part of the C-SVT dataset (30,000 images) in locations and text labels as full annotations and add 400,000 more images, where only the corresponding text-of-interest in the regions is given as weak annotations. To exploit the rich information from the weakly annotated data, we design a text reading network in a partially supervised learning framework, which enables to localize and recognize text, learn from fully and weakly annotated data simultaneously. To localize the best matched text proposals from weakly labeled images, we propose an online proposal matching module incorporated in the whole model, spotting the keyword regions by sharing parameters for end-to-end training. Compared with fully supervised training algorithms, this model can improve the end-to-end recognition performance remarkably by 4.03% in F-score at the same labeling cost. The proposed model can also achieve state-of-the-art results on the ICDAR 2017-RCTW dataset, which demonstrates the effectiveness of the proposed partially supervised learning framework.",60112903,"Baidu, Inc.",Beijing,China,"['1712', '1707']",33.857142857142854,0.08770712046574117,0.4518808777429468,1
147,147,ARGAN: Attentive recurrent generative adversarial network for shadow detection and removal,"In this paper we propose an attentive recurrent generative adversarial network (ARGAN) to detect and remove shadows in an image. The generator consists of multiple progressive steps. At each step a shadow attention detector is firstly exploited to generate an attention map which specifies shadow regions in the input image. Given the attention map, a negative residual by a shadow remover encoder will recover a shadow-lighter or even a shadow-free image. The discriminator is designed to classify whether the output image in the last progressive step is real or fake. Moreover, ARGAN is suitable to be trained with a semi-supervised strategy to make full use of sufficient unsupervised data. The experiments on four public datasets have demonstrated that our ARGAN is robust to detect both simple and complex shadows and to produce more realistic shadow removal results. It outperforms the state-of-the-art methods, especially in detail of recovering shadow areas.",60114004,"Kitware, Inc.",Clifton Park,United States,"['1712', '1707']",18.625,0.0619047619047619,0.47551020408163264,1
148,148,Learning local descriptors with a CDF-based dynamic soft margin,"The triplet loss is adopted by a variety of learning tasks, such as local feature descriptor learning. However, its standard formulation with a hard margin only leverages part of the training data in each mini-batch. Moreover, the margin is often empirically chosen or determined through computationally expensive validation, and stays unchanged during the entire training session. In this work, we propose a simple yet effective method to overcome the above limitations. The core idea is to replace the hard margin with a non-parametric soft margin, which is dynamically updated. The major observation is that the difficulty of a triplet can be inferred from the cumulative distribution function of the triplets' signed distances to the decision boundary. We demonstrate through experiments on both real-valued and binary local feature descriptors that our method leads to state-of-the-art performance on popular benchmarks, while eliminating the need to determine the best margin.",60003269,Princeton University,Princeton,United States,"['1712', '1707']",21.0,0.08112745098039216,0.43032212885154064,1
149,149,A deep step pattern representation for multimodal retinal image registration,"This paper presents a novel feature-based method that is built upon a convolutional neural network (CNN) to learn the deep representation for multimodal retinal image registration. We coined the algorithm deep step patterns, in short DeepSPa. Most existing deep learning based methods require a set of manually labeled training data with known corresponding spatial transformations, which limits the size of training datasets. By contrast, our method is fully automatic and scale well to different image modalities with no human intervention. We generate feature classes from simple step patterns within patches of connecting edges formed by vascular junctions in multiple retinal imaging modalities. We leverage CNN to learn and optimize the input patches to be used for image registration. Spatial transformations are estimated based on the output possibility of the fully connected layer of CNN for a pair of images. One of the key advantages of the proposed algorithm is its robustness to non-linear intensity changes, which widely exist on retinal images due to the difference of acquisition modalities. We validate our algorithm on extensive challenging datasets comprising poor quality multimodal retinal images which are adversely affected by pathologies (diseases), speckle noise and low resolutions. The experimental results demonstrate the robustness and accuracy over state-of-the-art multimodal image registration algorithms.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",20.8,0.027941176470588233,0.4391456582633053,1
150,150,Deep elastic networks with model selection for multi-task learning,"In this work, we consider the problem of instance-wise dynamic network model selection for multi-task learning. To this end, we propose an efficient approach to exploit a compact but accurate model in a backbone architecture for each instance of all tasks. The proposed method consists of an estimator and a selector. The estimator is based on a backbone architecture and structured hierarchically. It can produce multiple different network models of different configurations in a hierarchical structure. The selector chooses a model dynamically from a pool of candidate models given an input instance. The selector is a relatively small-size network consisting of a few layers, which estimates a probability distribution over the candidate models when an input instance of a task is given. Both estimator and selector are jointly trained in a unified learning framework in conjunction with a sampling-based learning strategy, without additional computation steps. We demonstrate the proposed approach for several image classification tasks compared to existing approaches performing model selection or learning multiple tasks. Experimental results show that our approach gives not only outstanding performance compared to other competitors but also the versatility to perform instance-wise model selection for multiple tasks.",60120116,Automation and Systems Research Institute,Seoul,South Korea,"['1712', '1707']",19.3,0.048214285714285716,0.3392857142857143,1
151,151,Scaling object detection by transferring classification weights,"Large scale object detection datasets are constantly increasing their size in terms of the number of classes and annotations count. Yet, the number of object-level categories annotated in detection datasets is an order of magnitude smaller than image-level classification labels. State-of-the art object detection models are trained in a supervised fashion and this limits the number of object classes they can detect. In this paper, we propose a novel weight transfer network (WTN) to effectively and efficiently transfer knowledge from classification network's weights to detection network's weights to allow detection of novel classes without box supervision. We first introduce input and feature normalization schemes to curb the under-fitting during training of a vanilla WTN. We then propose autoencoder-WTN (AE-WTN) which uses reconstruction loss to preserve classification network's information over all classes in the target latent space to ensure generalization to novel classes. Compared to vanilla WTN, AE-WTN obtains absolute performance gains of 6% on two Open Images evaluation sets with 500 seen and 57 novel classes respectively, and 25% on a Visual Genome evaluation set with 200 novel classes.",60005510,Nanyang Technological University,Singapore City,Singapore,"['1712', '1707']",25.571428571428573,0.14047619047619048,0.4328042328042328,1
152,152,Omni-scale feature learning for person re-identification,"As an instance-level recognition problem, person re-identification (ReID) relies on discriminative features, which not only capture different spatial scales but also encapsulate an arbitrary combination of multiple scales. We callse features of both homogeneous and heterogeneous scales omni-scale features. In this paper, a novel deep ReID CNN is designed, termed Omni-Scale Network (OSNet), for omni-scale feature learning. This is achieved by designing a residual block composed of multiple convolutional feature streams, each detecting features at a certain scale. Importantly, a novel unified aggregation gate is introduced to dynamically fuse multi-scale features with input-dependent channel-wise weights. To efficiently learn spatial-channel correlations and avoid overfitting, the building block uses both pointwise and depthwise convolutions. By stacking such blocks layer-by-layer, our OSNet is extremely lightweight and can be trained from scratch on existing ReID benchmarks. Despite its small model size, our OSNet achieves state-of-the-art performance on six person-ReID datasets. Code and models are available at: Https://github.com/KaiyangZhou/deep-person-reid.",60022109,"Queen Mary, University of London",London,United Kingdom,"['1712', '1707']",17.0,0.04494047619047619,0.5392857142857144,1
153,153,Bridging the domain gap for ground-to-aerial image matching,"The visual entities in cross-view (e.g. ground and aerial) images exhibit drastic domain changes due to the differences in viewpoints each set of images is captured from. Existing state-of-the-art methods address the problem by learning view-invariant images descriptors. We propose a novel method for solving this task by exploiting the gener- ative powers of conditional GANs to synthesize an aerial representation of a ground-level panorama query and use it to minimize the domain gap between the two views. The synthesized image being from the same view as the ref- erence (target) image, helps the network to preserve im- portant cues in aerial images following our Joint Feature Learning approach. We fuse the complementary features from a synthesized aerial image with the original ground- level panorama features to obtain a robust query represen- tation. In addition, we employ multi-scale feature aggre- gation in order to preserve image representations at dif- ferent scales useful for solving this complex task. Experi- mental results show that our proposed approach performs significantly better than the state-of-the-art methods on the challenging CVUSA dataset in terms of top-1 and top-1% retrieval accuracies. Furthermore, we evaluate the gen- eralization of the proposed method for urban landscapes on our newly collected cross-view localization dataset with geo-reference information.",60022144,University of Central Florida,Orlando,United States,"['1712', '1707']",23.11111111111111,0.10719696969696968,0.3253787878787879,1
154,154,DewarpNet: Single-image document unwarping with stacked 3D and 2D regression networks,"Capturing document images with hand-held devices in unstructured environments is a common practice nowadays. However, 'casual' photos of documents are usually unsuitable for automatic information extraction, mainly due to physical distortion of the document paper, as well as various camera positions and illumination conditions. In this work, we propose DewarpNet, a deep-learning approach for document image unwarping from a single image. Our insight is that the 3D geometry of the document not only determines the warping of its texture but also causes the illumination effects. Therefore, our novelty resides on the explicit modeling of 3D shape for document paper in an end-to-end pipeline. Also, we contribute the largest and most comprehensive dataset for document image unwarping to date - Doc3D. This dataset features multiple ground-truth annotations, including 3D shape, surface normals, UV map, albedo image, etc. Training with Doc3D, we demonstrate state-of-the-art performance for DewarpNet with extensive qualitative and quantitative evaluations. Our network also significantly improves OCR performance on captured document images, decreasing character error rate by 42% on average. Both the code and the dataset are released.",60026415,Stony Brook University,Stony Brook,United States,"['1712', '1707']",17.8,-0.037244897959183676,0.42551020408163265,1
155,155,3Dpeople: Modeling the geometry of dressed humans,"Recent advances in 3D human shape estimation build upon parametric representations that model very well the shape of the naked body, but are not appropriate to represent the clothing geometry. In this paper, we present an approach to model dressed humans and predict their geometry from single images. We contribute in three fundamental aspects of the problem, namely, a new dataset, a novel shape parameterization algorithm and an end-to-end deep generative network for predicting shape. First, we present 3DPeople, a large-scale synthetic dataset with 2 Million photo-realistic images of 80 subjects performing 70 activities and wearing diverse outfits. Besides providing textured 3D meshes for clothes and body we annotated the dataset with segmentation masks, skeletons, depth, normal maps and optical flow. All this together makes 3DPeople suitable for a plethora of tasks. We then represent the 3D shapes using 2D geometry images. To build these images we propose a novel spherical area-preserving parameterization algorithm based on the optimal mass transportation method. We show this approach to improve existing spherical maps which tend to shrink the elongated parts of the full body models such as the arms and legs, making the geometry images incomplete. Finally, we design a multi-resolution deep generative network that, given an input image of a dressed human, predicts his/her geometry image (and thus the clothed body shape) in an end-to-end manner. We obtain very promising results in jointly capturing body pose and clothing shape, both for synthetic validation and on the wild images.",60077572,Harvard John A. Paulson School of Engineering and Applied Sciences,Cambridge,United States,"['1712', '1707']",22.363636363636363,0.08374675324675326,0.39760822510822513,1
156,156,Mono-SF: Multi-view geometry meets single-view depth for monocular scene flow estimation of dynamic traffic scenes,"Existing 3D scene flow estimation methods provide the 3D geometry and 3D motion of a scene and gain a lot of interest, for example in the context of autonomous driving. These methods are traditionally based on a temporal series of stereo images. In this paper, we propose a novel monocular 3D scene flow estimation method, called Mono-SF. Mono-SF jointly estimates the 3D structure and motion of the scene by combining multi-view geometry and single-view depth information. Mono-SF considers that the scene flow should be consistent in terms of warping the reference image in the consecutive image based on the principles of multi-view geometry. For integrating single-view depth in a statistical manner, a convolutional neural network, called ProbDepthNet, is proposed. ProbDepthNet estimates pixel-wise depth distributions from a single image rather than single depth values. Additionally, as part of ProbDepthNet, a novel recalibration technique for regression problems is proposed to ensure well-calibrated distributions. Our experiments show that Mono-SF outperforms state-of-the-art monocular baselines and ablation studies support the Mono-SF approach and ProbDepthNet design.",60015776,Robert Bosch GmbH,Gerlingen,Germany,"['1712', '1707']",18.88888888888889,0.10142857142857145,0.4257142857142857,1
157,157,"Communication and customer relations strategy in improving hotel guests' satisfaction in Samosir tourism area, North Sumatra, Indonesia"," The research population is Hotel managers located on Samosir Island with saturated sample techniques where population units are sampled as a whole. Then, the data obtained were analyzed using regression analysis based on the Structural Equation Modeling (SEM) Partial Least Square (PLS). The empirical results of this study have shown that customer relationship marketing has an effect on the satisfaction of hotel guests. The success of the Hotel strategy in the Samosir area has given the guests satisfaction that has been a parameter for their future hotel success. Hotels that have failed in general have suffered a loss of trust and dissatisfaction with guests and communities. The communication strategies that have been established by the customer relationship hotel in Samosir area have shown good strategy. The customer relationship strategy that hotels in Samosir have created to increase guest satisfaction among them; Hotel provides Family Gathering activities. Family gatherings are of two types - employee gatherings are a regular event for all employees to develop intimacy between employees. Customers gathering is a special event for guests to foster relationships. Customers relationship Hotel in Samosir area also has strategies in handling guest complaints. The strategy of the Hotel in the Samosir area in dealing with guest complaints is through a cooperative approach to guests. Customers relations Hotel in Samosir area is divided into two parts; guest service and customer information section. The existing customer relations of the Samosir Hotel has become a mediator that connects the agency with its guests. The needs of any guest they want should go through the customer relations section. Here the role of customer relations is also the communicator of the agency. The service department has the task of welcoming guests; providing services for all guests' needs and providing information on procedures. Customer relations have been able to increase hotel guests’ satisfaction in Samosir area through innovation. It has been proven to increase the satisfaction of hotel guests. It is also closely linked to the hotel's customer relations strategy.",121414468,Faculty of Social and Political Science,Medan,Indonesia,['1706'],17.526315789473685,0.12362637362637363,0.30756551141166527,0
158,158,Learning to rank proposals for object detection,"Non-Maximum Suppression (NMS) is an essential step of modern object detection models for removing duplicated candidates. The efficacy of NMS heavily affects the final detection results. Prior works exploit suppression criterions relying on either the objectiveness derived from classification or the overlapness produced by regression, both of which are heuristically designed and fail to explicitly link with the suppression rank. To address this issue, in this paper, we propose a novel Learning-to-Rank (LTR) model to produce the suppression rank via a learning procedure, thus facilitating the candidate generation and lifting the detection performance. In particular, we define a ranking score based on IoU to indicate the ranks of candidates during the NMS step, where candidates with high ranking score will be reserved and the ones with low ranking score will be eliminated. We design a lightweight network to predict the ranking score. We introduce a ranking loss to supervise the generation of these ranking scores, which encourages candidates with IoU to the ground-truth to rank higher. To facilitate the training procedure, we design a novel sampling strategy via dividing candidates into different levels and select hard pairs to adopt in the training. During the inference phase, this module can be exploited as a plugin to the current object detector. The training and inference of the overall framework is end-to-end. Comprehensive experiments on benchmarks PASCAL VOC and MS COCO demonstrate the generality and effectiveness of our model for facilitating existing object detectors to state-of-the-art accuracy.",60118460,Alibaba Group Holding Limited,Yu Hang,China,"['1712', '1707']",22.181818181818183,-0.1538235294117647,0.4891176470588235,1
159,159,GarNet: A two-stream network for fast and accurate 3D cloth draping,"While Physics-Based Simulation (PBS) can accurately drape a 3D garment on a 3D body, it remains too costly for real-time applications, such as virtual try-on. By contrast, inference in a deep network, requiring a single forward pass, is much faster. Taking advantage of this, we propose a novel architecture to fit a 3D garment template to a 3D body. Specifically, we build upon the recent progress in 3D point cloud processing with deep networks to extract garment features at varying levels of detail, including point-wise, patch-wise and global features. We fuse these features with those extracted in parallel from the 3D body, so as to model the cloth-body interactions. The resulting two-stream architecture, which we call as GarNet, is trained using a loss function inspired by physics-based modeling, and delivers visually plausible garment shapes whose 3D points are, on average, less than 1 cm away from those of a PBS method, while running 100 times faster. Moreover, the proposed method can model various garment types with different cutting patterns when parameters of those patterns are given as input to the network.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",25.857142857142858,0.03199404761904764,0.3727678571428571,1
160,160,Learning to caption images through a lifetime by asking questions,"In order to bring artificial agents into our lives, we will need to go beyond supervised learning on closed datasets to having the ability to continuously expand knowledge. Inspired by a student learning in a classroom, we present an agent that can continuously learn by posing natural language questions to humans. Our agent is composed of three interacting modules, one that performs captioning, another that generates questions and a decision maker that learns when to ask questions by implicitly reasoning about the uncertainty of the agent and expertise of the teacher. As compared to current active learning methods which query images for full captions, our agent is able to ask pointed questions to improve the generated captions. The agent trains on the improved captions, expanding its knowledge. We show that our approach achieves better performance using less human supervision than the baselines on the challenging MSCOCO dataset.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",24.5,0.07916666666666668,0.4451388888888888,1
161,161,Video face clustering with unknown number of clusters,"Understanding videos such as TV series and movies requires analyzing who the characters are and what they are doing. We address the challenging problem of clustering face tracks based on their identity. Different from previous work in this area, we choose to operate in a realistic and difficult setting where: (i) the number of characters is not known a priori; and (ii) face tracks belonging to minor or background characters are not discarded. To this end, we propose Ball Cluster Learning (BCL), a supervised approach to carve the embedding space into balls of equal size, one for each cluster. The learned ball radius is easily translated to a stopping criterion for iterative merging algorithms. This gives BCL the ability to estimate the number of clusters as well as their assignment, achieving promising results on commonly used datasets. We also present a thorough discussion of how existing metric learning literature can be adapted for this task.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",22.142857142857142,-0.035897435897435895,0.5294871794871795,1
162,162,Stochastic exposure coding for handling multi-tof-camera interference,"As continuous-wave time-of-flight (C-ToF) cameras become popular in 3D imaging applications, they need to contend with the problem of multi-camera interference (MCI). In a multi-camera environment, a ToF camera may receive light from the sources of other cameras, resulting in large depth errors. In this paper, we propose stochastic exposure coding (SEC), a novel approach for mitigating. SEC involves dividing a camera's integration time into multiple slots, and switching the camera off and on stochastically during each slot. This approach has two benefits. First, by appropriately choosing the on probability for each slot, the camera can effectively filter out both the AC and DC components of interfering signals, thereby mitigating depth errors while also maintaining high signal-to-noise ratio. This enables high accuracy depth recovery with low power consumption. Second, this approach can be implemented without modifying the C-ToF camera's coding functions, and thus, can be used with a wide range of cameras with minimal changes. We demonstrate the performance benefits of SEC with theoretical analysis, simulations and real experiments, across a wide range of imaging scenarios.",60032179,University of Wisconsin-Madison,Madison,United States,"['1712', '1707']",19.555555555555557,0.11796428571428572,0.4508452380952381,1
163,163,Relation parsing neural network for human-object interaction detection,"Human-Object Interaction Detection devotes to infer a triplet < human, verb, object > between human and objects. In this paper, we propose a novel model, i.e., Relation Parsing Neural Network (RPNN), to detect human-object interactions. Specifically, the network is represented by two graphs, i.e., Object-Bodypart Graph and Human-Bodypart Graph. Here, the Object-Bodypart Graph dynamically captures the relationship between body parts and the surrounding objects. The Human-Bodypart Graph infers the relationship between human and body parts, and assembles body part contexts to predict actions. These two graphs are associated through an action passing mechanism. The proposed RPNN model is able to implicitly parse a pairwise relation in two graphs without supervised labels. Experiments conducted on V-COCO and HICO-DET datasets confirm the effectiveness of the proposed RPNN network which significantly outperforms state-of-the-art methods.",60009860,Fudan University,Shanghai,China,"['1712', '1707']",16.375,0.1625,0.31666666666666665,1
164,164,HAWQ: Hessian aware quantization of neural networks with mixed-precision,"Model size and inference speed/power have become a major challenge in the deployment of neural networks for many applications. A promising approach to address these problems is quantization. However, uniformly quantizing a model to ultra-low precision leads to significant accuracy degradation. A novel solution for this is to use mixed-precision quantization, as some parts of the network may allow lower precision as compared to other layers. However, there is no systematic way to determine the precision of different layers. A brute force approach is not feasible for deep networks, as the search space for mixed-precision is exponential in the number of layers. Another challenge is a similar factorial complexity for determining block-wise fine-tuning order when quantizing the model to a target precision. Here, we introduce Hessian AWare Quantization (HAWQ), a novel second-order quantization method to address these problems. HAWQ allows for the automatic selection of the relative quantization precision of each layer, based on the layer's Hessian spectrum. Moreover, HAWQ provides a deterministic fine-tuning order for quantizing layers. We show the results of our method on Cifar-10 using ResNet20, and on ImageNet using Inception-V3, ResNet50 and SqueezeNext models. Comparing HAWQ with state-of-the-art shows that we can achieve similar/better accuracy with 8× activation compression ratio on ResNet20, as compared to DNAS, and up to 1% higher accuracy with up to 14% smaller models on ResNet50 and Inception-V3, compared to recently proposed methods of RVQuant and HAQ. Furthermore, we show that we can quantize SqueezeNext to just 1MB model size while achieving above 68% top1 accuracy on ImageNet.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",19.692307692307693,0.10803571428571428,0.4107142857142857,1
165,165,"VaTeX: A large-scale, high-quality multilingual dataset for video-and-language research","We present a new large-scale multilingual video description dataset, VATEX, which contains over 41,250 videos and 825,000 captions in both English and Chinese. Among the captions, there are over 206,000 English-Chinese parallel translation pairs. Compared to the widely-used MSR-VTT dataset, vatex is multilingual, larger, linguistically complex, and more diverse in terms of both video and natural language descriptions. We also introduce two tasks for video-and-language research based on vatex: (1) Multilingual Video Captioning, aimed at describing a video in various languages with a compact unified captioning model, and (2) Video-guided Machine Translation, to translate a source language description into the target language using the video information as additional spatiotemporal context. Extensive experiments on the vatex dataset show that, first, the unified multilingual model can not only produce both English and Chinese descriptions for a video more efficiently, but also offer improved performance over the monolingual models. Furthermore, we demonstrate that the spatiotemporal video context can be effectively utilized to align source and target languages and thus assist machine translation. In the end, we discuss the potentials of using vatex for other video-and-language research.",60029241,"University of California, Santa Barbara",Santa Barbara,United States,"['1712', '1707']",26.142857142857142,0.04796650717703349,0.3734848484848485,1
167,167,Aligning latent spaces for 3D hand pose estimation,"Hand pose estimation from monocular RGB inputs is a highly challenging task. Many previous works for monocular settings only used RGB information for training despite the availability of corresponding data in other modalities such as depth maps. In this work, we propose to learn a joint latent representation that leverages other modalities as weak labels to boost the RGB-based hand pose estimator. By design, our architecture is highly flexible in embedding various diverse modalities such as heat maps, depth maps and point clouds. In particular, we find that encoding and decoding the point cloud of the hand surface can improve the quality of the joint latent representation. Experiments show that with the aid of other modalities during training, our proposed method boosts the accuracy of RGB-based hand pose estimation systems and significantly outperforms state-of-the-art on two public benchmarks.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",23.0,0.052333333333333336,0.5154444444444445,1
168,168,Self-supervised deep depth denoising,"Depth perception is considered an invaluable source of information for various vision tasks. However, depth maps acquired using consumer-level sensors still suffer from non-negligible noise. This fact has recently motivated researchers to exploit traditional filters, as well as the deep learning paradigm, in order to suppress the aforementioned non-uniform noise, while preserving geometric details. Despite the effort, deep depth denoising is still an open challenge mainly due to the lack of clean data that could be used as ground truth. In this paper, we propose a fully convolutional deep autoencoder that learns to denoise depth maps, surpassing the lack of ground truth data. Specifically, the proposed autoencoder exploits multiple views of the same scene from different points of view in order to learn to suppress noise in a self-supervised end-to-end manner using depth and color information during training, yet only depth during inference. To enforce self-supervision, we leverage a differentiable rendering technique to exploit photometric supervision, which is further regularized using geometric and surface priors. As the proposed approach relies on raw data acquisition, a large RGB-D corpus is collected using Intel RealSense sensors. Complementary to a quantitative evaluation, we demonstrate the effectiveness of the proposed self-supervised denoising approach on established 3D reconstruction applications. Code is avalable at https://github.com/VCL3D/DeepDepthDenoising.",60026208,Center For Research And Technology - Hellas,Thessaloniki,Greece,"['1712', '1707']",20.9,0.013246067657832363,0.43471234647705237,1
169,169,Health and hygiene practices among school children in Mangalore city," Globally, billions of people do not have access to improved health and hygiene. Sanitation is least cared for. So, this study is undertaken with the objectives, to find the practices of health and hygiene among school children in Mangalore city and to compare the practices on health and hygiene between Government, Private and Aided school children. Tools used for the study were Survey method and Questionnaire. Children in the age range of 10-12 years were selected for the study. Sixteen schools, 8 from north and 8 from south were taken for the study. Questionnaires were distributed to 820 respondents, i.e. 183 Government, 309 Aided and 328 Private school children to elicit information regarding their practices on health and hygiene. Questions were explained to them clearly during the study. The opinions collected by using the questionnaire were scored and tabulated. It was seen from the finding that mean practice scores were found highest in Private school (74.2%) when compared to Government school (55.8%) and Aided school (55.4%) respondents. The data wasanalyzed statistically by using the F test and found that there was a highly significant difference between different types of school and the mean practice score on health and hygiene (F=733.32**).",123840304,Besant Women’s College,Mangalore,India,['1706'],16.75,-0.018181818181818177,0.5234848484848484,0
170,170,Fashion++: Minimal edits for outfit improvement,"Given an outfit, what small changes would most improve its fashionability? This question presents an intriguing new computer vision challenge. We introduce Fashion++, an approach that proposes minimal adjustments to a full-body clothing outfit that will have maximal impact on its fashionability. Our model consists of a deep image generation neural network that learns to synthesize clothing conditioned on learned per-garment encodings. The latent encodings are explicitly factorized according to shape and texture, thereby allowing direct edits for both fit/presentation and color/patterns/material, respectively. We show how to bootstrap Web photos to automatically train a fashionability model, and develop an activation maximization-style approach to transform the input image into its more fashionable self. The edits suggested range from swapping in a new garment to tweaking its color, how it is worn (e.g., rolling up sleeves), or its fit (e.g., making pants baggier). Experiments demonstrate that Fashion++ provides successful edits, both according to automated metrics and human opinion.",60104837,Cornell Tech,New York,United States,"['1712', '1707']",22.285714285714285,0.1902097902097902,0.4353146853146853,1
171,171,Attribute manipulation generative adversarial networks for fashion images,"Recent advances in Generative Adversarial Networks (GANs) have made it possible to conduct multi-domain image-to-image translation using a single generative network. While recent methods such as Ganimation and SaGAN are able to conduct translations on attribute-relevant regions using attention, they do not perform well when the number of attributes increases as the training of attention masks mostly rely on classification losses. To address this and other limitations, we introduce Attribute Manipulation Generative Adversarial Networks (AMGAN) for fashion images. While AMGAN's generator network uses class activation maps (CAMs) to empower its attention mechanism, it also exploits perceptual losses by assigning reference (target) images based on attribute similarities. AMGAN incorporates an additional discriminator network that focuses on attribute-relevant regions to detect unrealistic translations. Additionally, AMGAN can be controlled to perform attribute manipulations on specific regions such as the sleeve or torso regions. Experiments show that AMGAN outperforms state-of-the-art methods using traditional evaluation metrics as well as an alternative one that is based on image retrieval.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",23.285714285714285,0.02529761904761905,0.5074404761904762,1
172,172,Fine-grained segmentation networks: Self-supervised segmentation for improved long-term visual localization,"Long-term visual localization is the problem of estimating the camera pose of a given query image in a scene whose appearance changes over time. It is an important problem in practice that is, for example, encountered in autonomous driving. In order to gain robustness to such changes, long-term localization approaches often use segmantic segmentations as an invariant scene representation, as the semantic meaning of each scene part should not be affected by seasonal and other changes. However, these representations are typically not very discriminative due to the very limited number of available classes. In this paper, we propose a novel neural network, the Fine-Grained Segmentation Network (FGSN), that can be used to provide image segmentations with a larger number of labels and can be trained in a self-supervised fashion. In addition, we show how FGSNs can be trained to output consistent labels across seasonal changes. We show through extensive experiments that integrating the fine-grained segmentations produced by our FGSNs into existing localization algorithms leads to substantial improvements in localization performance.",60000990,Chalmers University of Technology,Göteborg,Sweden,"['1712', '1707']",24.285714285714285,0.08392857142857142,0.40992063492063485,1
173,173,JPEG artifacts reduction via deep convolutional sparse coding,"To effectively reduce JPEG compression artifacts, we propose a deep convolutional sparse coding (DCSC) network architecture. We design our DCSC in the framework of classic learned iterative shrinkage-threshold algorithm. To focus on recognizing and separating artifacts only, we sparsely code the feature maps instead of the raw image. The final de-blocked image is directly reconstructed from the coded features. We use dilated convolution to extract multi-scale image features, which allows our single model to simultaneously handle multiple JPEG compression levels. Since our method integrates model-based convolutional sparse coding with a learning-based deep neural network, the entire network structure is compact and more explainable. The resulting lightweight model generates comparable or better de-blocking results when compared with state-of-the-art methods.",60030162,Columbia University in the City of New York,New York,United States,"['1712', '1707']",16.857142857142858,0.12034375880529725,0.49749929557621875,1
174,174,GODS: Generalized one-class discriminative subspaces for anomaly detection,"One-class learning is the classic problem of fitting a model to data for which annotations are available only for a single class. In this paper, we propose a novel objective for one-class learning. Our key idea is to use a pair of orthonormal frames - as subspaces - to ''sandwich'' the labeled data via optimizing for two objectives jointly: I) minimize the distance between the origins of the two subspaces, and ii) to maximize the margin between the hyperplanes and the data, either subspace demanding the data to be in its positive and negative orthant respectively. Our proposed objective however leads to a non-convex optimization problem, to which we resort to Riemannian optimization schemes and derive an efficient conjugate gradient scheme on the Stiefel manifold. To study the effectiveness of our scheme, we propose a new dataset Dash-Cam-Pose, consisting of clips with skeleton poses of humans seated in a car, the task being to classify the clips as normal or abnormal; the latter is when any human pose is out-of-position with regard to say an airbag deployment. Our experiments on the proposed Dash-Cam-Pose dataset, as well as several other standard anomaly/novelty detection benchmarks demonstrate the benefits of our scheme, achieving state-of-the-art one-class accuracy.",60008950,Australian National University,Canberra,Australia,"['1712', '1707']",33.833333333333336,0.0602152477152477,0.33921957671957664,1
175,175,Gated-SCNN: Gated shape CNNs for semantic segmentation,"Current state-of-the-art methods for image segmentation form a dense image representation where the color, shape and texture information are all processed together inside a deep CNN. This however may not be ideal as they contain very different type of information relevant for recognition. Here, we propose a new two-stream CNN architecture for semantic segmentation that explicitly wires shape information as a separate processing branch, i.e. shape stream, that processes information in parallel to the classical stream. Key to this architecture is a new type of gates that connect the intermediate layers of the two streams. Specifically, we use the higher-level activations in the classical stream to gate the lower-level activations in the shape stream, effectively removing noise and helping the shape stream to only focus on processing the relevant boundary-related information. This enables us to use a very shallow architecture for the shape stream that operates on the image-level resolution. Our experiments show that this leads to a highly effective architecture that produces sharper predictions around object boundaries and significantly boosts performance on thinner and smaller objects. Our method achieves state-of-the-art performance on the Cityscapes benchmark, in terms of both mask (mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong baselines.",60076695,NVIDIA,Santa Clara,United States,"['1712', '1707']",22.666666666666668,0.1867224880382775,0.6130223285486442,1
176,176,Controllable artistic text style transfer via shape-matching GAN,"Artistic text style transfer is the task of migrating the style from a source image to the target text to create artistic typography. Recent style transfer methods have considered texture control to enhance usability. However, controlling the stylistic degree in terms of shape deformation remains an important open challenge. In this paper, we present the first text style transfer network that allows for real-time control of the crucial stylistic degree of the glyph through an adjustable parameter. Our key contribution is a novel bidirectional shape matching framework to establish an effective glyph-style mapping at various deformation levels without paired ground truth. Based on this idea, we propose a scale-controllable module to empower a single network to continuously characterize the multi-scale shape features of the style image and transfer these features to the target text. The proposed method demonstrates its superiority over previous state-of-the-arts in generating diverse, controllable and high-quality stylized text.",60014966,Peking University,Beijing,China,"['1712', '1707']",21.571428571428573,0.1291208791208791,0.5972527472527472,1
177,177,Occlusion-shared and feature-separated network for occlusion relationship reasoning,"Occlusion relationship reasoning demands closed contour to express the object, and orientation of each contour pixel to describe the order relationship between objects. Current CNN-based methods neglect two critical issues of the task: (1) simultaneous existence of the relevance and distinction for the two elements, i.e, occlusion edge and occlusion orientation; and (2) inadequate exploration to the orientation features. For the reasons above, we propose the Occlusion-shared and Feature-separated Network (OFNet). On one hand, considering the relevance between edge and orientation, two sub-networks are designed to share the occlusion cue. On the other hand, the whole network is split into two paths to learn the high semantic features separately. Moreover, a contextual feature for orientation prediction is extracted, which represents the bilateral cue of the foreground and background areas. The bilateral cue is then fused with the occlusion cue to precisely locate the object regions. Finally, a stripe convolution is designed to further aggregate features from surrounding scenes of the occlusion edge. The proposed OFNet remarkably advances the state-of-the-art approaches on PIOD and BSDS ownership dataset.",60026054,Lenovo Group,Morrisville,United States,"['1712', '1707']",19.555555555555557,0.04458333333333334,0.56375,1
178,178,Object-driven multi-layer scene decomposition from a single image,"We present a method that tackles the challenge of predicting color and depth behind the visible content of an image. Our approach aims at building up a Layered Depth Image (LDI) from a single RGB input, which is an efficient representation that arranges the scene in layers, including originally occluded regions. Unlike previous work, we enable an adaptive scheme for the number of layers and incorporate semantic encoding for better hallucination of partly occluded objects. Additionally, our approach is object-driven, which especially boosts the accuracy for the occluded intermediate objects. The framework consists of two steps. First, we individually complete each object in terms of color and depth, while estimating the scene layout. Second, we rebuild the scene based on the regressed layers and enforce the recomposed image to resemble the structure of the original input. The learned representation enables various applications, such as 3D photography and diminished reality, all from a single RGB image.",60019722,Technical University of Munich,Munich,Germany,"['1712', '1707']",19.375,0.06360544217687075,0.4306122448979592,1
179,179,Image generation from small datasets via batch statistics adaptation,"Thanks to the recent development of deep generative models, it is becoming possible to generate high-quality images with both fidelity and diversity. However, the training of such generative models requires a large dataset. To reduce the amount of data required, we propose a new method for transferring prior knowledge of the pre-trained generator, which is trained with a large dataset, to a small dataset in a different domain. Using such prior knowledge, the model can generate images leveraging some common sense that cannot be acquired from a small dataset. In this work, we propose a novel method focusing on the parameters for batch statistics, scale and shift, of the hidden layers in the generator. By training only these parameters in a supervised manner, we achieved stable training of the generator, and our method can generate higher quality images compared to previous methods without collapsing, even when the dataset is small (∼100). Our results show that the diversity of the filters acquired in the pre-trained generator is important for the performance on the target domain. Our method makes it possible to add a new class or domain to a pre-trained generator without disturbing the performance on the original domain. Code is available at github.com/nogu-atsu/small-dataset-image-generation.",60025272,University of Tokyo,Tokyo,Japan,"['1712', '1707']",22.555555555555557,0.033072791406124735,0.508008658008658,1
180,180,Hierarchical point-edge interaction network for point cloud semantic segmentation,"We achieve 3D semantic scene labeling by exploring semantic relation between each point and its contextual neighbors through edges. Besides an encoder-decoder branch for predicting point labels, we construct an edge branch to hierarchically integrate point features and generate edge features. To incorporate point features in the edge branch, we establish a hierarchical graph framework, where the graph is initialized from a coarse layer and gradually enriched along the point decoding process. For each edge in the final graph, we predict a label to indicate the semantic consistency of the two connected points to enhance point prediction. At different layers, edge features are also fed into the corresponding point module to integrate contextual information for message passing enhancement in local regions. The two branches interact with each other and cooperate in segmentation. Decent experimental results on several 3D semantic labeling datasets demonstrate the effectiveness of our work.",60002798,Chinese University of Hong Kong,Shatin,Hong Kong,"['1712', '1707']",21.0,0.017708333333333333,0.4427083333333333,1
181,181,Hyperpixel flow: Semantic correspondence with multi-layer neural features,"Establishing visual correspondences under large intra-class variations requires analyzing images at different levels, from features linked to semantics and context to local patterns, while being invariant to instance-specific details. To tackle these challenges, we represent images by 'hyperpixels' that leverage a small number of relevant features selected among early to late layers of a convolutional neural network. Taking advantage of the condensed features of hyperpixels, we develop an effective real-time matching algorithm based on Hough geometric voting. The proposed method, hyperpixel flow, sets a new state of the art on three standard benchmarks as well as a new dataset, SPair-71k, which contains a significantly larger number of image pairs than existing datasets, with more accurate and richer annotations for in-depth analysis.",60013373,INRIA Institut National de Recherche en Informatique et en Automatique,Le Chesnay,France,"['1712', '1707']",30.25,0.12913419913419913,0.43806637806637805,1
182,182,Predicting 3D human dynamics from video,"Given a video of a person in action, we can easily guess the 3D future motion of the person. In this work, we present perhaps the first approach for predicting a future 3D mesh model sequence of a person from past video input. We do this for periodic motions such as walking and also actions like bowling and squatting seen in sports or workout videos. While there has been a surge of future prediction problems in computer vision, most approaches predict 3D future from 3D past or 2D future from 2D past inputs. In this work, we focus on the problem of predicting 3D future motion from past image sequences, which has a plethora of practical applications in autonomous systems that must operate safely around people from visual inputs. Inspired by the success of autoregressive models in language modeling tasks, we learn an intermediate latent space on which we predict the future. This effectively facilitates autoregressive predictions when the input differs from the output domain. Our approach can be trained on video sequences obtained in-the-wild without 3D ground truth labels. The project website with videos can be found at https://jasonyzhang.com/phd.",60025038,"University of California, Berkeley",Berkeley,United States,"['1712', '1707']",21.11111111111111,0.09469696969696968,0.2791666666666667,1
183,183,Symmetric graph convolutional autoencoder for unsupervised graph representation learning,"We propose a symmetric graph convolutional autoencoder which produces a low-dimensional latent representation from a graph. In contrast to the existing graph autoencoders with asymmetric decoder parts, the proposed autoencoder has a newly designed decoder which builds a completely symmetric autoencoder form. For the reconstruction of node features, the decoder is designed based on Laplacian sharpening as the counterpart of Laplacian smoothing of the encoder, which allows utilizing the graph structure in the whole processes of the proposed autoencoder architecture. In order to prevent the numerical instability of the network caused by the Laplacian sharpening introduction, we further propose a new numerically stable form of the Laplacian sharpening by incorporating the signed graphs. In addition, a new cost function which finds a latent representation and a latent affinity matrix simultaneously is devised to boost the performance of image clustering tasks. The experimental results on clustering, link prediction and visualization tasks strongly support that the proposed model is stable and outperforms various state-of-the-art algorithms.",60120116,Automation and Systems Research Institute,Seoul,South Korea,"['1712', '1707']",27.166666666666668,0.13804713804713806,0.47744107744107744,1
184,184,Predictive analytics in harnessing financial efficacy of banks using camel model,"In India, Cooperative Banking has an idiosyncratic position in the rural credit delivery system. Cooperative Banks are providing timely and easy credit to rural people. The financial efficacy of Cooperative Banks is of immense importance for smooth credit disbursement. In the present study, we have taken 17 District Central Cooperative Banks (DCCBs) of Odisha and attempted to measure their efficacy of finance flow. For this purpose we have used the CAMEL model which is based on five parameters like Capital Adequacy, Asset Quality, Management Quality, Earning Ability and Liquidity. Under each parameter two ratios, are calculated for 10 years and DCCBs are ranked according to their score. Synthesized Index Table is developed by taking the average ranks of each parameter and DCCBs are ranked accordingly.",60079572,Siksha O Anusandhan (Deemed to be University),Bhubaneswar,India,['1706'],17.857142857142858,0.07833333333333334,0.3283333333333333,1
185,185,Feature weighting and boosting for few-shot segmentation,"This paper is about few-shot segmentation of foreground objects in images. We train a CNN on small subsets of training images, each mimicking the few-shot setting. In each subset, one image serves as the query and the other(s) as support image(s) with ground-truth segmentation. The CNN first extracts feature maps from the query and support images. Then, a class feature vector is computed as an average of the support's feature maps over the known foreground. Finally, the target object is segmented in the query image by using a cosine similarity between the class feature vector and the query's feature map. We make two contributions by: (1) Improving discriminativeness of features so their activations are high on the foreground and low elsewhere; and (2) Boosting inference with an ensemble of experts guided with the gradient of loss incurred when segmenting the support images in testing. Our evaluations on the PASCAL-5i and COCO-20i datasets demonstrate that we significantly outperform existing approaches.",60013402,Oregon State University,Corvallis,United States,"['1712', '1707']",19.875,-0.045625,0.6060416666666666,1
186,186,Design of electrical equipment integration system for LNG single-fuel bulk carrier,"This paper mainly designed the electrical equipment integrated system for LNG (Liquefied Natural Gas) single fuel bulk carrier, aiming at providing a solution scheme for realizing real-time, reliable and expandable communication between the ship and the shore. The core communication layer of the system adopts star-structure to communicate with the monitored equipment. According to the actual communication ability of electrical equipment, different communication configurations are made. Data access is accomplished by centralized communication protocol conversion through NX control components, which can solve the problem of communication matching under different communication protocols and transmission rates. In addition, for ship-shore communication, the 4G mobile communication links is configured. Under the special sections without mobile signal coverage, the network communication monitoring and data replenishment functions are designed to ensure the integrity and reliability of data remote transmission.",60103926,Nanchang Institute of Technology,Nanchang,China,['1700'],22.333333333333332,0.07248677248677249,0.391005291005291,1
187,187,Variational few-shot learning,"We propose a variational Bayesian framework for enhancing few-shot learning performance. This idea is motivated by the fact that single point based metric learning approaches are inherently noise-vulnerable and easy-to-be-biased. In a nutshell, stochastic variational inference is invoked to approximate bias-eliminated class specific sample distributions. In the meantime, a classifier-free prediction is attained by leveraging the distribution statistics on novel samples. Extensive experimental results on several benchmarks well demonstrate the effectiveness of our distribution-driven few-shot learning framework over previous point estimates based methods, in terms of superior classification accuracy and robustness.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1707']",18.2,0.020238095238095236,0.3424107142857143,1
188,188,Rescan: Inductive instance segmentation for indoor rgbd scans,"In depth-sensing applications ranging from home robotics to AR/VR, it will be common to acquire 3D scans of interior spaces repeatedly at sparse time intervals (e.g., as part of regular daily use). We propose an algorithm that analyzes these ''rescans'' to infer a temporal model of a scene with semantic instance information. Our algorithm operates inductively by using the temporal model resulting from past observations to infer an instance segmentation of a new scan, which is then used to update the temporal model. The model contains object instance associations across time and thus can be used to track individual objects, even though there are only sparse observations. During experiments with a new benchmark for the new task, our algorithm outperforms alternate approaches based on state-of-the-art networks for semantic instance segmentation.",60003269,Princeton University,Princeton,United States,"['1712', '1707']",26.0,-0.014090909090909098,0.3590559440559441,1
189,189,Route optimization of robot groups in community environment,"The paper studies the path planning and task assignment of robots in the low-efficiency distribution of express delivery in the community. The grid method is used to model the environment and a community is analyzed as an example. In the ant colony optimization (ACO), the heuristic function is reconstructed by the valuation function of the A* algorithm to improve the convergence speed of the ACO. The algorithm has enhanced global search ability in the early stage, and the convergence speed is fast in the later stage with the improvement of pheromone volatilization coefficient, and the experimental parameters simulation analysis is done in MATLAB software. The experimental results show that the improved ACO has faster convergence and higher efficiency than the basic ACO. The rationality of the path planning model and the effectiveness of the optimized ACO are verified.",60022414,Wuhan University of Technology,Wuhan,China,['1700'],23.0,0.09375,0.29062499999999997,1
190,190,Deep graphical feature learning for the feature matching problem,"The feature matching problem is a fundamental problem in various areas of computer vision including image registration, tracking and motion analysis. Rich local representation is a key part of efficient feature matching methods. However, when the local features are limited to the coordinate of key points, it becomes challenging to extract rich local representations. Traditional approaches use pairwise or higher order handcrafted geometric features to get robust matching; this requires solving NP-hard assignment problems. In this paper, we address this problem by proposing a graph neural network model to transform coordinates of feature points into local features. With our local features, the traditional NP-hard assignment problems are replaced with a simple assignment problem which can be solved efficiently. Promising results on both synthetic and real datasets demonstrate the effectiveness of the proposed method.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",19.0,0.10158730158730159,0.461111111111111,1
191,191,Unsupervised graph association for person re-identification,"In this paper, we propose an unsupervised graph association (UGA) framework to learn the underlying viewinvariant representations from the video pedestrian tracklets. The core points of UGA are mining the underlying cross-view associations and reducing the damage of noise associations. To this end, UGA is adopts a two-stage training strategy: (1) intra-camera learning stage and (2) intercamera learning stage. The former learns the intra-camera representation for each camera. While the latter builds a cross-view graph (CVG) to associate different cameras. By doing this, we can learn view-invariant representation for all person. Extensive experiments and ablation studies on seven re-id datasets demonstrate the superiority of the proposed UGA over most state-of-the-art unsupervised and domain adaptation re-id methods.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",16.57142857142857,-0.041666666666666664,0.4055555555555556,1
192,192,A study of mediclaim policyholders in Indore city," Among all the insurance policy, there is a mediclaim policy done for covering illness. The purpose of this research paper is to study about the mediclaim policy holders in Indore city. An empirical study has been conducted in Indore city with 80 respondents to get the required data. The questionnaire result was analysed with chi square test. In the research it was found that age plays an important role in getting information or awareness through internet. This research will help the insurance co. in making marketing strategy.",122507100,St. Paul Institute of Professional Studies,Indore,India,['1706'],12.571428571428571,0.25,0.55,0
193,193,EPIC-fusion: Audio-visual temporal binding for egocentric action recognition,"We focus on multi-modal fusion for egocentric action recognition, and propose a novel architecture for multi-modal temporal-binding, i.e. the combination of modalities within a range of temporal offsets. We train the architecture with three modalities - RGB, Flow and Audio - and combine them with mid-level fusion alongside sparse temporal sampling of fused representations. In contrast with previous works, modalities are fused before temporal aggregation, with shared modality fusion weights over time. Our proposed architecture is trained end-to-end, outperforming individual modalities as well as late-fusion of modalities. We demonstrate the importance of audio in egocentric vision, on per-class basis, for identifying actions as well as interacting objects. Our method achieves state of the art results on both the seen and unseen test sets of the largest egocentric dataset: EPIC-Kitchens, on all metrics using the public leaderboard.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",19.428571428571427,-0.016666666666666663,0.18333333333333335,1
194,194,CompoNet: Learning to generate the unseen by part synthesis and composition,"Data-driven generative modeling has made remarkable progress by leveraging the power of deep neural networks. A reoccurring challenge is how to enable a model to generate a rich variety of samples from the entire target distribution, rather than only from a distribution confined to the training data. In other words, we would like the generative model to go beyond the observed samples and learn to generate ''unseen'', yet still plausible, data. In our work, we present CompoNet, a generative neural network for 2D or 3D shapes that is based on a part-based prior, where the key idea is for the network to synthesize shapes by varying both the shape parts and their compositions. Treating a shape not as an unstructured whole, but as a (re-)composable set of deformable parts, adds a combinatorial dimension to the generative process to enrich the diversity of the output, encouraging the generator to venture more into the ''unseen''. We show that our part-based model generates richer variety of plausible shapes compared with baseline generative models. To this end, we introduce two quantitative metrics to evaluate the diversity of a generative model and assess how well the generated data covers both the training data and unseen data from the same target distribution.",60018491,Simon Fraser University,Burnaby,Canada,"['1712', '1707']",29.428571428571427,0.19285714285714287,0.4946428571428572,1
195,195,Bottleneck potentials in markov random fields,"We consider general discrete Markov Random Fields(MRFs) with additional bottleneck potentials which penalize the maximum (instead of the sum) over local potential value taken by the MRF-assignment. Bottleneck potentials or analogous constructions have been considered in (i) combinatorial optimization (e.g. bottleneck shortest path problem, the minimum bottleneck spanning tree problem, bottleneck function minimization in greedoids), (ii) inverse problems with L-{infty}-norm regularization and (iii) valued constraint satisfaction on the (min,max)-pre-semirings. Bottleneck potentials for general discrete MRFs are a natural generalization of the above direction of modeling work to Maximum-A-Posteriori (MAP) inference in MRFs. To this end we propose MRFs whose objective consists of two parts: Terms that factorize according to (i) (min,+), i.e. potentials as in plain MRFs, and (ii) (min,max), i.e. bottleneck potentials. To solve the ensuing inference problem, we propose high-quality relaxations and efficient algorithms for solving them. We empirically show efficacy of our approach on large scale seismic horizon tracking problems.",60000256,Max Planck Institute for Informatics,Saarbrucken,Germany,"['1712', '1707']",17.0,-0.01818181818181818,0.36233766233766235,1
196,196,PANet: Few-shot image semantic segmentation with prototype alignment,"Despite the great progress made by deep CNNs in image semantic segmentation, they typically require a large number of densely-annotated images for training and are difficult to generalize to unseen object categories. Few-shot segmentation has thus been developed to learn to perform segmentation from only a few annotated examples. In this paper, we tackle the challenging few-shot segmentation problem from a metric learning perspective and present PANet, a novel prototype alignment network to better utilize the information of the support set. Our PANet learns class-specific prototype representations from a few support images within an embedding space and then performs segmentation over the query images through matching each pixel to the learned prototypes. With non-parametric metric learning, PANet offers high-quality prototypes that are representative for each semantic class and meanwhile discriminative for different classes. Moreover, PANet introduces a prototype alignment regularization between support and query. With this, PANet fully exploits knowledge from the support and provides better generalization on few-shot segmentation. Significantly, our model achieves the mIoU score of 48.1% and 55.7% on PASCAL-5i for 1-shot and 5-shot settings respectively, surpassing the state-of-the-art method by 1.8% and 8.6%.",60017161,National University of Singapore,Singapore City,Singapore,"['1712', '1707']",23.375,0.11897759103641459,0.4796218487394957,1
197,197,Learning to jointly generate and separate reflections,"Existing learning-based single image reflection removal methods using paired training data have fundamental limitations about the generalization capability on real-world reflections due to the limited variations in training pairs. In this work, we propose to jointly generate and separate reflections within a weakly-supervised learning framework, aiming to model the reflection image formation more comprehensively with abundant unpaired supervision. By imposing the adversarial losses and combinable mapping mechanism in a multi-task structure, the proposed framework elegantly integrates the two separate stages of reflection generation and separation into a unified model. The gradient constraint is incorporated into the concurrent training process of the multi-task learning as well. In particular, we built up an unpaired reflection dataset with 4,027 images, which is useful for facilitating the weakly-supervised learning of reflection removal model. Extensive experiments on a public benchmark dataset show that our framework performs favorably against state-of-the-art methods and consistently produces visually appealing results.",60014966,Peking University,Beijing,China,"['1712', '1707']",25.166666666666668,0.21240079365079367,0.3887896825396826,1
198,198,Improving adversarial robustness via guided complement entropy,"Adversarial robustness has emerged as an important topic in deep learning as carefully crafted attack samples can significantly disturb the performance of a model. Many recent methods have proposed to improve adversarial robustness by utilizing adversarial training or model distillation, which adds additional procedures to model training. In this paper, we propose a new training paradigm called Guided Complement Entropy (GCE) that is capable of achieving 'adversarial defense for free,' which involves no additional procedures in the process of improving adversarial robustness. In addition to maximizing model probabilities on the ground-truth class like cross-entropy, we neutralize its probabilities on the incorrect classes along with a 'guided' term to balance between these two terms. We show in the experiments that our method achieves better model robustness with even better performance compared to the commonly used cross-entropy training objective. We also show that our method can be used orthogonal to adversarial training across well-known methods with noticeable robustness gain. To the best of our knowledge, our approach is the first one that improves model robustness without compromising performance.",60022847,Industrial Technology Research Institute of Taiwan,Hsinchu,Taiwan,"['1712', '1707']",25.142857142857142,0.25742424242424244,0.5275252525252525,1
199,199,"Image aesthetic assessment based on pairwise comparison - A unified approach to score regression, binary classification, and personalization","We propose a unified approach to three tasks of aesthetic score regression, binary aesthetic classification, and personalized aesthetics. First, we develop a comparator to estimate the ratio of aesthetic scores for two images. Then, we construct a pairwise comparison matrix for multiple reference images and an input image, and predict the aesthetic score of the input via the eigenvalue decomposition of the matrix. By varying the reference images, the proposed algorithm can be used for binary aesthetic classification and personalized aesthetics, as well as generic score regression. Experimental results demonstrate that the proposed unified algorithm provides the state-of-the-art performances in all three tasks of image aesthetics.",60005273,Korea University,Seoul,South Korea,"['1712', '1707']",21.2,0.0875,0.18333333333333335,1
200,200,Learning perspective undistortion of portraits,"Near-range portrait photographs often contain perspective distortion artifacts that bias human perception and challenge both facial recognition and reconstruction techniques. We present the first deep learning based approach to remove such artifacts from unconstrained portraits. In contrast to the previous state-of-the-art approach cite{fried2016perspective}, our method handles even portraits with extreme perspective distortion, as we avoid the inaccurate and error-prone step of first fitting a 3D face model. Instead, we predict a distortion correction flow map that encodes a per-pixel displacement that removes distortion artifacts when applied to the input image. Our method also automatically infers missing facial features, i.e. occluded ears caused by strong perspective distortion, with coherent details. We demonstrate that our approach significantly outperforms the previous state-of-the-art both qualitatively and quantitatively, particularly for portraits with extreme perspective distortion or facial expressions. We further show that our technique benefits a number of fundamental tasks, significantly improving the accuracy of both face recognition and 3D reconstruction and enables a novel camera calibration technique from a single portrait. Moreover, we also build the first perspective portrait database with a large diversity in identities, expression and poses.",60029311,University of Southern California,Los Angeles,United States,"['1712', '1707']",20.555555555555557,0.10248015873015874,0.3976190476190476,1
201,201,Miss detection vs. false alarm: Adversarial learning for small object segmentation in infrared images,"A key challenge of infrared small object segmentation (ISOS) is to balance miss detection (MD) and false alarm (FA). This usually needs ''opposite'' strategies to suppress the two terms, and has not been well resolved in the literature. In this paper, we propose a deep adversarial learning framework to improve this situation. Departing from the tradition of jointly reducing MD and FA via a single objective, we decompose this difficult task into two sub-tasks handled by two models trained adversarially, with each focusing on reducing either MD or FA. Such a new design brings forth at least three advantages. First, as each model focuses on a relatively simpler sub-task, the overall difficulty of ISOS is somehow decreased. Second, the adversarial training of the two models naturally produces a delicate balance of MD and FA, and low rates for both MD and FA could be achieved at Nash equilibrium. Third, this MD-FA detachment gives us more flexibility to develop specific models dedicated to each sub-task. To realize the above design, we propose a conditional Generative Adversarial Network comprising of two generators and one discriminator. Each generator strives for one sub-task, while the discriminator differentiates the three segmentation results from the two generators and the ground truth. Moreover, in order to better serve the sub-tasks, the two generators, based on context aggregation networks, utilzse different size of receptive fields, providing both local and global views of objects for segmentation. As verified on multiple infrared image data sets, our method consistently achieves better segmentation than many state-of-the-art ISOS methods.",60025709,The University of Sydney,Sydney,Australia,"['1712', '1707']",21.333333333333332,0.008279220779220768,0.3445988906926407,1
202,202,Adversarial representation learning for text-to-image matching,"For many computer vision applications such as image captioning, visual question answering, and person search, learning discriminative feature representations at both image and text level is an essential yet challenging problem. Its challenges originate from the large word variance in the text domain as well as the difficulty of accurately measuring the distance between the features of the two modalities. Most prior work focuses on the latter challenge, by introducing loss functions that help the network learn better feature representations but fail to account for the complexity of the textual input. With that in mind, we introduce TIMAM: A Text-Image Modality Adversarial Matching approach that learns modality-invariant feature representations using adversarial and cross-modal matching objectives. In addition, we demonstrate that BERT, a publicly-available language model that extracts word embeddings, can successfully be applied in the text-to-image matching domain. The proposed approach achieves state-of-the-art cross-modal matching performance on four widely-used publicly-available datasets resulting in absolute improvements ranging from 2% to 5% in terms of rank-1 accuracy.",60005837,University of Houston,Houston,United States,"['1712', '1707']",27.5,0.21887755102040818,0.4651360544217687,1
203,203,Video object segmentation using space-time memory networks,"We propose a novel solution for semi-supervised video object segmentation. By the nature of the problem, available cues (e.g. video frame(s) with object masks) become richer with the intermediate predictions. However, the existing methods are unable to fully exploit this rich source of information. We resolve the issue by leveraging memory networks and learn to read relevant information from all available sources. In our framework, the past frames with object masks form an external memory, and the current frame as the query is segmented using the mask information in the memory. Specifically, the query and the memory are densely matched in the feature space, covering all the space-time pixel locations in a feed-forward fashion. Contrast to the previous approaches, the abundant use of the guidance information allows us to better handle the challenges such as appearance changes and occlussions. We validate our method on the latest benchmark sets and achieved the state-of-the-art performance (overall score of 79.4 on Youtube-VOS val set, J of 88.7 and 79.2 on DAVIS 2016/2017 val set respectively) while having a fast runtime (0.16 second/frame on DAVIS 2016 val set).",60016912,Yonsei University,Seoul,South Korea,"['1712', '1707']",20.444444444444443,0.15364583333333337,0.46354166666666663,1
204,204,Learning with unsure data for medical image diagnosis,"In image-based disease prediction, it can be hard to give certain cases a deterministic ''disease/normal' label due to lack of enough information, eg, at its early stage. We call such cases ''unsure' data. Labeling such data as unsure suggests follow-up examinations so as to avoid irreversible medical accident/loss in contrast to incautious prediction. This is a common practice in clinical diagnosis, however, mostly neglected by existing methods. Learning with unsure data also interweaves with two other practical issues: (i) data imbalance issue that may incur model-bias towards the majority class, and (ii) conservative/aggressive strategy consideration, ie, the negative (normal) samples and positive (disease) samples should NOT be treated equally - the former should be detected with a high precision (conservativeness) and the latter should be detected with a high recall (aggression) to avoid missing opportunity for treatment. Mixed with these issues, learning with unsure data becomes particularly challenging. In this paper, we raise ''learning with unsure data' problem and formulate it as an ordinal regression and propose a unified end-to-end learning framework, which also considers the aforementioned two issues: (i) incorporate cost-sensitive parameters to alleviate the data imbalance problem, and (ii) execute the conservative and aggressive strategies by introducing two parameters in the training procedure. The benefits of learning with unsure data and validity of our models are demonstrated on the prediction of Alzheimer's Disease and lung nodules.",60098464,Microsoft Research Asia,Beijing,China,"['1712', '1707']",28.5,-0.033204329004329,0.4355419913419913,1
205,205,"MVP matching: A maximum-value perfect matching for mining hard samples, with application to person re-identification","How to correctly stress hard samples in metric learning is critical for visual recognition tasks, especially in challenging person re-ID applications. Pedestrians across cameras with significant appearance variations are easily confused, which could bias the learned metric and slow down the convergence rate. In this paper, we propose a novel weighted complete bipartite graph based maximum-value perfect (MVP) matching for mining the hard samples from a batch of samples. It can emphasize the hard positive and negative sample pairs respectively, and thus relieve adverse optimization and sample imbalance problems. We then develop a new batch-wise MVP matching based loss objective and combine it in an end-to-end deep metric learning manner. It leads to significant improvements in both convergence rate and recognition performance. Extensive empirical results on five person re-ID benchmark datasets, i.e., Market-1501, CUHK03-Detected, CUHK03-Labeled, Duke-MTMC, and MSMT17, demonstrate the superiority of the proposed method. It can accelerate the convergence rate significantly while achieving state-of-the-art performance. The source code of our method is available at url{https://github.com/IAAI-CVResearchGroup/MVP-metric}.",60121156,Horizon Robotics,Haidian,China,"['1712', '1707']",18.444444444444443,0.08948177426438293,0.5074879227053141,1
206,206,Attribute-driven spontaneous motion in unpaired image translation,"Current image translation methods, albeit effective to produce high-quality results in various applications, still do not consider much geometric transform. We in this paper propose the spontaneous motion estimation module, along with a refinement part, to learn attribute-driven deformation between source and target domains. Extensive experiments and visualization demonstrate effectiveness of these modules. We achieve promising results in unpaired-image translation tasks, and enable interesting applications based on spontaneous motion.",60019616,Harbin Institute of Technology,Harbin,China,"['1712', '1707']",17.25,0.3,0.5592592592592593,1
207,207,Detecting the unexpected via image resynthesis,"Classical semantic segmentation methods, including the recent deep learning ones, assume that all classes observed at test time have been seen during training. In this paper, we tackle the more realistic scenario where unexpected objects of unknown classes can appear at test time. The main trends in this area either leverage the notion of prediction uncertainty to flag the regions with low confidence as unknown, or rely on autoencoders and highlight poorly-decoded regions. Having observed that, in both cases, the detected regions typically do not correspond to unexpected objects, in this paper, we introduce a drastically different strategy: It relies on the intuition that the network will produce spurious labels in regions depicting unexpected objects. Therefore, resynthesizing the image from the resulting semantic map will yield significant appearance differences with respect to the input image. In other words, we translate the problem of detecting unknown classes to one of identifying poorly-resynthesized image regions. We show that this outperforms both uncertainty- and autoencoder-based methods.",60028186,Ecole Polytechnique Fédérale de Lausanne,Lausanne,Switzerland,"['1712', '1707']",23.285714285714285,0.06862745098039215,0.5450980392156862,1
208,208,VrR-VG: Refocusing visually-relevant relationships,"Relationships encode the interactions among individual instances and play a critical role in deep visual scene understanding. Suffering from the high predictability with non-visual information, relationship models tend to fit the statistical bias rather than ''learning' to infer the relationships from images. To encourage further development in visual relationships, we propose a novel method to mine more valuable relationships by automatically pruning visually-irrelevant relationships. We construct a new scene graph dataset named Visually-Relevant Relationships Dataset (VrR-VG) based on Visual Genome. Compared with existing datasets, the performance gap between learnable and statistical method is more significant in VrR-VG, and frequency-based analysis does not work anymore. Moreover, we propose to learn a relationship-aware representation by jointly considering instances, attributes and relationships. By applying the representation-aware feature learned on VrR-VG, the performances of image captioning and visual question answering are systematically improved, which demonstrates the effectiveness of both our dataset and features embedding schema. Both our VrR-VG dataset and representation-aware features will be made publicly available soon.",60018308,Xi'an Jiaotong University,Xi'an,China,"['1712', '1707']",20.5,0.16475757575757574,0.3846363636363636,1
209,209,Semantic adversarial attacks: Parametric transformations that fool deep classifiers,"Deep neural networks have been shown to exhibit an intriguing vulnerability to adversarial input images corrupted with imperceptible perturbations. However, the majority of adversarial attacks assume global, fine-grained control over the image pixel space. In this paper, we consider a different setting: What happens if the adversary could only alter specific attributes of the input image? These would generate inputs that might be perceptibly different, but still natural-looking and enough to fool a classifier. We propose a novel approach to generate such ''semantic'' adversarial examples by optimizing a particular adversarial loss over the range-space of a parametric conditional generative model. We demonstrate implementations of our attacks on binary classifiers trained on face images, and show that such natural-looking semantic adversarial examples exist. We evaluate the effectiveness of our attack on synthetic and real data, and present detailed comparisons with existing attack methods. We supplement our empirical results with theoretical bounds that demonstrate the existence of such parametric adversarial examples.",60004354,Iowa State University,Ames,United States,"['1712', '1707']",22.714285714285715,0.053703703703703705,0.38379629629629625,1
210,210,SplitNet: Sim2Sim and task2task transfer for embodied visual navigation,"We propose SplitNet, a method for decoupling visual perception and policy learning. By incorporating auxiliary tasks and selective learning of portions of the model, we explicitly decompose the learning objectives for visual navigation into perceiving the world and acting on that perception. We show improvements over baseline models on transferring between simulators, an encouraging step towards Sim2Real. Additionally, SplitNet generalizes better to unseen environments from the same simulator and transfers faster and more effectively to novel embodied navigation tasks. Further, given only a small sample from a target domain, SplitNet can match the performance of traditional end-to-end pipelines which receive the entire dataset.",60019647,Georgia Institute of Technology,Atlanta,United States,"['1712', '1707']",20.6,0.1125,0.4333333333333333,1
211,211,U-CAM: Visual explanation using uncertainty based class activation maps,"Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: A) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanation for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.",60021988,Indian Institute of Technology Kanpur,Kanpur,India,"['1712', '1707']",18.375,0.09509803921568627,0.26666666666666666,1
212,212,Toyota smarthome: Real-world activities of daily living,"The performance of deep neural networks is strongly influenced by the quantity and quality of annotated data. Most of the large activity recognition datasets consist of data sourced from the web, which does not reflect challenges that exist in activities of daily living. In this paper, we introduce a large real-world video dataset for activities of daily living: Toyota Smarthome. The dataset consists of 16K RGB+D clips of 31 activity classes, performed by seniors in a smarthome. Unlike previous datasets, videos were fully unscripted. As a result, the dataset poses several challenges: High intra-class variation, high class imbalance, simple and composite activities, and activities with similar motion and variable duration. Activities were annotated with both coarse and fine-grained labels. These characteristics differentiate Toyota Smarthome from other datasets for activity recognition. As recent activity recognition approaches fail to address the challenges posed by Toyota Smarthome, we present a novel activity recognition method with attention mechanism. We propose a pose driven spatio-temporal attention mechanism through 3D ConvNets. We show that our novel method outperforms state-of-the-art methods on benchmark datasets, as well as on the Toyota Smarthome dataset. We release the dataset for research use.",60110693,Université Côte d'Azur,Nice,France,"['1712', '1707']",16.0,0.049457671957671936,0.32884920634920634,1
213,213,Attribute attention for semantic disambiguation in zero-shot learning,"Zero-shot learning (ZSL) aims to accurately recognize unseen objects by learning mapping matrices that bridge the gap between visual information and semantic attributes. Previous works implicitly treat attributes equally in compatibility score while ignoring that they have different importance for discrimination, which leads to severe semantic ambiguity. Considering both low-level visual information and global class-level features that relate to this ambiguity, we propose a practical Latent Feature Guided Attribute Attention (LFGAA) framework to perform object-based attribute attention for semantic disambiguation. By distracting semantic activation in dimensions that cause ambiguity, our method outperforms existing state-of-the-art methods on AwA2, CUB and SUN datasets in both inductive and transductive settings.",60118080,School of Computer and Computing Science,Hangzhou,China,"['1712', '1707']",26.75,0.03333333333333335,0.2357142857142857,1
214,214,Pyramid graph networks with connection attentions for region-based one-shot semantic segmentation,"One-shot image segmentation aims to undertake the segmentation task of a novel class with only one training image available. The difficulty lies in that image segmentation has structured data representations, which yields a many-to-many message passing problem. Previous methods often simplify it to a one-to-many problem by squeezing support data to a global descriptor. However, a mixed global representation drops the data structure and information of individual elements. In this paper, we propose to model structured segmentation data with graphs and apply attentive graph reasoning to propagate label information from support data to query data. The graph attention mechanism could establish the element-to-element correspondence across structured data by learning attention weights between connected graph nodes. To capture correspondence at different semantic levels, we further propose a pyramid-like structure that models different sizes of image regions as graph nodes and undertakes graph reasoning at different levels. Experiments on PASCAL VOC 2012 dataset demonstrate that our proposed network significantly outperforms the baseline method and leads to new state-of-the-art performance on 1-shot and 5-shot segmentation benchmarks.",60073460,China University of Mining and Technology,Xuzhou,China,"['1712', '1707']",21.625,0.08176406926406925,0.4818722943722943,1
215,215,Semantic-transferable weakly-supervised endoscopic lesions segmentation,"Weakly-supervised learning under image-level labels supervision has been widely applied to semantic segmentation of medical lesions regions. However, 1) most existing models rely on effective constraints to explore the internal representation of lesions, which only produces inaccurate and coarse lesions regions; 2) they ignore the strong probabilistic dependencies between target lesions dataset (e.g., enteroscopy images) and well-to-annotated source diseases dataset (e.g., gastroscope images). To better utilize these dependencies, we present a new semantic lesions representation transfer model for weakly-supervised endoscopic lesions segmentation, which can exploit useful knowledge from relevant fully-labeled diseases segmentation task to enhance the performance of target weakly-labeled lesions segmentation task. More specifically, a pseudo label generator is proposed to leverage seed information to generate highly-confident pseudo pixel labels by incorporating class balance and super-pixel spatial prior. It can iteratively include more hard-to-transfer samples from weakly-labeled target dataset into training set. Afterwards, dynamically-searched feature centroids for same class among different datasets are aligned by accumulating previously-learned features. Meanwhile, adversarial learning is also employed in this paper, to narrow the gap between the lesions among different datasets in output space. Finally, we build a new medical endoscopic dataset with 3659 images collected from more than 1100 volunteers. Extensive experiments on our collected dataset and several benchmark datasets validate the effectiveness of our model.",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1707']",23.77777777777778,0.16177156177156174,0.415413752913753,1
216,216,SO-handNet: Self-organizing network for 3D hand pose estimation with semi-supervised learning,"3D hand pose estimation has made significant progress recently, where Convolutional Neural Networks (CNNs) play a critical role. However, most of the existing CNN-based hand pose estimation methods depend much on the training set, while labeling 3D hand pose on training data is laborious and time-consuming. Inspired by the point cloud autoencoder presented in self-organizing network (SO-Net), our proposed SO-HandNet aims at making use of the unannotated data to obtain accurate 3D hand pose estimation in a semi-supervised manner. We exploit hand feature encoder (HFE) to extract multi-level features from hand point cloud and then fuse them to regress 3D hand pose by a hand pose estimator (HPE). We design a hand feature decoder (HFD) to recover the input point cloud from the encoded feature. Since the HFE and the HFD can be trained without 3D hand pose annotation, the proposed method is able to make the best of unannotated data during the training phase. Experiments on four challenging benchmark datasets validate that our proposed SO-HandNet can achieve superior performance for 3D hand pose estimation via semi-supervised learning.",60032083,"University at Buffalo, The State University of New York",Buffalo,United States,"['1712', '1707']",25.428571428571427,0.4175,0.6083333333333334,1
217,217,EM-fusion: Dynamic object-level SLAM with probabilistic data association,"The majority of approaches for acquiring dense 3D environment maps with RGB-D cameras assumes static environments or rejects moving objects as outliers. The representation and tracking of moving objects, however, has significant potential for applications in robotics or augmented reality. In this paper, we propose a novel approach to dynamic SLAM with dense object-level representations. We represent rigid objects in local volumetric signed distance function (SDF) maps, and formulate multi-object tracking as direct alignment of RGB-D images with the SDF representations. Our main novelty is a probabilistic formulation which naturally leads to strategies for data association and occlusion handling. We analyze our approach in experiments and demonstrate that our approach compares favorably with the state-of-the-art methods in terms of robustness and accuracy.",60030569,Max Planck Institute for Intelligent Systems,Tubingen,Germany,"['1712', '1707']",20.333333333333332,0.15520833333333334,0.509375,1
218,218,On the global optima of kernelized adversarial representation learning,"Adversarial representation learning is a promising paradigm for obtaining data representations that are invariant to certain sensitive attributes while retaining the information necessary for predicting target attributes. Existing approaches solve this problem through iterative adversarial minimax optimization and lack theoretical guarantees. In this paper, we first study the ''linear' form of this problem i.e., the setting where all the players are linear functions. We show that the resulting optimization problem is both non-convex and non-differentiable. We obtain an exact closed-form expression for its global optima through spectral learning and provide performance guarantees in terms of analytical bounds on the achievable utility and invariance. We then extend this solution and analysis to non-linear functions through kernel representation. Numerical experiments on UCI, Extended Yale B and CIFAR-100 datasets indicate that, (a) practically, our solution is ideal for ''imparting' provable invariance to any biased pre-trained data representation, and (b) the global optima of the ''kernel' form can provide a comparable trade-off between utility and invariance in comparison to iterative minimax optimization of existing deep neural network based approaches, but with provable guarantees.",60071323,"Eastern Mediterranean University, Famagusta",Famagusta,Cyprus,"['1712', '1707']",25.571428571428573,0.174025974025974,0.4595238095238096,1
219,219,PU-GAN: A point cloud upsampling adversarial network,"Point clouds acquired from range scans are often sparse, noisy, and non-uniform. This paper presents a new point cloud upsampling network called PU-GAN, which is formulated based on a generative adversarial network (GAN), to learn a rich variety of point distributions from the latent space and upsample points over patches on object surfaces. To realize a working GAN network, we construct an up-down-up expansion unit in the generator for upsampling point features with error feedback and self-correction, and formulate a self-attention unit to enhance the feature integration. Further, we design a compound loss with adversarial, uniform and reconstruction terms, to encourage the discriminator to learn more latent patterns and enhance the output point distribution uniformity. Qualitative and quantitative evaluations demonstrate the quality of our results over the state-of-the-arts in terms of distribution uniformity, proximity-to-surface, and 3D reconstruction quality.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1707']",27.6,0.25284090909090906,0.5511363636363636,1
220,220,Task2Vec: Task embedding for meta-learning,"We introduce a method to generate vectorial representations of visual classification tasks which can be used to reason about the nature of those tasks and their relations. Given a dataset with ground-truth labels and a loss function, we process images through a 'probe network' and compute an embedding based on estimates of the Fisher information matrix associated with the probe network parameters. This provides a fixed-dimensional embedding of the task that is independent of details such as the number of classes and requires no understanding of the class label semantics. We demonstrate that this embedding is capable of predicting task similarities that match our intuition about semantic and taxonomic relations between different visual tasks. We demonstrate the practical value of this framework for the meta-task of selecting a pre-trained feature extractor for a novel task. We present a simple meta-learning framework for learning a metric on embeddings that is capable of predicting which feature extractors will perform well on which task. Selecting a feature extractor with task embedding yields performance close to the best available feature extractor, with substantially less computational effort than exhaustively training and evaluating all available models.",60031581,California Institute of Technology,Pasadena,United States,"['1712', '1707']",27.142857142857142,0.1564102564102564,0.27298534798534796,1
221,221,DeepHuman: 3D human reconstruction from a single image,"We propose DeepHuman, an image-guided volume-to-volume translation CNN for 3D human reconstruction from a single RGB image. To reduce the ambiguities associated with the reconstruction of invisible areas, our method leverages a dense semantic representation generated from SMPL model as an additional input. One key feature of our network is that it fuses different scales of image features into the 3D space through volumetric feature transformation, which helps to recover accurate surface geometry. The surface details are further refined through a normal refinement network, which can be concatenated with the volume generation network using our proposed volumetric normal projection layer. We also contribute THuman, a 3D real-world human model dataset containing approximately 7000 models. The network is trained using training data generated from the dataset. Overall, due to the specific design of our network and the diversity in our dataset, our method enables 3D human model estimation given only a single image and outperforms state-of-the-art approaches.",60025278,Tsinghua University,Beijing,China,"['1712', '1707']",22.285714285714285,0.0020089285714285764,0.42886904761904754,1
222,222,TextPlace: Visual place recognition and topological localization through reading scene texts,"Visual place recognition is a fundamental problem for many vision based applications. Sparse feature and deep learning based methods have been successful and dominant over the decade. However, most of them do not explicitly leverage high-level semantic information to deal with challenging scenarios where they may fail. This paper proposes a novel visual place recognition algorithm, termed TextPlace, based on scene texts in the wild. Since scene texts are high-level information invariant to illumination changes and very distinct for different places when considering spatial correlation, it is beneficial for visual place recognition tasks under extreme appearance changes and perceptual aliasing. It also takes spatial-temporal dependence between scene texts into account for topological localization. Extensive experiments show that TextPlace achieves state-of-the-art performance, verifying the effectiveness of using high-level scene texts for robust visual place recognition in urban areas.",60026851,University of Oxford,Oxford,United Kingdom,"['1712', '1707']",19.571428571428573,0.1321875,0.39833333333333326,1
223,223,Photorealistic style transfer via wavelet transforms,"Recent style transfer models have provided promising artistic results. However, given a photograph as a reference style, existing methods are limited by spatial distortions or unrealistic artifacts, which should not happen in real photographs. We introduce a theoretically sound correction to the network architecture that remarkably enhances photorealism and faithfully transfers the style. The key ingredient of our method is wavelet transforms that naturally fits in deep networks. We propose a wavelet corrected transfer based on whitening and coloring transforms (WCT2) that allows features to preserve their structural information and statistical properties of VGG feature space during stylization. This is the first and the only end-to-end model that can stylize a 1024x1024 resolution image in 4.7 seconds, giving a pleasing and photorealistic quality without any post-processing. Last but not least, our model provides a stable video stylization without temporal constraints. Our code, generated images, pre-trained models and supplementary documents are all available at https://github.com/ClovaAI/WCT2.",60121134,NAVER Corporation,Seongnam,South Korea,"['1712', '1707']",19.25,0.13824404761904763,0.5214285714285715,1
224,224,Pointcloud saliency maps,"3D point-cloud recognition with PointNet and its variants has received remarkable progress. A missing ingredient, however, is the ability to automatically evaluate point-wise importance w.r.t.! classification performance, which is usually reflected by a saliency map. A saliency map is an important tool as it allows one to perform further processes on point-cloud data. In this paper, we propose a novel way of characterizing critical points and segments to build point-cloud saliency maps. Our method assigns each point a score reflecting its contribution to the model-recognition loss. The saliency map explicitly explains which points are the key for model recognition. Furthermore, aggregations of highly-scored points indicate important segments/subsets in a point-cloud. Our motivation for constructing a saliency map is by point dropping, which is a non-differentiable operator. To overcome this issue, we approximate point-dropping with a differentiable procedure of shifting points towards the cloud centroid. Consequently, each saliency score can be efficiently measured by the corresponding gradient of the loss w.r.t the point under the spherical coordinates. Extensive evaluations on several state-of-the-art point-cloud recognition models, including PointNet, PointNet++ and DGCNN, demonstrate the veracity and generality of our proposed saliency map. Code for experiments is released on url{https://github.com/tianzheng4/PointCloud-Saliency-Maps}.",60032083,"University at Buffalo, The State University of New York",Buffalo,United States,"['1712', '1707']",16.333333333333336,0.05909090909090909,0.5712121212121212,1
225,225,Airport safety system and procedures as a determinaton of aviation safety and security from acts against the law,"Safety and security flight is one of the objectives of flight management, in order to achieve flight security and safety, an optimal management system for managing airport safety is required. The success of flight safety and security starts at the airport. The airport is the frontline for achieving flight safety and security goals. If airports implement a strict security system, crime against flights will be minimized. Crime prevention programs against aviation and aviation facilities must be implemented optimally in order to achieve flight security and safety. The security will be carried out properly if the security supporting components can be met. The components that need to be met are human resources, software, adequate security equipment. With professional personnel supported by legal umbrella in the form of good regulations and SOP (standard Operating system) and supported by renewable airport equipment will determine the implementation of systems and procedures for airport security that are optimal and professional so that crime against flight can be eliminated which ultimately results in flight can be achieved. Indonesia as part of the International Civil Aviation Organization (ICAO) is demanded in the administration of flight security. One of ICAO's recommendations is the rules on flight security and safety set out in annex 17 Safeguarding International Civil Aviation Agencies Acts of Unlawful Interference at the Cichago convention. That contains procedures for implementing procedures that must be carried out by airport aviation security personnel and about security facilities that must be available at international airports in accordance with CASR (Civil Aviation Safety Regulations) or civil aviation safety regulations that have been legislated as legal products based on the Decree of the Minister of Transportation in the form of a Ministerial Regulation which is an implementing regulation of Law number 1 of 2009 concerning flights.",60069439,Universitas Sebelas Maret,Surakarta,Indonesia,['1700'],26.818181818181817,0.16145833333333334,0.21145833333333333,1
226,226,Exploiting ST-Based representation for high sampling rate dynamic signals,"In this chapter, dynamic wideband signals with high sampling rate are analysed through the discrete Stockwell transform (ST). To this end, a reduced complexity ST-based transform with independent time and frequency resolution is investigated. We call it dual-resolution approach. It results in a new strategy based on a trade-off between the time–frequency resolution and the ST computational time addressing the problem of large amount of samples in wideband signals. Short-time Fourier transform (STFT) representation is also included to discuss the applicability to feature-based methodologies in a Cognitive Radio context. Real modulated signals are generated by a Software-Defined Radio testbed to validate the dual-resolution technique. Just 11–20% of the time necessary to generate the T matrix without dual-resolution is requested and 3–12% of the ST computational time with respect to the conventional ST. While, the number of samples can be till four times larger.",60025153,Università degli Studi di Genova,Genoa,Italy,"['1706', '1705', '1710']",17.875,0.06308802308802311,0.4302140452140452,1
227,227,Local binary patterns of spatial plane and temporal linear for spotting spontaneous expression frames,"Spontaneous expression can reveal people's true emotions as comparing with traditional expression. Spotting spontaneous expression frames in the video is prerequisite for studying its characteristics. This paper proposes the local binary patterns feature extraction algorithm based on spatial plane and temporal line. Firstly, the improved normalized cross-correlation algorithm is used to finely match the eye region and the mouth region respectively. Then, fusing two kinds of features, one is the mean local binary patterns features of linear region which are extracted from the temporal linear, the other is the local binary patterns features of the sector region which are extracted from the spatial plane. Finally, the feature is converted into the frame feature by feature correlation function, and frame feature of the spontaneous expression frame is larger than threshold. The experimental results show that our algorithm performs well on the CAS(ME)2 database. The hitting rate of negative spontaneous expression segments increases by 27% than the ULBP algorithm. Simultaneously, the AUC value of the ROC curve increases by 1% as comparing to the LBP-TOP algorithm.",60013614,Hangzhou Dianzi University,Hangzhou,China,"['1712', '1709', '1707', '1705']",19.333333333333332,0.15439814814814815,0.5164351851851853,1
228,228,Towards an architecture for big data analytics leveraging edge/fog paradigms,"An industry transformation is being boosted by Big Data and Cloud technologies. We present a Big Data architecture, which expands the life cycle of data processing through the Edge, Fog and Cloud computing layers. The proposed architecture takes advantage of the strengths of each: the Cloud layer executes heavy analytical processes, the Fog is responsible for the ingestion and performing aggregations, and the Edge manages devices and actuators. The proposed architecture tackles two main goals, 1) latencies and response times can be reduced by bringing the analytics closer to where the data is generated and 2) the use of computing resources is optimised. In order to conceptualise this architecture, an orchestration module is proposed with the goal of optimising the deployment of analytical workloads across the three layers, by evaluating their computing resources. In addition to this, another module is designed to monitor the performance of such workloads allowing the redistribution of tasks assigned to each node. These modules will be implemented in a real case scenario in the train domain.",60110404,TECNALIA,Donostia-San Sebastian,Spain,"['1712', '1709', '1707', '1705']",24.428571428571427,0.04583333333333334,0.2979166666666666,1
229,229,Process-mining based dynamic software architecture reconstruction,"Dynamic architecture reconstruction approaches aim to reconstruct the run-time architecture of a software system. Process mining is an emerging field combining process analytics and data science techniques. In this paper, we present an approach that creates interactive architecture visualizations without requiring any knowledge of the source code of the system under study. The approach is implemented in the tool AJPOLog. with two case studies, we show that this approach creates reliable results with relatively little effort. Though the studies also show that more research is needed to apply process mining techniques in the field of architecture reconstruction.",60007989,Utrecht University,Utrecht,Netherlands,"['1712', '1709', '1707', '1705']",16.166666666666664,0.078125,0.29166666666666663,1
230,230,Extension of strongin’s global optimization algorithm to a function continuous on a compact interval," Zabotin, Pavel A. ChernyshevskijThe Lipschitz continuous property has been used for a long time to solve the global optimization problem and continues to be used. Here we can mention the work of Piyavskii, Yevtushenko, Strongin, Shubert, Sergeyev, Kvasov and others. Most papers assume a priori knowledge of the Lipschitz constant, but the derivation of this constant is a separate problem. Further still, we must prove that an objective function is really Lipschitz, and it is a complicated problem too. In the case where the Lipschitz continuity is established, Strongin proposed an algorithm for global optimization of a satisfying Lipschitz condition on a compact interval function without any a priori knowledge of the Lipschitz estimate. The algorithm not only finds a global extremum, but it determines the Lipschitz estimate too. It is known that every function that satisfies the Lipchitz condition on a compact convex set is uniformly continuous, but the reverse is not always true. However, there exist models (Arutyunova, Dulliev, Zabotin) whose study requires a minimization of the continuous but definitely not Lipschitz function. One of the algorithms for solving such a problem was proposed by R. J. Vanderbei. In his work he introduced some generalization of the Lipchitz property named ε-Lipchitz and proved that a function defined on a compact convex set is uniformly continuous if and only if it satisfies the ε-Lipchitz condition. The above-mentioned property allowed him to extend Piyavskii’s method. However, Vanderbei assumed that for a given value of ε it is possible to obtain an associate Lipschitz ε-constant, which is a very difficult problem. Thus, there is a need to construct, for a function continuous on a compact convex domain, a global optimization algorithm which works in some way like Strongin’s algorithm, i.e., without any a priori knowledge of the Lipschitz ε-constant. In this paper we propose an extension of Strongin’s global optimization algorithm to a function continuous on a compact interval using the ε-Lipchitz conception, prove its convergence and solve some numerical examples using the software that implements the developed method.",60088527,Kazan National Research Technical University named after A. N. Tupolev -KAI,Kazan,Russian Federation,"['1706', '1703']",19.941176470588236,0.04200000000000001,0.4846666666666667,0
231,231,Certainty Factor Triunity in Medical Diagnostics Tasks,"Abstract: This paper suggests approaches to investigating and solving the problem of three factors that characterize the measure of expert confidence in the occurrence of symptoms in diseases, the timing of the manifestation of symptoms, and the frequency of symptoms in progressive hereditary diseases in five age groups that differ in clinical manifestations (a polyvariant character space). Linguistic scales of fuzzy characteristics (interval age and the occurrence of signs) and certainty factors should contribute to a more subtle and accurate evaluation of diagnostically significant traits and increase the effectiveness of diagnosis at different ages. The measure of confidence is determined with respect to each characteristic used for a given nosological form. In the process of assessing risk factors, specific features of the thinking of experts are considered, that is, intuition, confidence in their knowledge, and reflexivity (regarding emerging hypotheses). Various stages and variants of group expertise with the participation of a cognitive scientist are considered.",60110807,Federal Research Center Informatics and Management of the Russian Academy of Sciences,Moscow,Russian Federation,['1700'],31.0,0.10833333333333334,0.47777777777777786,1
232,232,Gender balance in computer science and engineering in Italian universities,"Multiple studies have shown that gender balance in the fields of Science, Technology, Engineering and Maths - and in particular in ICT - is still far to be achieved. Several initiatives have been recently taken to increase the women participation, but it is difficult, at present, to evaluate their impact and their potential of changing the situation. This paper contributes to the discussion by presenting a descriptive analysis of the gender balance in Computer Science and Computer Engineering in Italian Universities.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1709', '1707', '1705']",27.0,-0.025925925925925925,0.39814814814814814,1
233,233,Q-DFN: Q-learning decisive fusion network for object detection,"Traditional approaches to each image simply depend on detectors of the classification network and the bounding box regression network. These approaches are, although working well, fail to exploit the satisfied accuracy for specific object detection or many methods sacrifice the accuracy for the speed of real-time detection. The reason for the unsatisfied results is that the relationship between the various objects is not effectively considered. In this paper, we propose a decisive fusion network for object detection. After the network extracts the features from the backbone first, the last five layers are treated as the feature pyramid structure. Each layer is responsible for the bounding box by the border regression algorithm, and the Deep Q-Learning (DQN) algorithm is responsible for the classification of the target. The fusion function connects the DQN algorithm with the object detection network, and considers the selection relationship between objects through the DQN algorithm to improve the overall accuracy. Through a lot of experiments, the parameters of DQN are better adjusted. The experiments show our method is better than tradition approaches.",60022422,Ocean University of China,Qingdao,China,"['1712', '1709', '1707', '1705']",19.444444444444443,0.115625,0.45200892857142855,1
234,234,Classification of Text Documents Based on a Probabilistic Topic Model,"Abstract—: An approach to text document classification that utilizes a probabilistic topic model, which is characterized by the fact that its training document set contains objects of only one class, is proposed. This approach makes it possible to identify positive samples (samples resembling the target class) in collections and streams of text documents. This article considers models created for solving the problems of text document classification and trained on samples of a single class, describes their key features. The Positive Example Based Learning-TM classification model is presented and a software prototype that implements it as a basis for classification of text documents is developed. Despite having no information about negative document samples, the model demonstrates a high level of classification accuracy that exceeds the performance of alternative approaches. The superiority of the Positive Example Based Learning-TM model with respect to the classification accuracy criterion when using a small training set is experimentally proven.",60101977,St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences,Saint Petersburg (ex Leningrad),Russian Federation,['1700'],25.5,0.035032467532467526,0.5742207792207793,1
235,235,Assisting women in career change towards software engineering: Experience from Czechitas NGO,"Technological growth affects the way we live, communicate, and work. Over the coming decades, up to 60% of existing jobs might be lost to automation. This creates pressure on the job market, demanding more tech professionals, while creating job insecurity for positions that might be automated. Although tech and computing is an appealing career choice with high salary, job security, working flexibility, space for creativity and career growth, vast majority of women are dropping their interest in tech during adolescence, with very limited recovery in later years, when preventable reasons are stopping them from reconsidering their decision and joining tech. In this paper, we share our experience with a project assisting women in their 20s and 30s in changing career towards tech. The project has been implemented within our education non-profit organization, called Czechitas, which is recognized as the leading platform for addressing gender diversity in tech and software engineering in the Czech Republic.",60029543,Masaryk University,Brno,Czech Republic,"['1712', '1709', '1707', '1705']",25.666666666666668,0.1719294990723562,0.4608163265306123,1
236,236,Advertising video automatic visual effects processing for a novel mobile application,"Today, advertising videos are in a heavy demand on e-commerce platform; however, for most small and micro enterprises, producing an advertising video which could attain a satisfied advertising effect easily at a low cost is a huge challenge due to the lack of the professional knowledge. With the advent of the 5G era, the programmatic advertising video production will be pushed to a new enthusiasm. In the future, the production of advertising video through mobile devices will be a development trend. This paper explores the mobile advertising video generation system, and proposes an automatic video visual effect processing method for a novel mobile application. This method combines intelligent video recognition technology and visual dynamic effect processing, aiming to assist users to generate compelling product advertising videos.",60033100,Nanjing University,Nanjing,China,"['1712', '1709', '1707', '1705']",25.2,0.1440909090909091,0.42141414141414135,1
237,237,Impact of IT an innovation on business education,"The aim of this paper is to provide the knowledge related to the impact of information technology an innovation on business education. This paper will discuss what the necessary skills are needed to be successful in business. In addition, it will also discuss the use of info graphics in order to enhance the knowledge area of its users. The Information Technology (IT) and the Information and Communication Technology (ICT) are integrating and innovating the relationship between the organizations and individuals.",60103612,Jubail University College,Jubail,Saudi Arabia,['1706'],20.0,0.25,0.7833333333333332,1
238,238,Predicting fishing activities based on DeepFM,"With the advent of the era of big data, it is necessary to obtain volume, veracity information on fishing activities. In this paper, we present a new approach to predict fishing activities using DeepFM with historical fishing data of Chinese vessels. This work is an innovative attempt to use deep learning model to find worthy feature interactions in historical fishing data automatically. First, we pre-processed the historical fishing data. Then we used DeepFM to learned low-order and high order feature interactions from pre-processed historical fishing data automatically, and the output of DeepFM was taken as the probability of fishing. Finally, we assessed experimental results by calculating the Area Under Curve (AUC). By comparing with the FM and DNN, DeepFM had achieved the best results, and we founded that high-order feature interactions are more worthy than low-order feature interactions in predicting fishing activities.",60028265,Lanzhou University,Lanzhou,China,"['1712', '1709', '1707', '1705']",20.285714285714285,0.17437001594896331,0.4225199362041467,1
239,239,Gender gap?: A snapshot of a bachelor computer science course at Graz University of Technology,"Although career chances are good, technology, engineering and especially computer science (CS) related studies still do not attract as many female students as other fields. This paper describes a study in the context of an introductory CS course for first semester university students. In this course essential programming concepts are taught and exercised. The first contact with programming is crucial to keep students in the long run. By conducting a survey before and after the course we aim at finding short-term measures to improve the course on organizational level and answer questions about gender equality, such as ""Are female students disadvantaged and thereby negatively affects their grades?"" and ""Is there a difference between female and male students in their perceived CS education prior to university and if, does this have an impact on their academic performance?"". Female and male students' self ratings regarding their programming skills are investigated concerning gender differences and whether they have an impact on their academic performance. Our results show, that neither previous education nor the students' performance differ significantly according to gender. Self ratings differ significantly between genders, but for both genders self ratings do not correlate with academic performance.",60019663,Technische Universitat Graz,Graz,Austria,"['1712', '1709', '1707', '1705']",24.375,0.07233333333333332,0.35700000000000004,1
240,240,Multi-camera vehicle tracking from end-to-end based on spatial-temporal information and visual features,"In large-scale traffic video analysis, continuous tracking of vehicles across cameras overcomes the time and space limitations of a single camera, and is conducive to transportation design and traffic flow optimization. In this work, we propose an end-to-end framework for multi-camera vehicle detection, tracking and reidentification in complex traffic environments with urban multijunctions, which integrates visual features and temporal-spatial information of the trajectories for optimization. Based on detection and tracking of multi-vehicles in a single camera, our method distinguishes and marks the vehicle trajectories from different intersections where they enter and exit. Then, the visual features of the same vehicle keyframes are extracted to match between the cameras of the specific matching link, while taking into account the constraint of the trajectory time. In the end, our algorithm shortens vehicle trajectories' average matching time in two cameras to 2 seconds, and the accuracy is 81.59% in the test scenarios, which greatly improves the efficiency and accuracy of vehicle re-identification.",60000937,Shenzhen University,Shenzhen,China,"['1712', '1709', '1707', '1705']",31.8,0.018831168831168834,0.2571428571428572,1
241,241,Customer perception towards payment bank: A case study of cuttack city,"A new model of banks conceptualized by the Reserve Bank of India (RBI) is popularly known as Payment Bank. As these banks cannot issue loans and credit cards, but both current and savings accounts can be operated by such banks. Money is the life blood of every economy. Now-a-days cash transactions are much simpler due to the popularization of internet, smart phones and other digital technologies. Therefore most of the transactions were cashless and if these practices will continue as it is then in future physical form of currencies will no longer be a king. Privacy, security and convenience are the factors which influence the users while using the facility of payment banks. The last decade has seen tremendous growth in use of internet and mobile phone in India. Increasing use of internet, mobile penetration and government initiative such as Digital India are acting as catalyst which leads to exponential growth in use of digital payment. But still many people are there who were not ready to accept this system of banking as they have a thinking of being cheated. The current paper will help to identify the customer perception towards payment bank.",60011103,Ravenshaw University,Cuttack,India,['1706'],19.3,0.10161822304679446,0.3610441146155432,1
242,242,Single image super-resolution via convolutional sparse coding with one group of filters,"Using the characteristic that image patches can be represented sparsely on a selected over-complete dictionary, the sparse coding based super-resolution (ScSR) method pioneers a new avenue for the SR technology. However, ScSR will result in obvious blockeffect because of the block preprocessing of the image. For this purpose, Zeiler et al. proposed convolutional sparse coding based SR (CSC-SR) method to solve this problem. Because it needs to learn two groups of filters and mapping function between HR and LR feature maps, CSC-SR usually puts forward high demand to storage and relatively large the calculation expense. In this paper, we propose a modified CSC-SR method to single image superresolution. The proposed method only needs to train one group of filers, and explores directly the mapping function by least squares algorithm, which can effectively reduce the workload of model training. Experimental results for different test images show that our model has achieved effective improvement over the previous methods.",60029322,Dalian Maritime University,Dalian,China,"['1712', '1709', '1707', '1705']",19.5,0.07039249639249638,0.4947157287157287,1
243,243,Linear and nonlinear optimization models of multiple covering of a bounded plane domain with circles," Galiev, Alexander V. KhorkovProblems of multiple covering (k-covering) of a bounded set G with equal circles of a given radius are well known. They are thoroughly studied under the assumption that G is a finite set. There are several papers concerned with studying this problem in the case where G is a connected set. In this paper, we study the problem of minimizing the number of circles that form a k-covering, k ≥ 1, provided that G is a bounded convex plane domain. For the above-mentioned problem, we state a 0-1 linear model, a general integer linear model, and a nonlinear model, imposing a constraint on the minimum distance between the centers of covering circles. The latter constraint is due to the fact that in practice one can place at most one device at each point. We establish necessary and sufficient solvability conditions for the linear models and describe one (easily realizable) variant of these conditions in the case where the covered set G is a rectangle. We propose some methods for finding an approximate number of circles of a given radius that provide the desired k-covering of the set G, both with and without constraints on distances between the circles’ centers. We treat the calculated values as approximate upper bounds for the number of circles. We also propose a technique that allows one to get approximate lower bounds for the number of circles that is necessary for providing a k-covering of the set G. In the general linear model, as distinct from the 0-1 linear model, we require no additional constraint. The difference between the upper and lower bounds for the number of circles characterizes the quality (acceptability) of the constructed k-covering. We state a nonlinear mathematical model for the k-covering problem with the above-mentioned constraints imposed on distances between the centers of covering circles. For this model, we propose an algorithm which (in certain cases) allows one to find more exact solutions to covering problems than those calculated from linear models. For implementing the proposed approach, we have developed computer programs and performed numerical experiments. Results of numerical experiments demonstrate the effectiveness of the method.",60088527,Kazan National Research Technical University named after A. N. Tupolev -KAI,Kazan,Russian Federation,"['1706', '1703']",21.058823529411764,0.05533126293995859,0.4034679089026915,0
244,244,Inspection guidelines to identify security design flaws,"Recent trends in the software development practices (Agile, De-vOps, CI) have shortened the development life-cycle causing the need for efficient security-by-design approaches. In this context, software architectures are analyzed for potential vulnerabilities and design flaws. Yet, design flaws are often documented with natural language and require a manual analysis, which is inefficient. Besides low-level vulnerability databases (e.g., CWE, CAPEC) there is little systematized knowledge on security design flaws. The purpose of this work is to present and evaluate a catalog of security design flaws accompanied by inspection guidelines for their detection. To this aim, we conduct empirical studies with master and doctoral students. This paper presents a catalog of 19 inspection guidelines for detecting security design flaws and contributes with an empirical evaluation of the inspection guidelines. We also account for the shortcomings of the inspection guidelines and make suggestions for their improvement with respect to the generalization of guidelines, catalog re-organization, and format of documentation. We record similar precision, recall, and productivity in both empirical studies.",60000990,Chalmers University of Technology,Göteborg,Sweden,"['1712', '1709', '1707', '1705']",18.555555555555557,0.07125,0.36,1
245,245,A link growing method for clustering,"Cluster analysis plays an important role in machine learning. In cluster analysis, there still exist many classical problems, like how to determine the number of clusters and how to find arbitraryshaped clusters. We focus on these problems in this paper. We propose a link growing method by using the fact that the similarity within a cluster is usually high than the similarity in other clusters. The method first constructs multiple links, then merge links into clusters, finally a dataset is divided into multiple clusters. Experiments demonstrate the effectiveness of the proposed algorithm. The proposed algorithm has good performance on nonspherical datasets.",60022281,Beijing University of Technology,Beijing,China,"['1712', '1709', '1707', '1705']",14.428571428571429,0.1885,0.43483333333333335,1
246,246,An ensemble deep active learning method for intent classification,"Intent classification plays a primary and critical role in intelligent dialogue systems. However, faced with the lack of labeled data, the training of robust intent classification model is timeconsuming and costly. Thanks to the powerful pre-trained model and active learning, it's possible to construct an integrated method to fulfill this task efficiently. Therefore, we propose an ensemble deep active learning method, which constructs intent classifier based on BERT and uses an ensemble sampling method to choose informative data for efficient training. Experimental results on both Chinese and English intent classification datasets suggest that the proposed ensemble deep active learning method can achieve state-of-the-art performance with less than half of the training data. In addition, the performance of the proposed method is stable and scalable for both datasets. In general, the proposed method shows substantial advantages in building intent classifier across different datasets.",60088567,Beijing Information Science &amp; Technology University,Beijing,China,"['1712', '1709', '1707', '1705']",20.285714285714285,0.06203703703703705,0.48518518518518516,1
247,247,"1st workshop on systems, architectures, and solutions for industry 4.0 (SASI4)","Industry 4.0 (I4) is the next software revolution from computerized systems to digitalization of industry solutions. This fourth generation of the industrial revolution attempts to automate as much as possible all industry processes and manage an unprecedented amount of data where cyber-physical systems (CPSs) interact with humans to produce software-intensive systems more efficiently. From a software engineering perspective such complex systems must be produced in many cases using continuous software engineering approaches and multiple releases demanding continuous integration and delivery. From the software architecture point of view, flexible and open architectures are required to integrate the diversity of platforms and technology in support of I4 processes and manage the vast amount of data required by complex engineering processes. Consequently, this workshop aims to increase the awareness combining software architecture and complex systems engineering processes to understand how modern systems under the industry 4.0 umbrella must be designed and efficiently built at lower costs.",60072208,"ABB Corporate Research, Heidelberg",Heidelberg,Germany,"['1712', '1709', '1707', '1705']",30.6,0.06428571428571428,0.4571428571428572,1
248,248,Consumer buying behaviour of virgin edible oils – A literature survey and conceptual framework,"With the growing importance of inter disciplinary approaches in management, it was also relevant to study the impact of consumer behaviour towards buying virgin edible oils. In the present study, the author tried to understand the combination of factors influencing the buying behaviour of virgin edible oils. Further the literature review approach as carried out to understand the definite gap that exists in the selected area of research. Also the study added two more variables to the study say, consumer awareness, attitude and the level of satisfaction towards the future buying potential of the edible oils. This would enhance the focus of consumers on buying decision of the edible oils which in turn would help to understand the customer pulse based on the identified relationship between the variables of the study. Vast literature was assessed on all the variables and the research gap was identified paving way for an important objective of studying the impact of factors influencing customer buying behaviour of virgin edible oils.",113098555,RVS Institute of Management Studies and Research,Coimbatore,India,['1706'],27.5,0.13,0.5625,1
249,249,User guided digital artwork colorization,"In this paper, we present a user-guided digital artwork colorization approach. We propose a novel network structure for this task. Our network takes grayscale artworks along with sparse user-specified color points as input and outputs color artworks using a convolutional neural network (CNN). We train our network on ten thousand digital paintings collected from the internet with simulated user inputs. The experiment result shows that our network outperforms other networks in the task of interactive digital artwork colorization and can produce artistic and convincing color artworks.",60108756,Hubei University of Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",17.2,0.08854166666666666,0.296875,1
250,250,Road crack image segmentation using global context unet,"Road crack is one of the common factors that affect traffic safety. Generally, the segmentation of road crack images is performed by professional inspectors or engineers. However, manual segmentation of road crack images is a very time-consuming and labor-intensive task. Therefore, an automatic road crack image segmentation method is required to process the task. In this paper, we present a novel road crack image segmentation approach based on U-net and global context block. The proposed method uses the classical segmentation network U-net as the backbone network and embeds a lightweight global context block in the U-net structure to make the network focus on the global context features information so as to achieve the refined segmentation of road crack images. The proposed method is called global context U-net (GCUnet) and it can effectively model global context information to process the features of random shapes and complex textures exhibited by road cracks. A public road crack dataset is used to test our network and the experimental results show that the proposed method can achieve satisfactory results for road crack image segmentation.",60108756,Hubei University of Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",22.375,-0.0031249999999999976,0.22291666666666668,1
251,251,A neural network go rating model considering winning rate,"The existing rating system, as the foundation of estimating results of competitive sports and games, has problems of insufficient use of competing information and the unilateral considering of competing process modeling. In this paper, the Artificial Intelligence (AI) of go based on reinforcement learning and Monte Carlo Tree Search (MCTS) was used to obtain the winning rate during progress of the matches. Also, the Neural Network Go Rating (NNGR) model considering the winning rate was established on the basis of classical Bradley-Terry model, using Mini-Batch Gradient Descent Method to calculate efficiently. History decay method was adopted to improve the time efficiency when dealing with long-span match data. The experiment results and analysis on actual go matches indicated that NNGR model showed excellent objectivity and stability, and higher prediction accuracy compared with Elo, TrueSkill and Whole-History Rating (WHR) algorithms.",60018308,Xi'an Jiaotong University,Xi'an,China,"['1712', '1709', '1707', '1705']",27.6,0.14375,0.6000000000000001,1
252,252,Towards creation of a reference architecture for trust-based digital ecosystems,"With progressing digitalization and the trend towards autonomous computing, systems tend to form digital ecosystems, where each autonomous system aims at achieving its own goals. Within a highway ecosystem, for example, autonomous vehicles could deploy smart agents in the form of software applications. This would enable cooperative driving and ultimately formation of vehicle platoons that reduce air friction and fuel consumption. In the smart grid domain, software-defined virtual power plants could be established to enable remote and autonomous collaboration of various units, such as smart meters, data concentrators, and distributed energy resources, in order to optimize power generation, demand-side energy and power storage. Effective collaboration within these emerging digital ecosystems strongly relies on the assumption that all components of the ecosystem operate as expected, and a level of trust among them is established based on that. In this paper, we present the idea of trust-based digital ecosystems, built upon the concept of a digital twin of this ecosystem, as a machine readable representation of the system and a representation of goals and trust at runtime. This creates demand for introducing a reference architecture for trust-based digital ecosystems that would capture their main concepts and relationships. By modeling the goals of the actors and systems, a reference architecture can provide a basis for analyzing competitive forces that influence the health of an ecosystem.",60029543,Masaryk University,Brno,Czech Republic,"['1712', '1709', '1707', '1705']",27.75,0.17467532467532465,0.46341991341991345,1
253,253,"Challenges in adoption of new technologies in banking sector – A study with reference to selected private banks, Bengaluru","The main aim of this research was to carry out an analysis on impact of new technologies in private banks refer to consumers Perception. A background study has been carried out to understand the factors that are affecting the new technologies in private banks. A survey was conducted to 225 respondents from 5 private banks ICICI Bank, HDFC Bank, Axis Bank, IndusInd Bank, IDBI Bank. The research results found that respondents have started using new technologies and are satisfied with the services provided by their banks and digital India played an important role in shaping the new era in banking sector and move towards the cashless economy. It was found that most of them told that watch banking is expensive to use and only few banks offer this service to customers.",60109970,M. S. Ramaiah University of Applied Sciences,Bengaluru,India,['1706'],26.2,0.09414141414141412,0.50510101010101,1
254,254,Financial inclusion and gender barriers for rural women,"This paper tries to examine the gendered nature of barriers faced by rural women which intersects financial inclusion worldwide. Although financial inclusion for rural women has been linked with poverty eradication and economic empowerment, the delivery of financial products and services to rural women has been at a disadvantageous position. Some of the barriers women experience in accessing financial resources are embedded in the patriarchal bias of the society. Gender related barriers are those barriers that are specific to women which arise due to discrimination and societal norms. Gender related barriers that inhibit women's ability to access to financial services and block women empowerment should be considered carefully while preparing these programs. A feminist analysis was done to understand the causes of gender related barriers and measures adopted worldwide to devise innovative strategies. Gender-transformative approaches to financial inclusion go beyond focussing on access to financial services to challenging the existing gender inequalities that impede women’s financial inclusion and economic empowerment.",124092518,Barpeta Girls’ College,Barpeta,India,['1706'],22.857142857142858,0.04886363636363636,0.25,1
255,255,PororoGAN: An improved story visualization model on pororo-SV dataset,"Generating a sequence of images from a multi-sentence paragraph is a recently proposed task called Story-Visualization. In this task, how to keep the global consistency across dynamic scenes and characters in the story flow is the distinct difference from other single-image works, which is also a significant challenge. However, the visual quality and semantic relevance of existing results are not satisfying when handling datasets with high semantic complexity, such as Pororo-SV cartoon dataset. To address this issue, we propose a new story visualization model named PororoGAN, which jointly considers story-to-imagesequence, sentence-to-image and word-to-image-patch alignment. In particular, we introduce ASE (aligned sentence encoder) and AWE (attentional word encoder) to improve global and local relevance, respectively. Additionally, we add an image patches discriminator to improve the reality of results. Both quantitative and qualitative studies show that PororoGAN outperforms the state-of-the-art models.",60021427,Communication University of China,Beijing,China,"['1712', '1709', '1707', '1705']",19.857142857142858,0.05086868686868687,0.32630303030303026,1
256,256,"Promoting social inclusion for migrant populations through media, technologies and languages","While the globalized nature of contemporary society can be empowering for many, it may mean the maintenance of social iniquities for others, such as migrant populations. Spain, like many other European countries, has faced a high migration influx in the last decades. As a result, the government has invested in measures orientated toward social inclusion for these populations, including policies for the acquisition of language and culture. To support these efforts, the aim of the present study is twofold: Firstly, to evaluate the design of a cloud-based platform which supports learning authentic language and culture material appearing in media. Secondly, to present the results of a group of 12 trainers teaching language and culture courses through the platform and 63 adult A2-B1 migrants taking the courses offered there. The research examines the main findings of how migrants' profiles may play a role in the effectiveness of online media as a teaching tool.",60017838,Universidad de Extremadura,Badajoz,Spain,['1706'],25.333333333333332,0.1160294117647059,0.30504901960784314,1
257,257,Optimizing energy consumption for cloud computing: A cluster and migration based approach (CMBA),"The increased use of IT technologies and number of IT users have triggered cloud computing resource demand including the need for more data centers. Each data center consumes electricity for its un-interrupted operations and maintenance, therefore responsible for the emissions of carbon dioxide, a potent greenhouse gas causing climate change. Hence, there is a necessity to provide a solution through which energy consumption for cloud data centers can be reduced. As virtual machine located in data center are run under loaded to maintain higher performance but it causes wastage of resources and power. While, task overloading severally reduce the performance of data center. To address this issue, we propose CMBA (Cluster and Migration Based Approach) for cloud resource allocation that maps groups of tasks to customized virtual machine types based on processing, memory and network requirements. Proper placement of workload with specific VMs and dynamic migration concept reduce energy consumption for running physical machine and its respective host or data centers. Taking altogether, intelligent customization of virtual machines by adopting CMBA approach will maintain high efficiency of datacenters with reduced energy consumption.",60010953,Donghua University,Shanghai,China,"['1712', '1709', '1707', '1705']",22.75,0.14066666666666666,0.294968253968254,1
258,258,Effect of financial globalization on developing countries,"Research in the field of globalization has become a dynamic area. This research paper provides the effects of financial globalization for developing economies .It mainly focuses on the analysis about how the developing countries can achieve the benefits and control the risk of financial globalization. This research paper also comes to a conclusion about the rapidly growing, positive support for financial globalization. This article hopes to provide a better perspective to the reader.",124092764,University-Center for Management Studies,Bengaluru,India,['1706'],18.25,0.1277056277056277,0.22077922077922077,1
259,259,Investigating quality requirements from a human perspective in IoT-based software architectures for education,"Internet of Things (IoT)-based software architectures are rapidly growing as a network of connected objects. Because of their ubiquitous nature, educational institutions are looking to incorporate IoT technologies in the teaching and learning activities. However, software architectures conceived to be deployed in the scholar environment can have an intense impact on the students lives, raising a discussion on the social responsibility of those software, and the importance of addressing human values. This paper contributes to the ongoing discussion on the benefits and challenges of incorporating IoT in education while focusing on quality attributes from a social perspective. More precisely, it provides a summary that reports on results of a systematic literature review we conducted on IoT in education. Besides, we also offer a discussion on three domain-related quality requirements in IoT-based software architectures for education, namely, security and scalability from a human point of view, and humanization quality attribute itself.",60073786,Penn State Great Valley,Malvern,United States,"['1712', '1709', '1707', '1705']",25.0,0.17708333333333331,0.36041666666666666,1
260,260,Role of knowledge management processes in improving quality of educational services “applied study of sample views from faculty members in a number of faculties of the University of Thi-qar”,"This study discussed the knowledge management processes of acquisition, storage, transfer and application of knowledge in one of Iraqi universities, University of Thi-Qar, Where token a sample Consisting of (120) Teaching for different levels of (6) faculties, which represents research community, the relationship and impact of these processes on the quality and educational services were analyzed and their dimensions (tangibility, Reliability, Response, guarantee and empathy), Provided by these colleges, The analysis of the data that resulted from the questionnaire, Number of her questions (41) question, showed that there was a correlation and impact between the two variables. The sample was concerned with the documentation of knowledge which is describe by excellence in performance and application of ideas in practice and is concerned with the good appearance and provide good service, despite its lack of knowledge of steps to simplify important methods In the provision of educational services, which, although presented but still need to develop the modernization of the methods used.",60077692,University of Al-Qadisiyah,Al-Qadisiyah,Iraq,['1706'],80.5,0.3833333333333333,0.55,1
261,261,Understanding Public Response to Air Quality Using Tweet Analysis,"Poor air quality is recognized as a major risk factor for human health globally. Critical to addressing this important public-health issue is the effective dissemination of air quality data, information about adverse health effects, and the necessary mitigation measures. However, recent studies have shown that even when public get data on air quality and understand its importance, people do not necessarily take actions to protect their health or exhibit pro-environmental behaviors to address the problem. Most existing studies on public attitude and response to air quality are based on offline studies, with a limited number of survey participants and over a limited number of geographical locations. For a larger survey size and a wider set of locations, we collected Twitter data for a period of nearly 2 years and analyzed these data for three major cities: Paris, London, and New Delhi. We identify the three hashtags in each city that best correlate the frequency of tweets with local air quality. Using tweets with these hashtags, we determined that people’s response to air quality across all three cities was nearly identical when considering relative changes in air pollution. Using machine-learning algorithms, we determined that health concerns dominated public response when air quality degraded, with the strongest increase in concern being in New Delhi, where pollution levels are the highest among the three cities studied. The public call for political solutions when air quality worsens is consistent with similar findings with offline surveys in other cities. We also conducted an unsupervised learning analysis to extract topics from tweets in Delhi and studied their evolution over time and with changing air quality. Our analysis helped extract relevant words or features associated with different air quality–related topics such as air pollution policy and health. Also, the topic modeling analysis revealed niche topics associated with sporadic air quality events, such as fireworks during festivals and the air quality impact on an outdoor sport event. Our approach shows that a tweet-based analysis can enable social scientists to probe and survey public response to events such as air quality in a timely fashion and help policy makers respond appropriately.",60026227,Clarkson University,Potsdam,United States,['1706'],27.076923076923077,0.09765414765414765,0.40188662688662696,1
262,262,Sociological study on the conditions of migrant workers in the garment industry in Ernakulam city post 2018 floods,"Internal migration or movement of people within a country has been historically viewed as a coping strategy for earning a livelihood. There is more than enough evidence of both voluntary and forced migration, which may be the result of pull factors like search for better livelihood options and push factors like natural disasters, a failed monsoon and the consequent famine, Poverty and indebtedness are the most important factors that lead to migration. Workers migrating within a country usually move from less developed regions to more developed ones. Kerala has been one of the most promising destinations for migrants from north and north-east India mainly due to the higher earning potential and lesser harassment by the authorities. The devastating floods of August 2018 led to the complete disruption in the lives of these migrant workers. The present paper is an attempt to look into the conditions of the migrant workers in the garment industry in Ernakulam city after the floods. The resettlement and rehabilitation efforts of the Government post flood scenario and the new schemes that would help them to cope with any future calamities have also been examined in detail.",60114086,M.O.P. Vaishnav College for Women,Chennai,India,['1706'],27.142857142857142,0.059411421911421916,0.41043123543123544,1
263,263,A segment-based trajectory similarity calculation method SDTW,"The analysis based on spatio-temporal data has become a hot topic in the field of machine learning. Urban traffic trajectory clustering is one of the key points of urban traffic data mining, and trajectory similarity calculation is the basis of traffic trajectory clustering. In the light of the weakness of current mainstream similarity calculation method under complex roads that proposed one segmentation-based trajectory similarity calculation method(SDTW). The algorithm fully considers the shape of the trajectory and has good performance. The experimental part uses different similarity algorithms, and combines the hierarchical clustering algorithm to cluster the actual vehicle trajectory, and selects the average contour coefficient and the cluster success rate as the evaluation indicators. The results show that the average contour coefficient of the proposed algorithm is 33.86% and 12.94% higher than that of DTW and SDTW, respectively, and the clustering success rate is also improved to some extent.",60028891,Chang'an University,Xi'an,China,"['1712', '1709', '1707', '1705']",24.666666666666668,0.10000000000000002,0.37941176470588234,1
264,264,Assessing the usability of the Saudi Digital Library from the perspective of Saudi scholarship students,"This study aims to assess the usability of the Saudi Digital Library from the perspective of Saudi scholarship students. To this end, it uses a global tool for measuring the usability of computer application interfaces, namely the Software Usability Measurement Inventory (SUMI). It includes five criteria for measuring usability from the user's perspective: effect, efficiency, learnability, helpfulness and control. In general, the participating Saudi scholarship students were neutral about the level of usability in the Saudi Digital Library interface, there was a good level of satisfaction among them, also, there a positive relationship between the usability criteria of the interface of the Saudi Digital Library and user satisfaction. Gender played a role in the ,statistical differences in the responses of the participants about the usability of the Saudi Digital Library interface based on in these criteria; these differences were in favor of the male sample .There were also statistical differences in the responses of the participants due to differences in Internet skills, these differences were in favor of participants who had Internet skills.",60005880,Al-Imam Muhammad Ibn Saud Islamic University,Riyadh,Saudi Arabia,"['1712', '1709', '1707', '1705']",34.6,0.08522727272727273,0.21204545454545456,1
265,265,Design of new intelligent bedside lamp,"The system mainly uses C language to program, uses light sensor, pyroelectric infrared sensor and other components to collect the relevant data, and switches the collected data information through microprocessor to meet the user's intelligent control of the light demand in different scenes. The system has a variety of modes for users to choose from. During the day according to the light intensity automatically adjust the brightness of the light, night automatic induction of human activity to turn on the light.",114496057,Linyi University,Linyi,China,"['1712', '1709', '1707', '1705']",27.0,0.2946969696969697,0.6098484848484849,1
266,266,Research on the current status of sparse neural network acceleration processing technology in deep learning,"With the development of neural network, the demand of storage and memory bandwidth is increasing rapidly. At the same time, most of the data in the neural network can be reduced and compressed. This paper analyzes various techniques of neural network acceleration, compares the advantages and disadvantages of these techniques, and looks forward to some applicable methods of sparse neural network acceleration.",116198185,Officers College of PAP,Chengdu,China,"['1712', '1709', '1707', '1705']",20.666666666666668,0.16666666666666666,0.375,1
267,267,Isotropic multidimensional catalytic branching random walk with regularly varying tails," BulinskayaThe study completes a series of the author’s works devoted to the spread of particles population in supercritical catalytic branching random walk (CBRW) on a multidimensional lattice. The CBRW model describes the evolution of a system of particles combining their random movement with branching (reproduction and death) which only occurs at fixed points of the lattice. The set of such catalytic points is assumed to be finite and arbitrary. In the supercritical regime the size of population, initiated by a parent particle, increases exponentially with positive probability. The rate of the spread depends essentially on the distribution tails of the random walk jump. If the jump distribution has “light tails”, the “population front”, formed by the particles most distant from the origin, moves linearly in time and the limiting shape of the front is a convex surface. When the random walk jump has independent coordinates with a semiexponential distribution, the population spreads with a power rate in time and the limiting shape of the front is a star-shape nonconvex surface. So far, for regularly varying tails (“heavy” tails), we have considered the problem of scaled front propagation assuming independence of components of the random walk jump. Now, without this hypothesis, we examine an “isotropic” case, when the rate of decay of the jumps distribution in different directions is given by the same regularly varying function. We specify the probability that, for time going to infinity, the limiting random set formed by appropriately scaled positions of population particles belongs to a set B containing the origin with its neighborhood, in Rd. In contrast to the previous results, the random cloud of particles with normalized positions in the time limit will not concentrate on coordinate axes with probability one.",60002049,Novosibirsk State University,Novosibirsk,Russian Federation,"['1706', '1703']",26.181818181818183,-0.07843822843822844,0.46022951407566787,0
268,268,Construction and application of big data analysis platform for enterprise,"A data revolution has been leading by big data, which have the extremely profound influence on the economic, social development and public life. This paper introduces the meaning of big data, and discusses the innovation and opportunity of enterprise under the perspective of big data. According to the information architecture, this paper supplies the basic construction of enterprise big data analysis platform, and suggests the strategy of application, which have certain realistic directive significance.",60108759,Yunnan University of Finance and Economics,Kunming,China,"['1712', '1709', '1707', '1705']",24.666666666666668,0.06341991341991342,0.25119047619047624,1
269,269,Residual mask based on mobileNet-V2 for driver's dangerous behavior recognition,"We introduce a new residual mask into the inverted residual structure in MobileNet-V2, which significantly improved the performance of the original network, with only a minimal number of parameters added. We train our networks on a larger public dataset to detect distract behaviors of a driver. Experiments show that MobileNet-v2 with the proposed residual mask converges faster and achieves better accuracy than the original network.",60108756,Hubei University of Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",21.666666666666668,0.1845959595959596,0.6106902356902357,1
270,270,National cultures and gender balance in ICT: A preliminary study,"In this paper, authors study what factors explain the scanty presence of women both in the studies and in the industry of the Information and Communication Technologies (ICT) sector. For this, we analyze three socioeconomic variables (Unemployment, GDP per Capita and Gender Equality Index) and the six cultural dimensions by Hofstede. Both the data of the socioeconomic variables and the percentages of women students and workers in the ICT sector are extracted from Eurostat. The data of the different cultural dimensions for each country analyzed is obtained through Hofstede insights. All of the countries belonging to the European Union have been analyzed with the exception of Cyprus (N = 27). The statistical analyses performed is based on bivariate correlations and simple and multiple regression analysis. The results obtained report that none of the selected socioeconomic variables (Unemployment, GDP per Capita and Gender Equality Index) is determinant to explain the scanty presence of women in the studies and in the ICT industry. Likewise, the cultural dimensions do not conclusively explain the scanty presence of women in the studies and in the industry sector, with the exception of the dimension of Masculinity vs. femininity. According to the results obtained, the most masculine countries, that is, more oriented towards achievement, competitiveness and material rewards, show a lower presence of women in the ICT industry. Some explanations are proposed to understand these results.",60101843,HØgskolen i Østfold,Halden,Norway,"['1712', '1709', '1707', '1705']",20.818181818181817,0.13999999999999999,0.25571428571428567,1
271,271,Production and productivity of natural rubber: A study on growth-trends of rubber plantation in Tripura,"Production of natural rubber plays a most important role in the economic development of Tripura. The state is the second-largest contributor to the total production of natural rubber in India. Over the last two decades, there is a shift in cropping pattern towards the production of natural rubber in the state from food crops and from other commercial crops. The natural rubber is the second-largest crop in Tripura after rice and area under natural rubber has registered a phenomenal increase during this period. The rubber growers of Tripura suffer from problems like low productivity, poor quality of processing and weak marketing system. The study examines the present status of natural rubber in Tripura in respect of growing trend in the area, production and productivity. The result shows that increasing growth trend of both expansions of area and production of rubber. The elasticity of production of rubber w.r.t. the matured area of rubber plantation is 1.18, that means for a 1 % increase in matured area, there is a 1.18% increase in production of rubber i.e. it is elastic in nature. There is no statistically significant mean difference of productivity between Kerala and India but mean productivity of Tripura is lower than both at all India level as well as state level.",60018003,Assam University,Silchar,India,['1706'],19.181818181818183,0.05000000000000001,0.45555555555555555,1
272,272,E-DAM: Encoder-decoder with attention mechanism for city-scale taxi trajectory prediction,"Taxi trajectory prediction plays an important role in perceiving urban traffic conditions and analyzing taxi passengers' travel behaviors. In this paper, an urban taxi trajectory prediction model is proposed based on attention mechanism and Long-short Term Memory (LSTM). In this model, road networks is partitioned into grids, and the road segment with the grid which the road segment lies in is represented with embedding vector. Encoder-decoder framework is adopted, and both the encoder and decoder are implemented with LSTM, in which encoder is used to turn the taxi trajectory into coding vector and decoder is employed to transform the coding vector back into taxi trajectory. Furthermore, in order to improve the performance of the trajectory prediction model, attention mechanism is introduced to put the attention on the combination among road segments during prediction. In the experiment, the proposed model was fully verified using Xi'an taxi GPS data. The result shows that the model can effectively predict the city-scale taxi trajectory, and its prediction performance is better than that of the traditional time series prediction models and the existing deep network models.",60028891,Chang'an University,Xi'an,China,"['1712', '1709', '1707', '1705']",25.857142857142858,0.1875,0.43124999999999997,1
273,273,A study of ciphertext fuzzy retrieval based on information matrix,"To the ciphertext retrieval and the security of ciphertext database, we propose a ciphertext fuzzy retrieval method based on the information matrix in this paper. On the basis of the Bloom Filter, we introduce the index of the information matrix and the digital disturbance in the process of index generation, after which we performe the string conversion encryption. It not only supports the fuzzy search function of strings, but resists similarity attacks as well. With the DFR method during ciphertext retrieval, the first stage of filtering is completed by index matching, and then the exact retrieval is performed. Experiments and safety analysis show that the scheme has more advantages in efficiency and safety.",60022414,Wuhan University of Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",22.6,0.2,0.41666666666666663,1
274,274,Networked Influence: An Introduction,"We are witnessing a changing social media environment with new actors, new influencers, and new challenges. Considering the changes on social media platforms, the rise of bots, and the increased participation of state actors, this thematic collection addresses the methodological, topical, and ethical issues of networked influence. The Facebook-Cambridge Analytica scandal opened a new chapter to analyze what “influence” means in our current, complicated social media age. As discussed in the five papers stemming from the 2018 International Conference on Social Media & Society, this special issue introduces a wide array of interdisciplinary topics and approaches that highlight the rapid changes in social media environments, use, and users—with a focus on networked influence; by doing so, we attempt to answer some of the key research questions in this area, such as (1) how to identify and measure influence (broadly defined), (2) how to track propaganda campaigns, (3) how to effectively disseminate information and measure the public’s response to these information campaigns, (4) how do bots influence opinion trends on social media, and, finally, (5) how does the public frame privacy in a social media age?",60030838,Ryerson University,Toronto,Canada,['1706'],46.25,0.04809002725669393,0.3389670514670514,1
275,275,Time Series Anomaly Searching Based on DBSCAN Ensembles,"Abstract—: This article suggests a technique for building an ensemble based on the DBSCAN algorithm. This technique uses the internal structure of a time series for adaptively selecting input parameters. When used in experiments, it shows a narrower variance and higher levels of anomaly detection using real and synthetic data compared with a number of popular approaches.",60000308,Moscow Institute of Physics and Technology,Moscow,Russian Federation,['1700'],19.0,0.2625,0.42500000000000004,1
276,276,An analysis of application of key financial ratios for human resources valuation in organizations,"Knowledge workers are now most crucial resources for modern business organizations which keep all other assets men, money, machine and materials operative. However, with growing emergence of knowledge economy, the traditional valuation methods has been put into question due to the non-inclusion of Human capital as a major part of firm’s total value in balance sheet. The value of Human Resources in an organization should be measured for sustainable growth of the organization since it plays the role of motivational tool, efficiency measure yardstick and cost clarification. Human Resource Accounting (HRA) measures and reports the value of employees in B/S which helps management take strategic decisions related to human resources in order to enhance efficiency and productivity. Unlike other category of assets, valuation of Human Assets seems to be complex. One shortcoming is availability of good valuation model since all the models developed till now suffer from limitations in one form or other. This paper tries to suggest a comprehensive, easy to use and relatively limitation free valuation ratio model termed Intellectual Capital Value (ICV), which is modification of existing ratio based models available. For this, all the financial ratios useful for human resources valuation are analyzed first and then the new model termed Intellectual Capital Valuation (ICV) prescribed.",60094571,Lovely Professional University,Phagwara,India,['1706'],26.125,0.0931936553030303,0.37566287878787885,1
277,277,A blending model combined DNN and LightGBM for forecasting the sales of airline tickets,"The main goal of this paper is to forecast the sales of airline tickets in time series affected by many factors including different flights, date features and short, middle, long-term historical sales information. The Deep Neural Network (DNN) model and Light Gradient Boosting Machine (LightGBM) model are combined as a Blending model to forecast the sales of airline tickets in future. Simulation results demonstrate the Blending model is better than DNN and LightGBM evaluated by performance metrics including Mean absolute error (MAE) and Mean squared error (MSE).",60027363,University of Chinese Academy of Sciences,Beijing,China,"['1712', '1709', '1707', '1705']",29.0,0.08782051282051281,0.441025641025641,1
278,278,On a class of distributed storage systems with prioritized data sources,"The rate regions and sufficiency of simple linear codes for a class of distributed storage systems with prioritized data sources are investigated in this paper. The exact repair problem is considered. Different from conventional setups, the scenario considered in this paper has prioritized data sources, where the hot data has higher priority than cold data in the decoding process. It is assumed that a user demanding cold data demands hot data as well. Instead of using same capacity for all storage nodes, the rate regions of interest are all feasible different storage sizes versus different tuples of source entropies, with assumption of sufficient large repair bandwidth. Both symmetric and asymmetric repairs are discussed in the paper. Linear network codes over some finite field are said to be sufficient for such a distributed storage system if and only if for every point in the rate region, there exists a code over that finite field to achieve it. As a multi-source multi-sink network coding problem, the rate regions are obtained from computer-aided approaches via bounding the region of entropic vectors. Experimental results on the rate regions of hundreds of non-isomorphic distributed storage systems are presented for demonstration. In addition, it is shown that binary linear codes suffice for most of them.",60021182,Sun Yat-Sen University,Guangzhou,China,"['1712', '1709', '1707', '1705']",20.9,0.027731092436974795,0.5834033613445379,1
279,279,A semantic matching model based on optimal selection mechanism,"Optimal features selection is essential for sentence similarity recognition. In this paper, a semantic matching model based on optimal selection mechanism is designed. Compared with other models that without using an optimal feature selection mechanism, the model uses optimal features that are closest to the original semantics to match, resulting in higher matching. This paper proposes an improved semantic information selection mechanism. This mechanism selects a candidate feature that is as close as possible to the semantics of the original text by calculating the probability of distribution of semantic information in the sentence. Furthermore, a new attention focus mechanism is designed, which iteratively updates the information weight to obtain another candidate feature that may affect the matching accuracy. Then, an optimal feature selection algorithm is designed by using the context vector and two candidate features. The coefficients are selected, and the optimal features are further selected from the candidate features for semantic matching. The experimental results show that the accuracy of sentence matching is greatly improved on Quora benchmark and a self-defined Chinese dataset, this indicates that the proposed model outperforms existing matching models.",60008919,Guilin University of Electronic Technology,Guilin,China,"['1712', '1709', '1707', '1705']",20.444444444444443,0.1737603305785124,0.5254132231404959,1
280,280,Synthesis of datasets with specific characteristics for the clustering problem,"In this paper, we propose a method for synthesis of datasets with specific characteristics for the clustering task. Namely, we propose an algorithm, which can generate a clustering dataset given its meta-feature description. The method we propose is based on an evolutionary algorithm with crossover and mutation operators that are capable to improve candidate datasets in a natural way. We experimentally compared this method with two other approaches for dataset synthesis. We used meta-feature vectors of 247 real-world datasets as inputs. The proposed method outperformed existing ones with respect to Mahalanobis distance between target meta-feature vectors and characteristics of generated datasets.",60072485,"Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO",Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",16.833333333333336,0.05500000000000001,0.34,1
281,281,Risk assessment and quantification of wealthsurance equity growth fund of IdBI federal life insurance,"The objective of risk management is not to prohibit or prevent risk taking activity, but to ensure that the risks are consciously taken with full knowledge, clear purpose and thorough understanding so that it can be measured and mitigated. It also prevents an institution from suffering unacceptable loss causing it to fail or materially damage its competitive position. Balancing risk and return is not an easy task as risk is subjective and not quantifiable whereas return is objective and measurable. This paper includes both qualitative and quantitative research. The former uses a survey, face-to-face discussions and telephonic interviews on study sample which helped to decipher the demographics and the financial needs of the clientele. The latter uses empirical data sources to gauge the risks associated with a unit-linked insurance plan (ULIP), wealthsurance equity growth fund of IDBI federal life insurance based on risk parameters. A regression analysis is performed on the 5 year monthly historical data of portfolio returns of wealthsurance equity growth fund of IDBI federal life insurance and market returns. The findings suggest that the portfolio returns are almost independent of market returns thereby involving a high amount of risk for the fund managers to take to provide better returns. To conclude, if insurance industry has to do well in India, it has to reconfigure and change the way it has done business over the last 20years.",60033308,Indian Institute of Management Ahmedabad,Ahmedabad,India,['1706'],25.444444444444443,0.07770833333333332,0.2561458333333333,1
282,282,Overset grids approach for topography modeling in elastic-wave modeling using the grid-characteristic method," Khokhlov, Vladislav O. Stetsyuk, Ivan A. MitskovetsWhile modeling seismic wave propagation, it is important to take into account nontrivial topography, as this topography causes multiple complex phenomena, such as diffraction at rough surfaces, complex propagation of Rayleigh waves, and side effects caused by wave interference. The primary goal of this research is to construct a method that implements the free surface on topography, utilizing an overset curved grid for characterization, while keeping the main grid structured rectangular. For a combination of the regular and curve-linear grid, the workability of the grid characteristics method using overset grids (also known as the Chimera grid approach) is analyzed. One of the benefits of this approach is computational complexity reduction, caused by the fact that simulation in a regular, homogeneous physical area using a sparse regular rectangle grid is simpler. The simplification of the mesh building mechanism (one grid is regular, and the other can be automatically built using surface data) is a side effect. Despite its simplicity, the method we propose allows us to increase the digitalization of fractured regions and minimize the Courant number. This paper contains various comparisons of modeling results produced by the proposed method-based solver, and results produced by the well-known solver specfem2d, as well as previous modeling results for the same problems. The drawback of the method is that an interpolation error can worsen an overall model accuracy and reduce the computational schema order. Some countermeasures against it are described. For this paper, only two-dimensional models are analyzed. However, the method we propose can be applied to the three-dimensional problems with minimal adaptation required.",60000308,Moscow Institute of Physics and Technology,Moscow,Russian Federation,"['1706', '1703']",20.53846153846154,0.00795454545454546,0.34775224775224767,0
283,283,Robust feature detection method in high-density structured light system,"How to achieve high coding density with a small coding window by using a few coding elements is an interesting and challenging topic in the research domain of structured light techniques (SLT). This paper designed a high-density coding pattern in SLT and a corresponding subpixel feature detection algorithm was proposed. The pattern primitives were designed as checkerboard blocks with a simple embedded geometrical shape - L. Two different types of features are involved to guarantee high coding density. One is checkerboard grid points, which were taken as the main features (MFs) and the other is L shape feature points, which were taken as the auxiliary features (AFs). Specially-designed templates were utilized to locate MFs and a robust feature detecting method based on K-means clustering and Shi-Tomasi algorithm were utilized to locate the AFs accurately. With both MFs and AFs, the density of reconstructed point clouds can be increased by threefold.",60102083,Shenzhen Institute of Advanced Technology,Shenzhen,China,"['1712', '1709', '1707', '1705']",21.428571428571427,0.1426388888888889,0.5065674603174604,1
284,284,A secure transmission scheme of sensitive power information in ubiquitous power IoT,"As one of the national key infrastructures, the ubiquitous power Internet of Things (IoT) provides a convenient method for largescale power information collection. The widespread transmission of massive power information using data mining techniques for large amounts of data can yield valuable information. Therefore, hacker attacks are endless, posing a threat to the security of the state, society, collectives and individuals. In this paper, we propose a secure transmission scheme of power information, named ""SSD"" (Split & Signature & Disturbing). In the scheme, after the data is split, it will be anonymized and selected for different paths to be transferred to the destination node. After recombination, the data will be restored. The SSD ensures the indistinguishability and security of the sensitive data by data splitting and disturbing method, and protects the anonymity of individual identities by group signature. The experimental results show that the individual prediction/actual data similarity approaches 0%, and the similarity ratio of the category data (three types in the experiment) is 37.32%, which can be judged to be basically non-correlated.",60018273,University of Science and Technology Beijing,Beijing,China,"['1712', '1709', '1707', '1705']",21.625,-0.025892857142857145,0.6732142857142858,1
285,285,A Multi-Criteria Decision-Making Procedure with an Inherited Set of Starting Points of Local Optimization of the Scalarizing Functions,"Abstract—This paper proposes a new interactive iterative procedure of searching for a preferred solution of a complicated non-linear multi-criteria optimization problem, in which global optimization of the scalarizing functions of criteria is too difficult because of numerous local extrema of the function and other reasons. In the suggested procedure, instead of global optimization of the scalarizing function of criteria, a large number of local optimization problems are solved on each iteration, while the set of starting points of local optimization processes is generated in a small neighborhood of the decision inherited from the previous iteration and the type of the scalarizing function of varies from iteration to iteration. The proposed procedure, named the Inherited Decisions Method, was applied for multi-criteria selection of rules for controlling the Angara cascade of reservoirs, while the rules are described by hundreds of parameters and the problem is characterized by more than two dozen decision criteria.",60021331,Russian Academy of Sciences,Moscow,Russian Federation,['1700'],50.333333333333336,-0.04606782106782107,0.32831890331890334,1
286,286,1st international workshop on software architectures and human values (SAHVA),"Sustainable software systems require an in-depth understanding about the role that software systems play in our society at a scale and along time frames that are often difficult to grasp and envisage. We argue that a values 'first' software engineering (SE) perspective can offer new insights not only about the human and social aspects that shape SE decision-making processes, but also the potential uses, misuses, and vulnerabilities of complex socio-technical systems afforded by high-level design decisions. While the area of values-based SE has explored means for identifying and making sense of values in the analysis of software production, more effort is required to investigate how values are ultimately instantiated in the architectural structuring of software systems, and the long-term implications of such design decisions. This workshop provides a unique forum where students, researchers, and practitioners working on requirements engineering, software processes, societal aspects of SE, and software sustainability can come together to advance the field of value-based software architectures.",60008088,Universidade de Sao Paulo - USP,Sao Paulo,Brazil,"['1712', '1709', '1707', '1705']",39.75,0.041224747474747477,0.6128787878787879,1
287,287,An improved model of multi-attention lstm for multimodal sentiment analysis,"Multimodal sentiment analysis is the task of detecting emotions in videos using multimodal information such as text, visual and audio. One difficulty that is often faced is the complexity associated with different modes in the fusion of feature layers. In this paper, we present a novel feature-level fusion method for analyzing emotions called Multi-attention LSTM (MALM). The proposed approach uses LSTM to capture context information of contexts in the same video. At the same time, we use the attention mechanism before and after multimodal information fusion in order to focus attention on relatively important sequences and modalities. We evaluate our proposed approach on two multimodal sentiment analysis benchmark datasets and compare to various proposed approaches on the same datasets. Evaluation results show approximately 5-10% performance improvement over the state-of-the-art models for the benchmark datasets.",122703056,Tiangong University,Tianjin,China,"['1712', '1709', '1707', '1705']",19.142857142857142,0.0,0.35750000000000004,1
288,288,Stochastic hybrid systems meet software components for well-founded cyber-physical systems software architectures,"Cyber-physical control systems (CPCS) are notoriously difficult to specify, implement, test, validate and verify. In this paper, we propose to integrate hybrid systems, and their declensions as hybrid automata and DEVS simulation models, within a full-fledged and well-founded software component model tailored for CPCS. The key concept is to attach to components modular, composable and reusable behavioural and simulation models. The goal is to seamlessly support the software development process, from model-in-the-loop initial validation, until deployment time actual system verification. The resulting comprehensive modeling and software implementation tool aims at fully supporting the different phases of the software life cycle to provide more reliable, robust, reusable and adaptable CPCS using less resources.",60001422,Sorbonne Universite,Paris,France,"['1712', '1709', '1707', '1705']",22.4,0.07833333333333334,0.45166666666666666,1
289,289,Application of mathematical fracture models to simulation of exploration seismology problems by the grid-characteristic method," Muratov, Igor B. PetrovIn real problems of exploration seismology we deal with a heterogeneity of the nature of elastic waves interaction with the surface of a fracture by the propagation through it. The fracture is a complex heterogeneous structure. In some locations the surfaces of fractures are placed some distance apart and are separated by filling fluid or emptiness, in some places we can observe the gluing of surfaces, when under the action of pressure forces the fracture surfaces are closely adjoined to each other. In addition, fractures can be classified by the nature of saturation: fluid or gas. Obviously, for such a large variety in the structure of fractures, one cannot use only one model that satisfies all cases. This article is concerned with description of developed mathematical fracture models which can be used for numerical solution of exploration seismology problems using the grid-characteristic method on unstructured triangular (in 2D-case) and tetrahedral (in 3D-case) meshes. The basis of the developed models is the concept of an infinitely thin fracture, whose aperture does not influence the wave processes in the fracture area. These fractures are represented by bound areas and contact boundaries with different conditions on contact and boundary surfaces. Such an approach significantly reduces the consumption of computer resources since there is no need to define the mesh inside the fracture. On the other side, it allows the fractures to be given discretely in the integration domain, therefore, one can observe qualitatively new effects, such as formation of diffractive waves and multiphase wave front due to multiple reflections between the surfaces of neighbor fractures, which cannot be observed by using effective fracture models actively used in computational seismology. The computational modeling of seismic waves propagation through layers of mesofractures was produced using developed fracture models. The results were compared with the results of physical modeling in problems in the same statements.",60000308,Moscow Institute of Physics and Technology,Moscow,Russian Federation,"['1706', '1703']",24.076923076923077,0.02656725990059323,0.40373977873977873,0
290,290,Software architecture knowledge sharing with the architecture knowledge base (AKB),"The Software Architecture Knowledge Base (AKB) is a web-based application for architecture knowledge sharing. It uses compact architecture knowledge descriptions, which we call architecture profiles, as building blocks for establishing a community-driven software architecture knowledge base. The tool facilitates documentation, sharing and reuse of architectural knowledge both within and across different software projects. We have used it in different student projects and are currently evaluating it in an industrial context.",60021931,Johannes Kepler Universitat Linz,Linz,Austria,"['1712', '1709', '1707', '1705']",17.5,-0.32,0.72,1
291,291,The applicability of palladio for assessing the quality of cloud-based microservice architectures,"When adopting microservices, software architects have to make several design decisions which impact the quality of the application in terms of scalability, elasticity and cost-efficiency. A prominent model-driven architectural simulator that aids software architects in analysing and predicting the quality of their architecture is Palladio. There is active work on extending Palladio to support new needs, however, there is lack of evidence for its applicability in the context of microservice architectures. Therefore, we conduct a case study at a partner company where we apply Palladio to analyse the performance as well as to assess scalability, elasticity and cost-efficiency aspects of a cloud-based microservice application. In this work, we highlight some of the results which show that Palladio is able to predict the application performance with a sufficient accuracy. However, when assessing scalability, elasticity and cost-efficiency the applicability of Palladio comes with several workarounds and not automated for all the chosen scenarios.",60015815,Universität Stuttgart,Stuttgart,Germany,"['1712', '1709', '1707', '1705']",25.166666666666668,0.16717171717171717,0.4465909090909091,1
292,292,Automatic essay scoring model based on two-layer bidirectional long-short term memory network,"Automatic essay scoring provides a cost-effective and consistent alternative to human correction. However, in order to obtain good performance, human experts are needed to extract features of text manually in traditional ways. We propose a two-layer bidirectional long-short term memory model that a fully automatic essay scoring model. The agreement of essay scores which marked by our model and human raters respectively has achieved to 0.870 based on metrics of Cohen's . This model can achieve excellent results like human beings' professional raters.",60104000,ShenZhen Institute of Information Technology,Shenzhen,China,"['1712', '1709', '1707', '1705']",16.6,0.19545454545454544,0.34545454545454546,1
293,293,Big data from the cloud to the edge: The aggregate computing solution,"We advocate a novel concept of dependable intelligent edge systems (DIES) i.e., the edge systems ensuring a high degree of dependability (e.g., security, safety, and robustness) and autonomy because of their applications in critical domains. Building DIES entail a paradigm shift in architectures for acquiring, storing, and processing potentially large amounts of complex data: data management is placed at the edge between the data sources and local processing entities, with loose coupling to storage and processing services located in the cloud. As such, the literal definition of edge and intelligence is adopted, i.e., the ability to acquire and apply knowledge and skills is shifted towards the edge of the network, outside the cloud infrastructure. This paradigm shift offers flexibility, auto configuration, and auto diagnosis, but also introduces novel challenges.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1709', '1707', '1705']",32.25,0.08973626373626374,0.38878021978021976,1
294,294,Financing fixed assets decision: An analysis,"The investment in fixed assets is imperative for carrying out the operating activities of a business concern. It determines the profitability, growth, risk reduction and social goals of the business concern. Financing fixed assets is a challenging task. This is true especially in the case of manufacturing concerns. Financing fixed assets is one of the significant aspects of fixed assets management. It requires a large cash outlay and, thus, involves a crucial financial decision. It is very difficult to reverse after the decision has been taken. The financial manager, therefore, has to take such a decision with utmost care. The present paper focuses on the real corporate world practices regarding financing fixed assets decision in the management of fixed assets. The main aim is to enlighten the shareholders, creditors, investors, bankers, prospective entrepreneurs, students and academicians relating to financing fixed assets decision and its implications. The study would reveal how far, the risk and return associated with the financing mix and a trade-off between risk and return will result in an acceptable financing strategy for most of business concerns.",60013919,Pondicherry University,Puducherry,India,['1706'],16.272727272727273,0.09953416149068324,0.42406832298136643,1
295,295,Architecture description language for climate smart agriculture systems,"Smart agriculture is a new concern in IoT systems. IoT technologies can provide information about the agriculture field and its surroundings and act accordingly. Architecting smart agriculture systems can benefit from architecting methods available for IoT systems. In this paper, we introduce CSA-CAPS, a Climate Smart Agriculture modeling framework designed based on CAPS. CAPS is an architecture-driven modeling framework for developing IoT Systems. CSA-CAPS includes a modified meta model for the software architecture of CAPS. It adds special sensors and functionalities for climate concerns of building smart agriculture systems. This paper shows the capability of CSA-CAPS by applying motivating scenarios.",60072733,An-Najah National University,Nablus,Palestine,"['1712', '1709', '1707', '1705']",12.5,0.25009276437847866,0.5710575139146568,1
296,296,Numerical Solution of Linear and Higher-order Delay Differential Equations using the Coded Differential Transform Method," The CDTM is developed and applied to delay problems to show the efficiency of the proposed method. The coded differential transform method is a combination of the differential transform method and Mathematica software. We construct recursive relations for a few delay problems, which results in simultaneous equations, and solve them to obtain various series solution terms using the coded differential transform method. The numerical solution obtained by CDTM is compared with an exact solution. Numerical results and error analysis are presented for delay differential equations to show that the proposed method is suitable for solving delay differential equations. It is established that the delay differential equations under discussion are solvable in a specific domain. The error between the CDTM solution and the exact solution becomes very small if more terms are included in the series solution. The coded differential transform method reduces complex calculations, avoids discretization, linearization, and saves calculation time. In addition, it is easy to implement and robust. Error analysis shows that CDTM is consistent and converges fast. We obtain more accurate results using the coded differential transform method as compared to other methods.",60108737,Manipal University Jaipur,Jaipur,India,"['1706', '1703']",17.0,0.1552083333333333,0.43041666666666667,0
297,297,Dynamic security rules for legacy systems,"Industry 4.0 tries to digitalize the production process further. The digitalization is achieved by connecting different entities (machines, worker) to data-exchange, which needs to be dynamic and to adapt to different changing situations and members in the process. However, just exchanging data might lead to confidentiality issues. The data-exchange needs to be protected to secure the confidentiality and trust in the system. Therefore, security rules need to adapt to these dynamic situations. One part of a possible solution might be dynamic access control rules. However in many cases, existing ""legacy"" systems are reused, which can in not handle dynamic access control rules. Due to this gap between the required and provided functionality, we propose an approach, which integrates dynamic access control based on the system-context into legacy systems. Our approach uses a security adaption controller, which dynamically adapts the access control rules to a new situation and integrates them into an existing legacy system. We discussed our approach with industrial practitioners and related our approach to their existing legacy system. In addition, we performed a scalability analysis to demonstrate the applicability of our approach in a realistic environment.",60111762,CAS Software AG,Karlsruhe,Germany,"['1712', '1709', '1707', '1705']",17.09090909090909,0.06112689393939394,0.4122632575757576,1
298,298,SSVEP offline analysis procedures for low cost BCI systems,"Setting low-cost brain computer interfaces (BCIs) has been a topic of interest in developing countries. There is a variety of EEG equipment, and mathematical techniques that can help achieve this goal, but some of these techniques may have some flaws by their own. A low complexity alternative using an OpenBCI optimized equipment and based on two mathematical techniques here is discussed for an ongoing develoment of a low-cost BCI project. The selected techniques for data analysis inspection are linear discriminant analysis (LDA) and multivariate synchronization index (MSI). The procedure will be shown from the basics, the OpenBCI optimized equipment is validated offline against a g.Nautilus EEG and the performance of the techniques is shown individually. Therefore, it is discussed the possibility of combining both feature extraction techniques (LDA and MSI) for steady state visual evoked potentials (SSVEP), in order to achieve a concept with better performance for an SSVEP BCI.",60103993,Universidad Tecnologica de Panama,Panama,Panama,"['1712', '1709', '1707', '1705']",25.0,0.15833333333333333,0.3375,1
299,299,Research on path planning of ship cleaning robot,"With the development of the shipping industry, a large number of long-term ships on the sea have serious problems in the accumulation of hull attachments. It is difficult and inefficient to clean up the attachment manually. It is one of the main ways to use intelligent cleaning robot instead of artificial cleaning. It can to solve the problem of low coverage, high repetition rate and low efficiency of path optimization algorithm etc. In this paper, a path planning of cluster robot algorithm is proposed based on a biological excitation neural network. MATLAB is used to simulate the algorithm. The results show that the algorithm has the characteristics of full coverage of hull path points and low repetition rate, which verifies the effectiveness and feasibility of the algorithm.",112211754,Tianjin Maritime College,Tianjin,China,"['1712', '1709', '1707', '1705']",18.142857142857142,0.05202380952380953,0.5848809523809523,1
300,300,"Numerical simulation, parallel algorithms and software for performance forecast of the system “fractured-porous reservoir – Producing well” during its commissioning into operation"," Konyukhov, Ivan V. Konyukhov, Anatolii N. ChekalinThe mathematical model, finite-difference schemes and algorithms for computation of transient thermo- and hydrodynamic processes involved in commissioning the unified system including the oil producing well, electrical submersible pump and fractured-porous reservoir with bottom water are developed. These models are implemented in the computer package to simulate transient processes with simultaneous visualization of their results along with computations. An important feature of the package Oil-RWP is its interaction with the special external program GCS which simulates the work of the surface electric control station and data exchange between these two programs. The package Oil-RWP sends telemetry data and current parameters of the operating submersible unit to the program module GCS (direct coupling). The station controller analyzes incoming data and generates the required control parameters for the submersible pump. These parameters are sent to Oil-RWP (feedback). Such an approach allows us to consider the developed software as the “Intellectual Well System”. Some principal results of the simulations can be briefly presented as follows. The transient time between inaction and quasi-steady operation of the producing well depends on the well stream watering, filtration and capacitive parameters of oil reservoir, physical-chemical properties of phases and technical characteristics of the submersible unit. For the large time solution of the nonstationary equations governing the nonsteady processes is practically identical to the inverse quasi-stationary problem solution with the same initial data. The developed software package is an effective tool for analysis, forecast and optimization of the exploiting parameters of the unified oil-producing complex during its commissioning into the operating regime.",60105869,Innopolis University,Kazan,Russian Federation,"['1706', '1703']",20.076923076923077,0.10952380952380952,0.3587962962962963,0
301,301,Mitigating security threats through the use of security tactics to design secure cyber-physical systems (CPS),"Cyber-Physical Systems (CPS) attract growing interest from architects and attackers, given their potential effect on privacy and safety of ecosystems and users. Architectural tactics have been proposed as a design-time abstraction useful to guide and evaluate systems design decisions that address specific system qualities, but there is little published evidence of how Security Tactics help to mitigate security threats in the context of Cyber-Physical Systems. This article reports the principled derivation of architectural tactics for an actual SCADA-SAP bridge, where security was the key concern; the key inputs were (1) a well-known taxonomies of architectural tactics, and (2) a detailed record of trade-offs among these tactics. The project architects used client-specified quality attributes to identify relevant tactics in the taxonomy, and information on their trade-offs to guide top-level decisions on system global shape. We venture that all architectural tactics taxonomies should be enriched with explicit trade-offs, allowing architects to compare alternative solutions that seem equally good on principle but are not so in practice.",60007087,Universidad Técnica Federico Santa María,Valparaíso,Chile,"['1712', '1709', '1707', '1705']",32.8,0.14659090909090908,0.5431818181818181,1
302,302,Real-time target tracking based on PCANet-CSK algorithm,"This paper presents a real-time target tracking method by combining PCANet and CSK. To speed up PCANet feature extraction, we give a lightweight PCANet to simplify the structure of PCANet. In tracking step, in order to improve tracking performance, we integrate the scale adaptive module into traditional CSK algorithm and optimize its model updating mechanism inspired by LMCF. The experimental results on OTB50 validate the effeteness of our method. Compared with the traditional CSK algorithm using gray features, the tracking success rate of our method is about 26% higher , and the tracking accuracy increases about 29%.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1709', '1707', '1705']",19.4,0.13,0.48,1
303,303,Detecting and resolving flow entries collisions in software defined networks,"Software-defined network(SDN) provides flexible management by separating control plane and data plane. Multiple function modules distribute flow entries to OpenFlow switches via centering controllers. Unfortunately, making and managing flow entries and policies are often error- prone and complex due to the lack of systematic analysis tools. Since the network updating takes place frequently, the analysis scheme must be efficient enough. In this paper, we propose a Trie based scheme to analysis collision occurring in the data plane. Extensive experiments demonstrate that our method is 3-40 faster than the traditional scheme andcost less memory. Moreover, a policy-oriented strategy was introduced to help resolve the collision, which can be treated as reference advice for administrators. Also, we implement and evaluate our scheme in the simulation environment to verify its practicability.",60019118,University of Science and Technology of China,Hefei,China,"['1712', '1709', '1707', '1705']",16.0,-0.11018518518518519,0.4138888888888889,1
304,304,Text similarity calculation method based on hybrid model of LDA and TF-IDF,"The traditional TF-IDF-based text similarity calculation model uses statistical methods to map text to the keyword vector space and convert the similarity of text into the distance between text vectors. Such methods have problems such as high computational dimensions, sparse data, and inability to take advantage of the semantic information contained in the text itself, so the results obtained are not as similar as the physical text. The text similarity model based on the topic model changes the traditional spatial similarity of keyword vectors, and can fully utilize the semantic information contained in the text itself. But this approach ignores the effect of words on text semantic representations with different weights. In the process of converting text into topic feature space, valuable information is lost. In view of the above problems, this paper proposes a text similarity hybrid model (L-THM) integrating LDA and TF-IDF for calculating text similarity. The model uses the semantic information contained in the text itself and the keyword information reflecting the text to comprehensively analyses and calculates the similarity between the texts. The experimental results show that the hybrid model can better represent the text information than the single model, and obtain a good F value in the cluster, which effectively improves the text similarity calculation effect.",60022422,Ocean University of China,Qingdao,China,"['1712', '1709', '1707', '1705']",26.375,0.1420408163265306,0.4855102040816326,1
305,305,A hedge algebras based fuzzy inference system for clustering in multi-hop WSNs,"To prolong the lifetime of wireless sensor networks, the clustering technique is a key point to create optimized sensor node groups for effective transmission processes. There are many factors affected the efficiency of clustering algorithms that come from uncertain characteristics of both inside and outside network conditions. Therefore, the fuzzy logic-based clustering technique can be seen as a promising technique since it allows combining and evaluating diverse parameters in an efficient sense. Moreover, the Fuzzy Inference System (FIS) is an efficient modeling tool to utilize the best input data features and expert knowledge for supporting appropriate decisions. However, using the human reasoning process to assign linguistic terms for setting fuzzy rules may lead to ineffective results because of intuitively heavily dependent problem. Otherwise, thanks to a good property of hedge algebras that provides a mathematical formalism for designing the order-based semantic structure of term domains of linguistic variables as a quantitative model. Hence, this paper proposes a novel fuzzy inference system based hedge algebras which combine for forming clusters in multi-hop sensor networks. The numerical results are shown in this paper to validate the efficiency of the proposed model.",60113358,Thang Long University,Hanoi,Viet Nam,"['1712', '1709', '1707', '1705']",23.625,0.2633333333333333,0.36666666666666664,1
306,306,Developing QR payment to enhance the technological service in sederhana restaurant network,"This research is conducted in the Sederhana Restaurant network that use the system based on profit sharing among stakeholders with a ratio of the number 10: 7: 3 for employees, investors and brand holder respectively. Nowadays the restaurant network is managed manually with traditional cash payment. In order to meet the globalization and technology development, the restaurant planned to use QR for payment, so that the customers can make payment easily. This research uses SDLC model that consists of five stages such as planning, analysis, design, implementation, and maintenance. Subjects of the research are people who use the system such as customers and stakeholders. This research is still on going and the researchers would like to present the design of the system. Research findings show that QR payment can support restaurant and it is proper to be implemented.",60112423,Kalbis Institute,Jakarta Timur,Indonesia,"['1712', '1709', '1707', '1705']",19.714285714285715,0.11666666666666667,0.4729166666666667,1
307,307,Application of the grid-characteristic method for mathematical modeling in dynamical problems of deformable solid mechanics," PetrovThe grid-characteristic method is a promising numerical method for solving hyperbolic systems of equations, e.g., equations describing elastic and acoustic waves. This method has high precision and allows physically correct simulations of wave processes in heterogeneous media. The grid-characteristic method makes it possible to correctly take into account boundary conditions and conditions on surfaces with different physical characteristics. The method offers the greatest advantages for one-dimensional equations, especially in combination with a fixed difference grid, as in conventional grid-based methods. However, in the multidimensional case using the algorithms of splitting with respect to spatial variables, the author has managed to preserve its positive qualities. The use of the method of Runge – Kutta type, or the integro-interpolation method for hyperbolic equations makes it possible to effectively carry out a generalization of methods developed for linear equations, in the nonlinear case, in particular, to enforce the difference analogs of the conservation laws, which is important for shock-capturing, for example, discontinuous solutions. Based on the author’s variant of the grid-characteristic method, several important problems of seismic prospecting, seismic resistance, global seismic studies on Earth and Mars, medical applications, nondestructive testing of railway lines, the simulation of the creation and characteristics of composite materials for the aerospace industry and other areas of practical application were numerically solved. A significant advantage of the constructed method is the preservation of its stability and precision at the strains of the environment. This article presents the results of a numerical solution based on the grid-characteristic method to the problem of modeling elastic-plastic deformation in traumatic brain injury.",60000308,Moscow Institute of Physics and Technology,Moscow,Russian Federation,"['1706', '1703']",29.0,0.15482966309053264,0.509201957462827,0
308,308,A formal semantics for supporting the automated synthesis of choreography-based architectures,".The European Conference on Software Architecture (ECSA), held this year from September 9th to 13th at the FIAP, in Paris, France, is a premier European software architecture conference providing researchers, practitioners, and educators with a platform to present and discuss the most recent, innovative and significant findings and experiences in the field of software architecture research and practice. This year was special, as we shared the venue and part of the program with the Systems & Software Product Lines Conference (SPLC). Some keynotes and tracks were common to both events. In addition to the main track, the conference featured various events and tracks including the Track on Women in Software Engineering (WSE), a Doctoral symposium, a Tool, demos and poster session, and six workshops. All these events were held with the aim to explore new trends and to support researchers in the early stages of their careers.",60018783,Università degli Studi dell'Aquila,L'Aquila,Italy,"['1712', '1709', '1707', '1705']",29.4,0.13108379715522572,0.3774505256648113,1
309,309,One-class classification with deep adversarial learning,"One-class classification (OCC) seeks to build a machine-learning model when the negative class is either absent, poorly sampled, or not well defined. In this paper, we present a deep adversarial learning based architecture for one-class classification. Our architecture is composed of two deep neural networks, a generator and a discriminator, that are competing while collaborating with each other since it is inspired by the success of Generative Adversarial Networks (GANs). The generator network contains a Deconvolutional Neural Networks (aka. decoder), which is trained using a zero-centered Gaussian noise as the feature representation of the pseudo-negative class to learn a good representation as well as the boundary for the classifiable distortion of the target (or positive) class with the assistance from the target class. The outputs produced by the generator network are aggregated with the real positive class data samples, which are then used to train the discriminator network, whose goal is to understand the underlying concept in the positive class, and then classify the negative testing samples. The proposed architecture applies to a variety of OCC problems such as novelty detection, anomaly detection, and mobile user authentication. The experiments on MNIST and Caltech-256 images demonstrate that our architecture achieves superior results over the recent state-of-the-art approaches.",60000711,Valdosta State University,Valdosta,United States,"['1712', '1709', '1707', '1705']",25.75,0.09136363636363636,0.44893939393939397,1
310,310,Chinese medical entity annotation based on autonomous learning,"Named entity annotation means an entity that needs to be labeled in a prediction sequence on a given text sequence. Labeling highquality medical entities from Chinese medical texts plays an important role in named entity recognition, and construction of medical knowledge graph. Named entity annotation in medical texts is the premise of the full-supervised and semi-supervised named entities recognition. The current mainstream named entity annotation require a lot of manpower on the corpus labeling, which is laborious and time consuming. For medical entities widely distributed in Chinese medical texts, in this paper, we propose a small number of manually labeled medical entities to autonomously learn medical text features, and iteratively generating new labeled entities. The model automatically iterates the annotations from the original medical text collection to be processed and generates a valid medical entity. The autonomously medical entity labeling work makes it easy to label Chinese medical texts. This framework is tested on real Chinese medical records, and the experimental results show that the method can effectively identify the entities, and has certain practical value.",60014966,Peking University,Beijing,China,"['1712', '1709', '1707', '1705']",22.0,0.08246366728509587,0.23961811997526278,1
311,311,Source-code divergence diagnosis using constraints and cryptography,"This paper presents a new technique that informs developers of potential architectural-type violations and non-compliance checking in their software system after changes in the source code. The violations identified by our technique not only concern broken calls/dependencies/inheritance or data-dependencies but also concern the dissatisfaction of some constraints which may be defined and imposed by OCL. The technique partitions the software system into small grain nodes and filters out nodes that have no role in dependency-based software architecture adherence and nodes that cannot jeopardize the validity of a function regarding OCL adherence. It thus presents a reduced version of the source code where additional developer-defined links may be established between entities (e.g., method to method) based on the developer's implicit knowledge of the architecture of the system. A change in, for example, an assignment expression would 1) single out the containing entity of the node(s) (e.g., method or class), and 2) issue an alert to all of the linked entities. To establish the link/call/chain, we suggest using an architecture consistency chain technology (inspired by blockchain).",60009602,University of Limerick,Limerick,Ireland,"['1712', '1709', '1707', '1705']",29.0,-0.0975108225108225,0.5781385281385282,1
312,312,Semi-automatic mapping of source code using naive Bayes,The software industry has not adopted continuous use of static architecture conformance checking. One hindrance is the needed mapping from source code elements to elements of the architecture. We present a novel approach of generating and combining dependency and semantic information extracted from an initial set of mapped source code files. We use this to train a Naive Bayes classifier that is then used to map the remainder of the source code files. We compare this approach with the HuGMe technique on six open source projects with known mappings. We find that our approach provides an average performance improvement of 0.22 and an average precision and recall F1-score improvement of 0.26 in comparison to HuGMe.,60108011,"Linnaeus University, Växjö",Vaxjo,Sweden,"['1712', '1709', '1707', '1705']",19.166666666666668,-0.014285714285714282,0.45714285714285713,1
313,313,Impact of security and privacy issues in Internet marketing-a study.,"Purpose of the study is to analyze security issues which have an impact on the online shopping buying behavior of the customer. Also highlights the factors which helps in retaining the online customer. The survey is conducted with 175 consumers. A Questionnaire was designed with 5 points Likert scale (Strongly agree - 1 to strongly disagree – 5) and ranking. The article also focuses on the relationship and the significance between securities versus online purchasing. For effective analysis, statistical tools like factors analysis and correlation test are performed.",60013041,Bharathiar University,Coimbatore,India,['1706'],14.666666666666666,0.4888888888888889,0.7555555555555555,1
314,314,New solitary wave solutions to the three coupled nonlinear Maccari's-system with a complex structure,"In this article, the three nonlinear Maccari's-system (TNLMS) which describe how isolated waves are propagates in finite region of space is included. New accurate travelling wave solutions of this model are obtained using the balanced modified extended tanh-function method (BMETFM). The obtained results give an accuracy interpretation of the propagation of these isolated waves. We listing comparison between our realized results and that satisfied in the previous work.",60026112,Benha University,Banha,Egypt,"['1706', '1703']",17.0,0.21742424242424244,0.5636363636363636,1
315,315,Developing a mobile multimedia-based learning resource on living of komodo dragons,"The study aimed developing a mobile multimedia-based learning resource model on living komodo dragons. The model is a supplementary resource for teaching materials of learning process and lecturer?s guide in a university. The research conducted using research and development method from January 2018 to January 2019. Outcome of this study was a set of information about living of Komodo dragons that can be accessed using smartphone, complemented with the set of teaching tools; i.e. teaching materials, student worksheets, and lecturers guide. Results of the testing in development phase indicated that the product was proper to be implemented in learning after some revision had been conducted, so the product could be used as a learning model using mobile device.",60112423,Kalbis Institute,Jakarta Timur,Indonesia,"['1712', '1709', '1707', '1705']",19.666666666666668,0.0,0.1,1
316,316,Real-time online multi-object tracking: A joint detection and tracking framework,"In recent years, object detection technology has been continuously developed, and the tracking-by-detection strategy has gradually become the main method of multi-object tracking. Based on detection, the accuracy of the multi-object tracking depends on the detection results to a large extent. However, in many practical applications, especially the case of complex scenes and crowded objects, the detection results are usually inaccurate. In this paper, a joint detection and tracking framework is proposed with a unified confidence scoring function to evaluate tracks confidence and complement low confidence detections with high confidence tracks. In this way, detections and tracks can be combined organically and achieved complementarity. High confidence detection results can prevent long-term tracking drift, while high confidence tracking prediction can deal with false detection and missed detection caused by occlusion during object interaction. Moreover, we trained the ReID appearance feature with higher identification capabilities on the large-scale person reidentification datasets, which has higher identification capability. Extensive experiments are conducted on MOT17 benchmarks to demonstrate the real-time and advanced performance of our tracker.",60025278,Tsinghua University,Beijing,China,"['1712', '1709', '1707', '1705']",21.375,0.08299719887955183,0.46560224089635843,1
317,317,A study for application in vehicle networking and driverless driving,"From the future social trends, economic trends and technological trends, it can be clearly found that the advent of the Internet of Things and the development of communication technologies have jointly subverted the definition of action. In the past, traffic accidents caused by fatigue driving and unsafe driving behavior will begin to decline due to advances in technology. Therefore, the impact on the future automobile industry is particularly significant, forcing the auto industry to carry out reforms again and again. In the near future, people's transportation will move toward fully-automobile driving, and will soon become the normal state of human life in the future. The development of 5G will also make human life more successful in the transformation. In view of this, the research will use the case study method to conduct an inductive analysis of the technology required for driverless driving and 5G technology. Through analysis, it will provide a reference for the future unmanned system service planning. It is expected that the fully-automated driving vehicles will be shared in the future. Excellent quality of interconnection and green environmental protection.",60025502,Chaoyang University of Technology,Taichung,Taiwan,"['1712', '1709', '1707', '1705']",20.11111111111111,0.11969696969696968,0.33636363636363636,1
318,318,Automatic detection of architectural bad smells through semantic representation of code,"Bad design decisions in software development can progressively affect the internal quality of a software system, causing architecture erosion. Such bad decisions are called Architectural Smells (AS) and should be detected as soon as possible, because their presence heavily hinders the maintainability and evolvability of the software. Many detection approaches rely on software analysis techniques which inspect the structure of the system under analysis and check with rules the presence of AS. However, some recent approaches leverage natural language processing techniques to recover semantic information from the system. This kind of information is useful to detect AS which violate ""conceptual"" design principles, such as the separation of concerns one. In this research study, I propose two detection strategies for AS detection based on code2vec, a neural model which is able to predict semantic properties of given snippets of code.",60012306,University of Milano - Bicocca,Milan,Italy,"['1712', '1709', '1707', '1705']",23.166666666666668,0.030769230769230792,0.5006410256410256,1
319,319,A logical architecture design method for microservices architectures,"The use of microservices architectures has been widely adopted in software development, especially for cloud-based solutions. Developing such solutions faces several challenges beyond typical architecture and service design concerns, including service exposition (API), inter-service communication, and infrastructure deployment, among others. Although model-driven approaches allow abstracting microservices behavior from the business domain, there is a lack of proper methods for addressing the referred challenges. In this paper, the elicitation of microservices, their identification uses using functionally decomposed UML use cases as input within a logical architecture derivation method, namely an adapted version of the Four Step Rule Set (4SRS), using SoaML diagrams, that responds to microservices specific characteristics. We demonstrate the approach using a scenario within a live industrial project.",60078903,"Centro de Computação Gráfica, Guimaraes",Guimaraes,Portugal,"['1712', '1709', '1707', '1705']",23.8,0.0132996632996633,0.375,1
320,320,A framework for managing uncertainty in software architecture,"Software architecture records key decisions about software systems. Changes to architecture decisions can, therefore, have significant costs. One of the main causes of architecture changes is uncertainty, which is an inherent feature in open, real-world software systems. We hypothesise that capturing uncertainties, as far as they can be predicted, pertaining to structure, behaviour and resources of systems in software architecture and treating them as first-class concerns, would make architecture decisions more resilient to change. Explicitly considering and representing uncertainty in architecture can help developers design for change and minimise architecture erosion as changes invariably occur. In this PhD project, we aim to develop a conceptual framework for the management of uncertainty in software architecture. The conceptual framework will be realised in the form of a workbench of tools for managing uncertainty at the architectural level. The effectiveness of the framework and the workbench will be evaluated using case studies. An ideal case study for evaluation will demonstrate different aspects of uncertainty in software architecture. Potential domains under consideration for case studies include wireless sensor networks and health care systems.",60022132,University of St Andrews,St Andrews,United Kingdom,"['1712', '1709', '1707', '1705']",17.9,0.22685185185185183,0.7564814814814815,1
321,321,Modeling of Collective Decisions by a Virtual Council,"Abstract—The paper presents the results of modeling collective decision making in small groups for the situation of diagnosing arterial hypertension, namely: analysis of the known modeling methods and integration of knowledge and diagnostic decision support tools, development of the architecture of the Virtual Council research prototype and its software implementation, as well as experiments with the council.",60031254,Immanuel Kant Baltic Federal University,Kaliningrad,Russian Federation,['1700'],57.0,-0.25,0.4,1
322,322,Towards a parallel template catalogue for software performance predictions,"Software Performance Engineers evaluate quality attributes (like response time) of software rich systems based on architectural models during early design time. Thereby, they use model-based approaches to analyze the software's behaviour and resource consumption. One prominent approach is the Palladio Component Model (PCM) which has been researched for over a decade. However, when it comes to multicore support or massive parallel execution the approaches still suffer from major drawbacks. Drawbacks include inaccurate prediction models, insufficient modelling languages, and missing tool support, to name just some of them. In this paper, we focus on overcoming the last two drawbacks, namely improving the modelling language and the tool support. We present a template catalogue for parallel performance patterns in software performance predictions. We use the example of a parallel-loop in the Palladio Component Model to exemplify our idea.",60015815,Universität Stuttgart,Stuttgart,Germany,"['1712', '1709', '1707', '1705']",17.0,0.08375000000000002,0.36666666666666664,1
323,323,Applicability of controlled natural languages for architecture analysis and documentation: An industrial case study,"Formal approaches are a prerequisite for automated quality control. However, such approaches are often difficult to learn and apply and thus have not found their way into mainstream software development. Controlled natural languages (CNLs) seek to overcome the drawbacks of formal approaches by hiding their formality behind a restricted set of natural language, which is intended to be easier to use. In this paper, we analyze the applicability of CNLs for automated architecture analysis and as a means for architecture documentation in an industrial case study. We evaluated the CNL with 12 experienced practitioners in a focus group. The results show that practitioners perceive CNLs as an appropriate and an understandable means for formalizing and documenting architectural rules. Even without verifying rules automatically, a project can benefit from such languages, since they allow to find a common sense about architecture concepts and relations and to use those concepts and relations consistently throughout the development and evolution phase.",60028229,Universität Hamburg,Hamburg,Germany,"['1712', '1709', '1707', '1705']",22.428571428571427,0.05500000000000001,0.565,1
324,324,We Should Not Get Rid of Incivility Online,"Incivility and toxicity have become concepts du jour in research about social media. The clear normative implication in much of this research is that incivility is bad and should be eliminated. Extensive research—including some that we’ve authored—has been dedicated to finding ways to reduce or eliminate incivility from online discussion spaces. In our work as part of the Civic Signals Initiative, we’ve been thinking carefully about what metrics should be adopted by social media platforms eager to create better spaces for their users. When we tell people about this project, removing incivility from the platforms frequently comes up as a suggested metric. In thinking about incivility, however, we’ve become less convinced that it is desirable, or even possible, for social media platforms to remove all uncivil content. In this short essay, we discuss research on incivility, our rationale for a more complicated normative stance regarding incivility, and what other orientations may be more useful. We conclude with a post mortem arguing that we should not abandon research on incivility altogether, but we should recognize the limitations of a concept that is difficult to universalize.",60015583,New America Foundation,"Washington, D.C.",United States,['1706'],23.0,-0.026249999999999996,0.46291666666666664,1
325,325,Detection of conflicts and inconsistencies between architecture solutions,"This paper presents a semi-automated approach for detecting conflicts and inconsistencies between architecture solutions. Inconsistencies occur when two or more architecture solutions rely on each other but cannot be satisfied, and conflicts when there are contradictions within one single decision specification, such as contradictory variable range and value. The proposed approach comprises a set of checks followed by transformations of architecture solutions specified according to a domain-specific-language, also created in the context of this work, into state machines. The semi-automated approach is implemented as a plugin for the MagicDraw modeling tool, and was evaluated in a project from the automotive domain.",60009941,Technische Universität Kaiserslautern,Kaiserslautern,Germany,"['1712', '1709', '1707', '1705']",25.25,0.08622448979591837,0.36989795918367346,1
326,326,Architecture trace diagrams for cyber-physical systems,"Developing a suitable architecture for Cyber-Physical Systems requires architects to consider all necessary areas - software, hardware, networking - and have an understanding of how information is passed between the different components. Errors in some part might be caused by problems in another, thus a deeper understanding of the information flow is necessary to identify possible error sources. We present how Architecture Trace Diagrams (ATDs) can be used to model the architecture and information flow of Cyber-Physical Systems. In a study with several developers, we show that participants using ATDs achieved better results in terms of correctness, speed, and participant self-efficacy in comparison to UML diagrams.",60014264,Universität Duisburg-Essen,Essen,Germany,"['1712', '1709', '1707', '1705']",26.5,0.13125,0.60625,1
327,327,Semantic Technologies for Semantic Applications. Part 1. Basic Components of Semantic Technologies,"Abstract—: This paper discusses the basic aspects of the modern understanding of semantic computations, semantic technologies, and semantic applications in the field of artificial intelligence. The basic terminology accepted in the work is introduced and specific examples of semantic applications, including industrial-level ones, are given. The paper demonstrates that the basic components of semantic technologies of artificial intelligence are ontologies and semantic models of their use, semantic resources, and the semantic component of the technology. The semantic resources contain information about the semantics of words and other entities, as well as means of refinement of these semantics. The semantic component is used to create formal descriptions of the meanings of natural language entities and numerically evaluate their pairwise semantic similarity. The available semantic resources are discussed and a comparative analysis of them is given. Information on natural language entity types (primitives) is given and then used for the practical purposes of building models of formal description of the meaning of texts in various semantic applications. The latter components of description of text semantics constitute the contents of the second part of this paper.",60101977,St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences,Saint Petersburg (ex Leningrad),Russian Federation,['1700'],22.875,-0.03749999999999999,0.3482142857142857,1
328,328,Some objective methods for determining relative importance of financial ratios,"The segregation of financial ratios into input and output ratios are useful to determine the business insolvency/failure and financial efficiency of the business organizations. A total of 18 software companies are considered with nine financial ratios. The aim of this study is to examine the efficiency of various financial ratios and identify their average weights through objective methods namely MLP of Artificial Neural Network, Entropy and Critic Methods.",60023544,Andhra University,Visakhapatnam,India,['1706'],22.666666666666668,-0.045,0.275,1
329,329,Streamlining value in a FOSS project,"Today, different actors, such as developers, supporters, companies or public entities, contribute in different ways to non-profit open source software projects. The majority of them is contributing for individual and personal reasons, aiming to create (intangible) value that is important to themselves. Besides that, users are today often not directly involved in the development process. This results in the need to have a software and management structure that actively aligns these different actors, pays respect to their needs, and involves them in the software creation process. We present the case of Catrobat and how different influences, e.g., by contributors, users, or stakeholders, affect the project and its development. We outline the challenges that occur in practice when it comes to an open software project situated in a complex ecosystem of different actors and highlight the requirements on such a project and how they are encountered in the presented case.",60025272,University of Tokyo,Tokyo,Japan,"['1712', '1709', '1707', '1705']",24.833333333333332,-0.004901960784313723,0.48039215686274495,1
330,330,Named entity recognition for Russian historical texts,"With the raise of big data, machine learning and crowdsourcing, the volume of existing datasets for different machine learning problems have greatly increased. The natural language processing field is not an exception; so, as a result, most of the researches have transitioned into investigating and applying different deep architectures for it. One of the main issues of this trend is as follows: it is hard to adopt such approaches for somewhat poorly studied languages, which do not have training data enough as for natural language processing perspective. In this paper, we investigate some modern approaches to named entity recognition as for Russian language and show that for historical texts their results are much lower than for general ones. In addition, we propose our own algorithm that improves the results of for these historical texts.",60072485,"Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO",Saint Petersburg (ex Leningrad),Russian Federation,"['1712', '1709', '1707', '1705']",26.8,0.10124999999999999,0.41125000000000006,1
331,331,Has social sustainability been addressed in software architectures?,"Research on sustainability in software engineering has gained importance as a result of the need to create better software and therefore avoid compromising future generations opportunities, whether in the social, economic, technical or environmental dimension. Social dimension encompasses the direct support of the software systems in any domain, as well as activities or processes that create benefits for social communities, such as health, education, and transportation. Although social aspects have been previously examined within the broader context of software engineering, the software systems design based on the notion of social sustainability is still poorly understood and practiced. This paper outline relevant points surrounding social sustainability as a concern in software architectures design. In particular, we discuss some issues in designing software systems that generate social values and have a positive impact on communities. We hope that this discussion will help broaden the concept of social sustainability in architectural design decisions and to bring awareness to the particular needs of software systems that have a direct impact on human well-being and contribute to sustainable development.",60008088,Universidade de Sao Paulo - USP,Sao Paulo,Brazil,"['1712', '1709', '1707', '1705']",29.0,0.07093663911845732,0.26077823691460056,1
332,332,Assessment tool for environmental management system performance according to the ISO 14001,"The present paper is concerned with a statistical approach involving latent and manifest variables applied in order to assess the Environmental Management System performance. The main idea is to develop an assessment tool in order to measure the Environmental Management System practices performances (which are divided into seven segments: Context of the organization, Leadership, Planning, Improvement, Support, Operation, and Performance Evaluation) described in the ISO14001 standard., enabling the company to characterize her performance regarding to the ISO 14001 standards. For this, we conceptualize a structural equation modeling (SEM) which describes various causal connections between the Environmental Management requirements. The SEM’s resolution is based on the Partial Least squares (PLS) method and the implementation is running in the XLSTAT software. The obtained results could be examined in order to plan the improvements and develop an action plan. It is necessary to control Environmental Management System performance to ensure that it is either good enough, or that something is being done to improve it.",60025457,Hassan II University of Casablanca,Casablanca,Morocco,['1706'],27.0,0.056666666666666664,0.37333333333333335,1
333,333,Named entity extraction for Chinese electronic medical records,"Named entity extraction task refers to identifying and extracting proper named entities from natural language texts. It is the key task in knowledge graph construction. Disease, symptom and drug entities are widely distributed in Chinese electronic medical records (EMRs). Extracting high-quality medical entities from EMR plays an important role in building medical knowledge graph, medical question & answer and assistance decision making. For the widely distributed entities, in this paper, we propose an end-to-end named entity extraction framework, which uses popular deep learning based approach, known as conditional random field (CRF), bidirectional-long short-term memory (Bi- LSTM+CRF) and BERT+Bi-LSTM+CRF for training and testing the named entities. These models are tested on real medical records, and the experimental results show that the method can effectively identify the entities, and has certain practical value.",60014966,Peking University,Beijing,China,"['1712', '1709', '1707', '1705']",21.833333333333332,0.07301587301587302,0.3817460317460318,1
334,334,Reinforcement learning based on multi-subnet clusters,"The main task of reinforcement learning is to enable the subject to obtain the most reward from the environment. Reinforcement learning has been proposed and achieved certain results. However, many reinforcement learning methods still have inefficiencies that result in inability to meet the demand in some applications. Aiming at the above problems, this paper proposed a reinforcement learning algorithm based on multi-subnet cluster (MSC-RL). The proposed network consists of multiple subnet clusters and the primary storage network. Each subnet cluster is composed of multiple subnets and one sub-storage network. In the subnet cluster, multiple subnets are used to explore the solution space simultaneously and saves the searched information to the sub-storage network. At regular intervals, the subnet cluster saves the searched information to the primary storage network. In traditional reinforcement learning, there is not enough interaction between the independent subnets. Insufficient information interaction between the independent subnets can cause the algorithm to fall into local optimum. MSC-RL can exchange information searched by each subnet through the sub-storage network to realize information interaction within the subnet cluster. Each cluster uses the primary storage network for information interaction. The method enhances the information interaction between subnets and improves the ability of the algorithm to optimize. This paper uses the Atari game to verify the performance of the proposed method and compared it with some mainstream reinforcement learning methods. The experimental results show that the proposed algorithm is superior to some mainstream reinforcement learning methods in the performance of the Atari game.",60108756,Hubei University of Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",16.6,0.13540372670807455,0.36587036152253555,1
335,335,A formal design of the hybrid European rail traffic management system,"Railway Transportation Management Systems are an emerging field in the context of advanced distributed software systems. Methods and techniques supporting rigorous formal design of system architecture where software components interact with each other and control physical components are highly demanded to assure reliability of the system operation. We present a formal model of the Hybrid ERTMS/ETCS Level 3, the new standard of the European Rail Traffic Management System, aiming to replace the different national train control and command systems by a unique European railway management system. We use the Abstract State Machine (ASM) formal method to provide a complete specification of the standard. The model has been developed through a sequence of model refinement steps following the incremental way in which requirements describe train operation. We have exploited the ASMETA tool-set supporting the ASMs to simulate the abstract models and validate them with respect to the operational scenarios that are given as part of the requirements. We discuss ambiguities and inconsistencies of the requirements, as well as difficulties encountered in the specification and during scenarios simulation.",60030318,Università degli Studi di Milano,Milan,Italy,"['1712', '1709', '1707', '1705']",25.142857142857142,0.08590909090909091,0.278466810966811,1
336,336,Terminal bulb segmentation of caenorhabditis elegans under small samples based on two-stage u-net network,"Convolutional neural network based on machine learning has become one of the most popular methods of image recognition and segmentation, but it needs huge data samples to get better results. In this study, based on U-Net network, a two-stage convolution neural network method for automatic segmentation of Terminal bulb of Caenorhabditis elegans in small samples was proposed. The method solves the problem that traditional singlestage network cannot be implemented in small samples. The Dice coefficient reaches 89.5%, which is higher than that of the baseline U-Net method.",60014643,Wuhan University of Science and Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",21.75,0.21875,0.60625,1
337,337,Placing human values at the core of socio-technical systems development: A project case study,"Socio-technical systems such as software systems play a critical role in modern society. Our societies have rapidly transformed into information societies. At the same time, there is a distinction between system-centred design and human-centred design. Recent studies indicate the challenges concerning system architecture design and usability. Still, software architecture modeling techniques such as the UML are inconsistent with human-centredness. Users are no longer passive consumers but co-designers, co-creators, and content producers of interactive systems. Therefore, human-centred development has become a focus for many systems development ranging from medical devices, business support software to media and learning applications. We report our activities, preliminary findings, and lessons learned from an ongoing project detailing a unified media playout for audiovisual heritage items. Our approach follows the human-centred design methodology described in ISO 9241-210.",60112390,Technische Informationsbibliothek (TIB),Hannover,Germany,"['1712', '1709', '1707', '1705']",14.444444444444445,0.0875,0.371875,1
338,338,Kubow: An architecture-based self-adaptation service for cloud native applications,"This paper presents Kubow, an extensible architecture-based self-adaptation service for cloud native applications. Kubow itself was implemented by customizing and extending the Rainbow self-adaptation framework with support for Docker containers and Kubernetes. The paper highlights Kubow's architecture and main design decisions, and illustrates its use and configuration through a simple example. An accompanying demo video is available at the project's web site: https://ppgia-unifor.github.io/kubow/.",60027950,Carnegie Mellon University,Pittsburgh,United States,"['1712', '1709', '1707', '1705']",15.75,0.18888888888888888,0.36349206349206353,1
339,339,Visual tracking by gated PixelCNN model,"This paper proposed a novel visual tracking method based on the Gated PixelCNN and particle filtration. First, unlike the convolutional layers in traditional trackers, Gated PixelCNN is a generative model of images with a tractable likelihood. When trained, it is not limited to the existing classified datasets and video datasets. Second, similar to RNN, its shared convolutional layers extract the generic image features by calculating the pixel relationship maps of the pixels between the first pixel and the N th pixel, instead of just adjacent pixels. Through comparative experiments, We prove that the convolutional layers of Gated PixelCNN are not inferior to convolutional layers in traditional trackers. In this paper, we employ this new kind of convolutional layers in tracking. In addition, Particle Filtration is introduced in our algorithm to increase the tracker's resilience to occlusions. In the experiments, we compared our tracking method with other well-known trackers on 12 video sequences to evaluate the performance. The experimental results showed that the proposed algorithm demonstrated better overall performance than other state-of-the-art methods.",60021227,North China Electric Power University,Beijing,China,"['1712', '1709', '1707', '1705']",19.11111111111111,0.10137987012987013,0.35712932900432903,1
340,340,Analysis of purchase behavior ofresidential solar roof top PV adopters,"Residential Solar Roof Top PV (RSRTPV) is a nascent technology and though India is a sun kissed land, yet the PV technology has not gained momentum by way of installations of roof tops in the residential sector. The objective of this study is to get an insight into the purchase behavior of the residential solar roof top adopters in the city of Chennai, South India. The study is based on primary data which was collected using a questionnaire. This RSRTPV adopter centric research of 105 respondents was conducted in the city of Chennai in South India. A structured, undisguised, questionnaire with 46 preselected questions was adopted after pilot testing. The length of the survey questionnaire was kept optimum with close-ended questions based on Likert scale to elicit quick responses, by the sampled adopters. The demographic variables of the respondents indicate the green profile of a PV adopter. The study reveals their domestic consumption details like the nature of RSRTPV system, its size, type of installation, roof top area, type of dwelling and the financial option of the consumers etc. reflecting the characteristic status of RSRTPV installations. The study concludes that consumers’ experience, purchase behavior, knowledge of technology, its beneficial effects, accessible information on installations and customized financing options are vital inputs for aggressive market development of RSRTPV. The study also concludes that residential solar roof top segment remains the least developed, with its small transaction size, lower tariff and less third-party ownership. The study identifies the need for consumer awareness to translate into interest in and adoption of RSRTPV. Chennai has 8.69 million population, while it has only 350 MW of roof top solar, which implies that the offtake is poor owing to loans and subsidies, not being nattractive to induce adoption. Research points the need for bringing about local laws mandating solar with net/gross metering regulations/relevant tariff rules for uptake of solar installations.",60032269,Aligarh Muslim University,Aligarh,India,['1706'],22.428571428571427,0.1358695652173913,0.3916666666666667,1
341,341,Target tracking algorithm based on CUDA parallel acceleration,"TLD is a single-target visual tracking algorithm with good robustness and high accuracy, which can solve the problems of occlusion and deformation of the target during the tracking process. However, due to the high complexity of the algorithm, it can't meet application requirements. Based on the analysis of the parallelism and complexity of the improved TLD algorithm, a parallel implementation algorithm is proposed and implemented with CUDA to improve the real-time performance of the improved TLD algorithm for the foreground detection classifier and integrated classifier in the algorithm detection module. The results show that the improved TLD algorithm based on CUDA improves the average speed of the detection module by 8.8 times and the speed is 181 frames per second. For the test videos with different resolutions, the average execution speed of TLD algorithm is 56 frames per second, which satisfies the requirement of intelligent video monitoring.",60073708,Xi'an Institute of Posts and Telecommunications,Xi'an,China,"['1712', '1709', '1707', '1705']",29.4,0.11625,0.3629166666666667,1
342,342,An attention-based sequence learning model for scene text recognition with text correction,"Recognizing text from images taken in natural scenes is a challenging task and a hot research topic in computer vision. Unlike traditional optical character recognition (OCR), words in natural images often possess irregular layout (e.g. arbitrarily orientation, blurring, perspective distortion) which are difficult to recognize. In this paper, we develop a novel method consisting of a text recognition network and a text correction component, which is more robust to irregular text. The text correction component rectify the text of an input image to a more ""readable"" text. The text recognition network is a more ""location aware"" attentionbased sequence learning model that take the rectified image as input and recognize the text. The entire networks are trained jointly by only images and word-level annotations. The standard Softmax loss function only considers the separability between classes but does not restrict the aggregation within classes. Therefore, we adopt a new loss function based on the Softmax loss function to enable the model to learn more discriminative features, reduce misjudgments and improve accuracy. Extensive experiments on seven popular standard benchmarks, demonstrate the proposed method is comparable to state-of-the-art performance.",60122052,Southwest University,Chongqing,China,"['1712', '1709', '1707', '1705']",18.5,0.1668181818181818,0.5781439393939395,1
343,343,Development of an effective cryptographic algorithm using random matrix shared key,"Data security refers to protect digital privacy measures that are applied to prevent unauthorized access to computers, databases and websites. Confidentiality is one of the most important part of security and the principle of confidentiality ensures only the sender and the intended recipients have access to the contents of a message. There are a number of algorithms using encryption and decryption procedure to achieve security measures for data and information. Each algorithm has different method. For encrypting and decrypting large number of data sets, most of the algorithms are complex and some existing algorithms are vulnerable to cryptanalysis attacks. The main objective of our research work is to build a simple algorithm which can encrypt and decrypt large number of data sets and is free from maximum cryptanalysis attack to provide confidentiality. In this research paper, an effective symmetric cryptographic algorithm is proposed where the algorithm procedures are much simpler to encrypt or decrypt large number of data sets. Security level is higher because poly-alphabetic substitution mapping method, translation and transposition techniques are used.",60111554,"Jagannath University, Bangladesh",Dhaka,Bangladesh,"['1712', '1709', '1707', '1705']",21.75,0.1588624338624339,0.49312169312169307,1
344,344,Analysis motion imagination EEG signal in spatiotemporal-energy domain,"Brain is the most advanced part of the nervous system. As an emerging neighborhood exploring the brain, the brain-computer interface (BCI) may completely influence people's current communication and lifestyle in the future. We propose an architecture for feature extraction and classification model in brain-computer interface (BCI). Three features of EEG signal are extracted and combined in an attempt to describe the EEG signal more comprehensively including Wavelet packet decomposition, Information entropy and Co-space pattern (CSP). We construct the C-LSTM model combining the Convolutional Neural Networks (CNN) and the Long Short-Term Memory (LSTM) to perform the classification. Comparison was made with traditional approaches, and results show the method has a better performance for classification of motor imagery.",60010851,Hohai University,Nanjing,China,"['1712', '1709', '1707', '1705']",19.333333333333332,0.21666666666666667,0.46388888888888885,1
345,345,ArchLearner: Leveraging machine-learning techniques for proactive architectural adaptation,"Self-adaptation is nowadays considered as one of the possible solutions to handle the uncertainties faced by software at run-time. This is especially true in the case of IoT systems. These uncertainties can, in turn, affect the system QoS (Quality Of Service). In this tool demo, we present a machine learning driven proactive decision-making tool named ArchLearner, for aiding architectural adaptation. The tool enables the given IoT system to i) automatically identify the need for adaptation at an early stage; ii) perform automated decision making for generating the best adaptation strategy; iii) gather the feedback of the selected decision for continuous improvement. It also enables the architects/developers to i) visualize the adaptation process in near real-time; ii) specify the required configurations; iii) visualize the real-time QoS data.",60018783,Università degli Studi dell'Aquila,L'Aquila,Italy,"['1712', '1709', '1707', '1705']",21.0,0.31666666666666665,0.49999999999999994,1
346,346,Women participation in open source software communities,"Gender diversity in open source is an area of concern due to underrepresentation and unfair treatment of women. This paper presents results from research into the experiences of women who participate in open source software (OSS), their advice to newcomer women and the role that the online communities can play in creating a welcoming collaborative environment for women. The results of an online survey (58 women) and follow up interviews (11) where we asked women about their experiences and their recommendations for OSS online communities are presented in this paper.",60015574,"The University of Tennessee, Knoxville",Knoxville,United States,"['1712', '1709', '1707', '1705']",30.0,-0.15625,0.59375,1
347,347,Measuring performance quality scenarios in big data analytics applications: A DevOps and domain-specific model approach,"Big data analytics (BDA) applications use advanced analysis algorithms to extract valuable insights from large, fast, and heterogeneous data sources. These complex BDA applications require software design, development, and deployment strategies to deal with volume, velocity, and variety (3vs) while sustaining expected performance levels. BDA software complexity frequently leads to delayed deployments, longer development cycles and challenging performance monitoring. This paper proposes a DevOps and Domain Specific Model (DSM) approach to design, deploy, and monitor performance Quality Scenarios (QS) in BDA applications. This approach uses high-level abstractions to describe deployment strategies and QS enabling performance monitoring. Our experimentation compares the effort of development, deployment and QS monitoring of BDA applications with two use cases of near mid-air collisions (NMAC) detection. The use cases include different performance QS, processing models, and deployment strategies. Our results show shorter (re)deployment cycles and the fulfillment of latency and deadline QS for micro-batch and batch processing.",60052106,"Universidad de Los Andes, Colombia",Bogota,Colombia,"['1712', '1709', '1707', '1705']",18.875,0.1012987012987013,0.4503246753246753,1
348,348,Multi-experience pool local state parallel Q-network,"Deep Q Network (DQN) takes the entire game interface as input, makes use of neural network to output Q value, and maps it into actions. However, the contribution of different game interfaces to Q value often varies, and sometimes only a few interfaces are closely related to the execution of agents. Hence, we propose a deep reinforcement learning model based on multi-experience pool local state parallel Q-Network (MEPLSPQ-Network), which takes the advantage of multiple parallel Q networks to predict Q values collaboratively. In this model, the input of each Q network is the non-overlapping sub-region of the original game interface, and subsequently each Q network will study respectively what characteristics different sub-regions of the game interface have. Experimental results indicate that the performance of MEPLSPQNetwork exceeds that of DQN in three various game scenes.",60022281,Beijing University of Technology,Beijing,China,"['1712', '1709', '1707', '1705']",26.8,-0.07840909090909089,0.3602272727272728,1
349,349,Towards service discovery and autonomic version management in self-healing microservices architecture,"Microservices architectures (MSAs) contribute to building complex distributed systems by decomposing monolithic systems into a set of independent microservices. This makes it possible to design, develop and deploy scalable and flexible systems. However, various unexpected changes could happen during execution, such as a service upgrade, a sudden increase of traffic, or an infrastructural failure. In this cases, how to react autonomously to these changes without outages becomes a challenge to consider. A PhD project has been launched to propose a self-healing microservices architecture, which can adapt dynamically to inside and outside changes without human intervention. In this paper, we present the first results of a systematic state of the art in the field of self-healing MSA systems. As an entry point of our research, we focus on self-healing triggered by upgrade changes. The initial contribution is a new component of a version manager in our self-healing MSA solution, in relation with service discovery elements. This approach can provide an autonomic version management on both the application level and the system level, and helps to control services upgrading changes. We plan to validate our proposition in a company project use case by deploying it in an emulated production environment, and applying a chaos engineering approach.",60116488,Institut Polytechnique de Paris,Palaiseau,France,"['1712', '1709', '1707', '1705']",20.4,0.017979797979797978,0.39752525252525245,1
350,350,Ultrasound vascular image segmentation based on full convolutional aggregation neural network,"The concept of ultrasound therapy has been proposed long ago. However, most of the previous methods of ultrasound therapy destroy tissue through thermal effects and cause great damage to patients. In recent years, ultrasound cavitation therapy has caused extensive discussion and research due to its unique noninvasiveness. In order to achieve real-time access to the patient during treatment, the lesion area must be processed simultaneously and accurately. However, ultrasound images mostly have lower signal-to-noise ratio, contrast, and blurred edges. In order to solve the segmentation problem, this paper proposes a new segmentation model Du-net based on the full convolutional neural network. Under the premise of deepening the network depth to obtain more information, the Encoder- Decoder method and the layered aggregation mode are used to prevent the gradient explosion. Solving boundary segmentation problem by constructing joint network, In the case of a small data set, the data enhancement method using a suitable data set effectively increases the usable image features and achieves better results on the ultrasound blood vessel image.",60014643,Wuhan University of Science and Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",21.25,0.24553872053872056,0.4923821548821549,1
351,351,Urbanised real-time parking detection system using deep learning,The aim of this paper is about the creation of a Deep Learning Object detection Model which will be able to rightfully detect a vacant or occupied parking spot in any parking area regardless of the position and quality of the camera setup. The paper also promises to deliver a decentralised approach to parking space detection in order to minimise traffic congestion caused due to parking in metropolitan cities.,60109348,"Birla Institute of Technology and Science, Pilani – Dubai Campus",Dubai,United Arab Emirates,"['1712', '1709', '1707', '1705']",34.5,0.125,0.4666666666666666,1
352,352,Editorial message for the international workshop on designing and measuring cyber security in software architectures (DeMeSSA),"With the growing complexity of software and in particular of software-reliant systems and systems-of-systems, the focus of cybersecurity on network and code has been increasingly shifted to design and more recently to ""cybersecurity by design"" or ""design for cybersecurity"", where the software architecture is the keystone for enforcing cybersecurity. Early evidence of cyber risks, attacks and vulnerabilities enables efficient and effective cybersecurity solutions. Security measurement of software architectures is needed to produce sufficient evidence of cybersecurity level in the design phase. Moreover, software architectures have to support runtime security measurement to obtain up-to-date cybersecurity information. This is essential for self-protecting systems and self-adaptive cybersecurity solutions.",60033191,VTT Technical Research Centre of Finland,Espoo,Finland,"['1712', '1709', '1707', '1705']",21.0,0.22777777777777777,0.4138888888888889,1
353,353,Initial Generation of Concepts in Image Processing Based on the Algebra of Fourier-Dual Operations,"Abstract—Inductive concept generation in image processing on neural networks that perform the algebra of Fourier-dual model-determining operations is considered. A model of initial (i.e., when there are no earlier concepts) concept generation is proposed. The biological inspiration of the model is established. The phenomenon of cognitive saturation is proposed, which is expressed by stopping the growth of the performance evaluation of the formation of an inductive hypothesis with an increasing number of examples. The mechanism of this phenomenon is analyzed and the relationship with the information capacity of patterns of the internal representations of perceived images, due to the inherent characteristics of the cognitive agent, is given. The simulation results are given based on the example of the Darii syllogism inversion when the weights of links are recorded in plane and in volume.",60072485,"Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO",Saint Petersburg (ex Leningrad),Russian Federation,['1700'],22.166666666666668,-0.03125,0.21875,1
354,354,The afterlife of discarded woollens: Who is recycling my clothes?,"Purpose- This photo shoot aims to document and understand the process, present scenario, facilities and workers condition of wool recycling units in Panipat, a small town in northern part of India. The city emerged as the recycling hub when the owners of Panipat mills bought second-hand machines from Prato, Italy and started recycling wool and producing shoddy yarn. Panipat is acknowledged as the “cast off capital” and is a part of recycling $182 million value of worn clothes imported to India annually. Methodology- In total, 5 wool recycling units were visited for studying the processes and taking photographs. 20 unstructured interviews of workers, 5 unstructured interviews of factory owners, factory managers/ labor contractors each were conducted. Findings- The findings were categorized into three subheads: The processes, Worker condition and the present scenario. The process of recycling has been same since the inception. With the industry mainly driven by the unorganized sector, there is a lack of investment from the owners towards machinery up -gradation and worker well-being. The economic and social aspect of sustainability is lacking in the whole system. Poor working conditions, lowest worker wages and workers prone to respiratory disorders is the other face of the industry that is doing good to the planet by recycling waste. The industry is on the decline due to competition from the lightweight polyester blanket, almost of the same price, softer in hand feel and of better aesthetics. Large amounts of clothing lie without processing due to the slump in demand. The price of imports per kg has fallen by almost 3 times as compared to early 1990’s when it was approximately 50 Rs/kg to now at 16 Rs/kg now. The lightweight polyester substitute, excess supply of second-hand clothing and fall in demand of its recycled products posses many questions about the future of recycling fashion. This is a case where substitutes are cannibalizing sustainability efforts. Implications- The photos from this study have a direct implication on creating awareness of the social impact of overconsumption and over disposal. We need to think beyond eco-friendly disposal. At the time when we are concerned about “who made my clothes”, it is also the phase when we ask “Who is recycling my clothes” and what substitutes hamper recycling too.",60027220,National Institute of Fashion Technology India,New Delhi,India,['1706'],20.77777777777778,0.027793040293040285,0.32097069597069594,1
355,355,A recommender system for software architecture decision making,"Making the right design decisions for a software system is a difficult task. Inappropriate design decisions are often hard to reverse and can lead to high costs and a poor quality of the software product. To support architects in the decision-making process, we present a hybrid recommender system for software architecture decision making. The system provides recommendations for areas of system design and for design options within these areas. It uses two kinds of codified architectural knowledge for decision making: decision models for describing potential design options in a design space, and architectural profiles for documenting design decisions in different software systems. The developed recommender system is able to make recommendations early on in the decision-making process and provides more tailored recommendations the more software architecture knowledge is available. The system has been experimentally applied to microservice decision making.",60021931,Johannes Kepler Universitat Linz,Linz,Austria,"['1712', '1709', '1707', '1705']",19.857142857142858,0.09693650793650793,0.5228253968253969,1
356,356,To what extent formal methods are applicable for performance analysis of smart cyber-physical systems?,"The dynamic nature of complex Cyber-Physical Systems (CPS) introduces new research challenges since they need to smartly deal with changing situations in their environment. This triggers the usage of methodologies that keep track of changes and raise alarms whether extra-functional requirements (e.g., safety, reliability, performance) are violated. In this context, we investigate the usage of formal methods as support to provide a model-based performance evaluation of smart CPS. The main goal is to understand to what extent well-known performance models, specifically Queueing Networks, are suitable to represent these dynamic scenarios.",60136210,Gran Sasso Science Institute,L'Aquila,Italy,"['1712', '1709', '1707', '1705']",22.5,0.12270021645021645,0.4446158008658009,1
357,357,A reinforcement learning-based decentralized method of avoiding multi-UAV collision in 3-d airspace,"Recently, large-scale multi-UAV collaboration system have been proposed for mobile sensor network applications and the collision avoidance becomes the core of the scalable control for any multi- UAV system. We present a decentralized collision avoidance mechanism of cooperative unmanned aerial vehicles (UAVs) in three-dimensional airspace, which directly maps the observed environment information to a UAV's steer commands. We solve the problem on continuous state space and action space and design a multi-module reward function to decrease the collision rate of UAV-UAV and UAV-obstacle, deviation from the planned trajectory and the cost of turning angular velocity. Our method is based on the Distributed Proximal Policy Optimization (DPPO) algorithm with asynchronous training framework, which is a policy gradient of Reinforcement Learning algorithm to learn an optimal policy. Subsequently, we propose a multi-scenario multistage training process to our experiment as for a good convergence solution. After testing our method in non-stationary stochastic environments and conducting a contrast experiment, the result shows that our method is able to find collision-free policy for a large-scale multi-UAV swarm.",60009400,Nanjing University of Post and TeleCommunications,Nanjing,China,"['1712', '1709', '1707', '1705']",28.666666666666668,0.19999999999999998,0.2892857142857143,1
358,358,Image aided point-wise autonomous annotation for LiDAR data,"This paper presents an autonomous method to realize the annotation of LiDAR (Light Detection And Ranging) point clouds with the help of images. Different from directly labeling on point clouds, our approach first utilizes mature image segmentation method to derive pixel level labels of images. Point clouds are annotated through the corresponding relationship between 2D and 3D under the guidance of image labels. A point label rectification procedure is proposed using the 3D structure characteristics to reduce the error of annotation. Experimental results demonstrate our approach is able to annotate LiDAR point clouds and rectify the results effectively.",60025084,Shanghai Jiao Tong University,Shanghai,China,"['1712', '1709', '1707', '1705']",19.6,0.27222222222222225,0.5175925925925926,1
359,359,"The role of efl learners' autonomy, motivation and self-efficacy in using technologybased out-of-class language learning activities","This study aims to identify which technologybased out-of-class activities are more commonly used by Iranian efl learners outside language classrooms. Furthermore, it explored the relationship between the use of technologybased out-of-class language learning activities (tbocllas) by efl learners and three individual learner characteristics such as motivation, autonomy and self-efficacy. The participants of the study consisted of 100 Iranian efl learners who were asked to take part in the study by filling out four questionnaires regarding tbocllas, motivation, autonomy, and self-efficacy. The results revealed that among different tbocllas, receptive activities were relatively more frequent among learners than productive ones. Results also indicated that there was a strong positive correlation between technology-based out-ofclass language learning activities and Iranian efl learners' motivation levels. Moreover, it was found that there was a strong correlation between tbocllas and the efl learners' autonomy. In the same vein, the findings revealed a strong and statistically significant correlation between tbocllas and the learners' self-efficacy. Finally, the research findings suggested that learners' motivation, autonomy, and self-efficacy were all significantly contributing to the participants' use of technologybased out-of-class language learning activities. Among the above mentioned individual factors, motivation had the highest predictive value, and among self-efficacy and autonomy, the latter could better predict the use of tbocllas by the learners.",60118817,Majan University College,Muttrah,Oman,['1706'],23.333333333333332,0.17886363636363636,0.4985227272727273,1
360,360,Artificial intelligence in operating system,"The rapid advancement in artificial intelligence, semiconductor and electronic technology, software engineering and programming techniques as well as hardware interfaces and communication has raised the demand for advancement in operating system. In this article we have studied the classical and current operating systems and have proposed the advanced components such as new user interfaces, advanced human-to-machine interfaces, communication, artificial intelligence and advanced hardware technology etc. which are necessary for next generation operating systems.",60073441,Beijing Institute of Graphic Communication,Beijing,China,"['1712', '1709', '1707', '1705']",24.333333333333332,0.012396694214876042,0.5595041322314049,1
362,362,Effects of acute moderate intensity exercise on emotion based on beta power in EEG,"According to previous studies, high anxiety leads to an increase in beta power, while pleasure and relaxation of emotion reduces beta power. In this experiment, the International Standard Picture Stimulation Library(IAPS) was used to induce positive and negative emotions of subjects, and EEG signals were collected when subjects were looking at pictures. Comparing the beta power of positive and negative EEG induced by before and after exercise, we found that the power of beta stimulated by positive and negative pictures before exercise is generally greater than that after exercise. It indicates that subjects were happier when facing positive stimuli than before exercise, and less negative emotions were produced when facing negative stimuli than before exercise. In short, acute moderate intensity exercise can improve people's negative emotion in the face of negative stimuli. The purpose of this study is to explore the mechanism of the effect of acute moderate intensity exercise on emotion by analyzing beta power in late positive potential (LPP).",60122052,Southwest University,Chongqing,China,"['1712', '1709', '1707', '1705']",26.833333333333332,0.010521212121212122,0.4760242424242424,1
363,363,A systems-of-systems security framework for requirements definition in cloud environment,"There are many aspects that involve the development of secure software. Regardless of the development model, the verification and validation of security must always be present, in all environments and stages. Systems-of-Systems (SoS) refer to a complex system that comprises other systems (the constituent systems), which have operational and managerial independence, geographical distribution, emergent behavior, and evolutionary development processes. By integrating cloud computing applications and services into a complex existing system, many challenges arise, especially those related to security issues. In this paper, it is proposed a security framework to guide the planning and definition phases of security requirements for SoS considering agile methods for application development and a DevSecOps approach. By using a checklist and some questions to identify which security aspects should be included, security drivers were obtained to integrate cloud computing in a SoS context, taking into account the perspectives of existing IT Governance Model, IT Operational Model, and IT Processes. Additionally, it is emphasized the need for a human resources management that aims at the positive acceptance of organizational change by all involved.",60001430,Universidade Federal do ABC,Santo Andre,Brazil,"['1712', '1709', '1707', '1705']",25.285714285714285,0.11685606060606062,0.4642045454545454,1
364,364,Evaluation of pooling operations and regularization parameters in neural networks for drug-drug interaction extraction,"Recently, deep neural networks have been widely used in biomedical relation extraction, especially CNN and LSTM. Relation extraction is a classification task which uses pooling operations in neural networks to reduce dimensions and integration features and it uses regularization to prevent overfitting. This paper evaluates the performance of CNN and LSTM in Drug-drug interaction extraction. We discuss the models' performance differences using different pooling operations and regularization parameters. Firstly, regularization can prevent over-fitting effectively, but it is important to ensure that the regularization parameters are set within the correct ranges. Secondly, the max pooling is better than other single pooling methods. Max pooling outperforms the others alternatives because is the only one which is invariant to the special pad tokens that are appending to the shorter sentences known as padding.",60029322,Dalian Maritime University,Dalian,China,"['1712', '1709', '1707', '1705']",18.571428571428573,0.1392857142857143,0.5533882783882784,1
365,365,A novel type-based API search engine for open source elm packages,"Searching for API is a hard problem, as text is not commonly representative of what a program does. In this paper, we present Moogle, a type-based API search engine for open-source Elm packages, with an online demonstration1. In Moogle, queries are based on names or type signatures, whose adequate information is leveraged for matching APIs from open-source libraries. Moogle applies unification algorithm, where generic type signatures can be matched to concrete ones and vice versa. In order to optimize the performance of applied matches, Moogle stores information of type signatures in an AST-based graph model, by applying graph DBMS, Neo4j. Moogle also has its implementation on a parser to convert its DSL, MoogleQL, into AST data models or string queries. According to our test, Moogle outperforms its congeneric work, Elm-search2, on many aspects including search range and allowed patterns with acceptable trade-offs.",60073652,Tongji University,Shanghai,China,"['1712', '1709', '1707', '1705']",20.285714285714285,0.12023809523809524,0.31071428571428567,1
366,366,Full-wave 3D earthquake simulation using the double-couple model and the grid-characteristic method," Bagaev, Vasily I. Golubev, Yulia A. GolubevaOne of the destroying natural processes is the initiation of the regional seismic activity. It leads to a large number of human deaths. Much effort has been made to develop precise and robust methods for the estimation of the seismic stability of buildings. One of the most common approaches is the natural frequency method. The obvious drawback of this approach is a low precision due to the model oversimplification. The other method is a detailed simulation of dynamic processes using the finite-element method. Unfortunately, the quality of simulations is not enough due to the difficulty of setting the correct free boundary condition. That is why the development of new numerical methods for seismic stability problems is a high priority nowadays. The present work is devoted to the study of spatial dynamic processes occurring in geological medium during an earthquake. We describe a method for simulating seismic wave propagation from the hypocenter to the day surface. To describe physical processes, we use a system of partial differential equations for a linearly elastic body of the second order, which is solved numerically by a grid-characteristic method on parallelepiped meshes. The widely used geological hypocenter model, called the “double-couple” model, was incorporated into this numerical algorithm. In this case, any heterogeneities, such as geological layers with curvilinear boundaries, gas and fluid-filled cracks, fault planes, etc., may be explicitly taken into account. In this paper, seismic waves emitted during the earthquake initiation process are numerically simulated. Two different models are used: the homogeneous half-space and the multilayered geological massif with the day surface. All of their parameters are set based on previously published scientific articles. The adequate coincidence of the simulation results is obtained. And discrepancies may be explained by differences in numerical methods used. The numerical approach described can be extended to more complex physical models of geological media.",60000308,Moscow Institute of Physics and Technology,Moscow,Russian Federation,"['1706', '1703']",14.904761904761905,0.04124458874458875,0.38579895594601477,0
367,367,Impact of GST on spending behaviour of the consumers,"Goods and Service Tax (GST) is a single tax on the supply of goods and services. The statutory tax rates under GST came into effect from 1st July, 2017 which replaced all other applicable indirect taxes. The present study aims to analyse the relationship between income and spending behaviour and to measure the impact of GST on spending behaviour. The researcher has used Factor Analysis and ANOVA to test the hypotheses. The result showed that there is strong relationship between income and Electronic and Sport Equipments and no relationship between income and Wheat, rice, clothing, hair oil, soap, tooth paste, cosmetics, dry fruits, tobacco, fast food, internet connection, newspapers and magazines, fruits and vegetables, entertainment, vehicle maintenance and foot wares. The study also found that impact of GST is more on essential items than comfort and superfluous items.",115392322,Shri S.S. Shasun Jain College for Women,Chennai,India,['1706'],23.0,0.1087797619047619,0.4153273809523809,1
368,368,The Possibilities for Intelligent Analysis of Scientific Texts by Construction of their Cognitive Models,"Abstract: This paper provides a study of cognitive structures of scientific texts within the framework of the activity paradigm. We define mental actions as actions that are aimed at constructing new or reconstructing already existing abstract objects. As is typical for scientific communication, forms of implementing mental actions mediated by certain verbal units and textual techniques are considered as mental operations. This pilot study demonstrated the fundamental possibility of constructing a model of the intelligent structure of a scientific text, including an assessment of the textual representation of categories reflecting various mental operations, and the identification of its intelligent scheme. A formal presentation of mental operations used to “describe a phenomenon new to science” is proposed.",60110807,Federal Research Center Informatics and Management of the Russian Academy of Sciences,Moscow,Russian Federation,['1700'],23.2,0.11836219336219338,0.44004329004329,1
369,369,A study of over-the-air (OTA) update systems for CPS and IoT operating systems,"There is growing use of Internet-of-Things (IoT) and Cyber-Physical Systems (CPS) in industry, homes, cars, and other environments, and several operating systems have been proposed to manage these environments. The growing use of long-lived IoT and CPS has made them susceptible to obsolescence and change, just like ""normal"" software, demanding systematic support for periodic updates of their embedded software. However, there is little empirical data about the structure, architecture, specifications, and dependencies of these subsystems. This article presents an analysis of over-the-air (OTA) update support in 26 existing open-source IoT/CPS operating systems and embedded software projects, performed primarily by examining their documentation and supplementing with occasional source code examination. We found that seven projects give details of an OTA update mechanism; four projects do not report details of OTA update mechanisms, but third-party developers implemented specific solutions to support OTA updates using these projects; and the remaining 15 projects do not report a particular update capability at all in their documentation. This study will allow extending, organize, and compare OTA update capabilities of future IoT/CPS operating systems.",60007087,Universidad Técnica Federico Santa María,Valparaíso,Chile,"['1712', '1709', '1707', '1705']",29.5,0.050416666666666665,0.2833333333333333,1
370,370,Blueprints for architecture drivers and architecture solutions for Industry 4.0 shopfloor applications,"Industry 4.0 aims at evolving the current industrial processes towards directly connecting shopfloor machines to systems from different layers of the automation pyramid, such as Enterprise Resource Planning (ERP) or Manufacturing Execution Systems (MES). There are key functional and quality requirements that apply to most Industry 4.0 systems independent of the application domain, e.g., requirements related to interoperability, recoverability, security, and modifiability. Despite their importance, there is still a lack of understanding of (i) architecture drivers that focus on these quality aspects and (ii) architecture solutions for these architecture drivers that are adequate for a wide range of Industry 4.0 contexts. To contribute to filling this gap, we present in this paper (i) quality-centered architecture drivers derived from industrial cases, and (ii) architecture solutions based on the concepts of Digital Twins, Service-Oriented Architecture, and Virtual Automation Bus for four recurrent production plant scenarios. The architecture drivers and solutions presented in this paper were instantiated in different Industry 4.0 contexts, such as BaSys 4.0 (the German national reference project for Industry 4.0), and by the BaSys industry project partners.",60007411,Fraunhofer Institute for Experimental Software Engineering IESE,Kaiserslautern,Germany,"['1712', '1709', '1707', '1705']",35.6,0.05555555555555556,0.38388888888888884,1
371,371,Transfer learning for image classification using hebbian plasticity principles,"Transfer learning is a deep learning technique has proved to be of great importance. However, most of the standard transfer learning algorithms are designed to repeat the same method for fine-tuning of the weights on the target domain. If we try to investigate the human brain?s mechanism of learning a new complex concept based on a simple and basic concept, we can say, it is different from just the repetition of the same method of learning on a different dataset. In this article, we have introduced a novel transfer learning algorithm referred to as HTL (Hebbian transfer learning) using synaptic plasticity. The Hebbian theory, introduced by Donald Hebb, explains the ""associative learning"" in which the simultaneous activation of the brain cells positively affects the increase in the synaptic connection strength between the individual cells. This particular behaviour of Hebbian learning, makes it a very viable candidate for discriminative learning for the search of the specific feature for the task of object recognition or image classification. It helps connection weights of the learned model to adapt as per task dataset using numerical methods defining plasticity principles. Learning to discriminate between instances of different classes, over a variable number of classes within the dataset space defined by the task at hand, can be the result-oriented approach for classification problem. Extensive experiments verify that HTL, using synaptic plastic behaviour in heterogeneous transfer learning task does better than the standard state of the art methods of transfer learning on the cross-domain image classification task.",60009387,"Dongguk University, Seoul",Seoul,South Korea,"['1712', '1709', '1707', '1705']",27.77777777777778,0.10137741046831956,0.3488095238095238,1
372,372,Architecting for scale: The case for systematic software reuse in managing technical debt in start-ups,"Most start-ups aspire to become non-start-ups someday. One would argue then that architecting for scale means doing it right the first time. However, start-ups usually start with a single idea in search of market fit. Taking time to design and implement a scalable architecture is time that is not spent responding to customer demands and is usually not a priority. This short-term vision may lead start-ups to accumulate technical debt. This work is geared towards understanding how start-ups find a viable trade-off between customer demands and long term goals. We conduct expert interviews at start-ups and scale-ups with the hypothesis that reusing software for the management of technical debt would allow a start-up to quickly respond to the demanding needs of the market in the long run.",60012937,Universiteit Antwerpen,Antwerpen,Belgium,"['1712', '1709', '1707', '1705']",18.142857142857142,0.11712454212454212,0.3141025641025641,1
373,373,The construction method of geographic knowledge graph ontology model based on GML,"Geographic ontology model is the conceptual model of geographic knowledge graph and the logical basis for constructing the pattern layer of geographic knowledge graph. In the classification of geographic ontology research, geographic ontology model is in the category of domain ontology. It is a set of abstract structures to express ontology according to the spatial location, attribute characteristics and relational characteristics of geographic data. This paper discussed the logical components and architecture of geographic ontology, designed the geographic ontology model reference to GML, described the model using OWL language, and constructed the geographic ontology model based on GML. The geographic ontology model comprises three sub-models: element model, geometric model and spatial relation model. Finally, based on Protégé ontology construction tool, this paper designed the semantic description of geographic entity and realized the construction of geographic ontology system.",101852788,Information Engineering University,Nanjing,China,"['1712', '1709', '1707', '1705']",22.833333333333332,0.16666666666666666,0.5,1
374,374,Promoting trust in interoperability of systems-of-systems,"The ability of constituent systems to collaborate effectively in a System-of-System (SoS) depends on the extent of interoperability achieved among them. However, communication among constituents relies on common agreements made by intermediaries in many levels of interoperability, increasing the cost and barriers of collaboration. In this scenario, this work presents a Trust Interoperability Blockchain Architecture (TIBA) to enable trust in the interoperability of SoS. TIBA will be evaluated though simulations in a large company in the context of Industry 4.0, considering the Product as a Service (PaaS) business model. We expect simulations results reveal that TIBA can contribute towards the assurance of trust interoperability in SoS.",60008088,Universidade de Sao Paulo - USP,Sao Paulo,Brazil,"['1712', '1709', '1707', '1705']",21.2,0.25357142857142856,0.5571428571428572,1
375,375,Protein image classification based on convolutional neural network and recurrent neural network,"Proteins are an essential component in the cell where the functions are executed to enable life. At present, the manual evaluation and classification of protein images is not practical given the current situation for generated images on a large scale. Hence, the requirement of automating protein image classification can be quite useful. Until now, classical machine learning and convolutional neural network algorithms have achieved results in image classification without the desired level of accuracy. Under the circumstances, the research aims to propose an accurate classified model for protein image classification by combining a convolutional neural network with a recurrent neural network.",60102426,Xi'an Jiaotong-Liverpool University,Suzhou,China,"['1712', '1709', '1707', '1705']",20.2,0.1306122448979592,0.25170068027210885,1
376,376,Effects of activation functions and optimizers on stock price prediction using LSTM recurrent networks,"In stock exchange market, investors need to decide which shares to buy based on their future market value. Because of the variable market, it is obligatory to have a reliable prediction of the values of the stocks. Now-a-days the machine learning system can forecast well than the contemporary stock prediction methods. Machine learning system provides a scientific demonstration based on sample data to forecast. In this work, Linear Regression (LR), Support Vector Regression (SVR) and, Long Short-Term Memory (LSTM) algorithms are used to predict stock market prediction. Among the several features, the most important feature has been selected by using the feature selection algorithm, which is closing price. The effects of different activation functions and optimizers are experimented on stock price prediction using LSTM networks.",60004766,East West University,Dhaka,Bangladesh,"['1712', '1709', '1707', '1705']",17.857142857142858,0.14523809523809522,0.3988095238095238,1
377,377,Brand awareness and preference towards qualcomm snapdragon in mobile among consumers,"Consumers' conscience is satisfied according to their needs and desires, so they choose the product from which they get maximum value and satisfaction. For any business Marketing plays a vital part and advertising being the most important part of marketing. The researchers focused on brand awareness of the American semiconductor and telecommunications equipment company Qualcomm Snapdragon, which designs processors and wireless telecommunications. As a part of this research process, the researchers focuses not only on brand awareness and preference towards Qualcomm Snapdragon(QS) and also consumers awareness of Qualcomm Snapdragon products, who are their major competitors and how this company can exhibits its USP in the competitive Indian economy. This survey was also conducted to understand the factors influencing the consumers to choose Snapdragon product on their mobile phone, their satisfaction level and to address the gap between consumers need versus their level of satisfaction. This survey was done through a primary data collection with a deep research of the customer profile and various others factors taking into consideration. Chi Square analysis is done based on responses from 190 respondents out of 220 sample chosen for the study. After thorough analysis some recommendation were offered which would help to know about Brand Awareness and Preference of Qualcomm Snapdragon towards consumers and finally a brief conclusion of the study is drawn.",122429542,Ramaiah Institute of Management,Bengaluru,India,['1706'],27.375,0.1784090909090909,0.5575757575757576,1
378,378,An exploration and experiment tool suite for code to architecture mapping techniques,"Reflexion modeling can be used to validate that source code conforms to an intended architecture. However, it requires a mapping of source code modules (e.g., classes) to (software) architecture elements. We have developed a tool suite that allows for evaluation and exploration of automatic techniques to map source code modules to architecture elements. The suite includes a reusable core component and tools to define the architecture, define and run experiments with mapping strategies, and explore the results of these experiments. The experiments can be executed locally or in a remote high-performance computing environment.",60108011,"Linnaeus University, Växjö",Vaxjo,Sweden,"['1712', '1709', '1707', '1705']",18.6,0.0,0.25,1
379,379,Discovering architectural rules in practice,"Architecture conformance checking is an important technique to verify whether a software system's implementation adheres to predefined architectural rules. The adherence to architectural rules is crucial, since architectural rules are intended to ensure that fundamental properties are correctly implemented in the source code. A lot of tools have been proposed and developed for automatic conformance checking. They are also successfully applied in industry. However, those tools mainly focus on the validation of static dependencies between modules or on ensuring the adherence to the layered architecture. In this poster, we present an industrial case study which discovers architectural rules from three industrial projects. This study shows that software architects also define other types of architectural rules that are not yet covered by state-of-the-art conformance checking tools. The architectural rules found in the projects are categorized into architectural rule categories. We use four representative tools as examples and show that the tools are able to formalize only a specific extent of the discovered rules. The results of the study motivate for improving existing tools and to collect further examples of architectural rules that can potentially be reused in projects with similar characteristics.",60028229,Universität Hamburg,Hamburg,Germany,"['1712', '1709', '1707', '1705']",19.0,0.16369047619047622,0.6077380952380953,1
380,380,Lung cancer detection with 3D ensemble convolution neural network,"Lung cancer, with the highest morbidity and mortality in 21th century, is difficult to cure because people often fail to detect it in time. With the blossom of artificial intelligence and big data research, people seem to see the dawn of solving this problem. Computer aided diagnosis (CAD) system of lung cancer based on deep learning techniques have been a popular research topic, which aims at utilize the computer system to analyze the possibility of cancer which is beneficial to the treatment in early stages and increase the possibility of recovery. Here we propose an integrated network system based on 3D Convolutional Neural Network (CNN), consisting mainly of two different 3D CNNs. And finally we reached 82.89% accuracy by combining 3D CNNs? feature outputs and using the softmax activation function to get the final disease probability. Also, we modified the decision making method to make the final result tending to get the negative output to decrease the false positive rate and the true positive rate reached 90.38% eventually.",60007711,Jilin University,Changchun,China,"['1712', '1709', '1707', '1705']",28.0,-0.03698752228163994,0.6278966131907308,1
381,381,Effect of artificial intelligence on customer relationship management of Amazon in Bangalore,"Electronic commerce or ecommerce is a term for any type of business, or profitable transaction, that includes the transmission of information transversely the Internet. It covers a range of unlike types of businesses, from consumer-based retail sites, through sale or music sites, to business connections trading goods and services among companies. It is currently one of the most significant aspects of the Internet to develop. Ecommerce allows customers to electronically exchange goods and services with no barricades of time or distance. Electronic commerce has prolonged rapidly over the past five years and is forecast to continue at this rate, or even hasten. In the near future the limitations between ""conventional"" and ""electronic"" commerce will become gradually blurred as more and more businesses move The analysis and advice presented in this is based on the data collected from the study conducted in Bangalore with a sample size of 100 which includes 63 male respondents and 37 female respondents within the age group of 18 to 40 years and above. All the data was represented in the form of tables and charts (pie charts). Correlation analysis has been used to examine the hypothesis and the findings of the survey by using MS-Excel. During the study it was found that Artificial Intelligence has a major role to play in managing the customer relationship of e-commerce giant like Amazon and people are now getting familiar about the benefits that Artificial Intelligence brings and how it totally enhances their user experience.",122429542,Ramaiah Institute of Management,Bengaluru,India,['1706'],27.333333333333332,0.04553571428571429,0.5013227513227513,1
382,382,Pathological image classification of breast cancer based on residual network and focal loss,"This paper proposes an improved deep residual neural network for the classification of breast cancer as either benign or malignant. Inspired by the success of using focal loss in object detection, we present a new focal loss for pathological image classification to solve the class imbalance problem encountered during training stage. Furthermore, we introduce a multi-scale acquisition structure into ResNet to get a larger range of receptive fields for each network layer and represent features at multiple scales. Data enhancement and migration learning are also used to optimize the initial parameters solving the problem of overfitting in the network. Experimental results show that our approach achieves higher accuracy of classification compared to previous methods.",60010953,Donghua University,Shanghai,China,"['1712', '1709', '1707', '1705']",22.8,0.06196969696969697,0.2421212121212121,1
383,383,Bi-directional generation between attributes and images,"This paper investigates the problem of generating images from visual attributes and vice versa. Given the prevailing research of image recognition, the bi-directional generation between attributes and images is rarely explored due to the challenges of learning a good bidirectionally generative model and the different structure of these two modalities. To address this problem, the bidirectional generative model (BGM) which based on a variant of variational auto-encoders (VAEs) is proposed in this paper. The attributes in BGM are represented by attribute functions. The attribute functions directly ground the meaning of attributes in visual representations. They also allow the BGM to generate images and attributes bi-directionally. The BGM is applied to 3D chairs dataset to verify its validity. The BGM achieves 85.2% and 81.7% accuracy in attribute inference and image reconstruction tasks, respectively. The experimental results demonstrate the efficiency of the BGM.",60007711,Jilin University,Changchun,China,"['1712', '1709', '1707', '1705']",15.666666666666666,0.11944444444444444,0.375,1
384,384,Efficient Provision of Service Function Chains in Overlay Networks using Reinforcement Learning,"IEEESoftware-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies facilitate deploying Service Function Chains (SFCs) at clouds in efficiency and flexibility. However, it is still challenging to efficiently chain Virtualized Network Functions (VNFs) in overlay networks without knowledge of underlying network configurations. Although there are many deterministic approaches for VNF placement and chaining, they have high complexity and depend on state information of substrate networks. Fortunately, Reinforcement Learning (RL) brings opportunities to alleviate this challenge as it can learn to make suitable decisions without prior knowledge. Therefore, in this paper, we propose an RL approach for efficient SFC provision in overlay networks, where the same VNFs provided by multiple vendors are with different performance. Specifically, we first formulate the problem into an Integer Linear Programming (ILP) model for benchmarking. Then, we present the online SFC path selection into a Markov Decision Process (MDP) and propose a corresponding policy-gradient-based solution. Finally, we evaluate our proposed approach with extensive simulations with randomly generated SFC requests and a real-world video streaming dataset, and implement an emulation system for feasibility verification. Related results demonstrate that performance of our approach is close to the ILP-based method and better than deep Q-learning, random, and load-least-greedy methods.",60022381,Beijing Jiaotong University,Beijing,China,"['1712', '1710', '1708', '1706', '1705']",22.22222222222222,0.10333333333333335,0.454537037037037,1
385,385,Eye Blink Detection Using Back Ground Subtraction and Gradient-Based Corner Detection for Preventing CVS," All rights reserved.Many individuals experience eye discomfort and vision problems when viewing digital screens for extended periods leading to Computer Vision Syndrome (CVS). The solutions to digital screen- related vision problems are by insisting suitable preventive actions by obtaining regular eye care. The proposed work uses Viola Jones algorithm for detecting the eyes, eye blink using background subtraction, gradient based corner detection and it is capable of detecting common cases of fatigued behaviour linked with prolonged computer use by tracking the eye blink rate. Hence, this proposed system could significantly reduce the symptoms among regular computer users leading to improved health habits.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],25.75,0.09166666666666666,0.3420940170940171,0
387,387,Fast and Area Efficient Implementation of RSA Algorithm," All rights reserved.Efficient hardware implementations of public-key cryptosystems have been gaining interest in the past few decades. To achieve the goal, a high frequency as well as low latency Rivest-Shamir-Adleman (RSA) cryptosystem is reported in this paper. To configure such cryptosystem shift-add multiplier have been re-constructed and binary digit based modular exponentiation circuitry is proposed. Such exponentiation circuitry has been implemented through binary bit distribution technique, where, most significant bit (MSB) has been discarded for the implementation, owing to increase the operating frequency. The functionality of the reported algorithms were justified and compared in Hardware Description Language (HDL), simulated in Modelsim and synthesized in Xilinx ISE 14.2 platform. The proposed hardware implementation of RSA algorithm has a maximum frequency of operation of 545 MHz and 298 MHz for the bit sizes of 8 and 64 respectively. The proposed method shows improvements in terms of speed as well as in number of Look-up-tables (LUTs). Moreover, application-specific integrated circuit (ASIC) implementation of such cryptosystem of RSA was carried out through Encounter® RTL Compiler v11.10-p005-1 of Cadence® tool.",60107379,National Institute of Technology Meghalaya,Shillong,India,['1700'],22.0,0.08954545454545454,0.4604545454545454,0
388,388,An Efficient Sentiment Analysis Approach for Product Review using Turney Algorithm," All rights reserved.Sentiment analysis can be done by means of Classification and its most important tasks are text categorization, tone recognition, image classification etc. Mostly the extant methods of supervised classification are based on traditional statistics, which can provide ideal results. The main aim is to increase the accuracy and to report the manufacturer about the negatives of the product. The major problem is categorization of sentiment polarity, which is the problem of sentiment analysis. There are two levels of categorization and they are Review-level Categorization and Sentence-level Categorization. Categorization of review-level becomes arduous when we attempt to classify the reviews respect with their specific rating related to star-scaled. Second, Review-level Categorization has a drawback in Implicit-level sentiment analysis. Mostly SVM, Naïve Bayesian and Decision Tree are mainly used to improve the efficiency of classification. Amazon Dataset is used as Dataset in proposed system to improve the accuracy of Turney algorithm. Semantic Orientation (SO) with Point wise Mutual Information yields good results than other classification methods. The review level gets subjected as positive value, on acquaintance of positive average SO. On the other hand, the review level acquires a negative level in accordance with attainment of negative average SO.",60105818,M.Kumarasamy College of Engineering,Karur,India,['1700'],16.666666666666664,0.1543642951251647,0.5101119894598155,0
389,389,Medical Cyber Physical Systems and Its Issues," All rights reserved.In the previous decade, many technologies have attracted attention from several research communities. Internet of Things (IoT) is main invention of the recent/ past decade. When these smart devices or internet connected devices are interact together, then they create a cyber infrastructure. These cyber infrastructures face several serious concerns privacy, trust, security, etc. These smart devices make an automatic environment (executed without the intervention of a human) in applications likedefense, manufacturing, e-healthcare, etc. In e-healthcare, these devices built the structure of Medical Cyber Physical System (MCPS). MCPS are facing several critical issues and challenges in current era, i.e., several attacks, issues and challenges which we require to overcome in current and next decade to provide efficient and reliable service to patients. MCPS is need of smart healthcare and require attention from several research communities towards its raised issue. Hence, this article provides a detailed study about CPS, MCPS, mitigated attacks on same architecture (CPS and MCPS), issues and challenges in CPS/ MCPS, including several research gaps in CPS/ MCPS (with opportunities for future researchers).",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.666666666666668,0.039980158730158734,0.278670634920635,0
390,390,Docking linear ligands to glucose oxidase,"GOX (3QVR), glucose oxidase, is an oxidoreductase enzyme, which has found many applications in biotechnology and modern diagnostics with typical assays including biosensors useful in the determination of free glucose in body fluids. PEI (polyethylenimines) are polymer molecules made up of amine groups and two aliphatic carbons, which are cyclically repeated. PEI are transfection reagents which, using positively charged units, bind well to anionic DNA residues. During the studies on GOX, PEI were used both in their linear and branched structures. Rhombellanes, RBL, are structures decorated with rhombs/squares. The aim of the paper is to study the interactions of two kinds of linear ligands: PEIs (Polyethylenimines) and CHRs (ethers of Hexahydroxy-cyclohexane) with the glucose oxidase enzyme, GOX (3QVR). To understand the structure-activity relationship between the GOX enzyme and the linear ligands PEI and CHR, two steps of docking simulation were performed; mapping the whole area of the 3QVR enzyme and docking on the first and second surface of the enzyme, separately. The studied ligands interacted with amino acids of GOX inside the protein and on its surface, with stronger and shorter bonds inside of the protein. However, long chain ligands can only interact with amino acids on the external protein surface. After the study, two domains of the enzyme were clearly evidenced; the external surface domain more easily creates interactions with ligands, particularly with CHR ligands.",60024615,Ludwik Rydygier Collegium Medicum in Bydgoszcz,Bydgoszcz,Poland,['1701'],22.6,0.18003565062388593,0.413458110516934,1
391,391,Diabetics Retinopathy Vision Analysis using Image Identification Service Analysis Approach," All rights reserved.Retinopathy is one of the leading causes of visual impairment in the developed world, it is provoked by complications of mellitus. The consequence of retina complications are exudate in retina patients perceive no symptoms until visual loss develops. The employment of digital images for diagnosis of eye diseases could be exploited for computerized early detection of exudate from retinal image. In existing System, the blood vessel is detected using morphological operations. To overcome the disadvantages of the existing system the proposed method Exudate Image Identification (EII) approach which will track the images as exudate and non-exudate and it categorize the image with the criteria of mild, moderate and severe based on the captured images. The small exudates are identified with the green channel images. From the images the exudates are calculated with the proposed blood vessel segmentation and optical segmentation algorithm. From this the exudates are calculated with the method called parametric analysis, which can be used for the quick analysis of the exudate evaluation of a Diabetic Retina (DR).",60012454,Kumaraguru College of Technology,Coimbatore,India,['1700'],21.625,0.041666666666666664,0.3,0
392,392,A Mean Model Based Incremental Learning Technique for Extreme Learning Machine," © 2019 Procedia Computer Science. All rights reserved.Development of efficient methods for processing the online data is interesting as well as challenging in the computing scenario of data intensive applications, especially in streaming. Because of the inherent computational nature of Extreme Learning Machine, the non-iterative learning mechanism, it has undergone serous studies and exploitation especially in the domain of online data analysis. This paper gives a simple and effective strategy for updating the learned parameters, the knowledge of a machine learning system, in a computationally better perspective comparing with the existing state-of-the-art learning techniques. The performance of different measures for the central tendency is analyzed in this work. It is found that the results are comparable in respect of normal models. The overall performance of the proposed method with LIBSVM data sets gives an interesting direction for the improvement of learning machines for online data processing.",60031566,University of Kerala,Thiruvananthapuram,India,['1700'],21.0,0.20192307692307693,0.6274725274725275,0
393,393,Secured Reversible matrix embedding based on dual image using Integer wavelet and Arnold Transform, All rights reserved.Steganography is the art and science of hiding information. In Steganography host image is destroyed and cannot be attained to the original state. In a sensitive area such as military and medical recovery of the original cover medium is required without any loss. A special case of data hiding that retrieves the cover media and secret information without a loss of a pixel is known as reversible data hiding. In this paper reversible data hiding technique is proposed to improve the security and enhance the capacity; a hybrid model of integer wavelet transform and Arnold transform are used. The cover image is decomposed into the integer wavelet sub-band; each sub-band is further scrambled using Arnold transform before embedding scrambled secret information. In this work dual image embedding mechanism is used such that it makes matrix embedding reversible without any bookkeeping data. The experimental result shows that the proposed method provides high embedding capacity.,60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.5,0.04362637362637363,0.5316483516483517,0
394,394,Secure Hash Authentication in IoT based Applications," All rights reserved.Secure authentication while communicating data between sender and receiver nodes is a key concept when providing Internet of Things as a service. Hash algorithms can provide such an authentication mechanism for IoT based applications. The most recent secure hash algorithm technique standardized by the NIST is SHA-3. SHA-3 is fully apt in ensuring authentication for a sender and receiver transaction. A novel signature generating technique based on SHA-3 is presented in the paper. Two of the popular IoT communication models of publish subscribe and request response are examined under this authentication scheme. The sender generates a unique hash code for the data that it is about to send. This hash code serves as the authenticating token for the transaction. Mechanisms for the sender receiver interaction are built into the program codes in both the simulated communication models. The system architecture also manages interaction of the receiver with the cloud. This interaction ensures proper authentication through the mechanisms and api(s) provided by the cloud service providers, and these mechanisms are also integrated into the simulation. Both the cloud services used in the system architecture, i.e. cloud messaging as a service, and cloud database as a service ensure that the sender's identity is verified. In this way a blanket authentication system is set up for the aforementioned IoT architectures.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],15.714285714285714,0.2475,0.585,0
395,395,Definable transformation to normal crossings over henselian fields with separated analytic structure,"We are concerned with rigid analytic geometry in the general setting of Henselian fields K with separated analytic structure, whose theory was developed by Cluckers-Lipshitz-Robinson. It unifies earlier work and approaches of numerous mathematicians. Separated analytic structures admit reasonable relative quantifier elimination in a suitable analytic language. However, the rings of global analytic functions with two kinds of variables seem not to have good algebraic properties such as Noetherianity or excellence. Therefore, the usual global resolution of singularities from rigid analytic geometry is no longer at our disposal. Our main purpose is to give a definable version of the canonical desingularization algorithm (the hypersurface case) due to Bierstone-Milman so that both of these powerful tools are available in the realm of non-Archimedean analytic geometry at the same time. It will be carried out within a category of definable, strong analytic manifolds and maps, which is more flexible than that of affinoid varieties and maps. Strong analytic objects are those definable ones that remain analytic over all fields elementarily equivalent to K. This condition may be regarded as a kind of symmetry imposed on ordinary analytic objects. The strong analytic category makes it possible to apply a model-theoretic compactness argument in the absence of the ordinary topological compactness. On the other hand, our closedness theorem enables application of resolution of singularities to topological problems involving the topology induced by valuation. Eventually, these three results will be applied to such issues as the existence of definable retractions or extending continuous definable functions. The established results remain valid for strictly convergent analytic structures, whose classical examples are complete, rank one valued fields with the Tate algebras of strictly convergent power series. The earlier techniques and approaches to the purely topological versions of those issues cannot be carried over to the definable settings because, among others, non-Archimedean geometry over non-locally compact fields suffers from lack of definable Skolem functions.",60021361,Uniwersytet Jagielloński w Krakowie,Krakow,Poland,['1701'],22.5,0.08767006802721086,0.48880952380952375,1
396,396,A Contemporary Research on Perceptual Expert System for Medical Diagnosis through Neural Dust Sensor," All rights reserved.In the past few years many researches have been dedicated towards Neural dust sensor such as Deep Brain Simulation (DBS), Brain Machine interface (BMI), Ultrasonic backscattering system and so on. Mainly the Brain-Machine Interface is considered as the neural interface system that can be usable for a lifetime and to increase the life span of the sensor with the implementation of wireless electromagnetic neural interface. By implementing all this to detect the blood clot in human brain and to reduce the blood clot using ultrasonic waves and further other implementation in medical field. And, Neural Dust sensor is considered as the central nervous system of a particular system. This study aims to provide a review on usage of neural dust sensor in medical diagnosis.",60107090,Hindustan Institute of Technology and Science,Chennai,India,['1700'],25.4,0.01987179487179487,0.28012820512820513,0
397,397,Intrusion Detection for Enhancing RPL Security," All rights reserved.Internet of things is a new paradigm that connects the internet to the physical objects of different domain viz. home automation, human health services, and industrial process automation and environmental monitoring. It is deeply presented in our daily activities through various devices. The devices connected with the internet bring many benefits but simultaneously bringing the security issues also. For protecting the network and information systems the intrusion detection system is an important tool. However traditional techniques used for intrusion detection are not sufficient to protect the network consists of specific characteristics like constraint resourced devices and specific protocol stacks. In this paper, we proposed an intrusion detection system for RPL (Routing Protocol for Low power and lossy networks) which is focused on WSN and constrained resources. Proposed IDS follows detection of an attack, IDS placement strategy, and validation process.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],17.75,0.07972027972027972,0.3844155844155844,0
398,398,Towards User Profiling from Multiple Online Social Networks," All rights reserved.Social media networks are exponentially growing and it leads us to challenging issues in independent user assign assumption from the Big Data prospect. The main objective of the user profile is to generate a profile for the users by grouping user intelligence. For effective marketing and advertisement accurate user profiling is necessary in personalized endorsement system. For Instance, Twitter users can address their profile with 'narrative tags. The tags deliver a user explanation and used to retrieve smoothen data and another implementation of Yelp. On food, users desire accurate profiling for example, it will notably upgrade presentation on suggesting restaurants to the user. This work, we endorse a hypothesis for providing a profile user perception in online social medias. The mechanism may vary in profiling users by depending on its purpose and applications. The study of dissimilar implementations used in user profiling is under the extent of fortune aspires. The proposed model is used to attain the advanced activity to endorse modules in groups of members.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],16.9,0.25,0.4909722222222222,0
399,399,Sketch based image retrieval using grid approach on large scale database," All rights reserved.Several approaches are found in study for image retrieval from the database. A sketch based system is an efficient method which does not require the user to have a high skill to draw the query sketch. Sketch-to-image matching system on a large-scale image database should ensure that the system always tries to find correct matches for a given sketch query. In this paper, we present an efficient method for image retrieval from large database using sketch as a query image. Features are extracted from the image by placing a non-overlapping grid and overlapping grid over the image, respectively. Using a weighted similarity approach, the most similar images to the query are then retrieved from the image dataset. For performing experiments images of flickr15k dataset are used. The proposed method shows excellent retrieval performance in comparison to methods available in the literature.",119750813,Akkamahadevi Women's University,Bijapur,India,['1700'],18.0,0.2415873015873016,0.41873015873015873,0
400,400,Object Detection in Underwater Acoustic Images Using Edge Based Segmentation Method," All rights reserved.Image segmentation techniques play a vital role in partitioning the image into segments. These techniques are used for detecting the objects in the images. The real challenge in the acoustic image segmentation lies in differentiating the sea floor, sediments and the objects. Due to the typical characteristics and low resolution of the acoustic images, segmentation techniques such as region based, morphological based and edge based methods are not suitable. The sediments will also be traced along with the objects that makes the detection process a very difficult one. In this research paper, edge based segmentation method that uses the morphological operations for identifying the edges followed by a object tracing algorithm is proposed. The images used in this work are captured in real time using Edgetech 4125 Side scan sonar device. The acoustic images are first pre-processed using Wiener and Median filters and a morphological gradient is obtained by subtracting the morphologically dilated and eroded image. Next the edge map of the acoustic images are obtained using binarization method by which the object's boundary is made visible. Finally a Moore's object tracing algorithm is used for detecting the objects in the images.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],19.5,-0.03888888888888888,0.47986111111111107,0
401,401,Examine the role of transformational leadership in entrepreneurial orientation and innovation: Explain the mediating and moderating role of learning-orientation,"Understanding the needs and expectations of customers and responding to changes in the market plays a key role in organization’s success. For this purpose, it is inevitable to employ the introverted strategic orientations of entrepreneurship and learning orientation in organizations. Also, the need for continuous organizational change in today's dynamic and changing environmentsis the existence of visionary, strategic, or more clearly transformational leaders. Therefore, in this research, it is attempted to examine the relationship between transformational leadership, organizational entrepreneurship and innovation by examining the mediating and moderating role of learning orientation. This study was conducted in a sample of 368 senior managers of small and medium enterprises active in Iran’s food industry in 2016using a multi-stage cluster sampling method. The results of the analysis of the data collected with LISREL and PLS software show that the transformational leadership style, directly and indirectly through learning orientation, is a significant driving force in enterprise entrepreneurship orientation. Evidence also support the mediating role and lack of supportingthe moderating roleof learning orientation in the relationship between transformational leadership and entrepreneurship orientation in small and medium enterprises active in Iran’s food industry.",60027546,Payame Noor University,Tehran,Iran,['1700'],26.714285714285715,0.05069444444444445,0.5270833333333333,1
402,402,A denotational semantics of textually aligned SPMD programs,"We discuss the benefit of enforcing textual alignment in programming languages proposing unstructured SPMD-like collective operations. Our study is based on a simple language which provides support for global synchronization barriers. A formal definition of textual alignment, based on an operational semantics, is considered. We prove that this property entails the absence of deadlocks. Finally, we provide a compositional denotational semantics which is equivalent to the operational semantics for textually aligned programs.",60029689,Universite d'Orleans,Orleans,France,"['1712', '1703']",14.4,-0.003125,0.3392857142857143,1
403,403,An efficacious intellectual framework for host based intrusion detection system," All rights reserved.Intrusion detection systems (IDS) are indispensible for all types of networks to protect them from the intruders. The IDS have to process millions of network packets with many features, which delay the detection of anomalies. To understand the attacks of the past and to design proper tools to defeat their impending peril, Host-based IDS or HIDS, establishes to be a robust design. An Efficacious Intellectual Framework for Host based Intrusion Detection with Rule Structure Generation and Pattern Matching algorithm sets the rule structure for the unknown attack generated by using Association Rule Mining in the Map Reduce Framework. It is accomplished in two stages. In the first stage, an efficacious Rule structure is generated using Intellectual method. In the second stage, Brute Force algorithm pattern matching algorithm is utilized in the proposed framework. It is proper to audit and review logs for malicious activity. Notably intrusions are rare after proven analysis to prevent the attacks to happen. The present HIDS establishes to be a robust design for understanding of attacks of the past and determining effective methods to defeat their future threats.",60015537,Mother Teresa Women's University,Kodaikanal,India,['1700'],18.5,0.146875,0.35989583333333336,0
404,404,Image Dehazing using Improved Dark Channel Prior and Relativity of Gaussian," All rights reserved.Bad climatic weather conditions occur in our daily life are snow, sandstorm, mist, haze and fog etc. These various atmospheric particles affect the natural scene and the visibility will be tampered. Different dehazing methods are used to restore the visual perception of the image, increase the natural panoramic view and preserve the structural features of the image. Poor visibility becomes a significant issue for most outdoor vision applications. Image dehazing is a highlighted research area because of its real time applications in surveillance systems, driver assistance system especially for the people who resides in hilly areas where mist and haze is prominent. This paper presents an modified dark channel prior based image dehazing system with an enhanced and refined transmission map constructed by utilizing the RGB and YCrCb color system. Transmission map is constructed and estimated from combined airlight component obtained from the above said color models. In this work, we compute the Relativity of Guassian for RGB and YCbCr color space to produce guidance image. The both guidance images thus obtained are applied to guided filter for smoothening. Finally, hazeless image reconstruction is performed by utilizing the guidance images obtained from the previous step. In this proposed work, we focus on improving the transmission map by utilizing the concept of Relativity of Gaussian and Guided filter. We can find that the proposed method does not over enhance the images. Results analysis focuses on investigating the efficiency of proposed method by reconstructing the image without distortion, with no color artifacts and better aesthetic visual image.",60031566,University of Kerala,Thiruvananthapuram,India,['1700'],19.846153846153847,0.07791666666666666,0.41708333333333336,0
405,405,Privacy Preservation and Signature Aggregation for Medical Data," All rights reserved.Remote healthcare monitoring systems have been successful and are present at the vanguard of the technological revolution of the 21st Century. These systems make use of wireless body area network (WBAN) as one of their major components that is responsible for recording the medical parameters of a patient's health and transmit them to the server where they can be diagnosed. These networks, sometimes also make use of local processing units (LPUs) such as your mobile devices for transmission of the recorded data. Unfortunately, this wireless transmission of data increases the number of risks involved with the sensitive recorded data. This can lead to the violation of user's privacy rights and also causes a decline in the system's integrity and authenticity. This paper presents a novel security and signature aggregation scheme implemented using the Arduino Uno microcontroller, the MAX30100 SPO2 and Pulse Oximetry sensor, and the AD8232 sensor. The Privacy Preservation and Signature Aggregation Scheme (PPSA) for Medical Data that we present in this paper helps provide security against cyber attacks, thus strengthening the integrity and authenticity of the medical data. The Privacy Preservation part of the overall scheme has been implemented using the Blowfish and the Elgamal Encryption schemes, that helps the system to maintain the security of the system, whereas the Signature aggregation scheme involves the use of a co-Decisional Group Diffie-Hellman Signature scheme that helps the system to verify the authenticity of the medical data that is being transmitted within the system. The PPSA scheme, when implemented, was found to give correct results and provide the system with reliable security.",60015537,Mother Teresa Women's University,Kodaikanal,India,['1700'],29.444444444444443,0.040833333333333326,0.29333333333333333,0
406,406,Optimized Feature Integration and Minimized Search Space in Content Based Image Retrieval," All rights reserved.The semantic gap between the user request and retrieval result is an important but unsolved problem in the content-based image retrieval (CBIR) systems. This paper introduces a new multi-level structure in a CBIR system to bridge the semantic gap using the combination of low-level visual contents of an image. The initial stage of the proposed system depends on the statistical information of the color images which gives the most prominent images for the further level of the process. In the next step, low-level features such as color and texture details are extracted using dominant color descriptor (DCD) and radial mean local binary pattern over the query and selected images. Subsequently, Particle Swarm Optimization (PSO) is applied over both the color and texture similarity measure between the query and selected images. Finally, this multi-level system is experimented on OT-scene and Corel-10k databases to assess the performance and it gives 78.43% and 52.34% average precision rate.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],26.166666666666668,0.07670454545454546,0.4351461038961039,0
407,407,Weather Prediction Model using Savitzky-Golay and Kalman Filters," © 2019 Procedia Computer Science. All rights reserved.Daily Weather forecasting is essential in multiple areas like agriculture, energy supply, transportation and so on. It is a predictive challenge that has mainly relied on model based methods. We explore new techniques for forecasting weather with a data intensive approach. This proposed work studies, the power of making predictions via various deep learning approaches-a hybrid approach that combines a Long Short-term Memory Recurrent Neural network with Genetic Algorithm and a Statistical approach that uses the ARIMA (Auto Regressive Integrated Moving Average) model and an Estimation approach for the weather parameters taken into consideration with the usage of Filters. We show how the base model can be enhanced with the application of these approaches keeping in mind the dependencies between the parameters. Evaluation of these methods is done by experiments on real world meteorological data.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],20.428571428571427,-0.0496969696969697,0.4087878787878788,0
408,408,Nonlinear rayleigh quotients and nonlinear spectral theory,"We give a new and simplified definition of spectrum for a nonlinear operator F acting in a real Banach space X, and study some of its features in terms of (qualitative and) quantitative properties of F such as the measure of noncompactness, α(F), of F. Then, using as a main tool the Ekeland Variational Principle, we focus our attention on the spectral properties of F when F is a gradient operator in a real Hilbert space, and in particular on the role played by its Rayleigh quotient R(F) and by the best lower and upper bounds, m(F) and M(F), of R(F).",60002838,Università degli Studi di Siena,Siena,Italy,['1701'],50.5,0.20774410774410773,0.2801346801346801,1
409,409,An enhanced algorithm of RNN using trend in time-series,"The concept of trend in data and a novel neural network method for the forecasting of upcoming time-series data are proposed in this paper. The proposed method extracts two data sets-the trend and the remainder-resulting in two separate learning sets for training. This method works sufficiently, even when only using a simple recurrent neural network (RNN). The proposed scheme is demonstrated to achieve better performance in selected real-life examples, compared to other averaging-based statistical forecast methods and other recurrent methods, such as long short-term memory (LSTM).",60029274,Daegu University,Gyeongsan,South Korea,['1701'],21.5,0.028571428571428574,0.5010204081632653,1
410,410,Low Cost IoT Based Air Quality Monitoring Setup Using Arduino and MQ Series Sensors with Dataset Analysis," All rights reserved.ThispapertalksaboutcosteffectiveArduinobasedAirQualityMonitoringsetupusingMQseriessensorswhicharequitesuitable to install in both indoor and outdoor provided that properly calibrated before installing. There are many MQ series sensors out of which MQ135 and MQ7 have been considered here as MQ135 is able to detect ammonia, carbon dioxide, alcohol or even smokeandMQ7helpstocalculateCarbonMonoxidealoneandthesetwosensorsarequitesuitablefortheapplicationconsidered. Government of India has taken enough measures already to minimize the air being polluted. The whole setup can be made as acompact device with low cost and can be used as a carry-in device such that awareness is brought among the people of how's the airqualityleveloftheareasurroundedbythepersoneitherindoororoutdoor.Adverseeffectsofairpollutionleadstorespiratory problems, skin diseases etc., Moreover, the data collected by these sensors will be pushed to the cloud on back end, say here ThingspeakischosenandtherearemanyopensourceIoTsupportingplatforms.Attheend,dataanalysiswasdoneonthedataset collected from the setup which is installed at various places across the VIT University, Vellore. This analysis helps in deeper understanding of the air quality status such that people will be aware of what will happen if the same air quality continues for a longtime.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],32.0,0.12083333333333333,0.35833333333333334,0
411,411,BLE Bluetooth Beacon based Solution to Monitor Egress of Alzheimer's Disease Sufferers from Indoors," All rights reserved.With the ageing people community, Alzheimer's disease (AD) is the most common disease in prevalence. It affects the memory of the affected individual by causing neuron degeneration. Such cognitive disability leads people to roam around places since they are ignorant about location. They may go afar from the safe area to traffic prone areas which cause serious, life threatening issues to them. Proposed study introduces a technology that involves a wearable device for Alzheimer disease affected elderly patients and listening device given to care takers or doctors. This system detects and notifies caregivers about the departure of people to risk locations from their residence zone. This system uses Bluetooth Low energy (BLE) communication technology that utilizes transmitter and receiver fixed to elderly individual as wearable device and in residence respectively. Based on the signal strength between the transmitter and receiver, the distance estimation between the elderly and the receiver is calculated with the help of a Raspberry Pi(Rpi) and an alert notification is sent to doctors/caretakers when the distance exceeds safety limit.",60103989,"Sri Krishna College of Engineering and Technology, Coimbatore",Coimbatore,India,['1700'],21.875,0.04666666666666667,0.4066666666666666,0
412,412,KBR: Knowledge Based Reduction Method for Virtual Machine Migration in Cloud Computing," All rights reserved.Through large scale deployment of cloud data centers, burning up of energy by data center is very high and violations of service level agreements (SLA) are increasing. Implementation of Virtual machine consolidation techniques direct to physical host over exploitation which degrades the performance of physical host and Virtual machine. It has been a momentous confronts to get better exploitation of resources and energy effectiveness in cloud data center. This paper proposed knowledge based reduction method for Virtual machine assignment and consolidation. This method chooses the Virtual machines from the overloaded host and migrate the Virtual machines to other physical host to diminish energy burning up and get better quality of service. To provide evidence and effectiveness of proposed method, the experiment is conducted with diverse workload circumstances of real system. The experimental consequences exhibits that the proposed method diminishes energy burning up and optimizes infringement of service level agreements in achieving better performance.",60094585,Dr. Ambedkar Institute of Technology,Bengaluru,India,['1700'],22.285714285714285,0.14266326530612244,0.3381530612244898,0
413,413,From distributed coordination to field calculus and aggregate computing,"Aggregate computing is an emerging approach to the engineering of complex coordination for distributed systems, based on viewing system interactions in terms of information propagating through collectives of devices, rather than in terms of individual devices and their interaction with their peers and environment. The foundation of this approach is the distillation of a number of prior approaches, both formal and pragmatic, proposed under the umbrella of field-based coordination, and culminating into the field calculus, a universal functional programming model for the specification and composition of collective behaviours with equivalent local and aggregate semantics. This foundation has been elaborated into a layered approach to engineering coordination of complex distributed systems, building up to pragmatic applications through intermediate layers encompassing reusable libraries of program components. Furthermore, some of these components are formally shown to satisfy formal properties like self-stabilisation, which transfer to whole application services by functional composition. In this survey, we trace the development and antecedents of field calculus, review the field calculus itself and the current state of aggregate computing theory and practice, and discuss a roadmap of current research directions with implications for the development of a broad range of distributed systems.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1703']",38.8,-0.033749999999999995,0.27125,1
414,414,The PSS design GuRu methodology: Guidelines and rules generation to enhance PSS detailed design,"Manufacturers are often compelled to navigate the transition towards servitisation. In relation to this phenomenon, the present work focuses on design problems related to physical product enhancement when the addition of a service component is needed. A methodology generating the most suitable technical directions and design ideas to be followed during the integrated product-service system (PSS) design is provided. These design directions are deployed per the design for product service supportability approach on two different levels: Guidelines (non-company and PSS specific) and rules (derived through design for X (DfX) approaches) specific to a company and a particular solution. An application case in an Italian company operating in the heating, ventilation, air-conditioning and refrigeration market is conducted.",60023256,Politecnico di Milano,Milan,Italy,['1704'],23.2,0.11060606060606061,0.27965367965367965,1
415,415,An Image Encryption Algorithm Based on Fractal Geometry," All rights reserved.This paper introduces an effective image encryption method based on fractals for colored images. Fractals are now widely used in image security due to its randomness property and infinite boundaries. Since images are traversed over the public channel in day-to-day life confidentiality, integrity and authenticity must be pledged for prosperous transmission. This method capsulizes a larger key space and complex behavior to accomplish a productive confusion and diffusion techniques in a fruitful way. Julia set and Mandelbrot set are constructed and active confusion is exerted till the image pixels are altogether disordered and ensuing diffusion with XOR operation. Experimental results show the ability of the proposed system with respect to various statistical measures.",60008648,University of Madras,Chennai,India,['1700'],19.333333333333332,0.004166666666666668,0.5041666666666667,0
416,416,Improved Method for Enhancing Dark Images based on CLAHE and Morphological Reconstruction," All rights reserved.The image acquired are often flawed due to various defects from environmental scenarios such as indoor lighting, cloudy weather etc especially at night time. The dark image contains compressed dynamic range that can be enhanced for understanding the detailed information. In this investigative work, an improved method for enhancing extremely dark images is proposed utilizing the concept of illumination reflection model. This improved technique is based on Contrast Limited Adaptive Histogram Equalization (CLAHE) and reconstruction done using morphological processing with Top-hat transformation. The image is perceived in HSV color system and V component is estimated. This intensity (V) component is normalized and the inverse of the intensity component is computed. Then CLAHE algorithm is applied on the negative image. Then multiscale image enhancement is applied to the resultant image. Gamma enhancement is used to adaptively adjust the brightness component of an image. After gamma enhancement, the results of two gamma enhanced images with different gamma values are obtained. Principal Component Analysis extracts the significant information from these images that can be used for image fusion. During the PCA based image fusion, the weight value is adaptively calculated by using morphological Top-hat transformation to improve the quality of the image and illuminate the inconsistent background pixels. The proposed method focuses detail enhancement of extremely dark images by preserving the edges and structures. Experimental validations and results show the better performance of the proposed method than the existing method in terms of qualitative and quantitative measures.",60031566,University of Kerala,Thiruvananthapuram,India,['1700'],17.642857142857142,-0.004464285714285712,0.49434523809523817,0
417,417,On the modeling of optimal and automatized cloud application deployment,"We investigate the problem of modeling the optimal and automatic deployment of cloud applications. We follow an approach based on three main pillars: (i) the specification of the computing resources needed by software components and those provided by the executing environment (e.g. virtual machines or containers), (ii) the declarative description of deployment rules, (iii) and the computation of an optimal deployment that minimizes the total cost by using constraint solving techniques. We experiment with such an approach by applying it to the Abstract Behavioural Specification language ABS, and we validate it by modeling and simulating with ABS (and its tool-suite) the Fredhopper Cloud Services, a worldwide system offering e-Commerce services, currently deployed on Amazon EC2.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,"['1712', '1703']",28.75,-0.11666666666666667,0.5966666666666666,1
418,418,AI-Based Enhancement of Base Station Handover," All rights reserved.With exponential increase in digital data transfer and growing consumer base, there is a need to efficiently handle large set of users. In addition to that, we face a lot of problems due to poor signal connectivity during travel. Though operators look towards plantation of additional base stations or additional hardware, there is also a need to efficiently regulate the existing ones to utilize the resources in an effective manner thereby avoiding band exhaustion and also facilitating the handover of mobile stations in travel. When a mobile device is at travel, the device determines the next base station to which it has to be connected using the Received Signal Strength and requests the same. Therefore, prediction of the next potential base station in advance leads to a hexa-directional ambiguity (the mobile station may move to any of the adjacent 6 hexagonal cells in future which can't be predicted easily in advance). Ping-pong effects during the handovers are also a problem. Few other systems have been introduced which requires tracking of the device over a period of time to determine the trajectory thereby predicting the next potential base station in advance leading to privacy concerns. An addition to the system is proposed that could manipulate these handovers in an efficient manner while conserving privacy. We propose a triangular way of determining the next potential base station in advance. This method eliminates the hexa-directional ambiguity and determines the next one perfectly in advance thereby increasing the efficiency manifold. Reservation of band is done based on the prediction thereby reducing connectivity delays. Improving the existing ones manifold will reduce the requirement of additional hardware thereby facilitating sustainable development by reducing the dangerous impacts on Mother Nature.",60106323,"Sri Sai Ram Engineering College, Chennai",Chennai,India,['1700'],23.833333333333332,-0.1539377289377289,0.5639194139194139,0
419,419,An optimization framework for codes classification and performance evaluation of RISC microprocessors,"Pipelines, in Reduced Instruction Set Computer (RISC) microprocessors, are expected to provide increased throughputs in most cases. However, there are a few instructions, and therefore entire assembly language codes, that execute faster and hazard-free without pipelines. It is usual for the compilers to generate codes from high level description that are more suitable for the underlying hardware to maintain symmetry with respect to performance; this, however, is not always guaranteed. Therefore, instead of trying to optimize the description to suit the processor design, we try to determine the more suitable processor variant for the given code during compile time, and dynamically reconfigure the system accordingly. In doing so, however, we first need to classify each code according to its suitability to a different processor variant. The latter, in turn, gives us confidence in performance symmetry against various types of codes-this is the primary contribution of the proposed work. We first develop mathematical performance models of three conventional microprocessor designs, and propose a symmetry-improving nonlinear optimization method to achieve code-to-design mapping. Our analysis is based on four different architectures and 324,000 different assembly language codes, each with between 10 and 1000 instructions with different percentages of commonly seen instruction types. Our results suggest that in the sub-micron era, where execution time of each instruction is merely in a few nanoseconds, codes accumulating as low as 5% (or above) hazard causing instructions execute more swiftly on processors without pipelines.",60104671,University of Hail,Hail,Saudi Arabia,['1701'],26.333333333333332,0.11412087912087912,0.4168772893772893,1
420,420,New symmetric differential and integral operators defined in the complex domain,"The symmetric differential operator is a generalization operating of the well-known ordinary derivative. These operators have advantages in boundary value problems, statistical studies and spectral theory. In this effort, we introduce a new symmetric differential operator (SDO) and its integral in the open unit disk. This operator is a generalization of the Salagean differential operator. Our study is based on geometric function theory and its applications in the open unit disk. We formulate new classes of analytic functions using SDO depending on the symmetry properties. Moreover, we define a linear combination operator containing SDO and the Ruscheweyh derivative. We illustrate some inclusion properties and other inequalities involving SDO and its integral.",60029157,University of Malaya,Kuala Lumpur,Malaysia,['1701'],13.875,-0.017045454545454548,0.46401515151515155,1
421,421,Performance Evaluation of Area-Based Segmentation Technique on Ambient Sensor Data for Smart Home Assisted Living," All rights reserved.Activity recognition(AR) is a popular subject of research in the recent past. Recognition of activities performed by human beings, enables the addressing of challenges posed by many real-world applications such as health monitoring, providing security etc. Segmentation plays a vital role in AR. This paper evaluates the efficiency of Area-Based Segmentation using different performance measures. Area-Based segmentation was proposed in our earlier research work. The evaluation of the Area-Based segmentation technique is conducted on four real world datasets viz. Aruba17, Shib010, HH102, and HH113 comprising of data pertaining to an individual, living in the test bed home. Machine learning classifiers, SVM-R, SVM-P, NB and KNN are adopted to validate the performance of Area-Based segmentation. Amongst the four chosen classification algorithms SVM-R exhibits better in all the four datasets. Area-Based segmentation recognise the four test bed activities with accuracies of 0.74, 0.98, 0.66, and 0.99 respectively. The results reveal that Area based segmentation can efficiently segment sensor data stream which aids in accurate recognition of smart home activities.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],15.454545454545455,0.13110119047619048,0.43184523809523817,0
422,422,Video Traffic Analysis over LEACH-GA routing protocol in a WSN," All rights reserved.One of the most advanced evolutions of Wireless communication is Wireless Sensor Network (WSN), which plays a vital role in many applications. The growth and attention towards the designing of many new QoS aware routing protocol for WSN has been increased for the past few decades. Energy awareness has a greater significance while developing a routing protocol in order to increase network lifetime. In this paper, a traditional LEACH-GA routing protocol has been used for analyzing the video traffic over the sensor network.",60115615,Dr. N.G.P. Institute of Technology,Coimbatore,India,['1700'],21.5,0.22148760330578512,0.43677685950413225,0
423,423,Performance Analysis of Distributed and Federated Learning Models on Private Data," All rights reserved.There has been significant research in privacy-related aspects of machine learning and large scale data processing. In traditional methods of training a model, data is gathered at a centralized machine where training on the entire data takes place. This has led to a major problem of not only scalability but also of preserving the anonymity and privacy of sensitive user data. As a consequence, there has been extensive work done towards distributed machine learning. In more recent times, Federated Learning has gained a lot of traction. This is because of the features that make it highly suitable to train models collaboratively while preserving the privacy of sensitive data. In this paper, we compare basic machine learning, distributed machine learning, and federated learning by modelling on the Fashion MNIST dataset. Our results show that federated learning model not only maintains privacy but is also fast, and allows deployment at scale- even with low compute, mobile devices.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.75,0.13136160714285716,0.6148065476190477,0
424,424,MLPPT-MHS: Multi-Layered Privacy Preserving and Traceable Mobile Health System," All rights reserved.Personal Health Record (PHR) is a transpiring patient-centric embodiment of patient information trade that is customarily contracted out to third parties, for illustration, cloud service providers. There were far-reaching privacy apprehensions as individual medical records may possibly be unveiled to some third-party servers in addition to unconstitutional parties. On the road to warrant the patients' charge to access their medical records, it is a hopeful procedure to encrypt the medical records prior to outsourcing. Hitherto, questions like exposure to privacy, scalability during key management, in addition to proficient user revocation, have lingered the most imperative tests in the direction of accomplishing fine-grained access control. This manuscript puts forward a fresh multi-layer patient-centric scaffold in addition to an anthology of techniques in support of data access control to medical records amassed in honest-but-curious servers. In the direction of accomplishing fine-grained as well as scalable access control, a new-fangled modification of Cipher-text Policy Attribute-Based Encryption (CP-ABE) technique is persuaded with random key length in the offline encryption phase to encrypt each patient's PHR file. In the online phase, the CP-ABE encrypted data is transmitted to the cloud through a secure tunnel and then the data in rest is encrypted again by the 256-bit Advanced Encryption Standard (AES-256). In order to eliminate the problem aroused from leaked keys, both attribute and user revocation is done. The proposed system achieves data confidentiality, access control, user revocation, random key length, resists collusion attack, tracks the user location periodically, and preserves forward and backward secrecy. Within the MLPPT-MHS scheme, the computation time to perform Key Generation, Encryption, and Decryption would be 823.75ms, 152.43ms, 82.54ms and the storage overhead incurred to record the Public Parameters, Secret Key and Cipher Text would be 6098 bits, 59,653 bits, and 26,712 bits. These investigational outcomes demonstrate the security, scalability, as well as efficiency of this MLPPT-MHS scheme.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],28.181818181818183,0.013043478260869571,0.4768115942028985,0
425,425,Predicting value of binding constants of organic ligands to beta-cyclodextrin: Application of marsplines and descriptors encoded in SMILES string,"The quantitative structure-activity relationship (QSPR) model was formulated to quantify values of the binding constant (lnK) of a series of ligands to beta-cyclodextrin (β-CD). For this purpose, the multivariate adaptive regression splines (MARSplines) methodology was adopted with molecular descriptors derived from the simplified molecular input line entry specification (SMILES) strings. This approach allows discovery of regression equations consisting of new non-linear components (basis functions) being combinations of molecular descriptors. The model was subjected to the standard internal and external validation procedures, which indicated its high predictive power. The appearance of polarity-related descriptors, such as XlogP, confirms the hydrophobic nature of the cyclodextrin cavity. The model can be used for predicting the affinity of new ligands to β-CD. However, a non-standard application was also proposed for classification into Biopharmaceutical Classification System (BCS) drug types. It was found that a single parameter, which is the estimated value of lnK, is sufficient to distinguish highly permeable drugs (BCS class I and II) from low permeable ones (BCS class II and IV). In general, it was found that drugs of the former group exhibit higher affinity to β-CD then the latter group (class III and IV).",60024615,Ludwik Rydygier Collegium Medicum in Bydgoszcz,Bydgoszcz,Poland,['1701'],21.333333333333332,0.05475324675324676,0.29578066378066376,1
426,426,Ontology development life cycle: A review,"It is widely known that ontology plays a major role in semantic web as machine understandable language. There are manymethodologies have been developed in the last two decades. However, the degree of maturity and acceptance of these methodologies is still lacking due to the insufficient information about the techniques employed in them. Different methodologies provide different notions of development life cycle.Some methodologies can be manually created orsemi-automatically created. Some methodologies areapplication-driven orapplication independent. Some methodologies followan iterative development life cycle and some are not.Their application in real project is comparatively limited despites of their growing number. This study presents the similarities and differences of some prominent methodologies based on six phases of the ontology development life cycle, namelyscope definition, capturing, encoding, integration, evaluation and documentation.Another important aspect of ontology development is the ontology evolution. This topic is also presented in this paper.",60025577,Universiti Putra Malaysia,Serdang,Malaysia,['1700'],17.75,0.08050595238095239,0.4507936507936508,1
427,427,Plant disorder precognition by image based pattern recognition," All rights reserved.Proliferating population in the world has ushered a lot of burden on resources in agriculture. In order to sustain the population and the economy, it is very important to obtain maximum yield from crops. Diseases in plants are the chief cause of damage in plants which leads to production loss in agriculture. Earlier disease detection is manual, where farmers refer guide books or use their experiences to recognize the diseases. This process is time-consuming and requires some knowledge for selection of pesticides. Capturing images of leaves and processing them with the help of an automated system to identify the disease infected leaves could be a better solution for farmers. This paper discuss about how image processing and machine learning is effectively used in detection of diseases in plants. Analysis is done with various classification techniques and the comparison is made between Active contour and Sobel edge detection techniques. Experimental results indicate that Multiclass Support Vector Machines combined with Active contour edge detection gives better results compared to other methods for disease classification.",60021176,Anna University,Chennai,India,['1700'],19.444444444444443,0.18283333333333335,0.5774999999999999,0
428,428,Tweedle: Sensitivity Check in Health-related Social Short Texts based on Regret Theory," All rights reserved.Twitter helps us to know what is happening in the world and what people are talking right now. Every day, millions of Twitteraties tweet something personal or impersonal to express their emotions and valuable knowledge. In the health domain, disclosure of personal health information will have a long-term effect to common individuals either directly or indirectly, which emphasize the presence of unrealistic social boundaries and the need of sensitivity analysis in social media. The proposed Tweedle framework was built with 100K tweets extracted based on a set of 20 health-related cyber-keywords. The framework of Tweedle was bounded with Regret Theory for tweet annotation, content and contextual feature scores for feature selection and various machine learning algorithms for sensitivity classification. The tweets annotated in accordance with Regret Theory by domain experts of Amazon Mechanical Turkresulted in 61.5% of sensitive tweets with health data. The context and content-oriented features scoresare introduced in terms of Primary / Secondary tweet score, Named Entity Recognition Score of tweets, Term Frequency-Inverse Document Frequency(TF-IDF), Cyber-KeywordRatioin tweets, hashtag mentions, user mentions as features for classification.The Tweedle experimented Regret Theory in combination with various classifiers like Support Vector Machine, Naïve Bayes, Random Forest, Decision Tree, Logistic Regression and Recurrent Neural Network + Long Short-Term Memory for sensitivity classificationin health domain tweets.The training and testing results proved RNN + LSTM as the better performing model to identify tweets with sensitive health data.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],33.57142857142857,-0.005742296918767505,0.4805322128851541,0
429,429,Deep Learning Based Automated Attendance System," All rights reserved.A significant portion of the time allocated to a faculty for teaching purposes is consumed on the task of taking attendance of the students. This is an issue because it takes the valuable time of teachers which could be spent on more productive tasks such as teaching and interacting with students. In excess to the increase in chaos and loss of decorum in the classroom environment, the presence of proxy attendance also plagues the existing method of manual attendance keeping. To counter these issues, this paper proposed the Deep Learning Assisted Attendance System (DPAAS); which keeps track of students attending a particular class with the help of a continuous stream of pictures captured from a video streaming device located inside a classroom connected to the remote server. The proposed DPAAS method reduces the amount of time spent by the faculty on taking attendance, and leads to a reduction in chaos inside a classroom. DPASS is proposed handles the issues in existing systems such as multi-class identification for multiple individuals in a classroom, occlusion and differing light scenarios. The DPAAS methodology compares the results of the state of art algorithms, and uses the best fit architecture which provides the lowest false rate on evaluation. There is no need of user interaction in the proposed DPAAS. Experimental results show that the proposed DPAAS method gives 94.66% accuracy which is better than the other existing methods.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],26.22222222222222,0.153921568627451,0.3990196078431373,0
430,430,REMOVING RF VULNERABILITIES from IOT DEVICES," All rights reserved.RF vulnerabilities is a massive problem nowadays. If you see TV remote, AC remote, camera and car remotes RF have been using everywhere. The problem with RF security is that it always generates a signal with the same key which locked or unlock the system. RF signals are also unencrypted and It transfers signal through an unsecured channel so It suffers from key relay attack where the same key signal used to generate every time from a captured RF signal having the same key to make work to the system. Our problem statement is ""Removing RF vulnerabilities to transfer data securely so that RF can avoid any types of relay attack threats"". we proposed a system which transferred data securely, In our system, we advise key rolling algorithm with a 2-way handshake, Key rolling algorithm rolls key which provides a new key every time of data transferring and 2-way handshaking provide synchronization between sender and receiver.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],26.5,0.007575757575757575,0.6738636363636363,0
431,431,Smart Plant Watering System with Cloud Analysis and Plant Health Prediction.," All rights reserved.One of the major global concerns of our current era is water scarcity. This makes it all the more important to design water-efficient systems for irrigating our crops and plants. The main aim of this paper is to design a watering system for status of the plant health. The existing methods do not follow a convenient approach to visualize the recorded sensor data graphically nor do they have any facility to predict and inform the farmers about the health status of the plant Our design involves analyzing the moisture content, temperature of surrounding in which the plant grows to decide whether to release water or not from the electric motor and the data of the sensors will be displayed in graphical form on an Adafruit cloud page, which is an IOT platform (hardware and software interface) and this is further used to analyze the plant health and send an email alert to the farmer or person concerned. The system thus conserves water while irrigating the plants whilst avoiding the compulsion for continuous human supervision.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],35.4,0.14114583333333333,0.4166666666666667,0
432,432,Household Energy Management Model to Maximize Solar Power Utilization Using Machine Learning," All rights reserved.Electricity from solar energy is the new trend in electricity production companies. Many plants have been set up to harness energy from the sun. Since solar energy can be harnessed from open-air, starting the same from home is the best way. Most commonly solar energy is harnessed from a rooftop-mounted solar panel but is connected only for a few selective loads. All the other loads when in need of electricity cannot be utilized from solar energy. Since this is the format for electricity usage, the maximum usage of this is not done. This framework is proposed to maximize the usage of solar power by connecting both solar and grid to the same node and employing a unique switching strategy using decision tree machine learning algorithm in python environment. The hardware setup has been done for the same by using data acquisition techniques, collecting real-time data consisting of demand and solar power which is updated into the database in the local setup server. This real-time data is exported and prediction for the switching configuration is done and sent to an Arduino board to predict the source that has to be given to the particular demand in real-time.",60107595,"Amrita Vishwa Vidyapeetham University, Bangalore",Bengaluru,India,['1700'],22.11111111111111,0.13686868686868686,0.3691919191919192,0
433,433,A Review of Dimensionality Reduction Techniques for Efficient Computation," All rights reserved.Dimensionality Reduction (DR) is the pre-processing step to remove redundant features, noisy and irrelevant data, in order to improve learning feature accuracy and reduce the training time. Dimensionality reductions techniques have been proposed and implemented by using feature selection and extraction method. Principal Component Analysis (PCA) one of the Dimensions reduction techniques which give reduced computation time for the learning process. In this paper presents most widely used feature extraction techniques such as EMD, PCA, and feature selection techniques such as correlation, LDA, forward selection have been analyzed based on high performance and accuracy. These techniques are highly applied in Deep Neural Network for medical image diagnosis and used to improve the classification accuracy. Further, we discussed how dimension reduction is made in deep learning.",60109987,"CMR Institute of Technology, Hyderabad",Hyderabad,India,['1700'],21.333333333333332,0.0016666666666666728,0.4566666666666667,0
434,434,Efficient hierarchical identity-based encryption system for internet of things infrastructure,"Security is a main concern for the Internet of Things (IoT) infrastructure as large volumes of data are collected and processed in the systems. Due to the limited resources of interconnected sensors and devices in the IoT systems, efficiency is one of the key considerations when deploying security solutions (e.g., symmetric/asymmetric encryption, authentication, etc.) in IoT. In this paper, we present an efficient Hierarchical Identity-Based Encryption (HIBE) system with short parameters for protecting data confidentiality in distributed IoT infrastructure. Our proposed HIBE system has the public parameters, private key, and ciphertext, each consisting of a constant number of group elements. We prove the full security of the HIBE system in the standard model using the dual system encryption technique. We also implement the proposed scheme and compare the performance with the original Lewko-Waters HIBE. To the best of our knowledge, our construction is the first HIBE system that achieves both full security in the standard model and short parameters in terms of the public parameters, private key, and ciphertext.",60018205,Xiamen University,Xiamen,China,['1701'],24.142857142857142,0.11406926406926407,0.3899891774891774,1
435,435,Analysis of Twitter Specific Preprocessing Technique for Tweets," All rights reserved.Social media plays an important role in capturing the thoughts of people in their own representation of sentences. Twitter, the popular microblog, traps abundant rich information in it, in terms of short texts posted by users. Processing of such colloquial and informal sentences require a specific preprocessing technique that can alleviate its understanding and analysis. Understanding these natural language sentences to produce a desired result is a challenging task. The paper aims at analyzing, identifying and explaining the advantages of twitter specific preprocessing technique and find out if it performs equally well with the established baseline preprocessing method. Experiment is carried out for classifying tweets to assess the performance of preprocessing techniques. The results indicate the effectiveness of twitter specific preprocessing technique and its competence with the baseline text preprocessing technique.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.142857142857142,0.24423076923076925,0.5711538461538461,0
436,436,Custom Block Chain Based Cyber Physical System for Solid Waste Management," All rights reserved.The aim of this paper is to develop an intelligent cyber-physical system for the waste management in a locality which will not only keep records of the use of the trash bins in the but also ensure they have an additional blockchain based verification system which will ensure the proper working even in the presence of an adversary. The proposed system is an ensemble of the database server, blockchain server, embedded system based clients and an android app. This is inspired by the recent global trend in smartphone popularity which has piqued interest in the above mentioned division. The advent of smartphone popularity helps us to create an ideal system for a plethora of reasons such as processing capability and native storage etc. Furthermore, blockchain technology, introduced by Satoshi Nakamoto in 2009 ensures decentralization and security of transactions due to its use of cryptographic hash functions and public key cryptographic system. To further excite the situation, India recently revised its solid waste management policy in 2016 after 16 long years. All of the above factors together pointed to creation of a smart waste management system to prevent further exacerbation of India's existing waste management crisis.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],28.285714285714285,0.042694805194805195,0.3538419913419913,0
437,437,The recognition of the bifurcation problem with trivial solutions,"This paper studies the recognition criterion of the bifurcation problem with trivial solution. The t-equivalence is different from the strong equivalence studied by Golubitsky et al. The difference is that the second component of the differential homeomorphism is not identical. Consider the normal subgroup of t-equivalence group, we obtain the characterization of higher order terms P(h). In addition, we also explore the properties of intrinsic submodules and the finite determinacy of the bifurcation problem.",60104243,Hainan Tropical Ocean University,Sanya,China,['1701'],14.8,0.16666666666666666,0.4966666666666667,1
438,438,Renewable Energy Based Smart Irrigation System," All rights reserved.Agriculture is the primary occupation in India and is called India's backbone. But of late, a lot of problems are being faced in agriculture by the farmers. One of the major problems being water scarcity. As per surveys, almost 20 percent of the agricultural land is wasted due to water scarcity and becomes a barren land. Thus, this research gives an idea of smart irrigation system. This irrigation system uses three sensors namely temperature sensor, humidity sensor and soil moisture sensor, and fuzzy logic is used to operate the solenoid valve. The data from the sensors is then sent to the cloud by using adafruit.io and the farmer can view the moisture level, humidity level and temperature recorded by these sensors. All the operations are governed by an Arduino and the power supply for the Arduino is given by a solar panel which uses LDR (Light Dependent Resistor) and makes it into an automatic tracking system. The crops are grown in two tubs and comparison of growth of plant with automated irrigation and normal irrigation is carried out.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],20.11111111111111,0.0752232142857143,0.49598214285714287,0
439,439,Entropy Analysis on Planar Anamorphic Images," All rights reserved.Anamorphosis is an art of drawing, which creates illusion effect over the drawn image plane, and the impact of the illusion is nullified when the specific viewing position is used to view the drawn image. In digital imaging domain, the effect of anamorphosis is analyzed quantitatively by the amount of distortion present in the anamorphized image. This study on the anamorphized image suggested that the optimal combination of parameters can create the better-anamorphized image.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],25.666666666666668,0.0,0.041666666666666664,0
440,440,Local bit plane adjacent neighborhood dissimilarity pattern for medical CT image retrieval," All rights reserved.In this article, new feature descriptor local bit plane adjacent neighborhood dissimilarity pattern (LBPANDP) is introduced for CT image retrieval. In the proposed method, the input image is first decomposed into eight binary bit planes. Then in each of the first four most significant bit planes, for each center pixel, the dissimilarity information of its binary neighbors are encoded into a single value. The encoded values of each bit plane is then compared with the intensity of the center pixel and this relationship is finally encoded to devise the LBPANDP descriptor. The proposed descriptor is highly discriminative and considers only the first four most significant bit planes for encoding, which greatly reduces the dimension of the feature vector. Retrieval performance of LBPANDP is investigated on two CT image databases and the results show a significant improvement in retrieval efficiency by LBPANDPover many recent techniques.",60007709,Tezpur University,Tezpur,India,['1700'],24.5,0.22104921394395075,0.5017805878332194,0
441,441,Very short-term photovoltaic power forecasting using stochastic factors," All rights reserved.This paper proposes a photovoltaic (PV) power forecasting model, using the application of a Gaussian blur algorithm filtering technique to estimate power output and the creation of a stochastic forecasting model. As a result, affected power can be forecasted from stochastic factors with machine learning and an artificial neural network. This model focuses on very short-term forecasting over a five minute period. As it uses only endogenous data, no exogenous data is needed. To evaluate the model, results were compared to the persistence model, which has good short-term forecasting accuracy. This proposed PV forecasting model gained higher accuracy than the persistence model using stochastic factors.",60022498,Naresuan University,Pitsanulok,Thailand,"['1710', '1705']",18.0,0.11000000000000001,0.6799999999999999,0
442,442,Correlation dynamics of dipolar bosons in 1D triple well optical lattice,"The concept of spontaneous symmetry breaking and off-diagonal long-range order (ODLRO) are associated with Bose-Einstein condensation. However, as in the system of reduced dimension the effect of quantum fluctuation is dominating, the concept of ODLRO becomes more interesting, especially for the long-range interaction. In the present manuscript, we study the correlation dynamics triggered by lattice depth quench in a system of three dipolar bosons in a 1D triple-well optical lattice from the first principle using the multiconfigurational time-dependent Hartree method for bosons (MCTDHB). Our main motivation is to explore how ODLRO develops and decays with time when the system is brought out-of-equilibrium by a sudden change in the lattice depth. We compare results of dipolar bosons with contact interaction. For forward quench (Vf > Vi), the system exhibits the collapse-revival dynamics in the time evolution of normalized first-and second-order Glauber's correlation function, time evolution of Shannon information entropy both for the contact as well as for the dipolar interaction which is reminiscent of the one observed in Greiner's experiment [Nature, 415 (2002)]. We define the collapse and revival time ratio as the figure of merit (t) which can uniquely distinguish the timescale of dynamics for dipolar interaction from that of contact interaction. In the reverse quench process (Vi > Vf), for dipolar interaction, the dynamics is complex and the system does not exhibit any definite time scale of evolution, whereas the system with contact interaction exhibits collapse-revival dynamics with a definite time-scale. The long-range repulsive tail in the dipolar interaction inhibits the spreading of correlation across the lattice sites.",60031745,Abdus Salam International Centre for Theoretical Physics,Trieste,Italy,['1701'],28.77777777777778,0.1608974358974359,0.5358974358974359,1
443,443,Implementing smart swapping algorithm to boost the performance of Linux PC's.," All rights reserved.Swap space in Linux is used when the amount of physical memory (RAM) is full. If the system needs more memory resources and the RAM is full, inactive pages in memory are moved to the swap space. While swap space can help machines with a small amount of RAM, it should not be considered a replacement for more RAM. Swap space is located on hard drives, which have a slower access time than physical memory. If any memory-intensive application is deployed on a PC with limited amount of Random-Access Memory, the inactive (not recently used) application which is generally the system UI is shifted to the Swap memory (much slower than RAM). This makes the entire UI slow but the higher priority processes (the most recent applications) remain unaffected because they remain in the RAM. When we are finished with our work with the memory intensive application and close it, the RAM gets cleared and has ample of space to accommodate the contents of the SWAP memory. But the swap memory stays as it is, and does not get transferred back to the RAM. This results in slower UI even though the system has enough RAM and no memory intensive process is running. This then results in lag in UI transition, delayed application launches, slower processing of programs and a large overhead.In years past, the recommended amount of swap space increased linearly with the amount of RAM in the system. But because the amount of memory in modern systems has increased into the hundreds of gigabytes, it is now recognized that the amount of swap space that a system needs is a function of the memory workload running on that system.In the world of enhanced hardware and superior machines, the software enhancements and optimization for low end PC's is sometimes neglected. Hence, we propose a technique to overcome the lag created by the swap space y moving the content of the swap memory back to the RAM and a total boost is provided to the system. The technique is evaluated under various configurations and proves to solve the problem.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],27.076923076923077,0.10004105090311985,0.3697865353037767,0
444,444,Exploration of Autism Spectrum Disorder using Classification Algorithms, All rights reserved.Data mining plays a vital role in identifying the classification algorithm for classification and prediction of disease in medical field. Predicting disease depends on the accuracy of the dataset and mechanism of machine learning algorithms used to classify the dataset. To detect new born with risk of autism spectrum disorder (ASD) which is predominantly diagnosing the behavioral observation of children with above 2 years. Although identifying brain disease using magnetic resonance imaging (MRI) available in the last few years it is time consuming and very expensive. Early stage of predicting autism disorder done with the help of using machine learning algorithms. This paper criticize various classification algorithms then evaluates the accuracy and then selects the best classification algorithm to analyze and classify each individual who gets affect from autism spectrum disorder (ASD) in early stage.,60114457,Sri Krishna Arts and Science College,Coimbatore,India,['1700'],23.0,0.07587412587412587,0.3254778554778554,0
445,445,A Deep Neural Network Framework for Road Side Analysis and Lane Detection," All rights reserved.This paper presents a computer vision based framework with the aim of aiding the task of driving. The framework serves the purpose of road analysis. Road analysis is further divided into two sub-tasks. The first task aims at recognition of the different road signs, the second task aims at lane analysis. The task of automatic driving requires humans to multitask and perform many operations in split seconds. The framework is introduced to aid this task of driving if not completely automate it while keeping in mind of using it with a simple hardware and software setup. The effectiveness of the framework lies in its feature of having minimal complexity which enables it to be used in real-time. The results of the pipeline are quantified by first measuring its accuracy in the classification of road signs, second measuring its ability to gather the information about the road (lane analysis and 2 vehicle detection) thirdly by performing the time bench-marking.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],20.125,0.07727272727272727,0.3294372294372294,0
446,446,Image Segmentation in Constrained IoT Servers," All rights reserved.Image segmentation forms an important concept in the computer vision technology. Image segmentation breaks the image into boundaries that differentiate meaningful components. For computer vision to realize its full potential it is essential that the image segmentation algorithms give accurate results in a fast and efficient way. In hierarchical architecture based IoT networks set up to ""see"" the world, methods of computer vision need more analysis. The need for low cost setup for IoT networks in terms of memory and their computational capabilities demands research for developing methods that are resource sensitive and can be successfully integrated into such networks of low end IoT servers. Addressing this need, a refined graph cut segmentation technique for low to medium resolution images and for constrained devices is presented in the paper. Implementation and analysis of the refined graph cut segmenter for linux based IoT servers is discussed. A comparison with the contemporary segmentation methods under similar constraints is also presented.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],20.125,0.21041666666666667,0.55625,0
447,447,Ensuring liveness properties of distributed systems: Open problems,"Often fairness assumptions need to be made in order to establish liveness properties of distributed systems, but in many situations they lead to false conclusions. This document presents a research agenda aiming at laying the foundations of a theory of concurrency that is equipped to ensure liveness properties of distributed systems without making fairness assumptions. This theory will encompass process algebra, temporal logic and semantic models. The agenda also includes the development of a methodology and tools that allow successful application of this theory to the specification, analysis and verification of realistic distributed systems. Contemporary process algebras and temporal logics fail to make distinctions between systems of which one has a crucial liveness property and the other does not, at least when assuming justness, a strong progress property, but not assuming fairness. Setting up an alternative framework involves giving up on identifying strongly bisimilar systems, inventing new induction principles, developing new axiomatic bases for process algebras and new congruence formats for operational semantics, and creating matching treatments of time and probability. Even simple systems like fair schedulers or mutual exclusion protocols cannot be accurately specified in standard process algebras (or Petri nets) in the absence of fairness assumptions. Hence the work involves the study of adequate language or model extensions, and their expressive power.",60029470,Commonwealth Scientific and Industrial Research Organization,Melbourne,Australia,"['1712', '1703']",26.75,0.17067837465564734,0.49905057064147973,1
448,448,"A detailed examination of sphicas (2014), generalized EOQ formula using a new parameter: Coefficient of backorder attractiveness","Researchers have used analytic methods (calculus) to solve inventory models with fixed and linear backorder costs. They have found conditions to partition the feasible domain into two parts. For one part, the system of the first partial derivatives has a solution. For the other part, the inventory model degenerates to the inventory model without shortages. A scholar tried to use the algebraic method to solve this kind of model. The scholar mentioned the partition of the feasible domain. However, other researchers cannot understand why the partition appears, even though the scholar provided two motivations for his derivations. After two other researchers provided their derivations by algebraic methods, the scholar showed a generalized solution to combine inventory models with and without shortages together. In this paper, we will point out that this generalized solution approach not only did not provide explanations for his previous partition but also contained twelve questionable results. Recently, an expert indicated questionable findings from two other researchers. Hence, we can claim that solving inventory models with fixed and linear backorder costs is still an open problem for future researchers.",60079715,National Defense University Taiwan,Taipei,Taiwan,['1701'],16.545454545454547,-0.04479166666666667,0.46718750000000003,1
449,449,The Qualitative Study on Input - Output Channel Configurations in Wireless Body Area Network," All rights reserved.Increasing interest in wireless networks and the electrical devices with the help of semiconductor technology has empowered the active participation of people in the development of Wireless Body Area Networks. Sensor network's environment for using free space is different from that of Wireless Body Area Network as it transmits signals through body parts. There are lots of areas which need to be taken care of during the transmission of signals. One of the predominant points is fading.This manuscript deals with simulating transmissions over fading channels and presents a comparative study of various input-output channel characteristics in Wireless Body Area Network. The power profile of Wireless Body Area Network with various input-output channel configurations is generated using Weibull characteristics according to NICTA's (previously known as National ICT Australia Ltd) measurement in MATLAB software. It is known that as the distance increases fading occur in the signal as well as in the channel. This work basically deals with the various type of power profile which will be achieved by changing input and output channel configurations. Moreover, channel's power profile has been plotted to get mean fading values using carrier frequency, relative body movement, and scattering density. Here few of the mitigation methods to remove the effect of fading are also discussed.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],23.555555555555557,-0.041249999999999995,0.44541666666666657,0
450,450,"Impact of financial literacy on investment behavior and consumption behaviour of middle-class families in Karnataka, India","Financial Literacy is an inevitable parameter in the current competitive society. The process of financial literacy is to make people aware about safe savings and other investment products available. This improved awareness will lead to better financial behaviour in terms of saving, budgeting and availing the credit wisely at cheaper cost. In tune with that, an attempt has been made in this paper to measure the impact of financial literacy on investment behavior and consumption behavior of middle-class families in Karnataka. Structured questionnaire is used to collect the data from 444 respondents. Stratified random sampling method is adopted.Confirmatory factor analysis is used to verify the model, and hypothesized relation is tested by applying the Structural Equation Model (SEM) to find the goodness of fit. The study resulted in that financial literacy has an impact on investment behavior and consumption behavior of the middle-class families in Karnataka. However, investment behavior is not influencing the consumption behavior of an individual and vice versa.",60106812,"Christ University, Bengaluru",Bengaluru,India,['1700'],20.125,0.13281249999999997,0.35156250000000006,1
451,451,Characterizing the Outlying Feature Set of Groups," All rights reserved.Outlying feature set of groups is useful in many applicationscenarios.However, most of existing literatures focusedoncharacterizing outlying feature set of individuals rather than group level. A method that can identify outlying feature setof groups effectively from large scale dataset is not yet available. This paper aims to tackle this challenge by proposing a novelgroup outlying feature set identification algorithm, named GOFSI, which can identify the outlying feature set at the group level automatically. The Experiments on both synthetic and real-world data sets confirmed the effectiveness of ourmethod.",60103533,Xinjiang Technical Institute of Physics and Chemistry,Urumqi,China,['1700'],22.25,0.4163265306122449,0.5183673469387755,0
452,452,Fake News Detection using Bi-directional LSTM-Recurrent Neural Network," All rights reserved.Media plays a vital role in the public dissemination of information about events. The rapid development of the Internet allows a quick spread of information through social networks or websites. Without the concern about the credibility of the information, the unverified or fake news is spread in social networks and reach thousands of users. Fake news is typically generated for commercial and political interests to mislead and attract readers. The spread of fake news has raised a big challenge to society. Automatic credibility analysis of news articles is a current research interest. Deep learning models are widely used for linguistic modeling. Typical deep learning models such as Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN) can detect complex patterns in textual data. Long Short-Term Memory (LSTM) is a tree-structured recurrent neural network used to analyze variable-length sequential data. Bi-directional LSTM allows looking at particular sequence both from front-to-back as well as from back-to-front. The paper presents a fake news detection model based on Bi-directional LSTM-recurrent neural network. Two publicly available unstructured news articles datasets are used to assess the performance of the model. The result shows the superiority in terms of accuracy of Bi-directional LSTM model over other methods namely CNN, vanilla RNN and unidirectional LSTM for fake news detection.",60001945,"Devi Ahilya Vishwavidyalaya, Indore",Indore,India,['1700'],16.46153846153846,-0.08621794871794872,0.43878205128205133,0
453,453,Identification of Network Intrusion in Network Security by Enabling Antidote Selection," All rights reserved.Cloud computing is an application of the storage of items used as network services. On their virtual machines, cloud users can access hacker technology that used to emphasize back doors in cloud security. For their ability to replicate hardware environments and share resources, virtual machines are quickly replacing personal computer infrastructures. The hacking and denial of service attacks were revealed to physical devices. On their Virtual Machines, Cloud users can download vulnerable programs, leading to cloud security violations. There are many safety issues that need to be addressed in a partial security environment. There is a data centre in the existing system, where system administrators have full control over the host computers, which can be monitored in a hierarchical way by the system administrator. Patching known cloud safety holes data centre where cloud users are usually entitled to control the software installed on their virtual machines. Essentially it may not operate and may breach the Service Level agreement. We can't find the detection of intrusion. Virtual machines are vulnerable to denial of service attack cloud users can set up susceptible software on their Virtual Machines which actually leads to cloud security violations. Network intrusion detection and countermeasure choice combines intrusion detection processes with attack map analytical procedures. If an attacker targets the server using a user account, the attacker can add multiple levels of malware to the database if and only if he can access the server, but because of the server cloud service it is difficult to detect the intruder in the existing system. In the proposed system, If the attacker's server with the attack user account finds the attacker and administrators to warn the user's attempts (zombie attack) to access another user account to install malware and attempts to manage the largest multi-level wait, then administrators will stop it.",60106323,"Sri Sai Ram Engineering College, Chennai",Chennai,India,['1700'],21.714285714285715,-0.044444444444444446,0.3961904761904762,0
454,454,IoT based Voice/Text Controlled Home Appliances," All rights reserved.Internet of Things (IoT) is formulated to remotely connect, access, monitor and control the existent world entities through the Internet. When the IoT is conceptualized towards home, it converts simple home to smart home which is safer and automated. In this paper a Voice/Text controlled Home Application is developed where the users can remotely access the home appliances. The users can merely provide voice commands or text messages through which they will be able to turn the appliances ON or OFF depending upon the necessity. The users can schedule the status of the appliances when they are not physically present in the environment. They will also be provided with the information regarding the previous schedules, and they can also turn on the appliances for specific period of time. The Node-RED Technology is used for the functions of the application which is embedded with IoT device (NodeMCU). This developed application is deployed in the Dialog Flow Account. The NodeMCU is connected with regular home appliances. As per the parameters fetched from the cloud the NodeMCU operates the Home Appliances. The implementation cost of this application is very cheaper since high performance and least cost equipment's are used. This application is greatly consistent and proficient for the elderly people and differently abled person who cannot reach the switch, for switching ON/OFF the device.",60104476,Vel Tech Rangarajan Dr.Sagunthala R&amp;D Institute of Science and Technology,Chennai,India,['1700'],18.666666666666668,0.021036414565826334,0.328446455505279,0
455,455,Statistical Measurements of Multi Modal MRI - PET Medical Image Fusion using 2D - HT in HSV color Space," All rights reserved.The goal of image fusion is to obtain large amount of information into a single image with more quantitatively and qualitatively. The image fusion can be applicable in various fields like multi-focus, multi-modal medical, satellite etc. This paper proposed statistical measurements of Multimodal MRI-PET medical image fusion using 2D Hartley transform (HT) in HSV color space. This proposed method was discussed with two different modalities of medical images like MRI (Magnetic Resonance Imaging) and PET (Positron Emission Tomography) and also discussed with five steps. Initially the PET color image is converted into HSV channels. Second step is MRI and V component of PET image are divided into 8∗8 blocks and then apply 2D Hartley transform on each block of two input images. Third step is compute variance of each block of two images and then select best blocks. Fourth step is applying inverse 2D HT and all blocks are arranged into single image i.e. new V component. Finally concordination of New V component, H, S to get HSV image and then convert HSV to RGB to obtain final fused image with more accurate. The result shows the importance of the proposed image and this is superior to existing methods like DFT along with Smooth, Hartley along with Smooth, Hartley along with Mean, DFT along with Mean and DCT along with Smooth. The evaluation parameters such as Mean, Standard Deviation and Gradient plays a major role in image fusion for testing the quality.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],20.416666666666668,0.12563852813852813,0.40873556998557,0
456,456,"Strive for what others want - The role of mindfulness, social pressure, time pressure and time perspectives on designers' happiness"," © The Author(s) 2019.The present study investigated the specific life circumstances that determine designers' happiness measured in terms of life satisfaction and subjective well-being. To this aim, self-reports of 252 participants in an online survey were analysed using psychological measurement instruments for pressure, self-aspects, happiness and mindfulness. The findings highlight that social pressure and time pressure are negatively related to designers' happiness and to positive self-aspects (self-esteem, creative self-efficacy) by a small to medium effect size (r = .21). Judging partially mediates this detrimental effect by a small effect size (r = .09), is highly related to social comparison frequency (r = .50) and global happiness (r = -.40). Present focus and present value relate more positively to global happiness than future focus and future value (r = .17). A positive implication for designers derives from the result that creative self-efficacy closely relates to positive emotions (r = .43) and life satisfaction (r = .40) but is unaffected by social and time pressure.",60016912,Yonsei University,Seoul,South Korea,['1704'],27.333333333333332,0.17695924764890283,0.26935736677115985,0
457,457,Region Driven Remote Sensing Image Captioning," All rights reserved.Remote sensing Image Captioning is a special case of Image Captioning which solves the difficulties in processing the remote sensing images. Issues may arise due to translation, rotation and viewpoint of images and maintaining semantic consistency in the generated captions. This method of describing a remote sensing scene in the form of sentences plays an important role in a number of fields, such as image retrieval, scene classification and as a vision companion. A Domain-driven approach is developed, in which the domain probabilities are used for captioning the remote sensing images. This approach concentrates on the domain- based information available in the images. A new dataset, called UAVIC dataset is created for images captured using Unmanned Aerial Vehicle (UAV), which covers wide range of land having multiple terrains and gives a better view of the landscapes. The proposed domain driven approach is applied to UCM and UAVIC dataset and the quality of resulting captions are evaluated using BLEU scores.",60021176,Anna University,Chennai,India,['1700'],23.142857142857142,0.10526973026973027,0.3923826173826174,0
458,458,Hypergraph Learning for Fundamental Shape Detection," All rights reserved.Geometry was the science of shape and it was used to measure the shape. The shape was the outline of something and it was related to size and pose. There were so many normal and abnormal variability present in the shape of a structure like oval, oblong, round, square, diamond, etc. Shape analysis was an extremely challenging task in medical image processing. There was a need in medical research to abstract the form of an object present in the image. It should describe it with a few geometrical attributes or even with words. And also it should relate it to the form of another object, and group together. All these processes need to be automated. So describing the shape of objects in mathematical representation was the better preference. In this paper, a novel hypergraph based shape recognition framework called MRS-Framework was developed. It was used to identify basic geometric shapes. It will be used in medical analyze to diagnose the disorders.",60005630,"National Institute of Technology, Tiruchirappalli",Tiruchirappalli,India,['1700'],13.666666666666666,0.09000000000000001,0.26499999999999996,0
459,459,Automated Dispute Resolution System (ADRS) - A Proposed Initial Framework for Digital Justice in Online Consumer Transactions in India," All rights reserved.In the new era of technology, innovativeness in technology is bursting into the legal domain. For a speedier and an inexpensive resolution of disputes, legal courts in India and in various other jurisdictions have ventured into the technological advancements. But Indian courts have minimal use of technology for exercising due process of law. There is much to be carried out to be in the fast-growing technology taking into consideration the current business demands. This article focuses on the existing dispute resolution mechanisms available in India to deal with business to consumer disputes (B2C) and in other jurisdictions dealing with digital consumer claims. Difficulties and challenges confronted by consumers in reality in the digital commerce transactions in terms of dispute resolution including online dispute resolution are well described and an initial framework for a unified model of computer automated dispute resolution system is proposed with the worked through example so as to ease the process of resolving digital consumer claims and to protect consumers rights and interests absolutely.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],28.333333333333332,0.05383522727272727,0.31122159090909096,0
460,460,Start to Finish Automation Achieve on Cloud with Build Channel: By DevOps Method," All rights reserved.Innovations through IoTs urge software developing industry need to come up with new life cycle model instead than usual. Process of software developments should be go along with advancements life cycle. This brings the attention for native and adoptable software life cycle process that is required for current industry standards. Manufactures are integrating the methodologies of software development process in a single bundle as automation with support of cloud with DevOps. The operation engineers, development engineers and QAs participate together for building the software applications will spin into minutes instead of days. Automation is the ultimate demand for DevOps approach. This approach advents continual automation to the software life cycle is known as delivery. This continually performs the tests and analysis of code. The developers provision and build the software into their cloud environment. Every step in the continuous delivery can be repeated in a several time a day depending on how much new applications need to release. Automation in DevOps improving speed of development, precision, consistency and increases the number of delivery.",60109336,Saveetha School of Engineering,Chennai,India,['1700'],16.0,-0.006957328385899817,0.3961966604823748,0
461,461,Pathological Myopia Image Analysis Using Deep Learning," All rights reserved.Pathological Myopia (PM) is one among the main reason of visual defect in the world. Pathological myopia is associated with decaying changes in the retina. If it remains untreated it may lead to vision loss that can't be recoverable. The correct diagnosis of pathological myopia will facilitate proper treatment and improve disease management which reduce the growth of the disease. However, it is nearly impossible to scan the whole population. Computer-aided diagnosing tools in eye image study will build the method scalable and economical. This paper focuses on the problems of classification of Pathological myopia images and non-pathological myopia images and optical disc, fovea detection, localization, lesions (atrophy and detachment) segmentation with 400 samples provided by International Symposium on Biomedical Imaging (ISBI). In this paper, a deep learning method with Convolutional Neural Networks (CNN) is used for classification and U-net model is used for Image segmentation which shows that it achieves highly competitive results.",60005630,"National Institute of Technology, Tiruchirappalli",Tiruchirappalli,India,['1700'],19.625,0.017777777777777778,0.40814814814814815,0
462,462,Symmetric Measure of Network Traffic using Packet Ratio and Packet Symmetry," All rights reserved.Flood attacks on a network occur when attackers send a very high volume of traffic to a system. This leads to an exhaustion of resources of the targeted system. Such a system or infrastructure under attack won't be able to cope up with the services it needs to provide due to capacity overload. These types of attacks are also called as Denial of Service (DoS) attacks. As it is essential for companies and organizations to provide high speed and high-quality services the network in which it operates needs to be secured against DoS attacks. As it is said prevention is better than cure, it is always better to detect an attack in the preliminary stages itself and deny an attacker any opportunity to continue the assault on the system. There are various kinds of DoS attacks, in this study the focus is on three kinds of attacks and its detection ICMP flood attack, UDP flood attack and TCP SYN flood attack. The detection mechanism employed is based on packet symmetry which can be used in to monitor the data flow in a network and detect any malicious anomalies in the network traffic at any instant. The experimental results, show that the packet symmetry is a reliable metric to detect attacks on the network by checking the data flow in the ICMP, UDP and TCP layers.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],25.333333333333332,0.16754545454545455,0.5098787878787879,0
463,463,A Modified Priority Preemptive Algorithm for CPU Scheduling," All rights reserved.Priority Preemptive scheduling algorithm is a popular among various other algorithms for scheduling CPU, however it leads to the problem of starvation which happens when processes with lower priority are not given any chance of CPU utilization due to continuous CPU usage by processes with higher priorities. To eradicate this problem here, we have proposed a new algorithm for scheduling CPU which we call it as Modified Priority Preemptive Scheduling Algorithm based on a new approach where we are executing priority Preemptive scheduling in a round robin fashion taking the time quanta equal to the shortest burst time of all the available processes. On analyzing the results, it is observed that modified Preemptive algorithm not only solves the problem of starvation but also enhances the performance of regular Priority Preemptive algorithm by lowering the mean turnaround time and mean waiting time.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],48.0,0.031980519480519484,0.5043581418581419,0
464,464,Implementation Topology of Full Adder Cells," All rights reserved.Design of different complementary metal-oxide-semiconductor (CMOS) topologies of 1-bit full adder (FA) cell in terms of power, delay, power-delay-product (PDP) and energy-delay-product (EDP) have been analyzed for the application of the intelligent systems. The FA cells have been implemented with respect to the different CMOS topologies such as complementary-CMOS (C-CMOS), complementary pass-transistor logic (CPL), CMOS transmission gates (TGA), and CMOS transmission function (TFA) and simulated at 180 nm technology. The work has been extended to the comparison of FA cell implementation using the increasingly demanding ultra-thin-body silicon-on-insulator (UTBSOI) transistors. Based on the simulation results, the application of UTBSOI in the FA cell has resulted in 26.7%, 24.3%, 44.6% and 44.7% improvements over that of best design architecture reported in this literature in terms of power, delay, PDP, and EDP, respectively.",60107379,National Institute of Technology Meghalaya,Shillong,India,['1700'],33.25,0.3071428571428571,0.5071428571428571,0
465,465,Classification of Abnormal Masses in Ultrasonic Elastography Breast Images," All rights reserved.The specificity of US (ultrasound) B-mode imaging in detecting benign masses is less due to overlap of features of malignant and benign masses. The intensity variations in a US B-mode image are due to variation in the texture of the underlying tissues, but in a US elastography image relates to strain value in tissues and have more potential in tissue differentiation. This study aims to develop a new scheme to automatically determine a seed point in an US elastography image based on mean strain value, thereby speeding up the segmentation process and to use elasticity features extracted from the segmented images to improve the classification rate. A new method of mean strain value calculation within the abnormal region is introduced to develop a new automatic method of selecting a seed point that helps in the precise segmentation of the lesion area. A neural network is used to classify the abnormal masses from texture, shape and two new elasticity features extracted from the segmented regions. The new approach of automatic seed point selection used on a dataset of 62 US elastography images achieved an accuracy of 90.32%. The average Tanimotto coefficient of US elastography images segmented using this approach is 0.75123. The classifier provided a sensitivity, specificity and classification accuracy of 80.00%, 86.67%, and 84.00% respectively. This is the first study that applies mean strain value for automatic seed point selection in US elastography images, reducing time consumed by the user and usage of elasticity features for classification of abnormal breast masses.",60100946,St. Joseph's College of Engineering,Chennai,India,['1700'],28.22222222222222,0.01927361853832442,0.4873663101604277,0
466,466,Automated Goal Score Detection in Football Match Using Key Moments," All rights reserved.Automated goal score detection in a football match is a comprehensive work and a challenging task as well. In this paper, we proposed a methodology for goal score detection using key moments of the match. Key moments in any sports are referred as actions that stimulate excitement or attraction of the audience. So, key moments can be identified using computer vision. Extracting one key moment involves many steps to happen at a time and it is necessary to integrate all the steps to identify it as a key moment. It is necessary to identify the goalpost region and track the ball to calculate the goal in football match. The proposed work analyses the various tracking algorithms and finalize MIL (Multiple Instance Learning) tracker technique to track the ball. So, the proposed work identifies the goal post region using sequence of image processing operations, tracks the ball using multiple instance learning tracker and confirms whether the goal has been occurred or not. The results of the proposed work have been shown.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.22222222222222,0.08333333333333333,0.75,0
467,467,Contour Detection based Ear Recognition for Biometric Applications," All rights reserved.Now-a-days, securing ones information has become a greatest threat. The advancement in the technology has paved way for many biometrics systems. These biometrics using finger prints have been highly hacked these days. This paper suggests a technique using the human ear as the perfect source of person identification as it has its own unique features. A few image processing algorithms were applied to segment the ear but some lacked in perfect. The proposed system emphasizes on developing a biometrics system that would detect and recognize a person using the features of their ear where the ear is segmented using appropriate segmentation techniques. The ear recognition is then carried out by using feature matching technique.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],16.714285714285715,0.49350000000000005,0.674,0
468,468,A Genetic Algorithm for the Snake-in-the-Box Problem using Modified Edge Recombination," All rights reserved.Snake-in-the-box is a graph theory problem of finding the longest path in a hypercube with some constraints. As the dimension of the hypercube increases, the number of paths grow, increasing the search space exponentially. In the past, genetic algorithms have been known to work well with problems having such large search spaces. In this paper, a genetic algorithm using a modification of the edge recombination operator is presented to find the longest snake in dimensions one to nine with lesser edge failures.",60026157,PSG College of Technology,Coimbatore,India,['1700'],21.25,-0.008928571428571432,0.41964285714285715,0
469,469,EWPTNN: An Efficient Workload Prediction Model in Cloud Computing Using Two-Stage Neural Networks," All rights reserved.Allocating insufficient resources to the cloud applications, leading to the loss of revenues, consumers and, Quality-of-Services (QoS). Another side, allocating resources more than is needed leading to the wastage of energy and cost to maintain the resources like servers, datacenters and, network bandwidth etc. So, this problem can be solved with predictive scaling methods by using machine learning approaches, which can estimate the future needed resources and, performing scaling operations in advance. To perform accurate scaling operations, authors presented an enhanced prediction model based on a neural networks, which is a combination of a classification and prediction model to predict the accurate utilization of resources. At the first stage, the proposed model categorizes the resources into three classes like over, normal and, under adaptively based on the utilization of resources. In the next stage, it predicts the future utilization of resources by using neural network regression model based on the classification results. The experimental results showed that the proposed model achieved accurate results.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],23.714285714285715,0.22000000000000003,0.4033333333333333,0
470,470,Brain Tumor Detection from Multimodal MRI Brain Images using Pseudo Coloring Processes," All rights reserved.In this work, we come up with a novel method to merge the color channels created from multi modal images to form a RGB image and then highlight the tumor in the MRI brain images, detect and extract the tumor region from the human head scan MRI images. This extraction process is done purely based on multimedia color channels and the basic characteristics of a MRI brain image. The original multi modal grayscale images (FLAIR, T2, T1c) are used to build the Red, Green and Blue channels respectively and then combined to form a whole RGB image using the pseudo coloring process. The Pseudo colored brain images are then analyzed for the presence of specific colors in the images which clearly identifies the tumor region in the whole brain¬ image. The tumor and necrotic regions are shown in the RGB images in Golden Yellow color and White color respectively. Experimental study was done on BRATS high glioma imagesets. The main objective of this work is to detect the tumor in the human brain scans. A detailed study has to be done to detect the various regions of tumor. The results given by the proposed method reached good qualitative and quantitative level.",60102020,The Gandhigram Rural Institute,Gandhigram,India,['1700'],22.666666666666668,0.1180848861283644,0.30898550724637674,0
471,471,Image Contrast Enhancement by Homomorphic Filtering based Parametric Fuzzy Transform," All rights reserved.In this paper, a new image contrast enhancement technique by taking the advantages of Homomorphic decomposition and fuzzy transform is been employed. For increasing the clarity of the image generally, histogram or Retinex theory based algorithms were used. These procedures worked on enhancing the reflectance layer by ignoring illumination, which is not a better strategy and leads to poor results. Fuzzy based image enhancement approach makes use of illumination by omitting reflectance. In our proposed algorithm, Homomorphic decomposition is used for getting the exact illumination image from the value layer of HSV (Hue, Saturation, Value) image. Next, the parametric fuzzy transform is employed to enhance the image by updating its membership functions and thereby smoothing the luminance layer. Finally, a weighted image is generated by pixel neighborhood property for preserving the image details. The results show the profoundness of the algorithm in terms of its clarity and complexity even for nonuniform illumination images.",60114435,Kakatiya Institute of Technology &amp; Science,Hanamkonda,India,['1700'],19.5,-0.03051948051948052,0.4720779220779221,0
472,472,Analysis of Classifiers for Fake News Detection," All rights reserved.As time flows, the amount of data, especially text data increases exponentially. Along with the data, our understanding of AI also increases and the computing power enables us to train very complex and large models faster. Fake news has been gathering a lot of attention worldwide recently. The effects can be political, economic, organizational, or even personal. This paper discusses the approach of natural language processing and machine learning in order to solve this problem. Use of bag-of-words, n-grams, count vectorizer has been made, TF-IDF, and trained the data on five classifiers to investigate which of them works well for this specific dataset of labelled news statements. The precision, recall and f1 scores help us determine which model works best.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],17.571428571428573,0.05675324675324676,0.42032467532467527,0
473,473,Certain Investigation on MANET Security with Routing and Blackhole Attacks Detection," All rights reserved.Mobile Ad-hoc Network (MANET) is a self-configuring network depending upon infrastructure, also is a significant technology which supplies virtual hardware and software resources as per requirement of mobile ad hoc network. The Intrusion Detection System (IDS) has been established to protect Cross Interior (routing) at source to goal from different types of attack. Current IDS approaches can be classified as either anomaly or signature-based methods such as Rule-based expert systems, State transition analysis, Bayesian alarm networks aspects are various challenges with respect to the efficiency as well as performance. The major challenge is the compromise of performance because of unavailable resources with respect to the MANET. To increase the MANET environment's performance, various techniques are employed for routing, security purpose. An efficient security module requires a routing in terms of packet loss. The Integrated Cross Interior (ICI) structure for Intrusion Detection System (IDS) namely ICIs for IDS are proposed for exactness of black hole attacks detection. The ICIs for IDS performs the task of routing of the mobile nodes. The proposed (ICIs for IDS) produces the enhancement of Intrusion Detection System (IDS) with routing algorithm named as Integrated Cross Interior algorithm that performs maps the security with the secure IDS communication and distributes the packets among different destination, based on priority. This paper proposes a novel Integrated Cross Interior structure for Intrusion Detection System (ICIS for IDS) to secure our network from black hole attacks. This algorithm is proposed for node routing and node security by considering maximum throughput 83.5% with minimum routing cost, response time with 6.3ms. The experimental results specify that ICIs for IDS based security policy effectively minimizes the response time as well as the mobile routing cost, response time of an application with respect to other existing approaches such as IDS with AODV. The proposed algorithm is experimented using Network Simulator-2 and the results demonstrated that the performance of the algorithm is better than other conventional algorithms like IDS with AODV.",60106781,JNT University Anantapur,Anantapur,India,['1700'],25.23076923076923,0.0744047619047619,0.4282091097308489,0
474,474,Robust blind detection of integer carrier frequency offset for terrestrial broadcasting systems using band segmented transmission,"In the integrated services digital broadcasting-terrestrial (ISDB-T) system, the combination of digital terrestrial transmission and MPEG-4 advanced video coding (MPEG-4 AVC) has offered ways to provide a variety of digital high-definition television (HDTV) programs. Using band segmented transmission orthogonal frequency division multiplexing (BST-OFDM), the delivery of innovative video-on-demand and HDTV services is supported. To take full advantage of the attractive benefits of BST-OFDM, it is important to estimate integer frequency offset (IFO) without a priori knowledge on the segment type that is transmitted over transmission and the multiplexing configuration control (TMCC) signal. To address this issue, an efficient IFO detection method is proposed for the ISDB-T system employing BST-OFDM. To enable IFO detection independent of the segment type, information-bearing TMCC signals that are asymmetrically distributed in the frequency domain are used as pilot symbols. Numerical analysis is performed to present the relationship between error probability and design parameter. We show via the numerical results that the multiple transmitted TMCC information is efficiently used for blind estimation of the IFO, achieving robust estimation in the presence of the fractional frequency offset.",60027884,Sejong University,Seoul,South Korea,['1701'],25.714285714285715,0.14999999999999997,0.38782051282051283,1
475,475,Diagnosis of Parkinson's disease using Gait Dynamics and Images, All rights reserved.Parkinson's disease is a neuro-degenerative disorder in which dopamine producing neurons in the brain structure called substantia nigra has damaged entire over time. PD leads to number of modal problems and mental disabilities. This paper presents a gait dynamic technology for the early stage prediction of Parkinson's disease and a discussion on the Image processing technologies related to PD diagnosis. The analysis of gait in Parkinson's disease helps to understand the behaviour of the neural system and so the early detection of Parkinson's disease is possible. This can help neurologists to improve their treatment and to give guidance in reintegrate programs. This paper introduces an efficient multi-sensor data analysis of gait force in PD with respect to healthy subjects using PARAFAC model. Tensor decomposition is proposed in the work for the analysis of multi-sensors data. The data are collected from PhysioNet gait database consist of multichannel recording from force sensors of 93 patients with PD and 73 healthy subjects.,60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],20.25,0.12222222222222223,0.4435185185185185,0
476,476,On the assumption of the independence of thermodynamic properties on the gravitational field,"A reversible cyclic process is analyzed in which the center of mass of an ideal gas is raised in a gravitational field during both an expansion phase and a subsequent contraction phase, with the gas returning to its initial height in a final step. When the properties of the gas are taken as uniform, the thermodynamic efficiency of this cycle is able to exceed that of a corresponding Carnot cycle, which is a violation of the second law of thermodynamics. The source of this discrepancy was previously claimed, when analyzing a similar heating and cooling of a sphere, to be the assumed independence of the internal energy on the gravitational field. However, this violation is only apparent since all of the effects of the gravitational field were not incorporated fully into the thermodynamic analysis of the cycle. When all the influences of the gravitational field are considered, no possible violation of the second law can occur. The evaluation of the entropy changes of the gas throughout the cycle also highlights other key inconsistencies that arise when the full effects of the gravitational field are neglected. As the analysis of the cycle provided here shows, the assumption of the independence of the internal energy, as well as other thermodynamic properties, on the gravitational field strength can still be invoked.",60009254,Purdue University,West Lafayette,United States,['1701'],31.142857142857142,0.059166666666666666,0.3995833333333333,1
477,477,Multi Criteria based Resource Score Heuristic for Cloud Workflow Scheduling," All rights reserved.Scheduling scientific workflows modelled by Directed Acyclic Graphs (DAG) is an NP complete problem. Cloud computing provides reliable Quality of Service defined in terms of Service Level Agreements (SLA). To schedule scientific workflows in cloud environment, where resources are shared, it is important to manage the cloud resources efficiently by maximizing utilization. The dynamic nature of cloud resources, due to sharing, heterogeneity, virtualization and workload variations offer a host of challenges in terms of resource availability and performance. This may have a significant impact on task execution times and data transfer times, thus introducing delay in overall execution time called makespan, In this paper, Multi Criteria based Resource Score Heuristic for Cloud Workflow Scheduling is proposed, with an objective of minimizing makespan considering the probability of temporal availability of resources in a cloud computing environment. To choose the best virtual machine with optimal value of maximum resource availability and minimum task execution time, a method of compensatory aggregation of conflicting criteria, is used for scoring each resource. The simulation results demonstrate that the proposed heuristic, can generate schedules with better makespan minimization and is found to be more reliable since resource availability factor is considered while mapping tasks to virtual machines.",123085501,Maharani Lakshmi Ammanni College for Women,Bengaluru,India,['1700'],29.142857142857142,0.275,0.4216666666666667,0
478,478,Implicit Aspect Extraction for Sentiment Analysis: A Survey of Recent Approaches," All rights reserved.The research in Sentiment analysis (SA) is in vastly growing stage as people become more expressive on social media, blogs, forums and e-commerce websites by sharing their opinions, reviews and comments. In Aspect-level SA opinions about various aspect or features of an entity is extracted. Users specify aspects by explicit words (i.e. Explicit aspects) or sometimes the aspects must be inferred from the text (implicit aspects).Detecting implicit aspects is challenging but very important and limited studies focused on the extraction of implicit aspects. This paper provides a survey on recently proposed techniques for detecting implicit aspects. We have classified the studies according to approaches they have followed, also specified limitations and future work stated by authors. We have discussed different issues in implicit aspect extraction which will give directions for future research.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.285714285714285,0.19015873015873017,0.5257936507936508,0
479,479,Non-Dual multi-granulation neutrosophic rough set with applications,"Multi-attribute decision-making (MADM) is a part of management decision-making and an important branch of the modern decision theory and method. MADM focuses on the decision problem of discrete and finite decision schemes. Uncertain MADM is an extension and development of classical multi-attribute decision making theory. When the attribute value of MADM is shown by neutrosophic number, that is, the attribute value is complex data and needs three values to express, it is called the MADM problem in which the attribute values are neutrosophic numbers. However, in practical MADM problems, to minimize errors in individual decision making, we need to consider the ideas of many people and synthesize their opinions. Therefore, it is of great significance to study the method of attribute information aggregation. In this paper, we proposed a new theory-non-dual multi-granulation neutrosophic rough set (MS)-to aggregate multiple attribute information and solve a multi-attribute group decision-making (MGDM) problem where the attribute values are neutrosophic numbers. First, we defined two kinds of non-dual MS models, intersection-type MS and union-type MS. Additionally, their properties are studied. Then the relationships between MS, non-dual MS, neutrosophic rough set (NRS) based on neutrosophic intersection (union) relationship, and NRS based on neutrosophic transitive closure relation of union relationship are outlined, and a figure is given to show them directly. Finally, the definition of non-dual MS on two universes is given and we use it to solve a MGDM problem with a neutrosophic number as the attribute value.",60069726,Shaanxi University of Science and Technology,Xinyang,China,['1701'],21.90909090909091,0.13741258741258738,0.4567599067599068,1
480,480,Diabetes Prediction using Machine Learning Algorithms," All rights reserved.Diabetes Mellitus is among critical diseases and lots of people are suffering from this disease. Age, obesity, lack of exercise, hereditary diabetes, living style, bad diet, high blood pressure, etc. can cause Diabetes Mellitus. People having diabetes have high risk of diseases like heart disease, kidney disease, stroke, eye problem, nerve damage, etc. Current practice in hospital is to collect required information for diabetes diagnosis through various tests and appropriate treatment is provided based on diagnosis. Big Data Analytics plays an significant role in healthcare industries. Healthcare industries have large volume databases. Using big data analytics one can study huge datasets and find hidden information, hidden patterns to discover knowledge from the data and predict outcomes accordingly. In existing method, the classification and prediction accuracy is not so high. In this paper, we have proposed a diabetes prediction model for better classification of diabetes which includes few external factors responsible for diabetes along with regular factors like Glucose, BMI, Age, Insulin, etc. Classification accuracy is boosted with new dataset compared to existing dataset. Further with imposed a pipeline model for diabetes prediction intended towards improving the accuracy of classification.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],16.0,0.07146890987800081,0.4471987860624224,0
481,481,Improvement of Crop Production Using Recommender System by Weather Forecasts," All rights reserved.Establishing linkages between Meteorological and climatic data, and farming decision-making is a challenging task. The following paper addresses the challenges associated with this. A large amount of weather and climate information is presently available for farmers. A portion of the information is operational or already under development, and in particular, forecasting through climatic data and formation may not be suitable for farmers when it comes to the decision-making process. The best way to gain an advantage from natural factors is to consider them during decision-making and understand them in the best way possible. Meteorological information pertaining to agriculture, and climatic data, in particular, is an important aspect of planning in the context of agricultural production. Therefore, climatic conditions must be an integral part of the decision-making process. These factors can be determined by recording hourly, daily, and weekly temperature data, rainfall, solar radiation, wind speed, evaporation, relative humidity, and evapotranspiration. Artificial Neural Networks possess the capability of not just analysing the data but also learning from the data. This paper presents a predictive analysis to analyse the best crop which can be produced for specific weather conditions and also suggests a hybrid recommender system that adopts CBR - Case-Based Reasoning for enhancing the success ratio of the system. This proposed novel hybrid system is a combination of the collaborative filtering technique and case-based reasoning.The novelty of the model lies in the of district-wise agriculture data analysis for predicting future climatic conditions and recommending crops based on that climatic conditions and also considering the agriculture pattern of the district using a hybrid recommender system.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],24.181818181818183,0.27355889724310783,0.4155388471177945,0
482,482,Performance analysis and optimum design of a redundant planar parallel manipulator,"This work presents a comprehensive performance evaluation and optimum design of a novel symmetrical 4-PPR (P indicates the prismatic joint, R denotes the revolute joint, and the letter with underline represents an active joint) redundant planar parallel manipulator. The kinematic model is established, upon which the inverse position and singularity are analyzed. Based on the evaluation of dexterity, velocity, and stiffness performance, the optimum region is achieved. With the optical design parameters, a case study for the analysis of dynamic behavior is conducted. Performance comparison between the redundant manipulator and another two non-redundant 3-PPR planar parallel manipulators, one with a D-shape symmetrical structure and the other with U-shape symmetrical structure, is presented. Simulation results reveal that the U-shape manipulator has the greatest velocity performance. Moreover, the redundant manipulator possesses the best dexterity, stiffness, and dynamic performance.",60031991,Chongqing University of Technology,Chongqing,China,['1701'],19.428571428571427,0.19551282051282054,0.3852564102564103,1
483,483,Error Detection of Data Conversion in Flash ADC using Code Width Based Technique," All rights reserved.The high integration density of the complex electronic system requires the multi-functional testing facility to ensure the accuracy of the circuit function. In addition, the wide population of submicron technologies results in the persistent requirements of high precision analog and mixed-signal (AMS) circuits. In the complex, high-density circuits, observing the correctness of output are limited due to the limitations of input and output pins which develop the AMS circuit test as very difficult and expensive. A digital built-in self-test (BIST) scheme has been presented in this paper for testing an analog to digital converter (ADC) in the time domain. The testing scheme consists of the linear analog ramp generator, ADC as a circuit under test, output response analyzer and a BIST controller. Bootstrap linear ramp generator is used to generate the linear analog ramp signal which is applied to ADC to develop the digital word sequence for testing. Among various types of ADCs, here a Flash ADC has used since it is fastest and accurate in digital conversion. A Flash ADC has been designed with the seven-bit resolution and tested using the proposed digital BIST scheme. The ADC comprises a sample-hold circuit, 2N -1 comparator, XOR gates, and encoder block. The output response analyzer verifies the digital output sequence to validate the static test parameters of ADC called monotonicity, missing codes, DNL, and INL error. The BIST controller generates the control signals to control the test sequence. The complete test sequence of ADC BIST has simulated in Tanner EDA with TSMC 0.18um technology. ORA is used to analyze the presence of monotonicity, missing codes, DNL and INL error in the ADC output.",60005941,Madras Institute of Technology,Chennai,India,['1700'],21.153846153846153,-0.05363945578231292,0.3348185941043084,0
484,484,Geographic wayfinders and space-time algebra,"Time Geography is a framework for describing reachable points in a (static) spatio-temporal environment. While originally devised to facilitate reasoning about an individual's or a population's living conditions, it was later adapted to many other applications. A wayfinder is an entity that moves through a space-time continuum with possible obstacles. We show how to model the pertinent notions in relational algebra (and, more abstractly, in modal semirings) with box and diamond operators. Admissible or undesired regions can be described as Boolean combinations of primitive regions such as the set of all points reachable by forward or backward movement from a given region or starting point. To derive results about the region blocked by the union of two regions we introduce an abstract algebraic view of coordinates that is largely independent of dimensional and metric aspects and thus very general. Moreover, the approach lends itself quite well to machine-supported proofs.",60016060,Universität Augsburg,Augsburg,Germany,"['1712', '1703']",21.285714285714285,0.13576923076923075,0.4461538461538461,1
485,485,"IoT based Assistive Device for Deaf, Dumb and Blind People"," All rights reserved.Focusing and addressing the problems faced by the differently abled people such as visually, audibly and vocally challenged, through a single device is a tough job. A lot of research has been done on each problem and solutions have been proposed separately. But not all of them are addressed together. The aim of the project is to create a single device solution in such a way that is simple, fast, accurate and cost-effective. The main purpose of the device is to make the differently abled people, feel independent confident by seeing, hearing and talking for them. The paper provides a Google API and Raspberry Pi based aid for the blind deaf and dumb people. The proposed device enables visually challenged people to read by taking an image. Further, Image to text conversion and speech synthesis is done, converting it into an audio format that reads out the extracted text translating documents, books and other available materials in daily life. For the audibly challenged, the input is in form of speech taken in by the microphone and recorded audio is then converted into text which is displayed in the form of a pop-up window for the user in the screen of the device. The vocally impaired are aided by taking the input by the user as text through the built-in customized on-screen keyboard where the text is identified, text into speech conversion is done and the speaker gives the speech output. This way the device speaks for the user.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],22.818181818181817,0.006424792139077857,0.41836734693877553,0
486,486,An insightful review on educational big data analytics in cloud-based e-learning system,"With the rapid momentum of progress in the methodology of knowledge delivery system in existing cloud-based e-learning system, there is also a rising awareness of the complexity of the upcoming educational big data in present times. In current era of cloud computing, there has been various research-based implementations toward leveraging analytical operation along with presence of wide ranges of analytical tools. However, there is no much reported tool to offer educational-based big data analytics. This problem has been addressed by various researchers with an aid of conceptualized, analytical, qualitative, and quantitative models. Therefore, the contribution of the proposed manuscript is to perform an exhaustive review of big data-based approaches as well as research-based analytical tools presented by various researchers in the form of advantages and limitation as well as exploration of open research issues.",60078724,Ramaiah Institute of Technology,Bengaluru,India,['1700'],26.8,0.004166666666666666,0.29583333333333334,1
487,487,Preface to the special issue on the 10th International Conference on Graph Transformation,"This special issue contains extended versions of five selected papers from the 10th edition of the International Conference on Graph Transformation (ICGT 2017). The articles cover the analysis of conflicts and dependencies of graph transformation, the specification of graph languages by type graphs, a new approach to graph transformation supporting cloning, modelling and analysis of probabilistic timed systems, and parsing for hyperedge replacement grammars.",60026796,Universidad Autónoma de Madrid,Madrid,Spain,"['1712', '1703']",32.0,0.18587662337662336,0.3189935064935065,1
488,488,Tight bounds on 1-harmonious coloring of certain graphs,"Graph coloring is one of the most studied problems in graph theory due to its important applications in task scheduling and pattern recognition. The main aim of the problem is to assign colors to the elements of a graph such as vertices and/or edges subject to certain constraints. The 1-harmonious coloring is a kind of vertex coloring such that the color pairs of end vertices of every edge are different only for adjacent edges and the optimal constraint that the least number of colors is to be used. In this paper, we investigate the graphs in which we attain the sharp bound on 1-harmonious coloring. Our investigation consists of a collection of basic graphs like a complete graph, wheel, star, tree, fan, and interconnection networks such as a mesh-derived network, generalized honeycomb network, complete multipartite graph, butterfly, and Benes networks. We also give a systematic and elegant way of coloring for these structures.",60073547,Anhui Jianzhu University,Hefei,China,['1701'],25.5,0.10357142857142859,0.5660052910052911,1
489,489,Personalized Review Selection," All rights reserved.With the popularity of the online social network, reviews gradually becoming the main data source for users to understand the qualities of the goods to be purchased. However, with the proliferate of online reviews, these large amounts of reviews make it difficult for users to select useful information. Aiming to enable users to quickly obtain valid information from large amounts of reviews, this paper proposes a new method named PG to implicate personalized review selection. The proposed method in our paper is efficient for users by helping them select useful information from massive reviews.",60103533,Xinjiang Technical Institute of Physics and Chemistry,Urumqi,China,['1700'],24.25,0.14984258166076347,0.46015348288075564,0
490,490,Effective Diagnosis of Alzheimer's Disease using Modified Decision Tree Classifier," All rights reserved.Alzheimer's disease (AD) is described as a severe form of the neural disorder that collectively degenerate the essential cognitive activities of a human being (thinking, memory retention, etc.,) in particular among the elderly individuals and eventually results in death. In addition to the adverse ill-health effects on the patients, AD imposes paramount responsibility and burden on the caretakers too. Several genetic and pathological traits and non-invasive diagnostic strategies are being vigorously investigated and explored to discover the early onset of this debilitating disease. The prognosis of AD assumes importance, as the deterioration of health due to its progression may be either contained or controlled. Moreover, early and accurate detection of AD helps medical practitioners to prescribe case-specific medical treatment procedure. Among the popular machine learning algorithms, decision tree technique is widely used for classification/prediction, due to its accuracy and speed.This research article presents a novel decision tree-based classification technique, with optimum hyper parametertuning, that is ideally suitable for AD diagnosis, even at the early stages of development. The performance of this newly proposed Decision Tree Classifier with Hyper Parameters Tuning (DTC-HPT) is validated on the Open Access Imaging Studies Series (OASIS) dataset that contains patients' data on the different stages of AD. The DTC-HPT is designed with the primary objective to classify the nature of brain abnormality using the most relevantand potentially significant data attributes/parameters. The efficiency of DTC-HPT on AD classification is measured as Accuracy, Precision, Recall, and F1-Score. The correctness of AD classification by DTC-HPTwith an average accuracy of 99.10% endorse that this classification technique can be used for AD detection on the AD clinical datasets.",60102020,The Gandhigram Rural Institute,Gandhigram,India,['1700'],27.1,0.1511679292929293,0.41234217171717163,0
491,491,Hybrid Segmentation and Feature Extraction Approach to Detect Tumour Based on Fuzzy Rough-in Mammogram Images," All rights reserved.Tumor classification plays a significant area of research in mammogram images. In this paper, we introduce the tumor classification method in mammogram images by using Fuzzy rough set theory (FRST) and it offers an accurate approach of texture and feature extraction. The core purpose of deploying FRST is feature extraction which is achieved by using a quick reduct algorithm which helps to identify the tumor without loss of pixels in a short period. Fuzzy rough instance selection (FRIS) is applied to remove the noise from the mammogram image and finally the combination of fuzzy-rough nearest neighbor (FRNN) method is used in segmentation. The results obtained using the proposed methods are compared in various performance measures such as accuracy, sensitivity and specificity are calculated accurately.",60021927,Madurai Kamaraj University,Madurai,India,['1700'],25.4,0.12803030303030305,0.521969696969697,0
492,492,Cognitive Learning Based Missing Value Computation in Cardiovascular Heart Disease Prediction Data," All rights reserved.The entity defined as data science is being utilized day in and day out in variant domains ranging from health care, finance, banking, production and manufacturing industry. The vital requirement for the entity mining of data based upon application methodology is to acquire digital data which the attributes of crystal clear added to consistency. Many times it is literally a challenge in wangling this defined digital data right out of the unstructured realm. The above mentioned digital data may possess unwanted noises, falsified details, and may or may not be prone to error. This desideratum of this manuscript sheds light in monitoring an innovative overture in overseeing a unique erratum, which in turn defined as the values which are lost that which forms the metrics in a cardio vascular disease data which holds these values together. The entities existing in this planet have a purpose, like wise this manuscript stamps its purpose by means of guesstimating the steadfastness of networks based out of neural for infusion of sets of data which were deemed lost by any means by permutated possibilities in the domain of Healthcare.",60023330,Sathyabama Institute of Science and Technology,Chennai,India,['1700'],31.333333333333332,0.24672619047619046,0.4599206349206349,0
493,493,Exploring the perspective of health and well-being among orang asli: Case study of Jakun,"This study is focus on health perspectives and its impact on the Orang Asli well-being. Through aboriginal worldview, health can be studied from physical, mental, emotional and spiritual components. Using qualitative study, we aim to understand Orang Asli perspectives of health and its components and the way it impacts their overall well-being. Participants were purposively selected from the largest tribe of Orang Asli in Malaysia. Based on the analysis, all components of health in the predetermined construct are important for them and affect their well-being. Further discussions are made on each construct and components particularly in relation to well-being.",60110424,Universiti Islam Sultan Sharif Ali,Bandar Seri Begawan,Brunei Darussalam,['1700'],16.5,0.058333333333333334,0.3699404761904762,1
494,494,On eccentric topological indices based on edges of zero divisor graphs,"This article is devoted to the determination of edge-based eccentric topological indices of a zero divisor graph of some algebraic structures. In particular, we computed the first Zagreb eccentricity index, third Zagreb eccentricity index, geometric-arithmetic eccentricity index, atom-bond connectivity eccentricity index and a fourth type of eccentric harmonic index for zero divisor graphs associated with a class of finite commutative rings.",60106293,Jazan University,Jazan,Saudi Arabia,['1701'],30.5,0.06944444444444443,0.27777777777777773,1
495,495,Big Data Performance Analysis on a Hadoop Distributed File System Based on Geometric Data Perturbation Technique," All rights reserved.In this paper, we proposed a Big Data Security Analysis based on a modified perturbation technique in a Hadoop Distributed File System which is commonly used in various real time applications. This work have utilized an improved K-means clustering algorithm, which selects the initial clustering centres based on the density parameters. The poor assurance of initial centres and in order to improve the precision and packing effect of the K-means clustering computation is to be need a new method. In order to group the data of same cluster based on their similarities clustering algorithm was used. In the various clustering methods, this paper is utilizing the geometric data perturbation technique which is clustered, data are perturbed whose values are challenging to be recognized. The performance was evaluated on a sample Health Care database and the metrics under studies are memory usage, precision, recall, accuracy, F-measure, clustering time and execution time, Perturbation time, De-perturbation time. In this paper, we focused only on Perturbation Time, De-Perturbation Time and the Accuracy. The experimental result shows that the proposed approach reduces the complexity and shown to less computation time and better accuracy than that of the existing techniques.",60114400,Valliammai Engineering College,Kattankulathur,India,['1700'],24.625,0.03797979797979798,0.4030808080808081,0
496,496,Statistical inference of the rayleigh distribution based on progressively type II censored competing risks data,"A competing risks model under progressively type II censored data following the Rayleigh distribution is considered. We establish the maximum likelihood estimation for unknown parameters and compute the observed information matrix and the expected Fisher information matrix to construct the asymptotic confidence intervals. Moreover, we obtain the Bayes estimation based on symmetric and non-symmetric loss functions, that is, the squared error loss function and the general entropy loss function, and the highest posterior density intervals are also derived. In addition, a simulation study is presented to assess the performances of different methods discussed in this paper. A real-life data set analysis is provided for illustration purposes.",60022381,Beijing Jiaotong University,Beijing,China,['1701'],21.2,-0.03,0.44000000000000006,1
497,497,IoT Device for Disabled People, All rights reserved.Sign language is a medium used for communicating feelings and emotions with normal people using expression and gestures. The focus of this research work is to create an IoT device that connects the real world and the people with disability. Physically challenged still prefer using sign language and our aim is to create a bridge that removes the communication gap between the disabled and normal people. The proposed design makes use of hand gloves mounted with flex sensors which recognize the characters and commands [4]. The gestures recognized will be displayed as audio and visual output through LCD and Bluetooth speaker. The Optical Character Recognition is used for the blind people in order to recognize the text-based images for audio and LCD display [16]. This system consists of live tracking as one of the modules for tracking the physically challenged people. The purpose is to enhance and improve the system for detecting sign language. The device not only converts sign languages to speech but also have incorporated modules like Optical Character Recognition (OCR) and live tracking[I].,60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],19.88888888888889,0.006611570247933876,0.4411255411255411,0
498,498,Telemedicine Setup using Wireless Body Area Network over Cloud," All rights reserved.Healthcare has been grown into a new paradigm because of Telemedicine. Hence patients get easy access of teleconsultations for diagnosis and treatments. Patients get numerous benefits in practicing telemedicine when there is a need of an immediate consultation, being anywhere. In this paper, through wireless body area network, telemedicine has been investigated and practiced for remote patients constantly being monitored. The medical records of patients are stored very carefully in the cloud. The doctors create a network who can respond to emergency conditions of patients. Here, three different parameters viz., blood viscosity, blood pressure and blood sugar level are measured, constantly monitored, and sent to cloud for storage and analysis. Then, for emergency condition, on the spot treatment is given after teleconsultation, by the doctor near the patient's locality; otherwise teleconsultation alone is given. The healthcare professionals at the care centers have remote monitoring capability as well as registers patients for storing and monitoring health information anytime, anywhere. Security during teleconsultation is also possible as the data are stored in cloud. Cloud gives dynamic, scalable and portable infrastructure. This is achieved through the use of trusted software, compliance understanding, lifecycle management, portability, continuous monitoring, and choice of right people. It is possible through secure log-in access, risk tolerance, cost-benefit analysis giving protection to data, applications and infrastructure. There is high-level security like avoiding attack, no unauthorized leaks and exposure of data and no weak access of control. This is achieved through data-centric approach where the data is encrypted and strengthened through the authorization process of requiring strong passwords and two factor authentication.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],17.666666666666668,0.09145803270803271,0.5286255411255412,0
499,499,Impact of factors determining retailing culture in india and its impact on the online shopping of electronic goods and in india: An empirical study,"Purpose of the Study: The study aims to find out that the factors determining the online shopping of electronic goods in India, which is an emerging market. The study related through empirical evidences the various salient features of online retailing to their intention to purchase the consumer electronic goods. Scope: The study is limited to the online retailing determinants in relation to the electronic goods industry. The geographic scope of the study is Delhi-NCR. The study comprehensively covers the various aspects of online retailing as independent variables consumer buying behavior towards electronic goods as dependent variables. Research Design & Methodology: The study is descriptive in nature. The data have been collected from the respondents who had made at least one online purchase of an electronic item in the last six months. The sample size of the study was 500 and the data has been analyzed with the help of regression analysis. Findings: The study finds that various determinants of online retailing have a positive and significant impact on online consumer buying behavior towards electronic products. Originality: The study determines the online retailing factorswith the items that have been newly explored in the present work only. The study has determined the association between the factors that support electronic buying Type: Empirical Research Paper.",108583127,Maharishi Dayanand University,Rohtak,India,['1700'],19.272727272727273,0.037813852813852813,0.3806349206349206,1
500,500,Time analysis of actor programs,"This paper proposes a technique for estimating the computational time of programs in an actor model, which is intended to serve as a compiler target of a wide variety of actor-based programming languages. We define a compositional translation function returning cost equations, which are fed to an automatic off-the-shelf solver for obtaining the time bounds. Our approach is based on a new notion of synchronization sets, which captures possible difficult synchronization patterns between actors and helps make the analysis efficient and precise. The approach is proven to correctly over-approximate the worst computational time of an actor model of concurrent programs. Our technique is complemented by a prototype analyzer that returns upper bound of costs for the actor model.",60110772,Western Norway University of Applied Sciences,Bergen,Norway,"['1712', '1703']",23.6,-0.15194805194805192,0.6649350649350649,1
501,501,Comparative Study of different Lazy Learning Associative Classification Methods," All rights reserved.Lazy Learning Associative Classification (LLAC) is a promising approach in the field of data mining. It is one of the associative classification methods in which it delays the processing of training datasets until it receives the test instance for the class prediction. Lazy learning associative classification can be constructed in two phases. Subset generation is the first phase and the subset evaluation is the second phase. In the past decades, many lazy learning associative classification methods have been proposed. These algorithms utilize several different methods for subset generation and subset evaluation. This paper focuses on comparative study of different lazy learning associative classification methods.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],15.285714285714286,-0.004545454545454544,0.5257575757575756,0
502,502,Contra gη-continuityin topological spaces,In this paper a new class of functions namely contra gη-continuous in the light of gη-continuous in topological spaces is introduced. Further some of their characterizations are investigated.,60114579,PSGR Krishnammal College for Women,Coimbatore,India,['1700'],14.0,0.1787878787878788,0.5515151515151515,1
503,503,An enhanced optimization scheme based on gradient descent methods for machine learning,"A The learning process of machine learning consists of finding values of unknown weights in a cost function by minimizing the cost function based on learning data. However, since the cost function is not convex, it is conundrum to find the minimum value of the cost function. The existing methods used to find the minimum values usually use the first derivative of the cost function. When even the local minimum (but not a global minimum) is reached, since the first derivative of the cost function becomes zero, the methods give the local minimum values, so that the desired global minimum cannot be found. To overcome this problem, in this paper we modified one of the existing schemes-the adaptive momentum estimation scheme-by adding a new term, so that it can prevent the new optimizer from staying at local minimum. The convergence condition for the proposed scheme and the convergence value are also analyzed, and further explained through several numerical experiments whose cost function is non-convex.",60029274,Daegu University,Gyeongsan,South Korea,['1701'],27.333333333333332,0.02305194805194805,0.25183982683982686,1
504,504,Two Three Step Authentication in ATM Machine to Transfer Money and for Voting Application," All rights reserved.Voting plays a major role in electing a right person by the public to rule the country. The main aim of the paper is to perform two operations such as transaction of money and for voting application through ATM machine, by providing the authentication like Biometric - Fingerprint and Face Recognition through the comparison with the Aadhar car for more security and privacy. This voting application through ATM's makes more easier and faster for the people to increase the percentages of votes.",60100082,Karunya Institute of Technology and Sciences,Coimbatore,India,['1700'],28.333333333333332,0.21641156462585034,0.4193877551020408,0
505,505,"Design of New Multi-Column 5,5:4 Compressor Circuit Based on Double-Gate UTBSOI Transistors"," All rights reserved.In the modern electronic devices, compressor circuits are used to speed up the partial product addition (PPA) stage in the multipliers. This paper presents an architecture of multi-column 5,5:4 compressor whose new transistor level implementation has been carried out through the ultra-thin-body silicon-on-insulator (UTBSOI) transistors. Such compressor has been simulated in Cadence-spectre, and the performance parameters like power consumption and delay has been calculated at the rising and falling edge transition of input pulses. Advantage of the UTBSOI-compressor is further clarified from its comparison with the CMOS based design (CMOS-compressor). Simulation results reveal that the PDP exhibited by the UTBSOI-compressor is reduced by 79.89% than that of CMOS counterparts. Furthermore, to showcase the advantage of such compressor, it has been applied in the multiplier for PPA which offers ≈11.5% improvement in terms of power-delay-product (PDP) in the Virtex 6 platform.",60107379,National Institute of Technology Meghalaya,Shillong,India,['1700'],23.833333333333332,0.048051948051948054,0.36493506493506495,0
506,506,Classification of Neurodegenerative Disease Stages using Ensemble Machine Learning Classifiers," All rights reserved.Existing research works for Alzheimer's disease (AD) can predict the prevalence of disease only after the advancement of the disease. With these existing prediction models, it is possible only to reduce and delay the symptoms of the disease. The exact usefulness is when the presence of the disease is identified at an early stage and this early detection makes a great impact in subjects' recovery. Thus, early detection of controls at high risk of development of Alzheimer's disease is of a key objective of the proposed work. Existing machine learning and deep learning algorithms derive only limited predictive accuracy. Also, they derive results based on expensive machine learning algorithms that had hard-to-collect features and classifying becomes complex with numerous overfitting in choosing decision boundaries. The proposed study intends to develop a learning algorithm for the prediction of Alzheimer's disease at an early stage. It also classifies the features if the subjects with Mild Cognitive impairment (MCI) and Pre-Mild Cognitive Impairment (Pre-MCI)has the likelihood to develop Alzheimer's disease. A dataset of AD controls was used to train different machine learning algorithms. Onset information like social behavior, demographic characteristics, neurological test scores, clinical cardiovascular index, and brain atrophy ratio can also be used as the extract predictor. A validation procedure was applied to identify a relevant subset of predictors. The conversion to AD in MCI and Pre MCI subjects are based only on non-invasively and effectively collectible predictors.",60103989,"Sri Krishna College of Engineering and Technology, Coimbatore",Coimbatore,India,['1700'],19.916666666666668,0.04188492063492064,0.5770634920634921,0
507,507,An asymmetric bimodal distribution with application to quantile regression,"In this article, we study an extension of the sinh Cauchy model in order to obtain asymmetric bimodality. The behavior of the distribution may be either unimodal or bimodal. We calculate its cumulative distribution function and use it to carry out quantile regression. We calculate the maximum likelihood estimators and carry out a simulation study. Two applications are analyzed based on real data to illustrate the flexibility of the distribution for modeling unimodal and bimodal data.",60025749,Universidad Católica de Temuco,Temuco,Chile,['1701'],15.2,0.2,0.30000000000000004,1
508,508,Multiple Sub-Filter Adaptive Noise Canceller for Fetal ECG Extraction," All rights reserved.Non-invasive monitoring of fetal cardiac signs through the signal processing of maternal abdominal signals has been emerging as a promising technique in the field of obstetrics and gynaecology. The underlying challenges in obtaining the Fetal Electrocardiogram (FECG) from maternal abdominal signals include elimination of dominant maternal ECG and other noises. The simple technique based on adaptive noise cancellers uses Single Long Filter (SLF) as adaptive filter for extracting the FECG. In this paper, we propose an algorithm for implementation of adaptive filter in adaptive noise canceller (ANC) as Multiple Sub-Filters (MSF). Each of the adaptive sub-filters are updated using the Least Mean Square (LMS) algorithm. The proposed MSF architecture is compared with traditional SLF ANC by testing using a real data from Daisy database. From the obtained results, it is observed that MSF-ANC performs better than SLF-ANC with 91.66% positive predictive value and 84.61% accuracy.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],21.142857142857142,0.016795704295704296,0.38687562437562445,0
509,509,Generalized orbifold euler characteristics on the grothendieck ring of varieties with actions of finite groups,"The notion of the orbifold Euler characteristic came from physics at the end of the 1980s. Coincidence (up to sign) of the orbifold Euler characteristics is a necessary condition for crepant resolutions of orbifolds to be mirror symmetric. There were defined higher order versions of the orbifold Euler characteristic and generalized (""motivic"") versions of them. In a previous paper, the authors defined a notion of the Grothendieck ring(VarC) of varieties with actions of finite groups on which the orbifold Euler characteristic and its higher order versions are homomorphisms to the ring of integers. Here, we define the generalized orbifold Euler characteristic and higher order versions of it as ring homomorphisms from (VarC) to the Grothendieck ring K0(VarC) of complex quasi-projective varieties and give some analogues of the classical Macdonald equations for the generating series of the Euler characteristics of the symmetric products of a space.",60027282,Universidad Complutense de Madrid,Madrid,Spain,['1701'],29.0,0.00151515151515152,0.4484848484848485,1
510,510,Emotional intelligence and its relationship with leadership quality among malaysian gifted and talented students,"This study aims to identify the Emotional Intelligence (EQ) competency and its relationship with Leadership Qualities (LQ) among Gifted and Talented Students (GTS) in Malaysia. Quantitative approach was employed where 294 GTS from Pusat PERMATApintar® Negara answered two questionnaires. The findings show that GTS had a high EQ score (81.85) and average leadership qualities (77.86). GTS obtained the highest score in maturity domain (91.70). In regards to LQ, GTS obtained a high score in collegiality (84.80%). There is a strong positive correlation between EQ and LQ (r [294] = 0.775, p = 0.00 (p <0.01). Results from this research support the view that GTS has a potential for excellent leadership. The Guidance and Counselling Unit needs to be committed in providing intervention programs to enlighten the GTS on leadership responsibilities and accountability. Programs related to EQ and LQ development can be integrated across subjects and co-curricular activities. This will help strengthen the psychological well-being and leadership qualities among GTS.",60001821,Universiti Kebangsaan Malaysia,Bangi,Malaysia,['1700'],15.9,0.252550505050505,0.6507323232323232,1
511,511,Credit Card Fraud Detection using Machine Learning Algorithms," All rights reserved.Credit card frauds are easy and friendly targets. E-commerce and many other online sites have increased the online payment modes, increasing the risk for online frauds. Increase in fraud rates, researchers started using different machine learning methods to detect and analyse frauds in online transactions. The main aim of the paper is to design and develop a novel fraud detection method for Streaming Transaction Data, with an objective, to analyse the past transaction details of the customers and extract the behavioural patterns. Where cardholders are clustered into different groups based on their transaction amount. Then using sliding window strategy [1], to aggregate the transaction made by the cardholders from different groups so that the behavioural pattern of the groups can be extracted respectively. Later different classifiers [3],[5],[6],[8] are trained over the groups separately. And then the classifier with better rating score can be chosen to be one of the best methods to predict frauds. Thus, followed by a feedback mechanism to solve the problem of concept drift [1]. In this paper, we worked with European credit card fraud dataset.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],18.2,0.17333333333333334,0.40611111111111103,0
512,512,The fairer sex: Male/female differences in architects' use of colour when designing,"This paper considers if the gender of architects, as one aspect of their cultural indoctrination, impacts their colour use. In other words, it considers if colour use in architectural design is gendered via a process of cultural indoctrination that is influenced by the attitudes towards gender, principally in relation to the biological sex binary, that are prevalent in the cultural contexts that shape us. A survey of 274 designers asked: Does gender affect an architect's general attitude towards three dependant variables: 1) colour use; 2) colour preferences; 3) use of colour when designing? It was found that while female architects perceived colour to be more important to architecture than males did, females' portfolios are significantly less colourful. Gender differences were also found for hue preference, dominant colour use and the use of colours for building exteriors. The findings provide the design community with more information about the relationship between culture and colour responses and highlight how gender values may, via colour use, impact architectural design. The authors argue for an approach to design education that acknowledges the potency of architects' subjective tendencies in relation to objective design influences such as the brief or the physical context of a building.",60018805,Deakin University,Geelong,Australia,['1704'],33.166666666666664,0.10416666666666667,0.3203231292517007,1
513,513,Automatic Determination of K in Distributed K-Means Clustering," All rights reserved.Traditional K-Means based distributed data clustering require number of clusters as input which is difficult to obtain in case of a real life application like wireless sensor network. To mitigate this issue here an Automatic Distributed K-Means (ADK-Means) algorithm is proposed. In this algorithm cluster assignment is carried out with point symmetry based distance instead of Euclidean distance, to effectively detect arbitrary shaped clusters. The performance of proposed algorithm is demonstrated on four synthetic and one practical dataset. Three cluster quality evaluation methods have been employed and comparative analysis is done with existing distributed K-Means. The improved performance is up to 12.6% in terms of Silhouette index reported as compared to existing approach.",60017757,Malaviya National Institute of Technology Jaipur,Jaipur,India,['1700'],19.333333333333332,0.049999999999999996,0.675,0
514,514,Updated constraints on the variations of the fine-structure constant from an analysis of white-dwarf spectra,"I fused observed spectra from the white-dwarf star G191-B2B to constrain the spatial and temporal variation of the fine-structure constant. The analysis was combined with laboratory-measured and astronomically observed lines in [Ni V] to find Δα/α = (-0.003 ± 0.072) x 10-6. The obtained result allows a symmetry of the related comparison with previous studies looking for cosmological variations of α using spectra from Quasi Stellar Objects (QSOs). In this way, we can expect higher sensitivity from white-dwarf spectra than QSO spectra. Therefore, this study should have orders-of-magnitude higher sensitivity per system than previous quasar studies, and we should reduce statistical and systematic errors. The results of this study place a more stringent limit on Δα/α than previous studies using the same data.",60078563,Ton-Duc-Thang University,Ho Chi Minh City,Viet Nam,['1701'],20.5,7.569702440626067e-18,0.3734848484848485,1
515,515,Potential impact of commoditisation on roof top solar PV in India," Solar PV is a growing industry and it is beginning to play a major role in the electricity mix in our country. The objective of this study is to understand the need for India to commoditise PV for effective implementation, bringing about a paradigm shift in harnessing energy from the abundant freely available sunshine. Commoditization can be a prerequisite for enhanced and speedier adoption of PV even in homes. The study is based on the secondary data collected from Research articles, renewable energy journals and websites of solar energy organisations. The study helps understand the elements and the factors responsible for commoditisation which can culminate in aggressive market development of RTS. Assessing India’s stance to bring about rapid commoditisation and how best to tackle the problems encountered in the Indian scenario are elucidated. The basic idea of the researcher is to lay emphasis on producing a roof top model that can be plugged in a socket to produce your own energy.The study concludes that potential challenges like effective net metering implementation, grid connectivity, fragmented electricity market, thrust for green financing etc. have to be addressed to trigger the growth of RTS.",60032269,Aligarh Muslim University,Aligarh,India,['1706'],24.0,0.2708333333333333,0.5083333333333333,0
516,516,LiFi for Vehicle to Vehicle Communication - A Review," All rights reserved.Light Fidelity, also known as LiFi, is a technology based on communication using light as a medium. This technology is known as Visible Light Communication (VLC) which removes the complexity of cable communication. LiFi has evolved over the past years and has been proven to be secure, efficient and can send data at very high rates. The proposed paper reviews the overall foundation of LiFi and studies the possibility of implementing LiFi in a communication system by explaining the architecture, the modulation techniques and its pros and cons. This paper also demonstrates a communication system in which data is sent from a transmitter to a receiver using light as a medium to control the speeds of two motors.",60107595,"Amrita Vishwa Vidyapeetham University, Bangalore",Bengaluru,India,['1700'],24.2,0.22257142857142861,0.5217142857142857,0
517,517,Cascade fuzzy controller based vibration reduction in switched reluctance motor drive in electric screw press machine,"This paper presents the cascade fuzzy controller based switching angle compensator for reducing the torque ripples and vibrations of the SRM drive used in electric screw machine. The switching angle such as Turn-ON and Turn-OFF angle of the motor are automatically changed with respect to speed and current values. Cascade fuzzy controller consists of two fuzzy controller connected in series, the first controller tune the Turn-OFF angle according to the speed and current changes and second controller tune the Turn-ON angle according to the tuned Turn-OFF angle and current value. The vibration of the motor under different load conditions and FFT spectrums of measured vibration signals are calculated. The proposed algorithm has been tested through the MATLAB simulation. A simulation results are proved that the proposed switching angle compensator can increases the performance of drives in terms of less speed oscillation, less torque ripples and less vibration even at low speed in steady state condition than the constant switching angle method.",60105818,M.Kumarasamy College of Engineering,Karur,India,['1700'],26.833333333333332,-0.006410256410256409,0.30512820512820515,1
518,518,Embedded Bi-directional GRU and LSTMLearning Models to Predict Disasterson Twitter Data," All rights reserved.The deep learning techniques namely Long Short Term Memory (LSTM) network and Bi-directional Gated Recurrent Unit (BGRU) network turn to be de facto to build an optimal assembly line for neural network models. The prevailing state-of-the-art approaches require a substantial amount of labeled data detailed to an unambiguous event in the training phase. In this paper, embedded bi-directional GRU and LSTM learning models is applied for disaster event prediction that uses deep learning techniques to categorize the tweets. The performance of the proposed neural network model is evaluated on CrisisLexT26 benchmarking dataset. The resulting validation accuracy is estimated by comparing LSTM and bi-directional GRU with and without word embeddings. The experiments demonstrate the model selector choose the deep learning techniques to predict the disaster event with reasonably high accuracy.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],22.0,0.07285714285714286,0.4557142857142857,0
519,519,Using models as boundary objects in early design negotiations: Analysis and implications for decision support systems," © The Author(s) 2019.One common strategy to include more downstream lifecycle dimensions in early design is to enrich modelling and simulation techniques embedded in decision support systems. However, downstream dimensions are difficult to trade against more traditional engineering objectives. This research studied through individual interviews how six disciplines use models to negotiate design trade-offs. References to models were categorised according to whether models supported or hampered the duration of trade-off identification and how they impacted the duration of trade-off resolution. The results point to the difficulty of applying downstream lifecycle issues earlier in the design process because of the characteristics of the models that are used. A list of characteristics promoting and limiting the use of four models as boundary objects (CAD models, simulation results, total cost of ownership and decision matrices) is provided. The cross-analysis of these characteristics provides insights into how models need to be organised in decision support systems.",60016636,Blekinge Tekniska Högskola,Karlskrona,Sweden,['1704'],21.857142857142858,0.03333333333333334,0.5777777777777777,0
520,520,Computational Analysis of Breast Cancer Sequences using Next Generation Sequencing Methods in Julia," All rights reserved.Breast cancer is one of the life-threatening diseases for mammals. Complete activities of living organisms are grounded on the DNA (Deoxyribonucleic Acid) /RNA (Ribonucleic Acid) sequences of their body. This was the salient motivation behind exploring the research on computational analysis of cancer sequences. In this paper, breast cancer sequences of Homo sapiens and mice are considered for analysis. A DNA sequence is framed with four key chemicals, A (Adenine), G (Guanine), C (Cytosine) and T (Thymine) which are referred as Nucleobases. The sequences taken for analysis vary in their size. Genome reduction for making equal sizes for all sequences may lead to non-optimal analysis and hence the original length is considered for the entire analysis. Genomic analysis such as individual Nucleobase average count, AT and GC-content, AT/GC composition, G-Quadruplex occurrence and occurrence status of Open Reading Frame (ORF) in each sequence are calculated. Execution time was calculated for sequence fetching process and ORF analysis. The human and mouse sequences were fetched approximately at 79 milli seconds(ms) and 177ms respectively. ORF analysis was processed between 640ms and 703ms. The entire analysis was done with JULIA analytical tool.",60023330,Sathyabama Institute of Science and Technology,Chennai,India,['1700'],15.833333333333334,-0.03392857142857143,0.4964285714285714,0
521,521,Fake bitrate detection of HEVC videos based on prediction process,"In order to defraud click-through rate, some merchants recompress the low-bitrate video to a high-bitrate one without improving the video quality. This behavior deceives viewers and wastes network resources. Therefore, a stable algorithm that detects fake bitrate videos is urgently needed. High-Efficiency Video Coding (HEVC) is a worldwide popular video coding standard. Hence, in this paper, a robust algorithm is proposed to detect HEVC fake bitrate videos. Firstly, five effective feature sets are extracted from the prediction process of HEVC, including Coding Unit of I-picture/P-picture partitioning modes, Prediction Unit of I-picture/P-picture partitioning modes, Intra Prediction Modes of I-picture. Secondly, feature concatenation is adopted to enhance the expressiveness and improve the effectiveness of the features. Finally, five single feature sets and three concatenate feature sets are separately sent to the support vector machine for modeling and testing. The performance of the proposed algorithm is compared with state-of-the-art algorithms on HEVC videos of various resolutions and fake bitrates. The results show that the proposed algorithm can not only can better detect HEVC fake bitrate videos, but also has strong robustness against frame deletion, copy-paste, and shifted Group of Picture structure attacks.",60073441,Beijing Institute of Graphic Communication,Beijing,China,['1701'],18.9,0.0069940476190476185,0.6238095238095237,1
522,522,#CycloneGaja-Rank based Credibility Analysis System in social media during the crisis," All rights reserved.Online Social Networking (OSN) is a platform, which allows users to impart information to other people. Twitter plays an instrumental role in public and political conversations related to the particular crisis events. This research work aims to rank the credibility of the tweets associated with the Natural Disasters and identifies the tweets that spread fake information. The authors propose a Credibility-Analysis-System to rank tweet messages according to their credibility. The authors have compared the performance of tweet credibility with state-of-art of machine learning algorithms such as Naive Bayes classifier, SVM rank algorithm, and Random Forest classifier. The experimentation has been performed on the real-time dataset collected during the Gaja cyclone event. The results present the Random Forest classifier to be the most suitable algorithm for credibility analysis with an accuracy of 87%.",60079728,"SSN College of Engineering, Kalavakkam",Kanchipuram,India,['1700'],19.285714285714285,-0.1652777777777778,0.5106481481481482,0
523,523,24X7 Lifeline Chip for Soldiers, All rights reserved.Soldiers spend a tough and risky life in battlefield. During an emergency situation they fight without any backup for saving their life. This causes the country to lose huge number of soldiers due to lack of technology rather than enemy attack. Location tracing of a soldier during such panic situation is required to get information of soldier's current situation. High end technological devices have been produced to help them manage various situations during their mission. In the current study one lightweight wearable device is developed that embed existing small devices onto a Chip (SoC) which piecewise integrate these devices to develop a user-friendly watch or batch or helmet. The proposed system enables a communication with the army base station to track the location and health status of soldiers. This is done through embedding GPS (Global positioning system) module with low power wireless body sensors in the system. Communication is set up two way: using antenna and using a GSM module. This improves reliability of the communication and makes it more fault tolerant. Hence the risk of non-functioning of the system in case of a failure in one part is reduced. Another important feature of this device is that it supports SDR (Software Define Radio) radio communication system used in Indian army.,60109533,"Amrita Vishwa Vidyapeetham, Mysuru Campus",Mysuru,India,['1700'],17.833333333333332,-0.020034722222222225,0.5155208333333334,0
524,524,Digital Twin of an Automotive Brake Pad for Predictive Maintenance," All rights reserved.The traditional manufacturing industry is being challenged globally with the comprehensive growth in digital technologies and big data. Digital Twin (DT) technology is one such vision that refers to a comprehensive physical and functional description of a physical component, product or an entire system with all the operational data. The Digital Twin of a product establishes a physical-virtual connection that paves way to real time monitoring all through the entire life cycle of the related product. This paper describes the advance of a digital twin that supports in the predictive maintenance of an automobile brake system. As a proof of concept, brake pressure was measured at different vehicle speeds using ThingWorx Internet of Things (IoT) platform. The data captured using the platform was used to demonstrate the prediction of brake wear using the CAD model implemented in CREO Simulate.",60103989,"Sri Krishna College of Engineering and Technology, Coimbatore",Coimbatore,India,['1700'],23.666666666666668,0.013333333333333334,0.27904761904761904,0
525,525,Handwriting Analysis based on Histogram of Oriented Gradient for Predicting Personality traits using SVM," All rights reserved.Handwriting Analysis is a method to understand and predict the characteristic traits of a person based on his handwriting style. Graphology is the scientific term used for handwriting analysis. Professional handwriting examiners, called graphologists, manually study and understand the handwriting of an individual to classify the writers personality. Nevertheless, the manual process of handwriting analysis is time-consuming, costly and depends majorly on the skills of the graphologists. To make this process computerized we extracted several features of handwriting samples and classified the writer into 5 personality traits namely Energetic, Extrovert, Introvert, Sloppy and Optimistic. Histogram of oriented gradient(HOG) extracts the features from the handwriting sample of the writer which serves as an input for the Support Vector Machine model to give output as the personality trait of the person. For this paper, digital handwriting sample data of 50 different users were collected. The proposed system predicts the personality trait of a person with 80% correctness using the Polynomial kernel. In this paper, we propose a computerized method for personality trait prediction based on the users handwriting. Two different methods are applied to the same handwriting sample data to measure and compare the performance of the proposed system.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],20.0,0.016287878787878785,0.36742424242424243,0
526,526,A hybrid technique of machine learning and data analytics for optimized distribution of renewable energy resources targeting smart energy management," All rights reserved.The distributed generation in smart grids has become highly prevalent due to its inherent characteristics like robust, reachable, lossless and emission less. The increased usage of sensor devices, wireless and network communication, cloud computing and IoT (Internet of things) explores the merge of smartness in energy field which results in an extensive collection of data getting populated in the electricity sector. This paper proposes a hybrid machine learning with big data analytic techniques for optimized distribution of available energy resources targeting smart energy management. The system aims in handling smart energy management using the data received from conventional sources and various distributed generation sources like photovoltaic, wind, small hydro and biomass. For unsupervised power data an efficient clustering methodology such as grid based clustering has been incorporated for optimal distribution of energy received from the nodal and zone regions. For structured power data, support vector machine algorithm of supervised learning is used for smart distribution which performs classification and regression of the vast electricity data. Regressive analysis over electricity data across the country with respect to various regions is carried out to understand the energy consumption which gives the insight of energy deficit. Thus the machine learning hybrid techniques were performed over the collected data to validate the smart distribution and the result obtained ensures a substantial gain which leads to conservation of generated energy through smart energy management.",60106323,"Sri Sai Ram Engineering College, Chennai",Chennai,India,['1700'],29.0,0.064510582010582,0.4960714285714285,0
527,527,Image-Based Smart Surveillance and Remote Door Lock Switching System for Homes," © 2019 Procedia Computer Science. All rights reserved.Internet of Things (IoT) has found multiple use-cases when it comes to our homes. Smart home-surveillance is one of them. This work presents a prototype of a smart surveillance system that works with photos instead of videos. Not only such a system is more cost-efficient, but it is also one that limits internet traffic. On particular triggers, the system clicks a photo, and in case if it is some person who triggered the system, the taken image is labelled using a facial recognition service that labels the person based on the images uploaded by the system's user/s via a mobile application beforehand. This paper also presents a secure and reliable mechanism for remote switching of the house's doors using the same mobile application. An added feature in the door-lock switching mechanism is that of an onsite greeting system.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],18.25,0.12683982683982684,0.4130952380952381,0
528,528,The effect of virtual instruction via imo application on intrinsic-motivated and extrinsic-motivated efl learners' vocabulary development,"Virtual instruction gives the chance of using a personable portable device to enhance learning and presents it the ""anytime, anyplace"" feature (Wu, R. et al., 2006). There is an increase in the use of virtual instruction in both educational purposes and personal usage all over the world (Mckethan. W., et al., 2001). The current study aimed to investigate the effect of virtual instruction via imo application on intrinsic-motivated and extrinsic-motivated EFL learners' vocabulary development. To this end, 60 Iranian EFL learners from two language institutes in Yasuj, Iran, were selected based on convenience random sampling. Second, the selected participants took the motivation questionnaire. In terms of the questionnaire results, the participants were divided into the extrinsic-motivated and intrinsic-motivated learners. Both groups had a virtual instruction via Imo application within six sessions. Prior to the instruction, the vocabulary pretest was administered to ensure the homogeneity of the two groups regarding the vocabulary proficiency. After the instruction, the posttest was conducted to compare groups’ vocabulary development through independent samples t-test. The findings revealed that the virtual instruction was more effective on Iranian EFL extrinsic-motivated learners than Iranian EFL intrinsic-motivated learners.",60026904,"Islamic Azad University, Najafabad Branch",Isfahan,Iran,['1700'],15.666666666666666,0.09444444444444444,0.3194444444444444,1
529,529,Twitter sentimental and emotional variations of public reactions about the public personalities in social media using deep learning,"It is difficult to predict the personality of people with high accuracy but it is possible nowadays by using the information which are shared by them in the social media. In order to find the personality with high accuracy, we examine Twitter account of six categories of the Public. Based on position in the society, we categorized the people into six major categories such as Political Personalities, Sports Stars, Business Bodies, Hollywood Figures, General Public and Indian Geneticist. Their twitter profile data are collected, stored (using MySQL), Pre-processed and Analysed analysis is done in accordance with the features of profile images such as colour, image composition, their Post and their online engagement. For explicable, our analysis targeted aesthetic and physiognomy to explore personality characteristics. Based on the profile picture chosen our results predict the behaviour of the twitter users. For example, studious and agreeable users having positive emotions while others use aesthetic photos. After analysing these data, the accuracy rate was predicted by using various algorithms such as Support Vector Machines (SVM), Naïve Bayes and Maximum Entropy etc. These algorithms gave the accuracy rate of about 60-70%. For accuracy prediction we used D-CNN technique, which achieved 98.457% of accuracy measurement and also concluded that personality prediction is difficult for robust accuracy.",112595497,St. Peter’s Institute of Higher Education and Research,Chennai,India,['1700'],21.1,-0.01918087121212121,0.4953409090909091,1
530,530,Smart Metro Rail Ticketing System," All rights reserved.Transportation plays a vital role in ones life. The main goal of this paper is to eradicate the day to day and one of the major problems with regard to carrying a ticket during transportation from ones life and make traveling a lot more peaceful. For this purpose, we are proposing a biometric-based ticketing system in the metro railway scenario but not limited to the same. In order to get a unique identifier for each person, we are considering their fingerprint right away from registration, booking tickets and validating the fingerprint on the day of the journey so he/she can travel on a particular day and on the desired train to his/her preferred destination. The fingerprint sensor will be interfaced with Arduino which in turn will store the fingerprint data to the cloud. We are proposing a two-way encryption standard for storing the sensitive fingerprint data in the cloud. This two-way encryption standard involves encrypting the data during data generation at the hardware end and encrypting it again before storing it in the cloud database.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1700'],25.428571428571427,0.1570970695970696,0.4054029304029304,0
531,531,Design of a Smart Safety Device for Women using IoT," All rights reserved.Women safety has always been an issue even in these modern times with so much advancement in technology. Women are not safe anywhere and are most vulnerable when traveling alone into lonely roads and deserted places. Existing hand held safety devices for women require human intervention for activating the device such as pressing the button or shake the device etc after sensing the danger. We propose a solution which will try to overcome the disadvantages of the existing systems and also aim at providing false proof safety to women. The proposed work aims at designing an IoT based safety device that relies on providing security to women by fingerprint-based method of connectivity to the device and alerting nearby people and police when a women is not safe. An unsafe situation is sensedby fingerprint verification for a minute then it will automatically alert nearby people and police if the device senses no signal. Moreover, for first-hand safety, shockwave generator is also designed that women can use to attack the perpetrator. Additional features such as sending group messages, audio recording are also part of the proposed design. A mobile app is designed for women safety where safe locations from victim's current location will be shown on the map so that women can reach the safe place from her current location.",60106090,"Vellore Institute of Technology, Chennai",Chennai,India,['1700'],24.555555555555557,0.020312499999999994,0.42187500000000006,0
532,532,A survey on mitigation techniques against ddos attacks on cloud computing architecture,"Service availability is one of the most important aspects of cloud environments. The threat to availability of Distributed Denial of Service (DDoS) attacks plays an important role when designing the security architecture. A successful DDoS attack might result in service degradation or complete outage. The methods and techniques used against DDoS attacks in cloud environment are sometimes different from those used within the traditional networks, and on other times they are the same. In this paper, we are going to investigate challenges and mitigation techniques against DDoS attacks in cloud and compare between them in cloud environment. This survey will support the future research and development work as well as to raise the awareness about the presented approaches.",60010294,Cairo University,Cairo,Egypt,['1700'],19.666666666666668,0.20249999999999999,0.5825,1
533,533,Semi-active suspension system control using skyhook and groundhook controller,"The purpose of this research paper is to analyze the effect of skyhook and groundhook control strategies on a semi-active suspension system. Computer simulation of the quarter-vehicle model is conducted through MATLAB/SIMULINK. The ride comfort and handling characteristics of the suspension system are predicted for random road input by the mathematical model. The passive suspension system performance is compared with skyhook and groundhook controlled semi-active suspension system. The result shows that the groundhook control offers better ride comfort and handling as compared to skyhook and passive suspensions. Also, the results showed in the time domain, frequency domain, power spectral density, and root mean squares values.",60018623,South Valley University,Qena,Egypt,['1700'],17.5,-0.0425,0.3375,1
534,534,A first-time investigation of psychosocial inclusivity in design: Inclusive supermarket design for older individuals," © The Author(s) 2019.As a first-time investigation of 'psychosocial inclusivity' in design, this paper introduces and establishes the concept of psychosocially inclusive design, and explores it within the context of supermarket shopping for older individuals, as one instrumental activity of daily living. Inclusive design theory and practice have been predominantly concerned with issues of physical access, limiting its scope and relevance to the wider more complex psychosocial issues. Employing research triangulation and rigorous empirical investigations, this paper advances the fundamental understanding, extends the general research agenda, and pushes the current boundaries of inclusive design towards non-physical inclusion by identifying any possible psychosocial constructs. Four constructs including 'cognitive', 'emotional', 'social', and 'value' were identified in the context of supermarket shopping through ethnographic interviews; creative workshop; and observations conducted with a total of 58 older individuals. The results may play a crucial role in establishing the theoretical foundations to the concept of psychosocial inclusivity in design.",60029336,Bournemouth University,Bournemouth,United Kingdom,['1704'],31.0,0.07604166666666667,0.4547619047619047,0
535,535,"Structural monitoring and performance assessment of shield tunnels during the operation period, based on distributed optical-fiber sensors","The weak parts of shield tunnels are not obvious, so it is urgently necessary to implement distributed monitoring based on an advanced sensing method. As the horizontal loads at both sides of the shield tunnel present a type of symmetric distribution, the deformation parameters under the vertical loads are often selected as the key monitored parameters, such as convergence, settlement, and seam opening. In this paper, the monitoring of the proposed deformation parameters is innovatively implemented with only one sensing technology, namely distributed optical-fiber strain sensing technology. First, the improved distributed optical-fiber sensors are introduced with the sensing performance. Second, a structural health monitoring (SHM) system for operational shield tunnels is proposed, including optical-fiber sensor installation, data logging and saving, key parameter analysis, and structural health assessment. The key monitoring theory and technology are also proposed. The proposed system has been verified by experiments at the Nanjing Yangtze River tunnel. In the experiments, the proposed optical-fiber sensors were installed on the surface of a selected tunnel ring, with a longitudinal span of approximately 90 m long. The experiments were conducted over 55 days to measure the distributed strain and temperature. Then the key parameters were obtained from the measurements, with which the structural health was assessed. The possibility that the shield tunnel SHM system can be constructed with the improved distributed optical-fiber sensors, monitoring theory, and technology is proven.",60033100,Nanjing University,Nanjing,China,['1701'],20.818181818181817,0.04833333333333333,0.663888888888889,1
536,536,Acquisition and utilization of mental imagery capability in robotic action sequencing tasks," All rights reserved.This work presents a series of neurorobotic models underlying learning in robots. It demonstrates the way in which, during sensorimotor exploration, robots do not just gain knowledge about how to form movement primitives but also obtain a mental imagery capability. Mental imagery plays a key role in these computational models by accelerating learning processes of action sequencing tasks. The first experiment involves permitting a humanoid robot to learn how to retrieve an out-of-reach object using a provided tool. This experiment explores a phenomenon on tool use development found in human infants. In addition, it tests two hypotheses on tool use development. The second experiment extends the domain of robot learning by targeting a useful robotic application. It drives a service robot to learn to acquire knowledge of how to manipulate perceived objects based on the objects’ information and a goal from users. By means of planning, learning the sequence of actions in mind, the robots are able to learn by examining actions’ outcome without really performing actions. This allows the second model to completely exclude parts of overt movements from the training loop. The results confirm that two types of robots can complete their given tasks in a reasonable period of time. The proposed models would benefit robotic applications in terms of online learning.",60018809,Silpakorn University,Nakhon Pathom,Thailand,"['1710', '1705']",18.083333333333332,0.084375,0.28489583333333335,0
537,537,Real Time Feature Point Detectors for Determining Ego Motions," All rights reserved.Ego motion determination is an important application to recognize the motion of an observer in real time. Here we have implemented feature point detector using FFME for ego-motion determination. The main objective of this work is to detect the motions of any objects such as humans, animals, vehicles, missiles and so on. The camera plays a vital role in surveillance of isolated and or restricted area. To improve the intelligence of camera some efficient video processing algorithms are needed. In this process, the detection of unwanted features were derived and developed for some video processing applications. There are various types of feature detectors like edge, corner and points which can be detected from a video frame. To detect those features, feature point detectors like SIFT, ORB, FAST, BRIEF and FFME are more reliable with good efficiency, less memory size and high processing speed. These feature point detectors are compared and evaluated under parameters of speed and number of feature point matches. Although, FFME algorithm has high speed when compared to other feature point detection algorithms, it is prone to more errors caused by illumination differences, as it detects the feature points using Gradient magnitude of the pixel. To overcome this, we have introduced a novel work that uses FFME with gradient phase technique. The resultant output exhibits high processing speed with less error when compared to other feature point detectors and even FFME with gradient magnitude.",60008648,University of Madras,Chennai,India,['1700'],19.916666666666668,0.13816666666666672,0.42349999999999993,0
538,538,Community-aware Photo Quality Evaluation by Deeply Encoding Human Perception,"IEEEComputational photo quality evaluation is a useful technique in many tasks of computer vision and graphics, <formula><tex>$e.g.$</tex></formula>, photo retaregeting, 3D rendering, and fashion recommendation. Conventional photo quality models are designed by characterizing pictures from all communities (<formula><tex>$e.g.$</tex></formula>, &#x201C;architecture&#x201D; and &#x201C;colorful&#x201D;) indiscriminately, wherein community-specific features are not encoded explicitly. In this work, we develop a new community-aware photo quality evaluation framework. It uncovers the latent community-specific topics by a regularized latent topic model (LTM), and captures human visual quality perception by exploring multiple attributes. More specifically, given massive-scale online photos from multiple communities, a novel ranking algorithm is proposed to measure the visual/semantic attractiveness of regions inside each photo. Meanwhile, three attributes: photo quality scores, weak semantic tags, and inter-region correlations, are seamlessly and collaboratively incorporated during ranking. Subsequently, we construct gaze shifting path (GSP) for each photo by sequentially linking the top-ranking regions from each photo, and an aggregation-based deep CNN calculates the deep representation for each GSP. Based on this, an LTM is proposed to model the GSP distribution from multiple communities in the latent space. To mitigate the overfitting problem caused by communities with very few photos, a regularizer is added into our LTM. Finally, given a test photo, we obtain its deep GSP representation and its quality score is determined by the posterior probability of the regularized LTM. Comprehensive comparative studies on four image sets have shown the competitiveness of our method. Besides, eye tracking experiments demonstrated that our ranking-based GSPs are highly consistent with real human gaze movements.",60013614,Hangzhou Dianzi University,Hangzhou,China,"['1711', '1706']",21.0,0.05992888064316637,0.30555658627087207,1
539,539,An approach for conversion of Japanese emoticons into emoji based on character-level neural autoencoder," All rights reserved.In this paper, we propose a method for converting Japanese emoticons into emoji. The method creates a model that translates text into emoji using training neural networks with a character-based feature; the model determines the positive/negative/neutral polarity of the emoji from the text. By extracting a feature vector from the hidden layer of the model, we calculate the similarity between the input sentence and the text annotated with emoji in the database; the conversion candidates come from the emoticon in the input text. In comparison tests of the proposed method and a word-level feature method that uses a word distributed representation vector, the emoji emotion polarity-based model achieved a maximum accuracy rate of 90.0%, representing an 8% improvement over the word-level feature method.",60015698,Aomori University,Aomori,Japan,['1702'],31.5,-0.08333333333333333,0.16666666666666666,0
540,540,A scheme to classify skin through geographic distribution of tonalities using fuzzy based classification approach," All rights reserved.The skin recognition is a topic that has been studying since some years ago using machine learning and artificial vision, nowadays this topic has many applications in the medical industry, for example, cancer detection, injuries, mood recognition, telemedicine, among other applications. In this industry, if we can classify the skin tonalities, we able to limit the diseases that attack each type of skin tonality. Many papers have studied skin recognition, where the goal is the recognition of the skin in a picture or video, they need to have a good database and powerful algorithms of machine learning. This paper proposes a system able to segment the skin through the map and the recognition of the skin in an image. The results show that is possible to generate a skin geographic distribution; it gives the opportunity to classify the skin tonalities, for another hand, we tested the proposed system to recognize skin showing interesting results for different tonalities of skin.",60019176,Instituto Politécnico Nacional,Mexico City,Mexico,['1702'],32.4,0.23125000000000004,0.6104166666666666,0
541,541,Research on radar pulse flow signal formation algorithm based on hash algorithm," All rights reserved.AEVWUDFW. In the process of radar electromagnetic environment simulation design under battlefield conditions, the RF (radio-frequency) pulse model is established by PDW5 parameters. In order to deal with the pulse flow density and loss probability, a high quality PDW flow is generated. As required by the training requirements, the algorithm of radar signal pulse flow formation based on Hash algorithm is proposed on the basis of common merging algorithm. The superiority of each algorithm is compared by simulation and complexity analysis.",112313847,Wuhan Mechanical College,Wuhan,China,['1702'],16.8,-0.06999999999999999,0.52,0
542,542,Rule-based ontology framework (ROF) for auto-generating requirements specification: A case study," All rights reserved.Building requirements specification document in semi-formal notation and natural language needs great effort from users and developers. However, the current approach to the requirements engineering process is still lacking in auto-generating model and documentation. Most approaches only focusing in building UML use cases and a brief version of Software Requirements Specification (SRS), which are not enough as a basis for the code development process. A Rule-based Ontology Framework (ROF) for AutoGenerating Requirements Specification is proposed. It is used for auto-generating requirements specifications that consist of semi-formal modeling in Business Process Model Notation (BPMN) and natural language of Software Requirements Specification (SRS) in IEEE template. This paper discusses the implementation of ROF in a requirement engineering process in a University located in Indonesia. It is applied in Lecturer Workload Management (LWM) Application, an application that summarizes lecturer workload and calculates the scores as basis for generating salary. This application was developed by the Department of Information Systems (ISD). Existing requirements engineering process mostly depend on users' perspective which causes building the requirements documentation require much effort and do not represent the real needs of users. Thus, the requirements documents do not support the development process which causes project delay. Using ROF, the requirements engineering process becomes more effective by specifying functional requirements that represent user's needs and produce document that is feasible to be used as a reference for the development process.",60012005,Multimedia University,Malacca Town,Malaysia,['1702'],21.272727272727273,0.2571428571428572,0.49166666666666664,0
543,543,An improved unbounded Hibe scheme in the prime order setting," All rights reserved.Unbounded Hierarchical Identity-Based Encryption (HIBE) is a new HIBE where the public parameters size is constant and independent of the length of the identity vectors. In this paper, we improve Lewko-Waters unbounded HIBE scheme and get a new give an HIBE scheme. Our scheme is constructed in the prime order setting, and more efficient than previous unbounded HIBE schemes. Furthermore, our scheme removes the constraint on hierarchical identity in the Lewko-Waters construction and can be proven selective security in the security model.",60031991,Chongqing University of Technology,Chongqing,China,['1702'],21.25,0.08658008658008658,0.3001082251082251,0
544,544,Public opinion monitoring and analysis system based on localization," All rights reserved.In this study, localization services and internet public opinion monitoring technology were combined to develop a public opinion monitoring system based on localization to improve the accuracy and pertinence of public opinion regulation on the Internet. The results indicated that the use of the latest cloud computing technology in this system not only improved the efficiency and accuracy of public opinion regulation, but also the convenience and applicability of the public opinion analyses. Furthermore, the system framework and structural design of the public opinion monitoring system were analyzed, and the applied technologies of each main function module were investigated. The system developed in this study could be used by the government to effectively monitor public opinion on the internet.",60108816,Zhejiang University of Media and Communications,Hangzhou,China,['1702'],30.5,0.11388888888888889,0.31666666666666676,0
545,545,Iterative solution of multi-shifted linear systems with multiple right-hand sides," All rights reserved.We present a performance study of variants of shifted block Krylov subspace methods for the iterative solution of multi-shifted linear systems with multiple right-hand sides given at once. All the methods can solve the whole sequence of systems simultaneously. We analyse the effect of deflated restarting to restore the superlinear convergence rate by augmenting the Krylov subspace with approximate eigenvectors recycled over the iterations, and of block size reduction strategies to handle the situation when some of the right-hand sides converge much faster than others, or the right-hand side vectors are approximately linearly dependent.",60028891,Chang'an University,Xi'an,China,['1702'],32.33333333333333,-0.06666666666666667,0.3,0
546,546,Incremental collaborative clustering using information theory and information compression," All rights reserved.Clustering is one of the most important task in Machine Learning. It consists in grouping together similar objects and is often considered to be an information compression task. In real life applications, clustering is often applied to online data to process live stream that may come from several sources. In this work, we propose an incremental version of collaborative clustering based on information theory. Our algorithm has the advantage of handling incremental learning while combining the strengths of both information theory methods that have proved to be efficient and ideal candidates for clustering tasks, and collaborative clustering algorithms that have the capacity to process data from several sources such as neural network. Our proposed model relies on a Kolmogorov complexity based formulation of collaborative clustering, and data-wise division and optimization of this objective function, thus enabling to individually process multi-view data as they arrive. The proposed incremental method also has a lower computational complexity than the original batch version. Our approach was tested on several datasets and compared with other state of the art methods and has proved to be very promising.",116272556,ISEP,Issy-les-Moulineaux,France,['1702'],23.125,0.17642424242424243,0.4316666666666667,0
547,547,A hybrid blockchain system based on parallel distributed architecture for central bank digital currency," All rights reserved.The Central Bank Digital Currency (CBDC) is the foundation of the future digital economy and society. However, most of the common blockchain currency only provide a creative technical architecture ignoring social effects or sacrificing performance in exchange for decentralization. Here, we proposed a hybrid blockchain system based on parallel distributed architecture by combining account and Unspent Transaction Output (UTXO) for center bank digital currency. Social effects are considered in this system and the centralized management is achieved with good performance. In experiment, the transferring speed of the proposed hybrid system is 80% faster than the UTXO method. Furthermore, a parallel distributed architecture is designed to optimize this system. Results show that the processing speed is 38.1% faster than the traditional blockchain account method and 17.8% faster than the UTXO method.",113992766,State Key Laboratory of Information Photonics and Optical Communications,Beijing,China,['1702'],19.0,0.0803921568627451,0.29754901960784313,0
548,548,Design and analysis of a multiple-valued hysteretic characteristic unit based on RTD," All rights reserved.Based on the negative differential resistance (NDR) characteristic of resonant tunneling diode (RTD) and negative resistance equivalent model, a multiple-valued hysteretic characteristic unit is realized in this paper. The effects of device parameters of the equivalent model on the multiple-valued RTD hysteresis loop are analyzed. Simulation results show that the designed unit can complete the conversion between various resistance states under excitation of the periodic signal. This design broadens the application area of RTD and multiple-valued logic, and provides a theoretical basis for the future cross-research on multiple-valued negative differential resistance circuits and multiple-valued memristor circuits.",60013614,Hangzhou Dianzi University,Hangzhou,China,['1702'],24.75,-0.1037037037037037,0.36203703703703705,0
549,549,Fuzzy control of microwave dryer for drying Chinese jujube," All rights reserved.Microwave drying is a rapid dehydration technique that can be applied to preserve agricultural products. For its complex application environment, the temperature and humidity in the drying material cannot be precisely controlled during microwave drying process. However, microwave drying without exactly controlling temperature and humidity is unable to guarantee the quality of agricultural products. To achieve a high quality, this paper proposed a fuzzy control method for the microwave dryer, which could control the temperature and humidity precisely. To identify the dry effect of the proposed fuzzy control scheme, drying time of Chinese jujube during fuzzy microwave (FM) drying, ordinary microwave (OM) drying, and temperature microwave (TM) drying were investigated, quality attributes such as vitamin C (VC), color and total flavonoids content (TFC) of dried samples were evaluated. As the results showed, total drying time used to reduce 500 g jujube moisture content from 74% to 6% on dry basis required 30, 26, and 31 min using FM drying, OM drying and TM drying, respectively. The drying rate with FM drying was the fastest. Jujube dried by FM drying revealed better color and higher retentions of VC and TFC content than TM and OM drying. Compared with TM and OM drying, FM drying performed shorter drying time and better quality of samples, indicating that microwave dryer with fuzzy controller can provide a practical and effective method for drying jujube with acceptable product quality.",60000174,Shaanxi Normal University,Xi'an,China,['1702'],26.22222222222222,0.07383333333333333,0.5295,0
550,550,Investigation on data augmentation for object detection using deep neural network for traffic signs application," All rights reserved.Data augmentation is being widely used to enrich the datasets and enhance the performance of neural network for classification and detection. However most of the recent works focus only on the augmentation for classification. A technique for detection augmentation by template blending has been introduced in the literature. The limitation of blending technique is an extra polygon shape of each object needed to blend with the scene. In this paper we investigate the effect of the geometric transformations for detection augmentation on the Malaysian Traffic Sign Detection (MTSD) datasets. We propose and investigate a new augmentation framework for object detection datasets and train using faster-rcnn with ZF network as a backbone. We measure the Average Precision (AP) as stated in paper [PASCAL VOC] and show the correlation matrix for each class. Our findings show that data augmentation improving the performance for true positive. However, many false positive also occur but decreased by 19.7% after augmentation.",60103730,Telkom University,Bandung West Java,Indonesia,['1702'],17.555555555555557,0.06853146853146852,0.5111888111888112,0
551,551,An approach for intelligent evaluation of the state of complex autonomous objects based on the wavelet analysis," All rights reserved.Increasing requirements for the quality of functioning of complex autonomous technical objects (bodynets, robotic complexes, unmanned cars and aerial vehicles, etc.), as well as their security and reliability, made the problem of assessing their state particularly relevant given the impact of various types of attacks and destabilizing factors, aging and technological dispersion of parameters. The paper proposes a new approach to intelligent evaluation of the state of such objects. The approach is based on interval assessment of parameters, use of a knowledge base about critical and state conditions, and application of wavelet analysis. The architecture and realization of an intelligent system for evaluation of the state of complex autonomous technical objects is considered. The carried-out experimental assessment of the offered approach showed that use of wavelet analysis when forming areas of objects' operability allows one to make accurate differentiation of classes of their technical states that increases the accuracy and reliability of state identification and also to expand possibilities of technical means of control and diagnostics.",60101977,St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences,Saint Petersburg (ex Leningrad),Russian Federation,['1702'],33.8,0.10191387559808614,0.5151515151515151,0
552,552,A multi-objective approach to solve an optimal control problem applied to a simplified activated sludge system model," All rights reserved.In this work a model representing the 24 hours operation of an activated sludge system from a wastewater treatment plant is presented. An optimal control problem is formulated in order to minimize the dissolved oxygen (control variable) and the quality index (amount of pollution). This problem is treated using direct methods, leading to a multi-objective nonlinear problem, solved using a weighted sum multi-objective approach. It was coded in the AMPL programming language and numerical experiments were carried out using the NLP solver from the NEOS Server platform.",60020475,Universidade do Minho,Braga,Portugal,['1702'],22.5,0.1,0.4,0
553,553,Variational autoencoders for baseball player evaluation," All rights reserved.In the sporting world, baseball has been quicker to embrace the use of data analytics than any other sport, as detailed baseball statistics have become readily available in large and diverse quantities to the general public. Professional baseball teams use this data to develop game plans and evaluate players. In this work, we explore the latter by using a Variational Autoencoder (VAE), a special class of artificial neural networks. Specifically, we wish to relate a player's season-long batting statistics with the latent skills that a professional athlete needs to succeed in the MLB. In the growing field of sports analytics, we find this work incredibly important as it provides a novel, flexible, and powerful method to predict specific athletic skills based on years of recorded statistics.",60024324,University of Iowa,Iowa City,United States,['1702'],25.8,0.07976190476190476,0.45444444444444443,0
554,554,An empirical mode decomposition (EMD) enabled long sort term memory (LSTM) based time series forecasting framework for web services recommendation," All rights reserved.The convergence of SMAC technologies resulted in an unexpected upsurge of web services on the internet. The flexibility and rental approach of the cloud makes it an attractive option for the deployment of web services based applications. Once a number of web services are available to gratify the similar functionalities, then the choice of the web service based on personalized quality of service (QoS) parameters plays an important role in deciding the selection of the web service. The role of time is rarely being discussed in deciding the QoS of web services. The delivery of QoS is not made as declared due to the correlated behavior of non-functional performance of web services with the invocation time. This happens because service status usually changes over time. These limitations have affected the performance of neighborhood based collaborative filtering. Hence, the design of the time aware web service recommendation system based on the personalized QoS parameters is very crucial and turn out to be a challenging research issue. In the current work, empirical mode decomposition (EMD) enabled deep learning model long short term memory (LSTM) is used for the prediction of these time aware QoS parameters and the results are compared with the previous approaches. The experimental results show that the EMD-LSTM based Time Series Forecasting Framework is performing better. The RMSE, MAE and MAPE are used as an evaluation metric and their value for the prediction of Response time (RT) is found to be 0.085661, 0.049031 and 1.46208 respectively. The RMSE, MAE and MAPE are used as an evaluation metric and their value for the prediction of throughput (TP) is found to be 0.043878, 0.030688 and 1.485613 respectively. Thus, the experimental results show that the EMD-LSTM model of Time Series Forecasting for Web Services Recommendation Framework is performing better as compared to previous methods.",60008721,Banaras Hindu University,Varanasi,India,['1702'],23.46153846153846,0.1416666666666667,0.4703333333333334,0
555,555,Research on pavement skid resistance performance prediction model based on big data analysis and XGBoost algorithm," All rights reserved.In order to explore the correlation among various influence factors on pavement skid resistance performance and improve the performance prediction accuracy, this research has established a pavement skid resistance performance prediction model based on XGBoost algorithm, with the analysis and pre-process of related big data from LTPP database. The research then uses this prediction model to analyze the influence of basic features and time sequence features on pavement's skid resistance performance, and compares the prediction results with other commonly used prediction models to evaluate the prediction accuracy and effectiveness. Results have shown that in terms of model evaluation index R2 and RMSE values, the XGBoost model has much better prediction performance than the linear regression model LR, the gray model GM, and the BPNN model. According to the output of XGBoost model, the initial side-way force coefficient is the most important indicator for predicting SFC, while rainfall and snowfall are also strongly correlated with skid resistance performance prediction. Meanwhile, if target characteristics and prediction features modified to different occasions, this XGBoost prediction model has great potential for even wider application.",60087828,Ministry of Transport of the People's Republic of China,Beijing,China,['1702'],36.6,0.1577380952380952,0.5059523809523809,0
556,556,Requirement patterns and its importance - A survey," All rights reserved.Generally, Software Patterns are the reflection of conceptual structures that provides successful solutions to common problems. Software Patterns depict proven solutions and best practices that assist in evolving software engineering into an experienced engineering discipline. Therefore, it is applied in the various phases (analysis, design and architecture) of software development lifecycle in order to develop confined solutions to specific problems. Patterns can be revisited and can be implemented anytime to improve the design of a system. It can also be easily searched and assorted. Any best pattern should notably provide aesthetic and services to the software. However, the challenge lies in extracting the best pattern that is very much applicable to the problem domain. Therefore, this attempt investigates the available Software Patterns that are widely employed in the applications frequently with its characteristics. Applying appropriate software patterns for solving a particular problem is a manual activity which leads to the occurrence of failure sometimes. Therefore, the merit of a pattern should sneak in terms of its success in solving a commonly occurring problem. Empirical research evaluating the use of Software Patterns by engineers can help in establishing the worthiness of the given pattern in the problem-solving process. Though the patterns target analysis, design, and constructing architecture of a software development life cycle, evolving Patterns for collecting requirements would be a challenging task. This paper makes an attempt to the evolution process of Software Patterns especially in requirement engineering.",60010618,"Vellore Institute of Technology, Vellore",Vellore,India,['1702'],18.53846153846154,0.30878787878787883,0.4682575757575757,0
557,557,Authentication and key distribution scheme for two-tiered IoT based on PUF," All rights reserved.A new authentication and key distribution scheme based on physical unclonable functions (PUFs) is proposed for two-tiered Internet of Things (IoTs). It provides two-way authentication and efficient key distribution at different tiers. The PUF is difficult to be cloned and predicted, which enhances the security and network performance of IoT nodes. Keys are not stored in nodes but instantly generated by the PUF, improving the resilience against node capture. The analysis shows that the proposal guarantees the authentication, security, and efficiency.",124101970,School of Network Security,Nanjing,China,['1702'],16.8,-0.05194805194805195,0.6948670377241806,0
558,558,The degree of arity ≤ n about m-fuzzifying convex space," All rights reserved.The definition of the degree of arity ≤ n about M-fuzzifying convex space is introduced in this paper. It can be viewed as a generalization of arity ≤ n and M-fuzzifying arity ≤ n. Moreover, the relationships among the degree of arity ≤ n, arity ≤ n and M-fuzzifying arity ≤ n are surveyed.",60018844,Fujian Normal University,Fuzhou,China,['1702'],19.0,0.2,0.6,0
559,559,A controller design based on affine T-S fuzzy model via coordinate transformation," All rights reserved.Compared with the widely used T-S fuzzy model to represent the dynamics of a non-linear system, the affine T-S fuzzy model can be viewed as a more general one, in which there are affine terms in the local state-space equations of the consequent part of fuzzy rules. While the existing works had involved the affine terms in the system stability conditions when designing controllers, this paper pays attention to the compete availableness of the affine terms, and makes an effort to employ them as much as possible in the controller via certain appropriate coordinate transformation over the model. As a result, the proposed controller will make the closed-loop control system uniformly stable. In addition, a computer simulation is provided to illustrate the effectiveness of the controller proposed.",60032427,Hiroshima Prefectural University,Shobara,Japan,['1702'],32.5,0.16632653061224492,0.4959183673469388,0
560,560,Research on delay prediction compensation of teleoperation robot network control system," All rights reserved.Time delays in network transmission have been a concern in teleoperation robot. In order to solve the problem, this paper proposes a delay prediction compensation scheme based on Wolf Pack Algorithm (WPA)-Back Propagation (BP) neural network model combined with generalized predictive control algorithm. The WPA has optimized the initial weights and threshold of the BP neural network and has improved the convergence speed and prediction accuracy of the BP neural network so that the WPA-BP model can accurately predict the time delay of a network. The time delay obtained by the model was combined with the improved generalized predictive control algorithm to calculate control increments for the design of a controller. The improved generalized predictive control algorithm can directly identify controller parameters without having to solve the Diophantine equation, saving time on online computation. The simulation results show that the solution can well compensate the time delay of network transmission ensuring a real-time and stable system.",60003353,Harbin Engineering University,Harbin,China,['1702'],26.5,0.1666666666666667,0.3444444444444445,0
561,561,A novel Chinese character recognition method based on multi-modal fusion," All rights reserved.In recent years, deep learning models are significantly improving capacity of computer vision. Especially in the field of Chinese character recognition, due to the complex structure of the characters, traditional rule-based or machine learning methods have been no longer competitive in terms of the measures such as recognition precision. Inspired by the actual reading process of human beings, we find that the processing of character recognition involves multiple modal information, while single-modal information of images is not only needed. Thus, we study the multi-modal fusion, and propose a novel multi-network model for Chinese character recognition in this paper. The proposed model consists of CNNs, LSTMs and full connection networks, fusing multi-modal information for classifying input images. After experiments, we found that multi-modal fusion can improve the accuracy of character recognition.",60025785,Shanghai Maritime University,Shanghai,China,['1702'],22.166666666666668,0.02,0.41999999999999993,0
562,562,Formal transformation from UML sequence diagrams to Queueing Petri Nets," All rights reserved.In this paper, a formal strongly consistent transformation from UML Sequence diagrams (SDs) to Queueing Petri Nets (QPNs) is defined. Sequence diagrams are charts used to identify the sequence of event occurrences of a certain audience. QPNs are graphical formalisms, at a lower level of abstraction, for which efficient and mature simulation-based solution techniques are available. We show how the language of sequence diagrams is mapped onto an equivalent language of QPNs through formal transformation rules. We develop 12 general rules for formal SD-to-QPN transformation. We also present applying the proposed rules for a typical case study of a cloud service system. Experimental results are also provided.",60071354,Hanoi University of Science and Technology,Hanoi,Viet Nam,['1702'],15.714285714285714,0.11845238095238095,0.3401785714285714,0
563,563,Measuring the performance of multilayer perceptron on car navigation simulator: A comparative study," All rights reserved.Neural network deals with matter of developing programs that enhance their performance at some task through experience. Many have proven that the Neural Network has great practical value in many domains of application. One useful use of Neural Network is for complex problem domains where a little knowledge exists for humans to develop effective algorithms and also in domains where programs must adjust to changing conditions. Software Engineering can be a perfect field where many software development task and maintenance task could be constructed as problems to be learned and approaches in terms of optimizing the software performance. In this research, two different versions of neural network structure called Multilayer Perceptron (MLP) is used to compare the performance of the software which is a car navigation simulator in terms of finding the solution for its problem. The performance of the software is strictly compared using parameters from the algorithm used which is Genetic Algorithm (GA) and also parameters from the car navigation simulator. From this research, the MLP structure does shows different performance value of the software when finding the solution for its problem. This research also shows that the software optimization technique using neural network may improve the software engineering field in terms of performance optimization of the developed software.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1702'],26.75,0.3177083333333333,0.5375,0
564,564,Jumping fuzzy general finite automata and their simplified description," All rights reserved.The paper deals with a simplified form of jumping fuzzy general finite automata where transition function is bivalent and only the final states form a fuzzy set. It is proved that despite the simplification, the computational power of the automata is not reduced.",60008287,Univerzita Tomase Bati ve Zline,Zlin,Czech Republic,['1702'],23.0,0.016666666666666673,0.8333333333333334,0
565,565,Propagation of uncertainty expressed in intervals on the confidence of fuzzy association rules," All rights reserved.Association analysis searches data for potentially useful patterns in the form of rules. The aim of this paper is to analyze thoroughly the influence of imprecision or uncertainty in data on the uncertainty of the rule's quality measure, which is called the confidence. An experiment is conducted that allows to analyze the amount of uncertainty propagated from data to the resulting rule's confidence. For that, artificial data are generated with various characteristics and uncertainty settings. Results of the experiment show the dependency of the amount of uncertainty in a rule's confidence on the rate, type and position of uncertainty in data. Also, the effect of a t-norm selected in the definition of confidence is evaluated.",60025670,Ostravská Univerzita v Ostrave,Ostrava,Czech Republic,['1702'],19.666666666666668,-0.09999999999999999,0.5,0
566,566,Comparison of bat neural networks and bat optimisation neural networks for rainfall forecasting: Case study for Kuching City," All rights reserved.This paper compares two metaheuristic neural networks (ANNs) models, Bat algorithm neural network (BANN) and Bat optimisation neural network (BatNN) for spatial downscaling of long term precipitation. For BANN, model parameters for both pulse rate (R) and loudness (A) are fixed as 0.5. Whilst, R and A parameters for BatNN will dynamically self-adapt in searching the optimal configuration during the training process. Hidden node (HN), iteration number (IN) and learning rate (LR) for both models are predetermined to be 100, 1000 and 1 respectively for comparison. Investigations were carried out with different population (b), maximum pulse frequency (fmax) and velocity factor (α). Models performance will be measured with Square Root of Correlation of Determination (r), Root Mean Square Errors (RMSE), Mean Absolute Error (MAE) and Nash and Sutcliffe coefficient (E). Data from 1961 to 1990 are used for training, whilst validation data are from 1991 to 2010. Predictors of three climate models including HadCM3, ECHAM5 and HadGEM3-RA cum collected precipitation data from Kuching Airport Rainfall Station are input into the models. Model output is the forecasted precipitation. Results showed BatNN is more robust than BANN with its average r=0.96, average RMSE=1.69, average MAE=1.4 and average E=0.84 across the three climate models; while BANN achieved average r=0.95, average RMSE=1.91, average MAE=1.75 and average E=0.82 across the three climate models. The higher accuracy of BatNN can be attributed to the modifications done where dynamical parameters R and A are used in place of static parameter to allow BatNN to self-adapt during the training process.",60021005,Universiti Teknologi Malaysia,Johor Bahru,Malaysia,['1702'],23.181818181818183,-0.02587719298245614,0.474122807017544,0
567,567,Image enhancement of palm veins based on adaptive fusion and Gabor filter," All rights reserved.A palm vein enhancement method based on adaptive fusion and Gabor filter is proposed to overcome the degradation of recognition performance due to low image contrast, unclear details, and effects of noise, palm print, and false veins. First, the image is enhanced on the basis of the difference of Gaussian (DOG) algorithm and the partial overlapped sub-block histogram equalization (POSHE) algorithm, respectively. Second, the two kinds of enhanced images are fused adaptively according to the second-order statistic of each gray-level co-occurrence matrix. Lastly, a multidirectional Gabor filter is used to obtain the final enhanced image. This method not only retains the advantages of the DOG algorithm in separating the background from the veins, indicating an enhanced vein edge details, but also preserves the benefits of the POSHE algorithm in enhancing image contrast and local details. Simultaneously, the multidirectional Gabor filter is used to enhance the direction information, eliminate the interferences of noise, palm print, and false veins, and obtain a clear enhanced image of the palm vein. Experiment results carried out on two public databases and a self-built database yield the equal error rates of 0.0004, 0.0451, and 0.0395 and correct recognition rates of 99.96%, 94.50%, and 94.89%, respectively. The results indicate that the proposed method has better abilities of reducing equal error rate and improving recognition accuracy.",60002593,Southern Medical University,Guangzhou,China,['1702'],27.625,-0.010294117647058832,0.3602941176470587,0
568,568,Joint scheduling of tasks and VM migrations with multi-objectives in Saas cloud," All rights reserved.In SaaS cloud, there are two interrelated steps to schedule user requests. The first is to choose the proper VM (service) to handle the request, and the second is to map each VM (service) onto a proper physical machine (server). In this paper, we first put forward a heuristic algorithm to enhance the resource utilizations in a heterogenous data center and then propose a cascaded fuzzy dynamic programming (CFDP) method to do joint optimization of tasks and VM migrations to pursue long-term and maximum rewards with multi-objectives, which refer to performance benefits, energy consumptions, cooling costs for hot-spots, penalties for unfinished requests before deadline and VM migration costs. CFDP can learn from characteristics of incoming requests, does not rely on priori prediction of request arrivals, and considers both current and future impacts in the process of decision-making. Besides, value function approximation method is used to cope with state explosions and guarantee high scheduling speed at the same time. Finally, a group of experiments with both synthetic and realistic workloads are conducted, and QoS comparisons verify the effectiveness and robustness of our approach. In theory, we have extended the ability to comprehensively make two or more correlated decisions together in long-term and multi-objective optimizations with extremely large shared state.",101579472,Institute of Systems Engineering,Beijing,China,['1702'],30.142857142857142,0.0900595238095238,0.29550595238095245,0
569,569,Auto-updating portable application model of multi-cloud marketplace through bidirectional transformations system," All rights reserved.At present, the cloud marketplace becomes more and more widely used for delivering cloud applications to consumers. The diversity of IaaS and PaaS services from many cloud providers gives customers many choices that benefit them the most. If a customer is not satisfied with his existing cloud resource service (IaaS or PaaS), he is going to stop using the service in use and consider other cloud service providers. And he also wants his cloud software bought on the market to be hosted on new cloud platforms. However, changing cloud resource services for multi-cloud application is not trivial. In this paper, we propose an approach that uses a Composable Application Model (CAM) to construct the topology of a multi-cloud application in a Blueprint. Thereby, all the changes of cloud platform services are reflected to the Blueprint. In this way, the cloud application is managed. Thus, cloud application operation is guaranteed after one or several of its software components are re-deployed on new cloud platform services and re-established application interconnections so that the operation of the cloud application is as an initial state. For updating the Blueprint, we built a bidirectional transformation system where the core is a bidirectional transformation program. We show how the Blueprint which is described by TOSCA-based specification is automatically correctly auto-updated.",60071354,Hanoi University of Science and Technology,Hanoi,Viet Nam,['1702'],19.727272727272727,0.1784090909090909,0.3774350649350649,0
570,570,The existence and constructions of DSMDs and LSMDs matrix on ring ℤ/(2M)," All rights reserved.In this paper, we will talk about the branch number of matrix of order n over ring ℤ/(2m), while there are few papers on it, but there are some crypotosystems based on the ring ℤ/(2m). In 2017, Qu etc only proved that there no MDS matrix (i.e. the branch number of matrix is n + 1)on the ring ℤ/(2m). We firstly introduce the DSMDS (LSMDS) matrix (i.e. the differential (linear)separable branch number of matrix is n)and prove there exist such matrice of order 2, 3, 4. Secondly, we give a sufficient and necessary condition of DSMDS (LSMDS) matrix,respectively. Thirdly, we show there are no DSMDS (LSMDS) matrix of order n for n ≥ 5 using conditons got above. So, we should study the upper bound of the branch number of a matrix. Finally, we give another depiction of the branch number of a matrix and conjecture a new tight upper bound of it,which smaller than the known upper bound given in 2008, for n ≥ 6. We prove that it is true when n = 6, 7 and leave it as an open problem for n ≥ 8.",60025345,Guangzhou University,Guangzhou,China,['1702'],19.1,0.021046600458365164,0.3778584160937102,0
571,571,Facial expression recognition based on PCA-SIFT and fuzzy-edge detection," All rights reserved.The traditional method of facial expression recognition (FER) is difficult to accurately describe a facial expression. The illumination, facial angle, individual differences, and other factors make the low recognition accuracy. Thus, in this paper, we present a method of combining SIFT to filter the feature points and PCA to reduce the dimension of feature images. Meanwhile, fuzzy edge detection is adopted to detect the edge of face. For the experimental result, this method outperforms other state-of-the-art methods .",60031863,"Northeastern University, China",Shenyang,China,['1702'],16.2,-0.020833333333333325,0.3527777777777777,0
572,572,Indoor radiofrequency signal propagation and attenuation prediction hybrid modelling and wireless local area network case study simulation," All rights reserved.This work presents a Hybrid Model of indoor radiofrequency signal propagation and prediction to be applied to a wireless local area network environment. The wireless local area network environment Computer Aided Design prototype consists of a 1-floor area 25x110m2, with offices and classrooms and it was simulated using 914 MHz indoor radio frequency signals propagation. This new indoor Hybrid Model for a wireless local area network includes features based on the classical indoor communication models suggested by Seidel, Cheung, Honcharenko and International Telecommunication Union recommendation P.1238-9 (06/2017 updated) methods, for signal propagation and prediction methods, the planning of indoor radio communication systems and radio local area networks in the frequency range from 300MHz to 100GHz. The simulation of this hybrid model for indoor radio frequency signal propagation and prediction aims lower attenuation intensity and better quality of service of the radio frequency signal prediction and propagation. The features includes diffraction rays, exponent attenuation distance dependence, angle dependence attenuation factor and the diffraction coefficient for an absorbing wedge as suggested by the classical indoor prediction methods of Seidel, Cheung, Honcharenko and International Telecommunication Union Recommendation P.1238-9. As contribution and advantage of this hybrid model are case study of the Hybrid model, the facility in the method implementation, fast computational processing, lower signal attenuation and better accuracy of indoor radio frequency prediction results when compared with the classical methods indoor wireless local area network.",112722724,Federal Center for Technological Education of Minas Gerais,Belo Horizonte,Brazil,['1702'],39.166666666666664,0.10242424242424243,0.2003030303030303,0
573,573,PRARS: Risk assessment model for recommender systems," All rights reserved.Recommender systems play a vital role in web-based information systems, especially in the domain of e-commerce. Most of these systems provide their recommendation based on user's preferences. However, based on different situations of the user, their preferences can differ. Providing recommendations based only on the user's preferences and ignoring their situation can be risky and can lead to inaccurate recommendations resulting in poor acceptance and a non-purchase. The aim of this research is to evaluate the risk of a user not purchasing before providing a recommendation to an ecommerce user. The proposed model classifies sessions as risky or non-risky, which indicates the likelihood of the session containing a purchase. The risk calculation is based on two perspectives and seven factors. We evaluate the work experimentally and use three metrics, which are True Positive Rate, True Negative Rate, and AUC (area under curve) of ROC (receiver operating characteristic) curve. The proposed model outperforms two state of the art algorithms on two different real world datasets, as measured by the AUC. The highest AUC of ROC is 0.97 when the users' sessions history is included, and the lowest AUC of ROC is 0.79 when the users' sessions history is not included. Our experiments show that the proposed risk calculation is a good predictor of a user's purchase intention.",60005686,University of Auckland,Auckland,New Zealand,['1702'],19.90909090909091,0.11737373737373735,0.5808080808080809,0
574,574,Incremental mining of spatial co-location patterns based on the fuzzy neighborhood relationship," All rights reserved.A spatial co-location pattern is a set of spatial features frequently co-located in nearby geographic spaces. Due to the spatial database is constantly changing as time goes on, the incremental mining of prevalent co-location pattern algorithms have been proposed in the literature. And focusing on the ignorance of the proximity level between instances, the co-location pattern mining based on fuzzy neighborhood relationship (FNR) has also been studied. However, the problem of incremental mining of prevalent co-location patterns based on fuzzy neighborhood relationship on the dynamic databases has not been addressed. In this paper, based on FNR, by capturing the changed (added and decreased) fuzzy neighborhood relationships, we define the incremental fuzzy participation index for measuring the prevalence of the changed co-location in the updated data sets, and design the algorithm of incremental mining of prevalent co-location patterns based on FNR (the IMPCP-FNR algorithm). Extensive experiments are conducted and demonstrate that, by compared to the naive method that re-discovers the prevalent co-locations on the whole updated data sets, our purposed algorithm is more efficient.",60028009,Yunnan University,Kunming,China,['1702'],29.333333333333332,-0.0027777777777777926,0.4564814814814815,0
575,575,FDG-SD: A new hybrid technique for solving subgroup discovery problem," All rights reserved.Subgroup discovery is a problem in machine learning and data mining in which the population data is mined to discover interesting subgroups with respect to a target property. The goal of subgroup discovery is to find rules describing subsets of the population. In this paper, a new solving approach is proposed (FDG-SD). The new approach adopts fuzzy rule induction that uses a dynamic programming like algorithm to discover fuzzy subgroups. FDG-SD surpasses disadvantages of existing approaches. It is able to find better solutions for almost half out of 30 UCI machine learning repository datasets based on significance, unusualness, support, confidence and running time quality measures. According to Friedmann test results, the new approach (FDG-SD) is ranked first among mostly used algorithms with respect to significance, unusualness, support and running time quality measures.",60010294,Cairo University,Cairo,Egypt,['1702'],19.285714285714285,0.2492424242424242,0.41553030303030314,0
576,576,The problem of a maximal weighted area of axis-parallel rectangle that covers polygons," All rights reserved.The paper presents the problem of finding the optimal location of the rectangle with the maximum weighted area. The dimensions of the rectangle are set, the sides of the rectangle are parallel to the axes. On the plane, there are non-self-intersecting polygons of arbitrary shape with a given density. The weighted area of a rectangle is calculated as a sum of the area of the parts of polygons covered by the rectangle multiplied by their densities. The algorithm for solving the problem is described. This problem arises when determining the places of forest felling when the planned cutting area can be modelled by a rectangle, and the polygons describe the areas with same forest taxation, for each of which is known forest stock per hectare.",60031202,Petrozavodsk State University,Petrozavodsk,Russian Federation,['1700'],21.333333333333332,-0.175,0.40625,0
577,577,The collaborative strategy of multiple USVs with deep reinforcement learning method," All rights reserved.The unmanned surface vehicle (USV) has been widely used to accomplish tasks that cannot be completed by ships with human drivers on certain sea areas. It is not only necessary but essential to obtain a robust strategy in order to ensure multiple USVs accomplish collaborative tasks successfully and efficiently. To meet the challenge, a deep reinforcement learning method is proposed, which is combined with an improved A star algorithm. A statistically promising collaborative strategy is achieved by the proposed method under the guidance from the unmanned aerial vehicles (UAVs). After the collaborative strategy is generated, the improved A star algorithm is used to navigate the USVs. To verify the proposed algorithm, several tasks are tested on a simulation platform. Experimental results demonstrate that the proposed method outperforms state-of-the-art reinforcement learning methods such as DQN and DeepSarsa.",60023813,Shanghai University,Shanghai,China,['1702'],19.857142857142858,0.08956043956043956,0.4708791208791209,0
578,578,The environment quality evaluation and prediction algorithm based on WSN," All rights reserved.The growth of pig not only depends on its gene, but also depends on its growing environment. The factors that influence the piggery environmental quality mainly include temperature, humidity, ammonia, hydrogen sulfide, carbon dioxide, methane, etc. In this research, six environmental factors were chosen and summarized as two significant comprehensive factors through factor analysis, which are gas factor and drying factor. And the cumulative variance contribution rate is 81.066%. The comprehensive evaluation results of factor analysis are: (1) Under the same condition, the increase of temperature leads to the increase of ammonia concentration in piggery; (2) With the increase of humidity, ammonia concentration increased in the piggery; (3) Compared with other gas pollutants such as carbon dioxide, methane and ammonia, hydrogen sulfide concentration is relatively low in livestock and poultry. The above conclusions are consistent with the relevant literature and the actual situation. Therefore, the factor analysis method is suitable for analysis of environmental quality in pig house. At the end, the comprehensive ranking of piggery environmental quality were given based on factor analysis, which would provide certain theoretical basis and reference value for piggery environment quality based on small changes in climate.",60108806,Henan University of Animal Husbandry and Economy,Zhengzhou,China,['1702'],24.5,0.051934523809523805,0.479985119047619,0
579,579,Adoption of agile by software developers in Thailand," All rights reserved.Agile has gained increasing interest in the software developer community in Thailand. Although many Thai developers have incorporated Agile methods in their software projects in recent years, the project teams are still largely unaware of the rationale behind the developers' decision to adopt Agile methods. This paper presents the results of a survey conducted to determine the usage of Agile methods by Thai software developers. We collected data from 108 respondents who use Agile methods. The empirical evidence from this study can help researchers and Thai developers gain more insight into software engineering practices, in particular, the adoption of Agile in Thailand.",60090656,Universiti Tun Hussein Onn Malaysia,Batu Pahat,Malaysia,['1702'],21.0,0.28055555555555556,0.5527777777777777,0
580,580,Quality and sustainability dimensions toward green software product: A review," All rights reserved.Green software is an initiative to improve the atmosphere which reduces the negative impact and makes software activities more toward green environment friendly. Meanwhile, software quality is the characteristics of a product itself that fulfils the need and expectation from end-user. Recently, software quality is a research to make effort for green software product with new attributes of greenness embedded in the model. Green and sustainability are normally closely related to ensure that software are always relevant and usable. This is supported by the sustainability dimensions which are identified as economy, social, environmental, technical and individual. Previous studies more emphasised on power consumption, energy consumption, waste reduction and disposal on green hardware. However, it seems lack of studies in green software even though software has impact indirectly to the environment and to the software itself. Several studies works on green exclusively but lack of integration with the whole sustainability dimensions. The first objective of this paper is to review the current works in green and sustainability software quality, and the second objective is to identify the existing relationships between software quality factors and sustainability dimension. The outcome of this paper reveals the importance of software quality factors and sustainability dimensions in determining the greenness of software product.",60001821,Universiti Kebangsaan Malaysia,Bangi,Malaysia,['1702'],21.0,0.01707251082251083,0.31147186147186146,0
581,581,Minimum initial marking estimation in labeled Petri Nets using simulated annealing," All rights reserved.Computing the minimum initial marking (MIM) in labeled Petri nets (PN) while considering a sequence of labels constitutes a difficult problem. The existing solutions of such a problem suffer from diverse limitations. In this paper, we proposed a new approach to automatically compute the MIM in labeled PNs in a timely fashion. We adopted a simulated annealing based algorithm to model the MIM problem. The choice of such an algorithm is justified by the nature of the MIM process which belongs to the NP-hard class. We experimentally showed the effectiveness of our approach and empirically studied the initial marking quality in particular.",60050038,Université de Monastir,Monastir,Tunisia,['1702'],17.5,0.040303030303030306,0.41878787878787876,0
582,582,Technical architecture and security design of ex-post supervision systems of commercial banks," All rights reserved.Commercial banks' ex-post supervision system is a useful tool for preventing financial risks. Owing to the extremely high security requirements for bank systems, the ex-post supervision systems tend to involve huge storage and transmission of data. Hence, appropriate security architecture of ex-post supervision systems is of great significance. This study focuses on the description of technical architecture, security strategy, and security design of the ex-post supervision systems.",60122420,Shandong University of Finance and Economics,Jinan,China,['1702'],17.5,0.3085714285714286,0.3985714285714286,0
583,583,Augmented reality as learning tool in education of sculpture arts," All rights reserved.Learning materials with media is one of the most important elements of an educational institution, especially in order to acquire a consistent learning session and an intermediary tool between teachers and students. With the emphasis given to Augmented Reality's technology, based on E-SeniArca learning tool, it will provide a way to deliver the information with more effectively, which is, students are easy to learn the topic of the sculpture compare just imagine through the picture. In line with this study, the purpose is to design, transfer, construct and test the effectiveness of the E-SeniArca learning tool in sculpture topics. The method used in this study is through quantitative methods to enable data collection and analysis be done. This learning tool is one of the interest to be given an emphasis based on the concepts, methods, learning theories and methodologies used based on intelligence technologies, such as Augmented Reality, so that it can attract students and produce effectiveness and efficient learning.",60103633,Universiti Pendidikan Sultan Idris,Tanjong Malim,Malaysia,['1702'],32.6,0.32592592592592595,0.6259259259259259,0
584,584,Predicting chronic diseases based on split and merge method and streaming feature causal structure learning algorithm," All rights reserved.Early detections of chronic diseases contribute to the prevention of such diseases. Due to the limitation of dealing with big data of BN structure learning, we figure out a new structure learning algorithm called SAM (Split And Merge) algorithm based on the thought of Adaboost, to process big data. We combine SAM algorithm with casual discovery based on the streaming features(CD-SF) algorithm to form the SAM-CD-SF algorithm. To evaluate the performance of the proposed approach, we conducted extensive experiments on the questionnaires collected from Behavior Risk Factor Surveillance System. The SAM-CD-SF can effectively deal with relative large datasets. In order to further improve the time performance, we combine SAM algorithm with casual discovery with symmetrical uncertainty based on the streaming features (CD-SU-SF) to form SAM-CD-SU-SF algorithm. Compared with SAM-CD-SF algorithm, SAM-CD-SU-SF algorithm have slightly worse accuracy, but much better time performance.",60002836,Hefei University of Technology,Hefei,China,['1702'],20.571428571428573,-0.0053107606679035435,0.458913110698825,0
585,585,Energy consumption balancing algorithms on optimizing dynamic topology in WSNs," All rights reserved.Wireless Sensor networks (WSNs) are constructed of sensors with awareness and limited energy whose topologies are set up by the signals strength being emitted. In general, the signals transmitted are usually not in uniform distribution, which lead to the living sensors having unequal residual energies. The energy holes might be emerging in WSNs since of some sensors failure. We study static WSNs with two initial energy levels. Assume that the sensors acting as base stations will never be failure and the other sensor nodes have limited energy. Adjusting hierarchical topology, using relay nodes or the density of sensors, the emergence of the energy holes would be delayed vs reduced. The separateness between data collection and data processing is also considered to balance the energy dissipation of transmission. We propose three routing algorithms named Density_Sep, SecCluHead_Sep and Relay_Sep for improving cluster head (CH) selection in legacy SEP routing protocol in WSNs. Then we briefly explained that our algorithms could be completed in polynomial time. The simulation results obtained support that our algorithms are efficient in terms of network lifetime and balancing network energy consumption.",60008332,Nanchang University,Nanchang,China,['1702'],18.6,-0.08551587301587303,0.3536706349206349,0
586,586,Methodology to ensure information security in a distributed architecture for a public organization of Ecuador," All rights reserved.Elements of risk assessment and information security models that administer the assets were analyzed. The problem is the lack of an information management mechanism in environments distributed in the public sector. The main objective is to generate a methodology to increase the level of information security on distributed architecture for a Public Organization of Ecuador. Were used the deductive method and exploratory research to examine the information of the reference articles. It turned out the following: Prototype of distributed architecture, Generic algorithm to mitigate risks expressed on flowchart and Attack probability formula. It was concluded that the proposal generated is an alternative to maintain the information in a secure way, with persistence and available.",60008943,Universidad de Guadalajara,Guadalajara,Mexico,['1702'],19.5,0.12083333333333333,0.20833333333333331,0
587,587,A novel borehole video expansion and mosaic algorithm for un-aligned hole and camera centers," All rights reserved.Traditionally, the video panorama expansion algorithms were basically based on the assumption of the alignment of hole center and camera center. In real applications, due to hardware limitations, the borehole video image in the actual resource survey and acquisition project was obtained under the condition that the center of the borehole and the camera were not aligned. To solve the difficult task of obtaining panoramic images from borehole imagers and eliminate distortion in the resultant image for centers unaligned situation, this paper proposes a new borehole video image processing algorithm. Firstly, the image was expanded by using the ideal model (the aligned situation data), finding the corresponding circular region, and proper interpolating manipulation. The expanded image contains the cylinder hole wall information within certain depth scope but has some kind of distortion. Then by using least square fitting method and adopting the initial phase optimization estimation method, we obtained the high-order polynomial fitting depth direction correction curve. And the expanded images are corrected frame by frame. Lastly, the displacement of the horizontal direction is searched by the template region matching method, and the panoramic image of the borehole wall is obtained by pixel-level data fusion. The experimental results are evaluated. The peak signal-to-noise ratio of the algorithm is 21.0907 and the structural similarity is 0.7976 in terms of objective metric. While subjectively the average of the proposed algorithm is 3.6. Both objective and subjective measure are better than the existing algorithm. The resultant images are more intuitive than the original video.",60003977,Northwestern Polytechnical University,Xi'an,China,['1702'],19.53846153846154,0.13602597402597405,0.38603896103896107,0
588,588,Hypergraph clustering by generating large pure hyperedges using greedy neighborhood search," All rights reserved.Pairwise similarity between data points is usually computed in the traditional clustering methods. But in many cases, especially for high dimensional data in computer vision, it is required that more than two data points should be involved in representing the similarities. In this case, hypergraph clustering is an ideal tool for data analysis, where high order similarities on the data subsets, represented by hyperedges, can reflect the similarity among more than two data points. Hypergraph clustering usually includes hypergraph construction and hypergraph partition. Two important questions in hypergraph construction are how to generate the hyperedges and how many hyperedges should be used to represent the original data. Recently, Pulak Purkait et al. have proposed a method for generating the large pure hyperedges, which is proved to be more effective than the traditional methods for computer vision tasks. However, the method needs a specified number of hyperedges in advance, and uses random sampling to generate hyperedges, which may lead to suboptimal clustering results. Therefore, a novel sampling method called greedy neighborhood search is proposed in this work, which generates large pure hyperedges based on Shared Reverse k Nearest Neighbors (SRNN) and learns the number of hyperedges simultaneously. Experiments show the benefits of applying the proposed method on high dimensional data .",60073730,Hexi University,Zhangye,China,['1702'],21.3,0.2222670807453416,0.5772670807453416,0
589,589,"Game-based element within rehabilitation program: Case study at community-based centers (PDKs in Putrajaya, Malaysia)"," All rights reserved.Disabled individuals are those born with disabilities or transform into due to unfortunate events. To assist the disabled individuals for preparing them for normal life or even to getting ready for return-to-work (rtw), intervention and rehabilitation programs are critical. Unfortunately, these medically structured programs require prolonged, continuous and intensive recovery activities that can be time-consuming, difficult, costly and boring. Hence, the intervention and rehabilitation programs tend to be not well-received by many patients. Innovative home-based and community-based rehabilitation programs should be studied as to engage patients continuing their treatment for better success. Three community-based rehabilitation centers in Selangor, Malaysia were studied; the goal is to investigate the objectivity of improving one of the current rehabilitation programs i.e. music therapy session with game-based activities. Data showed that by injecting the element of games into its music therapy, the sessions provide more engagement and encouraged patients to challenge their physical and mental abilities.",60005762,Universiti Tenaga Nasional,Kajang,Malaysia,['1702'],19.25,-0.015277777777777755,0.5482142857142857,0
590,590,Bayesian belief networks-based fault-alarm assessment in communication networks," All rights reserved.With the networks grow in size and complexity, even a slight fault can cause large and abrupt network system behaviors disorder. Fault prediction and state assessment technology is a monitoring and proactive maintenance security form that can ensure a network smooth running before a failure effect to service quality. We present a belief propagate model of fault-alarm based on the Bayesian belief propagate scheme. It can identify the risk alarm that cause significant impacts and irreversible catastrophic consequences. We show through simulation that our method is validity and accuracy.",60022381,Beijing Jiaotong University,Beijing,China,['1702'],18.4,0.05442176870748299,0.46717687074829933,0
591,591,Comparing neural and regression models to predict NBA team records," All rights reserved.Neural networks have been widely used in artificial intelligence over the last ten years. They attract a lot of attention recently because of their ability to generalize and respond to unexpected inputs and patterns. This study is an extension of my previous study, in which NBA offensive and defensive statistics was analyzed, and a multiple linear regression model was built to predict NBA teams' winning percentages. The objective of this study is to apply neural network algorithms to predict NBA team records, and to compare the results with regression models. In this study, the neural network modes has a better prediction accuracy than the linear regression models. This is likely due to neural networks being able to handle nonlinear parameters while also implementing ensemble learning.",101737849,Mission San Jose High School,Fremont,United States,['1702'],21.333333333333332,0.04345238095238096,0.44523809523809527,0
593,593,Multi-view clustering via nonnegative matrix factorization with L21norm," All rights reserved.With the progress of science and technology, multi-view clustering exploring heterogeneous information among diverse views has been widely employed in real-world applications. Nonnegative Matrix Factorization (NMF) has received wide attention because of its interpretability. However, existing multi-view clustering methods based on NMF are vulnerable to outliers and noise. To alleviate these problems, we propose a novel model, named graph regularized multiple nonnegative matrix factorization with L2,1 norm (GRMNMF) method, for exploring multi-view data. GRMNMF utilizes L2,1 norm to calculate the error between the original data and the reconstructed data and simultaneously utilizes the geometrical structure of data space. A series of experiments were conducted in seven real data sets. The experimental results manifest the superiority of GRMNMF.",60028009,Yunnan University,Kunming,China,['1702'],17.142857142857142,-0.0035714285714285626,0.3928571428571428,0
594,594,The extension principle for probabilistic linguistic term sets," All rights reserved.The probabilistic linguistic term set (PLTS) extends the notion of the linguistic variable (LV). The existing operations of PLTSs are mainly based on the subscripts of linguistic terms and their probabilities while the membership functions of linguistic terms are ignored. Consequently, these operations may cause a loss of information. The extension principle is useful in doing the calculations between LVs and it considers membership functions simultaneously. Inspired by this idea, in this study, we introduce the extension principle for PLTSs and then define the operations of PLTSs. A novel representation of the PLTS is given. Then, the union of PLTSs is presented. Afterwards, we define the extension principle for PLTSs and give the algebraic operations of PLTSs. These algebraic operations based on the extension principle contain both the probabilities and membership functions of linguistic terms, and thus can enhance the precision of final results.",60016521,Sichuan University,Chengdu,China,['1702'],16.333333333333336,0.12083333333333333,0.22916666666666666,0
595,595,Design of a novel fractional order sliding mode controller for hypersonic vehicle attitude control," All rights reserved.This paper proposes a novel fractional order sliding mode controller for a second-order nonlinear system with disturbance. The new method contains fractional order terms which unify the form of traditional integer order PID. Firstly, the second-order nonlinear system with disturbance is investigated. Then a fractional order sliding mode controller is raised and the stability is proved based on Lyapunov stability theory. Furthermore, the numerical simulations are presented which show the effectiveness of the proposed method in the nonlinear second-order system. Finally, the proposed method is applied to hypersonic vehicle. The simulations show that the method in this paper can achieve satisfactory control results under external disturbance.",60016835,Beijing Institute of Technology,Beijing,China,['1702'],15.571428571428571,0.07727272727272727,0.5275757575757576,0
596,596,Thermal infrared ensemble tracker with an algorithm using Kullback-Leibler divergence," All rights reserved.Thermal infrared tracking (TIR) is able to track objects in dark environments such as night. It can be used mainly for surveillance and rescue for surveillance cameras at night. While the development of automatic driving is progressing in recent years, we believe that thermal infrared tracking can contribute to the improvement of safety even in places with few streetlights. However, unlike normal visual object tracking, thermal infrared tracking itself has some problems. In this paper, we propose an algorithm for improving the accuracy by selecting the optimal feature map for each sequence using Kullback-Leibler divergence (KLD) amount for ensemble tracking using the powerful expression ability of convolutional neural network (CNN). Using KLDs from response maps obtained from an ensemble tracker with multi-layer convolutional features in thermal infrared tracking (MCFTS), we determine the CNN filter most involved in creating the response map. By adjusting the bias value corresponding to these filters and learning the filter, it is possible to create a tracker corresponding to the sequence each time. In order to evaluate the performance of the tracker and conventional tracker which applied the proposed algorithm, we experimented with the thermal infrared tracking benchmark of VOT-TIR2016. We also compared the 24 types of trackers that were evaluated in the thermal infrared tracking benchmark. The experimental results demonstrate that the proposed tracker achieves effective and promising performances with some sequences.",60011157,Iwate Prefectural University,Iwate District,Japan,['1702'],23.0,0.13492063492063494,0.49436507936507934,0
597,597,Sentiment classification regarding the negative brand affect of enterprise Weibo comments," All rights reserved.A brand's official Weibo contains a large number of comments that reflect people's emotional responses to the brand's products, services and other aspects. Therefore, negative emotional information can receive much attention and spread widely, so it is very important to manage and control this effectively. This paper uses sentiment analysis to establish a sentiment classification model of brand affect based on the official Huawei Weibo comments. First, the official Huawei Weibo comments are obtained and word2vec is used to preprocess and characterize the comment text. Second, three machine learning algorithms are used to learn sentiment classification for brand affect, namely support vector machines, random forests, and deep belief networks. Through the comparison of the resulting classification accuracy from the experimental results, the best model is selected and the brand's negative emotional comments are obtained. Third, the word frequencies of these negative comments are obtained and the monthly trends of the proportion of high-frequency words and negative emotional comments are calculated. At the same time, the existing problems are analyzed and corresponding countermeasures and suggestions are proposed in order to solve this problem for an enterprise, so that the company's brand strategies are adjusted in a timely and reasonable way.",60019616,Harbin Institute of Technology,Harbin,China,['1702'],25.25,0.057240259740259744,0.4391774891774892,0
598,598,BBCoM visual weaver for model-driven software design," All rights reserved.BBCoM technology supports integrating software components in a system by providing a middleware environment, protocol based communication, and data dependencies for applications such as robotics and IoT. In this paper, we introduce the BBCoM Visual Weaver, which is a visual tool improving the BBCoM-based integration process of software components making it similar to the UML-based design. It incorporates the basic BBCoM elements and supports the developer's step-by-step guidance during the implementation process. The evaluation results show how BBCoM Visual Weaver automates most of the code and integration schema generation, reducing greatly the developer efforts.",60031404,The University of Aizu,Aizuwakamatsu,Japan,['1702'],24.25,0.1625,0.284375,0
599,599,ReciPicker: Recipe recommendation using hybrid filtering for reducing food waste," All rights reserved.In the literature, several researches on recipe recommendation have been proposed, taking into account different goals, such as to suggest healthy recipe and to personalize user taste. However, recommending recipes with a specific goal of reducing food waste is still an open issue. Meal preparation require recipes and ingredients. In some recipes, it is not always clear the quantity of ingredients has been used. If the ingredients are not fully utilise, it will lead to food waste. The goal of this study is to determine a useful way to recommend recipes using available ingredients in the house to prevent household food waste. We construct a hybrid filtering approach that combines the Term Frequency (TF) and Inverse Document Frequency (IDF) as content-based filtering and matrix factorization as collaborative filtering. We develop a recipe recommender system using the hybrid filtering approach. We conduct a preliminary user study to evaluate the usability of the recommender system. We found that all participants agreed that the system is useful and 80% of participants agreed that the system meet their needs. The recipe recommender system can be used to search recipes based on available ingredients. Furthermore, the system will be able to assist user to manage their time by reducing the time taken to prepare meals.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1702'],17.75,0.12666666666666665,0.2688888888888889,0
600,600,"Evolution of the internet architecture, from network model to internet brain model"," All rights reserved.Based on the new features of the frontier science and technology in the 21st century, this paper proposes that the Internet has evolved from a network structure to a brain model in the past 50 years. The rise of technologies including Internet of Things, cloud computing, big data, mobile Internet, industrial Internet, edge computing, artificial intelligence, etc. are all related to this change in the Internet. This paper proposes the definition of a new Internet brain model, elaborates the causes for the emergence of a number of cutting-edge technologies and interrelationships thereof, by depicting the development process of the Internet brain, and predicts the new technologies that will emerge in the next 20 years.",60019499,Chinese Academy of Sciences,Beijing,China,['1702'],29.25,-0.04898989898989899,0.34595959595959597,0
601,601,Integrating BPM and big data for BP modeling adaptability," All rights reserved.Data and processes are often complementary. In fact, if business process managers would like to have more efficient and effective processes, they must pay attention to how they use data. Nowadays, Big Data intersects with BPM and wherever the process management in the organization should be considered together with the new infrastructure technologies and analytics. In the present work, we will propose an approach integrating Big Data in the BPM lifecycle. The approach relies on how to incorporate the aspect of Big Data in all steps of Business Process Management, thus fostering Business Process Modeling adaptability.",60070317,Ecole Nationale des Sciences de l'Informatique,Manouba,Tunisia,['1702'],19.8,0.17662337662337663,0.29350649350649355,0
602,602,Fuzzy probabilities of fuzzy events, All rights reserved.An approach to finding a probabilistic characteristics of fuzzy events is considered. The concept of fuzzy probability of a fuzzy event is introduced. The examples of the tasks in fuzzy formulation is given.,60023137,Taras Shevchenko National University of Kyiv,Kiev,Ukraine,['1702'],12.0,0.0,0.0,0
603,603,Research on management decision based on machine learning: Taking the decision of location selection of a pharmaceutical retail enterprise as an example," All rights reserved.This paper studied the location selection problem of pharmaceutical retail enterprises and proposed a location classification decision model based on machine learning, which provided reference and guidance for the location decision of retail enterprises and took a significant part in both theoretical and practical. We constructed a model of location selection of pharmaceutical retail based on machine learning by using the approval forms and operation data of the sample company. By processing and analyzing the historical data, constructing feature vectors and supervision information for store location selection, then the data set was divided into training data set and test data set. We trained the model and solved the optimal model parameters, validated the model on the test data set, and constructed an evaluation index to evaluate the objectivity and effectiveness of the model. The experimental results show that the decision-making model based on machine learning was effective and could be used to guide the decision-making of the location of retail stores in practice.",124101316,Shanghai National Accounting Institute,Shanghai,China,['1702'],33.2,0.215,0.43499999999999994,0
604,604,Bridge moving load recognition based on deep learning," All rights reserved.We have adopted computer vision and deep learning techniques to obtain detailed information of heavy trucks on the bridge, assisting the bridge structure health monitoring(BSHM) for structural analysis and state assessment. The R-ZF (ZF with residual structure frameworks) algorithm was proposed, where the residual structure was added into the ZF network, and the anchor was optimized. The experimental results showed that the R-ZF method had a mean average precision of 91.51% for Truck and Wheel, and the model recognition speed reached 0.050s/frame. At the same time, this method could obtain the detailed information of heavy trucks on the bridge accurately.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1702'],25.75,0.04375000000000001,0.5145833333333333,0
605,605,Physical experimentation using waterjet for animal skin incision," All rights reserved.The paper presents a survey of Waterjet incision research. The paper describes an actual experimentation on cow skin and bone, for a demonstration system developed using a Flow Mach 4c XD 3020 WJ, a Prime Direct Drive Pump, and a special designed Stainless-Steel Catcher Tank with Clamp Fixture which is capable to evade any other contamination, An application and its results are also illustrated. The previously developed analytical model is verified using the experimental work conducted by Honl et al. The percent error between the results of the depth of cut of the two studies are as low as 9% at a WJ pressure of 101 MPa up to 23% of 69 MPa.",60022904,New Jersey Institute of Technology,Newark,United States,['1702'],29.0,0.06988095238095238,0.3313095238095237,0
606,606,Applications of financing optimization algorithms in internet financial system," All rights reserved.Small and micro enterprises play a very important role in national economic and social development, and their development affects the country's economic structure. In traditional financial system, small and micro enterprises face serious financing bottlenecks in development process, and cannot obtain stable financial support conducive to their long-term development. To breaking the financing bottlenecks of small and micro enterprises, we examined internet finance. This paper analyzed the financing bottlenecks and used method of constructing the optimization algorithms model of internet finance investment and financing. We showed internet finance can effectively solve the financing bottleneck by virtue of its advantages, and introduced a systematic framework of internet finance and small and micro enterprises financing model. The rationality of the framework is proved through a case. The system framework has a certain reference value for solving the financing bottlenecks of small and micro enterprises.",60011235,Guangdong University of Foreign Studies,Guangzhou,China,['1702'],20.714285714285715,0.031020408163265307,0.41819727891156466,0
607,607,Local metropolis move in variable dimension model for finance. A Bayesian Markov chain Monte Carlo approach," All rights reserved.In this paper, we propose a new Metropolis Hasting (HS) Sampling known as the Local Metropolis Move for Machines Learning. The aim is to help support better implementation of the Markov Chain Monte Carlo (MCMC) Simulation for Bayesian Computation. The Variable Dimension SV model via the Change-point Analysis was used to detect the accurate number of changepoint locations from the High Frequency Data (HFD) using the hourly Asian Foreign Exchange (FX) rates. We aim to use these for machine to detect changepoint location for identify the economic factors relevant to the country concerned during the crisis period. Our purpose is to examine whether the proposed MCMC algorithm can make machine think and capable to choose the appropriate number of changepoints for each systematic change of the problematic Asian Crisis currency in the Bayesian Inference via MCMC modeling.",60138776,"Sasin School of Management, Bangkok",Bangkok,Thailand,['1702'],28.0,0.19761363636363635,0.35440656565656564,0
608,608,Clustering based on covariance matrix for pollution areas identification in ERT monitoring of contaminated sites," All rights reserved.The clustering method based on resistivity values is a feasible method to identify the contaminated area from the monitoring results when using ERT to monitor site pollution. However, for layered soil media, when the resistivity value of a soil layer is close to that of contaminated soil, the method can not effectively distinguish between the soil layer and a contaminated area, resulting in inaccurate identification results. In order to solve this problem, a clustering algorithm based on covariance matrix is proposed in this paper. The horizontal and vertical covariance matrices are calculated respectively, and then, clustering is executed based on covariance matrices to identify the pollution area. The field experimental results show that the proposed algorithm based on covariance matrices can effectively overcome the clustering inaccuracy caused by soil medium stratification, the low resistivity soil layer caused by the infiltration of rain in the shallow layer was successfully avoided being identified as part of polluted area.",60083498,Shandong Jianzhu University,Jinan,China,['1702'],31.8,0.11666666666666667,0.5499999999999999,0
609,609,Learning coefficients and information criteria," All rights reserved.In recent studies, image or speech recognition, psychology, and economics, etc. in real big data have been analyzed by learning systems. It is one of important problems to approximate an unknown true density function from training data selected from the true density function independently and identically using learning models. In a stochastic model, many hierarchical learning models for analyzing real data have been proposed, and proved to be effective. They are, however, singular, which classic theories for regular models cannot apply to. Therefore, the need for appropriate model selection methods for singular models has increased and several information criteria for singular models have been developed. For example, singular Bayesian information criterion, widely applicable information criterion, widely applicable Bayesian information criterion, and cross-validation have been considered based on mathematical theorems in algebraic analysis and geometry. In this paper, we consider learning coefficients in learning theory, which serve to measure the main term of learning efficiency in singular learning models. These coefficients have an important role in information criteria and are mathematically equal to the log canonical thresholds of Kullback functions. We show several mathematical theorems for obtaining these coefficients, and apply these theorems to Poisson distribution mixture models.",60002561,Nihon University,Tokyo,Japan,['1702'],20.0,0.12638888888888886,0.3771634615384616,0
610,610,Cognitive CAPTCHA based on perceptual abilities," All rights reserved.This paper describes possible applications of perceptual features in creation of new classes of authorization procedures, which use cognitive systems. In particular it will present application of cognitive, and personal characteristics in development of protocols, dedicated for user authentication or information management in Cloud and Edge infrastructures. The area known as cognitive cryptography will be also describe in the context of presented research.",60017351,AGH University of Science and Technology,Krakow MP,Poland,['1702'],22.0,0.060606060606060594,0.4175757575757576,0
611,611,A comparative usability study using Hierarchical Agglomerative and K-means clustering on Mobile Augmented reality interaction data," All rights reserved.This article presents the experimental work of comparing the performances of two machine learning approaches, namely Hierarchical Agglomerative clustering and K-means clustering on Mobile Augmented Reality Usability datasets. The datasets comprises of 2 separate categories of data, namely performance and self-reported, which are completely different in nature, techniques and affiliated biases. This research will first present the background and related literature before presenting initial findings of identified problems and objectives. This paper will the present in detail the proposed methodology before presenting the evidences and discussion of comparing this two widely used machine learning approach on usability data. This paper contributes in presenting evidences showing K-means as the better performing clustering algorithm when compared to Hierarchical Agglomerative when implemented on the usability datasets. The results shown has contradicted with some recent studies claiming otherwise, and the findings have created more research gaps pertaining the combined utilization of machine learning and usability analysis.",60021005,Universiti Teknologi Malaysia,Johor Bahru,Malaysia,['1702'],25.833333333333332,0.11363636363636363,0.30757575757575756,0
612,612,Fuzzy logic based unsteady aerodynamics modeling and analysis of advanced aircraft," All rights reserved.In this paper, an accurate unsteady aerodynamic model of advanced aircraft flying at high angle of attack is established based on the fuzzy logic method. Firstly, on the basis of processing wind tunnel test data, the unsteady aerodynamic characteristics under large single-axis oscillation are compared and analyzed, and the key factors affecting the unsteady aerodynamic modeling are extracted. Secondly, the membership function, internal function, fuzzy rules, model input and output of the fuzzy logic model are determined. Finally, based on the idea of back substitution method, the parameters obtained by Newton gradient iteration method are treated as the initial values of the parameters for the next structural identification, thus the improved model structure and parameters are proposed. The identification algorithm determines the structure of the model while constantly seeking the parameters of the model in view of the accuracy requirement of the model. The simulation results show that the unsteady aerodynamic modeling method proposed in this paper has strong applicability and high modeling accuracy.",60003977,Northwestern Polytechnical University,Xi'an,China,['1702'],27.833333333333332,0.13450793650793652,0.40946031746031747,0
613,613,Semantic recognition and classification method of Chinese abstracts," All rights reserved.The published scientific and technical abstracts provide semantic fact data of problems, methods, and results in scientific research activities, as well as reliable factual data for the use of artificial intelligence in knowledge services. If they can be accurately identified and separated, an intelligent and innovative knowledge question and answer system can be realized. This study proposed a semantic recognition and classification method for scientific and technical abstracts. The method first sorted the scientific and technical abstracts according to the syntactic and semantic functions and then performed statistical analysis of the number distribution of class and sentence positions, sentence type, and semantic structure of the sentence. The semantic word order characteristics of sentences were finally classified and merged based on this analysis, and the classification and experiment of the problems of scientific and technical abstracts were realized. The accuracy of the classification was 99%. The effectiveness of semantic recognition and classification algorithm was verified manually. The experimental results showed that this method had a simple algorithm and displayed high classification accuracy and good universality.",60031454,Xi'an University of Architecture and Technology,Xi'an,China,['1702'],22.125,0.165,0.5117006802721088,0
614,614,Trajectory tracking of electrical mobility AIDS using L2 robust controller methods," All rights reserved.This paper describes a new design of L2 robust controller of electrical mobility aids. The ability of disturbance suppression is one of the key performance indicators of a system. The L2 robust controller designed contained in this paper shows its disturbance suppression ability according to the simulation. In this paper, we firstly elaborate the four-wheel nonlinear L2 robust controller of the electrical mobility aids designed by using the back-extrapolation method through the construction of storage function. The stability of the L2 control rule is proved based on Lyapunov theorem. Secondly, we analyze the relationship between the stability of the electrical mobility aids and L2 gain. The proposed method not only overcomes the difficulty of solving HJI nonlinear partial differential inequalities in the design method of system controller, but also solves the problem including disturbance suppression and trajectory tracking, make the L2 controller asymptotically stable. In the end, the simulation research of the trajectory tracking with nonlinear L2 robust controller verifies the effectiveness and correctness of the design method.",60023212,Shenyang University of Technology,Shenyang,China,['1702'],21.375,0.0893939393939394,0.6257575757575757,0
615,615,Multivariate normal distribution based over-sampling for numerical and categorical features," All rights reserved.Imbalanced data classification is an important task in data mining and machine learning. Imbalanced data consists of majority class and minority class, where the majority class leads to miss-classification of minority samples. Various approaches have been proposed in recent years to address this problem. Sampling, which focuses on balancing between classes, is one of the methods to solve the class imbalance problem. In previous our research, we have proposed Multivariate Normal Distribution based Over-Sampling (MNDO), which uses correlations between attributes and statistical methods, and have tackled this problem. In this paper, we propose Multivariate Normal Distribution based Over-sampling for Numerical and Categorical features (MNDO-NC) to sampling a dataset that contains both numerical data and categorical data. First, MNDO-NC generates numerical data using correlation coefficients and multivariate distribution. Next, calculate the distance between the generated data and the original data, and identify 5 nearest neighbors. The categorical data is sampled by applying a voting strategy for the neighborhood sample. Some existing methods generate new samples using distance function, but our method uses positive class statistics. Therefore, it can be applied even if the number of training samples is very small. In addition, outliers can be reproduced stochastically, so more realistic samples can be generated. In the experiment, we used 17 imbalanced datasets, which consist of numerical data and categorical data. To compare with the existing method, 6 sampling methods, 2 scaling and 3 learning methods were used. As a result of the experiment, the proposed method showed the same result as other methods.",60011157,Iwate Prefectural University,Iwate District,Japan,['1702'],17.0,0.10866477272727272,0.4470833333333332,0
616,616,Improve student performance prediction using ensemble model for higher education," All rights reserved.In higher education institutions, the most significant issue is to improve the students' performance and retention rate. Massive numbers of students' data are used to gain new hidden knowledge from students' learning behaviour, particularly to discover the initial symptom of at-risk students by using Educational Data Mining techniques. However, data with noises, outliers and irrelevant information might cause an inaccurate result. This study aims to develop a robust students' performance prediction model for higher education institution by identifying features of students' data that have the potential to increase performance prediction results, comparing and identifying the most suitable ensemble learning technique after preprocessing the data and optimizing the hyperparameters. Data are collected from 2 different systems, which are: student information system and e-learning system of undergraduate students from the Faculty of Engineering in one of Malaysia's public university. 4413 students' instances are used for this study. The process follows 6 different data mining phases namely: data collection, data integration, data preprocessing (such as cleaning, normalization, and transformation), feature selection, patterns extraction and finally model optimization and evaluation. Machine learning techniques used to build prediction model are Decision Tree, Support Vector Machine and Artificial Neural Network, while for ensemble learning: Random Forest, Bagging, Stacking, Majority Vote and 2 variants of Boosting techniques are AdaBoost and XGBoost. Hyperparameters for ensemble learning techniques are optimized to gain better performance and optimum result. The result shows that the combination of features of students' behaviour from e-learning and students information system using Majority Vote produced better result compared to other ensemble methods.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,['1702'],25.9,0.11145454545454545,0.5815151515151515,0
617,617,Research on a security chip power-down test method based on MP300 device," All rights reserved.The security chip operating system is the basis for the security chip to support complex and secure applications. In the case where the security chip suddenly loses power during the interaction with the terminal, a mechanism is needed to protect the chip data, that is, the power-down protection mechanism. This paper studies a method for testing the security chip power-down protection mechanism using MP300 device. This scheme can arbitrarily allocate the time interval of the power-down test, so as to select the required test accuracy, test start and end time according to the application. Therefore, the system is safe and stable under the condition of power down.",60105821,Beijing Aerospace Command and Control Center,Beijing,China,['1702'],22.0,0.007407407407407414,0.4148148148148148,0
618,618,Exploring the big pictorial data for tourists' perception analysis through three deep learning models," All rights reserved.In the era of big data, social media becomes an essential platform for contemporary people to share and socialize. Every day, tons of traveling photos are uploaded by different tourists from the world, which contain much valuable information. It is of considerable significance to mine and analyze the visual contents of the big pictorial data for obtaining tourists' perception and providing sufficient pieces of evidence for the development of tourism industry. In this study, 36119 photos shoot in Beijing by overseas tourists on the platform of Flickr were screened out by data mining techniques. We made an early attempt to employ three deep learning models in the field of computer vision to analyze the visual content of the photos, which are scene understanding, semantic segmentation, and emotional recognition, and ResNet, DeepLab澿 and WSCNet are the specific structures of the three models. A three-step process was adopted for analysis. Firstly, with the employment of scene understanding model, buildings as the dominated perceived tourism attractions in Beijing were selected out. Secondly, 13797 photos of buildings were further analyzed through the deep learning models of semantic segmentation and emotional recognition. At last, the specific relationship between the types of buildings, semantic elements, and emotional characteristics was revealed. The whole study provides an early empirical attempt for the application of big data in the field of tourism.",60018038,Nankai University,Tianjin,China,['1702'],22.6,0.04807692307692309,0.2724358974358974,0
619,619,Video content features based fast intra prediction algorithm on HEVC," All rights reserved.High Efficiency Video Coding (HEVC) is the mainstream international standard of video compression. HEVC introduces a more flexible division structure based on quadtree coding block and 35 intra prediction modes, and results in high video compression performance for intra prediction of HEVC. However, in order to get the best prediction mode, traditional encoders usually traverse all intra prediction modes, which have high complexities. To reduce the complexity of the coding of intra prediction, we propose a fast algorithm of intra prediction based on video content features. The fast algorithm of intra prediction proposed in this paper is implemented on the HM 16.7 which is a reference software of HEVC, and the results of experiment show that the average coding time is reduced by about 28.13% while the BD rate increases by only 0.92% under the all-intra conguration.",60017605,Fuzhou University,Fuzhou,China,['1702'],28.0,0.15166666666666667,0.4566666666666667,0
620,620,Research on experimental teaching of virtual and real welding technology and engineering specialty," All rights reserved.Experimental teaching as a process of applying theoretical knowledge to practice, aims to cultivate students' ability to observe things and develop the scientific spirit of continuous in-depth study and innovation. The emergence of virtual experiment system has successfully solved the problems of insufficient laboratory equipment, obsolescence and aging further expanded students' knowledge system, and promoted the diversification of teaching mode. Virtual experiments can also be updated in a timely manner. New technologies can be quickly incorporated into virtual experiments, and the advanced and systematic experimental and teaching contents can be realized in a timely manner. By introducing virtual experiment technology into the experimental teaching of welding technology and engineering specialty, the teaching quality of welding experiment can be greatly improved.",60019616,Harbin Institute of Technology,Harbin,China,['1702'],24.6,0.2910774410774411,0.5171717171717172,0
621,621,Dynamic magnetic resonance image reconstruction based on rosette sampling and tensor singular value decomposition," All rights reserved.Rosette k-space trajectories are faster, more motion robust, for dynamic Magnetic Resonance Imaging data, in this work we have extended the concept of Rosette trajectories to time-dimensions, repeated sampling of k-space points leads to off-resonance behavior and cause destructive interference or loss of image intensity but with little blurring, off-resonance signal can be removed as background noise, to restore correlations between data, we regarded the sampling data as a tensor and introduced iterative reconstruction method derived from Total Variation and tensor-Singular Value Decomposition regularization terms for dynamic Magnetic Resonance Imaging reconstruction. The experimental results demonstrate that the proposed reconstruction model can effectively achieve better performance and satisfied quality for under-sampled k-space data.",60016521,Sichuan University,Chengdu,China,['1702'],57.5,0.14125000000000001,0.5383333333333333,0
622,622,Using reo formalism for compliance checking of architecture evolution with evolutionary rules," All rights reserved.Assessment of architectural evolution is a challenge and plays a significant role in system evolution management. Although the evolution rules of the software architecture are defined by some expert engineers or architects, there is no guarantee that applying them will end to the desired change. So, having a reliable assessment technique promotes the overall accuracy and quality of the evolution process. Compliance checking with expert-defined rules is a well-known assessment approach that can be applied in architectural evolution. In this paper, an approach is proposed for compliance checking of evolution processes. To this end, evolution paths and processes are modeled by Reo coordination language and compliance checking is automatically performed by model checking of the Reo circuits. To demonstrate the applicability of our approach, we show how it can be applied to a real-world architecture evolution problem.",60027666,Sharif University of Technology,Tehran,Iran,['1702'],20.0,0.1875,0.4375,0
623,623,New entropy on the interval-valued neutrosophic set," All rights reserved.Entropy plays the powerful role in the fuzzy set theory to identify the uncertainty between alternatives as well as the weight of them. In this paper, the entropy is erected, it is an extension of Szmidt and Kacprzyk's entropy on the interval-valued neutrosophic set which use the cardinality of fuzzy sets and the ratio distances. We will proposed a multiple criteria decision making problem using the entropy on the interval-valued neutrosophic set. An example is performed to illustrate the proposed model.",104960134,Banking Academy,Hanoi,Viet Nam,['1702'],21.0,0.15,0.5,0
624,624,Time sensitive network fault detection and location method based on segment routing," All rights reserved.Time sensitive network requires ultra-low delay time services. It is necessary to know the state of the transmission paths, especially to be able to quickly detect and locate fault point when a fault occurs. The fault detection and location method based on segment routing is studied in this paper. A candidate probe paths set generation algorithm based on segment routing is proposed, and an optimal probe matrix construction algorithm is designed. According to the information about the probe paths in the probe matrix, the fault node can be detected and located quickly. Due to the minimization of the number of the probe paths, the detection process does not occupy too much bandwidth resources, and the time is short, which can meet the needs of time sensitive network.",60008919,Guilin University of Electronic Technology,Guilin,China,['1702'],21.666666666666668,0.20104166666666667,0.6468750000000001,0
625,625,Operating performance assessment for smart electric meter based on improved evidence theory," All rights reserved.With the era of Smart Grid, automated assessment of operating performance for smart electric meter is a challenging problem. It needs fuse multiple operating data of smart meters, this fusion is a typical ordered proposition fusion, i.e., the probability curve of fusion result should be convex. Traditional Dempster-Shafer theory model cannot guarantee the convex property, to issue the problem, in this paper we proposed an improved evidence theory based on asymmetric Gaussian model. Both theoretical analysis and experimental results demonstrate the effectiveness of the proposed method.",60007711,Jilin University,Changchun,China,['1702'],22.25,0.1341991341991342,0.5344155844155843,0
626,626,Usability of a learning management system in interface comparison," All rights reserved.This article presents the usability evaluation of an e-learning web application that supports students in self-directed learning of key competences and soft skills during project phases. We developed ""clavis"" based on an open-source learning management system and optimized it for mobile access to microlearning content. The usability evaluation explores how students interact with the learning environment using predefined interaction scenarios and questionnaires. We used thinking aloud, observation and an interaction recording to assess the usability from the students' point of view. Our article compares the evaluation results of desktop and mobile interface and discusses problems with the hybrid use of browser-optimized learning management systems on mobile devices.",60014264,Universität Duisburg-Essen,Essen,Germany,['1702'],22.0,0.06666666666666667,0.55,0
627,627,A de-theoretical experimental modal analysis method using data mining-symbol regression," All rights reserved.Experimental modal analysis (EMA) is a program that allows structure modal parameters to be extracted from the measured response under impulse excitation. Traditional EMA method is based on the assumption of linear mode theory, which is easy to cause pseudo-mode. Therefore, it is necessary to propose a de-theorizing EMA method. In order to solve the problem of obtaining modal parameters without theorizing, a method using data mining is proposed in this paper. As a data mining method, symbolic regression can obtain modal parameters by only mining function expression rules from single point response data. Taking modal parameter extraction based on modal theory as a reference, we designed a simulation test and an experiment to verify the feasibility of the proposed method. In addition, it has a good application prospect for de-theorizing modal rule mining based on data.",60025761,Huazhong University of Science and Technology,Wuhan,China,['1702'],20.0,0.176984126984127,0.732936507936508,0
628,628,Definitive screen design optimization of jeep performance on countryside terrain with a video game model," All rights reserved.Improving transportation safety on different terrains is a valuable topic to investigate. Countryside terrain is rugged, and cars need good equipment and technological design to drive safely. Hill Climb Racing is a physics-based driving video game and has demonstrated its potential of applying statistical data-driven and engineering problem-solving. The authors selected Jeep as vehicle and countryside landscape of Hill Climb Racing game, and used definitive screen design (DSD) to study what equipment had most influence on Jeep travelling distance on countryside terrain. To ensure the DSD structure, three examination criteria, including power analysis, confounding color-map analysis and uniformity analysis were conducted. The authors also conducted DSD optimization to build predictive modeling of Jeep performance on countryside terrain. The first model revealed that suspension and four-wheel drive (4WD) are the top two important factors, and the r-squared adjusted statistic was around 0.68. After model improvement and validation run, the r-squared and r-squared adjusted for the final model are 0.95 and 0.92. Suspension and 4WD remain the two most significant terms, while Suspension*4WD and Suspension*Suspension are also of significance. This project resulted in successful predictive modeling to determine the most important factors on Jeep driving on countryside terrain, where validity of the modeling and assumptions be further investigated. This methodology may be able applicable to transportation safety and car design research.",124101453,Stanford Online High School,Palo Alto,United States,['1702'],20.181818181818183,0.28194444444444444,0.6546296296296296,0
630,630,Analysis and comparison of multi-source information fusion technologies," All rights reserved.Multi-source information fusion technologies combine multiple homogeneous or heterogeneous information sources in space dimension or time dimension according to one specific standard, and obtain consistent interpretation or description of the measured object, then improve performance of the information system. According to the level of fusion, the fusion model usually integrates information from three levels including data level, feature level, and decision level. The system architecture used information fusion technology can be generally classified into three kinds, such as centralized fusion, distributed fusion and hybrid fusion architecture. According to the actual problem with the different information source data characteristics, we can separately adopt different level fusion methods or combine some two levels of fusion methods, and obtain better system performance.",60032504,Shanghai University of Engineering Science,Shanghai,China,['1702'],30.5,0.05,0.3113636363636364,0
631,631,Orthogonal low rank tucker decomposition for 2D+3D facial expression recognition," All rights reserved.Facial expression recognition (FER) has attracted persistently more and more attention due to its wide application potentials and scientific challenges. In this paper, we propose a novel approach to 2D+3D FER using orthogonal low rank Tucker decomposition (OLRTDFER). First, a new 4D tensor is built by stacking nine kinds of feature from 2D textured images and 3D face scans. Then, under a Tucker decomposition of this tensor, the low-rankness is imposed on the involved core tensor due to the high similarity of samples during projecting the three-dimensional face scans into the two-dimensional planes. Meanwhile the sparse representation of the factor matrix involved is carried out to avoid its denseness. Finally, a tensor completion is then embedded because the information is partly missed in the process of generating this 4D tensor. The validation performance are carried out on the BU-3DFE database, and the competitive results are obtained.",60022381,Beijing Jiaotong University,Beijing,China,['1702'],21.285714285714285,0.0246969696969697,0.48148989898989897,0
632,632,Design of multiple-valued logic unit by using R-HBT-NDR-based memristor," All rights reserved.A novel memristor with adjustable threshold voltage and resistance is introduced which is simulated by the R-HBT-NDR equivalent model according to the negative differential resistance (NDR) characteristic of Resonant Tunneling Diode (RTD). Experimental results show that the R-HBT-NDR-based memristor has a similar hysteresis loop to the TiO2 memristor, and can obtain adjustable thresholds and resistance by changing the equivalent model parameters. The R-HBT-NDR-based memristor is also applied to the multiple-valued logic operation units design. Compared to the conventional second type ternary CMOS logic units, the designed R-HBT-NDR memristor based multiple-valued NAND and NOR logic units not only have lower power consumption, but also have better output characteristic. This paper proposes a new idea for multiple-valued logic design of memristor circuits and cross-research of memristor and negative resistance device.",60013614,Hangzhou Dianzi University,Hangzhou,China,['1702'],26.2,-0.012711530893349067,0.4404565131837859,0
633,633,RFID localization based on optimized path loss propagation model," All rights reserved.In this paper, we propose an optimized path loss propagation model through analyzing the influence of multipath propagation and directional pattern on distance estimation, and then. to design more targeted experiments, we used the designed model for distance measurement and compared it with the maximum likelihood method without intermediate distance estimation process. The experimental results show that the proposed model is superior to the maximum likelihood Localization method in different dimensions.",60089933,Yancheng Teachers University,Yancheng,China,['1702'],24.666666666666668,0.32499999999999996,0.6,0
634,634,Discovering spatial co-location patterns by automatically determining the instance neighbor," All rights reserved.Spatial co-location pattern mining is an effective technique for identifying a group of features whose instances frequently located in geographical proximity. The distance between instances in space is commonly used to evaluate the proximity of them. If the distance between two instances is smaller than a distance threshold specified by users, they have a neighbor relationship. However, the neighbor relationships of instances determined in this way are ambiguous and it is difficult for users to set a suitable distance threshold. In addition, the neighbor relationships ignore the distribution of instances themselves, it is hard to deal with heterogeneous distribution density datasets. In this paper, we propose a new method based on the constrained Delaunay triangulation to determine neighborhoods of instances without distance thresholds for mining co-location patterns. First, applying the Delaunay triangulation to coarsely materialize the neighbor relationships of instances into an undirected connected graph. Then, we impose two strategies to constrain the Delaunay triangulation to prune undue edges. Finally, we develop a mining algorithm which can avoid the time-consuming generate-test candidate model which is widely used in previous algorithms. We perform experiments on both synthetic and real datasets to prove that our proposed method improves the accuracy and efficiency of mining results.",60028009,Yunnan University,Kunming,China,['1702'],20.6,0.03414502164502165,0.5390151515151514,0
635,635,Computation of virtual training samples and the experiments on face recognition," All rights reserved.Lack of training samples always reduces sharply the accuracies of face recognition. Generating virtual training samples is an effective method to improve the performance of face recognition. In this paper, we propose a new method to obtain virtual samples. The method allows the new virtual training samples to be little far from the original training samples. So they are able to contain proper variations of original face image, which caused by changeable illuminations and facial poses and expressions. The face recognition experiments on Feret and AR face databases show the effectiveness and robustness of the proposed method.",60073499,Hanshan Normal University,Chaozhou,China,['1702'],16.666666666666664,0.17365702479338843,0.5621900826446281,0
636,636,GAAMAAA: Generating automatically an adaptive multiagent system for ambient assistive applications," All rights reserved.The purpose of this paper is to present a clear description of an approach to automate the conception process, to implement and to deploy an open and adaptive multiagent system for personal assistive applications. This kind of applications increasingly relies on a network of connected objects which are present in the environment of elderly or sick people. It deals with exploiting the connected objects of this environment to offer a service (e.g., fall detection, localization) to these persons. Since the environment is dynamic, due to the availability or the lack of connected objects and to the diversity of situations, cooperation mechanisms among connected objects must be dynamically and adaptively designed. The proposed approach emphasizes the cooperation between these different connected objects. This work is based on cooperative multiagent systems in which each agent models a connected object. We will leverage interaction protocols in multiagent systems in order to design a platform capable of generating an adaptive multiagent systems automatically. The adaptation takes into consideration the context of the person as well as the existing interaction protocols. This paper presents an infrastructure which allows the use of ontologies for agent-oriented software engineering. The first results are very promising since they show several advantages of the approach in terms of adaptability of the generated multiagent system, as indicated by the experiments we have carried out.",60110530,University of Bisha,Bisha,Saudi Arabia,['1702'],22.6,0.04076530612244898,0.3903911564625851,0
637,637,An optimization algorithm for missing value imputation in microarray based on integrated information," All rights reserved.The technology of DNA microarray enables researchers to obtain thousands of gene expression data simultaneously, but for biological and technical reasons, inevitable missing values exist. We developed an optimization algorithm that preselects imputation candidates based on numerical features and biological meanings, combining statistical similarity, functional similarity and another similarity obtained through text mining. We applied the proposed algorithm and found that it improved the accuracy of some traditional imputation algorithms.",60029306,Wuhan University,Wuhan,China,['1702'],24.333333333333332,-0.02,0.44000000000000006,0
638,638,Cooperative navigation and positioning for multi-AUVs considering the effect of ocean current," All rights reserved.In cooperative navigation and position system of multi-AUVs, follower-AUV's navigation accuracy is low. A method considering the ocean current has been proposed to improve the positioning accuracy in this paper. Based on leader AUV's high accuracy navigation performance, the simulations of follower-AUV position with and without considering the ocean current are carried out to make comparison. The results show that positioning accuracy of the cooperative navigation and position system can be raised by considering the ocean current.",60003977,Northwestern Polytechnical University,Xi'an,China,['1702'],20.0,0.032,0.4079999999999999,0
639,639,Adaptive fuzzy sliding mode-based steering control of agricultural tracked robot," All rights reserved.The control system of the agricultural tracked robot is generally susceptible to various parameter perturbations and external disturbances. In this pursuit, the present work envisages the steering control based on an adaptive fuzzy sliding mode, by combining the fuzzy theory and the sliding mode control. Initially, the steering angle model of the tracked robot was deduced, and the characteristics of the DC servo motor were analyzed. Subsequently, a time-varying sliding surface with integral terms was designed to construct the adaptive control based fuzzy sliding mode on the equivalent control and the switching control. Based on fuzzy logic, the equivalent control used the sliding mode surface and its rate of change as the input of the fuzzy system, which were approximated to the equivalent control according to the simplified calculation of the fuzzy system output. This not only kept the rapidity and robustness of the sliding mode control, but also well suppressed the buffeting problem of the sliding mode control. The simulation and experimental results showed that the proposed control not only had strong robustness against the external disturbance and parameter perturbation, but also had the characteristics of a fast dynamic response and good tracking performance, when compared with the conventional sliding mode control method, thus making it applicable to the control system of the tracked robot.",60015487,Anhui Agricultural University,Hefei,China,['1702'],31.285714285714285,0.08936507936507936,0.40714285714285714,0
640,640,The application of the Dijkstra algorithm in the tourist route planning," All rights reserved.Taking Qinghai province as an example, Dijkstra algorithm and Lingo software are used to design a tourist route with the most scenic spots and the shortest distance for tourists, to provide the theoretical basis for the best route, and to obtain the optimal tourism plan for some tourist attractions.",124007581,Northwest Minzu University,Lanzhou,China,['1702'],52.0,0.5,0.3,0
641,641,E-learning BPaaS discovery in cloud based on a structural matching," All rights reserved.Recently, another cloud taxonomy service in addition to IaaS, PaaS and Saas services has been added: this is the business process as a service in the cloud (BPaaS). A BPaaS is any business process delivered through a cloud service model via internet with access through web interfaces. Therefore, process models will be developed by providers for discovery and use by tenants. In a previous work, we perform the design of an e-learning process as a business process in cloud. This paper examines the problem of discovering the similarity between e-learning processes. Given a pair of e-learning process models, the consumer lunches a request and the provider present a target process. The query is thus compared to the target process in order to check if it answers to the user needs. To achieve this goal, we use the graph based structural matching process and apply the graph edit edit-distance to measure the similarity between the two processes. We demonstrate the feasibility of our approach by testing the greedy and A-Star algorithms. The results we obtained show the efficiency and precision of the A-Star algorithm compared to the greedy algorithm.",60070317,Ecole Nationale des Sciences de l'Informatique,Manouba,Tunisia,['1702'],19.1,-0.022222222222222216,0.15555555555555556,0
643,643,Active learning of predefined models for information extraction: Selecting regular expressions from examples," All rights reserved.We consider the problem of constructing a regular expression for information extraction automatically, based only on examples of the desired extraction behavior. We describe an active learning framework that is not aimed at synthesizing a solution from scratch, but rather is aimed at selecting a solution from a set of more than 3000 solutions that have already proven useful in a broad range of practical applications. The user provides only one example of desired extraction and then interactively annotates text snippets selected by the system. The system constructs such queries based on uncertainty sampling, i.e., by selecting the snippet on which it is most uncertain at each learning step. The resulting framework allows solving many practical extraction problems quickly and simply.",60018363,Università degli Studi di Trieste,Trieste,Italy,['1702'],24.8,0.171875,0.4872138278388278,0
644,644,Missing rainfall data estimation using artificial neural network and nearest neighbor imputation," All rights reserved.Handling the missing values play important step in the preprocessing phase of hydrological modeling analysis. One of the challenges in preprocessing phase is to deal with the problems of missing data with good consideration on the pattern and approaches of the missing data. Hence, this paper presents a study on Feedforward neural network algorithm (FFNN) and Elman neural network (ENN) imputation algorithm in estimating missing rainfall data at different percentages of missingness. Reliable rainfall data series from nearest neighbor gauging stations were used as inputs to predict the missing rainfall data for an output station. The selected study area is Sungai Merang, East Malaysia. The study revealed that ENN method demonstrated a superior prediction of the missing daily rainfall data than FFNN method. It is also observed that the ENN model-infilling method could be highly beneficial in reducing the data gaps for continuous hydrological modelling analysis.",60021005,Universiti Teknologi Malaysia,Johor Bahru,Malaysia,['1702'],21.285714285714285,0.06333333333333332,0.3283333333333333,0
645,645,Infrared dim and small target detection based on spatio-temporal spectral saliency," All rights reserved.Infrared dim and small target detection plays a critical role in space-based infrared system and infrared search and track applications. Inspired by the visual saliency of human beings, the present study proposes an infrared dim and small target detection method based on the spatio-temporal and spectral saliency. In this regards, the 2D-DoG filter is initially applied to preprocess the image. Then, four data channels of quaternion are constructed through contrast measurement, velocity estimation and the direction feature extraction so that the saliency detection in the frequency domain is completed. Finally, considering the motion characteristics of the target, the false alarm rate is reduced by multi-frame confirmation of the pipeline filtering. Experimental results show that the proposed method can achieve stable and continuous target detection for different backgrounds.",60003977,Northwestern Polytechnical University,Xi'an,China,['1702'],21.666666666666668,-0.04615384615384616,0.4076923076923077,0
646,646,A deep learning approach for traffic condition prediction with dependency extraction and transfer," All rights reserved.Traffic prediction is an important application in intelligent transportation system (ITS) that leverages data mining and machine learning technologies to tackle traffic challenges such as low efficiency, disorder, congestion and so on. Thanks to the development and popularization of advanced apparatuses, data of traffic conditions are generated every minute in modern traffic system. In our research, we construct a specially designed deep learning model for traffic time series data to predict conditions in different locations. We involve an external data set of travel records, using transfer learning technique to extract and exploit dependencies that are implied by origin-destination information of each record. In the end, we test our model in real data experiment and achieve the best performance among multiple baseline methods.",60014966,Peking University,Beijing,China,['1702'],25.0,0.2540816326530613,0.43367346938775503,0
647,647,Design of network slicing system based on SDN/NFV," All rights reserved.Emerging network applications, such as multimedia cloud computing, virtual reality and big data analytics, require different Quality of Service (QoS). But the current Internet infrastructure designed to provide best-effort services, is difficult to meet these requirements simultaneously in a cost-effective manner. SDN/NFV (Software Defined Network/Network Function virtualization) based network slicing technology can well meet the above various requirements. In this paper, a network slicing system architecture and workflow based on SDN/NFV are proposed. The method can implement the slicing of network link resources and virtual network functions (VNF), and combine edge computing to provide differentiated network link quality and network virtual function services for multiple users.",60008919,Guilin University of Electronic Technology,Guilin,China,['1702'],21.8,-0.0625,0.4,0
648,648,Managing missing values in intuitionistic reciprocal preference relations: From numeric procedures to granular," All rights reserved.In decision making it has been generally assumed that the decision maker possesses the enough knowledge about the whole problem and she or he is able to distinguish the degree up to which an option is better than other one. However, this may be impractical in real world situations, which can involve many options to select from information sources that can be dynamic and conflicting. Therefore, different procedures for estimating incomplete information have been developed in the literature, which principally deal with fuzzy preference relations. In this research, and different from the existing procedures that deal with fuzzy preference relations, we introduce a procedure based on granular computing to estimate missing values in intuitionistic reciprocal preference relations. In particular, we describe how the granular computing can be used to estimate missing information so that the estimated values lead to complete intuitionistic reciprocal preference relations with consistency levels as high as possible. The results show that the procedure based on granular computing is able to increase the consistency level achieved by the existing procedures dealing with missing values in intuitionistic reciprocal preference relations.",60030835,University of Alberta,Edmonton,Canada,['1702'],30.833333333333332,0.11258333333333334,0.42074999999999996,0
649,649,HIV incidence in Russia: SIR epidemic model-based analysis," All rights reserved.The problem of predicting the incidence rate of the human immunodeficiency virus (HIV) in Russia is considered. The official morbidity levels were taken as initial data; for numerical modelling, the SIR model was applied to take into account the birth rate, mortality, as well as chemoprophylaxis and isolation of a group of infected but not epidemically dangerous patients. The search for the coefficients of the model is examined in detail using gradient descent with an auxiliary system applied. Various scenarios of the epidemic development are estimated, depending on the percentage of the number of patients who are undergoing therapy. The consequences of achieving the goals of the UNAIDS strategy 90-90-90 (90% people who are aware of their status, 90% among them are on HIV treatment and 90% among them are virally suppressed) are described. It is shown that upon reaching the target levels of involvement of patients in anti-epidemic measures, the number of infected people can be kept within 1% of the total population with a further decrease.",60031888,Saint Petersburg State University,Saint Petersburg (ex Leningrad),Russian Federation,['1700'],28.5,-0.049999999999999996,0.42857142857142855,0
650,650,Generating data to alleviate data imbalance problems in machine learning," All rights reserved.In this study, we address the problem of imbalanced data reducing machine learning performance. An analysis of the problem indicates that it is caused by differing amounts of data in each class and too few features in the minority class data. To address these issues, we propose a generative model that creates sufficient additional minority class data to eliminate the imbalance in the data amounts. This can also resolve the issue of a lack of minority class features. The proposed method is based on a neural network that uses the squared error as its error function, which is easy to calculate. The generated data is combined with the original minority class data, thereby reducing the proportion of generated data used and any effects due to differences between the generated and original data. We also expect that adding generated data will supplement the number of minority class features seen in the original data. Experiments evaluating our proposed method with artificial data show that it yielded a higher AUC value than that of undersampling. These results demonstrate that the proposed method can be an effective approach for addressing imbalanced datasets with small amounts of minority class data.",60004526,Future University - Hakodate,Hakodate,Japan,['1702'],22.0,0.12333333333333334,0.6258333333333334,0
651,651,Automated data-flow analysis and validation in process automation projects," All rights reserved.Process-driven applications (PDAs) rely on a combination of executable process models and code that implements individual process steps. These step implementations rely on process variables that maintain state across process steps and are used to take decisions on alternative execution paths, i. e. they hold data received from and saved to (external) backend systems. As a result, the data flow of a PDA can become complex even if each step implementation is kept simple. Complexity arises from various possibilities for manipulating process variables, in addition to the variety of execution paths that make it difficult to keep track of process variables. We propose a static analysis approach for managing or reducing complexity by limiting the solution space of implementations. It checks assertions on the data flow in PDAs while taking process variables into account. Assertions are specified using our novel data-flow validation language (DFVL). For demonstration, DFVL and automated assertion checking are implemented as part of an open source process application validation tool. The tool facilitates the use of DFVL for automated static analyses in the same way as unit tests are used for software testing. A short evaluation shows the applicability of our approach and tool.",115455666,Viadee Unternehmensberatung AG,Munster,Germany,['1702'],16.666666666666664,0.018181818181818177,0.49837662337662336,0
652,652,Discovering spatial co-location patterns under considering the distribution of spatial features," All rights reserved.As science and technology advance, massive data, such as spatial data in smart city application, have been collected. It has gradually become an important problem to mine prevalent co-location patterns from massive spatial data. Spatial co-location pattern mining is a very important research branch in the field of spatial data mining. A spatial co-location pattern is a set of spatial features which instances have frequently neighbor relationships each other in space. The traditional co-location mining method usually gives a single neighbor threshold to measure the neighbor relationship between instances, and the spatial distribution of instances of different spatial feature is not to be consistent. To solve the above problem, as explained by Tobler's first law, with the distance increases, the contribution of instances to the importance of patterns decreases, so the distance weight of instances is proposed. The influential threshold is defined from the distribution of feature instances. A spatial co-location pattern mining algorithm based on kernel density estimation model with influential threshold is proposed. Experiments are carried out in synthetic and real data sets. The results show that the algorithm improves effectiveness and efficiency compared with the traditional methods.",60028009,Yunnan University,Kunming,China,['1702'],19.3,0.08752100840336136,0.5509103641456583,0
653,653,A study of email author identification using machine learning for business email compromise," All rights reserved.Recently, Business Email Compromise (BEC) has become a big issue. Some security companies and organizations warn about BEC and say that we must defend against them. Although we have many SPAM filters, we have very few BEC filters. We have to find BEC by ourselves. One of the features of BEC is that the wording and style in BEC differ usual. If a software finds this point, it can help us to defend against BEC. Based on this idea, we propose a method to identify an email author using machine learning algorithms. In this approach, we make identification models from emails received in the past. We defined a target person in advance and use machine learning algorithms to make models which identify whether an email is sent by this person or not. We translate an email to a feature vector which consists of the similarity between the subject and the body, the distribution of Part of Speech and the occurrence of terms in the beginning part of the body. We make models from these feature vectors using machine learning algorithms, KNN, SVM, NBC and Decision Tree. And we try to identify whether a target person write a new email or not, with these models. We evaluated these approaches using open dataset and tools. The best accuracy is about 0.84 and the best Kappa statistics value is 0.68, therefore, our approach shows good agreement. However, we can get the better Kappa statistics value using a simple method. That is, we could not show the advantage of our approach. Overfitting is one of the reasons why our approach could not be better than an existing approach. We have to modify this weakness using literature resources and other approaches. Moreover, we have to evaluate our new approach using the bigger dataset. These are our future work.",60011157,Iwate Prefectural University,Iwate District,Japan,['1702'],15.3,0.19005892255892254,0.36275372775372766,0
654,654,Object-based storage system architecture model," All rights reserved.This paper introduces an object storage technology for the building of mass storage systems, and proposes an object-based system model. This model replaces the block-based storage with structured and unstructured P2P network topologies with object-based storage which facilitates data storage with high performance, high scalability, easy management, data sharing and high security. In engineering projects, this model can optimize the I/O performance of mass data storage systems which comprise heterogeneous OSD, following quantitative performance indicators.",60008691,University of Shanghai for Science and Technology,Shanghai,China,['1702'],26.0,0.1826666666666667,0.5106666666666666,0
655,655,The design of Quran memorization tool using low-fidelity prototype," All rights reserved.This paper aims to present the design of Quran memorization tool using a low-fidelity prototype based on preferred VARK learning style. This case study research involves 20 students age between 11-19 years old from Tahfiz Integration School in Sepang, Selangor. The proposed research will provide the Quran memorization learning process based on the feedback from the questionnaire and interview. The finding shows that most of the students have a different VARK learning style and there is a need to have multiple approaches in memorizing the Quran using suitable media of learning. Initial evaluation shows that the design can potentially improve students' performance in recalling their memory as well as retaining the Quran memorization.",60090706,Universiti Sains Islam Malaysia,Nilai,Malaysia,['1702'],23.2,0.14375,0.38125,0
656,656,Road crack classification based on improved VGG convolutional neural network," All rights reserved.In order to achieve accurate classification of road crack images, this paper proposes to classify road cracks based on improved VGG-16(Visual Geometry Group) convolutional neural network. First, the data set of road crack was constructed, which contains four types of pictures: single crack, transverse crack, patched crack, and no crack. A total of 8,400 pictures were taken, laying a foundation for the construction and training of subsequent models. Then, based on the VGG-16 network model, the model optimizes the number of fully connected layers and replaces the SoftMax classifier in the original VGG-16 network with a 4-label SoftMax classifier. These changes optimize the model structure and parameters, and then use the migration learning method to train the self-built data set. The final test accuracy of the model is 95%. In terms of average recognition accuracy, this research model and VGG-16NET are superior to AlexNET and GoogleNET. From the test results, the research model is slightly better than the VGG-16NET model, which has better classification performance for the road crack category and can accurately distinguish between single cracks, transverse cracks, patched cracks and no cracks. The realization of automatic identification and classification of road cracks plays an important role in saving labor costs, effectively implementing road maintenance and ensuring driving safety.",60028891,Chang'an University,Xi'an,China,['1702'],23.666666666666668,0.25547619047619047,0.5785714285714287,0
657,657,Development of rules and algorithms for model-driven code generator with UWE approach," All rights reserved.UML-based Web Engineering (UWE) is an object-driven method for model-driven Web application development based on the UML modeling language. Focusing on the principles of the Model-Driven Engineering (MDE) paradigm, UWE helps to develop Web applications speedily and efficiently. This approach provides four separated models for representing different web-application concerns, i.e., content, navigation, processing and presentation models. In this paper, we exploit UWE to propose rules and algorithms in order to automatically generate code from different models. We also develop a model-driven code generator tool named CODEGER-UWE which is embedded with the proposed rules and algorithms. CODEGER-UWE has been experimented to semi-automatically generate code for a typical example, i.e., a web-based address book application. We then evaluate the performance of CODEGER-UWE with respect to some metrics including the number of generated source codes, the generation speed and the completion level.",60071354,Hanoi University of Science and Technology,Hanoi,Viet Nam,['1702'],20.285714285714285,-0.05555555555555555,0.5666666666666667,0
658,658,Relative wireless positioning for multiple client devices using delta triangulation," All rights reserved.This paper considers a scenario in which a virtual map with relative positions for multiple wireless client devices has to be generated without resorting to fixed beacons. The proposal is unique in several elements, among which are the delta triangulation method and the method used to infer relative 2D positions for not only all client devices but also all WiFi Access Points (APs) within the local environment. APs provide what this paper refers to as local wireless context, comparing which across clients provides the deltas used for inference. The proposed concept is tested in a small field experiment while large-scale performance analysis is conducted on synthetic traces. Results show that relative distances among clients are preserved in the proposed layouts with high accuracy.",60025141,Tokyo University of Science,Tokyo,Japan,['1702'],25.2,0.03208333333333333,0.26166666666666666,0
659,659,Detection of outside historical routes for radar maritime targets," All rights reserved.A problem of detection of outside historical routes for radar maritime targets is considered. A new method is proposed for finding of normal historical routes and for detection of abnormal routes using radar data. This method is based on a grid-based modelling, an algorithm for finding of routing angles of all trajectories in each cell, and a modified DBSCAN algorithm with a new introduced distance function of two routing angles. It is shown that the classical distance functions such as Euclidean and Hausdorff cannot be able to use with the DBSCAN algorithm for clustering of routing angles. A test with real data is given. The false alarm rate (FAR) of the test is 0.",122935016,Viettel High Technology Industries Corporation,Hanoi,Viet Nam,['1702'],19.5,0.06856060606060606,0.3861742424242425,0
660,660,Comparison of accuracy estimation for weighted k-nearest neighbor classifiers," All rights reserved.Although nearest neighbor based classifier still shows good performance when training datasets are enough large, there are several improvements or comparisons to it. In this article, we discuss two kinds of k-nearest neighbor classifier (wk-NNC) weighted by different methods, and adjusted weights with n-fold cross validation for better classification performance. In fact, it is not enough to describe the performance of one classifier only depending on the classification accuracy. So we refer to the variance and the accuracy for performance comparison in this article. We develop experiments on different datasets (such as HEART, WINE, and HILL-VALLEY, downloaded from UCI), and compare the performance of wk-NNC under n=3, or 10 folds cross validation for adjusting the weights. The results show that (1) the instance wk-NNC is relatively more stable than the attribute wk-NNC when the dataset size is changed, (2) comparing the variance, the classifier performance is better when the fold number increase, just like on the datasets HEART and WINE, (3) if the dimension is greater than 100, the n-fold cross validation is failed, such as on the dataset HILL-VALLEY. Furthermore, this paper also gives a better insight into model selection on given set.",60032504,Shanghai University of Engineering Science,Shanghai,China,['1702'],28.142857142857142,0.15338345864661654,0.42255639097744363,0
661,661,Combining clustering and SVR for predicting passengers of regional airports on limited sample," All rights reserved.Due to lack of enough available sample of some regions (such as regional airports in Hainan province), it is difficult to establish a predictive model for the passenger amount of aviation transport using traditional statistical methods. After we analyze previous related works, we propose to combine hierarchical clustering and support vector regression (SVR) methods to obtain a predictive model. Firstly, we find the development level is similar to Hainan province (Guangxi province) using hierarchical cluster method. Secondly, we obtain the optimal SVR model (C=1024, g=0.0013811) by means of k-fold cross validation (k-CV) based on the sufficient samples of Guangxi province. After comparing the SVR model with the multiple linear regression prediction method, the result shows that has better prediction accuracy. Finally, the SVR model applied for predicting the passengers transported by regional airports from 2018 to 2020 in Hainan province, which could provide a decision-making reference and reliable theoretical basis for constructing of the regional airports in the future.",60032504,Shanghai University of Engineering Science,Shanghai,China,['1702'],27.0,0.030208333333333337,0.3859375,0
662,662,Principle component analysis study of coffee/tea nutrition," All rights reserved.The purpose of this project is to determine which Starbucks drinks (Frappuccino blended and Espressos) among all coffee and tea options are best for cardiovascular disease (CVD) prevention. A health index was constructed considering different coffee nutritions, including: saturated fat, cholesterol, sodium, carbohydrates, dietary fiber, sugars, protein, and caffeine. Antioxidant activity of flavonoids from Caffeine component can reduce free radical formation and scavenge free radicals. Principal Components Analysis (PCA) was used to explore all factors in the analysis and to inform on the utility of the health index in relation to its link to CVD prevention. Principle Component 1 is more relevant to unhealthy components such as sugars, carbohydrates, saturated fat, and total fat. Principle Component 2 is more related to Caffeine. Additionally, Dietary Fiber and Caffeine are most opposite against the other unhealthy components along the direction of the 1st Principle Component. PCA Eigen Analysis is very powerful to recognize coffee product types based on Nutrition patterns. In order to avoid variance factor in PCA analysis, original data has been Z-transformed. The new PCA-based Health Index was derived based on the eigenvalues and eigenvectors of the first two Principle Components. The new PCA-based Health Index was also compared to the Science-based Health Index (about 70%-80% R-Square Curve Fitting).",60012708,Stanford University,Palo Alto,United States,['1702'],19.272727272727273,0.21727272727272726,0.5627344877344878,0
663,663,Conceptual design for crowdsourcing biodiversity tagging application," All rights reserved.This paper presents the on-going work of MyDNAmark crowdsourcing biodiversity mobile application which enable the researchers and public alike to collaboratively record the species information and observation. The MyDNAmark application utilizes the Cordova API and various other APIs such as RESTful and Google Map to provide a means to display the collected species data, addition of new species data to server, get the geolocation of user, etc. A key feature is the offline capability which allows the user to save the species observation data locally when there are no Internet connection, and the local data is submitted to server once there are Internet connection. The capabilities of MyDNAmark is demonstrated through real end-user scenarios with the participation of fellow researchers working in the biological fields.",60021005,Universiti Teknologi Malaysia,Johor Bahru,Malaysia,['1702'],32.0,0.023484848484848483,0.35513468013468014,0
664,664,A novel framework for anomaly detection via feature selection and dimensionality reduction," All rights reserved.Anomaly detection of network traffic data is vital to the early warning of anomalous behaviors and the precaution of malicious intrusions. We consider a scenario, in which the network traffic data have large volumes and high dimensionality, and follow different patterns. To detect anomalies accurately and efficiently, a K-means and Bayesian inference based Conditional Random Fields (KBCRF) method is proposed here. Specifically, we first adopt a K-clustering method to categorize the network data into manifold classes so as to alleviate the interference from data with different patterns. Also, we propose a data reduction method via Bayesian inference to filter irrelevant data features, hence improving the performance of data training and anomaly detection. Then, we propose a Conditional Random Fields based method to determine the anomalies in the network data, upon the conditional probability of anomaly given the data distribution. For cyber security maintenance, KBCRF method provides more accurate and faster anomaly detection, compared with existing detection methods. The performance of the proposed method is evaluated by the ISCX 2012 dataset. Experimental results demonstrate the validation and efficiency of the proposed method in terms of precision, recall and F1-score.",60024350,National University of Defense Technology,Changsha,China,['1702'],21.22222222222222,0.05173469387755104,0.526326530612245,0
665,665,Genetic algorithm based optimization of deep neural network ensemble for personal identification with face and voice features," All rights reserved.Personal identification is a task of authenticating a person using individual biological features. Deep neural networks (DNNs) have demonstrated impressive performance in this field. It is well known, however, that no general algorithm is variable for every application problem. For a new application task, it is very time-consuming for non-experts to design adequately network structure, hyper parameters and an ensemble of base models effectively. In this paper, we present the genetic algorithm (GA) based approach in order to automatically construct network structures, tune their hyper parameters and generate base models for the ensemble algorithm. Then these base models with different network structures are performed to constitute an ensemble. Our original personal identification dataset is employed as the numerical example to illustrate the performance of the proposed method. Convergence property, experiment results, and performance analysis are discussed. The results indicate that several single base models provided by the proposal algorithm have strong classification ability by using the face and voice features and that an ensemble model which is constituted from these base models achieves better classification performance.",60000264,Nagoya University,Nagoya,Japan,['1702'],19.88888888888889,-0.024685631828488992,0.5850237064522779,0
666,666,Feature reduction based on modified dominance soft set," All rights reserved.Big data is a collection of larger volume of unstructured types of data such as images, videos and social media data. Recently, the applications of big data analytics in the field of medical image processing increased rapidly. Tumor detection and classification of leukemia cells are challenging tasks in medical image processing, as manual data analysis is time consuming and most often not accurate. In big data applications, the feature reduction has a prominent role in eliminating the irrelevant features and building a good learning model. Clustering based on Backtracking Search Optimization Algorithm (BSA) is used to segment the nucleus. Various types of features were used to address the segmented nucleus including shape, texture and colour based features. In this paper, a Modified Dominance Soft Set-based Feature Reduction Algorithm (MDSSA) is designed to select the most prominent features for the leukemia image classification. The results of MDSSA are tested using Analysis of Variance (ANOVA). In the feature extracted datasets, the MDSSA selected 17% of the features that showed more promising performance in comparison to existing feature reduction algorithms. The proposed method also reduces the computation time for further analysis of Big Data. The ANOVA results confirm that the efficiency of the proposed feature reduction method is better than other methods.",60015723,Prince Sultan University,Riyadh,Saudi Arabia,['1702'],19.272727272727273,0.15451388888888887,0.4614583333333333,0
667,667,A feature point matching algorithm based on space geometrical characteristics," All rights reserved.A kind of feature point matching algorithm based on the points feature and random sampling consensus is proposed. The describing function of feature points with simple structure is defined through simulating the Rank Order coding in the artificial neural network. A novel geometric model named the statistical deflection angle(SDA) is proposed to describe the points in the image. The SDA describes a feature point by combing with the local structure around the point and the global statistical information of all the points in the image. Then a point matching strategy improving random sample consensus is used to remove the outer points, the matching function with higher accuracy is obtained through iteration. It is proved by the experiment results that better effects in matching accuracy can be obtained by the method.",60089941,Nanyang Institute of Technology,Nanyang,China,['1702'],22.166666666666668,-0.10500000000000001,0.5157142857142857,0
668,668,Emotion recognition by convolutional neural network based on EEG-images plotting time series data," All rights reserved.One way to recognize human emotions is to use physiological signals. In particular, EEG is noticed because it is non-invasive and inexpensive. However, it is difficult to perform recognition with high accuracy because there are a number of problems such as EEG signals have a lot of noise. The high accuracy analysis of EEG is the subject of research by many researchers. In this paper, we propose converting EEG signals into images and performing emotion classification tasks using CNN. In the experiment, we use DEAP dataset, which is often used in emotion recognition tasks using EEG. The EEG signal is divided into short segments based on a predetermined time window and plotted in time series data format to generate images. About the data plotting method, the image is generated by the method of making 32 classes and the method of making 4 classes. The generated images are classified into each emotions using a convolutional neural network. The classification use two axes, arousal and valence. The best results differ by gender. Men are able to get the best results when the time window is 1.0 with a 4-class image. The accuracy at these results is 63.75% for arousal and 63.36% for valence. The time window is 1.5 seconds and arousal is 65.37% when women use 4-class images. On the other hand, valence is 59.96% in 1.5 seconds when using a 32-class image. Also, it is found that arousal tends to be higher for women and valence tends to be higher for men. The experimental results show that the proposed method outperforms some related work. The proposed method is not dependent on the dataset, so it can be applied to research using various data.",60011157,Iwate Prefectural University,Iwate District,Japan,['1702'],15.833333333333334,0.18305555555555555,0.44703703703703707,0
669,669,A conflict style large group dynamic emergency decision-making method based on time series," All rights reserved.Due to the dynamic, complex and unpredictable characteristics of unconventional emergencies, which greatly enhances the difficulty of emergency decision-making. A new decision-making method is proposed for the large-group dynamic emergency decision-making problem with unknown expert weight and stage weight which is related to time series. Firstly, we propose a distance formula considering the hesitancy degree of the interval-value intuitionistic fuzzy number and define the closeness of the interval-value intuitionistic fuzzy number. The preference information of experts in each stage is clustered by combining the closeness and similarity. Secondly, we propose a new formula to make up the shortcomings of the existing interval-value intuitionistic fuzzy entropy formulas. Considering the difference of knowledge level among experts and the nonhereditary characteristics of preference information in each stage, we use this formula to calculate the weight of experts under each attribute. Thirdly, considering the influence of time series on stage weights, we reasonably determine the aggregation weight and stage weight in order to reduce the conflict. Then we rank the alternatives according to comprehensive large group preference information. Finally, a case study verifies the validity and superiority of the proposed method.",60017060,Central South University,Changsha,China,['1702'],21.11111111111111,0.02314664502164502,0.4783955627705627,0
670,670,Applying machine learning and AI on self automated personalized online learning," All rights reserved.Machine Learning (ML) and Artificial Intelligence (AI) allowed researchers to view and analyze student's behaviors as never before. By monitoring them online, teachers can beforehand help students who need assistance. Many research papers revealed that there is a positive correlation between those students who exhibit good classroom behavior and academic achievement. RSU-AI-Monitoring System is an effective tool for behavioral improvement. RSU-AI-Monitoring System tracks many attributes on user activities' logs such as attendances, quiz marks, login and logout timestamps, IP addresses, names, etc. This research traces and directs students online to proper their behaviors. The experiment traced and tracked on two courses, which are THAI106 and ENG101. These subjects are the general education courses offering online. Student can access these subjects on an e-learning platform via mobile devices. Sample data were collected from 1,890 students in one semester. This paper discusses the data mining, ML and AI techniques to construct a new method enabling personalized learning. The experiment revealed a good progress on the overall student marks on their final examinations. 65 of 345 students were received the grade of B+ after participated in the tutoring program by AI Bot. 240 students who failed on the midterm examinations or received the low quiz scores, were able to pass their final examinations. The experiments revealed that 69.5% of the students had passed their final examinations and 18% obtained the B+ grades.",60023366,Rangsit University,Patum Thani,Thailand,['1702'],15.466666666666667,0.14808612440191388,0.5434210526315789,0
671,671,Stability of weak solutions of parabolic systems with distributed parameters on the graph," All rights reserved.The analysis of the behaviour of the evolutionary equation solution with unlimited time variable has been a subject of discussion in scientific circles for a long time. There are many practical reasons for this when the initial conditions of the equation are specified with a certain error: how the small changes in the initial conditions affect the behaviour of the solution for large values of the time. The paper uses the classical understanding of the stability of the solution of a differential equation or a system of equations that goes back to the works of A. M. Lyapunov: a solution is stable if it little changes under the small perturbations of the initial condition. In the work specified the stability conditions for the solution of an evolutionary parabolic system with distributed parameters on a graph describing the process of transfer of a continuous mass in a spatial network are indicated. The parabolic system is considered in the weak formulation: a weak solution of the system is a summable function that satisfies the integral form identity, which determines the variational formulation for the initial-boundary value problem. By going beyond the classical (smooth) solutions and addressing weak solutions of the problem the authors aim not only to describe more precisely the physical nature of the transfer processes (this takes on particular importance when studying the dynamics of multiphase media) but also to the path analysis processes in multidimensional network-like domains. The used approach is based on a priori estimates of the weak solution and the construction (the Fayedo-Galerkin method with a special basis - the system of eigenfunctions of the elliptic operator of a parabolic equation) of a weakly compact family of approximate solutions in the selected state space. The obtained results underlie the analysis of optimal control problems for differential systems with distributed parameters on a graph, which have interesting analogies with multiphase problems of multidimensional hydrodynamics.",60072688,Universidade Eduardo Mondlane,Maputo,Mozambique,['1700'],31.9,0.0026147959183673475,0.41449829931972787,0
672,672,Building ontology profiles with contextual elements for effective and efficient movies recommendation," All rights reserved.In coping with the increasing on-demand movies services provided through the Internet or Cloud platform, on-demand movies providers are competing intensively in providing more varieties and choices of programs. To retain and attract more users, service providers are moving towards recommending more personalized programs to satisfy users' needs and preferences. While the number of users and items are increasing, the effectiveness and efficiency of the recommendation become the main factors to address. This paper proposes to integrate ontological profiles with contextual elements based on hybrid recommendation approach. In this proposed system, namely HyOC-RS, ontological profile is incorporated with contextual elements to improve the recommendation mechanism. A semantically and hierarchically-linked data model represented the proposed ontological user profile. Performance of HyOC-RS is evaluated in terms of time and space complexity. HyOC-RS with small error measures has proven to be more efficient and accurate as compared to traditional recommendation systems. Additionally, experimental results have shown that HyOC-RS could resolve the problems inherent in many of the traditional content-based and collaborative filtering recommendation systems such as over specialization, data sparsity, new user, and new item problems.",60012005,Multimedia University,Malacca Town,Malaysia,['1702'],20.666666666666668,0.22781385281385283,0.5125541125541125,0
673,673,Possible architecture and some neuro-fuzzy algorithms of an intelligent control system for open pit mines transport facilities," All rights reserved.This article is focused on the organization of computational processes in the framework of the intelligent control system of transport and technological processes in the extraction of raw mineral materials in open pit mines. The main problems that researchers and developers face when building unmanned process control systems in quarries are listed. The architecture of the intelligent platform and features of functional tasks that are solved at various levels of the platform are considered. The main focus in on the issue of combined use of models belonging to two different classes: the deliberative type, represented by heuristic expert rules, and the computational type. The algorithm of the interaction of these models used for centralized intelligent control of mobile robots is described. The proposed approach, some obtained results and directions for further research are also discussed.",60068681,National University of Science &amp; Technology (MISIS),Moscow,Russian Federation,['1702'],23.0,0.25025641025641027,0.5928205128205128,0
674,674,The waveform generator and monitor based on FPGA&DSP for the pulsed power supply," All rights reserved.This paper presents a waveform generator and monitor based on FPGA &DSP. It is a high-speed data acquisition, digital processing and data communication system. It can edit the arbitrary waveforms by Matlab software conveniently, download the waveform online and display the waveform of the output pulse waveform from the pulsed power supply in real-time. It is not only a waveform generator but also a waveform monitor. It has been used for the pulsed power supply of China Spallation Neutron Source (CSNS) project successfully.",60027631,Institute of High Energy Physics Chinese Academy of Science,Beijing,China,['1702'],17.2,0.1625,0.6375,0
675,675,An efficient approach for selecting initial centroid and outlier detection of data clustering," All rights reserved.In recent years, vast amounts of unstructured data have been and are being produced from multiple sources around the world. In the field of data mining, clustering is the most efficient technique for grouping such unstructured or unsupervised data. In its basic form, data clustering is an unsupervised method that groups or cluster objects so that all objects within the same cluster are very similar to each other, whereas objects grouped similarly in the different clusters are quite distinct. However, due to the exponential growth of data amounts available in a wide variety of scientific fields, it has become increasingly difficult to manipulate and analyze such information. In addition, it is becoming progressively more cumbersome to extract hidden features from the resulting huge unstructured and unsupervised datasets. This study reports on an improved general k-means clustering algorithm that was created by modifying its initial centroid selection process and adding a new outlier detection and filtering algorithm. Under normal conditions, most algorithms select initial centroids randomly, which often leads to poor initial cluster quality. Additionally, most existing outlier detection techniques are inadequate due to their poor accuracy levels, high computational complexity, and inability to identify outlier data. In contrast, after an analysis of comprehensive experiments performed to validate our approach via comparisons against existing techniques and benchmark performance values, we found that our proposed approach performs better than existing methods in terms of initial centroid selection, outlier detection, and other related matters.",60031404,The University of Aizu,Aizuwakamatsu,Japan,['1702'],27.11111111111111,0.05209728867623604,0.43283891547049436,0
676,676,Multi-factor model optimization based on machine learning," All rights reserved.Based on Random Forest (RF) and Support Vector Machine (SVM) algorithm in machine learning theory, this paper studies the failure of the traditional multi-factor model for stock selection in China's stock market in 2017. The trading data of SSE (Shanghai Stock Exchange) 50 index stocks from 2016 to 2017 are taken as samples for training and cross-validation of the model. And Multidimensional comparisons are made. The traditional model is compared with the optimization model using machine learning algorithms, and different machine learning algorithms are also compared. The results show that the prediction accuracy of the models optimized by machine learning algorithms are significantly higher than that of the traditional model. Compared of two optimized models, the one based on Random Forest is better. Finally, a multi-factor model that can adapt to market changes is obtained.",60108842,Anhui University of Finance and Economics,Bengbu,China,['1702'],19.714285714285715,-0.056666666666666664,0.615,0
677,677,A research on solving multi-objective service selection problem based on service request flow," All rights reserved.With the rapid development of cloud computing, service computing and internet, the amount of service and service user both grow rapidly. A huge user requests to a service can form a request flow. How to select services for a composite service which is based on a request flow is an important problem. This paper firstly proposes a probability-based solution structure to solve the problem. Then an evaluation method of a solution is defined according to the solution structure. Lastly an improved artificial bee colony algorithm is applied to solve the selection of multiple composite service instances and their allocation probability at one time. Experiments show that this method can effectively guarantee the request flow constraints, and the speed of solution will not change greatly with the size of solution space. It is basically suitable for large-scale problem solving.",60031863,"Northeastern University, China",Shenyang,China,['1702'],17.625,0.2666666666666667,0.6222222222222222,0
678,678,Automatic demographic and personality extraction from anonymous social media," All rights reserved.This research proposes a feature extraction algorithm based on demographic and personality attributes on social media. The attributes including gender, age group, political affiliation, religion, and personality types are analyzed. Two feature sets are extracted for each user, including the comment text and community activity. Naïve Bayes and logistic regression classifier are performed to evaluate the attribute prediction. A dataset of comments from the Reddit website is obtained as a case study. Experimental results measured in term of F1 score are 88% in predicting user's political affiliation, 85% for gender, 57% for religion, 46% for personality type, and 42% for the age group. We found that the feature set obtained from user activity provides better performance in the user recognition task.",60021944,Kasetsart University,Bangkok,Thailand,['1702'],17.714285714285715,0.12666666666666665,0.2333333333333333,0
679,679,Applying a unified game-based model in a payment scheduling problem and design of experiments using MOEA framework," All rights reserved.This paper aims to put a new approach in the picture to the payment scheduling problem, which looks for a schedule that maximizes the benefit of all parties in a project. In a project, both sponsor and contractor seek to have a good payment strategy on their own. The timing of payments and the completion times of activities in projects are determined simultaneously in order to achieve an equitable schedule among the sponsor and the development team. In previous research, we developed a Unified Game-Based Model for conflicts in project management. In this paper, we applied this model to this problem, implemented in an open sourced evolutionary computation library named MOEA framework. The use of a Unified Game-Based Model enables us to figure out a suitable schedule for the problem, and in the tool, we conducted an experimental test of the model by the used of several multi-objective optimization algorithms. The experimental results demonstrated that the presented approach is effective and promising so that both parties could use this model to choose the proper tactics for each of them in scheduling payment.",60071396,Hanoi University,Hanoi,Viet Nam,['1702'],26.428571428571427,0.22459207459207461,0.4593240093240093,0
681,681,A stock decision model based on optimized neural network algorithm, All rights reserved.The stock comprehensive decision indexes are extracted by kernel principal component (KPC) analysis method. An effective stock decision model based on optimized neural network algorithm is presented. The weight and threshold value of the proposed BP neural network with KPC input and stock return output are adjusted and optimized by genetic algorithm. The empirical test results of CSI 300 stock sample show that the proposed stock decision model improves the operational efficiency and possesses strong learning ability with high prediction accuracy. This paper develops a bottom-up stock decision model to conduct data mining in stock returns and risks in order to select stock portfolio from individual companies with high quality.,60011235,Guangdong University of Foreign Studies,Guangzhou,China,['1702'],22.6,0.2422222222222222,0.5188888888888888,0
682,682,Quantitative assessments of haze research based on co-citation networks," All rights reserved.Haze has become one of the most concerning environmental problems recently. A number of cities all over the world have been suffering from severe haze pollution. An increasing number of scholars are dedicated to the research area of haze. Using scientometric and quantitative methods, this paper assesses the status quo and explores the evolution of haze research. The literature data from 1987 to 2017 is retrieved from the Web of Science. We establish co-citation networks and use visualization tools to reveal main research clusters. Based on our results, corresponding key elements, highly cited papers, the most influential and outstanding authors are determined. Furthermore, we note active authors, institutions, and countries in academic collaboration. Finally, we use burst detection to trace emerging hotspots and future directions of research. The results may be helpful in obtaining a general knowledge of the evolution of haze research and identifying future research directions.",60098512,Zhejiang University of Finance and Economics,Hangzhou,China,['1702'],15.1,0.1341025641025641,0.4883333333333333,0
683,683,A rapid hybrid method for powered reentry trajectory planning with uncertain no-fly zone constraints," All rights reserved.The reentry trajectory planning or optimization of a high lift-to-drag hypersonic gliding vehicle is a widely studied field. Current trajectory planning methods focus on very well-known tasks and in very well-known conditions. However, limited by maximal detection range of sensors or outdated intelligence, a key challenge is developing a fast real-time method that generating solutions for tasks in uncertain environments where traditional methods may not be available. This article seeks to combine the advantages of popular convex optimization and proposes trajectory stitching technique, to create a new approach that combines computational efficiency and optimal performance with uncertain no-fly zone constraints. Our approach first plans a baseline trajectory based on the initial guess by convex optimization. The optimized trajectory is then updated partially by an approximate algorithm once the change in the no-fly zone is detected. Furthermore, intermittent thrust is introduced to improve the maneuverability. Simulation result and the associated analysis demonstrate the potential benefit of this planning framework in reentry mission.",60013789,Beihang University,Beijing,China,['1702'],20.5,0.08289131920710868,0.5238983823194349,0
684,684,Internet user perception on data privacy protection: Big data analytics on twitter," All rights reserved.On May 25th, 2018, European Union has launched the regulation called General Data Protection Regulation (GDPR). The enforcement expands to Non-EU countries that lead to the global impact in 2018. All business and IT sectors need to review and change their system regarding the personal user data processing to respect user privacy's right. However, there is no study related to user's action or feedback regarding data privacy or data protection. This research aims to analyse user's behaviour and perception on personal data protection by using Twitter as a study platform. The population included in our study consists of 560,923 Internet users (61 nationalities), their engagement on Twitter are collect for 8 months starting from Jan 1st, 2018 to Aug 30th, 2018. We do data mining on social media to understand social perception or feedback on important issues. Information fusion from many enriched features of Twitter helps us to do societal analysis that is really useful for authorities or policy makers. We investigate various aspects and found many interesting discoveries regarding the user's perception on their privacy rights in different regions of the world. Sentiment analysis is performed on the Twitter's content to show how people in different regions feel about their rights. We visualize word clouds that represent the keyword in the text data from tweet messages to understand user's opinions. Moreover, we explore the use of Twitter's hashtags that reveal higher degree of conceptual on tweet message. User engagement is investigated in terms of Likes, Retweet and Reply. Many surprising results are obtained that help us to understand what happen around the world when the new paradigm of data privacy is shifted.",60021944,Kasetsart University,Bangkok,Thailand,['1702'],19.714285714285715,0.18646715603237346,0.3705910031996989,0
685,685,Prediction of high frequency trading financial data using stacked LSTMs for algorithmic trading," All rights reserved.This paper is focuses on the prediction of high frequency trading time series financial data using stacked LSTMs model for investment strategies in algorithmic trading. The goal is to give a deep learning (DL) approach that can be potentially beneficial to the complex investment strategies in algorithmic trading. This paper is not a complete investment strategy that generates a profit and loss curve (PNL). Rather, it shows how LSTM based deep neural networks can be applied to predict time series financial data. It can predict the asset prices or asset returns, and the generated predictions can be used to make certain decisions such as open a long position or close the short position.",60076695,NVIDIA,Santa Clara,United States,['1702'],23.2,-0.0019780219780219793,0.41626373626373625,0
686,686,Technique for annotation of fuzzy models: A semantic fuzzy mining approach," All rights reserved.The fuzzy models have shown to be ambiguous and characteristically primitive in nature when applied for data analysis problems in most settings. This is owing to the fact that with fuzzy models, it may not be practically possible to extract meaningful information about the underlying process elements when confronted with datasets that are unstructured in nature. To this end, the work in this paper demonstrates that it is possible to extract abstract knowledge and improve the information values of such type of models to a greater level by carefully integrating and tuning the semantics metrics that the fuzzy models lack. Theoretically, the work introduces a semantic fuzzy mining approach that is particularly focused on making use of the fuzzy logic and theories to represent the imprecise and uncertain (unstructured) data about the different domain processes, and then presents the resulting models in a format that allows one to analyse the available datasets based on concepts rather than the tags or labels in the events logs about the processes in question. In other words, this paper adopts the fuzzy logic which permits a proposal to be in another state as true or false, and in turn, evaluates the outcomes of the method using a series of case study experimentation and its comparison against the other benchmark algorithms used for process mining. The result shows that it is possible to determine through the classification process (e.g. using a classifier/reasoner) the presence of different patterns or traces that can be found within the discovered models, as well as the relationships the different process elements share amongst themselves within the knowledge-base. Ideally, the method is described as a fusion theory which integrates the fuzzy model with other tools or method, thus, supports a hybrid intelligent system.",60026116,University of East London,London,United Kingdom,['1702'],36.875,0.1543650793650794,0.6146825396825397,0
687,687,Quality measures collection and structuring for assessing and improving BPMN models," All rights reserved.Nowadays, Quality of business process (BP) models presents a huge interest to different disciplines of research. As a result, various standards have been suggested to determine, monitor, measure, assess and improve the BP models quality. In fact, to be efficient, a BP model should be reusable, easily maintainable and understandable. In order to assess a BP model quality, a set of measures has been presented in literature. In this context, this paper aims at defining quality measures, classifying them in criteria and implementing this latter by a prototype assisting to evaluate BP models quality named Business Process Models Quality Assess (BPMoQualAssess).",60058071,Université de Sousse,Sousse,Tunisia,['1702'],20.8,0.16666666666666669,0.5666666666666667,0
688,688,Convex programming for nonideal antenna array synthesis based on interval analysis," All rights reserved.Array mismatch which is caused by hardware and installation precision affects performance of antenna array significantly. Probability statistics is usually used to model array mismatch, so as to simulate array pattern. In this paper, the non-probabilistic interval analysis (IA) method is used to analyze the bounds of array pattern of uniform linear arrays in view of independent and simultaneous existence of amplitude and phase errors on array excitation. Based on the derived theoretical bounds of array pattern, array synthesis algorithm based on convex optimization is proposed. Compared with the algorithm using global random search, the proposed method can obtain better array excitation parameters with the same array mismatch. Computer simulation results verify the effectiveness and robustness of the proposed algorithm.",60005465,University of Electronic Science and Technology of China,Chengdu,China,['1702'],20.5,0.036111111111111115,0.3416666666666667,0
689,689,Iterative optimization of orbital dynamics based on model prediction," All rights reserved.Sliding door is an important part of commercial vehicle. Aiming at the problem of damage caused by the resonance of chuck and wheel in sliding guideway. The three-dimensional force and smoothness of sliding mechanism are studied. An improved guide rail system is designed in the grey model. In the non-linear optimization design [1], the trust domain multi-objective optimization algorithm is used to divide the model into a series of sub-regions. The model is solved iteratively in the trust region of the sub-region, and the design parameters satisfying the requirements of the smoothness of the guide rail are obtained. In ADAMS, the oblique vibration and force motion of components are simulated and analyzed when the track system is running normally. The results show that the force acting on each group of guide wheel mechanism can be effectively decomposed by using the multiwheel design with separated forces. The smoothness and reliability of the system are improved.",60024997,"University of Maryland, Baltimore County",Baltimore,United States,['1702'],17.444444444444443,0.2285714285714286,0.5071428571428571,0
690,690,Bridge apparent damage detection system based on deep learning," All rights reserved.We have proposed a novel scheme called Bridge Apparent Damage Detection System (BADDS) based on the network model of preliminary screening and fine recognition enabled by Faster Region Convolutional Neural Network (Faster R-CNN), which effectively improves the accuracy as well as reduces the omission factor. The average precision (AP) of honeycomb pitting, crack and salt out can reach up to 90.10%, 90.81% and 99.11%, which are increased by 23.89%, 21.04% and 35.43% respectively, compared with those of Faster R-CNN. On the other hand, the omission factor of them in BADDS are 6.26%, 3.72% and 12.17%, which are decreased by 10.81%, 9.94% and 11.27% respectively. The system performance is evaluated by Precision-Recall (P-R) curve.",60016930,Beijing University of Posts and Telecommunications,Beijing,China,['1702'],29.0,0.048958333333333326,0.41562499999999997,0
691,691,Forest management and environmental law enforcement policy against illegal logging in Indonesia,"Indonesia's forests have now been severely damaged. This condition is caused by various things such as illegal logging, encroachment, forest fires, and others. The root of the problem is the not yet realized good forest governance, so that it becomes a problem about how the current forest management policy? How to enforce environmental law on forest destruction due to illegal logging. The results of the study are firstly, in forest management through Law Number 41 of 1999 concerning Forestry and the provisions on eradicating forest destruction, can be re-established between the government and local communities, in order to place its function in the same view, the government bringing business actors can respect the system local people's lives and vice versa the community can understand the importance of development in the area and can improve the standard of living of the community; secondly, environmental law enforcement for forest destruction due to illegal logging through criminal law is a strict enforcement of the implementation of environmental laws and laws on prevention, eradication and destruction of forests that are oriented to the function of law as a means of carrying out social engineering, which includes the formulation of criminal acts, criminal liability, and sanctions.",123665179,Sahid University,South Jakarta,Indonesia,['1706'],50.25,-0.10350877192982456,0.3381578947368421,1
692,692,A method for designing the intelligent system in learning of algorithms," All rights reserved.The active learning methods bring enthusiasm for studying of students, especially in learning of algorithms and programming. Graphical and dynamic web based tools as visualization in learning these courses make more attractive to learners for spending much more their study time. In this paper, a method for designing an Intelligent system in learning of algorithms is proposed. This method proposes the model for representation the knowledge of an algorithm, called Algo-model. This model has the structure of tasks which are actions in the algorithm's processing. The proposed method also includes the processing to visualize the happen change in an algorithm's running. It will visualize on three contents synchronously: displaying the current state of the algorithm, results of data structures at this state, and visualizing this current state on the graphic environment. Based on the proposed method, an Intelligent learning system for Graph Theory at university has been constructed. This system meets requirements of an Intelligent system in learning of algorithms. It is useful for students to study and understand how the algorithm runs. It can interact to the student step-by-step based on the visualization of algorithms in learning tutors.",60110939,Ho Chi Minh City Open University,Ho Chi Minh City,Viet Nam,['1702'],17.454545454545453,0.33589743589743587,0.5897435897435899,0
693,693,Regret decision-making based on basic probability assignment function," All rights reserved.Decision theory based on regret has always been one of the hot spots of decision making. Recently, Yager proposed a new model that combines regret decision with D-S evidence theory for effective decision making. This model has certain rationality and foundation, But the state of nature is obeying the probability distribution rather than the basic probability assignment. Therefore, in this paper, an idea is present to reasonably transform BPA into a probability distribution, and then the expected value of regret is calculated for decision making. According to this idea, a new transferable belief model based on the proportional of elements in the BPA is proposed. A reasonable function is proposed to verify the rationality of the model by combining Deng entropy and evidence distance, and then used to calculate the expected value of regret. As a result, it has a certain guiding value for decision-making.",60005465,University of Electronic Science and Technology of China,Chengdu,China,['1702'],21.142857142857142,0.13471528471528466,0.4674575424575424,0
694,694,Sampled-Data Fuzzy Control With Guaranteed Cost for Nonlinear Parabolic PDE Systems via Static Output Feedback,"IEEEThis paper introduces a sampled-data static output feedback fuzzy control with guaranteed cost for nonlinear parabolic partial differential equation (PDE) systems. First, a Takagi-Sugeno (T-S) fuzzy parabolic PDE model is employed to represent the nonlinear PDE system. Second, with the aid of the T-S fuzzy PDE model, a sampled-data fuzzy control design with guaranteed cost under spatially averaged measurements is developed in the formulation of linear matrix inequalities (LMIs) by utilizing a time-dependent Lyapunov functional and inequality techniques, which can stabilize exponentially the PDE system while providing an optimized upper bound on the cost function. The membership functions of the proposed controller are determined by the measurement output and independent of the fuzzy PDE plant model. Finally, simulation results are presented to control the diffusion equation and the FitzHugh-Nagumo (FHN) equation for demonstrating the effectiveness of the proposed method.",60103801,University of Jinan,Jinan,China,"['1703', '1702']",27.8,0.09375,0.36979166666666663,1
695,695,A state of the art of digital twin and simulation supported by data mining in the healthcare sector," All rights reserved.Healthcare and more precisely private hospitals are critical and complex environments where making appropriate decisions is vital. For this reason, they are widely studied in many fields. This paper aims to provide the current state of the art of Digital Twin and/or Simulation involved in Decision Support System (DSS) whose data are processed through Data Mining techniques applied in the healthcare sector. In this view, the authors' research has been based on the following keywords: Healthcare, Hospital, Digital Twin, Simulation, Data Mining and Decision Support System. Doing so, it has been possible to gather 13 papers which have been carefully studied.",60025153,Università degli Studi di Genova,Genoa,Italy,['1702'],20.8,0.07857142857142856,0.45535714285714285,0
696,696,Experimental analysis of creep performance of rubber conveyor belt," All rights reserved.The finite element analysis method was used to simulate the creep performance of the rubber conveyor belt. In creep experiments and simulation experiments, the load applied to the rubber conveyor belt was 2000 N and 3000 N, and we record rubber changes every two hours. By comparing the results of creep test and simulation experiment, it is found that the rubber and creep experiments in the simulation are very close. Therefore, the correctness of the simulation is verified. At the same time, the research results have deepened the understanding of the creep properties of rubber, providing a reference for us to select and design rubber belts of suitable strength, and also ensure the efficient and safe operation of rubber conveyor belts.",112170010,Rizhao Polytechnic,Rizhao,China,['1702'],24.8,0.3125,0.41875,0
697,697,An analysis on performance of different type classifiers in handling big data sets," All rights reserved.Data analysis is one of the most important tasks in the decision making process. It helps decision maker to solve many problems such as classification and regression. However, wrong choice of method will produce inefficiency solution especially when dealing with big data sets. Besides, lack of information on data set characteristics also could make the analysis process more complicated and returned low analysis performance. Therefore, this study has conducted a few experimental works that evaluate six common algorithms in handling big data sets. A standard data analysis framework which consists of data initial process, data analysis and performance evaluation had been implemented. Results has shown that each algorithm has its own capability in handling different type of multi-variate big data sets. Naive Bayes is one of the algorithm that has successfully classified all selected data sets. Poker and Madelon required large space of memory during the analysis process. It can be concluded that, an information on data set characteristics and the capability of assigned data analysis method are important to be specified before any decision can be made.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,['1702'],18.1,0.09409937888198758,0.5425465838509316,0
698,698,Loss function optimization based on adversarial networks," All rights reserved.Autoencoder networks have been successfully applied to dimensionality reduction and information retrieval tasks. Lower-dimensional representations can improve performance on many tasks, such as image compression, reconstruction and clustering. The Mean Square Error (MSE) is commonly used as a loss function for autoencoder networks. The loss function suffers from performance degradation because it lacks the component distribution information of the input image. In the deep learning literature, recent works have shown the benefits of using adversarial-based losses to improve the performance on various image reconstruction and clustering tasks. This paper proposes a new algorithm which is called GAN-WMSE to generate weights for the MSE based on adversarial networks. With the distribution information integrated into the loss function, the autoencoder network and the adversarial weight network are jointly trained. Experiments on different image datasets show that the improved autoencoder networks employing our loss function can increase performance by 9.8% for PSNR, 10.3% for SSIM in image reconstruction, and 6.2% for image clustering.",60104000,ShenZhen Institute of Information Technology,Shenzhen,China,['1702'],20.375,0.01580578512396694,0.5492768595041322,0
699,699,Semantic data mining based on ranking in internet-enabled information systems1," All rights reserved.Collaborative work environments are a particular case of Internet-enabled information systems where the role of data mining is essential in creating digital support for people working together. The support is in the form of smart services to access to up-to-date information and evaluate its relevance. In this paper, we present an adaptive strategy of active control information updates for use in dynamic collaborative activity. We show applicable ranking methods of semantic data mining for selecting relevant information in collaborative activity.",60031202,Petrozavodsk State University,Petrozavodsk,Russian Federation,['1702'],20.75,0.08095238095238096,0.3678571428571428,0
700,700,Study on asymmetric deflection control scheme of SDR for flying wing aircraft," All rights reserved.Compared with conventional configuration aircraft, tailless flying wing configuration aircraft has a longer wing span than chord length. Aircraft with such aerodynamic characteristic has a shorter pitch arm and its pitch trim ability is insufficient when climbing at low speed and high angle of attack. Therefore, further exploring the aerodynamic efficiency of aircraft control surface and improving the pitch trim ability become a problem to be studied. The flying wing aircraft mostly adopts the split resistance rudder (SDR) symmetrical deflection to realize the stable control of the aircraft course; such an approach is simple and effective, but it reduces the control efficiency of the surface. So we want to explore the SDR asymmetric deflection control scheme to enhance the pitch control capability of the aircraft. In this paper, the dynamic modeling of SDR asymmetric deflection is studied and the mathematical model of over-drive system is established. The control effectiveness of SDR asymmetric deflection and symmetric deflection is compared by solving its attainable moment subset. The simulation results show that: Compared with symmetrical deflection, the pitch moment of asymmetric deflection control scheme increased by 47.5%. It can achieve greater pitch trim ability and control ability.",60003977,Northwestern Polytechnical University,Xi'an,China,['1702'],21.88888888888889,0.11926739926739928,0.42212454212454215,0
701,701,Celebrity influence on traditional festival analysis based on social network data mining," All rights reserved.Economic globalization has promoted the diversification of culture. With the development of Internet technology, people are increasingly exposed to different types of cultural forms. However, we can not deny the fact that especially in recent years, people have largely neglected the study of traditional culture in our country and more advocated foreign culture, which also caused the rapid sense of loss of traditional culture. In order to let the public inherit the traditional culture better, this paper aims to study whether the celebrities can play an important role in the inheritance and development of the traditional culture. Considering the domestic star-chasing craze, firstly we explore the star's festival influence from the perspective of the star's Sina Weibo influence. Then, by mining the micro-blogs related to the stars, we use the Naive Bayes classifier and natural language processing technology to calculate the emotional value of the micro-blogs and discover the importance of celebrity effect in traditional festivals by studying the positive sentiment ratio of the relevant micro-blogs. This research also has great reference significance in the practice of promoting traditional culture in the future.",60031863,"Northeastern University, China",Shenyang,China,['1702'],26.571428571428573,0.12266233766233768,0.540961038961039,0
702,702,Classification-based data mining applied in vehicle accident prediction," All rights reserved.į The purpose of the exploratory research is to employ a classification-based data mining technique to develop a vehicle accident prediction model. Data from 2014 to 2016 was collected from the open government data of Taoyuan municipality, Taiwan, that contains five categories as the potential determinants of vehicle accident, namely temporal, environmental, human (drivers), vehicle, and miscellaneous. Each category contains various variables. The class has 11 values (e.g., head, neck, leg (foot), multiple wounds). The mining mechanism used was ID3 which is a classification-based technique. The dataset used contains 92,558 cases. Steps were conducted including data preparation, mining mechanism implementation, and validation. The results reveal that variables in human category holds the highest classification power and the environmental ones reveals the lowest. The overall prediction accuracy is 73.05%. The total number of rule discovered is 10226, of which 4088 are reliable that the conflict rate is no less than 0.5. Findings and discussions are also addressed.",60028103,National University of Kaohsiung,Kaohsiung,Taiwan,['1702'],14.454545454545455,0.009259259259259259,0.33518518518518525,0
703,703,A smart weighted-louvain algorithm for community detection in large-scale networks," All rights reserved.This paper proposes a complex network community partitioning (Weighted-Louvain algorithm澿 WL) algorithm based on edge weights for serious skewed network data. This algorithm can discover the strong relational community in the weak relational network, thus mining the implicit user relationship in the network. The comparison between the experimental results of WL algorithm and Louvain algorithm on different datasets shows that the WL algorithm can find small-scale community structure in the network, and obtain higher resolution as well as higher operational efficiency, which is capable of mining real user relationships implied in the social networks.",60118699,Software College of Northeastern University,Shenyang,China,['1702'],32.33333333333333,0.04166666666666667,0.47196969696969693,0
704,704,Driving smart content as context for system level model of engineering structure," All rights reserved.Systems operated complex engineering structure (ES) constituting smart industrial or commercial product, prototype, or experimental configuration requires new way in model-based engineering. New style of engineering model system (EMS) is developed and applied in the course of continuous engineering to achieve system level, generic, and contextual model object structure which is in possession of self-modification capability to change itself for changed inside and outside context. Comprehensive software platform provides modeling capabilities during the whole innovation and life cycle of ES in industries engaged with smart products and production. Introducing work in engineering modeling for smart ES this paper focuses on the problem of multiple context driving of model object. The purpose of the reported work is to develop concept and methodology in intellectual driving structure for objects included in EMS and in cyber units of cyber physical systems. Paper starts with a scenario of multiple outside and inside context driving of object parameters and an outline of multiple context driven EMS. Following this, general process for managing contextual object structure of EMS which represents an ES is introduced. Main contributions in this paper are structured model of driving smart content (DSC) to drive objects in EMS and development of DSC as extension for EMS considering appropriate engineering platform. Finally, role of DSC and issues at its implementation are concluded considering the 3DEXPERIENCE platform by the company Dassault Systémes as cloud-based laboratory background at the Laboratory of Intelligent Engineering Systems, Óbuda University.",60113209,Obuda University,Budapest,Hungary,['1702'],27.11111111111111,0.12186147186147185,0.3582683982683983,0
705,705,Discussion on the application of virtual experiment technology in experimental teaching in university," All rights reserved.Experimental teaching is an indispensable teaching link in college teaching activities, which is conducive to training students' practical innovation ability. Traditional experimental teaching trains and improves students' practical ability through fixed experimental and physical experimental teaching methods. It is difficult for students to further improve their ability to apply theoretical knowledge to solve practical problems. Moreover, physical experimental teaching is easily restricted by the number and variety of equipment. With the intervention of the Internet, experimental teaching can be widely realized and promoted. Through real-time simulation of virtual simulation experiments, students can participate in experiments, mobilize students' enthusiasm, and solve the problems of lack of experimental equipment and funds. Therefore, as a new teaching method, virtual simulation experiment teaching is widely used in engineering experiment teaching in colleges and universities, providing an impetus for the improvement of experimental teaching efficiency.",60019616,Harbin Institute of Technology,Harbin,China,['1702'],20.428571428571427,0.05629984051036682,0.4538733196627934,0
706,706,Application of clustering in modeling user preference for leisure," All rights reserved.Multiple commercial systems focus on recommending suitable leisure activities to their users, yet little academic research has explored how to describe and model user preference for leisure. This paper investigates dimension-based and clustering-based approaches to modeling such preference. We rated a set of 135 leisure activities on 17 leisure dimensions in a user study, and relied on these dimensions as feature vectors to cluster the 135 leisure activities using k-means and its fuzzy variant. Another user study collected user preference for the 135 activities to be used as the ground truth. The 17 dimension and resulting clusters were then tested as descriptors of user preference in a series of linear regressions. We expected that the user would tend to like or dislike all activities in a hard cluster, since such activities would be similar to each other, and the user would like them to a similar extent. We further expected that a partial membership in a fuzzy cluster would correlate with the user preference for an activity if the user liked or disliked the underlying cluster. The results suggested that clustering could indeed be used to describe leisure preference. Hard clustering appeared to be more effective than fuzzy clustering, but both of them could be combined for an even more effective approach to preference modeling than using them separately. Finally, clustering could be combined with the four most effective of the 17 leisure dimensions to account for 27% of variance in the user preference for leisure. Such result suggests that a combination of leisure dimensions and cluster membership can be used as leisure activity features, which may be suitable for and useful in content-based and hybrid leisure recommendation systems.",60015986,Università degli Studi di Trento,Trento,Italy,['1702'],25.636363636363637,0.14459876543209876,0.5058641975308643,0
707,707,Hate crime on twitter: Aspect-based sentiment analysis approach," All rights reserved.Online media are well-known to be suitable for conveying hate speech. Hateful wording as such involves communications that unlawfully demean any group or person based on certain characteristics, including colour, race, gender, ethnicity, sexual orientation, religion, or nationality. The continuing rise of internet social platforms, including micro blogging services like Twitter, has compelled the need for more immediate analyses of hatreds and other antagonistic responses to various trigger events. This study aims to investigate the details using aspect-based inspections of sentiments. Content analysis of such tweets along with the associations between them is key. Nevertheless, due to the large data volumes involved, it can oftentimes be burdensome if not infeasible to conduct these types of analyses manually. The main problems of prior methods involve data sparsity, classification accuracy, and sarcastic content identification. for the techniques incorrectly categorise tweets as neutral. For content analysis, three dissimilar schemes were suggested, with all proposing to surmount the above-mentioned problems. The research results show that the proposed strategy has achieved correspondingly increased accuracies of some 75%, 71.43%, and 92.86%.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,['1702'],17.8,0.07678571428571429,0.5270833333333333,0
708,708,Clustering botnet behavior using K-means with uncertain data," All rights reserved.Botnets are the most deadly threat in the network due to the capability of exploiting resources within a network as an army to launch huge attacks such as Denial-Distributed-of-Service (DDOS) or spam emails. Network Intrusion Detection System (NIDS) that designed based on the behavior of botnets in network traffic is seen as the promising technique in detecting botnets that are hiding by using encryption technique or any hiding techniques. This paper proposes on K-means clustering algorithm as the first phase of botnet's behaviour detection model that extracts data from network traffic. The criterion highlighted for our behaviour detection model is that it should be able to detect botnet in encrypted packets(hiding techniques), structure-independent (centralized and peer-to-peer), requiring minimal computing resources and minimal time processing. Other than that, by representing the real-time of network traffics, the detection model also must be resistant to noise and able to identify the anomaly of botnets behavior among a huge number of normal traffic. We are using the botnet benchmark dataset and normal traffic from Malware Capture Facility Project and comparing our proposed method using K-means algorithm with Expectation Maximization algorithm that proposed by the previous researcher in clustering the similar pattern of botnet behavior. The result shows that the K-means algorithm producing much higher accuracy, 94% and lower false negative rate, 0.1413. While, average accuracy for Expectation Maximization algorithm is 88% and False Negative Rate, 0.2245 with the insertion of uncertain data from real network traffic.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,['1702'],30.625,0.04722222222222222,0.5125000000000001,0
709,709,A fast-settling fractional-N PLL with presetting frequency and dynamic bandwidth control," All rights reserved.A fast-settling dual-path fractional-N phase-locked loop(PLL) is presented in this paper, which is applied for frequent current charging and discharging. Compared with the conventional phase-locked loop, this one is significantly able to reduce the settling time with hybrid approaches. By employing direct presetting frequency, based on frequency-locked loop(FLL), the process locking is accelerated. To achieve low phase noise, 20-bits delta-sigma modulator is employed in PLL. Dynamic bandwidth is beneficial for both of them and results a smooth transition. Besides, the dual-path fractional-N PLL compensates the nonlinearity from the charge pump (CP), and provides a wider tuning range. Using the 0.6V supply voltage for 65nm CMOS, a 900MHz fractional-N PLL with mixed techniques exhibits less than 2.5μs transient settling time according the simulation results.",60016835,Beijing Institute of Technology,Beijing,China,['1702'],18.0,0.07904761904761906,0.33654761904761904,0
710,710,Improve-center:A deep learning face representation approach," All rights reserved.Convolutional neural networks have been widely used in object recognition, an important aspect of computer vision. The particular task of face recognition usually combines a softmax-loss function with some other loss function as the cost function in the training phase. In order to enhance the power of feature representation and speed up the training phase, this paper proposes a new supervised method called Improve-Center which is based on feature centers, the same as center-loss. It learns a center vector of features for every label and takes the feature of every sample closest to its center. This approach focuses on moving outer-space features closer to their center. The experimentation demonstrates that the approach is efficient. With softmax-loss and Improve-Center's joint supervision, a better model can be trained to make intra-class features more compact, and inter-class ones more discrete. In addition, the training process is faster.",60016521,Sichuan University,Chengdu,China,['1702'],18.375,0.10984848484848485,0.3644522144522145,0
711,711,Simplified DST matrix-based RD cost estimation model and hardware architecture in video coding," All rights reserved.Rate distortion optimization (RDO) is an important approach for ensuring the coding efficiency of the encoder by selecting the optimal combination of multiple candidate coding parameters in video coding. Discrete sine transform (DST) has high accuracy but causes high complexity in RDO, whereas Hadamard transform is simple but unsuitable for estimating the transform coefficients of DST in RDO. In this study, we initially proposed a new simplified DST transformation matrix to estimate the rate distortion (RD) cost accurately for intra prediction and then analyzed the decorrelated performance and complexity. Moreover, we designed a high-throughput hardware architecture based on the FPGA platform. Experimental results show that in comparison with the high efficiency video coding reference software HM16.7, the proposed simplified DST matrix-based RD cost estimation model improves the RD performance. Moreover, the proposed architecture achieves higher throughput with pipeline structure compared with the existing hardware structures. The implementation in Altera's Arria 10 FPGA can operate at 275 MHz and supports real-time processing of 4096×2160 ultra-high-definition at a minimum of 75 fps.",60017605,Fuzhou University,Fuzhou,China,['1702'],24.714285714285715,0.16057851239669424,0.45136560409287685,0
712,712,Lyapunov's first method: Estimates of characteristic numbers of functional matrices," All rights reserved.This paper contains the development of theoretical fundamentals of the first method of Lyapunov. We analyze the relations between characteristic numbers of functional matrices, their rows, and columns. We consider Lyapunov's results obtained to evaluate and calculate characteristic numbers for products of scalar functions and prove a theorem on the generalization of these results to the products of matrices. This theorem states necessary and sufficient conditions for the existence of rigorous estimates for characteristic numbers of matrix products. Also, we prove a theorem that establishes a relationship between the characteristic number of a square non-singular matrix and the characteristic number of its inverse matrix, and the determinant. The stated relations and properties of the characteristic numbers of square matrices we reformulate in terms of the Lyapunov exponents. Examples of matrices illustrate the proved theorems.",60031888,Saint Petersburg State University,Saint Petersburg (ex Leningrad),Russian Federation,['1700'],19.571428571428573,-0.016666666666666663,0.4703703703703704,0
713,713,Interval type-2 fuzzy control using distending function," All rights reserved.In this paper, we present a novel interval type-2 fuzzy controller. Its unique features are: 1) A new interval type-2 membership function called type-2 Distending Function (T2DF) is used. It can represent and handle different types of uncertainties using a few parameters; 2) The proposed control design is based on fuzzy arithmetic operations. As compared to existing methods there is no type reduction step; 3) The expressions used are in closed form which makes it suitable for on-line implementation; 4) The proposed design is simple, intuitive, computationally fast and handles uncertainties. The effectiveness of the proposed design is shown by an altitude control of a quadcopter.",60027332,Szegedi Tudományegyetem (SZTE),Szeged,Hungary,['1702'],21.8,0.10681818181818183,0.44018759018759024,0
714,714,Multi-obstacle tracking algorithm based on depth image of LiDAR," All rights reserved.An object recognizing and tracking method based on depth images of 3D Lidar is presented for perceiving dynamic surroundings in this paper. Based on the design principle of 3D Lidar sensor, the Lidar data is projected into 2D depth images and height images. The algorithm divides the depth image into different clusters by edge detection, and then extracts the spatial features. Then the obstacles can be associated to their history by feature comparing. At last, a Kalman filter is used to calculate the obstacles' velocity and predict the future location of obstacles, which can make a more accurate result for next loop. The proposed algorithm is tested on the self-developed mobile robot platform, ""Qilin-II"". As results, multiple obstacles within 20 meters have been recognized, tracked and re-matched successfully at the rate of 95 milliseconds per frame.",60102087,Yangtze Normal University,Chongqing,China,['1702'],19.857142857142858,0.11153846153846153,0.233974358974359,0
715,715,A novel secondary user selection-based cooperative spectrum sensing scheme for cognitive radio networks," All rights reserved.A novel secondary user selection-based cooperative spectrum sensing scheme for cognitive radio networks is rendered in this paper. It is demonstrated to be more energy-efficient, resource-efficient, and cost-saving. Firstly, we introduce the principle of the conventional cooperative spectrum sensing scheme. Also, the challenges that still exist in the conventional scheme are listed, i.e. high hardware requirement and cost, extra energy consumption, resource-consuming and vulnerable to environmental properties. Then we illustrate the proposed novel cooperative spectrum sensing scheme can address these problems by allocating part of cooperative Secondary Users who are under excellent detection condition to specialize in spectrum sensing in active and passive modes and releasing the others from the burdensome task of spectrum sensing. Finally, the issues related to the proposed scheme are explored.",60005465,University of Electronic Science and Technology of China,Chengdu,China,['1702'],18.285714285714285,0.030073260073260073,0.4836630036630037,0
716,716,Triangulating the implementation of hierarchical agglomerative clustering on MAR-learning usability data," All rights reserved.This paper presents fractions of research outcome from a bigger project involving machine learning, Hierarchical Agglomerative Clustering (HAC) Algorithms on usability data gathered through performance and self-reported data. This paper highlights the common problems in usability studies where the conventional analysis was frequently utilized while prioritizing usability issues. The utilization of clustering techniques is limited in the area of this study. A previous publication has shown how HAC was used in clustering usability problems in Mobile Augmented Reality (MAR) learning applications. However, there has not been a triangulation effort to confirm the first gathered results due to small datasets. This research presents a methodology adopted from previous studies in confirming earlier usability analysis results. The experiments found consistent evidence approving the feasibility of HAC in clustering and prioritizing Usability performance and self-reported data.",60021005,Universiti Teknologi Malaysia,Johor Bahru,Malaysia,['1702'],19.428571428571427,-0.051884920634920624,0.3326388888888889,0
717,717,Evolutionary approach for model compression of neural network using support vector machine with AND/OR layers," All rights reserved.Recently, deep learning has been studied as one of the most effective methods in the machine learning field, and lots of results have been reported. However, the most effective way to construct neural networks has not yet been determined. Besides, interpretation of an obtained network is difficult. In a previous study, we proposed a novel method to construct a neural network using a support vector machine called SVM-NN. However, there is also a problem in that, for hard to apply to a nonlinear problem and model size problem. In this study, we first propose a new network structure called AND/OR layers to solve the nonlinear problem of SVM-NN. AND/OR layers improve the effectiveness of identification by grouping support vectors based on training data results. This type of novel SVM-NN is called SVM-NN(AND/OR). We also utilize the genetic algorithm to pair and reduce support vectors to compress the model size of SVM-NN and SVM-NN(AND/OR). To confirm the effectiveness of the proposed methods, the computational experiments were carried out taking typical benchmark problems as exam-ples. The effectiveness of the proposed method is confirmed by computer simulations.",60008107,Osaka Prefecture University,Sakai,Japan,['1702'],17.0,0.15511363636363637,0.5830176767676768,0
718,718,Consideration of some aspects of designing with the digital to analogue converter," All rights reserved.Digital to Analogue Converters (DACs) connect the digital and analogue world and have thus become important elements in electronic systems. Efficient implementation, high speed and high resolution require the DAC design architecture of choice to be the binary weighted. Therefore, the paper introduces a model to speed up the design and reflect accurately on the behavior of the system prior to component level development and implementation. Furthermore, some of the aspects of designing with binary weighted DAC architecture data devices are considered. The study also covers behavioral modelling of the binary weighted DAC device from an ideal function to reality. The DAC model in this paper yields static characteristics as follows: Gain error of 1 LSB; K of 1.6; Offset voltage of 97 uV; Integral Non-Linearity (INL) error of -3.94E-02 LSB minimum and 5.00E-01 LSB maximum; Differential Non-Linearity error of -3.92E-02 LSB minimum and 2.06E-01 LSB maximum; Step height of 9.61E-01 LSB minimum and 1.21E00 LSB maximum. The DAC model yields fair and practical results as the INL errors are less than or equal to 0.5 LSB; the DNL errors are less than or equal to 2.06E-01 LSB. Additionally, the above errors show that the model yields a design with monotonic behaviour. Moreover, the DAC SFDR analysis shows that there are little variations in the SFDR values across the Nyquist band for the model. However, when frequency goes beyond 100 MHz, there is a degradation in the SFDR values.",60011653,"Central University of Technology, Free State",Bloemfontein,South Africa,['1702'],24.2,0.17994444444444443,0.4497777777777777,0
719,719,Comparison on two methods for ground target bearing estimation based on the theory of acoustic vector sensor," All rights reserved.Acoustic passive orientation is the most commonly used acoustic monitoring technology. The information of sound pressure, particle velocity and sound intensity of the sound wave radiated from the ground target were made full use in the method of passive bearing estimation based on the theory of acoustic vector sensor. Target direction finding can be achieved by acquiring particle velocity information or sound intensity information. In the paper, a comparative research was made on the direction finding method based on particle velocity and the method based on sound intensity. The specific algorithms of the two methods were given, and experimental research was carried out. The results show that when the sensor size is 0.3 m, the accuracy of sound intensity direction finding method combined use of sound pressure information and particle velocity information is better than that only use particle velocity information. Under the same conditions, sound intensity direction estimation method could significantly improve the accuracy of target direction estimation.",60112572,Xijing University,Xi'an,China,['1702'],23.142857142857142,0.2779411764705882,0.4573529411764707,0
720,720,Text classification of E-commerce product via Hidden Markov model," All rights reserved.E-Commerce is one of business mediums to offer a variety of choices to consumers. The explosion of data and information lead to the use of machine learning models to predict and customize the product categorization from online stores. This paper presents a study to assess the performance of Hidden Markov Model (HMM) in classifying e-commerce products. There are two parameter estimation approaches used in evaluating the HMM which are Baum-Welch and Viterbi Training algorithms. The results show that Baum-Welch algorithm performed better than Viterbi Training algorithm in estimating parameters of HMM. Hence, the former algorithm provides a better parameter estimation for the HMM in the study.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1702'],18.166666666666668,0.20833333333333334,0.3333333333333333,0
721,721,An outlier detection algorithm based on differential privacy," All rights reserved.Aiming at the problem that personal privacy is vulnerable to damage during outlier detection, this paper proposes an outlier detection method based on differential privacy. The algorithm uses the minimum spanning tree path to characterize the dissimilarity of the data, adds Laplace noise to the weight of the edge of the minimum spanning tree(MST),effectively resists background knowledge attacks. At the same time, combining the degree of dissimilarity and reverse k-similar number, a new anomaly judgment method is proposed, it improves the outlier detection rate. The experimental analysis shows that the algorithm can effectively protect the sensitive attributes of the data, improve the true positive rate(TPR) of outlier detection and reduce the false positive rate(FPR).",60008919,Guilin University of Electronic Technology,Guilin,China,['1702'],29.25,0.0764462809917355,0.5291322314049587,0
722,722,An on-line self-routing scheme for bio-inspired self-repairing hardware," All rights reserved.The bio-inspired self-repairing hardware is an array of electronic cells with identical structure, and communication connections are established between the cells through routing operations to achieve specific functions. When a working cell fails, the faulty cell can be replaced by the spare cell in the array and rerouted to restore the array's function. Most of the current self-repairing schemes require the assistance of external hardware and software, depend heavily on the placement of the array, have poor flexibility, and cannot effectively utilize spare cells. Therefore, this paper proposes an on-line self-routing algorithm with better comprehensive performance. The algorithm first removes the faulty cell and wires connected with the faulty cell from the fault net, and then comprehensively considers the congestion and timing performance of the circuit to find an optimal routing path from the target node to the fault wire net.",60024350,National University of Defense Technology,Changsha,China,['1702'],28.8,0.06249999999999999,0.34652777777777777,0
723,723,RANDS: A machine learning-based anti-ransomware tool for windows platforms," All rights reserved.Zero-day ransomware still threaten users' and enterprises' survival in the cyberspace by disturbing electronic amenities, damaging information systems, and causing data and money losses. Established anti-ransomware techniques are trying to mitigate this security issue, however they are lacking to identify ransomware families effectively without real-time performance overhead. Thus, this paper provides a multi-tier anti-ransomware tool (RANDS) performs via windows platform through three tiers: ransomware analysis tier, learning tier and detection tier. RANDS hybridizes the decisive functions of two machine learning algorithms (Naïve Bays and Decision Tree) to holistically analyze ransomware traits, and accurately classify ransomware families. The prototype implementation of RANDS shows its classification capability against ransomwares with (96.27%) as average accuracy rate and (1.32%) of average mistake rate throughout real-time assessment.",60090601,"Universiti Teknologi Malaysia, Kuala Lumpur",Kuala Lumpur,Malaysia,['1702'],25.0,0.039999999999999994,0.6066666666666667,0
724,724,"Sasaki-einstein 7-manifolds, orlik polynomials and homology","In this article, we give ten examples of 2-connected seven dimensional Sasaki-Einstein manifolds for which the third homology group is completely determined. Using the Boyer-Galicki construction of links over particular Kähler-Einstein orbifolds, we apply a valid case of Orlik's conjecture to the links so that one is able to explicitly determine the entire third integral homology group. We give ten such new examples, all of which have the third Betti number satisfy 10 ≤ b3(Lf ) ≤ 20.",60002817,Swarthmore College,Swarthmore,United States,['1701'],26.0,0.08209366391184572,0.2670798898071625,1
725,725,Spatial colocation pattern mining with the maximum membership threshold," All rights reserved.Spatial colocation pattern mining discovers the subsets of spatial features frequently observed together in nearby geographic space. The existing colocation pattern mining approaches ignore the proximity level between the instances by a user-specified distance threshold, and return a prevalent colocation pattern set under the single distance threshold. And in many cases, people may want to know the distance range in which a colocation pattern is prevalent instead of a single distance threshold. In this paper, fuzzy neighbor relationship (FNR) is introduced to measure the proximity level between instances by fuzzy set theory. We propose the algorithm for prevalent colocation pattern mining at a single membership threshold (PCP-SMT), and develop the basic algorithm for prevalent colocation pattern mining with the maximum membership threshold (PCP-MMT). Furthermore, an improved strategy is adopted for the PCP-MMT algorithm. The effectiveness and efficiency of the proposed algorithms and the optimization technique are evaluated with an extensive set of experiments.",60028009,Yunnan University,Kunming,China,['1702'],22.285714285714285,0.05510204081632654,0.2715986394557823,0
726,726,Idea development from consumers' complaint messages using data mining," All rights reserved.澢 This paper aims to conduct an exploratory research that proposes an idea generation model, named IGMCC, to develop innovative ideas from consumers' complaint messages. The model utilizes text mining and classification techniques to derive outputs. Data was collected from 2018/11/1 to 2019/4/30 in the domain of mobile phone from an online forum of a company in Taiwan. The collected dataset contained valid 2406 message records related to consumers' complaints about the products and services. The sparse terms were removed and produced term matrix with occurrence frequency was discretized to be used by the classification-oriented data mining algorithm. The results showed that 33 classification rules were obtained and the prediction accuracy is 77.1%. Discussion and implications are addressed.",60025585,Kun Shan University,Yung Kung,Taiwan,['1702'],17.285714285714285,0.06666666666666667,0.5333333333333333,0
727,727,PPSNN: Prediction of protein structure with neural network," All rights reserved.Protein structural can be regarded as one of the most significant elements in protein function. In this work, the amino acid residues' frequency featuring set and the EH description method have been employed as the classification features. And then, support vector machine and neural network have been employed as the classifier in this work. In these employed features, some novel features have the ability to making differences between α/β type and α+β one. In order to show the performance of the proposed method, the three employed benchmark datasets are utilized to train and test the proposed approach. The results demonstrated that some performances of the proposed method are better than existing method ones, especially in α/β and α+β types classification.",60104152,Zaozhuang University,Zaozhuang,China,['1702'],20.5,0.34375,0.71875,0
728,728,Speed up the process of reinforcement learning for robot grasping," All rights reserved.Robot has been widely used in a variety of fields, including grasping, transportation, welding. It is very precise and accurate. Grasping is the fundamental ability of the robot, which can determine the automatic level of the robot or the industry. Nowadays, the intelligent robot has become a very popular research field. This paper proposes the method of combining reinforcement learning and transfer learning, by training only once, and then slightly adjusting the neural network trained under similar environment or similar tasks, such as changing the number of layers or changing the action dimension, and then transferring to the new environment or tasks, so as to reduce the training time and improve efficiency.",60108756,Hubei University of Technology,Wuhan,China,['1702'],23.0,0.20580808080808086,0.5795454545454546,0
729,729,"Social community, personal involvement and psychological processes: A study of impulse buying in the online shopping carnival","The pomp of online shopping carnivals (OSC) and herein the frenzy of impulse buying (IB) have been extensively reported in media but received insufficient attention in academics. This study researched both the IB formation and enactment stages in ""Double 11"" OSC by conducting a large-scale online survey. Regarding the formation stage, consumers' social community and personal involvement were identified as significant factors in promoting the urge to buy impulsively (UBI) in the OSC. Specifically, consumers' OSC involvement appeared as their carnival experiences including participation, interaction, and pleasure; The social community consisted of their connections with e-commerce platforms, e-merchants, the media, net friends, close friends, and relatives during the OSC. Regarding the IB enactment stage, the cognitive evaluation revealed either a positive or negative effect on moderating the UBI-IB relationship via the direct path or the outcome expectancy-mediated path, respectively. Meanwhile, outcome expectancy exerted a dominant mediating effect on the UBI-IB relationship as the cognitive evaluation became sufficiently negative. These results yield valuable insights into 1) the distinguished preconditions of the OSC context facilitating consumers' impulse formation, 2) consumers' impulsive and reflective psychological processes behind the IB decision-making. This study also contributes substantially to IB theories and practical knowledge of OSC.",60031419,Ningbo University,Ningbo,China,['1706'],25.0,-0.016504329004329,0.30622294372294373,1
730,730,On axiomatic characterizations of positive-negative region covering-based rough sets," All rights reserved.Rough sets, as a method of granular computing, can be used for dealing with uncertain information. Compared with classical rough sets, covering rough sets have more widely used. There are two methods for studying rough sets, namely the axiomatic and constructive methods. In this paper, based on some notions, two types of positive-negative region covering-based rough sets are investigated within an axiomatic approach. First, we define two types of positive-negative region covering-based rough sets. Moreover, some characteristics of these positive-negative region are validated. Second, the axiomatic systems of these two types of negative region are founded. Final, the conditions of axiomatic systems for characterizing negative region are independent of each other.",60122027,Fuzhou University of Foreign Studies and Trade,Fuzhou,China,['1702'],14.25,-0.03026315789473684,0.3543859649122807,0
731,731,Student modeling using convex factorization machines," All rights reserved.Educational data mining (EDM) is the field of data mining specialized educational data. To get higher learning effect using an intelligent tutoring system, such as e-learning system, it is necessary to grasp the higher accuracy student knowledge state. The purpose of student modeling is the assessment of students' skills from log data such as examination results, and estimation whether a student solve a question or not. In this research, we propose a student skill modeling method using factorization machines. Factorization machines is a combination of the advantages of support vector machines (SVM) with factorization models. The results of conventional methods which predict student performance using factorization machines showed better than before ones. Especially, we use convex factorization machines with improved factorization machines to predict student skill state in order to improve student modeling. The previous research has predicted whether students would answer the next question or not. Our proposed method predicts whether students have the skill to solve the next question or not.",122033224,National Institute of Technology,Okayama,Japan,['1702'],18.444444444444443,0.13860544217687074,0.483843537414966,0
732,732,Low complexity SLM method based on threshold classification for PAPR reduction in OFDM systems," All rights reserved.Orthogonal frequency division multiplexing (OFDM) signal has a very high peak-to-average power ratio (PAPR), resulting in a serious decline in the performance of OFDM systems. Although original selective mapping (OSLM) can obviously reduce the PAPR of OFDM signals, it has large complexity. In order to reduce computational complexity, a low complexity SLM named threshold classification SLM (TC-SLM) has been proposed, which utilizes two orthogonal phase factor sets and threshold classification to reduce the complexity. Simulation results show that the proposed TC-SLM not only successfully achieves a reasonable PAPR performance, but also can reduce the computational complexity clearly.",60103801,University of Jinan,Jinan,China,['1702'],25.0,0.1513952380952381,0.6280571428571428,0
734,734,A planning algorithm for one-day circular tour using public transport," All rights reserved.Worldwide, the number of foreign independent tours (FITs) is rapidly increasing. FIT visitors usually use one hotel as a base: they leave from it, travel around various sightseeing areas using public transport, and return to their hotel the same day; in this paper, we term this the ""one-day circular tour"" (OCT). However, owing to restrictions with public transport schedules, it is difficult to visit many sightseeing areas efficiently and satisfactorily within a limited time. In this study, we present a planning algorithm for OCTs that offers high satisfaction when using public transport in this manner. After defining relevant terms related to sightseeing and tour conditions, we describe our new planning algorithm. Finally, we present the results of our evaluation of the algorithm by means of practical examples; we clarify the feasibility of our approach and make proposals for future studies.",60027844,Universidad de Granada,Granada,Spain,['1702'],23.833333333333332,-0.002384044526901663,0.3232096474953618,0
735,735,Leveraging AI-based Decision Support for Opportunity Analysis," All rights reserved.The dynamics and speed of change in corporate environments have increased. At the front-end of innovation, firms are challenged to evaluate growing amounts of information within shorter time frames in order to stay competitive. Either they spend significant time on structured data analysis, at the risk of delayed market launch, or they follow their intuition, at the risk of not meeting market trends. Both scenarios constitute a significant risk for a firm's continued existence. Motivated by this, a conceptual model is presented in this paper that aims at remediating these risks. Grounded on design science methodology, it concentrates on previous assessments of innovation search fields. These innovation search fields assist in environmental scanning and lay the foundation for deciding which opportunities to pursue. The model applies a novel AI-based approach, which draws on natural language processing and information retrieval. To provide decision support, the approach includes market-, technology-, and firm-related criteria. This allows us to replace intuitive decision-making by fact-based considerations. In addition, an often-iterative approach for environmental scanning is replaced by a more straightforward process. Early testing of the conceptual model has shown results of increased quality and speed of decision-making. Further testing and feedback is still required to enhance and calibrate the AI-functionality. Applied in business environments, the approach can contribute to remediate fuzziness in early front-end activities, thus helping direct innovation managers to “do the right things”.",60106415,"FHS St.Gallen, Hochschule für Angewandte Wissenschaften",St Gallen,Switzerland,['1706'],16.642857142857142,0.14954212454212457,0.4328754578754578,0
736,736,User evaluation on mobile application for shuttle bus service," All rights reserved.User plays an active role in the evaluation phase of system development life cycle. User evaluation is essential to ensure users can use the product (system or mobile application) to solve their problems. The findings of prior study shown that users (or bus riders) faced difficulties such as long waiting time for shuttle buses in a private university in Malaysia particularly if there is bus delay due to traffic congestion. A mobile bus application (app) is proposed after the prior study is conducted. In order to gain valuable insight regarding the usability of the mobile bus app which is developed to solve the bus delay issue, user evaluation on the mobile bus app was performed in this study. Firstly, bus riders need to download the mobile bus app and test it using their mobile devices. After testing, users provided feedback using an online survey. A total of eighty four respondents participated and provided their feedback about the usability of the bus app which were measured by two constructs namely usefulness and ease of use. The results show majority of users found the bus app is usable as it is able to estimate bus arrival time and track current location of the shuttle buses. At the same time. recommendations that given in user evaluation phase help mobile application developers to improve the application in future.",60101841,UCSI University,Kuala Lumpur,Malaysia,['1702'],20.636363636363637,0.04427083333333333,0.3463541666666667,0
737,737,User-based collaborative filtering using fuzzy clustering," All rights reserved.Collaborative filtering is a well-known technique successfully used in various recommender systems. However, it suffers from major drawbacks of the scalability and the data sparsity problems, when the system makes a recommendation based on the ratings records of similar users. This study aims at solving these problems by exploiting user interest in movie genres to build clusters of users. We make a slight variation of Fuzzy C-means algorithm such that several centers, one for each genre, per cluster are maintained. Experimental results showed that the proposed strategy demonstrated performance comparable to a conventional method without using clustering and significantly better than a well-known clustering algorithm of K-means.",60082101,Gyeongin National University of Education,Incheon,South Korea,['1702'],22.0,0.045725108225108224,0.4521645021645021,0
738,738,An investigation into the effects of message framing on crowdfunding funding level,"This study investigates two new informational cues (i.e., positive and negative framing), which are typically hidden in project descriptions of crowdfunding projects, and examines two research questions 1) How do positive and negative framing affect funding level? 2) Do public updates moderate the effects of these framings on funding level? We test these research questions using data from 644 technological gadget projects posted on a popular crowdfunding website over two years. We further investigate our hypotheses using three laboratory studies where we replicate the above effects on backing intention of backers. Results suggest that positive framing does not have a direct effect on funding level, but on the other hand, negative framing does have a positive effect on funding level. Moreover, results indicate that public update positively affects funding level and increases the positive effect of negative framing on funding level. Results also show that the combination of positive framing and public update has a negative impact on funding level. However, according to our experiments, a negatively framed update decreases the negative effect of a positively framed campaign on backing intention.",60134843,McCoy College of Business,San Marcos,United States,['1706'],30.166666666666668,0.010110722610722609,0.4279428904428904,1
739,739,Optimized workforce allocation in dockyards: A contextual analysis,"This paper is a contextual analysis of workforce allocation of dock workers at container terminals. The Kochi International Container Transshipment Terminal (ICTT) is taken as a case for this analysis. A key factor for the aggressiveness of a container terminal is the ideal management of its resources so as to accomplish elevated amounts of management working in consistence with different operational and administrative prerequisites. Apart from arranging of human resource is an issue normal to most port organizations, the particularity of container terminal movement, the need of guaranteeing 24hours/7days proficient managements, the different working and administrative limitations forced by activities and guidelines, and the fluctuating and unsure nature of work requirements needs an assorted and explicit methodology in allocation of port workforce. This paper targets giving a more profound comprehension of the HR the board issue as it emerges in Indian container terminals by examining the fundamental highlights that describe it.",117067938,Alliance University,Bengaluru,India,['1700'],30.2,0.16666666666666666,0.5590909090909091,1
742,742,Extraction-Based Text Summarization and Sentiment Analysis of Online Reviews Using Hybrid Classification Method,"The field of sentiment mining and text summarization has evoked the interest of many scientists and researchers over the last few years, as the textual data has become useful for many real-world applications and challenges. Sentiment Analysis and Opinion Mining is the most popular field for analyzing and discovering insights from text data from various sources, such as Facebook, Twitter and Amazon, Zomato, etc. It involves a computational study of an individual's behavior in terms of buying interest and then extracting his opinions on the business entity of the company. This entity can be viewed as an event, individual, blog post or product experience. Scholars in the fields of natural language processing, data mining, machine learning and others have tested a variety of methods for automating sentiment analysis. These reviews are increasing on a daily basis, as a result of which the summarization of the reviews plays a role where the text is summarized as needed, which provides useful information from a large number of reviews. It is very difficult for a human being to extract and interpret useful data from a very large file. In the text analysis, the value of sentences is decided on the basis of the linguistic characteristics of sentences. This paper provides a comprehensive review of current and past work on sentiment analysis and text description. In this research work, a new hybrid classification system is proposed based on coupling classification methods using arcing classifiers and their quality is evaluated within terms of accuracy. The Classifier Collection was constructed using Naïve Bayes (NB), Support Vector Machine (SVM) and Genetic Algorithm (GA). The proposed work consists of a comparative study of the efficacy of the ensemble technique for sentiment classification. The feasibility and benefits of the proposed approaches are demonstrated by a restaurant review that is widely used in the field of sentiment classification. A wide range of comparative studies is performed and, ultimately, some in-depth analysis is addressed and conclusions are drawn on the efficacy of the ensemble technique for sentiment classification.",60114939,"Lakshmi Narain College of Technology &amp; Science, Bhopal",Bhopal,India,"['1705', '1710']",24.071428571428573,0.09727772227772227,0.3791125541125541,1
743,743,Impact of IIoT Based Technologies on Characteristic Features and Related Options of Nonownership Business Models,"Industrial internet of things (IIoT) can positively impact business from the process and the technical perspective. There is a limited understanding of the impact of IIoT on business models in general especially the novel nonownership business models (NOBMs). In this paper we analyze the literature, especially case study literature, to understand the impact of IIoT based technologies and related features on the NOBMs using a morphological box (developed by Lay et al. [4]) as a framework. We understood that IIoT- enabled technologies enables the implementation of a larger variety of NOBMs, such as, the pay-per-use, pay-per-output and pay-per-outcome business models, as well as a variety of options related to them. We also realized that there is a need to develop a morphological box for capital intensive manufacturing companies by developing new characteristic features and related options that can take IIoT enabled technologies.",60021143,West Virginia University,Morgantown,United States,"['1710', '1705']",23.666666666666668,0.0268243661100804,0.4792517006802721,1
744,744,Teaching data structures through group based collaborative peer interactions,"Data structures and algorithms is an important subject in Computer Science curriculum and builds upon the programming concepts learned by the students in their earlier courses. However, the abstract nature of the concepts can often be difficult for students to grasp. This problem becomes aggravated in an international setting with students from diverse academic backgrounds, resulting in some students losing interest and failing to follow along. This paper describes our novel approach to teach data structures for Computing undergraduates from 30 African countries at African Leadership College (ALC) in Mauritius in partnership with Glasgow Caledonian University, UK. The blended learning program uses a student led ""flipped classroom"" approach, requiring students to view lecture and supporting material online prior to engaging in on-campus seminar session with the tutor. Peer instruction is a key component of the flipped approach. In seminars, students worked on group based problem-solving activities in data structures supported by the tutor. The students devised their solutions on white boards taking ownership of the problem, became motivated to discuss their ideas freely, and to select a group solution. The group solutions were then shared with the other groups and peer reviewed, led by the tutor. This collaborative learning environment was observed to facilitate discussions, and students' contributions and performance in later assessments offered evidence of understanding of core subject concepts.",60007573,Glasgow Caledonian University,Glasgow,United Kingdom,"['1712', '1709', '1707', '1705']",22.1,0.02892156862745099,0.37009803921568624,1
745,745,Motion-Structural Analysis of Systems Using Digital Twins,"Digital Twins enable the analysis of systems under real world conditions using multiphysics models, sensors and bidirectional data connections between the digital and its physical twin. At the Research Lab of the Department of Computer Integrated Design (DiK) of Technische Universität Darmstadt, a Digital Twin demonstrator was developed that enables a motion-structural simulation of a bending beam test bench. The approach provides proof of many of the claimed benefits and challenges through a comprehensible Digital Twin system.",60012881,Universidade Metodista de Piracicaba,Piracicaba,Brazil,"['1710', '1705']",25.666666666666668,0.13333333333333336,0.21587301587301588,1
746,746,A Data Preparation and Migration Framework for Implementing Modular Product Structures in PLM,"This paper reports the research on the complex process of implementing modular product structures in a Product Lifecycle Management (PLM) system. There are many challenges in implementing the system. One main challenge is organising or mapping existing product data and migrating it to the new PLM system. Companies often use a PLM tool for management of CAD files, documents and drawings, but they do not take advantage of the full potential of the PLM system to support the development activities of modular products. Product data management tools are used mainly for product CAD data management and PLM systems support by automating and managing some of the operational complexity of modular product design. The aim of this research is to propose a data model that can be used for implementing modular product structures in a PLM system and a tool that can formalise the existing data so as to migrate it into the PLM system.",60021889,University of Greenwich,London,United Kingdom,"['1710', '1705']",25.666666666666668,0.14567099567099567,0.5101731601731603,1
747,747,A Method for Solving the Problem of Map Connectivity Analysis when Mapping an Area by a Roboswarm with Communication,"Abstract—: An algorithm for solving the problem of analysis of connectivity of a map compiled by the distributed information robot system is described. This task can be implemented by a flock (or a swarm, which is a flock without a leader) of flying reconnaissance robots, e.g., to assess if a group of ground robots provided with the obtained information can pass between obstacles. The map connectivity is analyzed based on a special renumbering of connectivity areas, which is used in data exchange between reconnaissance robots.",60030998,Plekhanov Russian University of Economics,Moscow,Russian Federation,['1700'],28.333333333333332,0.15357142857142858,0.2857142857142857,1
749,749,Modified single shot multibox detector for fine object detection based on deep learning," All rights reserved.In this paper, we proposed an object detection method that combined a parallel network and a candidate region estimation process by using the SSD (Single Shot multibox Detector), which was a real-time object tracking algorithm based on deep learning. The proposed method used VGG-16 networks to extract feature maps in the convolution layer and tracked the objects through candidate region estimation. We used convolution layers containing semantic information and convolution layers containing detailed information. In order to use the information on the two layers together, the network structures proceeded with parallel. After extracting the feature map, the number of candidate bounding boxes was added and the candidate bounding box was used to generate the final bounding box. Conventional SSD may fail to detect objects that have a single structure and contain a small amount of information on the feature map. The proposed method used feature maps that contained more information to improve the object tracking rate. The proposed method showed a 2.2% improvement in mAP (mean average precision) values when compared with the conventional SSD method.",60013866,Kwangwoon University,Seoul,South Korea,['1700'],22.375,-0.05293367346938776,0.3985969387755102,0
750,750,Towards a Digital Thread Between Industrial Internet of Things and Product Lifecycle Management: Experimental Work for Prototype Implementation,"With the growing number of internet of things (IoT) and their miniaturisation, the technical possibilities associated with data collection are multiplied. In the future, it will be possible to install a sensor anywhere for a small cost. On the other hand, product lifecycle management (PLM) is a growing societal concern and products will need to be designed in such a way as to minimize their impact, while allowing businesses to have a viable business model. It will therefore be necessary to integrate data, coming from industrial internet of things (IIoT) into product lifecycle management, for companies to be able to offer product-as-a-service and pay-to-use. This paper aims to describe current advances on the integration of industrial internet of things in product lifecycle management. It also describes a prototype for a digital thread between IIoT and PLM allowing us to put forward open questions regarding the integration.",60019141,Polytechnique Montréal,Montreal,Canada,"['1710', '1705']",24.333333333333332,0.011363636363636364,0.45681818181818185,1
751,751,Robotic process innovation as mediator between technical traits and lean supply chain performance: An empirical study in Thailand,Thailand is not just thriving due to its tourism but the country's manufacturing sector is also leaning towards robotic process innovation. Such innovation is strengthening due to technological advancements and resulting in enhanced firms' productivity. This idea of bringing robotic process innovation is action can be really helpful for lean processes in organizations. This study has aimed to check the role of direct and indirect usefulness of technological traits on lean supply chain performance in mediating role of robotic process innovation. Study has taken only those Thailand's manufacturing organization in sample who have already included robotic processes in their production system and their employees have surveyed through questionnaire. CFA and SEM were used to analyze model fitness and hypotheses. Results have enlightened that Both direct and indirect usefulness have significant impact on lean supply chain performance and also flagged significant mediating role of robotic process innovation in same relationships. Novelty in this study has come due to including a unique outcome lean supply chain performance as an output of robotic process innovation and technical traits. This study has its implications for not only for manufacturing but service sectors too to adopt such robotic practices to improve their performance levels.,60103781,Suan Sunandha Rajabhat University,Bangkok,Thailand,['1710'],22.11111111111111,0.023913043478260877,0.41739130434782606,1
752,752,"PLM Implementation Success Rate in SME. An Empirical Study of Implementation Projects, Preliminary Findings","Research on the implementation of Product Lifecycle Management (PLM) has been published since the beginning of the 21st century. Some researchers claim that the success rate of PLM implementation projects is below 50%, but the authors have found no evidence of that figure. In this paper’s research, a number of PLM implementation cases have been analyzed for their project goals, implementation challenges, and project results. The research data are retrieved from project files and interviews with project managers. The investigated implementation cases are in Small to Medium-sized Enterprises (SME). The results have been structured and compared with findings from the authors’ earlier literature research on SME specific implementation challenges and recommended implementation methods. From this comparison, a conclusion is drawn regarding the implementation success rate and a hypothesis for causes of observed failure.",60020599,University of Twente,Enschede,Netherlands,"['1710', '1705']",19.0,0.004761904761904753,0.18928571428571428,1
753,753,Augmented Reality for Operator Training on Industrial Workplaces – Comparing the Microsoft HoloLens vs. Small and Big Screen Tactile Devices,"The digital revolution towards the industry standard 4.0 offers many ways to improve established methods and processes. In this paper, we report on the lessons learned about the pros and cons of Augmented-Reality-based operator training using the Microsoft HoloLens as compared to small and big screen tactile devices. Together with our industrial partner, we have chosen an encapsulation assembly task as use case. We have enriched the original training material with digital twins of the workplace, animations, videos, and contemporary forms of interaction, all of which made available in an optimised fashion on three different support technologies. Feedback from our testers, and those in charge of designing training courses, is suggesting that notably the HoloLens version of our prototype has the potential not only to replace current training methods, but to go beyond them up to the point where even novices can pass the training autonomously. It thus seems promising to integrate Augmented Reality into training programmes and so to complete the digital chain within the industry life management.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,"['1710', '1705']",28.166666666666668,0.13114035087719297,0.3903508771929825,1
754,754,Legislative dialogues with incomplete information,"This paper extends previous work by presenting a framework for modelling legislative deliberation in the form of dialogues with incomplete information. Roughly, in such legislative dialogues coalitions are initially equipped with different theories which constitute their private knowledge. Under this assumption they can dynamically change and propose new legislation associated with different utility functions.",60029470,Commonwealth Scientific and Industrial Research Organization,Melbourne,Australia,['1702'],18.0,-0.004329004329004329,0.38517316017316017,1
755,755,Project tomo: Automated feedback service in teaching programming in slovenian high schools,"Good and immediate feedback is one of the key components in learning programming. Therefore a tool enabling quick feedback can be very useful in the teaching process. As most such services already available had feedback possibilities more or less limited, we developed a new web service called Project Tomo. It is completely open and already has more than 4000 programming exercises that can be adapted and re-used in new courses. At the moment the service is used by over 30 educational establishments, most of which are high schools. The poster briefly describes the options available in the service and presents its use. Opinions of the teachers using this tool in their teaching are given as well.",60031106,University of Ljubljana,Ljubljana,Slovenia,"['1712', '1709', '1707', '1705']",16.57142857142857,0.23839826839826844,0.4220974025974026,1
756,756,Detection and Prevention of Distributed Denial of Service attacks in SMEs: The Case of CloudPlus,"Cybercrimes are on the rise, and are evolving with the passage of time. As organizations become increasingly reliant upon the contemporary Information and Communication Technologies, they also expose themselves to a vast pool of threats and vulnerabilities. The purpose of this paper is to bring focus on the detection and prevention of Distributed Denial of Service attacks with respect to Small and Medium Enterprises. The paper adopts a case study approach, and aims at designing a technology solution that could help CloudPlus in promptly detecting and preventing DDoS attacks. The technology solution comprises of three layers, including cloud signaling, firewalling and third-party cloud security through Akamai. The solution has been designed such that it can be replicated by any SME that is cloud-based. Research studies generally focus on DDoS attacks on large-scale organizations; however, small and medium enterprises are equally vulnerable to such attacks. Completion of this research study would also help fill this research gap.",121824877,Nangarhar University,Jalalabad,Afghanistan,"['1705', '1710']",19.5,-0.09791666666666667,0.49583333333333335,1
757,757,A comparison of two hybrid methods for analyzing evidential reasoning,"Reasoning with evidence is error prone, especially when qualitative and quantitative evidence is combined, as shown by infamous miscarriages of justice, such as the Lucia de Berk case in the Netherlands. Methods for the rational analysis of evidential reasoning come in different kinds, often with arguments, scenarios and probabilities as primitives. Recently various combinations of argumentative, narrative and probabilistic methods have been investigated. By the complexity and subtlety of the subject matter, it has proven hard to assess the specific strengths and points of attention of different methods. Comparative case studies have only recently started, and never by one team. In this paper, we provide an analysis of a single case in order to compare the relative merits of two methods recently proposed in AI and Law: a method using Bayesian networks with embedded scenarios, and a method using case models that provide a formal analysis of argument validity. To optimise the transparency of the two analyses, we have selected a case about which the final decision is undisputed. The two analyses allow us to provide a comparative evaluation showing strengths and weaknesses of the two methods. We find a core of evidential reasoning that is shared between the methods.",60010023,University of Groningen,Groningen,Netherlands,['1702'],22.22222222222222,-0.06865079365079364,0.5276190476190477,1
758,758,Towards Understanding the Role of Product Usage Information in Product Design Improvement,"A critical factor that makes a product successful is its acceptance in its market. To achieve this goal, producers oftentimes collect and analyze feedback information from the market. This information allows them to get a deeper understanding about the product behaviors, customers, their usage patterns, future needs and expectations. The academic literature describes a variety of use cases that outline how development-related tasks can benefit from Product Usage Information (PUI). They differ, for instance, in the investigated product, task, communication channel, information source, and the type of the result. This diversity and the lack of a generally agreed vocabulary in this research domain facilitates a fragmentation of PUI-related research. This paper provides a first systematic overview of a selection of PUI application cases in product design improvement. The study sample consists of 17 research papers from the last 20 years. We characterize and classify the papers mainly through three dimensions: product type, product development phase, and information sources and channels. The results indicate that PUI can support different tasks during product improvement, both in the task clarification phase and in the product conceptual, embodiment and detailed design phases. Our findings suggest that organizations need to know more about PUI-related information sources and channels.",60008293,University of Bremen,Bremen,Germany,"['1710', '1705']",18.454545454545453,0.19242424242424241,0.4507575757575758,1
759,759,"Observations, testing and security"," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Testing of security for multi-agent systems is proposed and studied. We assume an attacker, as an agent, who can accumulate and exploit knowledge about other agents. This will be done by observation function and security property called process opacity. Unfortunately, this property is undecidable in general, so we propose its more realistic variant based on tests and testing. Here we consider systems to be secure if they cannot be compromised by a given test or set of tests. In the end, we state a decidability result for security testing.",60001987,Comenius University,Bratislava,Slovakia,['1700'],16.833333333333336,0.12395833333333334,0.5385416666666667,0
760,760,The Information and Logical Model of National Scientific and Technological Potential,Abstract: An analysis of the innovative development features of the economies of Russia and foreign countries was carried out. Methodological approaches to determining the priorities of the national innovation policy and assessing the level of innovative development were described. A multilevel information and logical model of scientific and technological potential was developed for the formation and selection of variants of the innovative development strategy of the country. The model is based on a multi-aspect assessment of innovations and methodology of verbal decision analysis. Qualitative criteria with verbal scales for expert evaluation of model elements and relationships between the elements were proposed. An example of analysis of the economy innovative development strategy was given.,60110807,Federal Research Center Informatics and Management of the Russian Academy of Sciences,Moscow,Russian Federation,['1700'],18.833333333333332,0.278125,0.709375,1
761,761,An Approach to Assess Engineering Change Effort Retrospectively Utilizing Past Engineering Change Information,"The competitiveness of companies is nowadays highly dependent on an efficient product development. Shorter time to market, increased competition as well as accelerated market dynamics can be handled well by a continuous improvement in development efficiency. Hence, improving the development performance can have a big impact on the time to market. However, an increasing number of resources must be assigned to the management of engineering changes. The management of changes strongly influences the resources available for the actual design process. Furthermore, the increasing complexity of technical systems as well as the organization affects the engineering change situation and further induces change complexity. This paper therefore introduces an approach to retrospectively assess engineering change information to identify areas for reducing the change workload. It therefore introduces a procedure to guide users through the process of the assessment. In addition, it suggests indicators to evaluate the change situation regarding the induced workload. Finally, the approach is applied in a use case to investigate an engineering change data set.",60107405,Skolkovo Institute of Science and Technology,Moscow,Russian Federation,"['1710', '1705']",16.6,0.12416666666666666,0.43416666666666665,1
762,762,New method of increasing the efficiency of signal reception based on high-precision iterative decoding algorithms,The article discusses an iterative decoding method based on posterior probabilities to improve the energy characteristics of the transmission of information bits. An algorithm for high-precision iterative decoding is developed taking into account the maximum likelihood factor.,60111827,Tashkent University of Information Technologies named after Muhammad al-Khwarizmi,Tashkent,Uzbekistan,"['1705', '1710']",18.5,0.1,0.3,1
763,763,A dialogical model of case law dynamics,We describe a set of dialogue moves which give a procedure to model the development of case law over a sequence of cases.,60020661,University of Liverpool,Liverpool,United Kingdom,['1702'],23.0,0.0,0.0,1
764,764,Privacy-preserving queries on location information for predictive policing,". All rights reserved.Collection of location information is an essential element in surveillance environment. In this paper, we propose a numerical data de-identification method for privacy protection of personal location information.In this paper, numerical information is de-identified using inversion and shuffling. The original data cannot be obtained from the de-identified numerical information. Only those who know the seed of the pseudo random number such as the encryption key can restore the original data. Personal information can be secured based on the de-identification of numerical data.The proposed method is very efficient because a privileged person can perform range search queries on a non-identified database.In particular, it shows more effective than OPES, Bucketization, Index maintenance method, and MIN, MAX, COUNT operation can be performed on transformed data.Through this research, location information privacy can be protected in an intelligent surveillance environment. Especially in artificial intelligence-based intelligent surveillance environment, such research will be necessary.",60117634,Jeju National University,Jeju,South Korea,['1700'],21.428571428571427,0.12870370370370368,0.6462962962962963,1
765,765,Recursive Stock Price Prediction with Machine Learning and Web Scrapping for Specified Time Period,"In the finance world inventory trading is one of the most necessary activities. Stock market prediction is an act of attempting to decide the future price of a stock other monetary instrument traded on a financial exchange. The technical and integral or the time sequence evaluation is used with the aid of most of the stockbrokers while making the inventory predictions. This paper explains the prediction of a stock using Machine Learning. The input parameters include-open, high, low, close rate, trading volume, Price to Earning Ratio, MA, MACD for more accuracy. The Machine Learning algorithm, Random Forest Regression has been implemented in Python programming language which is used to predict the stock market. The algorithm has been used on the historical stock data along with web-scraping technique that has been applied to catch current market data of the stock. The recursive training model take its predicted value as input to predict further long term future stock rates.",60114939,"Lakshmi Narain College of Technology &amp; Science, Bhopal",Bhopal,India,"['1705', '1710']",19.625,0.06156249999999999,0.3665625,1
766,766,Graph-Based Tools for ECM Search Result Analysis to Support the Ideation Step,"Enterprise Content Management tool (ECM) is defined as the technologies, tools, and methods used to capture, manage, store, preserve, and deliver content. Using ECM in the ideation step of the innovation process may enhance the creativity of users to create new knowledge. In this paper, we discuss how to access this large amount of information efficiently without overwhelming users which may decrease their creativity. The purpose of this work is to avoid this situation by replacing the classical representation of ECM results with a graphical representation using graph theory. The advantages of this approach for visualizing and analyzing the connection between contents are discussed.",60026786,École de Technologie Supérieure,Montreal,Canada,"['1710', '1705']",20.8,0.21266233766233766,0.47077922077922074,1
767,767,A Novel Approach to Product Lifecycle Management and Engineering Using Behavioural Models for the Conceptual Design Phase,"This work builds upon a previous proposal for the use of the extended SAPPhIRE model of causality as a foundation for a PLM system, and more specifically the management of design data at the conceptual design phase. During the conceptual design phase, the product definition is in a state of flux as multiple iterations and options are considered until a suitable baseline design is developed. The role of PLM systems is to manage the people, processes and products involved in developing and sustaining a product in order to increase stakeholder satisfaction and product quality while reducing lifecycle costs. At the conceptual design stage, a balance must be struck between the freedom to iterate and the need to control the design process and capture relevant data. Currently, PLM systems are not well suited for the support of the conceptual design stage due to their reliance on the product structure, as the unavoidable, significant design changes to the physical configuration in the early design stages make it difficult to maintain a coherent product definition. This paper presents a case study of the product data created during the conceptual design phase of the SpudNik-1 CubeSat. The results demonstrate the ability of the model to represent a variety of design data representing different subsystems at several levels of maturity. This could prove to be more consistent and easier to use for conceptual design and is one part of a larger goal of redesigning PLM systems for the support of the extended product lifecycle.",60007655,University of Prince Edward Island,Charlottetown,Canada,"['1710', '1705']",31.125,0.13796296296296295,0.45886243386243386,1
768,768,Rules from granules vs. Granulated rules," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This article presents a comparison of classification effects using an exhaustive set of decision-making rules and a granular set of rules. Standard approach is that we perform granulation of the chosen data set looking for the optimal granulation radius and at the end we generate new decision rules, where on the other side, our method is based on the idea of building decision rules first and then granulating them using known methods.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],42.0,0.1268939393939394,0.360479797979798,0
769,769,Disassembly Process Planning Under End-of-Life Product Quality,"Quality of post-consumer products is one of the major sources of uncertainty in disassembly systems. This paper presents a decision tool for disassembly process planning under variability of the End-of-Life product quality. The objective is to maximize the profit of the disassembly process. This latter is the difference between the revenue generated by recovered parts and the cost of the disassembly tasks. The revenue of a product (subassembly, component) depends on its quality. The proposed approach helps to take decisions about the best disassembly process and the depth of disassembly, depending on the quality of the products to be disassembled. Industrial applicability and interest are shown using an industrial case focused on the remanufacturing of mechatronic parts in the automotive industry.",60108231,Décision et Information pour les Sytèmes de Production,Villeurbanne,France,"['1710', '1705']",17.285714285714285,0.265625,0.22499999999999998,1
770,770,A class project to prepare software engineering students for their capstone projects,"We discuss the design of a class project which we have introduced to improve our Software Engineering course presented on the thirdyear graduate level at our institution. For this project, the whole class collaborate to design and implement a single, reasonably large software system. We believe that the class project has the potential to provide an intensive learning experience for our students and may have several educational benefits. We investigate the impact of the class project on student academic achievement and project success in terms of the quality of the code of the developed system. We gauge the impact of the class project by analysing differences the academic performance of the students in the course. Further, we analyzed the differences in assessment marks assigned to projects. We also evaluate the code quality by observing variations in selected software code metrics of the source code of the software systems delivered by the students. Although the results are inconclusive, we feel the class project provides a unique opportunity for students to get hands-on experience in the development of real-world software for industry.",60021902,Universiteit van Pretoria,Pretoria,South Africa,"['1712', '1709', '1707', '1705']",22.5,0.11398809523809524,0.3410714285714285,1
771,771,Octree Based Voxel Model for Representation of Spatial Conflicts Across Multiple Design Domains,"This paper discusses use of octree based voxel model for representation of spatial conflicts across multiple design domains. A framework has been developed to create octree based voxel model linked with intended empty spaces in product, which are associated with design requirements, product lifecycle states and connected design domains. Knowledge in System Modelling Language (SysML), is used to select criteria for building octree voxel model. A case study of Coupled cavity travelling wave tube (CCTWT) Slow Wave structure (SWS) design has been taken to showcase the code capabilities. Octree voxels inside CAD platform show and represent spatial conflicts, detected by associativity modelling of Empty space blocks inside CAD along with the Product knowledge in SysML model.",60015465,Defence Research and Development Organisation India,Dehradun,India,"['1710', '1705']",23.2,-0.08,0.33999999999999997,1
772,772,An Efficient Approach for Image Resolution Enhancement Using Multi Step Magnification Method,"The low-resolution image is viewed as down sampled version of a high-resolution image, whose patches are assumed to have a sparse representation with respect to an over-complete dictionary of prototype signal-atoms. The principle of compressed sensing ensures that under mild conditions, the sparse representation can be correctly recovered from the down sampled signal. We will demonstrate the effectiveness of sparsity as a prior for regularizing the otherwise ill-posed super-resolution problem. We further show that a small set of randomly chosen raw patches from training images of similar statistical nature to the input image generally serve as a good dictionary, in the sense that the computed representation is sparse and the recovered high resolution image is competitive or even superior in quality to images produced by other SR methods.",124115287,Departmet of Electronics and Telecommunication,Jabalpur,India,"['1705', '1710']",32.0,0.03760378510378509,0.4467368742368743,1
773,773,Neural network models for assessing the financial condition of enterprises for supply chain,"The paper deals with the task of assessing the financial condition of enterprises. To solve it, we prove the necessity of building a neural network model for supply chain. A set of financial ratios is defined as the input parameters of the model: the current liquidity ratio of the enterprise, the equity ratio, the equity turnover ratio, and the return on equity ratio. The output parameters were the types of the financial condition of enterprises: an unstable state (regression), a normal state (stable) and an absolutely stable state (progression). The volume of input data for building neural network models for assessing the financial condition of enterprises amounted to 210 records. The construction and evaluation of the effectiveness of neural network models are based on the analytical platform Deductor. There have been built 32 modifications of neural network models with different architectures and trained with different samples formed randomly from the source data. To assess the effectiveness of the models built, a technique has been developed, which includes the stages of testing neural networks, evaluating their accuracy and average classification error taking into account weighting factors assigned by an expert. The results of calculations of errors of the first and second type for each financial condition, as well as the average total classification error, are presented. The best model with a minimum average classification error, which is a single-layer perceptron with 10 hidden neurons, was chosen. The classification accuracy of the model was about 98%. The neural network model is adequate and can be effectively used to solve the problem of assessing the financial condition of enterprises.",60088527,Kazan National Research Technical University named after A. N. Tupolev -KAI,Kazan,Russian Federation,['1710'],22.166666666666668,0.06594202898550725,0.3478260869565217,1
774,774,"Keep calm and code on your phone: A pilot of suacode, an online smartphone-based coding course","Africa lags behind the rest of the world in terms of digital literacy skills with less than one percent of African children leaving school with basic coding skills. One cause of this gap is poor access to equipment such as computers for teaching and learning. Yet, there is a proliferation of smartphones in Africa. Seeking to leverage this opportunity, we developed SuaCode, an online smartphone-based coding course to teach programming fundamentals to Africans. We designed the course to teach coding in a visual, interactive and fun way through the building of a pong game using Processing (a Java-based programming language). In this work, we describe our experience delivering the course online to 30 Ghanaian high school and college students. At the end of the course, 7 of the 30 students completed the first part of the course, building the pong game. The reflection essays from our students showed that they enjoyed the course and coding on a smartphone was not a barrier to completing the assignments. Improvements such as having more mentors and automated feedback on the coding assignments will improve the quality of the course. Given the difficulty in accessing computers in Africa, our work shows that smartphones can be leveraged to effectively introduce students to programming concepts via an online course. We are excited about the results of this pilot and see the potential to scale the course to eventually bring coding skills within arm's reach of millions across Africa, literally into their palms thereby bridging Africa's digital divide.",60025858,ETH Zürich,"Zurich ZH,",Switzerland,"['1712', '1709', '1707', '1705']",22.818181818181817,0.04849206349206349,0.4007142857142857,1
775,775,Legal compliance in a linked open data framework,"An approach for legal compliance representation and checking within a Linked Open Data framework is presented. It is based on modeling deontic norms in terms of ontology and ontology property restrictions. It is also shown how the approach can handle norm defeasibility. Such methodology is implemented by decidable fragments of OWL 2, while legal reasoning is implemented by available decidable reasoners.",60029470,Commonwealth Scientific and Industrial Research Organization,Melbourne,Australia,['1702'],15.25,0.16,0.36,1
776,776,"Programming, research and... coffee? an analysis of workplace activities by computing interns","To overcome the skills gap between industry demands and learning outcomes achieved by graduates in higher computing education, many Bachelor programs integrate some form of internship in their curriculum; students are assumed to encounter authentic tasks and recent technologies in the workplace. In practice, however, educators often do not know specifically which tasks their students perform and which technologies they use, mainly due to the distance between coach and student during the work placement and the lack of cohort-based overviews of activities performed in internships. In this study, we gathered and analyzed workplace activity data of 54 students over the course of their third-year semester-long internships in the computing industry. We performed descriptive analyses to gain insight into i) which categories of activities students performed most (programming, research and documentation) and ii) which of the activity categories they find most difficult (research, documentation (both academic and IT) and implementation/configuration). Subsequent text analysis gives us insight into students' perceptions of the categories used to label activities (testing, research, meetings, and academic documentation are congruous) and which technologies were used most by these students. Based on the results, we conclude it is feasible to use user-generated data to get insights into workplace activities of computing interns. The quality of this user-generated data does hamper us in drawing certain conclusions. Further research is needed with improved data quality and volume in order to obtain more generalizable results.",60104569,Utrecht University of Applied Sciences,Utrecht,Netherlands,"['1712', '1709', '1707', '1705']",29.25,0.1892857142857143,0.4330952380952381,1
777,777,Rough Mereology based CFill algorithm for robotic path planning," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This paper focuses on describing the CFill algorithm for rough mereology based intelligent agent path planning. The algorithm updates the methodology of the Square Fill Algorithm by increasing its adaptiveness, adding dynamic neighbour building and proposing a way to deal with dynamic changes to the robot environment, by implementing tree based path planning. The author describes the changes to the original algorithm with example values and their outcomes.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],26.666666666666668,0.22500000000000003,0.4833333333333333,0
778,778,Decision trees for knowledge representation," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In this paper, we consider decision trees as a means of knowledge representation. To this end, we design three algorithms for decision tree construction that are based on extensions of dynamic programming. We study three parameters of the decision trees constructed by these algorithms: number of nodes, global misclassification rate, and local misclassification rate.",60104126,Jouf University,Sakakah,Saudi Arabia,['1700'],22.0,0.1,0.23333333333333334,0
779,779,"Towards a computational theory of action, causation and power for normative reasoning","In order to effectively implement guidance structures in a computational social system, directives which are specified in general terms of duties and rights need to be transformed in terms of powers and liabilities attributed to social parties. The present paper is a work in progress report on an axiomatization of power structures in a logic programming setting, covering the intentional level in specifying actions, the connection between productive characterization of actions and causation, the default nature of action specifications, failures and omissions, the relations of causation and power, and the concept of interfering actions.",60002483,Universiteit van Amsterdam,Amsterdam,Netherlands,['1702'],47.0,0.1361111111111111,0.2555555555555556,1
780,780,Digitaljs: A visual verilog simulator for teaching,This paper describes a visual circuit simulator tool designed for teaching students digital circuit design. The tool runs in the browser and is simple to use. It allows to visualize the synthesized circuit generated from Verilog/SystemVerilog code and interact with it.,60016147,University of Wroclaw,Wroclaw,Poland,"['1712', '1709', '1707', '1705']",13.666666666666666,0.0,0.11904761904761905,1
781,781,A flipped classroom experiment the implementation of semi-synchronous learning,"With semi-synchronous learning, students are provided with online learning material, and allowed a window of time within which they study the material. This allows the students to employ mastery-based progression and just-in-time learning approaches. Furthermore, this also frees lecturers' time, allowing them to focus on helping students lagging behind. This article describes the process of converting a ten-week university course to a semisynchronous teaching format. Student grades and video viewing statistics were used to evaluate the new approach. Results show that some students had an initial resistance to the new format and leaned towards traditional teaching methods. However, video viewing statistics show that students remained engaged in learning the theory throughout the course duration. The new approach did not result in a significant difference in student grades.",60102765,The Hague University of Applied Sciences,Den Haag,Netherlands,"['1712', '1709', '1707', '1705']",15.875,0.05487012987012986,0.5269480519480519,1
782,782,Approximate Solution Scheme for Inverse Bin-Packing Problem Subject to Decision Maker’s Preferences,"Abstract: The problem of packing a maximal number of items in the given set of equal capacity bins subject to Decision Maker’s (DM’s) preferences over the items is under consideration. The solution of this problem must satisfy the following conditions: (1) the total weight of items in a bin is not to be greater than the bin capacity; and (2) for each unpacked item there are no packed items less preferable for DM, instead of which it may be packed without violating the capacity limit. The approximate solution scheme for this problem based on modified First Fit Decreasing algorithm is proposed.",60110807,Federal Research Center Informatics and Management of the Russian Academy of Sciences,Moscow,Russian Federation,['1700'],33.666666666666664,-0.033333333333333326,0.4333333333333334,1
783,783,Creating tutorial materials as lecture supplements by integrating drawing tablet and video capturing/sharing,"We report the experience of adopting an innovative technique for creating tutorial videos which complement lectures and facilitate students' learning. Our technique relies on: 1) preparing starter pages consisting of code fragments or writings/figures on a drawing tablet; 2) illustrating complex ideas on the drawing tablet; 3) recording all computer desktop activities (e.g., development of code on a programming IDE, illustration on the drawing tablet); and 4) sharing the recorded tutorial videos with students online. Our technique has been adopted in creating tutorial series for four Computer Science and Engineering courses, ranging from the first year to the third year. Analytics of these online tutorial videos is presented to show the average amount of time which each registered student spent on watching them. Course evaluation results indicate that our technique is perceived as effective for achieving the course learning outcomes. Comparison of students' performance on complex topics (arrays and loops) also indicates a positive impact of our approach.",60033420,York University,Toronto,Canada,"['1712', '1709', '1707', '1705']",26.333333333333332,0.08080808080808081,0.4420875420875421,1
784,784,Tracking the Capture of Tacit Knowledge in Product Lifecycle Management Implementation,"This study outlines the importance of tacit knowledge for engineering organizations, specially engineer-to-order organizations, and its impact in Product Lifecycle Management (PLM) implementations. The use of maturity models as roadmaps and its functions in PLM and knowledge management (KM) are explored. Difficulties of managing knowledge to prepare an organization for PLM implementation, and how PLM maturity models lack the granularity to support KM for PLM implementations are also explored. To support KM for PLM implementations, a tacit knowledge codification scale is developed from KM and PLM maturity models. The scale intends to help knowledge managers better prepare the organization for a PLM implementation and better support the implementation effort.",60026786,École de Technologie Supérieure,Montreal,Canada,"['1710', '1705']",21.8,0.3642857142857143,0.46785714285714286,1
785,785,Evaluating business attractiveness of cities by considering the human resource management for supply chains in cities more than million population in Russia,"Today, cities become centers of entrepreneurial activity and innovation development, the main driving force. Business chooses the territory where there are the best conditions for the development and further successful functioning, as well as guarantees of profit. It can be achieved by the human resource management based on the supply chain strategies. That is why large cities nowadays are becoming competitors for the most successful entrepreneurs. Attracting business directly depends on the effective use of the full potential of the city territory, as well as on designing the effective municipal policy for attracting business, taking into account city's strengths and weaknesses. In order to evaluate city attractiveness for business in Russia the authors collected a database consisting of a set of indicators over a period of five years (2013-2017). A comprehensive and detailed evaluation of each of the indicators made it possible to identify the strengths and weaknesses of each selected city and compare the data obtained by translating the values into indices. It allows us not to focus on the study of each city in isolation, but to compare them with each other, to reveal competitive advantages. Based on the integral index of business attractiveness, the following groups of Russian cities are distinguished: cities leading for business attractiveness (Yekaterinburg, Krasnoyarsk, Kazan), cities middling for business attractiveness (Ufa, Nizhny Novgorod, Rostov-on-Don, Perm, Novosibirsk, Samara, Chelyabinsk), cities-outsiders for business attractiveness (Voronezh, Volgograd, Omsk).",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],25.77777777777778,0.30294486215538846,0.562468671679198,1
786,786,Applications of tolerance rough set model semantic text analysis," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).Tolerance Rough Set Model (TRSM) is an extension of Rough Set theory and can be used as a tool for approximation of hidden concepts in collections of documents. In recent years, numerous successful applications of TRSM in web intelligence including text classification, clustering, thesaurus generation, semantic indexing, and semantic search, etc., have been proposed. This paper revises the basic concepts of TRSM, some of its possible extensions and some typical applications of TRSM in text mining. We also discuss some further research on TRSM.",60013756,University of Warsaw,Warsaw,Poland,['1700'],24.0,0.05972222222222223,0.49652777777777773,0
787,787,Review of CAD Visualization Standards in PLM,"The rise of new technologies has led to a growth in the number of 3D data types. Also 3D data are more voluminous and include a greater number of interrelationships between the data. These data can come from various sources, hence their heterogeneity and complexity. The level of data access is often a function of the user’s expertise since the 3D data are complex and registered to different file formats. A 3D data file format is used for storing information about 3D models. Each sector adopts his own 3D file format for different reasons. In this article, we are going to learn about 3D file formats and survey the functionality differences between some popular file formats, able to ease the integration of data, by analyzing on 3D viewing technology, some models made by two different CAD systems.",60023736,Universite de Technologie de Troyes,Troyes,France,"['1710', '1705']",19.571428571428573,0.2305785123966942,0.6072314049586777,1
788,788,Implementation of Pay-Per-Output Business Models and Advanced Automation Systems in Capital Goods Manufacturing SMEs,"Manufacturing small and medium enterprises (SMEs) are recognized as a major driving force in European Union (EU) and elsewhere both economically as well as technologically in this ever-changing manufacturing paradigm. SMEs have major difficulties in implementing digital technologies such as the industrial internet enabled technologies that can lead towards a change in the business models, especially towards pay-per-output type business models. In this paper, we have studied pioneering manufacturing SMEs that have implemented pay-per-output business models as well as the related advanced automation systems. Both case companies were able to demonstrate the benefits and difficulties that they faced because of the size (SME) during the implementation process of both the pay-per-output business model and the related advanced automation system.",60011170,Tampereen Yliopisto,Tampere,Finland,"['1710', '1705']",29.75,0.11346153846153847,0.4942307692307692,1
789,789,Computer Vision with Cognitive Learning to Improve the Decision-Making During the Sales Process in Physical Stores,"In a world where the information is obtained faster than ever seem, new methods to process that high volume of data are being developed frequently. This is more notorious in a virtual ambient where the data is generated in a manner that is faster and easier to analyze than in the real world. This is very evident in the retail field, where virtual stores have easy access to all the advertisement a user visited and simple to obtain user profile, on the other hand physical stores are limited to basically create a register in a database when there is a purchase. In an attempt to improve the retailers experience from physical stores to manage their business this document has the objective to develop a computational tool that will analyze the people flux going in the establishment, trying to inform the retailer the amount of people and their gender to help the sales process in physical stores. To this end, computational vision methods and algorithms were raised, which after selection, theoretical conception and tool’s implementation it was tested with benchmarks to operate locally and in real time by accessing the cameras installed strategically in a real scenario. Two scenarios were tested: static ambient light and dynamic light. Two tests were conducted: YOLOv2 against background subtraction-based counter; gender classification using full body features. Even though the results were not as positive as needed for commercial use, the tool demonstrated potential and space for improvements.",60020004,Pontificia Universidade Catolica do Parana,Curitiba,Brazil,"['1710', '1705']",30.25,0.1494644861311528,0.3784656084656085,1
790,790,A BigData approach for sentiment analysis of twitter data using Naive Bayes and SVM Algorithm,"Data mining and sentiment analysis are two most versatile research areas in field of real time knowledge extraction. Real time twitter data analysis can plays very crucial role to observe the thinking and view point of people and users. Nowadays, social networking sites have become centric points to share your thoughts and viewpoints. Analysis of social networking data can help a lot to observe trend of society. It can also help to derive user interest and hidden activities. Sentiment analysis is the approach to determine whether piece of writing is positive, negative or neutral. It also help to derive user opinion and attitude of writer. Sentiment analysis of twitter user can help to track eventual view point of user. Country wise accumulative view point can help to derive overall opinion of country citizens and their thinking criteria. This work has proposed sentiment analysis model to observe positive and negative view point of different countries based on sentiment analysis approach. The complete work will be implemented using Hadoop Ecosystem to perform parallel processing on large data.",60115223,The IIS University,Jaipur,India,"['1705', '1710']",15.909090909090908,0.09271284271284269,0.38256373256373266,1
791,791,The Trust over IP Stack,"This article defines a four-layer architectural stack called the ToIP stack for establishing trust between peers over the Internet and other digital networks. Patterned after the TCP/IP stack that standardized packet exchange and created the Internet, the ToIP stack is a decentralized architecture that encompasses business, legal, and technological requirements. Layer One establishes decentralized trust roots using decentralized identifiers (DIDs), an emerging W3C standard for decentralized PKI. Layer Two is the DIDComm protocol, a transport-independent protocol that uses DIDs to form and communicate over a cryptographically secure connection. Layer Three is a suite of credential exchange protocols based on the W3C Verifiable Credentials standard for cryptographically verifiable digital credentials. Layer Four adds cryptographically verifiable governance frameworks using a metamodel for describing the business, legal, and technical policies under which a peer is operating as an issuer, holder, or verifier of digital credentials. This governance metamodel can be applied at all four Layers of the stack, producing a parallel ToIP Governance Stack that fully integrates the non-technical dimensions of trust establishment. Further work on defining, testing, and integrating the ToIP stack is planned for a new project at the Linux Foundation.",60021293,International Business Machines,Armonk,United States,['1705'],23.75,0.062412587412587414,0.18688811188811186,1
792,792,Empirical analysis of mergers and acquisitions: Evidence from international and comparative supply chain operations in Russian market,"Fifty mergers and acquisitions deals that occurred in the period 2014-2017 in the Russian market were analyzed. Deals were randomly selected. The largest number of selected transactions accounted for 2015. 32% of all transactions occurred in the oil and gas sector of the economy. Within the framework of the study, two hypotheses were put forward: 1) the effectiveness of a merger and acquisition transaction increases with an increase in the capitalization of the company-buyer, 2) the effectiveness of a merger and acquisition transaction increases with an increase in its amount. The effectiveness of the merger and acquisition deal was expressed through the growth of the economic profit of the purchasing companies based on the comparative supply chain. Fifteen variables were selected as independent ones (return on invested capital; weighted average cost of capital; return on equity; return on assets; return on sales; multiplier ""share return"" multiplier ""price / earnings"" multiplier ""price / book value of assets"" multiplier "" business value / revenue "" multiplier"" Business cost / profit before interest, taxes and amortization "" profitability of the company before interest, taxes and the multiplier ""earnings before interest, taxes and depreciation / book value of assets"" the dollar exchange rate, etc.), however, only two of them were included in the final type of the regression model: the price / net profit multiplier and the amount of the merger / acquisition transaction.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],32.85714285714286,-0.056249999999999994,0.40312499999999996,1
793,793,Estimation of Prospective States of Mechanical Parts for Lifecycle Support by Part Agents,"This paper discusses the lifecycle simulation of mechanical parts that are managed by part agents to promote their effective reuse. It is essential to promote the reuse of mechanical parts with lifecycle management for the realization of a sustainable society. However, it is difficult to manage products in the use phase of product lifecycles owing to the unpredictable and uncontrollable behavior of consumers. This paper proposes a product lifecycle management system, called part agent system, using network agents and RFID tags attached on parts to promote reuse. A part agent generates advice for the user regarding the maintenance of corresponding parts based on its current state and lifecycle information. The lifecycle simulation scheme performed by part agents is described herein. First, a part agent expands the part lifecycle with time. Next, it estimates by simulating the deterioration of the part and subsequently selects preferable maintenance actions. To simulate forthcoming states of the part, the possibility of events related to the part is estimated based on the causal relation of events with the acquired data on the states of the part, user operations, and detected events. Herein, a proposed method is presented to describe how the deterioration process is represented as causal relations with probabilities and how the relation is created using simulation. The simulation method is described for two example cases: fatigue of spring and deterioration of joints of a robotic manipulator.",60015336,Chuo University,Hachioji,Japan,"['1710', '1705']",21.09090909090909,0.008333333333333331,0.44833333333333336,1
794,794,A new definition of composition of LTIHA," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).The aim of this paper is to solve some issues of linear time-invariant hybrid automata as defined in [9]. First these issues are explained on a small example, before the revised definitions of linear time-invariant hybrid automata and their composition operator are presented. Furthermore it is shown that this new composition operator is commutative and associative.",60008069,Technische Universität Chemnitz,Chemnitz,Germany,['1700'],22.666666666666668,0.12727272727272726,0.4375757575757576,0
795,795,Robot Coalition Formation Based on Fuzzy Cooperative Games over Blockchain-Based Smart Contracts,"In production cyber physical systems robots perform most operations. On the way to Industry 4.0 robots have to be automated and perform operation in coalition to reach common goals. The paper describes an approach to dynamic formation of coalitions of autonomous robots based on the integration of fuzzy cooperative games and smart contracts. Each robot is viewed as an agent, negotiating and bidding with others during the coalition forming for distribution of joint winnings. It is necessary to find combination of robots in way to maximize efficiency of joint work, while the efficiency of the entire coalition is unknown beforehand. A cooperative game with fuzzy core is used to form a coalition of robots allowing coordinating the actions of individual members to achieve a common goal, as well as to evaluate and distribute the overall benefit. To implement the negotiation process and record the composition of the coalition and the responsibilities of individual participants, it is proposed to use the smart contract technology, which now become a part of the blockchain technology. Smart contracts are proposed to be used as entity holding requirements and expected winnings of each participant in the immutable structure of a blockchain network. The final agreement can also be stored by all participants in form of smart contract that contains the distribution coefficients of the winnings given all the conditions of participation in the coalition. The availability of smart contracts to all participants in the coalition makes it possible to ensure joint control over the fulfillment of the task assigned to the coalition.",60101977,St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences,Saint Petersburg (ex Leningrad),Russian Federation,"['1710', '1705']",25.7,0.03673469387755103,0.5499433106575964,1
796,796,Improving the processing of question answer based legal documents,"In the legal domain, documents of various types are created in connection with a case. Some are transcripts prepared by court reporters, based on notes taken during the proceedings of a trial or deposition. For example, deposition transcripts capture the conversations between attorneys and deponents. These documents are mostly in the form of question-answer (QA) pairs. Summarizing the information contained in these documents is a challenge for attorneys and paralegals because of their length and form. Having automated methods to convert a QA pair into a canonical form could aid with the extraction of insights from depositions. These insights could be in the form of a short summary, a list of key facts, a set of answers to specific questions, or a similar result from text processing of these documents. In this paper, we describe methods using NLP and Deep Learning techniques to transform such QA pairs into a canonical form. The resulting transformed documents can be used for summarization and other downstream tasks.",60027090,Virginia Polytechnic Institute and State University,Blacksburg,United States,['1702'],18.22222222222222,0.057499999999999996,0.43,1
797,797,Proposed Machine Learning Classifier Algorithm for Sentiment Analysis,"Text Mining has emerged as an active domain in the field of NLP (Natural Language Processing) and due to availability of large data sets of reviews, it has become easy to do sentiment analysis and extract the result from it, but Now-a-days the objectives are expressed in different ways making the data massive and difficult to understand for machines. In this research work, machines are first trained (Supervised learning) with the help of the predefined data (or more clearly reviews) and then tested with the reviews available. This Research work will show you the working of a system that uses the supervised training which classifies a product review as positive or negative using various classifier algorithms like KNN, Logistic Regression and Support Vector Machines. The model which will give the more accuracy will be considered as the best model.",60114939,"Lakshmi Narain College of Technology &amp; Science, Bhopal",Bhopal,India,"['1705', '1710']",34.75,0.15685637891520243,0.535236822001528,1
798,798,Application of character-level language models in the domain of Polish statutory law,"Polish statutory law so far is distributed as PDF, HTML and text files, where the structure of the rules and the references to internal and external regulations is provided only implicitly. As a result, automatic processing of the regulations in legal information systems is complicated since the semi-structured text needs to be converted to a structured form. In this research, we show how character-level language models help in this task. We apply them to the problems of detecting the cross-references to structural units (e.g. articles, points, etc.) and detecting the cross-references to statutory laws (titles of laws and ordinances). We obtain 98.7% macro-average F1 in the first problem and 95.8% F1 in the second problem.",60021361,Uniwersytet Jagielloński w Krakowie,Krakow,Poland,['1702'],19.166666666666668,0.0062500000000000056,0.4541666666666667,1
799,799,Palm print Recognition Using Neighboring Direction Indicator,"Multibiometrics can provide higher identification accuracy than single biometrics, so it is more suitable for some real-world personal identification applications that need high-standard security. Among various biometrics technologies, palm print identification has received much attention because of its good performance. Combining the left and right palm print images to perform Multibiometrics is easy to implement and can obtain better results. However, previous studies did not explore this issue in depth. In this Process, we proposed a novel framework to perform Multibiometrics by comprehensively combining the left and right palm print images. This framework integrated three kinds of scores generated from the left and right palm print images to perform matching score-level fusion. The experiment is carried out by using MATLAB software image processing toolbox.",60104102,Jabalpur Engineering College,Jabalpur,India,"['1705', '1710']",17.714285714285715,0.22072829131652658,0.39243697478991596,1
800,800,Identification of rhetorical roles of sentences in Indian legal judgments,"Automatically understanding the rhetorical roles of sentences in a legal case judgement is an important problem to solve, since it can help in several downstream tasks like summarization of legal judgments, legal search, and so on. The task is challenging since legal case documents are usually not well-structured, and these rhetorical roles may be subjective (as evident from variation of opinions between legal experts). In this paper, we address this task for judgments from the Supreme Court of India. We label sentences in 50 documents using multiple human annotators, and perform an extensive analysis of the human-assigned labels. We also attempt automatic identification of the rhetorical roles of sentences. While prior approaches towards this task used Conditional Random Fields over manually handcrafted features, we explore the use of deep neural models which do not require hand-crafting of features. Experiments show that neural models perform much better in this task than baseline methods which use handcrafted features.",60025451,Tata Research Development and Design Centre,Pune,India,['1702'],22.285714285714285,0.13382352941176473,0.3137254901960785,1
801,801,AnoPpi: A pseudonymization service for Finnish court documents,"To comply with the EU General Data Protection Regulation (GDPR) publishing court judgments online requires that personal data contained in them must be disguised. However, anonymizing the documents manually is a costly and time-consuming procedure. This paper presents Anoppi service for automatic and semi-automatic pseudonymization of Finnish court judgments. Utilizing both statistics- and rule-based named entity recognition methods and morphological analysis, Anoppi is able to automatically pseudonymize documents written in Finnish preserving their readability and layout. The service is currently still in development but pilot tests are going to be carried out in Finnish courts in 2020.",60103653,Aalto University,Espoo,Finland,['1702'],19.4,0.1375,0.45625000000000004,1
802,802,DI2 co-innovation lab teaching software development in and for real business situations,"Digitization is changing the business world as a whole [7]. But, digitization affects not only the business world, but also university teaching significantly. The DI2 Co-Innovation Lab serves as a framework to work on joint projects and tasks with companies, students and lecturers in a spatial distributed, international and interdisciplinary setting (DI2) and at the same time to reduce the effort and risk of those involved. The Co-Innovation Lab (CIL) brings a proven agile project management method with knowledge assets from previous projects to support the work on real business problems. Aspects of mediation mitigate the effects of the complex setting. Tried and tested IT tools for acquisition, communication and knowledge management support the processing. Furthermore, branding and publications are used in the acquisition of projects.",60110687,Tampere University of Applied Sciences,Tampere,Finland,"['1712', '1709', '1707', '1705']",18.0,0.08981481481481482,0.4462962962962963,1
803,803,Unsupervised graphical user interface learning," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).While there are many different papers on automatic testing or generation of interfaces[1, 2, 3, 4], the information concerning similar to human perception user interface learning methods are scarce. Given the recent leaps in Artificial Intelligence (AI) one might find this topic very useful in implementing a solution for communication of AI with applications created for human interaction. User interfaces differ between operating systems, hardware possibilities and implementation. The main objective of the study was the analysis of the applications' Graphic User Interface (GUI) and interaction with the graphic interface elements in general. This method can be used to track the change in application behaviour based on any action from the user, without having knowledge about the underlying object structure.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],26.4,0.06916666666666667,0.3614583333333333,0
804,804,Comparing alternative factor- And precedent-based accounts of precedential constraint,"In this paper several existing dimension-based models of precedential constraint are compared and an alternative is proposed, which unlike existing models does not require that for each value assignment to a dimension it is specified whether it is for or against the case’s outcome. This arguably makes the model easier to apply in practice. In addition, it is shown how several factor- and dimension-based models of precedential constraint can be embedded in a Dung-style argumentation-based form, so that general tools from the formal study of argumentation become applicable.",60010023,University of Groningen,Groningen,Netherlands,['1702'],29.333333333333332,0.016666666666666673,0.16666666666666666,1
805,805,The neural network model of DDoS attacks identification for information management fail,"The paper discusses the concept and problem of identifying DDoS attacks for information management. The main starting mechanisms and types of DDoS attacks are analyzed. To identify them, signature and behavioral methods of analyzing network traffic are used. Analysis of the advantages and disadvantages of these methods actualized the need for their combined use. To detect and classify DDoS attacks, the need to develop and use a neural network model has been updated. The training and testing of the model were made on the initial data from the NSL-KDD set. All lines in this set are represented as sequences of TCP packets, UDP packets, and ICMP packets of network traffic transmitted from the source of the attack to the attacked network node. The total sample size was 8067 lines. Of these, half of the data corresponded to DDoS attacks, and the rest of the data characterized clear connections. The Deductor modelling environment was used to build the neural network model. The constructed neural network model was a single-layer perceptron with 11 input neurons, 23 hidden neurons and 1 output neuron. The accuracy of the constructed model was calculated based on contingency tables. The accuracy of the initial data classification at the training stage was 97.94%. The classification accuracy at the testing stage was 97.87%. To assess the quality of the neural network model, the errors of the first (0.93%) and second (3.3%) type are calculated. Testing the model showed good results since almost all DDoS attacks were successfully classified. Thus, the neural network model for detecting DDoS attacks has successfully solved the task of identifying and classifying malicious network connections.",60088527,Kazan National Research Technical University named after A. N. Tupolev -KAI,Kazan,Russian Federation,['1710'],15.882352941176471,0.18333333333333332,0.37692307692307697,1
806,806,Analysis and Design of Stub loaded Closed Loop Microstrip Line Filter for Wi-Fi Applications,"The design of a compact Band Stop Filter (BSF) operating at 2.4 GHz is discussed in this paper. Initially, a BSF is designed using insertion loss method and is validated by simulation software ANSYS Designer. The designed filter is then modified as a planar stub loaded closed loop resonator energized using microstrip line. The simulation of this filter is optimized using ANSYS HFSS. A prototype is fabricated on FR-4 epoxy having dielectric permittivity 4.4 and loss tangent 0.02. The theoretical results and simulation results are experimentally validated using Vector Network Analyzer (VNA). Empirical equations for the filter designs is also presented. The equations is able to predict the resonant frequency with less than 4 % error. All the three, theoretical results, simulation results and measured results are in good agreement.",60109532,"Amrita University, Amritapuri Campus",Kollam,India,"['1705', '1710']",14.444444444444445,0.11333333333333333,0.28416666666666673,1
807,807,Weakly supervised one-shot classification using recurrent neural networks with attention: Application to claim acceptance detection,"Determining if a claim is accepted given judge arguments is an important non-trivial task in court decisions analyses. Application of recent efficient machine learning techniques may however be inappropriate for tackling this problem since, in the Legal domain, labelled datasets are most often small, scarce and expensive. This paper presents a deep learning model and a methodology for solving such complex classification tasks with only few labelled examples. We show in particular that mixing one-shot learning with recurrent neural networks and an attention mechanism enables obtaining efficient models while preserving some form of interpretability and limiting potential overfit. Results obtained on several types of claims in French court decisions, using different vectorization processes, are presented.",60108488,Université de Montpellier,Montpellier,France,['1702'],23.0,0.0010416666666666716,0.46145833333333325,1
808,808,Building a Multi-aspect Ontology for Semantic Interoperability in PLM,"Interoperability support is a key task to enable seamless integration between various information systems. Today, in the era of Internet of Things and cyber-physical systems more and more systems have to collaborate. Product lifecycle management is not an exception. It covers multiple processes related to all stages of the product lifecycle and usually aimed at solving various tasks using different apparatus. As a result, a dilemma arises: on the one hand, there is a need of common information models enabling seamless information exchange, and on the other hand, the existing information models need to be preserved in order not to lose the already achieved efficiency in solving various tasks. In the present research, the problem of developing a single ontology for PLM support is investigated taking into account differences between terminologies (multi-aspect ontology) used at various stages of the PLM cycle. In this paper, the process of the multi-aspect PLM ontology building is presented based on the case study of PLM support at the automation equipment producer, Festo AG & Co KG.",60101977,St. Petersburg Institute for Informatics and Automation of the Russian Academy of Sciences,Saint Petersburg (ex Leningrad),Russian Federation,"['1710', '1705']",24.571428571428573,0.026680672268907565,0.38466386554621845,1
809,809,Towards a Novel Comparison Framework of Digital Maturity Assessment Models,"The fourth industrial revolution is forcing companies to rethink their status quo – creating a need to assess their digital maturity as a basis for improvements. As a result, there is a variety of maturity models available in the literature. This paper introduces a novel comparison framework designed to compare different digital maturity assessment models. Our framework has several steps: reverse engineering of criteria from existing models, criteria matching analysis, as well as computation of the coverage and spread ratios. These two metrics characterize respectively the similarity of two maturity models, and the spread between them. We tested the proposed approach with two well-known maturity self-assessment approaches, namely the IMPULS and PwC methods. From our analysis, we were able to derive several insights that will help to develop a new maturity model specifically dedicated to support SMEs in the aerospace industry and manufacturing sector.",60116450,LISPEN Laboratoire d'Ingénierie des Systèmes Physiques et Numériques,Aix-en-Provence,France,"['1710', '1705']",20.571428571428573,0.10363636363636364,0.21795454545454546,1
810,810,Emplobot - Design of the system," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This paper presents general overview of Emplobot recruiting system, designed by Emplocity Ltd. as part of the project „Development of autonomous artificial intelligence using the learning of deep neural networks with strengthening, automating recruitment processes”. The main goal of the described system is to facilitate, accelerate and automate recruiting process. For this propose the chatbot was implemented which can communicate with potential job candidates preparing their virtual CV. Thereafter, it can perfectly match the candidate profiles with jobs adds in completely automatic way.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],19.0,0.16166666666666668,0.6333333333333334,0
811,811,Assessment of the supply chain management as a comprehensive evaluation of the labour potential of the region,"The trajectory of future competitive development of the Russian Federation on the basis of innovation is closely correlated with the development of labor potential, the designation of the vectors of an effective tactical and strategic management which should be based on a comprehensive assessment of its formation, reproduction and applying. The methodological basis of the study were the monographic method, system approach and the method of analysis, statistical and economic analysis techniques, such as clustering and dispersion analysis, as well as principal components method. The research carried out a critical analysis of existing labor potential assessment methodologies at the regional level, which allowed taking into account the identified deficiencies offer the author's approach to express diagnostics, which does not require a special wide survey, allows to get objective results and it is the basis for identifying the most important problems and priority ways of solving them. The essence of the approach is to conduct regional clustering procedure on the level of the state of the labor potential on the basis of the author's indicator system. The result of research was defined typology of the subjects-regions of Central Federal District of Russia, which made it possible to carry out inter-regional comparison of the level of labor potential, taking into account the innovation component, highlight the characteristics of the obtained clusters of regions that are important in the acceptance of administrative solutions. The proposed toolbox can inure as a basis for analysis and information developed at the regional and federal level program activities aimed at formation and development of the labour potential.",60069257,Belgorod State University,Belgorod,Russian Federation,['1710'],43.333333333333336,0.12285714285714286,0.6273214285714286,1
812,812,Application of meta-learning methods in the recognition of drums and cymbals on the basis of short sound samples, Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This article presents proposal for application of Siamese neural network in the process of classifying the sound of short music instrument samples as percussion instrument or non-percussion instrument. In the learning process 15 sound samples representing each decision classes were used. The accuracy of solution was verified by 5-fold Cross Validation test. The proposed solution has achieved a satisfactory score.,60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],18.0,0.21666666666666667,0.35000000000000003,0
813,813,Pronto ontology refinement through open knowledge extraction,"This paper presents a refinement of PrOnto ontology using a validation test based on legal experts’ annotation of privacy policies combined with an Open Knowledge Extraction algorithm. Three iterations were performed, and a final test using new privacy policies. The results are 75% of detection of concepts and relationships in the policy texts and an increase of 29% in the accuracy using the new refined version of PrOnto enriched with SKOSXL lexicon terms and definitions.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,['1702'],25.0,0.09454545454545454,0.5218181818181817,1
814,814,"A Review, Focused on Data Transfer Standards, of the Uncertainty Representation in the Digital Twin Context","In the context of the digital twin, the relevance and challenges of the uncertainty quantification are recognized. Data acquired in the physical domain are incorporated into a cyber-space to assist in predictive and decision-making processes. The acquisition of data in the physical domain involves the measurement of physical magnitudes. The digital as-built or as-manufactured model derives from measured or scanned data of a physical product. Thus, it is relevant to know how much the data are true. The uncertainty of a measured magnitude is a significant indicator of the data truthfulness. This work shows how the uncertainty is being modeled in standards related to product data representation and in an engineering data fusion context. The ongoing uncertainty modeling work in the Collaborative Research Center (SFB 805) at TU Darmstadt is presented as an example of a data fusion context.",60028442,Universidad Politécnica de Madrid,Madrid,Spain,"['1710', '1705']",17.375,0.10208333333333335,0.3080357142857143,1
815,815,Building an ensemble of naive bayes classifiers using committee of bootstraps and Monte Carlo splits for a various percentage of random objects from training set," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In the work we have implemented an ensemble of Naive Bayes classifiers using committee of bootstraps and monte carlo splits. We have conducted 50 iterations of learning in each tested model. Fixed percentage of random objects from the original training system was used. New training decision systems that were considered consisted of 10 to 100 percent of random objects from original training decision system. Two main variants were checked, first with objects returning after the drawn (bootstraps) - and without returning (as monte carlo splits). We have presented how Naive Bayes classifier works in mentioned models on selected data from UCI repository.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],19.0,0.025252525252525252,0.5684343434343434,0
816,816,Methods and Software Implementation of Intelligent Planning for Integrated Expert System Design,"Abstract: This work is focused on the topical problem of developing efficient software tools to design intelligent systems, in particular, integrated expert systems (IESs), which have powerful functionality and scalable architecture. Automated planning methods are employed to facilitate IES development at the design and requirement analysis stages. General problems of developing a modern software tool base for IES design are discussed. In this context, the intelligent software environment of the AT-TECHNOLOGY workbench for IES development based on the problem-oriented methodology is described. The problem of planning the IES prototyping process is investigated, which forms the basis for implementing the basic components of the intelligent software environment (intelligent planner and technological knowledge base). An automation method based on heuristic search is proposed. The use of the intelligent software environment is illustrated by the development of a dynamic IES prototype for controlling and planning medical resources in serious road traffic accidents.",60068673,National Research Nuclear University MEPhI,Moscow,Russian Federation,['1700'],21.285714285714285,0.1739583333333333,0.6026041666666666,1
817,817,Integration Between PLM and MES for One-of-a-Kind Production,"Despite the amount of research addressing the formalization of product-related knowledge, the practical use of tools for knowledge management is still very low at the corporate level. Several commercial software applications are already available for product lifecycle management (PLM) and manufacturing execution system (MES). Unfortunately, these two applications are scarcely integrated thus preventing an efficient and pervasive collection of data and the consequent creation of useful information. This is more critical in One-of-a-kind Production (OKP), where each product is unique, the process is not completely defined at the design stage, but it is continuously improved at the shop floor level by skilled operator. In such situations, most of the company’s knowledge relies on the lessons learnt by operators in years of work experience, and their ability to reuse this knowledge in order to face new problems. Because OKP must develop unique product and complex processes in a short time, it is mandatory to reuse the acquired information in the most efficient way. It is therefore necessary to collect all the data from the shop floor and transform them in information that will be used in the development of the next product and process. The aim of this paper is to design a framework able to integrate data, from both design and manufacturing phases. To this aim, a framework has been designed to structure and relate information from the PLM and the MES systems. A case study has been developed for a car prototyping company to prove the efficiency of the proposed solution.",60012162,Politecnico di Torino,Turin,Italy,"['1710', '1705']",25.2,0.1450592885375494,0.4595454545454546,1
818,818,Applying IoT on Contemporary Traffic System,"An ever increasing urban population has substantially overburdened the cities of today. In particular, metropolitan city roads are being flooded with traffic each day and the numbers only seem to increase. While government bodies are busy in constructing numerous flyovers and underpasses to cope with the increasing traffic load, the current paper proposes an initiative to assist the government in better management of traffic through application of technology. As such, the paper proposes a unique traffic management system capitalizing over the Internet of Things. The system would work by virtue of a circuit board that is installed across the traffic signals and on the vehicles, allowing them to interact with traffic signals, change the light to red by detecting traffic overload on the opposite side of the road, respond to changing traffic lights and promptly identify vacant parking space for drivers. It is anticipated that actualization of this proposal would be of considerable assistance in better managing road traffic and in avoiding prolonged traffic jams.",121824877,Nangarhar University,Jalalabad,Afghanistan,"['1705', '1710']",27.5,0.15297619047619046,0.4416666666666667,1
819,819,Attack protection trees," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In this paper, an extended model for attack tree, called attack protection tree, is presented. The traditional attack trees threat model is extended with protection actions on the leaf nodes to protect the intermediate nodes from malicious attack. The proposed formalism allows the protection actions to be defined at the leaf nodes, by doing so, eliminating the chances of attack(s) being successful through OR-refinement. The concepts are illustrated through examples and we use a model checker for attack protection tree analyses.",60001987,Comenius University,Bratislava,Slovakia,['1700'],23.25,0.3125,0.675,0
820,820,On the formal structure of rules in conflict of laws,"Law has different methods and principles to resolve conflicts between norms, most of these come from Roman Law, they are well-known and much discussed. There is a whole branch of law, though, which is much less discussed while having been created exactly in order to resolve special conflicts: conflict of laws. This system within Private International Law is dedicated to providing metarules in legal situations where more than one national legal systems’ rules could be applied: CoL rules indirectly settle the situation by declaring which one’s should. The formal representation of how these rules work contributes not only to the modelling of this branch of law but also provides methodologies for concerns arising from other conflicting normative systems, such as ethically sensitive situations where there are multiple stakeholders with different moral backgrounds.",60072562,University of Luxembourg,Esch-sur-Alzette,Luxembourg,['1702'],33.0,0.11660401002506267,0.3941102756892231,1
821,821,Empirical Study of Multi-party Workshop Facilitation in Strategy Planning Phase for Product Lifecycle Management System,"This paper proposes a framework of short term and intensive workshop facilitation for multi-party stakeholders in PLM strategy planning phase. We have been empirically pursuing what a valuable facilitation for the workshop is; how multi-party PLM stakeholders can build proactively a mutual consensus in as short a time as possible. PLM project promotion members always encounter a difficulty of consensus building. This is because various stockholders have different opinions and responsibilities through sales, engineering, manufacturing, and service departments. Firstly, we mention key challenges of multi-party consensus building in PLM strategy planning phase. Secondly, we propose a programmatic framework on intensive workshop-facilitation which is configured twelve steps. The key outcome of the workshop is to craft a PLM Success Value Roadmap (PSVR) which is contained various hypothesis defined by the workshop participants helping by facilitators (KPIs). For example, there are PLM vision, strategy, initiative, process, and key performance indicator. Thirdly, we mention an empirical case study conducted our proposed workshop-facilitation method for an industrial company. Seventeen stakeholders were joined as the workshop participants who were invited from three different business units. It was held as a two-day intensive PLM trial workshop. Finally, we found that the proposed workshop-facilitation as a consensus building method contributed to the satisfaction of more than 60% of the participants. 85% of the participants commented that they would encourage colleagues to participate in the workshop that we have developed. We conclude that the multi-party intensive workshop was a valuable experience that it allows stakeholders to produce a PLM strategy in a relatively short time.",60023462,Waseda University,Tokyo,Japan,"['1710', '1705']",18.357142857142858,0.0675,0.4716666666666667,1
822,822,Adopting lean supply chain at Unipharma Syria to improve its response to clients,"This research aims to test the impact of the adoption of lean supply chain standards in improving Unipharma Syria response to its clients post the Syrian crisis of 2011. The researcher used descriptive and analytical approach to study Universal Pharmaceutical Industries. ""UNIPHARMA"" one of the well-known highly developed firms in the Pharmaceutical Industries in Syria. The data was collected from a questionnaire distributed to 100 employees working at Unipharma Damascus, 98 valid responses were received. The hypotheses were tested using SPSS software. The result of the research showed that the company's reliance on process standardization and industrial standards was relatively high and the adoption rate for industrial standards are the highest. The company's response rate to its customers in terms of flexibility and delivery is not high and convergent for both variables. The novelty of this study stems from the introduction of critical influences that determine an effective employment of lean production to Syrian Manufacturing Companies.",124114768,Cihan University,Peshawa,Iraq,['1710'],19.5,0.13,0.4966666666666666,1
823,823,Toward the Standardization of Grant-Free Operation and the Associated NOMA Strategies in 3GPP,"The dramatic increase in Internet traffic to and from wireless devices poses significant challenges for network operators. While the current growth of traffic is mostly due to consumers communicating more frequently and larger amounts of data over the wireless infrastructure, much of the future growth is predicted to originate from non-human-operated devices or so-called IoT communication. The 3GPP standardization activities toward 5G cellular systems envisages two IoT-centric scenarios: mMTC and URLLC. In this article, we quantify the advantages of grant-free operation for 5G mMTC using latency, signaling overhead, and power consumption aspects. We propose the high-level design of a new grant-free state of operation and explain its interaction with the legacy LTE operating states. We also describe promising grantfree NOMA solutions with respect to synchronization and HARQ, and resource collision handling procedures. Our discussion and proposal relate closely to the current 5G standardization activities in 3GPP and highlight solutions that can easily be integrated into the current LTE framework.",60114348,Indian Institute of Technology Dharwad,Dharwad,India,['1705'],22.714285714285715,0.09902597402597403,0.4616341991341991,1
824,824,"Supply chain performance of cayenne pepperin Gorontalo, Indonesia","The fluctuating price of cayenne pepper can be caused by the characteristics of agricultural commodities and also inefficient supply chain management arrangements. The supply chain approach is believed to be able to increase the effectiveness of each distribution chain, thus guaranteeing products according to consumer demands. The research objective was to examine the performance of the cayenne supply chain with the approach of SCOR supply chain performance attributes based on reliability, responsiveness, agility, and assets in Gorontalo. The research method used was a survey method using purposive sampling technique. The study was conducted a year (July 2017-July 2018) in Gorontalo Province. Data were obtained from direct interviews with farmers, collectors, wholesalers, retailers. Data analysis utilized DEA (Data Envelopment Analysis). The results showed that the performance of the cayenne supply chain doer in Gorontalo was mostly efficient, only 16.7% farmers, 10% collecting trader, 8.3% large trader and 16.7% retailers whose performance was not efficient. The novelty of this research has measured efficient supply chain performance with indicators of reliability, responsiveness, agility, and assets which are able to optimize supply chain networks and marketing activities.",60069390,Hasanuddin University,Makassar,Indonesia,['1710'],20.333333333333332,0.25918367346938775,0.5255102040816326,1
825,825,Design of a programming course for teachers supporting flexible learning trajectories,"How to design an online flexible learning trajectory course where students are in-service teachers with varied level of programming knowledge, interests, and different application need? This paper presents the design of such a course for teachers on applied programming. The main learning objective of the course is to provide in-service teachers with insight into how programming can be used to create digital solutions. The course is practically directed and emphasizes programming as a constructive and creative tool. The course is aimed at teachers in secondary schools. The paper describes the main design choices of the course. Based on the experience with the course, the paper reflects on the challenges to design courses that do not support a single learning path for all the students, but rather aims at providing a context where students can identify and follow the learning path that is best fitting for their competencies, interests, and needs of the local practices.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,"['1712', '1709', '1707', '1705']",25.666666666666668,0.1634920634920635,0.34841269841269834,1
826,826,Practical Implementation of Industry 4.0 Based on Open Access Tools and Technologies,"Industry 4.0 provides a major breakthrough for innovating processes in contemporary manufacturing companies, it arises from the simultaneous presence of an opportunity and a necessity. The opportunity is the availability of powerful ICT technologies, that everyone uses every day with smart phones thanks to the well-established and expensive infrastructure provided by tech giants. The necessity is the achievement of Lean transformation in western enterprises through a deep knowledge on manufacturing processes and an incessant training of workforce. Industry 4.0 will provide us with an integrated holistic view of the manufacturing processes and the possibility to control them according to appropriate forecasts and evaluation of performances and results. Industry 4.0 was born in 2011 and it is in its early stage, there are many research gaps which must be studied and large applications that must be fully integrated in the Industry 4.0 framework. In this paper a simple application of Industry 4.0 is presented with the aim of demonstrating that, using commercially available open source components, it is possible to integrate different technologies belonging to industry (robotics) and commercial components into one eco-system. Moreover, it integrates different I4.0 enabling technologies namely: Robotics, IoT and fog/edge computing. Finally, the proposed framework can serve as an educational and practical tool for demonstration of Industry 4.0.",60012162,Politecnico di Torino,Turin,Italy,"['1710', '1705']",26.5,0.11465419501133788,0.478344671201814,1
827,827,Legal text generation from abstract meaning representation,"Generating from Abstract Meaning Representation (AMR) is a non-trivial problem, as many syntactic decisions are not constrained by the semantic graph. Current deep learning approaches in AMR generation almost depend on a large amount of “silver data” in general domains. While the text in the legal domain is often structurally complicated, and contain specific terminologies that are rarely seen in training data, making text generated from those deep learning models usually become awkward with lots of “out of vocabulary” tokens. In our paper, we propose some modifications in the training and decoding phase of the state of the art AMR generation model to have a better text realization. Our model is tested using a human-annotated legal dataset, showing an improvement compared to the baseline model.",60028928,Research Organization of Information and Systems National Institute of Informatics,Tokyo,Japan,['1702'],25.0,0.04387755102040818,0.4859693877551021,1
828,828,Autism: Implications for inclusive education with respect to software engineering,"Within Computer science and Software engineering, the prevalence of students with a diagnosis of autism spectrum disorder is relatively high. Ideally, education should be inclusive, with which we mean that education must be given in such a way that additional support is needed as little as possible. In this paper, we present an overview on what is known about the cognitive style of autistic individuals and compare that cognitive thinking style with computational thinking, thinking as an engineer, and with academic thinking. We illustrate the cognitive style of autistic students with anecdotes from our students. From the comparison, we derive a set of guidelines for inclusive education, and we present ideas for future work.",60024360,Open University of the Netherlands,Heerlen,Netherlands,"['1712', '1709', '1707', '1705']",22.8,0.013333333333333336,0.3960416666666667,1
829,829,Modelling programmable logic controllers in refinement calculus of reactive systems," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).We present a translation from languages for programmable logic controllers (PLC) into refinement calculus of reactive systems (RCRS). RCRS is a compositional formal framework for modeling and reasoning about reactive systems. RCRS is based on monotonic property transformers (monotonic functions from sets of infinite output traces to infinite input traces) and is implemented in the Isabelle theorem prover. PLCs are industrial digital computers adapted for controlling manufacturing processes. Our translation provides a formal semantics for these systems, and a framework to formally analyze them.",60101819,Space Systems Finland Ltd,Espoo,Finland,['1700'],19.2,0.125,0.25,0
830,830,ERST: Leveraging topic features for context-aware legal reference linking,"As legal regulations evolve, companies and organizations are tasked with quickly understanding and adapting to regulation changes. Tools like legal knowledge bases can facilitate this process, by either helping users navigate legal information or become aware of potentially relevant updates. At their core, these tools require legal references from many sources to be unified, e.g., by legal entity linking. This is challenging since legal references are often implicitly expressed, or combined via a context. In this paper, we prototype a machine learning approach to link legal references and retrieve combinations for a given context, based on standard features and classifiers, as used in entity resolution. As an extension, we evaluate an enhancement of those features with topic vectors, aiming to capture the relevant context of the passage containing a reference. We experiment with a repository of authoritative sources on German law for building topic models and extracting legal references and report that topic models do indeed contribute in improving supervised entity linking and reference retrieval.",60018362,Otto von Guericke University of Magdeburg,Magdeburg,Germany,['1702'],23.571428571428573,0.25196078431372554,0.3852941176470589,1
832,832,Computer-assisted creation of boolean search rules for text classification in the legal domain,"In this paper, we present a method of building strong, explainable classifiers in the form of Boolean search rules. We developed an interactive environment called CASE (Computer Assisted Semantic Exploration) which exploits word co-occurrence to guide human annotators in selection of relevant search terms. The system seamlessly facilitates iterative evaluation and improvement of the classification rules. The process enables the human annotators to leverage the benefits of statistical information while incorporating their expert intuition into the creation of such rules. We evaluate classifiers created with our CASE system on 4 datasets, and compare the results to machine learning methods, including SKOPE rules, Random forest, Support Vector Machine, and fastText classifiers. The results drive the discussion on trade-offs between superior compactness, simplicity, and intuitiveness of the Boolean search rules versus the better performance of state-of-the-art machine learning models for text classification.",60029304,Hofstra University,Hempstead,United States,['1702'],23.333333333333332,0.1575757575757576,0.42121212121212126,1
833,833,Legal search in case law and statute law,"In this work we describe a method to identify document pairwise relevance in the context of a typical legal document collection: limited resources, long queries and long documents. We review the usage of generalized language models, including supervised and unsupervised learning. We observe how our method, while using text summaries, overperforms existing baselines based on full text, and motivate potential improvement directions for future work.",60002483,Universiteit van Amsterdam,Amsterdam,Netherlands,['1702'],21.666666666666668,0.026488095238095238,0.4147321428571429,1
834,834,An Approach to Semantic Interoperability for Product Development Through Automatic Requirement Extraction and Semantic Reconciliation,"The strong competitiveness challenges manufacturing industry to rationalize different ways of bringing new products to the market in the shortest time with competitive prices while ensuring higher quality. Industries need to effectively share product requirements, which comes from various sources and are heterogeneous in nature, during the Product Development Process (PDP) to stay competitive. However, problems with misinterpretation of such requirements have been identified during its sharing due to semantic interoperability obstacles related to the process of automatically gathering requirements and their translation and reuse. This research proposes an approach to automatically gather product requirements, extracting its knowledge and translate it for further use and reuse along PDP. The research structure consisted of firstly studying the current issues of the topic, secondly by exploring an approach, to be validated in an experimental case. Current issues point out to gaps related to the process of semantic reconciliation and knowledge extraction perspectives, giving it a multi-dimensional panorama where semantic issues are intertwined among different perspectives. The later solution presents an approach which considers raw information being processed into product features, refining knowledge during PDP and making it reusable in different cycles. The approach brings a new view on practical methods for automatically collect product requirements, extract its knowledge and translate it into product features, based on knowledge extraction methods and by using semantic reconciliation as means for translating product’s requirements. Further research will focus on expanding the approach and including more features to increasingly complex cases, to explore the full potential of the approach.",60020004,Pontificia Universidade Catolica do Parana,Curitiba,Brazil,"['1710', '1705']",28.0,0.07593671760338426,0.4578628161961496,1
835,835,The NAI suite – Drafting and reasoning over legal texts,"A prototype for automated reasoning over legal texts, called NAI, is presented. As an input, NAI accepts formalized logical representations of such legal texts that can be created and curated using an integrated annotation interface. The prototype supports automated reasoning over the given text representation and multiple quality assurance procedures.",60112770,The American University of Paris,Paris,France,['1702'],16.666666666666664,0.13,0.22999999999999998,1
836,836,Peer assessment by ranks,"Peer assessment is a teaching technique in which students assess each other's work. It can help students to learn and engage with the quality criteria of their subject, and to see their own work as others see it. However, they may have numerous anxieties about fairness, about any extra work involved, about their abilities to assess fellow students, and to be assessed by them. Twenty-one students were assigned a task to rank some designs from a previous class. They put the designs in order of value so that they only had to judge the designs in comparison to each other, and not to some imagined universal standard that they hardly know. The assignment allowed students to give their answers both formally, as a ranked order; and textually, so they could explain and justify their rankings. This mix permits automatic marking schemes to be applied, and we tested two. One is a standard, used quite commonly in multi-choice tests because it is simple. The second refines it, intending to give more accurate results for ranked questions. Results confirm this ranking task is shown to be viable. It gets over some of the problems with peer assessment, and gives students a new learning experience with its own set of advantages.",60029073,Volgograd State Technical University,Volgograd,Russian Federation,"['1712', '1709', '1707', '1705']",18.90909090909091,0.01306818181818182,0.4368344155844156,1
837,837,RIFs as the formal tool of measuring similarity between sets," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In my paper, I will present some results towards the formalization of Rough Inclusion Functions (RIFs) and their complementary mappings using the Mizar system. Following the lines established by Anna Gomoli´ nska, we reuse the notions which are already present in the Mizar Mathematical Library, in the theory of metric spaces, in order to establish the connections between the theory of such metrics and the theory of rough sets.",60005998,Uniwersytet w Bialymstoku,Bialystok,Poland,['1700'],40.5,0.03333333333333334,0.26666666666666666,0
838,838,WIMAX Smart Grid Communication network for a Substation,"Various communication technologies are suggested for building smart grid communication networks. As WiMAX provides features such as interoperability and quality of services scheduling options, it is considered to be one of the suitable technologies for various applications in smart grid. WiMAX networks can be utilized to build communication infrastructure of smart grid applications. In this paper, we have presented a review of recent research activities in smart grid communication using WiMAX technology. We analyzed the performance of WiMAX communication network for monitoring, control and protection type of traffic for substation automation. We classified the traffic types with Quality of Service options available in WiMAX using Network Simulator 3 and measured delay and packet delivery ratio to check whether it satisfies delay and reliability requirements of substation automation.",60100085,Thadomal Shahani Engineering College,Mumbai,India,"['1705', '1710']",21.166666666666668,0.1807142857142857,0.5471428571428573,1
839,839,Method to support auxiliary voice over ongoing MCPTX group call for low priority participants,"MCPTX (Mission Critical Push to X) is catering the need of group communication in different kind of emergency situations. Mission Critical (MC) operations in the civil domain comprise of activities handled by police officers, fire fighters, Search & Rescue teams, Medical Emergency support personnel, Civic Protection etc. There are low priority and high priority users. For Low priority user, it is always a problem to transmit the voice on priority under critical situation. In this paper, authors have proposed a method to support auxiliary voice from lower priority participants during MCPTX group call.",121970017,Samsung R and D Institute,Bengaluru,India,"['1705', '1710']",18.6,0.08444444444444445,0.5599999999999999,1
840,840,"Driver's personality traits, driving anger, risky driving, aggressive driving and road accident proneness in Malaysia: A proposed safety and logistic framework","Road accidents are recognized as the most serious threats that have been haunting worldwide motoring public from children to senior citizens. Human factors such as driver's personality traits, driving anger and risky driving has been recognized as the contributor to high rate of road accident proneness through their driving style such as aggressive driving. The studies in road accident proneness is still lacking and requires an extensive study, therefore it is important to understand the influence of driver's personality traits, driving anger and risky driving in predicting road accident proneness through aggressive driving. A conceptual framework is being proposed to investigate the relation and influence of these variables on road accident proneness. The contribution will beneficial for motoring public that want to find solution towards decreasing the rate of road accidents through their personality traits, emotions, attitude and driving style while driving. Besides, the result obtained will give overall benefits to related agencies to understand the impact of human factors and driver's driving style particularly aggressive driving in reducing road accident.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],28.5,-0.031666666666666655,0.3441666666666666,1
841,841,Hybrid Data-Driven and Physics-Based Modelling for Prescriptive Maintenance of Gas-Turbine Power Plant,"The methodology for prescriptive maintenance of complex technical systems is presented. The proposed methodology is based on a hybrid physics-based and data-driven modelling of complex systems. This approach integrates traditional physics-based simulation techniques such as finite-element modelling, finite-volume modelling, bond-graph modelling and data-driven models, with machine learning algorithms. Combined implementation of the both approaches results in the development of a set of reliable, fast and continuously updating models of technical systems applicable for predictive and prescriptive analytics. The methodology is demonstrated on the jet-engine power plant preventive maintenance case-study.",60107405,Skolkovo Institute of Science and Technology,Moscow,Russian Federation,"['1710', '1705']",17.8,-0.05714285714285714,0.40714285714285714,1
842,842,Deontic closure and conflict in legal reasoning,"We identify some legal reasoning patterns concerning deontic closure and conflicts in defeasible deontic logics. First, whether the logic allows the derivation of permissions from conflicting norms. Second, whether the logic treats norms as closed under logical implication. We suggest appropriate approaches for legal settings.",60031004,University of Queensland,Brisbane,Australia,['1702'],11.25,0.18571428571428572,0.2261904761904762,1
843,843,Neural network based rhetorical status classification for Japanese judgment documents,"We address the legal text understanding task, and in particular we treat Japanese judgment documents in civil law. Rhetorical status classification (RSC) is the task of classifying sentences according to the rhetorical functions they fulfil; it is an important preprocessing step for our overall goal of legal summarisation. We present several improvements over our previous RSC classifier, which was based on CRF. The first is a BiLSTM-CRF based model which improves performance significantly over previous baselines. The BiLSTM-CRF architecture is able to additionally take the context in terms of neighbouring sentences into account. The second improvement is the inclusion of section heading information, which resulted in the overall best classifier. Explicit structure in the text, such as headings, is an information source which is likely to be important to legal professionals during the reading phase; this makes the automatic exploitation of such information attractive. We also considerably extended the size of our annotated corpus of judgment documents.",60031126,Tokyo Institute of Technology,Tokyo,Japan,['1702'],19.625,0.1851449275362319,0.3847826086956522,1
844,844,Is deductive program verification mature enough to be taught to software engineers?,"Software engineers working in industry seldom try to apply formal methods to solve problems. There are various reasons for this. Sometimes these reasons are understandable-the cost of using formal methods does not make economic sense in many contexts. However, formal methods are also often greeted with scepticism. Formal methods are assumed to take too much time, require tools that are too academic, or to be too mathematical to be understood by practice-oriented software engineers. We tested these assumptions by designing a small course around a framework for program verification, aimed at regular computer science students enrolled in a Master's programme. After four lectures and associated exercises, students were given a small verification task where they had to model and verify a real, non-trivial, C function in Why3. A significant majority of students managed to prove a non-trivial functional specification of this C function in the time allotted, and many also pointed out inherent flaws of this function discovered during formalization. Participants reported no major difficulties or mental hurdles in learning Why3, and considered its approach to be appropriate for selected components of safety-critical software. While formal verification tools such as Why3 still have lots of room for improvement, this experience shows that in a short amount of time, software engineers can be taught to use a program verification tool, and obtain usable results without being fully proficient in it. We further recommend that courses on formal methods should also let students explore these as techniques to be applied, instead of only focusing on the theory behind them, as we expect this to gradually lower the barrier to wider acceptance.",60024360,Open University of the Netherlands,Heerlen,Netherlands,"['1712', '1709', '1707', '1705']",24.454545454545453,0.07218749999999999,0.4075961538461538,1
845,845,Accounting for System-Wide Regularities in System-Object Modeling of Organizational Knowledge,"Abstract—: This article clarifies the definition of system in terms of the Unit–Function–Object system-object approach based on the Abadi–Cardelli object calculus. The formalization of the concepts system-forming factor and system adaptation is proposed. The presented formalisms are used to take system-wide regularities in constructing graphical-analytical models of organizational systems and business processes by the system-object method of knowledge representation into account. The identified possible ways of taking regularities into account are compared with the capabilities of the system-structural and object-oriented approaches, as well as with the Business Process Model and Notation. A formal description of system-wide regularities is given that makes it possible to substantiate the hierarchical relationship between them.",60069257,Belgorod State University,Belgorod,Russian Federation,['1700'],22.0,0.0,1.0,1
846,846,Anomaly Based Performance on Sensing Errors by ANN,"Spectrum sensing Anomaly detection, spectrum decision, spectrum sharing and spectrum mobility are four major functions of cognitive radio systems. Spectrum sensing is utilized to observe the spectrum occupancy status and recognize the channel availability, while CR users dynamically access the available channels through the regulation processes of spectrum decision, spectrum sharing, and spectrum mobility. To ease the preparing defers associated with these four capacities and to improve the productivity of range use, range expectation for intellectual radio systems has been widely contemplated in the writing. This article introducing of ANN strategy to enhancement of range forecast in intellectual radio systems. We abridge the significant range forecast systems, delineate their applications, and present the important open research difficulties.",60104102,Jabalpur Engineering College,Jabalpur,India,"['1705', '1710']",23.4,0.19305555555555554,0.4972222222222222,1
847,847,Improved Identity Management with Verifiable Credentials and FIDO,"We describe how FIDO and W3C VCs can overcome the problems of existing identity management systems. We describe our conceptual model and architecture, and the protocol we used by extending FIDO's UAF in order to provide both strong authentication and strong authorization. We built a pilot implementation for U.K. NHS patients to validate our implementation. Patients were able to use a mobile phone with a fingerprint reader to access restricted NHS sites in order to make and cancel appointments and order repeat prescription drugs. Our initial user trials with 10 U.K. NHS patients found the system to be easy to use, and fingerprints to be preferable to using usernames and passwords for authentication.",60070818,Zayed University,Dubai,United Arab Emirates,['1705'],16.142857142857142,0.36,0.5850000000000001,1
848,848,Privacy and monopoly concerns in data-driven transactions,The increase of data-driven M&A transactions have raised apprehension over potential violations of data privacy rights. The economic significance attributed to Big Data has also called into question whether data privacy could be a parameter in merger control proceedings. Our purpose is to address the privacy and monopoly concerns arising from data-driven transactions within the scope of both the EC Regulation and the purpose limitation principle under the GDPR.,60025063,KU Leuven,3000 Leuven,Belgium,['1702'],23.0,0.06666666666666667,0.43333333333333335,1
849,849,A Concept to Integrate Manufacturing Execution and Product Data Management Systems,"Variant rich production of individualized products and customer solutions results in new challenges for all involved industrial information systems in a producing company. To keep pace with the new requirements of a volatile future market and to exploit benefits of flexible digital production environments, it is crucial to adapt integration concepts of Industry 4.0, e.g. enhance information exchangeability by improving interconnectivity between software solutions, utilize all sources of data from a products production and use phase, and maintaining an up-to-date digital twin of the product and production assets. This paper presents an integration concept for the interaction between Product Data Management (PDM) systems, Manufacturing Execution Systems (MES) and shop floor level client systems. It addresses the gap of information flow between the different involved key software tools in a twofold manner. On the one hand side, specific information gained from production and use phase data of products have to be looped back to the PDM system. This sets the foundation for a better understanding of production planning and execution as well as use phase issues related to the engineering phase where problems have to be addressed for continuous product improvement. On the other hand, a direct information flow from PDM to MES and shop floor clients is defined to enable forwarding of current variant product instance information. To evaluate the practical applicability and additional value of the developed integration concept, a case study with an industry partner is conducted.",60018163,Technische Universitat Wien,Vienna,Austria,"['1710', '1705']",26.555555555555557,0.07192513368983958,0.4049465240641712,1
850,850,Frequent use cases extraction from legal texts in the data protection domain,"Because of the recent entry into force of the General Data Protection Regulation (GDPR), a growing of documents issued by the European Union institutions and authorities often mention and discuss various use cases to be handled to comply with GDPR principles. This contribution addresses the problem of extracting recurrent use cases from legal documents belonging to the data protection domain by exploiting existing Ontology Design Patterns (ODPs). An analysis of ODPs that could be looked for inside data protection related documents is provided. Moreover, a first insight on how Natural Language Processing techniques could be exploited to identify recurrent ODPs from legal texts is presented. Thus, the proposed approach aims to identify standard use cases in the data protection field at EU level to promote the reuse of existing formalisations of knowledge.",60012259,Università degli Studi di Torino,Turin,Italy,['1702'],26.4,0.08,0.2783333333333334,1
851,851,Efficient Data Aggregation and Routing Algorithm for IoT Wireless Sensor Networks,"The Internet of Things (IoT) Wireless Sensor Network (WSN) mobile node has the following essential resources; Average Energy, Bandwidth, and Memory. These resources have to be used aptly for effectiveness in the application, and hence, it becomes challenging. The data aggregation and routing algorithm make use of energy, bandwidth, and memory in their operation. The existing data aggregation and routing algorithms reduce energy consumption by avoiding redundancy in data, hence effectively reducing bandwidth, and memory. There has been a tradeoff between the level of security (in data aggregation and routing), and energy consumption, as a high level of security will have more intensive computational operations and vice versa. The proposed research is presenting the improved Modified Power-Efficient Gathering (Aggregation) in Sensor Information System (Modified-PEGASIS) algorithm for efficient data aggregation and routing in IoT WSN. The simulation results of the proposed work show superior data safety and protection, leading to better throughput, packet delivery ratio, end to end delay, routing overhead, energy consumption, and security.",60001945,"Devi Ahilya Vishwavidyalaya, Indore",Indore,India,"['1705', '1710']",23.428571428571427,0.341,0.604,1
852,852,Governmental transparency in the era of artificial intelligence,"In the last years governments started to adapt new types of Artificial Intelligence (AI), particularly sub-symbolic data-driven AI, after having used more traditional types of AI since the mid-eighties of past century. The models generated by such sub-symbolic AI technologies, such as machine learning and deep learning are generally hard to understand, even by AI-experts. In many use contexts it is essential though that organisations that apply AI in their decision-making processes produce decisions that are explainable, transparent and comply with the rules set by law. This study is focused on the current developments of AI within governments and it aims to provide citizens with a good motivation of (partly) automated decisions. For this study a framework to assess the quality of explanations of legal decisions by public administrations was developed. It was found that communication with the citizen can be improved by providing a more interactive way to explain those decisions. Citizens could be offered more insights into the specific components of the decision made, the calculations applied and sources of law that contain the rules underlying the decision-making process.",60024361,Leibniz Center for Law,Amsterdam,Netherlands,['1702'],25.857142857142858,0.10292207792207791,0.41847041847041855,1
853,853,Multicriteria Choice on a Fuzzy Set as a Problem of Searching for Compromise,"Abstract: A problem of multicriteria optimization on a fuzzy set specified by its membership function is considered. A two-step approach is proposed to solve this problem. It involves searching for a compromise between the available criteria and the membership function. At the first stage, a new vector criterion is formed by adding the membership function to the set of initial criteria and information about the importance of criteria in the form of quanta of information is used to reduce the Pareto set. If the reduced Pareto set is not chosen as the final solution to the multicriteria optimization problem, scalarization that uses the concept of ​​goal programming is proposed at the second stage.",60031888,Saint Petersburg State University,Saint Petersburg (ex Leningrad),Russian Federation,['1700'],22.6,0.13106060606060607,0.36464646464646466,1
854,854,Static detection of design patterns in class diagrams,"Teaching Object-Oriented design on the class diagram level is often a cumbersome effort. Requiring the use of specific design patterns helps the students in structuring their design properly. However, checking whether students used the right design pattern can be a very time-intensive task due to the variety of possibilities of creating structure using design patterns on the high-level class diagrams. For the same reason, it is hard for students to check for themselves whether their solution fulfills the basic requirements that are required by the instructor with respect to the use of design patterns. Efficiency and the quality of design pattern education can be improved by automatic detection of design patterns in UML class diagrams. We introduce a new method to detect design patterns in class diagrams, together with a prototype of a tool that uses this new method. Using this tool, an instructor needs less effort to review solutions of design exercises since the tool can check the basic class requirements automatically. Consequently, an instructor can focus on the more high-level requirements that were set in the exercise and students can easier check for themselves whether their design satisfies the basic required properties on the pattern level. The method offers static decidability for those design patterns, that are identified by structural properties e.c. the names of the classes and their associations. It is non-duplicating. That is a specific occurrence of a design pattern is not reported multiple times. The method not only detects all 16 static Gang of Four design patterns without false positives or false negatives, but also it can detect redundant relations. Our tool contributes to the quality and efficiency of design pattern education, both for students and instructors.",60102765,The Hague University of Applied Sciences,Den Haag,Netherlands,"['1712', '1709', '1707', '1705']",20.142857142857142,0.03370035761340108,0.35991906644080557,1
855,855,Verifying meaning equivalence in bilingual international treaties,"This paper examines to what extent distributional approaches to induce bilingual lexica can capture correspondences between bilingual terms in international treaties. Recent developments in bilingual distributional representation learning methods have improved bilingual textual processing performances, and the application of these methods to processing specialised texts and technical terms has increased, including in the legal domain. Here we face at least two issues. Firstly, whether technical terms follow the distributional hypothesis or not is both theoretically and practically a critical concern. Theoretically, corresponding technical terms in different languages are the labels of the same concept and thus their equivalence is independent of the textual context. From this point of view, the distributional hypothesis holds only when the terms totally bind the context. This leads to the second issue, i.e. to verify the extent to which word embedding models trained on texts with different levels of specialisation are useful in capturing cross-lingual equivalences of terms. This paper examines these issues by conducting experiments in which different models trained on the texts with different degree of specialisations are evaluated against three different sets of equivalent bilingual pairs in the legal domain, i.e. of legal terms, of sub-technical terms and of general words. The results show that models learned on large-scale general texts fall far behind models learned on specialised texts in representing equivalent bilingual terms, while the former models have better performances for sub-technical terms and general words than the latter.",60025272,University of Tokyo,Tokyo,Japan,['1702'],21.636363636363637,0.03750000000000001,0.36197916666666663,1
856,856,Deep learning for detecting and explaining unfairness in consumer contracts,"Consumer contracts often contain unfair clauses, in apparent violation of the relevant legislation. In this paper we present a new methodology for evaluating such clauses in online Terms of Services. We expand a set of tagged documents (terms of service), with a structured corpus where unfair clauses are liked to a knowledge base of rationales for unfairness, and experiment with machine learning methods on this expanded training set. Our experimental study is based on deep neural networks that aim to combine learning and reasoning tasks, one major example being Memory Networks. Preliminary results show that this approach may not only provide reasons and explanations to the user, but also enhance the automated detection of unfair clauses.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,['1702'],23.2,-0.0679383116883117,0.6646103896103897,1
857,857,Multiband Slotted Microstrip Patch Antenna with Conducting Strips,The objective of the paper is to design an antenna with multiple resonant frequencies. The proposed antenna resonates at 12 different frequencies with a centre frequency at 5.3GHz. Microstrip patch antenna with conducting stips is used to achieved this purpose. Microwave substrate of size 30mm×30mm having a dielectric constant of 4.4 is used to design the antenna. The desired frequencies are obtained by cutting slots in the patch and impedance matching is done by providing defective ground. The multiband antenna is designed using high frequency structural simulator (HFSS) software with return loss of about-14.34dB and excellent gain of 20.51dB at 5.3GHz.,60104102,Jabalpur Engineering College,Jabalpur,India,"['1705', '1710']",16.833333333333336,0.08,0.4961904761904762,1
858,858,Similarity and relevance of court decisions: A computational study on cJEU cases,"Identification of relevant or similar court decisions is a core activity in legal decision making for case law researchers and practitioners. With an ever increasing body of case law, a manual analysis of court decisions can become practically impossible. As a result, some decisions are inevitably overlooked. Alternatively, network analysis may be applied to detect relevant precedents and landmark cases. Previous research suggests that citation networks of court decisions frequently provide relevant precedents and landmark cases. The advent of text similarity measures (both syntactic and semantic) has meant that potentially relevant cases can be identified without the need to manually read them. However, how close do these measures come to approximating the notion of relevance captured in the citation network? In this contribution, we explore this question by measuring the level of agreement of state-of-the-art text similarity algorithms with the citation behavior in the case citation network. For this paper, we focus on judgements by the Court of Justice of the European Union (CJEU) as published in the EUR-Lex database. Our results show that similarity of the full texts of CJEU court decisions does not closely mirror citation behaviour, there is a substantial overlap. In particular, we found syntactic measures surprisingly outperform semantic ones in approximating the citation network.",60018869,Maastricht University,Maastricht,Netherlands,['1702'],20.9,0.16309523809523813,0.5750000000000001,1
859,859,DaSt: An online platform for automated exercise generation and solving in the data science domain,"Over the last few years data science has emerged both as a new research field and as an educational domain that attracted a large number of researchers and data practitioners. Although data science research is developing at a high pace, the educational process in the field has been left behind in terms of educational tools and practices, despite the high number of data science courses offered and the number of involved stakeholders (professors, tutors, and students). The present work aims to cover the gap of educational data science tools by proposing a novel platform; the platform, coined Data Science Tutor (DaST), is a free online tool that offers automated step-by-step exercise solving in a variety of data science algorithms/techniques aiming at giving insight to the particularities of each algorithm. The solutions of the exercises are accompanied with in-context explanations that refer to the operation of the respective algorithm/technique, and are compatible with the terminology and the methodology in popular textbooks. The tool aims at students, lecturers, and data practitioners in many diverse fields (ranging from data analysts to transport engineers to logistics managers) that want to learn the particularities of data science algorithms in a stepwise, interactive manner. Through the proposed platform (a) students in the data science field or in related courses (e.g., machine learning, information retrieval) may get solutions for different types of exercises and focus on the details of each algorithm, (b) tutors (lecturers, lab assistants) may easily produce a wide variety of exercises with the accompanying solutions and use them in classroom or as an auxiliary tool for test correction, and (c) data practitioners may get valuable insights on popular data science algorithms. To the best of our knowledge, the proposed platform is the first educational tool that aims at the data science field, and has so far been warmly accepted by departments worldwide.",60003684,University of Peloponnese,Tripolis,Greece,"['1712', '1709', '1707', '1705']",44.0,0.2072850958565244,0.41951607915893635,1
860,860,Optimized fuzzy Petri nets and their application for transport logistics problem," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).This paper presents the conception to formalize the task of transport logistics in the form of tables. From these tables, we extract the fuzzy production rules that are the basis for the formation of fuzzy Petri nets. The use of optimized and weighted fuzzy Petri net for solving the transport logistics problem is proposed. The obtained solutions are illustrated by fuzzy Petri net software that simulate the search for the best passenger transport company in the context of transport logistics.",60068513,Yuriy Fedkovych Chernivtsi National University,Chernivtsi,Ukraine,['1700'],23.0,0.3,0.26,0
861,861,A computational model for pragmatic oddity,We introduce a computational model based on Deontic Defeasible Logic to handle the issue of Pragmatic Oddity. The key idea is that a conjunctive obligation is allowed only when each individual obligation is independent of the violation of the other obligations. The solution makes essential use of the constructive proof theory of the logic.,60029470,Commonwealth Scientific and Industrial Research Organization,Melbourne,Australia,['1702'],18.0,-0.020833333333333332,0.5333333333333333,1
862,862,Defeasible systems in legal reasoning: A comparative assessment,"Different formalisms for defeasible reasoning have been used to represent legal knowledge and to reason with it. In this work, we provide an overview of the following logic-based approaches to defeasible reasoning: Defeasible Logic, Answer Set Programming, ABA+, ASPIC+, and DeLP. We compare features of these approaches from three perspectives: the logical model (knowledge representation), the method (computational mechanisms), and the technology (available software).On this basis, we identify and apply criteria for assessing their suitability for legal applications. We discuss the different approaches through a legal running example.",60028218,Alma Mater Studiorum Università di Bologna,Bologna,Italy,['1702'],22.0,0.15625,0.31875,1
863,863,Product-Service Systems Lifecycle Management in Industry: Interests and Exploited Data,"Product-Service Systems (PSS) emerged as a response to the market demand for specific solutions to meet their needs in a competitive and sustainable way. In order to manage and improve the value offered to the customer, lifecycle information needs to be gathered and exploited. In this paper, we present a survey realized among PSS providers, aiming to identify the exploitations and anticipations serving best industry’s current interests. These exploitations were divided in five categories, which the respondents were invited to rank according to the pertinence to their business. The survey also covers the investigation of which data the providers dispose to achieve these exploitations. The answers were compared to general information about the PSS offered by the respondents, such as the type of PSS, product smartness level and type of services offered. The results indicate an initial stage of PSS development, with an important potential to improve. This analysis will further guide the proposition of an information system architecture for PSS lifecycle management in closed-loop, which may integrate the exploitations highlighted by the survey.",60108255,"Sciences pour la Conception, l'Optimisation et la Production de Grenoble (G-SCOP)",Grenoble,France,"['1710', '1705']",21.75,0.05909090909090909,0.475,1
864,864,Design and Manufacturing of a Device Made of Additive Manufacturing Machines for Fast and Reliable Measurement of Material Stiffness,"Additive Manufacturing (AM) technology is constantly expanding to small and large industry over the last 20 years. The vast potential of this technology has been perceived by many companies which invest in research and development for faster and more reliable machines with better capabilities and more quality products. AM expansion in industry has also been helped by a wide variety of materials, such as polymers, whose technology is developing rapidly with better mechanical properties related to stiffness and strength. In this paper we will describe a device which can be fully produced by all AM machines and enables users to measure in a fast and reliable way the stiffness of materials without the need for specialized and expensive methods, large-volume laboratory testing machines, specialized technical personnel and time. The objective is to design a small scaled three-point bending device using design intent through a parametric CAD system and manufacture it using AM technology. The device is designed to calculate the deformation and force applied to specific specimens and the Young’s modulus of the material. The proposed device and its process helps users to estimate the mechanical properties of materials and apply that information on production or in a simulation system to optimize the printing quality of products by selecting the right material and adjusting the related printing parameters of the machines with the mechanical properties of the produced parts.",60017404,University of the Aegean,Mytilene,Greece,"['1710', '1705']",32.714285714285715,0.09565217391304348,0.45170807453416156,1
865,865,A Preliminary Method to Support the Semantic Interoperability in Models of Manufacturing (MfM) Based on an Ontological Approach,"The product design and manufacturing complexity have been increased in the last few years. This has challenged the manufacturing industry to rationalise different ways of bringing to the market novel products in a short lead-time with competitive prices while ensuring higher quality levels and customisation. Design and Simulation systems bring to the product developer experts an abstraction required for the design of complex products. However, for a complex product manufacturing process has required simultaneously collaborations with multiple groups, producing and exchanging information from multi-perspectives within and across institutional boundaries. Thousands of different information must be exchanged across heterogeneous systems. Semantic interoperability obstacles have been identified in view of the information heterogeneity from multiple perspectives and their relationships across different phases of product manufacturing. In this context, this paper presents a preliminary method for Models for Manufacturing (MfM) to support the semantic interoperability across the manufacturing system based on reference ontologies, application ontologies and semantic rules. The MfM has been modelled in reference ontologies and specialised to perform multiple specific applications according to the product to be manufactured. Semantic rules are used to share, convert or translate information from multiple perspectives in order to infer the relation between multiple manufacturing levels. The main research contributions are: (i) the intelligence structuring information in elementary concepts responsible for representing the MfM, modelled in the core ontologies (Reference Ontologies) and (ii) the improvement of information exchanging (translation, conversion and sharing) from heterogeneous domain across different phases of manufacturing process based on the semantic rules.",60118569,AIRBUS Operations SL,Getafe,Spain,"['1710', '1705']",25.0,-0.03253968253968255,0.33690476190476193,1
866,866,Study of direct relationship determinants on the selection of Musyarakah Mutanaqisah (MM) products,"This study analyses the direct relationship of determinants-both intrinsic and extrinsic factors-affecting the selection of Musyārakat Mutanāqisat (MM) house financing products. Intrinsic factors include factors of confidence in sharia compliance value and factors regarding the knowledge level of potential customers. Extrinsic factors include MM product characteristics such as service quality, costs, product benefits and promotions. MM products are emphasised in this study because of their many benefits, including lowering the burden of customers' monthly payloads, a relatively shorter monthly payment period and increased benefits and profits for both banks and customers. Data were collected from 100 MM customers in Malaysia via the Internet (Facebook) and analysed using Structural Equation Modeling (SEM-SMART PLS) and the Statistical Package of Social Sciences (SPSS) software. The findings show that only the factors of promotion and religious compliance are significant when selecting MM products; in fact, the influence of promotional factors had a greater impact than the influence of religious compliance. Therefore, Islamic banks are urged to increase their promotional strategies in order to provide information about the role of religious law in selecting Islamic banking products, thus helping customers choose MM products that satisfy their needs while also meeting religious demands.",60108869,Universitas Mercu Buana,Jakarta,Indonesia,['1710'],28.142857142857142,0.11602564102564103,0.4493589743589744,1
867,867,Stub Loaded Semi-Circular Resonator for Filter Applications,This research article provides a detailed study of semi-circular resonator with stub loading for multiband filter applications. The layout of the design has a planar transmission line in which stubs are arranged in a semi-circular loop symmetrically and perpendicular to the transmission line. The proposed design ensures compactness with wide band configuration compared to the standard designs. The filters are designed and optimized in the frequency range of 2GHz to 7GHz using ANSYSS HFSS and the prototype is validated using Keysight Vector Network Analyzer E5080A.,60109532,"Amrita University, Amritapuri Campus",Kollam,India,"['1705', '1710']",21.25,0.10000000000000002,0.3833333333333333,1
868,868,Tying Ethics to Teamwork Training in a Minimodule,"Most CS and engineering curricula require that students take ethics training and acquire competence in teamwork skills before graduation. Both ethics and teamwork are course objectives mandated by the Accreditation Board for Engineering & Technology (ABET). However, ethics and teamwork are difficult to teach by regular STEM faculty. Lingard (2010) suggests that faculty may not have had much teamwork training themselves. Students can take ethics courses in other departments which may/not help the students to engage in moral reasoning or help them in considering societal implications of technologies they learn in CS or Engineering courses. Thus, there is a growing recognition of the need for a more integrative approach, such as to teach ethics across the curriculum (Pease and Baker, 2009) or embed ethics within the CS curriculum (Grosz et al, 2019). At the University of Alabama at Birmingham (UAB), we are pilot testing a short, integrative approach, i.e., a 4-class period minimodule, covering both ethics and teamwork, embedded in CS or ECE courses. It includes a short refresher on moral reasoning, examples of cooperative behavior in animals and student-led teamwork demonstrations. Using an andragogical approach we provide questions to guide discussions by student teams after viewing video lectures by renowned experts. Outside of class, student teams prepare teamwork demonstrations for the class. We report results and observations. We also report on an event in progress: The intercollegiate Ethics in Action Challenge-https://www.ub.edu/engineering/ece/news/127-ethics-in-action.",60027086,The University of Alabama at Birmingham,Birmingham,United States,"['1712', '1709', '1707', '1705']",19.333333333333332,0.05192307692307692,0.3386094674556212,1
869,869,Using Shuffled Frog-Leaping Algorithm for Feature Selection and Fuzzy Classifier Design,"Abstract: This paper considers a new approach for designing fuzzy rule-based classifiers. To optimize the parameters of classifiers, a continuous shuffled frog-leaping algorithm is applied. On a set of constructed classifiers, the optimal classifier is selected in terms of the accuracy and the number of features used, using the statistical Akaike informational criterion. The efficiency of the proposed approach is tested on 15 KEEL data sets. The results are statistically compared with the results of similar algorithms. The new approach to designing fuzzy classifiers proposed in this article makes it possible to reduce the number of rules and attributes, thereby increasing the interpretability of classification results.",60010892,Tomsk State University of Control Systems and Radioelectronics,Tomsk,Russian Federation,['1700'],17.666666666666668,0.06818181818181818,0.5772727272727273,1
870,870,"Communication Protocol Application for Enhanced Connectivity of Sensors, Machines and Systems in Additive Manufacturing and Production Networks","The connection between sensors, systems and machines in the production environment enables new concepts to increase quality or flexibility. Integrated sensors can measure machine performance parameters. The measurements serve for monitoring of process stability and quality or for affecting production planning through a new agile routing. To realize the new concepts, data needs to be transmitted from the sensors to a data management system, where the collected data can be analyzed and stored. The communication between sensors, machines and systems is a central aspect and, therefore, a big challenge. There exist different protocols to enable communication, but choosing the proper protocol for a special use case is difficult. There does not exist a method that supports the choice of the protocol depending on the initial situation and the user’s preferences. Therefore, the aim of this paper is the development and implementation of a method that supports the selection of a communication protocol in an Industrie 4.0 surrounding for enhanced connectivity between sensors, systems and machines in the production depending on the individual initial situation and the personal preferences. After a short motivation and state of the art, two use cases are described and the development of the concept is explained. The following implementation shows the realization of the concept and enables the use of the concept on the two use cases. The paper ends with a conclusion and outlook.",60011226,Technische Universität Darmstadt,Darmstadt,Germany,"['1710', '1705']",20.818181818181817,0.047889610389610385,0.3646915584415584,1
871,871,Evaluation of a structured design methodology for concurrent programming,"Learning how to design and implement a program is hard. Teaching methods and textbooks on Java programming often treat a new subject in terms of syntax and examples. Little attention is paid to systematically designing programs with these new concepts. Research has shown that such a complex task requires not only conceptual knowledge, but also explicit procedural support. In this paper, we investigate the effect of combining conceptual and procedural guidance to teaching and learning concurrent programming. We build on earlier research in which we have introduced such a structured design methodology which divides the development of multi-threaded Java programs into a sequence of explicit, manageable steps: The Steps Plan. We present our experiences with applying the Steps Plan in an introductory course on object-oriented programming, with multithreading. The main questions addressed are: ""What problems did the students encounter in direct relation to the Steps Plan?"", and ""What general problems surfaced?"" As to the first question, two important issues were that using a relatively far developed sequential solution as a stepping stone towards a multi-threaded solution wrong-footed some students, and that remedying race condition situations turned out to be supported at a too high level of abstraction. As to the second question, two notable issues were that deciding on the right amount and type of concurrency by themselves is maybe too difficult for students at this level, and that the notion of (establishing) correctness or quality of a solution is, different from the sequential case, not intuitively clear to students. For these issues, the paper recommends remedies and indicates directions for future work. We discuss the consequences for education as regards teaching materials and forms of teaching.",60032882,Technische Universiteit Eindhoven,Eindhoven,Netherlands,"['1712', '1709', '1707', '1705']",25.181818181818183,0.03997211122211123,0.4898001998001998,1
872,872,Realising angelic designs using logiak,"ANGELIC is a methodology for encapsulating knowledge of a body of case law. Logiak is a system intended to support the development of logic programs by domain experts, and provides an excellent environment for the rapid realisation of ANGELIC designs. We report our use of Logiak to realise ANGELIC designs, using both Boolean factors and factors with magnitude.",60099006,Weightmans LLP,Birmingham,United Kingdom,['1702'],19.333333333333332,1.0,1.0,1
874,874,Evaluating the Smart Readiness and Maturity of Manufacturing Companies Along the Product Development Process,"Nowadays, manufacturing industries are compelled to go down the river of Industry 4.0 to either become or remain competitive on the market: in this context digital technologies represent the most important means for manufacturers to drive their transformation. However, investing in this kind of technologies could be not enough to go through this transformation in an effective way: manufacturers need to realize which is their actual digital status and at the same time to evaluate how they support their product development process. In addition, it has not to be neglected the importance of how the process of product development is organized and managed throughout the several functions involved. So far, different methods and maturity models have been proposed in literature to help practitioners to evaluate the readiness and maturity of either their smart level or their design and engineering process. Nevertheless, a suitable combination of these tools still needs to be implemented to fully and systematically measure and gauge a company under a PLM and digital perspective: to do this, a case study has been conducted.",60023256,Politecnico di Milano,Milan,Italy,"['1710', '1705']",35.2,0.17554563492063496,0.45042162698412697,1
875,875,A Conceptual Model of Self-Consciousness for the Sign World View of an Intelligent Agent,"Abstract: This article deals with the problem of self-consciousness modeling for intelligent agents with a sign world view. A conceptual model of self-consciousness is proposed, which includes a description of the “I” sign components and the typology of its relations with other signs of the world view. The empirical research of the “I” sign semantic component was conducted using the “RSA machine,” which enables a deep linguistic analysis in the interests of socio-humanitarian sciences, and the results of the research are presented. It is concluded that a certain role behavior (e.g., a victim or a successful self-manager) affects a person’s unconscious use of predicates with some semantics.",60110807,Federal Research Center Informatics and Management of the Russian Academy of Sciences,Moscow,Russian Federation,['1700'],26.75,0.22053571428571428,0.4308035714285714,1
876,876,Combining textual and visual information for typed and handwritten text separation in legal documents,"A paginated legal bundle is an indexed version of all the evidence documents considered relevant to a court case. The pagination process requires all documents to be analysed by an expert and sorted accordingly. This is a time consuming and expensive task. Automated pagination is complicated by the fact that the constituent documents can contain both typed and handwritten texts. A successful auto-pagination system must recognise the different text types, and treat them accordingly. In this paper we compare methods for determining the type of text data contained within paginated bundle pages. Specifically, we classify pages as containing typed data only, handwritten data only, or a mixture of the two. For this purpose, we compare text classification methods, image classification methods, and ensemble methods using both textual and visual information. We find the text and image based approaches provide complimentary information, and that combining the two produces a powerful document classifier.",60020661,University of Liverpool,Liverpool,United Kingdom,['1702'],16.77777777777778,0.08636363636363638,0.7136363636363636,1
877,877,On constructing a knowledge base of Chinese criminal cases,"We are developing a knowledge base over Chinese judicial decision documents to facilitate landscape analyses of Chinese Criminal Cases. We view judicial decision documents as a mixed-granularity semi-structured text where different levels of the text carry different semantic constructs and entailments. We use a combination of context-sensitive grammar, dependency parsing and discourse analysis to extract a formal and interpretable representation of these documents. Our knowledge base is developed by constructing associations between different elements of these documents. The interpretability is contributed in part by our formal representation of the Chinese criminal laws, also as semi-structured documents. The landscape analyses utilizes these two representations and enables a law researcher to ask legal pattern analysis queries.",60030612,"University of California, San Diego",San Diego,United States,['1702'],19.0,-0.17499999999999996,0.44999999999999996,1
878,878,Development of a Valuation Method for IoT-Platforms,"A production facility enables the collecting of many different data with existing machinery. One reason for this are modern machines, which are usually equipped with cyber-physical-systems (CPS). CPS are the basis of Industry 4.0 and enable machines to collect and transfer data by using sensors and a communication interface. The IoT-platform can visualize and analyse the data collected. This enables production to be optimized by detecting and minimizing weak points. Due to the topicality of this topic, there is a large variety of platform providers on the market. However, the IoT-platforms of the different providers have different strengths and weaknesses. In order to be able to keep track of existing IoT-platform solutions and to be able to better point out advantages and disadvantages, this paper presents a method that supports the suitability and choice of an IoT-platform solution. For this reason, a method will be developed which is based on a matrix in which selected IoT-platform solutions are listed. In addition, criteria for evaluation are detected and an evaluation scheme is integrated. Based on the evaluation the method determines a suitable IoT-platform by taking the customer needs into account. After a brief introduction and portraying the state of the art, the concept of the evaluation matrix is followed by an outlook and a short summary.",60011226,Technische Universität Darmstadt,Darmstadt,Germany,"['1710', '1705']",17.916666666666668,0.14464285714285713,0.48199404761904757,1
879,879,Key factors of customer-supplier of smart manufacturing implementation,"The paper presents a conceptual framework of the key factors of customers and suppliers in the implementation of smart manufacturing in the company. The field of the study related to competitiveness through cutting-edge technologies related to the Industrial Revolution 4.0. Hence, it shows accurate and effective decision-making in real-time from the smart manufacturing implementation. This comes together with the converging of the actual manufacturing technologies as an aid for the operations and productions. On the conceptual development, the journal articles, conference proceedings, books, dissertations, online news and newspaper, magazines related to smart manufacturing have been analyzed. A critical review creates an appropriate conceptual framework with the relationships of the key concepts of the link between customers and suppliers for the smart manufacturing implementation, as a contribution to the body of knowledge.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],21.833333333333332,0.1683673469387755,0.6146258503401361,1
880,880,Beyond Consent: A Right-to-Use License for Mutual Agency,"Digital apps and services handle consent and other types of permissions in structurally and practically flawed ways. Consent as conceived of in data protection regulation cannot express all of the dimensions of Internet-enabled relationships. Moreover, ""consent"" is a poor descriptor for the type of relationship trust assessment people perform in these circumstances. What's needed is a method to enable true mutual agency between any two parties in an Internet-enabled relationship. We propose a right-to-use license for access permissions as a practical alternative to consent and contract as used today, and a taxonomy that classifies important types of permissions. We also examine new data sharing scenarios, including decentralized identity, that may support their use.",60000251,IEEE,New York,United States,['1705'],18.833333333333332,-0.019805194805194794,0.5113636363636364,1
881,881,Design decisions under object-oriented approach: A thematic analysis from the abstraction point of view,"Many authors consider abstraction as one of the key principles in objected-oriented approach, but the ability to abstract is very difficult to achieve. Specifically, during the software design stage, abstraction allows in a software architecture decrease the complexity and achieve a more efficient decomposition. However, despite its importance and difficulty, there is a lack of theoretical or empirical research that explores how to enhance such ability. In this paper, we report the results of a research that was undertaken in order to address this gap in the body of knowledge. Particularly, we conducted a qualitative study through a thematic analysis to explore how students apply abstraction during the object-oriented software design. Our results reveal that during the modeling of the problem domain in Unified Modeling Language (UML), students express a deficiency of abstraction, being the possible causes: Strict copy of reality to software, influence of structured approach, tendency to simplification, and lack of understanding of the concepts of object-oriented approach.",60105012,Yachay Tech,Urcuqui,Ecuador,"['1712', '1709', '1707', '1705']",26.666666666666668,0.06166666666666666,0.5033333333333333,1
882,882,On logical and mereological renderings of the Bayes theorem," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).1 The Bayes theorem published posthumously as the work of Rev. Thomas Bayes (1701/2-1761) in 'Essay Towards Solving a Problem in the Doctrine of Chances' (1764) rediscovered by Lagrange, provides a foundation for some areas of Artificial Intelligence like Bayesian Reasoning, Bayesian Filtering etc. It had been reformulated in logical terms by Jan Lukasiewicz (1913). Recently, an abstract version couched in mereological terms was formulated and a strengthening of it appeared derived from the Stone representation theorem for complete Boolean algebras. It is our aim to comprehensively present those approaches with emphasis on the abstract setting of mass assignments on mereological universes endiwed with rough inclusions induced by masses of things.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],24.6,0.01875,0.4125,0
883,883,RenVoi in private international law: A formalization with modal contexts,"The paper deals with the problem of formalizing the renvoi in private international law. A rule based (first-order) fragment of a multimodal logic including context modalities as well as a (simplified) notion of common knowledge is introduced. It allows context variables to occur within modalities and context names to be used as predicate arguments, providing a simple combination of meta-predicates and modal constructs. The nesting of contexts in queries is exploited in the formalization of the renvoi problem.",60012259,Università degli Studi di Torino,Turin,Italy,['1702'],19.5,-0.075,0.3080357142857143,1
884,884,Blockchain Research beyond Cryptocurrencies,"One of the key requirements of a properly functioning digital society is the implementation of a decentralized identity management scheme through which the identity of every citizen can be uniquely determined. Specifically, we believe what is required is for a PKI to be deployed at a global scale. A PKI consists of a collection of digital certificates that cryptographically bind an individual's identity to their public key. In this article, we present an overview of our recent work in the areas of identity management and privacy, with specific emphasis on the deployment of a blockchain backed PKI. Once a PKI is in place, we are in a position to perform a number of common network tasks much more securely and efficiently than we can do currently.",60011149,Trinity College Dublin,Dublin,Ireland,['1705'],25.2,0.0609375,0.37135416666666665,1
885,885,Modular Product Variety Generator Based on the Modified Genetic Algorithm: A Lego Plane,"Mass customization is a business strategy that aims at satisfying individual customer needs and provides them a large product mix. To achieve this goal, it is necessary to manage the product life cycle activities especially the volume and variety of products which have to be easily customizable. Designing modular products increases the possibility of obtaining customizable products. The modular design consists of breaking down a product into more or less independent sub-elements called modules. This paper focuses on setting up a Genetic-based automatic product variants generator. The product used as the testbed is a LEGO plane composed of bricks. Different operators are used for selection, crossover and mutation of genes. Each final plane assembly is qualified based on some criteria to respect pre-defined constraints. The obtained final assemblies are discussed at the end of the paper to highlights future challenges.",60070321,Ecole Nationale d'Ingenieurs de Sfax,Sfax,Tunisia,"['1710', '1705']",15.555555555555555,0.09467120181405896,0.5976757369614513,1
886,886,Digital Twin – Integrating Cloud Services into Communication Protocols,"The Digital Twin is the following development of ongoing improvements in communicational technologies, decreasing hardware costs and the need for products with decentralized decision-making abilities. In order to improve the qualities of decisions, there is the requirement for an easy, reliable way to transport data between Digital Twins, even if the network connection has a low bandwidth or is unstable. As a solution, the use of a cloud service as a broker architecture is described. A concept for communication architecture is given as well as the required design of a Digital Twin. The proposed concept has been implemented to assess the resulting advantages and limitations.",60012881,Universidade Metodista de Piracicaba,Piracicaba,Brazil,"['1710', '1705']",21.0,0.07222222222222223,0.20555555555555557,1
887,887,A Property Graph Data Model for a Context-Aware Design Assistant,"[Context] The design of a product requires to satisfy a large number of design rules so as to avoid design errors. [Problem] Although there are numerous technological alternatives for managing knowledge, design departments continue to store design rules in nearly unusable documents. Indeed, existing propositions based on basic information retrieval techniques applied to unstructured engineering documents do not provide good results. Conversely, the development and management of structured ontologies are too laborious. [Proposition] We propose a property graph data model that paves the way to a context-aware design assistant. The property graph data model is a graph-oriented data structure that enables us to formally define a design context as a consolidated set of five sub-contexts: social, semantic, engineering, operational IT, and traceability. [Future work] Connected to or embedded in a Computer Aided Design (CAD) environment, our context-aware design assistant will extend traditional CAD capabilities as it could, for instance, ease: (1) the retrieval of rules according to a particular design context, (2) the recommendation of design rules while a design activity is being performed, (3) the verification of design solutions, (4) the automation of design routines, etc.",60114689,LCPI Laboratoire de Conception de Produits et Innovation,Paris,France,"['1710', '1705']",26.714285714285715,0.04642857142857143,0.43285714285714294,1
888,888,Neuro-fuzzy model in supply chain management for objects state assessing,"This article considers the task of objects state assessing in conditions of uncertainty by considering the supply chain strategy. To solve it, the need to use fuzzy-production knowledge bases and fuzzy inference algorithms as part of fuzzy decision support systems is being updated. As a tool for constructing a knowledge base, a neural-fuzzy model is proposed. The proposed type of fuzzy-production rules and the logic inference algorithm on rules for objects state assessing are described. A structure of a fuzzy neural network, consisting of six layers, each of which implements the corresponding stage of the logic inference algorithm, is proposed. As a result of training a fuzzy neural network, a system of fuzzyproduction rules is formed, which make up the knowledge base of the decision support system for objects state assessing. On the basis of the proposed neuro-fuzzy model, a software package has been implemented for automating the processes of forming fuzzy-production rules. The main components of the software package are the knowledge base generation module and the fuzzy inference module. As an approbation of the neuro-fuzzy model, the formation of fuzzy rules for assessing the state of water lines at the cluster pumping stations in reservoir pressure maintenance systems has been carried out. The testing results confirmed the high efficiency of the neural-fuzzy model and the possibility of its practical use for the formation of fuzzy-production rules in various subject areas of human activity.",60088527,Kazan National Research Technical University named after A. N. Tupolev -KAI,Kazan,Russian Federation,['1710'],23.5,-0.20444444444444448,0.6451851851851852,1
889,889,Checking MTL properties of timed automata with dense time using satisfiability modulo theories," All rights reserved.We investigate a new SMT-based bounded model checking (BMC) method for the existential part of Metric Temporal Logic (MTL). The MTL logic is interpreted over linear dense infinite time models generated by timed automata with dense time. We implemented the new SMT-based bounded model checking technique for MTL and as a case study we applied the technique to the analysis of the Timed Generic Pipeline Paradigm and Timed Train Controller System, both modelled by a network of timed automata.",60024421,Uniwersytet Warminsko-Mazurski w Olsztynie,Olsztyn WM,Poland,['1700'],27.333333333333332,0.0909090909090909,0.30303030303030304,0
890,890,Estimation of innovative clusters efficiency based on information management and basic models of data envelopment analysis,"Clusters and information management play an increasingly important role in the innovative development of regions and operational management. With the help of such structural entities, socially significant issues are being addressed, infrastructure development of the territories is being carried out, the investment climate is improving and various innovative projects are being implemented, new products, services, technologies are being created, the level and quality of life of the population is being raised. In our research we analyzed 24 innovative clusters created in the Russian Federation with the participation of the Ministry of Economic Development. We used econometric and statistical research methods. We analyzed financial investments made by both private investors and the state in the formation and development of clusters. After that, we compared the output parameters with the input financing and, based on the data envelopment analysis method, calculated the relative efficiency of the innovation clusters. We have identified 3 cluster benchmarks and made recommendations for improving the management system of the other clusters.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],23.428571428571427,0.1775974025974026,0.5199675324675325,1
891,891,The Integration of True Lean and Industry 4.0 to Sustain a Culture of Continuous Improvement,"Recent advances in information and communication technology and the Internet of Things (IoT) are driving the development of Industry 4.0. Its objective is to enable real-time information exchange between people, machines, products and resources, providing new opportunities for improved safety, quality, productivity and cost factors which can be applied in all stages of Product Lifecycle Management (PLM). The application of lean principles and practices where Industry 4.0 is deployed can leverage real-time processing visibility into even greater productivity improvements if implemented correctly. To do this, companies need to go beyond the implementation of the familiar lean tools and practices such as 5S, visual management and management directed kaizen activities etc. to consider the thinking behind the tools, especially the role of the team members. An over-reliance on technology risks undervaluing the importance of human innovative capacity which can significantly impact the ability to conduct systematic problem solving, adversely effecting daily operational performance and significantly reducing continuous improvement (CI) capacity. This conceptual paper introduces the major elements and thinking of the Toyota Production System (TPS), also referred to as ‘True Lean’, which are often hidden or underdeveloped within the popular understanding of lean. This paper illustrates how TPS-thinking can be operationalized to support and sustain a CI environment while leveraging the improved visibility possible with Industry 4.0 to integrate all stages of PLM.",60015941,University of Kentucky,Lexington,United States,"['1710', '1705']",27.75,0.14248405103668263,0.538835725677831,1
892,892,Condition Monitoring of Interconnecting Transformer Through ANN Approach,"In present day world, every economy is dependent on electrical energy. This electricity generated & its consumption should always remain in equilibrium because storing high amount of electricity is neither economical nor practically easy to achieve. Hence generation & consumption should match at all times. Power sector all around the world is focusing more in making power system more efficient, economically viable and more reliable. For this many changes have been made in power system. A proper forecast of demand of electricity by consumer will be important for planning, for power market, for power market operation, for system design and for security of supply which for the operation of Electricity Company is very crucial.",60104102,Jabalpur Engineering College,Jabalpur,India,"['1705', '1710']",19.0,0.29944444444444446,0.6061111111111112,1
893,893,A fuzzy set tool in the classification and prediction software system (CLAPSS)," Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).In the paper, we give the outline of a fuzzy set tool implemented in the Classification and Prediction Software System (CLAPSS). CLAPSS is being developed for solving different classification and prediction problems using, among others, some specialized approaches based mainly on fuzzy sets and rough sets which are not available in other machine learning software systems. Theoretical background as well as the module embedded in CLPASS, for fuzzification of attribute values in information/decision systems, are described. Moreover, possible further steps in the usage of CLAPSS (generation of fuzzy decision trees as well as fuzzy flow graphs) are mentioned.",60007672,University of Rzeszów,Rzeszow,Poland,['1700'],27.5,0.031060606060606056,0.45530303030303027,0
894,894,Computing with natural numbers in cause-effect structures," All rights reserved.Implementation of the standard model of natural numbers arithmetic is constructed in terms of cause-effect (c-e) structures. The numbers are represented by sets of (unstructured) tokens at nodes of the c-e structures, so the unary coding of numbers is applied. Such modelling of arithmetic operations is possible due to the inhibiting capability in the c-e structures. The exact cost of the typical operations modelled by c-e structures constructed in this paper, is computed.",60112534,"University of Warsaw, Institute of Informatics",Warsaw,Poland,['1700'],19.0,0.008333333333333335,0.4321428571428571,0
895,895,Socialization agents for children,Children are important segment for marketers. Children these days are actively involved in the purchase process and are no more a passive users. Their voice is being recognized as a purchaser. They are both the purchaser of the products as well as the influencer. They have information about the market and various products in the market. There are many agents that contribute to the socialization process of the children. Both interpersonal and environmental agents play some role in the learning of the child. This paper attempts to analyze the various socialization agents for children. The study was conducted on 190 children in the age group of 6-12 years of age. The data was collected using structured questionnaire. The questionnaire was administered to the parents. The area of the study was Delhi.,60076774,"Amity University, Noida",Noida,India,['1700'],10.916666666666666,0.08611111111111112,0.6,1
896,896,Software development for cutting tool routing problems," Published by Elsevier B.V.Lots of studies on tool paths for cutting machines mainly deal with contour by contour cutting. While constructing a path one needs to determine the pierce point and the direction of contour passing. In this case only the length of idle passes may be optimized. To solve this problem generalized travelling salesman problem (GTSP) approach is used. Resource-efficient technologies for cutting sheet materials allow for the contours of cut-off details to be overlapped. It allows reducing the material waste and shortening the length of cuts. Common cuts are also the origin of one more set of precedence constraints. These constraints can be formalized as one general formal restriction called as Ordered Enclosing (OE) for plane graphs that are the homeomorphic images of the cutting plan. In this report we consider the common case of a cutting problem when combination of contours is allowed. We review the polynomial algorithms for all the possible restrictions: (1) part cut off a sheet does not require further cuts (constructing of OE-route); (2) there are no intersections of cuts (constructing of NOE-route); (3) there are some restrictions on placement of pierce points (constructing of PPOE-cover). Our paper considers software that, according to the cutting plan, allows to get a homeomorphic image of the graph to solve the routing problem, solves this problem and interprets the results of the solution.",60008009,South Ural State University,Chelyabinsk,Russian Federation,['1702'],20.727272727272727,-0.2770833333333333,0.7020833333333334,0
897,897,Effect of material hybridization on the strength of scarf adhesive joints," Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Adhesively-bonded joints have become more efficient due to the improvement of adhesives' characteristics. On the other hand, with the use of composites in structures it is possible to reduce weight. Due to this, new techniques are being explored, including adhesively-bonding different materials. Nowadays, in many high performance structures, it is necessary to combine composite materials with other light-weighted metals such as aluminium or titanium. This work reports on an experimental and numerical study for hybrid scarf joints between composite and aluminium adherends, and considering different values of the scarf angle (a). The numerical analysis by Finite Elements (FE), using the software Abaqus®, enabled the obtainment of peel (sy) and shear stresses (txy), which are then used to discuss the strength between different joint configurations. Cohesive zone modelling (CZM) was used to predict the joint strength and the results were compared to the experiments for validation. The joints' behaviour was highly dependent on a, and CZM were validated for the design process of hybrid scarf joints.",60013981,Institute of Science and Innovation in Mechanical and Industrial,Porto,Portugal,['1702'],20.11111111111111,0.06213903743315508,0.5432085561497326,0
898,898,"Monument of Ludovico Ariosto in Ferrara, Italy: Conservation of architectural surfaces and structural consolidation","The iconic Renaissance monument in Ferrara was requested by Duke Ercole I d’Este at the end of the 15th century for the “Piazza Nova” of the Erculean Addition. The project comprised an equestrian statue of the Duke positioned on two monolithic columns with a pedestal, capitals and trabeated system. The project was never completed except for the 10 m monolithic column, upon which statues of Pope Alexander VII (1675), Napoleon (1810) and, finally, Ludovico Ariosto (1833), the symbolic Ferrarese poet were placed. The project involves the removal of recent interventions which were structurally and aesthetically invasive: lowering the statue using a specially designed engineering technique; disassembling the 11 st components of the capital due to oxidisation of the metal connectors; replacing the oxidised parts with new connectors; controlled cleaning of the surfaces; integration with mortars made on-site with natural and sustainable materials. The purpose of this project is to restore the cleaner and safer Monument of Ludovico Ariosto to the community through a “critical restoration”, based on historical knowledge.",60000481,Università degli Studi di Padova,Padua,Italy,['1706'],33.8,0.10761183261183262,0.4834415584415584,1
899,899,Seismic and non-seismic analyses to preserve a cultural heritage Masonry building,"Romanian earthquakes in 1940 and 1977 produced severe damage to a significant number of buildings whose plans were characterized predominantly by irregularities like flexible diaphragms, structural discontinuities or L and H shapes, among others. These conceptual characteristics contributed in a decisive way to the damage or collapse of buildings designed and built according to the old seismic codes. On the other hand, European and international experience of previous strong earthquakes during the last decade shows that, in many urban areas, besides many old building, there is a number of modern RC buildings that do not meet the requirements of additionally improved codes for seismic-resistant design. The paper studies the behaviour of a masonry building under seismic and non-seismic actions, giving a practical and applicable interpretation of the dynamic amplification concept at the upper part of masonry buildings. Dynamic amplification effects, the types of damage and the variation of the structural rigidity after the consolidation works (compared to the initial situation), were evaluated. With respect to the instrumentation of micro-vibrations, the results obtained from the processing of the recorded micro-seismic data from 2019 emphasize the changes of the natural oscillation periods characteristic of the two directions, after applying the consolidation solution. This indicates an increase in rigidity obtained by reinforcing the building and, at the same time, it can be appreciated that the structural transfer of efforts has been made from the old structure to the new structural system. The work concludes that, in order to obtain correct information regarding the behavior of a structural system (due to the lack of data needed to create a reliable model), the contribution of each presented method is consistent, using the advantages of non-destructive methods and ambient/micro-seismic vibration monitoring.",60003012,Universitatea Tehnica de Constructii Bucuresti,Bucharest,Romania,['1706'],35.625,0.10045454545454545,0.2648484848484849,1
900,900,Research on consensus control of UAVs formation in distributed network: Algorithms and global convergence analysis," All rights reserved.For the research on consensus control of multi-agent systems formation in distributed network, aiming at the problem that communication delay effects may arise naturally which may destabilize a stable system, most researchers study on the performance of multi-agent systems with communication delay and the algorithms of delay robust control. However, in these studies, the researchers did not comprehensively consider network protocols, cooperative control mechanisms and application scenarios to design the system globally, so the results have serious limitation. In this paper, we take the typical application scenario, battlefield, as the background environment, we selected appropriate network protocols and cooperative control mechanisms based on scene analysis. Further, we build the communication delay model based on the cooperative control mechanisms and network protocols, and then, we design delay robust mechanism based on the delay model. Finally, we propose the two-hop cooperative control mechanisms oriented to the constraints of application scenario and network model, and we complete the stability analysis. The numerical examples and experiment are provided to illustrate the correctness of the results.",60022381,Beijing Jiaotong University,Beijing,China,"['1712', '1709', '1707', '1705']",29.0,0.07777777777777778,0.4962962962962963,0
901,901,"Historical heritage as a tourist resource: The case of the province of CÁdiz, Spain","This article has the purpose of analyzing the tourist situation of the historical heritage in the municipalities of the province of Cádiz, considering the need for this type of offer and the obligation to make changes in the management and planning of these resources. The objective of this study is to analyze the tourist use of heritage, its perception by society and the proposal for improvements. All the results presented are the product of a more extensive preliminary research on tourism in the province carried out at the University of Cádiz (Spain). The tourist functionality of historical assets has been studied through the use of different tools that combine the quantitative with the qualitative. At the provincial level, a total of 1,049 assets have been documented, representing an average of 23.84 assets per municipality. With the results obtained, a SWOT has been designed to facilitate the elaboration of proposals and conclusions, whose purpose is to redefine the planning and management of the goods, guaranteeing their sustainability and contribution to the diversification of the tourist offer.",60016476,Universidad de Cadiz,Cadiz,Spain,['1706'],29.166666666666668,0.04375,0.33541666666666664,1
902,902,Reading the research: Publications on vernacular architecture,"The aim of this study is to analyze the general profile of articles written on the subject of “vernacular architecture” (VA). The study integrates articles posted on the Web of Science database. In the first part of this study, all English language articles scripted between 2000 and 2018 and in the second part, articles listed under architecture category have been examined. Articles were analyzed based on their publication year, journals, categories, keywords and method and obtained data were analyzed via content-analysis method. Research findings manifest that VA is interlinked with a wide array of disciplines ranging from architecture-engineering sciences to art, archeology and geography. Once all of these categories are examined, it can be argued that, in general, local architecture is analyzed by associating it with environmental issues and building-physics subjects. Researchers claim that analyzing local production techniques and, based on these techniques, developing local, effective strategies is a salient research method. In the architecture category, the most widely-analyzed scale was detected as region scale; the most discussed location was Iran in the global scope. One of the featured titles in these studies is on the subject of thermal comfort. Another common subject in these articles is detected to be sustainability and matters related to sustainability. Aside from the subjects and concepts examined in these studies, another issue is the motives with which analyzed subjects were associated. Here, compiled data reveal that studies related to VA offer three key motives. The first one is protecting, the second one is learning and the third one is developing.",60086558,Ozyegin University,Istanbul,Turkey,['1706'],19.692307692307693,0.056521739130434775,0.3115942028985507,1
903,903,"Structural analysis of wood trusses of San Paolo Fuori Le Mura, Rome, Italy","The Roman double trusses of San Paolo fuori le Mura (FLM) are the oldest long-span Roman trusses for which sufficient information exists to perform a structural analysis. Span, spacing, and scantlings of members were recorded previous to the loss of the trusses due to a catastrophic fire in 1823. Wood species type can be inferred from comments by Pliny the Elder regarding other long-span trusses in ancient Rome. While the quality of the wood cannot be determined, the analysis results can be bracketed using allowable stresses from different wood visual grading standards. Dead and live loads can be estimated using loadings developed for current engineering practice. Quantifying the levels of stresses in the trusses of San Paolo FLM indicates a relatively conservative design. Stresses in the rafters, or upper chords, were reduced by the insertion of a collar strut providing an intermediate support to the upper chords. Even if it is assumed that timbers matching visual grade DF/L No. 2 were used, the combined flexural and axial stresses in the upper chords are well within those permitted by modern design standards.",60029653,Kent State University,Kent,United States,['1706'],20.11111111111111,-0.011268939393939397,0.21354166666666663,1
904,904,"Mechanical properties of rock units from the Pompeii Archaeological Site, Italy","The definition of compatible conservation interventions on the archaeological built asset requires a comprehensive knowledge of physical, chemical and mechanical properties of the ancient masonry structures and their components. However, information on the mechanical properties of units, mortars and masonry assemblages are still lacking especially with reference to one of the most popular UNESCO World Heritage Sites in Italy, the Pompeii archaeological site. Thus, the paper focuses on the mechanical characterization of original rock specimens collected within the new archaeological excavation work area in Regio V of the Pompeii site. Ultrasonic pulse velocity tests (UPV) and Schmidt hammer rebound test were carried out on ten units of three different rock types: three travertine, five lava and two foam lava (i.e. “calcare del Sarno”, “lava” and “cruma”). Then, UPV were carried out on 51 cubic specimens obtained from the cut of the units, both at ordinary moisture content and after drying. Finally, uniaxial compression tests were carried out on 32 cubic specimens. In the following, the results of non-destructive tests are discussed and compared with those provided by destructive tests in terms of compressive strength.",60017293,Università degli Studi di Napoli Federico II,Naples,Italy,['1706'],23.0,0.05075757575757576,0.43649350649350643,1
905,905,"Heritage significance of late 19th and early 20th century buildings in the Buganda Kingdom, Uganda","The paper sets out to investigate the heritage significance of four late 19th and early 20th century buildings in Buganda capital of Mengo. The buildings, Keweerimidde House (1890s), Basiima House (1902), Chwa Building (1904), and Muteesa I Dormitory (1904), were built during an extraordinarily tumultuous period in the history of the Kingdom which no doubt had an impact on the buildings that were constructed, and their subsequent use over the years. The exploration is undertaken through an approach that combines two exploratory techniques: values and narratives. These are used to investigate the many tales that surround these buildings, while reflecting on the socio-political developments of the period, which also influenced their commissioning and construction. This led to a better understanding of the embedded relationship between the specific buildings and the stories that are often neglected in discourse of heritage in the context of Uganda. A key part of the study was the documentation of the four buildings, which revealed a further dimension of heritage studies, such as cultural changes in Buganda during the period under question. Through this evaluation, the paper seeks to contribute to the understanding and appreciation of architecture of this period, while at the same time building a documented inventory of these buildings.",60116805,Uganda Martyrs University,Kampala,Uganda,['1706'],29.428571428571427,0.09487179487179488,0.4076923076923077,1
906,906,"Preventive preservation of cultural heritage within a hot and humid climate: A case study of Tainan Confucian Temple, Taiwan","We took the example of the Tainan Confucian Temple to explore preventive preservation of Taiwanese cultural assets within a hot and humid climate. We mainly used microclimate monitoring data and computational fluid dynamics simulation to analyze the overall environment and identify problem areas, which were shown by the results to be the Ritual Implement Storeroom and Musical Instrument Storeroom. The latter had the highest humidity due to a mango tree located at the rear with a canopy stretching 4–6 m across the roof, which blocked the sunlight during the day and prevented any reduction in humidity. This storeroom includes the original calligraphic wall panels and central beam of the Minglun Hall; therefore we propose measures to improve the current environment without modifying the building materials or structures. First, we suggest either changing the display items or shifting the exhibition area, and transplanting or pruning the mango tree. Second, dehumidification or ventilation equipment should be placed not only in the Musical Instrument Storeroom, but also in the Chung Sheng Shrine and Ta Cheng Palace at night during the hot season, and in the Ritual Appliance Storeroom in the day during the cold season, to improve environmental problems.",116791287,Ministry of Culture,Taichung,Taiwan,['1706'],32.66666666666667,0.0392156862745098,0.3730392156862745,1
907,907,19th century salt baths of Transylvania,"The cultural concept called the Salt Road is closely related to the connection between salt and salt mining throughout their multimillenary historical development in view of the economic, demographic and territorial impact on the settlements, in comparison with the revenue resulted from the exploited amount of salt and the earned income, to which the hydropathic character is added during the 19th century, which transforms and freshens the cultural tradition of the use of salt in the development of the settlements. The Romanian research remained due to the elaboration of a detailed analysis of the historical, vernacular and vacationer architectural patrimony. The spa-oriented feature had become part of an extended tendency aimed at enhancing the value of existent spa resources in Transylvania and Europe in the late 19th century. The endeavour to turn to good account the balneary potential in Transylvania used to be productive and attractive in its early days and the importance of the spas was significant and beneficial to the inhabitants. The awareness and deep insight into the past through the promotion and presentation of its history are intended, not only in order to protect the originality and peculiarity of the cultural and historical site, but also to inspire future generations.",110095229,University of Arts,Iasi,Romania,['1706'],40.6,0.11000000000000001,0.40875000000000006,1
908,908,Analysing the impact of comprehensive refurbishment policies on social and heritage protection issues,"Urban regeneration and housing refurbishment policies have prioritised integral interventions in the last few decades by considering together energetic efficiency, accessibility and safety issues. However, the increasing complexity of this approach can lead to the weakening of other important aims such as heritage protection or addressing social vulnerability. Accordingly, the objective of the paper is to analyse the evolution of current refurbishment strategies and their effects on socio-economic inequality and built-heritage conservation in order to identify deficiencies and stablish criteria to address them and improve existing public refurbishment programmes. For that purpose, variables related to each issue (refurbishment public aid, heritage preservation and socio-economic vulnerability) have been defined and analysed using GIS, overlapping data related to different variables and studying the relations between them at different scales (urban, census section and building). The city of Donostia (Gipuzkoa, Spain) has been used as a case study, where areas have been clustered according to the connection between the three aspects so that specific strategies can be developed and implemented for each case.",60027856,Universidad del Pais Vasco,Leioa,Spain,['1706'],34.0,0.03728070175438596,0.29824561403508776,1
909,909,"Using fiber-optic sensors and 3D photogrammetric reconstruction for crack pattern monitoring of masonry structures at the Aurelian Walls in Rome, Italy","This paper shows an application of the photogrammetric 3D reconstruction by SfM (Structure from Motion) technique and Fiber Bragg Grating (FBG) sensors to evaluate the long-term crack propagation and the damage evolution on the Aurelian Walls in Rome. Aurelian Walls were built between 270 and 275 A.C. by the Emperor Aureliano to defend Rome, the capital of the Empire, from barbaric attacks. Originally, they extended for about 19 km, nowadays remains are 12.5 km long and among the longest and best-preserved ancient wall murals in the world. The two adopted techniques offer complementary advantages. By the SfM reconstruction it is possible to acquire the geometry of the studied masonry structure and to detect most relevant cracks where FBG sensors can be installed for permanent monitoring. Moreover, SfM allows to acquire the crack pattern over extended surfaces and to compare its evolution with scheduled repeated measurements. FBG sensors allow continuous monitoring at selected critical locations and offer reference data for correlation of scheduled photogrammetry measurements. 3D Photogrammetric reconstruction by SfM took advantage of hardware and software capabilities of the HPC (High Performance Computing) resources available in ENEA, which are provided by the CRESCO (Research Computational Centre on Complex Systems) infrastructure. FBG sensors were installed in thermal compensation configuration and with both high stability for long-term static measurements and dynamic response capabilities. Experimental data so far acquired are presented with evidence of the preliminary results of the measurement campaign, which is planned to be continued in the long term.",60019637,"Ente Per Le Nuove Tecnologie, l'Energia e l'Ambiente",Rome,Italy,['1706'],22.454545454545453,0.15300000000000002,0.6064444444444447,1
910,910,"Structural assessment of Dubrovnik Cathedral, Croatia","In this paper a masonry baroque Dubrovnik Cathedral is analysed using the structural assessment method specific for historical buildings. The paper also describes the phases of an integrated approach to obtain accurate structure condition according to visible cracks and its seismic resistance capacity, with possible strengthening techniques. The Dubrovnik Cathedral is a masonry baroque church built in the period from 1671 to 1713. It was built in the same place where the 12th century Romanesque Cathedral had collapsed in the catastrophic earthquake of 1667. The present Cathedral is a monumental three-nave basilica with a dome over the crossing. In its lifetime the Baroque Cathedral did not show any vulnerabilities until 1979, when it was hit by another earthquake, in which the Cathedral structure was slightly damaged. After the 1979 earthquake the Cathedral was retrofitted from 1981 to 1986 with the aim of increasing the structure capacity under seismic loading. Soon after the retrofitting, cracks on the main columns of the Cathedral started to appear at its base. This was the reason a structural assessment of the Dubrovnik Cathedral was conducted. The activities for the assessment involved historical research based on the analysis of written documents and historical maps, with a focus on the previous major structural changes over the centuries. Visual inspections were undertaken to identify the location and extent of cracks and construction techniques. The assessment also included a geometrical survey of the Cathedral, which was used to develop a three-dimensional finite element model. The numerical simulations led to determining the damage distribution and to identifying the most vulnerable elements. It was used for a comparison between the numerical results and the damage survey. All this led to the conclusion and to identifying the reason for the crack occurrence on the Cathedral structure after the performed strengthening and reconstruction in 1986.",60008408,University of Zagreb,Zagreb,Croatia,['1706'],20.133333333333333,-0.031510416666666666,0.315625,1
911,911,Built heritage of the dismantled railway network: Main causes of its persistence,"The gradual deterioration experienced by the railway in the mid-20th century precipitated the dismantling of a great part of the once dense rail network, which articulated Europe and many of the most industrialized countries in the world, leaving a large set of infrastructures and buildings in disuse. In just a few decades since the closure of these lines, the existing number of buildings that formed these infrastructures has been decreasing alarmingly. From an academic point of view, most of the papers deal with the reasons for the continuous disappearance and destruction of railway heritage. The object of this article is to expose the main factors that have favoured the conservation of the buildings of those lines that have fallen into disuse, approaching from another perspective the vision of a reality in which both social and cultural aspects will play a role as relevant as architectural, technical and constructive ones. These lead us to the following question: Why are they still standing? To answer this question, more than 231 buildings from six disused railway lines which share similar characteristics, are close to each other and were part of one of the densest railway networks in Europe, such as the one in the Basque Country, have been analysed. Among them, the railway line of the Urola will stand out, due to its general state of preservation, experimented in the number, quality and conservation of its built elements. In this paper, we will present the different evidences why this line, coeval and analogous to the others and whose original buildings have remained almost the same, presents so different results from the rest. We will also determine and quantify the different indicators that could be relevant to define the possible level of recovery of the railway heritage in case of a hypothetical, future intervention, that could be extrapolated to the rest of the cases.",60027856,Universidad del Pais Vasco,Leioa,Spain,['1706'],38.75,0.15449308755760366,0.42672811059907834,1
912,912,Permitting significant harm in the conservation of heritage assets: Conflicts in sustainable land-use planning decisions,"Despite the increasingly divergent legislative framework for land use planning in England and Wales, both planning regimes are characterised by a commitment towards action and decision-taking by public bodies which contribute towards sustainable development (s.39, Planning and Compulsory Purchase Act 2004). The purpose of this is to ensure that the development and use of land facilitates economic, social and environmental progress for present and future generations. The conservation of heritage assets, in a manner appropriate to their significance, forms part of the core planning objectives upon which decisions should be made. However, assessing proposals for the repurposing of built historic assets with sustainable development principles can result in decisions which not only conflict with other aspects of sustainable development, but indeed run counter to it and its protection. This paper examines the implementation of law and policy by local authorities in appraising planning applications concerning the conversion of listed buildings. The article begins by considering the underpinning legal and policy contexts in relation to sustainable development and built heritage in England and Wales. Second, it discusses the duties on decision takers in assessing the merits of planning proposals and the discretionary character of the regimes. Last, drawing on two relevant and recent planning decisions, one of which the author, engaged as the Planning Officer was responsible for evaluating, the paper examines the application of the presumption in favour of sustainable development in proposals which seek to conserve listed buildings. The paper concludes that there is a tangible risk that prioritising the long-term conservation of listed buildings at the expense of other aspects of sustainable development and wider land use planning priorities could result in perverse and harmful outcomes to listed building themselves and to economic, social and environmental progress.",60100434,Birmingham City University,Birmingham,United Kingdom,['1706'],32.111111111111114,0.08083333333333334,0.2520833333333333,1
913,913,Multi-rate hierarchical fusion estimation of nearest neighbor clusters in sensor networks based on target tracking," All rights reserved.In order to overcome the shortcomings of low precision and high speed target tracking in wireless sensor networks, multi-rate hierarchical fusion estimation method based on target tracking is proposed. Sensors are divided into several clusters, and only the nearest cluster is used for target tracking. Each sensor detects a local estimate of the data, and then uploads it to the cluster head node for fusion to get the accurate information of the target. In order to improve positioning accuracy, strong tracking filtering (STF) estimator is used to identify time-varying structural parameters. By orthogonalizing the residual after filtering updating, the fading factor is obtained to correct the filter covariance matrix in real time, which guarantees the tracking ability of the filter to the change of structural parameters. The cluster head node uses the matrix weighted data fusion algorithm to obtain the final fusion results. The simulation results verify the effectiveness of the method.",60011592,Qilu University of Technology,Jinan,China,"['1712', '1709', '1707', '1705']",22.142857142857142,0.1325925925925926,0.5007407407407407,0
914,914,Value of wisdom through experience: Sustainable heritage,"Architectural heritage, like cultural heritage, is a very nourishing resource, providing meaning and wisdom from experience for the next generation. Without heritage, alienation, apathy and ignorance take hold. Human beings thrive from connections between past, present, and future. Yet, today, the field of architecture suffers from a lack of connection to the past. Effects from this can be seen in issues that face the field of architectural heritage, manifest through indifference, ignorance and neglect. Architecture in the past, built upon architectural heritage, both figuratively and literally. Design relied on precedence through documentation and analysis. Existing architecture found new life through adaptive reuse. There was a very comfortable and familiar interaction between old and new. Today, little reference or reverence is given to the past. This approach disengages with heritage, creating a chasm between old and new. The need for architectural heritage has become one dimensional, with a less compelling reason to care beyond an appreciation for what was once deemed valuable. These structures become artifacts of nostalgia in a museum culture. How did we get to a point where architectural heritage mattered so little? It is worth examining the trajectory of and forces behind this development, as well as the current state of architectural education. A review of the 128 accredited schools of architecture in the United States, show that there are only 22 schools of architecture that have a historic preservation component of the curriculum, and only 3 of those schools teach traditional design as a continuum from the past. Architecture schools must invest in heritage as an educational resource and engage with preservation. Through documentation, analysis and history, to learn aesthetic, construction and cultural lessons, the next generation may lead the way toward increased appreciation and reconnection with our architectural heritage.",60020444,Catholic University of America,"Washington, D.C.",United States,['1706'],17.235294117647058,-0.0011386593204774987,0.3577364554637281,1
915,915,Design of LED display screen based on soft font library," All rights reserved.In view of the shortcomings of external expansion with hard font chip in the LED display, a new solution using soft font library is presented. Taking a STC12C5410AD microcontroller as CPU, the minimum resolution dot matrix of font can be generated on demand by computer and stored in the built-in EEPROM memory of it. The new solution can effectively solve the defects of high cost, single font type and strict limitation on use caused by expanding external font chip in the LED display system.",60013789,Beihang University,Beijing,China,"['1712', '1709', '1707', '1705']",29.0,0.08551467051467052,0.3950048100048101,0
916,916,Research on the damage resistance of air transportation network based on complex network theory," All rights reserved.On the basis of complex networks theory, the robustness of China's air transportation network is measured and analyzed by random attack and planned attack under static and dynamic conditions. In the dynamic condition, a cascading Failure model is proposed, which defines the load value of nodes in the network as the node degree value and the function of the node number, and constructs the WS small world network and the BA scale-free network. It is compared with the air transport network in China. Under the different attack formula, the static condition and the dynamic condition are respectively in the different attack formula. The damage resistance of the three networks is compared and analyzed.",60108804,Baicheng Normal University,Baicheng,China,"['1712', '1709', '1707', '1705']",23.2,-0.030555555555555558,0.4333333333333333,0
917,917,Spanish social housing in the 20th century: Typological analysis of residential complexes built in Castell�n in the 1950s,"Since the 1940s, populations of Spanish cities have grown intensely, which was motivated mainly by rural emigration. In order to provide housing for such population growth, a great deal of social housing was built. The state would initially and directly control the implementation of this new urban structure by establishing a relative unitary housing typology, especially in the 1950s when most social housing legislation was introduced. These buildings, which helped shape the outskirts of cities at the time, now form part of their consolidated urban pattern, and their image shows the social character that identified these building types. At the same time, both the building image and housing typology are an anachronistic reference that needs to be intervened in order to adapt to changing life habits that today’s society demands. In Castellón, most of these social housing were carried out in the 1950s by the Obra Sindical del Hogar, an organisation that depended on the Instituto Nacional de la Vivienda, and was responsible for most of the social housing built during this period. This paper shows the results of the typological analysis of these residential complexes, which seems to indicate the obsolescence of such a housing type and, at the same time, offers valuable information to refurbish this large building stock in the city according to new users’ needs.",60002676,Universidad Jaume I,Castellon de la Plana,Spain,['1706'],31.285714285714285,0.1316177649510983,0.3007776174442841,1
918,918,Placemaking as an approach to foster cultural tourism in heritage sites,"The accelerating competition among cities brought on by globalization has resulted in a significant concern to harness cultural assets heritage recovery as a form of placemaking to establish relative competitive advantage and consequently attract more visitors and cultural tourism. It is evident that the physical heritage assets and cultural expressions play a substantial part in establishing a sense of place. Other factors related to the needs of tourists and visitors affect the degree of attractiveness and foster greater attachment to the place. In that sense, developing such heritage sites requires a comprehensive approach that considers various aspects in both tangible “physical” and intangible “unphysical” factors related to those spaces in which it creates authenticity and sense of place. This research attempts to explore the notion of placemaking as an approach for developing and conserving heritage sites, hence, promoting successful cultural tourism that balances the development between people and place. The research will consider using a qualitative approach, supported by statistical analysis through conducting a structured questionnaire for experts in the field in order to verify and weighing the importance of proposed qualities that contribute to building the suggested model. The research will result in demonstrating the proposed model of placemaking that is specialized for heritage sites, which it aims to achieve prosperous cultural tourism.",60107224,"Effat University, Saudi Arabia",Jeddah,Saudi Arabia,['1706'],30.571428571428573,0.1527777777777778,0.33531746031746035,1
919,919,Reviving craftsmanship and crafts within the context of industrial architectural heritage,"In this paper, we attempt to redefine the heritage of craftsmanship and to find out how and where it can exist alongside mass-production within our industrialized and digitalized society and within the setup of our industrial architectural heritage. This theoretical background is grounded through a design intervention that injects an urban/architectural program, with interactive public and craftsmen/designers’ spaces, within an urban hiatus that is dominated by an industrial environment of an abandoned early 20th century train station in the vicinity of the seaport of Tripoli, Lebanon. The paper starts by explaining the process of transformation of the notion of craftsmanship and its relationship with manufacturing and mass production since the industrial revolution. It then articulates the recent attempts at reviving craftsmanship through the paradigm of individuation through consumption where craftsmanship becomes not only a means of expressing individuality, but also a communal experience based on technology and digital expertise, and on the role of the designer. Then the paper moves into the design intervention in Tripoli where the revival of craftsmanship is projected onto the domain of revitalization of industrial and architectural heritage, in a place where different historical and architectural eras collapse into a number of abandoned sites and buildings, reconnected and regenerated in a new urban/architectural scheme, in an attempt at rescuing the district from the destined obsolescence it is heading towards. Finally, the paper concludes with highlighting the importance of salvaging potential socioeconomic patterns, especially in the domain of craftsmanship, through a smarter and more sustainable reclaiming of parts of the city that are belittled under the tag of “abandoned industrial sites” or “deserted industrial buildings”.",121384998,City University,Tripol,Lebanon,['1706'],44.833333333333336,0.04909090909090909,0.4180808080808081,1
920,920,"Renegotiation of metropolitan heritage in China: Yihe mansions, Nanjing","The Chinese economic reform and opening during the 1980s is not only credited for China’s modernisation – through accelerated urbanisation and its social and economic legislation – it is also acknowledged for the establishment of heritage legislation to protect Chinese cultural capital. In contrast, the consequences of these reforms are concomitantly blamed for the current imbalance between urban development and heritage protection that in the current reality favours economic growth over heritage policies. With heritage awareness on the rise, the recent government-led projects have spearheaded new directions, merging neoliberal planning and heritage protection in regeneration projects. This paper will discuss the Yihe Mansions project (), Nanjing, a regeneration project earmarked as a residential area for senior officials in the Republic of China. As one of four cases of a research programme, the Yihe Mansions case will illustrate the application of a developmental model, exploring the intricate balance between economic development, protection and contemporary lifestyles in inner urban areas. This paper also deliberates a new dialogue between decision makers and end users under the public ownership of land, exploring how the government integrates the public’s wishes as part of state-driven real estate projects. Applying unobtrusive and obtrusive research methodologies, this paper is grounded in a more holistic understanding of the renegotiation of Chinese metropolitan areas between development and protection that aims to establish a dynamic and feasible model of heritage protection in Chinese urban settings.",60025152,University of Cincinnati,Cincinnati,United States,['1706'],33.42857142857143,0.07972027972027974,0.2061188811188811,1
921,921,A multiplier design based on ancient indian vedic mathematics using reversible logic: A review,". All rights reserved.Very Large-Scale Integration (VLSI) is a technique for creating a single chip by integrating thousands of transistors that are capable of performing various operation. The most important factor to consider in the VLSI design is Power dissipation, which is a critical challenge to create a low-power and high speed circuit. Multiplier has an important function in many processor and computational applications. The system’s performance mainly depends on the multiplier circuit; so, the main goal of designing a multiplier is to reduce delay and power dissipation. Improved Vedic multiplier architecture with reversible logic can decrease power dissipation and increase a system’s speed. Optical computing, quantum computing, Nanotechnology and low power design are some of the areas of application in Reversible logic gates. Here, a detailed investigation is performed to find that reversible Vedic multiplier is foremost in terms of area, power, delay, memory and quantum-cost compared to the conventional multiplier.",60104751,Karpagam Academy of Higher Education,Coimbatore,India,['1700'],19.0,0.19136054421768706,0.5377210884353741,1
922,922,"Knowledge and interpretation processes of the AndalusÍ bath of el Nogal or BaÑuelo (ḤammĀm al-Ŷawza) in Granada, Spain (1832–2019)","The bath of the Walnut or Bañuelo (Ḥammām al-Ŷawza), in Granada (Spain), is one of the most notable and best-preserved buildings of its kind in the Iberian Peninsula, following the extensive conservation work directed by architect Leopoldo Torres-Balbás in 1927–1928. Traditionally, it has been dated to the 11th century, when a Taifa kingdom ruled by the Zirid dynasty, of Berber origin, was established in Granada. The recent restoration work carried out on it has prompted us to investigate the long process of study, characterization and valorisation of this important example of Andalusí architecture. The paper presents a broad critical analysis of this process of detailed discovery over almost two centuries (1832–2019), based on descriptions, photographs and plans. It starts with the first drawings made by the French artist J.-Ph. Girault de Prangey and finishes with the recent archaeological survey. During the discussion the authors give their own vision of the different hypotheses raised, assessing positive contributions of each of them. Finally, they propose a new hypothesis summing up the best ideas contributed by previous authors and correcting their errors or omissions. This new hypothesis is described and drawn in ground floor plans and cross-sections.",60021537,CSIC - Escuela de Estudios Arabes (EEA),Granada,Spain,['1706'],21.555555555555557,0.19149305555555554,0.48751578282828284,1
923,923,"Planned and untold story of the city’s architecture: The pre-industrial plan for the riverside boundary of Lisbon, Portugal – materialized and remaining aspects of Carlos Mardel’s plan from 1733","Vitrúvio establishes at DeArchitectura the principles of design and port construction to serve the city in nautical, commercial, warlike and architectural terms. Alberti retakes the concept and extends it. As far as we know, Lisbon never possessed, during classical antiquity, a port worthy of that name, as Vitruvius described. The justification for the absence of a port´s structures can be due an exceptional characteristic as the natural anchorage – ships are protected in Tagus even in stormy days, away from the sea. Here only the tides have effect, by the minor winds and curling/ripples, not obliging thus to the design/construction of the port as it happens in other maritime cities. The Tagus is a pleasant cove – “Olisipo”, interior sea. Francisco de Hollanda planned the city in accordance to the river, assuming it as an essential raw material of the locus. The image of the city is strongly linked to the aquatic environment. Tagus’s importance to the city is reinforced by Frei Nicolau de Oliveira in the “Lisbon Book of Greatness” – a strategy relocating peninsula´s capital to Lisbon; citing the Emperor Charles V: “If I had been King of Lisbon, quickly I would be of the world”. Following the words of King Charles V (I of Spain), King Philip II promoted works in view of Tagus’ navigability, intending to link Madrid to the Atlantic. It was up to the architect Carlos Mardel, the delineation of the desires of the Portuguese monarch, King D. João V, to create the “Atlantic-Rome”. The new plan, for the riverside front of Lisbon, redesigned the land-water frontier, suggesting a modern image and new port infrastructures. It was interrupted abruptly by the earthquake in November 1, 1755, and it erased, from the urban history of Lisbon what would be the largest pre-industrial plan for the city – one of the greatest for Europe at the time.",60106169,"Faculdade de Arquitectura, Universidade de Lisboa",Lisbon,Portugal,['1706'],22.214285714285715,0.1432413073038073,0.503637334887335,1
924,924,Visual documentation of the state of conservation by means of UAV: The case of marble cladding system on the FaÇades of the Brazilian palace of congress,"The high-rise building appeared as a constructive tendency in the 20th century. It also stood out in this period the researches for new materials and traditional materials applied in innovative ways. The stone, for example, began to be adopted as slabs, as part of cladding systems in modern buildings façades. This shift has raised the question of how to conserve this material as part of façade systems, a subject underexplored in the Conservation Technology field. Moreover, there are difficulties imposed to the inspection and monitoring of high-rise buildings façades. In this context, it is proposed to investigate the conservation of stone cladding systems, its characteristics, behaviour and cause and effect relations that affect its ageing. For that, it is adopted as case study the Brazilian Palace of Congress, specifically its 28-story towers. Conceived in the 1960s to be the highest building in the capital, it presents the white marble as one of the elements that confer unity in the modern set of the Palaces of Brasilia. In order to characterize the object of study and its state of conservation, the damages were mapped according to the procedures: i) capture of images by means of a digital camera conducted by Unmanned Aerial Vehicle (UAV); ii) digital processing with generation of orthomosaics; and, iii) damage vectoring. Despite the obstacles during the capture of images, such as adverse climatic conditions and the inherent characteristics of marble slabs (white and highly reflective surface, natural pattern easily mistaken with pathological manifestations), the procedures were effective in meeting the proposed objectives. Finally, the information obtained will be used in the subsequent stages of analysis and intervention proposal, as intended to contribute to the conservation actions regarding the marble cladding system, and the safeguarding of this remarkable example of modern heritage.",60024989,Universidade de Brasília,Brasilia,Brazil,['1706'],26.727272727272727,0.14585858585858588,0.39577200577200583,1
925,925,Indoor location method based on data mining," All rights reserved.In the process of WLAN indoor location, the K nearest neighbor (KNN) algorithm is often used as a matching algorithm to locate fingerprints. The disadvantage is that the location accuracy is often not high. In order to solve this problem, this paper uses KNN algorithm to sort and filter the location fingerprints in the original online positioning stage, then joins Dansity-based clustering of applications with Noise (DBSCAN) algorithm to cluster, removes the interference coordinates in the location fingerprints, only retains the core position coordinates, and finally gets the location coordinates by regression prediction. Compared with other algorithms, the proposed KNNDB algorithm has a significant improvement in positioning accuracy.",60009400,Nanjing University of Post and TeleCommunications,Nanjing,China,"['1712', '1709', '1707', '1705']",27.75,0.09083333333333332,0.7566666666666667,0
926,926,Towards a new approach of architectural heritage intervention in Portugal: Fernando TÁvora and the refurbishment of the Casa da Igreja of Mondim de Basto (1958–1961),"The Casa da Igreja of Mondim de Basto (1958–1961) is a pioneering work of architectural renovation in the career of the Portuguese architect Fernando Távora (1923–2005), where he applies the theoretical approaches of conciliation between the values of tradition and the advances of the Modern Movement directly on the historical pre-existence. The design was at a time of extraordinary intellectual density and great architectural production of the author, coinciding with his attendance at the last CIAM and conduction of the “Inquiry into Popular Architecture in Portugal”. Though little investigated previously, Casa da Igreja can be considered a paradigm of the so-called “third way” and an experimental work in search of personal criteria of heritage intervention. The project reveals careful analysis of pre-existence, supporting sensible introduction of contemporary language in respectful continuity with the forms and atmospheres of the past. This design strategy shows the key points of an emerging modus operandi to be developed in later interventions with strong repercussion and pedagogy in the Portuguese context.",60027856,Universidad del Pais Vasco,Leioa,Spain,['1706'],33.2,0.1382246376811594,0.4210144927536233,1
927,927,A rule based expert system to advise on air-filtering plants for indoor spaces in UAE," All rights reserved.The purpose of this study was to develop an expert system that recommends types of plants that help remove toxic substances to improve air quality in a given surrounding. Currently, it is usually horticultural experts who suggest the right plants as per the environment, where feasible. There is also a significant gap in research related to any such smart systems as revealed in the literature review. This led to the creation of the Plant Recommender Expert System (PRES) - an intelligent system that accesses expert knowledge by utilizing a set of inputs (e.g. expected humidity, average temperature, etc.) to recommend the type(s) of plants that should be purchased to suit the conditions of any given environment. Restricted to office environments within the United Arab Emirates (UAE), PRES was successfully evaluated using several case studies with known outcomes.",60113272,Murdoch University Dubai,Dubai,United Arab Emirates,"['1712', '1709', '1707', '1705']",23.333333333333332,0.17500000000000002,0.5321428571428573,0
928,928,An autonomous navigation method for indoor pedestrian based on dual MIMU and dual-foot distance measurement," All rights reserved.An autonomous navigation method for indoor pedestrian based on dual MIMU and dual-foot distance measurement, fixes two MIMUs and dual-foot distance measuring modules on the two feet of a pedestrian. The two systems respectively perform the strapdown inertial calculation and zero velocity update based on Kalman filter. Then it is available to fuse the distance data of two feet measured by ultrasonic transceiver and constrain the navigation results of the two MIMUs by using state-constrained Kalman filter algorithm. Therefore, the fuzzy physiological characteristics of the human body are transformed into strict mathematical problems, so as to obtain more optimized navigation results, and achieve more accurate indoor pedestrian navigation and positioning function. The experimental results show that by using this method, the performance of this indoor pedestrian navigation system is more stable, the overall heading deviation is obviously corrected, the average position error is effectively controlled, and the navigation positioning accuracy is more than 35% higher than that of single MIMU navigation system.",60024350,National University of Defense Technology,Changsha,China,"['1712', '1709', '1707', '1705']",33.0,0.2310924369747899,0.3969187675070028,0
929,929,Architecture and cultural heritage management tools: Landscape action plans,"In our southern European environment, planning continues to be addressed with 19th-century zoning instruments and defined policies. The growing reaction to the impositions of this territorial policy in local areas proposes a strong bottom-up, non-urbanism of the strategic and the punctual, whose results are beginning to be insufficient due to their limited continuity and difficult coordination. The work in network and with articulated and inter-connectable projects, is revealed, however, as a tool of utility not yet sufficiently tested. To overcome the barrier between what we define as “planning” or macroterritorial policy and “ordination” at a micro level, tools such as Landscape Action Plans (LAP) are proposed. The LAP is structured as a document that, starting from the micro analysis of all facets of the landscape (not only of how it is perceived, but also of its identity generating dimension, and even of its socio-economic aspects), and listening to the demands of the citizens through social dialogue processes, raise a solution to shared problems in local or municipal areas. This solution must be defined not only formally, but applying the determinations emanated from the regional policy of Territorial Planning designed for larger areas. In the last six years, the design of LAP by our Constructed Heritage Research Group (GPAC) has yielded very interesting results in terms of coordinating municipal and regional policies, such as the Landscape Action Plans of Trapagaran (2016) and Ortuella (2018), among others. The planning of small, embraced landscapes, endowed with strong character, through Landscape Action Plans (LAP), could be an option to channel this desire for local planning into a network, which compensates or inspires a broader and more democratic territorial policy.",60027856,Universidad del Pais Vasco,Leioa,Spain,['1706'],34.375,0.05848214285714285,0.3569940476190476,1
930,930,Planning and rehabilitation in historical areas and repercussions on the tourism and economic sectors in areas of Palestine,"The research aims to study the tourist reality in Hebron and create things to draw attention to these areas such as the development of tourism-related sectors, through the promotion of old craft industries, rehabilitating the market square in the Old City of Hebron, the preservation of archaeological and historical sites, and attract tourists from abroad and provide accommodation and services. The concept of tourism is growing, as it has become a phenomenon resulting from the need of exhausted humans from modern life pressure to achieve comfort, pleasure and change. Researchers give an economic definition to the concept of tourism and consider the direct and indirect economic activities. It is one of the most important industries of our time and it reflects the image of the civilized development of people in the world. It is considered as a source of national income, and it intervenes and overlaps with many fields, such as traditional industries, food, building facilities and others. The concept of tourism has been affected by scientific and technological progress, which has led to the expansion of its scope in many aspects and has increased its importance, becoming a promising industry. The concept of tourism will be discussed because of its impact and importance on economic life. The Israelis control tourism in the Palestinian areas, depriving it from returns and benefits, so it needs support and regulation. Our study will deal with the historic city of Hebron, especially the Old City, specifically the square market area, and will highlight the features of these areas by the work of a tourist path in the center of this city and by providing organized events through the town.",60072731,Palestine Polytechnic University,Hebron,Palestine,['1706'],30.555555555555557,0.15208333333333335,0.425,1
931,931,Estimation of blood concentrations in skin layers with different depths,"In this research, we proposed a method to estimate the concentrations of melanin and blood in different layers of skin tissue. Furthermore, we stimulated skin with a warm bath and a carbon dioxide bath and obtained spectral data by a multispectral camera six times during 18 minutes. Based on the captured image, we estimated the blood concentrations in each blood layers by the proposed method. The result showed that the blood concentration of the deep layer is increased only with the stimulation by carbon dioxide bath, and the blood concentration in the shallow layer is increased in both stimuli cases, but the rate of increase in the carbon dioxide bath was higher and the increase time was longer. Our result is consistent with the result of the previous research.",60002787,Chiba University,Chiba,Japan,['1707'],25.8,0.075,0.5020833333333333,1
932,932,Investigating the ways of learning from vernacular architecture,"The aim of this study is to investigate the methods for learning from the past and to explore alternative directions/approaches towards transferring past knowledge for the living environments of tomorrow. To achieve this objective, this study suggests a holistic model that combines a variety of layers, directions and methods for utilizing vernacular-architecture knowledge. Three key components of this model are: (1) Learning from Vernacular Architecture (LF-VA), (2) Learning from Experience (LF-E) and (3) Learning from Researchers (LF-R). Based on the scope of this study, each component has been independently examined and their unique characteristics as well as subcomponents have been indicated. Finally, the authors of this study suggested a model that can make alternative situations visible not only for their future researches, but also for other scholars aiming to learn from vernacular architecture.",60086558,Ozyegin University,Istanbul,Turkey,['1706'],26.6,-0.09090909090909091,0.5659090909090909,1
933,933,"Assessment and rehabilitation of a heritage masonry building in Piraeus, Greece","This paper presents the assessment, rehabilitation and strengthening of a heritage masonry structure in Piraeus, Greece. The two-storey structure was constructed around 1900 and is used as a student restaurant at the University of Piraeus. The geometry is complex for a masonry structure and, furthermore, the masonry walls have been prestressed via wrought-iron tendons. The floors are constructed with the jack-arch method, supported by steel girders. This study was particularly challenging because of uncertainties regarding the properties of the structural materials and alterations to the live loads related to the change in the use of the building. Because the building has been declared a protected monument by the Greek State, the primary concern of the suggested retrofit was the preservation of its architectural and historical value. Thus, additional issues arose in the effort to minimize interventions. Extensive numerical simulations are presented and an extended discussion is included regarding the appropriate rehabilitation and strengthening techniques in order to satisfy both the basic principles for heritage rehabilitation and the required safety level.",60031155,Panepistimion Patron,Patra,Greece,['1706'],21.25,0.12363636363636363,0.37583333333333335,1
934,934,Built heritage use and compatibility evaluation methods: Towards effective decision making,"Built heritage use can be seen as both an occasion and an impediment for its conservation; while an appropriate use of built heritage is necessary for the promotion of its cultural values and for its preservation, an incompatible use or a series of interventions for the satisfaction of the user’s requirements can provoke damages and lead to its loss. During the last few years, different methodologies for use compatibility have been developed in order to measure and evaluate the impacts on cultural heritage caused by the user’s requirements, providing in this way an evidence base for decision-making. This paper provides a literature review of these methods with the purpose of analysing their different approaches, underlining their particulate aspects, and reflecting upon their possible advancement.",60023256,Politecnico di Milano,Milan,Italy,['1706'],41.333333333333336,-0.018181818181818188,0.48787878787878786,1
935,935,Cost-effective edge server placement in edge computing," All rights reserved.In a smart city powered by the 5G network, a large amount of data never seen before will be generated. The conventional cloud computing paradigm cannot fulfil users' needs, especially for low latency. The new edge computing paradigm is emerging to mitigate the this problem. There has been some prominent research results in the field of edge computing, but most of the work is based on the assumption that edge servers have been deployed at ideal locations, and little attention has been paid to how edge servers are deployed in a geographic area. In this paper, we study how to deploy edge servers cost-effectively so that the collective area of edge servers is maximized under a certain deployment budget. In addition, there are two issues to consider in the deployment of edge servers. The first is the deployment cost, and the second is the area covered by those edge servers. For the first issue, a dynamic programming algorithm is proposed to find a solution. The key idea is to find the maximum area under a given cost. For the second issue, the geometric image approach is used to calculate the area covered by the edge server. The results of the experiments conducted on a real-world dataset demonstrate, our method is superior to several representative methods in terms of coverage maximization and running time.",60030804,Swinburne University of Technology,Melbourne,Australia,"['1712', '1709', '1707', '1705']",20.545454545454547,0.1867822966507177,0.49936204146730456,0
936,936,Traces and scars: The reconstruction of Madrid’s ciudad universitaria after the Spanish civil war,"Madrid’s Ciudad Universitaria is a clear example of the different political era that existed in Spain during the 20th century. The project for the campus was first designed during the 1920s under the reign of Alfonso XIII, then developed throughout Spain’s Second Republic, severely damaged during the Civil War, and finally rebuilt during Franco’s dictatorship, continuing its expansion until the present. Today, it is also one of the most interesting examples of Spanish architectural heritage, dating from the 20th century. After the partial destruction of the campus during the war, the idea of its reconstruction was imposed over other theses that defended the conservation of the ruins as symbolic and evocative elements. We can still see this today in one of the great models of that time that has been preserved. During the process of restoration of the university complex, the new regime aimed to rebuild Ciudad Universitaria, given its enormous symbolic significance. Parts of the buildings were reconstructed according to the original project, while others were modified and some of them disappeared. The purpose of this study is to analyze the different ways of reconstruction that were carried out on campus from a self-made inventory of the solution implemented on each building. This will allow us to conclude that, to a large extent, the decision taken in the reconstruction was very much related to the position that each building occupied with regard to the war front, and thus the consequent degree of destruction to which it was exposed. The traces of the destruction and the subsequent reconstruction have remained visible over time in most faculties and technical schools. A close observation, with the aid of graphic tools such as drawings or photography, can help us understand better the footprints and traces that are still around us today but which become invisible to the eye since they are not adequately understood.",60028442,Universidad Politécnica de Madrid,Madrid,Spain,['1706'],28.272727272727273,0.10109621561234465,0.3760682865521576,1
937,937,Access to heritage: The role of the maltese national cultural heritage agency,"A small island in the Mediterranean, Malta is rich in culture and heritage architecture spanning several thousand years – from prehistory to Roman, Arab, Norman, Medieval, Knights of St John, French, British and modern Malta. Heritage Malta is the national agency that manages several historical buildings and sites, including sites inscribed on the World Heritage List ranging from the underground Ħal Saflieni Hypogeum to the Megalithic Temples and the City of Valletta. The importance of preserving heritage buildings for all of humanity is widely accepted. Cultural heritage belongs to people from all walks of life, and each person has a right and responsibility to appreciate and conserve its universal values. Rendering sites accessible inherently implies a degree of impact; hence, this raises a number of questions: What is accessibility? What are the potential impacts and risks? Is physical accessibility a right in all cases? What solutions can be adopted to render cultural heritage accessible? This paper will focus on how Heritage Malta, through its various projects and interventions (past and future), is addressing its mission statement in rendering cultural heritage accessible to the wider public. Furthermore, the paper shall also highlight the benefits of having an agency setup managing multiple assets.",117546373,Heritage Malta,Malta,Malta,['1706'],33.5,0.07582417582417583,0.24734432234432233,1
938,938,"Knowledge to recover the built heritage: Case study of “San Rocco” church in Matera, Italy","The process of recovery, restoration and valorization of the built heritage is articulated, both for the complexity of historical architecture and the lack of adequate intervention tools. Each monument is an expression of the territory where it was built. Therefore, it’s necessary to plan the restoration of built heritage as a system in which technical and cultural variables create a balance between decisions and processes of conservation and transformation. In this context, the technicians must activate a series of procedures to safeguard the monuments starting from the recovery of the values preserving its future memory. This methodological approach has been tested in the recovery project of the ancient masonry church of “San Rocco” in Matera (Italy). It is dated from the 14th century, and it also has a great importance for the hosting of cultural and social activities within the Matera Cultural Capital of Europe 2019 Program. The preliminary phase of data acquisition, the direct survey of the degradation characteristics and the historical-constructive research is shown in this paper. Then, a critical analysis of the survey is performed together with a preliminary analysis of its seismic performance. The numerical analyses have been conducted with the macro-elements approach, where the most probably failure mechanisms of the church architectural parts are taken into considerations.",60020919,Università degli Studi della Basilicata,Potenza,Italy,['1706'],23.555555555555557,0.11666666666666671,0.31833333333333336,1
939,939,Utilizing virtual reality technology in the preservation of architectural heritage: An empirical study of the local architecture of Hijazi identity in the Mecca region of Saudi Arabia,"Architectural documentation is considered one of the first processes that take place in the preservation of historic and archaeological buildings. The emergence of the digital revolution and what it brings from modern technologies provide a new way to document and archive these historic locations. Due to the historical value of these buildings and their status in local heritage, it was deemed important for these locations to be archived in a way that helps in availability and ease of access for scholars and researchers. This paper outlines some methods that reach this goal, alongside an applied example of a historical building (a Hijazi palace in the Mecca Region) modeled in virtual reality. This paper is divided into two sections. The first section focuses on methods of archiving historical locations, while the second focuses on the applied example of the use of VR in archiving. It concentrates on the details of interior architecture to help researchers of interior design. These details have not previously been given attention due to the difficulty of reconstructing life in the time period, and the scarcity of reliable sources on the subject. However, utilizing photographic evidence, some historic illustrations, field visits of other historic buildings of the period, and visits to houses containing personal possessions of people who have lived in these buildings, it is possible to reconstruct spaces from the period in a way that depicts the fine details that represent the lives of the inhabitants of these historic buildings.",60108699,University of Jeddah,Jeddah,Saudi Arabia,['1706'],27.11111111111111,0.04778787878787878,0.23384848484848486,1
940,940,"Historical study of Jinja, Uganda: A city influenced by industrial developments during the early 20th century","This paper evaluates how industrial developments during the first three decades of the 20th century contributed to the founding and growth of Jinja. During this period Jinja grew to become an important inland port on Lake Victoria, a consequence of geography, as well as a multitude of conditions and circumstances linked to colonial developmental policies. The paper presents the socio-economic and socio-political context of colonial patronage which influenced the spatial developments of Jinja. It, however, makes a case that some industrial aspects were in place before Jinja was designated as the pre-eminent industrial hub of Uganda. The paper frames historical narratives through developmental paradigms. By selecting different lenses to cross-examine the growth of Jinja, the paper highlights themes of trade, transport and planning that influenced and shaped the growth of the city. Research for this paper draws primarily on historical information, through critical analysis with reference to embryonic urban centres in other British controlled territories across sub-Saharan Africa, as a means to better situate the conditions that shaped Jinja. The study of Jinja’s history also forms a basis for conservation policies and could be an instrument for promoting ideas of development which are compatible with Jinja’s genius loci.",60116805,Uganda Martyrs University,Kampala,Uganda,['1706'],24.75,0.09318181818181817,0.32803030303030306,1
941,941,Optimized service function path scaling in SDN/NFV networks," All rights reserved.Service Function Chaining (SFC) has received considerable attention due to the potential in improving the flexibility and efficiency of networks. In SFCs, packets comply with the SFC policy to flow through a number of network functions with a strict order and these network functions constitute a Service Function Path (SFP). In this paper, we consider the problem of increasing the network capacity by the way of scaling SFPs for accommodating more packets in case that the network reaches its limitation. To solve this problem, we first construct a multistage graph to guarantee the strict order of network functions and then derive the min cut of SFPs according to the max-flow min-cut theory. Next, a polynomial-time algorithm is presented for SFP scaling that minimizes the transmission cost. Finally, extensive experiments are carried out and the experimental results show the effectiveness and efficiency of our proposed method.",60019499,Chinese Academy of Sciences,Beijing,China,"['1712', '1709', '1707', '1705']",24.666666666666668,0.103125,0.4239583333333334,0
942,942,Education for saving material culture: Challenge of promoting heritage education in a developing economy,The concept of acknowledging and appreciating the value in items that reflect the past and the journey towards the present times are taken as a thing of pride and almost a national and natural philosophy in many parts of the western world. However the situation in developing countries such as Nigeria is so different that the conversations on methods and technology required to preserve heritage are far in advance of the basic issues here which border on the place of heritage in the scheme of things as promoted by governments and adopted by the people. This paper aims to discuss the issues that affect the promotion of the study of heritage issues from the perspective of university students. Methodology included focused interviews and questionnaires with the results suggesting a sustainable approach to an economically beneficial development of heritage consciousness.,60006448,University of Lagos,Lagos,Nigeria,['1706'],34.75,0.075,0.42750000000000005,1
943,943,A calculus for modeling floating authorizations,"Controlling resource usage in distributed systems is a challenging task given the dynamics involved in access granting. Consider, e.g., the setting of floating licenses where access can be granted if the request originates in a licensed domain and if the number of active users is within the license limits. Access granting in such scenarios is given in terms of floating authorizations, addressed in this paper as first class entities of a process calculus model, encompassing the notions of domain, accounting and delegation. We present the operational semantics of the model in two equivalent alternative ways, and report on a preliminary investigation of the behavioral semantics, addressing fundamental properties and informing on the specific nature of our authorizations. We also introduce a typing discipline to single out systems that never get stuck due to lacking authorizations, addressing configurations where authorization assignment is not statically prescribed in the system specification. Finally, we present a refinement of the type system which paves the way for obtaining a more efficient type checking procedure.",60102060,"Institutions Markets Technologies, Lucca",Lucca,Italy,"['1712', '1703']",28.166666666666668,0.09202380952380954,0.3647619047619048,1
944,944,Exploratory simulation drilling environment design based on interactive data generation method," All rights reserved.As one of the cutting-edge drilling technologies developed in recent years, intelligent guided drilling technology addresses the problems of drilling complex structural wells and ultra-deep wells under complex geological conditions. In order to provide a simulation environment for intelligent drilling algorithms to meet the actual drilling work, reasonable and reliable 3D geological modeling and visualization work is essential. However, in current geological modeling and visualization work, there are various problems such as insufficient modeling data, poor interaction with agents and lack of exploratory. In view of the above problems, this paper designs an intelligent guided drilling algorithm interactive system that can dynamically generate simulation data based on a small number of geological data samples and construct a three-dimensional geological environment in real time. We propose an interactive data generation mechanism, which can quickly generate simulated LWD (log while drilling) data within the detectable range according to the real-time position of drill bit, and provides a basis for real-time decision making of the intelligent guided drill model. At the same time, the system refers to the uncertainty of the actual formation distribution and adds some randomness in the process of simulating stratigraphic sections. Therefore, based on cross-sectional stacking method combined with the characteristics of intelligent guided drilling algorithms, the 3D geological model of drilling environment can be dynamically constructed during the real-time guiding process. Moreover, exploratory environment modeling method can provide a low-cost, versatile simulation test platform for intelligent guided drilling algorithms.",60016087,China University of Petroleum-Beijing,Beijing,China,"['1712', '1709', '1707', '1705']",30.5,0.19057971014492753,0.49021739130434794,0
945,945,"Meanings and significance of colonial architecture in Douala, Cameroon","The concept of heritage has experienced expanding meanings that link it to history, memories, tourism and business products, to name just a few of them. The heritagization process of architectural sites enlightened and focused most of the time, on aesthetical, know-how and the memory of the use of the site. Therefore, architectural heritage is not necessarily focusing on dynamics of memories surrounding it and might be limited to celebrating engineers and architects. In this regard, could it be worth referring to colonial architecture in Africa as heritage sites? To what extent could an architecture that celebrates former oppressors become a heritage site? What cultural or historical significance can colonial built remains convey to the African communities on whose territory they are located? This contribution, in light of the topic of heritage architecture and historical aspects, seeks to discuss the interaction between colonial memories and the enhancement of colonial built remains as historical/cultural heritage.",60025153,Università degli Studi di Genova,Genoa,Italy,['1706'],38.25,0.1523809523809524,0.29523809523809524,1
946,946,Concrete as heritage: Social perception and its valuing – the Zarzuela hippodrome case,"Concrete is the constructive material used to design most of the buildings of the 20th century, some of them of great architectural, historical and cultural relevance. However, the social perception that exists around these constructions, as regards the consideration as architectural and artistic heritage, reflects discordant aspects. Several authors affirm that the 20th century concrete heritage lacks enough appreciation by society, which hinders the tasks to develop or encourage their social consideration and their tourist use. On the other hand, in some cases, this kind of heritage are not considered attractive tourist resources, therefore the maintenance work is no longer a priority, which does not guarantee minimum standards of conservation. In this context, the University of Cadiz leads a European project H2020 called InnovaConcrete, whose aim is to preserve the 20th century monuments built in concrete in countries of the European Union. The Zarzuela Hippodrome (declared an Asset of Cultural Interest in 2009 and inaugurated in 1941, after the Spanish Civil War) has been selected as an ideal example when gathering aspects of economic, social, cultural, aesthetic and architectural functionality. The results obtained, through various surveys and interviews with agents involved, envisage a strong correlation between the widespread ignorance about the historical and architectural value of the building and its depreciation as a heritage element. It is therefore necessary to reflect on the special importance that, for this type of patrimonial groups, have the dissemination and information’s tasks about their historical and architectural, as well as artistic and social peculiarities.",60016476,Universidad de Cadiz,Cadiz,Spain,['1706'],31.25,0.17692577030812323,0.3381302521008403,1
947,947,Optical flow/INS navigation system in four-rotor," All rights reserved.Because of the fragility and vulnerability of the satellite navigation system, it is unable to provide continuous and reliable positioning navigation for UAVs in complex regions such as indoor and canyons. This paper presents a combined navigation method based on visual optical flow and inertial navigation. This method uses ORB to realize the factor extraction of images, and improve Lucas-Kanade method by using the whole optimization method. Combining optical flow and inertial navigation based on extending the Kalman filter. The result of simulation experience shows that the evaluated error of the arithmetic presented in this paper is 0.08m/s, which can satisfice the Indoor integrated navigation of unmanned aerial vehicle (UAV).",116496877,Xi'an Gaoxin No.1 High School,Xi'an,China,"['1712', '1709', '1707', '1705']",22.6,-0.12000000000000002,0.36,0
948,948,Offloading monocular visual odometry with edge computing: Optimizing image quality in multi-robot systems," All rights reserved.Fleets of autonomous mobile robots are becoming ubiquitous in industrial environments such as logistic warehouses. This ubiquity has led in the Internet of Things field towards more distributed network architectures, which have crystallized under the rising edge and fog computing paradigms. In this paper, we propose the combination of an edge computing approach with computational offloading for mobile robot navigation. As smaller and relatively simpler robots become more capable, their penetration in different domains rises. These large multi-robot systems are often characterized by constrained computational and sensing resources. An efficient computational offloading scheme has the potential to bring multiple operational enhancements. However, with the most cost-effective autonomous navigation method being visual-inertial odometry, streaming high-quality images can induce latency increments with a consequent negative impact on operational performance. In this paper, we analyze the impact that image quality and compression have on the state-of-the-art on visual inertial odometry. Our results indicate that over one order of magnitude in image size and network bandwidth can be reduced without compromising the accuracy of the odometry methods even in challenging environments. This opens the door to further optimization by dynamically assessing the trade-off between image quality, network load, latency and performance of the visual-inertial odometry and localization accuracy.",60006876,Turun yliopisto,Turku,Finland,"['1712', '1709', '1707', '1705']",20.7,0.18690476190476193,0.5043650793650793,0
949,949,A new method of lithium battery power estimation based on adaptive filtering," All rights reserved.State of charge (SOC) is a key parameter in battery management and vehicle energy management. In recent years, there are problems in the SOC estimation method for electric vehicle(EV) lithium-ion batteries, such as the battery model is too simple, and the sampling noise of voltage and current signals is too large. In this paper, a second-order RC circuit combined with adaptive unscented kalman filter (AUKF) is proposed to estimate the charging state of EV lithium ion batteries. Under the background of unscented kalman filtering (UKF), the adaptive factor is constructed by using the Innovation vector, and the adaptive adjustment of noise covariance in charge estimation is realized. The comparison between AUKF and UKF shows that the proposed method has better estimation accuracy. AUKF algorithm has good performance in estimating battery charging state.",60011592,Qilu University of Technology,Jinan,China,"['1712', '1709', '1707', '1705']",22.5,0.17678571428571427,0.5044642857142857,0
950,950,"Characterisation of historical lighthouses as industrial heritage elements: Application to the lighthouse of the Island of Santa Clara, Spain","Lighthouses are a symbiosis of architecture and technology, combining a tower, an adjacent building with living quarters and stores, and technology that produces signals for sailors. They must be permanently in operation and they must be unmistakably distinguished from other nearby lighthouses. They are extremely versatile elements that satisfy several functions in addition to the light signals. The authors consider that traditional lighthouses, commissioned in the mid-19th century, are genuine signalling factories, and that they must be studied as such, based on the concepts defined by the UNESCO documents, among others, for industrial heritage. Recently, the Institute of Cultural Heritage of Spain (IPCE), dependent upon the Government of Spain, has considered lighthouses with a historical value as industrial heritage elements. The authors accept this consideration and as such, in 2017, the drafting of the Catalogue of Lighthouses with heritage value in Spain was commissioned by the IPCE. A large number of projects are being activated today to include tourist uses in the lighthouses. However, it has been detected that these projects eliminate tangible and intangible materials that irreversibly distort the lighthouse as an example of our industrial heritage. The paper aims to detect the characteristics that must be assessed to establish the heritage value of historical lighthouses and propose a procedure for their evaluation. By way of an example, the value of the lighthouse of the Island of Santa Clara in Donostia-San Sebastian (Spain) is analysed from the viewpoint of its pertinence to the industrial heritage. To characterise a lighthouse, its architecture, location, the technology implemented in the lamp that tops the tower, and its spatial distribution must be analysed.",60027856,Universidad del Pais Vasco,Leioa,Spain,['1706'],24.545454545454547,0.06648351648351648,0.3925824175824176,1
951,951,Structural performance of concrete elements retrofitted by a geopolymer strengthening system: Input in the rehabilitation of historical buildings,"Rehabilitation of historic buildings is a priority since their structural elements suffered from various levels of damage that took place during their service life. Recently, geopolymer is gaining acceptance as an emerging material in the construction industry due to its added advantages. It has shown excellent bond strength to concrete substrate, lower creep and shrinkage, greater durability in severe environments and higher temperature and fire resistance. Geopolymer is relatively new in the rehabilitation system of building structures, although it had been used for new construction applications. Therefore, an effort was made to gather information on the use of geopolymer as repair and strengthening material. This paper reviewed the structural performance of geopolymer-strengthened concrete elements and the field applications of geopolymer as strengthening material for historical buildings. Information from the literature revealed that the load capacity of the non-damaged and fully damaged reinforced concrete (RC) beam can be increased by 12% and 100%, respectively, when strengthened using plain geopolymer. It was found that short fiber-reinforced geopolymer (SFRG) strengthening system enhanced the peak load of RC beam by 15% while 370% if using continuous fiber-reinforced geopolymer (CFRG). To date, field applications of geopolymer strengthening system on historical buildings were limited, nevertheless this technique provided good structural performance making it suitable in the rehabilitation process.",60011373,Danmarks Tekniske Universitet,Lyngby,Denmark,['1706'],23.555555555555557,0.1656006493506493,0.35920454545454544,1
952,952,Development strategy analysis of satellite mobile communication system based on SWOT," All rights reserved.Satellite mobile communication system is playing an important role in modern communication. It is of great significance to study the development trend and direction of satellite mobile communication system. The evaluation model of satellite mobile communication system development strategy is established by using SWOT quantitative analysis method, which provides support for the overall development strategy of satellite mobile communication system. The advantages, weakness, opportunities and threats in the development of satellite mobile communication system are analyzed and quantified. According to the score, the quadrilateral diagram and the intensity spectrum coordinate system of the development strategy of the satellite mobile communication system are generated. The conclusion is that the development strategy of satellite mobile communication is developmental and attention should be paid to exploiting strength while grasping development opportunities.",60024350,National University of Defense Technology,Changsha,China,"['1712', '1709', '1707', '1705']",21.833333333333332,0.35000000000000003,0.5125,0
953,953,Indicators of sustainable development for cultural landscapes: Film sceneries and cultural heritage,"Cultural tourism is a good way to promote and safeguard the cultural heritage of a place. Cultural tourism includes film tourism, which consists of those places where cinema and TV productions have been shot. This can contribute to valuing the local cultural heritage or, by contrast, to reifying it and, consequently, to the loss of its authentic and its identity. In the following article we propose a system of indicators of sustainable development in order to evaluate and guarantee long-term sustainability in those places identified with traditional cultural heritage and that have become film sceneries. Once the study cases have been identified, the cultural landscapes that are going to be evaluated will be defined. To do that, we will identify and select the film sceneries according to the degree of conciliation between these and cultural heritage. The impact on society of the cinema productions will also be taken into account. The union amongst the film sceneries through the local heritage (built heritage, landscape heritage, etc.) will result in one or several cultural landscapes where the balance between the welfare of the host society and the tourism demands will be evaluated. To put into practice the following methodology, the Historic Centre of Peñíscola has been chosen to be evaluated. This was declared a Historic-Artistic Site in 1972 and has a long history as film scenery, which has contributed to its valuation and has brought it closer to the audience.",60027856,Universidad del Pais Vasco,Leioa,Spain,['1706'],23.8,0.10833333333333334,0.19444444444444448,1
954,954,"Evaluating the performance of a daylighting traditional device, the Mashrabiya, in clear sky conditions: Case study of a traditional Bahraini house","The mashrabiya is used in traditional Islamic architecture to provide visual privacy, reduce the glare from direct sunlight, and allow natural ventilation. Traditional Bahraini houses were designed with specific features and characteristics to cater to the cultural and religious needs of the occupants and the bio-climatic conditions. This study has investigated the impact of the mashrabiya on daylight performance within a space and examined how it affects the quantity and quality of the daylight that is admitted into the space. A field study was conducted in one of the traditional houses in Bahrain for evaluating the performance of the mashrabiya in providing daylight in the space. The studied room was located on the upper floor and had an L shape layout (27.75 m2). The main wall of this room faced the north with openings covered with mashrabiya, while the inner part of the room (the south wall) overlooked an atrium with a skylight. The south wall had two small openings that increased the illumination level in a small part of the room. The results showed that the performance of daylight throughout the mashrabiya was better, to some extent, than without any screen. The mashrabiya in this case can provide the level of illuminance recommended for residential activities and can provide better uniformity as compared to the space without a mashrabiya. The mashrabiya device is capable of reducing the impact of glare in the whole space. It is preferable to improve the design of the mashrabiya to enhance the uniformity of daylight in the space. The chromaticity of light in the space, as the CCT calculation for all the measured points below the accepted level, was another challenge with regards to the performance of the mashrabiya device. A mashrabiya is likely to demonstrate a more successful performance and better daylighting if it is designed and modified to consider uniformity and the chromaticity of light in the space.",60104334,Imam Abdulrahman Bin Faisal university,Dammam,Saudi Arabia,['1706'],24.307692307692307,0.16319444444444445,0.4572916666666667,1
956,956,Architectural renewal: A rising dawn in ile-ife?,"“Conservation”, as a word frequently in use colloquially, has several nuances. In its most common usage, it is tantamount to “preservation”. However, the term “architectural conservation” invariably relates to heritage structures deemed worthy of conservation-restoration intervention because of their latent iconic cultural significance. “Renewal”, on its part, extends the frontiers of restoration: while putting back what was lost, it accommodates some change in the original, so as to extend the current usefulness and general relevance of the heritage structure, i.e. it is synonymous with “adaptive re-use”. Even at the level of government intervention, relatively very little is going on in Nigeria in terms of heritage-structure conservation. Private (family) concern for architectural renewal of historic property is a rarity. Notwithstanding this relative neglect of Nigeria’s heritage architecture, all over the country there are many worthy samples of the nation’s building culture, attesting to the rich prospects of their conservation and renewal. The ancient city of Ile-Ife is not left out of this tourism (and other) potential of heritage architecture. The paper adopts the case-study approach in discussing some experimental work in architectural heritage renewal being undertaken in Ile-Ife. Specifically, two buildings, Lowa’s House and the Odeyemi Family House, are critiqued, setting out the factors predisposing them to socio-cultural and architectural significance, and highlighting the unique features introduced to make them contemporarily relevant. It is submitted that, given the transformations that such interventions invariably confer (visual, utilitarian and subtly, psycho-social), it may not be far-fetched to expect a ripple effect as a fall-out of these experiments.",60006270,University of Ibadan,Ibadan,Nigeria,['1706'],21.166666666666668,0.11257716049382716,0.46296296296296297,1
958,958,Blockchain-based privacy-preserving authentication and message dissemination scheme for VANET," All rights reserved.The vehicular ad hoc network (VANET) is an intelligent transportation system application that aims to ensure the security of road traffic information over V2V communication and V2I communication. In this paper, we propose a blockchain-based privacy-preserving authentication scheme in VANETs. We explore the strategy of a local blockchain for VANETs. We make use of a private blockchain for authentication and a public blockchain for managing event messages. The trusted authority (TA) is responsible for making the transactions in the private blockchain within the boundary of the countries, the transactions are the identity information required for authentication of vehicles when they join the network for the first time, the other vehicles have the right to read and check from the private blockchain the authenticity of a new vehicle. The public blockchain is used for storing the event messages within the boundary of pre-defined regions to ensure the security of message dissemination, we called this kind of blockchain road-side unit blockchain (RSU-BC) because it takes the role of RSU in a VANET. In this way, we eliminate the necessity of RSU's deployment in VANETs and reduce the dependency on the TA. By way of security analysis and security-proofing, we prove that our scheme satisfies multiple security and privacy requirements and can resist many attacks, while the performance analysis shows the efficiency of the scheme in terms of computation overheads and communication overheads.",60025761,Huazhong University of Science and Technology,Wuhan,China,"['1712', '1709', '1707', '1705']",29.125,0.17647186147186147,0.38712842712842715,0
959,959,Validating model of travellers' intention to revisit of an islamic destination via consistency partial least square (PLSc),"The purpose of this study is to validate the links among factor influencing tourists to revisit of an Islamic destination towards Muslim amenities and lifestyle, cognitive destination image and quality of service on a traveller's intention to revisit Islamic tourism destination. All the data was being collected using a self-administered approach questionnaire. The influencing factors of tourists to revisit are being validated by using the Consistency Partial Least Square (PLSc) via Structural Equation Modelling (SEM) technique. The findings indicated that, the purposed model were valid to modelling the travellers' intention since the SRMR and NFI indices were meet the minimum requirement of the analysis. Besides that, Muslim-Friendly Amenities and Lifestyle, Cognitive Image, and Service Quality having a simultaneously positive significant effect toward Intention to Revisit. It is indicated that, Islamic tourism should be acknowledged of the importance of Muslim amenities and lifestyles, cognitive destination image and quality of services in keep tourists to revisit.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1710'],25.666666666666668,0.05056818181818181,0.5301136363636363,1
960,960,Ways to improve the supply chain management mechanism of the firm's competitiveness,"In the era of globalization and internationalization of the economy, competitiveness is one of the main criteria for its effectiveness. Today it is impossible to find a market in which there is no competition, so the problem of competitiveness of the firm is relevant and requires constant research. There are many definitions of the concept of managing a firm's competitiveness. In this article, after analyzing the different approaches, a generalized definition is derived. In unstable market conditions, the success of the firm in the market depends on its competitiveness, timely establishment of strategic goals, flexibility of the production system, which is ensured by the accuracy and timeliness of management decisions. Effective management of the firm in the market conditions is essentially reduced to the management of its competitiveness (to the assessment and analysis of factors that increase or decrease the competitiveness of the firm, the choice and implementation of appropriate strategies and tactics to achieve a particular goal). Since today in the world of high technology it is more difficult for a firm to survive, the firms themselves, which use as many methods of management as possible, will be more interesting for investors, what is the result of the introduction of certain innovations. The purpose of management in this situation is to react to innovations and changes in time. The article highlights a number of key factors affecting the competitiveness of the firm and management decision-making, the management tools of competitiveness management.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],26.88888888888889,0.09040564373897707,0.5374603174603175,1
961,961,Resource supply attributes affecting delay of high-rise building construction in Thailand,"Delay is one of the serious problems in the construction industry, particularly in high-rise building construction projects in Thailand. Therefore, this research aims to investigate the major resource supply causes and effects of delay problems in high-rise building construction projects in Thailand. The study employs both quantitative and qualitative study with concurrent mixed method design. Thirty-three resource supply causes and nine effects extracted from the literature review were used as the basis for further analysis. Relative Importance Index technique was used to analyse and calculate to the ranking of resource supply causes and effects of delay in Thai construction projects. The survey results were compared with the interview to unearth the true major causes of delay in Thai high-rise building construction projects. The results showed that the most significant resource supply factors of construction delay were: (1) change orders, (2) financial problem of contractor, (3) slow decision-making, (4) shortage of labour, (5) improper planning, (6) lack of good communication, (7) third party delay such as subcontractors or suppliers, (8) ambiguity of shop drawing designs, (9) shortage of construction materials and (10) late payment by owners. In terms of potential effects, the results indicated that the five most important effects were a delay in obtaining funds and profits for owners and contractors, cost overrun, time overrun, low quality due to hasty work and arbitration. Implications from these findings are further discussed.",60103781,Suan Sunandha Rajabhat University,Bangkok,Thailand,['1710'],25.555555555555557,0.07534722222222222,0.5229166666666667,1
962,962,Factors effecting human resource practices on employee performance in libya oil & gas industry,"The success of every organization depends highly on the human resources of the organizations. This is where the human resource has the skills, knowledge and competencies required for the execution of organizational strategy and planning. Many HRM studies have indicated positive effect of HR practices on employee performance, but there are some other studies that indicate the otherwise, indicating that the findings of the existing HRM studies are seemingly inconclusive. Equally, most studies are conducted in other contexts other in Libyan context, most especially in the context of Oil and Gas sector. Therefore, this study try to examine the effect of human resource practices (job design, training and development, compensation, performance appraisal and employee participation and communication) on employee performance in the Libyan oil and gas sector. Using the cross-sectional research approach, data were collected from a sample of 100 employees of Waha Oil Company (WOC). Multiple regression analysis technique will be used to test the study's hypotheses. The results provided support for two out of the five hypotheses. The overall findings signified a positive effect of training & development and performance appraisal on employee performance. This indicates that HR practices could have significant effect on performance, but the effect could be altered and modified by the contingent variables. The findings could also imply that the direct relationship between HR practices and performance could contain some mechanisms in-between. Lastly, the implications, limitations and suggestions for future research were discussed.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],19.916666666666668,0.11497835497835499,0.3629797979797979,1
963,963,Economic and statistical analysis of the management efficiency by the supply chain strategy and grouping method,"The paper considers the possibility of using statistical methods to identify the impact of organizational factors on improving production efficiency. It investigates the existing problems in the application of the grouping method in the analysis of management effectiveness. The authors used a systematic approach to the statistical study of production and management efficiency. Methodological approaches to the integrated assessment of enterprise activities were developed by combining three characteristics in one grouping - the level of technical equipment, labor efficiency and capital productivity. Further research is aimed at developing and examining a generalized assessment of the organizational and technical level of enterprises on the basis of the grouping method.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],21.6,0.025,0.25,1
964,964,Panel analysis of relationship between supply chain strategy in competitive area and economic growth in the European Union,"Theoretically, the supply chain competitiveness is conclusively believed to be positively related with economic growth. While empirically, this relationship does not always hold in many countries for several reasons. In the empirical literature, the link between economic growth and competitiveness has been highly debated. Thus, the main purpose of current article is to examine the link between economic growth and competitiveness in European Union (EU-28 countries) over period from 2007 to 2017. Using Panel Models (Fixed and random effects models). In conclusion, the findings suggest that competitiveness is robustly and positively associated with real GDP per capita, if we make a policy to increase the GDP per capita, it included rise in competitiveness score for the country.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],19.5,0.09729055258467023,0.2716934046345811,1
965,965,Influence of economic indicators on supply chain: Evidence from Indonesian fishing industry,"The supply chain dynamics has been broadly examined and experienced by the academes, industrialists as well as economists. However, still the literature is missing with the effect of economic indicators on supply chain practices, particularly in fishing industry. Therefore, the objective of the current study is to examine the role of economic indicators on supply chain in fishing industry of Indonesia. Fishing industry is one of the industries which is working from many centuries and now growing rapidly and considered to be the important element of economic growth in different countries like Indonesia. Six hypotheses were formulated with the help of previous studies, concerning the relationship between inflation rate, interest rate, human development index (HDI), gross domestic product (GDP) and supply chain. GDP was considered as the mediating variable. Managerial employees of fishing companies were selected as the respondents of this study. Primary data was collected by conducting the questionnaire survey. Total number of one hundred and ninety-six (196) response were received. These responses were analysed with the help of statistical software namely; Partial Least Square (PLS). It was found that economic indicators have influence on supply chain. Increases in inflation rate and interest rate decreases the supply chain. However, increases in HDI enhances the GDP and promote supply chain activities. Additionally, GDP is a mediating variable between HDI and supply chain which positively enhances the supply chain through HDI. Thus, study provides the clues for government to promote supply chain by controlling inflation and interest rate.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],16.46666666666667,0.11771694214876036,0.3571797520661157,1
966,966,Modelling islamic hotel relationship between servicescape and customer satisfaction in klang valley: Evidence from PLS-SEM and IPMA analysis,"Malaysia is a country that consists of various regions in which the official region is Islam. Therefore, Malaysia is known as a popular destination for Muslim tourist to visit to and as for that there is opportunity for Malaysia to develop Islamic Hotel concept in order to fulfill the demand of Muslim tourist. Understanding the consumer attitudes towards Islamic Hotel should be the guideline for marketers in strategizing the marketing tactics. The objective of this study is to provide and insight consumers options towards Islamic hotel by measuring the service scape of the hotel which been divided into three segments which are ambiance, interior design and facilities. A questionnaire survey has been distributed for this study and result showed that there are several aspects under each of segments that can lead to customer satisfaction by using the PLS-SEM and IPMA analysis. The findings in this study can be used by other hotel operators to have a thoughtful mind on the factors that driven customers' preferences and satisfaction that will aid in designing a message with better persuasion and at the same time attract more tourists to come and visit Malaysia.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1710'],31.666666666666668,0.20833333333333334,0.3888888888888889,1
967,967,Factors affecting adoption of paddy estate project among rice farmers for increasing rice production and supply,"Rice is an important commodity in Malaysia as it is the most prominent staple food of the population. The National Agrofood Policy of Malaysia highlighted the need to ensure adequate rice supply and to increase farmers' income level. One of the efforts to increase rice production is the implementation of the Paddy Estate Project (PEP). The objective of the programme is to increase rice production with a lower operating cost. The present paper provides a case study of rice farmers in the Muda granary area, which covers the states of Kedah and Perlis, using primary data to identify the factors on the adoption of PEP among farmers. The research findings indicate that the key factors determining the farmers' adoption of the PEP are age, secondary jobs, effective communication with the extension agency, increased rice yield, lower operating cost, lower working time in the fields, and support services, such as assistance, incentives, and facilities from the government.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1710'],26.0,0.2212121212121212,0.5484848484848485,1
968,968,The effectiveness of company's financial analysis and supply chain policy in bpredicting the future prices of stocks,"The core idea behind this research is to examine the significance of financial ratios taken from the financial reports or statements to forecast trend in stock price. For this purpose financial ratios have been taken to forecast stock returns from 2008 to 2018. Thus to predict the future price of stock four financial ratios have been taken, ""price to book ratio (P/B), price to earnings ratio (P/E), dividend per share (DPS) and firm sizes"". This research comprises on panel data with fix and random effect model for analysis that is a very effective and comprehensive predictive regression method for forecasting the stock returns. This study reveals results which show that the financial ratios are the most efficient tool for predicting stock returns. Among the four taken ratios in this research the firm size has proven to be more accurate prediction power as compare to dividend per share as well as price to book ratio. Nevertheless, the relationship between price to earnings ratio and stock returns has not been proven to be significant. Thus the study has proven that financial ratios are reliable tool to predict stock price while making investment decisions.",60077692,University of Al-Qadisiyah,Al-Qadisiyah,Iraq,['1710'],23.875,0.0784375,0.35208333333333336,1
969,969,Constructing two-sided group chain acceptance sampling plans for non-symmetrical data,"In developing acceptance sampling plan, the mean is often the choice due to the fact that it is a good estimator. However, it is only a good estimator when dealing with symmetrical data. If the data is not symmetrical, then the mean is no longer a good estimator, but the median is. The recent two-sided group chain acceptance sampling plans (TSGChSP) has only been applied to Pareto distribution of the 2nd kind by using the mean to cater for symmetrical data. In reality, some data are actually non-symmetrical. Hence, motivated by such scenario, the aim of this study is to produce the TSGChSP for Pareto distribution of the 2nd kind by using the median. The performances of TSGChSP are measured based on minimum number of groups, g and probability of lot acceptance, L(p). The g is calculated by satisfying the consumer's risk while the L(p) is obtained at several values of median ratio. Finally, the number of million revolutions for 23 ball bearings is shown in order to show the application of the TSGChSP in the industry.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],19.666666666666668,0.14407894736842106,0.5730263157894737,1
970,970,Digital economy for the supply chain as indicator of competitiveness of the cites,"The current state of development of world urbanistic community shows that the main accents in competitive interdependence between basic subsystems of territories are transferred from nationwide - the national level on more local-regional and local: cities and city systems. One of the main technology management for supply chain is digital technology. The digital economy which key factor of production data in a digital form - digital technologies act gives great opportunities for the development of the city, acts as a factor of increase in its competitiveness. In relation to the cities of the Russian Federation, the main, most objective indicators of competitiveness are productivity (efficiency), employment, the standard of living, quality of the urban environment. Introduction of the digital economy is accompanied by a number of risks. In relation to the cities and agglomerations, it is necessary to provide actions for minimization of the risks connected with a problem of creation of the corresponding infrastructure. Digitalization potentially influences the majority of parameters of quality of the urban environment and promotes improvement of quality of life of citizens: welfare and employment, level of expenses, education level and human capital, existence of free time and nature of its use, level of environmental pollution, existence and quality of social communications, general satisfaction with life.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],30.142857142857142,0.10705128205128203,0.3016025641025641,1
971,971,Using awards excellence models in assessing supply chain management systems: A case study in the plants of general company of leather industries,"This research is aimed to test and apply the concept of excellence awards of quality, according to the awards models of criteria to assess the extent of the application of quality management systems. A group of awards adopted by international, regional and local organizations means, outstanding administrative systems to evaluate performance and follow-up measuring their self-performance to reach excellence. The quality awards standards are of the most important methods of measuring performance, it has been access to a set of standards to achieve them. According to the present research the General Company for Leather Industries determined as industrial organization working for the public sector. The present study population for this research focused on testing those common standards and the extent of its contribution to the achievement of excellence in Organizational performance. The important elements used are Leadership, Strategic planning 'Human Resources, Resource management, Relationship with Partners, Processes, Focusing on the beneficiary, Impact on workers, Impact on the community, Evaluate the results of performance, Information, and the availability of such standards. The present study relied on the analytical method and results, some conclusions are made. Notably that awarded quality and organizations excellence in the field of quality and helps to spread the culture of quality. It was the most important recommendations that the Organization select their targets according to company policy and follow-up to achieve them and review the senior management to check the level of performance and attention to the management of operations and human resources and encourage them to work as a team continued excellence.",60107554,Middle Technical University,Baghdad,Iraq,['1710'],28.444444444444443,0.16388888888888886,0.3967592592592592,1
973,973,Sociotechnical aspects of lean and sustainability,"In recent years, lean healthcare has been used by numerous scholars as a major trend for exploring the purpose of practicing lean healthcare in an operational context but apparently not considering the human or social factors. Furthermore, less studies have been conducted on how social or sociotechnical aspects of lean enables the achievement of sustainability in healthcare organizations, which also includes the three main pillars, namely economic, social, and environmental aspect. Therefore, this paper intended to examine the link between sociotechnical aspects of lean and sustainability in the healthcare sector. It also discussed theoretical approaches that explain these variables, namely Sociotechnical and Stakeholder theories. Finally, this paper has given important significance for academic researchers who intend to study the sociotechnical aspects of lean and sustainability as well as practitioners who deal with complex problems. Conclusions and future works are also included in this paper.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1710'],24.0,0.02573529411764706,0.30147058823529416,1
974,974,Application of Canadian experience for supply chain strategy and territorial organization of tourist information centres in the regions of Russia,"One of the countries that have a common and long-running TIC network is Canada. The experience of this large northern country in the formation of regional information visit-service systems is of interest to Russia, since the countries in their characteristics are similar in size, distances, and natural conditions based on the supply chain strategy. Consider the TIC systems in the four Atlantic Canadian provinces. Tourist Information Centres are a new branch of services and a significant component of tourism management in many countries. In Russia, tourist information centres (TIC) are organized mainly in the largest cities of the regions and at the main sites visited. The experience of countries that are close in terms of geographic conditions and advanced in relation to the tourist infrastructure is important for the Russian regions. The study of the territorial organization of the Visitor Centres in the Atlantic Canada allows us to determine some geographical patterns. They will be taken into account when developing the system of tourist information centres in the Permsky Krai, one of the internal regions of Russia, which begin to form a high-level tourist infrastructure.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],23.125,0.16607559107559108,0.448060273060273,1
975,975,Transformation of the views of China on the problem of supply chain management of territorial regulation of the borders of India in the last quarter of the XX century,"After the death of Mao Zedong in September 1976, the PRC opens a new page in its foreign policy history. This is mostly due to the reforms and transformations that Deng Xiaoping proclaimed. The change of sociopolitical and economic structures that had taken place laid the foundation for China's entry into world leaders in some positions. By the time Deng Xiaoping came to power, the Chinese economy was in decline after the ""political adventures"" of Mao Zedong. To get out of this situation, it was necessary to liberalize the economic and social sectors, as well as solve a whole range of foreign policy problems (from establishing official diplomatic relations with the USA and improving relations with the USSR, to solving the problems of Hong Kong and Macao) in order to become a harmonious part of the world community. To strengthen its position in the Asia-Pacific region, China needed, first of all, to establish relations with all its neighbours and resolve territorial disputes, of which there were many. This article is supposed to consider the question of the attempts of the PRC to resolve existing differences on the disputed parts of the borders with the Republic of India. In the period under review, China had several territorial disputes with its neighbours, which did not allow to realize the foreign policy potential, and there was also not a sufficient number of allies and economic partners of the PRC. As an example of a solution to border disputes, one can cite a positive result achieved in the course of negotiations with the USSR on the demarcation of the border. If China managed to achieve its goals with its northern neighbor, the question with India still remains open. In our study, an attempt will be made to analyse the course of the negotiation process between the PRC and the Republic of India in the last quarter of the 20th century and to identify the reasons for the lack of a decision on this issue. This analysis is interesting not only in terms of forecasting the development of the situation in the APR but also within the framework of other territorial problems of the PRC.",60107804,The Russian Presidential Academy of National Economy and Public Administration,Moscow,Russian Federation,['1710'],30.0,0.07591540404040405,0.3413194444444445,1
976,976,"Relationship between the operational risk, operations and information management in Russian banking sector","The paper considers the issue of operational risk management in Russian commercial banks. The correlation and regression analysis also revealed the dependence of the operational risk level on liquidity risks (current and long-term liquidity ratios) and crediting risks (the amount of overdue debt, the aggregate risk for bank insiders, and reserves for possible losses on loans and equivalent debt). It has been proved that with the growth of current and long-term liquidity ratios, overdue debts and reserves for possible losses on a loan, loan debt and its equivalent ratios, the operational risks of credit organizations in Russia grow, whereas with an increase in the aggregate risk for bank insiders (H10.1), the level of operational risks of the banking sector is reduced. The values of operational risk in the banking sector of the Russian Federation are predicted on the basis of the scenario approach for 2019-2020. As part of the pessimistic and moderate growth scenario, an increase in the level of operational risks is predicted, which makes it necessary to implement new approaches to managing this type of risk in credit institutions and introduce new methods of managing operational risk by the Central Bank of the Russian Federation.",60070941,Kazan Federal University,Kazan,Russian Federation,['1710'],39.4,0.020979020979020976,0.43531468531468526,1
977,977,Forecasting of electricity consumption and supply for campus university using time series models,"Electricity is an important energy source in university as lecture classes need electricity supply to function. It is also important for the development of the university. Since electricity consumption is a necessity of a university's operation, the forecast of electricity consumption on the university campus should be made. This is essential for the development of the university as the treasury department can manage the funding from the government according to the value forecasted to make full use of the funding in the university's development. There are several forecasting methods used in this study, including time series regression, seasonal exponential smoothing, Box-Jenkins (SARIMA), decomposition and the naïve method. Error measurements used to evaluate the performance of forecasting model were mean square error (MSE), root mean square error (RMSE), mean absolute percentage error (MAPE) and geometric root mean square error (GRMSE). The results of this study showed that the seasonal exponential smoothing model was the best in the 1-step ahead and 2-step ahead forecasting while SARIMA (0,2,2)(0,2,1)12 was the best in the 3-step ahead forecast. The overall performance of seasonal exponential smoothing was the best in this study. Throughout this study, suggestions were made for the next study regarding electricity consumption in university to consider factors such as semester breaks and students' activities in order to examine its effect in electricity consumption.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],24.444444444444443,0.19374999999999998,0.49374999999999997,1
978,978,Examining new product development speed and team work quality relationship: Evidence from telecom industry,"Although prior research has suggested that team work quality and internal market orientation can affect new product development (NPD) speed in a positive direction, however relatively little research has examined the incremental validity of team work quality to NPD speed after controlling for internal market orientation. To address this theoretical gap in marketing literature, the present study attempts to examine whether the dimensions of team work quality account for incremental variance in NPD speed, after controlling for the dimensions of internal market orientation. Using a random sampling, a total of 149 members of NPD teams in Saudi telecommunications firms responded to measures of each construct. Hierarchical multiple regression analysis was performed to access the incremental validity. Overall results suggest that cohesion accounted for a significant amount of variance relative to coordination, balance of member contribution, efforts, communication, mutual support and other dimensions of internal market orientation in the prediction of NPD speed.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],30.4,-0.004344919786096256,0.24117647058823527,1
979,979,Collaborative supply chain management (SCM) tools for improved teamwork in construction projects,"Fragmentation or the separated working environment has been a major hinderance to effective collaboration among construction industry players and these has been mainly blamed upon the wasteful conventional working practice. Supply Chain Management (SCM), which hold tightly on the notion of collaboration being among its most important enabler and has also proven to contribute to many important elements of an effective collaboration such as better trust, transparency, knowledge sharing, pain-gain sharing etc.; has therefore been promoted to overcome the problem via numerous Collaborative Tools it has to offer. This paper presents part of an on-going research aimed at using SCM Tools to overcome delay and definitely collaboration is an aspect that needs improvement. After conducting a comprehensive literature reviews on past proposal and applications, a number of SCM Collaborative Tools have been identified, elaborated and discussed in this paper; which is expected to serve as a guide towards adopting SCM into construction project practices and thus, achieve the benefits it has to offer. Some of them have been applied in major projects and experienced success hence, deserve more appreciation by the construction world.",60002763,Universiti Utara Malaysia,Sintok,Malaysia,['1710'],36.6,0.23601190476190476,0.5313095238095238,1
980,980,Evaluation of supply chain performance through integration of hierarchical based measurement system and traffic light system: A case study approach to iron sheet factory,"Some of literature shows that the SCM model is effective enough in evaluating and measuring whether the enterprise is went well, efficient and effective. Nevertheless, the available literature is still quite limited in offering perspective in integrating various methods in evaluating and the measurement of SC performance easily and simply. The SCOR model as one of approach in measuring the SC performance, operationally still need to be integrated with another method. This is intended to reveal the clarity of the target and the result of measurement in more effectively, comprehensively, and accountably. In this study, it would be conduct a measurement of SC performance of iron sheet factory enterprise within using the SCOR model through the hierarchical integration based measurement system with traffic light system. The results of this study indicate that the integration of several methods such as Hierarchical Based Measurement System and Traffic Light System can provide a solution for management to evaluate and measure company performance more effectively, comprehensively, accountably and integrated.",60105202,Universitas Muslim Indonesia,Makassar,Indonesia,['1710'],27.5,0.3101190476190476,0.5520833333333334,1
981,981,Effectiveness on drop trailer method (DTM) of haulage industry in Malaysia,"This paper focuses on the customers' commitment and behaviour towards an effective of 'drop trailer method' (DTM) in haulage industry. There was limited study in customers' commitment and behaviour on the efficiency of DTM. The study on DTM was due to the increasing volumes of international trade using haulage transport and trailers which led to rapid growth of container volumes at Malaysian ports. The maximum usage of trailers are needed to cater the growth of containers' movements at present. The detention trailers by the customers during loading and unloading processes caused inefficiency in haulage performance. Therefore, monitoring on the usage of trailers will increase to the overall movements and reduction in the detention times. Exploratory and qualitative studies are also used in this research. The results indicated that the effectiveness of DTM is a crucial part to benchmark on the overall businesses, particularly in effective ways coordinating and utilising to the overall trailers. It is used to indicate haulage operators' achievement towards their objectives. The better control in DTM may be used for better planning in the movements in future. The study suggests on the effective DTM structure for better impact in monitoring haulage business towards costs, revenues and profits.",60031886,Universiti Kuala Lumpur,Kuala Lumpur,Malaysia,['1710'],18.181818181818183,0.2069047619047619,0.36952380952380953,1
982,982,Comparative analysis of multiple criteria decision making (mcdm) approach in warehouse location selection of agricultural products in Thailand,"The objective of this study was to select the suitable warehouse location, which is the focus for business organisations that buy, produce, and store the agricultural products of grass flowers, by using the Multiple Criteria Decision Making theory (MCDM). Three methods were used, which were the Simple Additive Weighting (SAW), Analytic Hierarchy Process (AHP), and Technique for Order Preference by Similarity to Ideal Solution (TOPSIS). Seven main factors that influence the selection of an agricultural product warehouse were explored - the size of the area, land price, labour cost, utilities, the quantity of raw materials in the area, ease of access to the place, and distance from the source of the raw materials to the location. Five areas for the warehouse Chiang Rai province, Thailand were compared to ascertain the suitability of warehouse location by using these factors. The results show that Pa Sang Sub-district, Mae Chan District (E) was the most suitable for the agricultural product warehouse. This study can be further applied to decision making in agricultural businesses.",60103781,Suan Sunandha Rajabhat University,Bangkok,Thailand,['1710'],28.333333333333332,0.20046620046620048,0.47395937395937404,1
984,984,Review on leader member exchange theory: Supply chain management to increase efficiency,"This study aims to examines three elements shape leadership in Leader-Member Exchange (LMX) theory as a relationship and process. The goal of supply-chain management is to create a satisfied customer by coordinating all of the activities of the supply-chain members into a seamless process. LMX quality is important for the company, because it relates to employee behavior and attitudes, including improving employee performance. The research method applied literature review using description logic and systematics. In this article the theory will be observed specially the effect of LMX on employee performance and antecedents of LMX. The results of the study found that the effect of LMX quality on performance is determined by the characteristics of the task as antecedent LMX in the company.",60069383,Universitas Airlangga,Surabaya,Indonesia,['1710'],20.333333333333332,0.3392857142857143,0.6678571428571429,1
985,985,Performance factors in aloe vera's value chain as a green product,"Market mechanism of agricultural products which is currently applied is based on green economy. Green economy is also1 run in a farm of Aloe Vera in Pontianak, Indonesia. This study aims to analyze performance factors of Aloe Vera's value chain as a green product. Value chain is analyzed using SEM analysis (Structural Equation Modelling). This research employs multi-stage sampling method and the samples include farmers, traders, consumers, and policy makers (110 respondents). The results showed that coefficient value was positive, indicating that if there is an increase of attention in value chain, farm performance will improve. Activities of value chain's actors will improve performance as it is related to farming's input-output management, synergy, and value chain's integrity. Both indicators are important to ensure value chain's actors can work to achieve farming performance. Quality performance was examined in terms of diversification and improvement of farming efficiency, increase in added value, increase in farm profitability, and improvement of marketing efficiency. This study contributes to the latest literature by examining the management of the value chain of Aloe Vera farming which is an icon local commodity in Pontianak which is the center of Aloe Vera production in Indonesia.",119764409,Faculty of Economics and Business,Pontianak,Indonesia,['1710'],19.5,0.042727272727272725,0.4245454545454545,1
987,987,Risk management in strategic sourcing: An African perspective,"In this paper, we survey existing literature from scholarly journals published from 1980 to 2015 on the risks and mitigation factors of strategic sourcing in Africa. We also attend the same to a case study based on a large electrical power provider in South Africa. The paper identifies the various supply chain risks facing organisations conducting business in Africa, and where applicable, its mitigation strategies. The study reviewed literature found in numerous scholarly and peerreviewed journals using supply chain risk and risk mitigation as the main search words to filter articles that discuss related topics. The preliminary finding was that there is generally an underrepresentation of Africa in supply chain management literature. It also found that studies discussing supply chain risk and mitigation issues in Africa have focused mainly on the challenges of sourcing in Africa. Another observation was that literature provides some limited insights on how supply chain management tools such as total quality management, negotiation and supplier selection, and just-in-time procurement may be implemented in African countries. However, the available literature manifests significant limitations in scope, both empirically and theoretically when compared to the vast amount of contributions from emerging economies in Asia as well as developed economies. The study thus demonstrates that an untapped opportunity exists for future research in supply chain risk management, which would develop an integrated framework for risk management in strategic sourcing in Africa.",60017220,Radford University,Radford,United States,['1710'],25.666666666666668,0.07901002506265666,0.3901629072681704,1
988,988,Enhancing supply chain performance of SMEs in Thailand using the integrated personnel development model,"Personnel development is a salient component of the human resource supply chain of a business organization. This is especially true for small and medium sized enterprises (SMEs) which has limited resources and could potentially affect their supply chain performance. In an era where modern businesses are driven by innovation, a fresh approach to entrepreneur personnel development should be considered crucial and indispensable. Thus, the objective of this study has been to find a comprehensive and multi-dimensional approach in developing outstanding SME entrepreneurs that could bring about enhanced business performance, including in the vital supply chain functions. Through content analysis of relevant literatures in human resources, three pertinent constructs with strong empirical foundations have been identified, namely happy workplace, transformational leadership, learning organization, were selected and later hypothesized to affect organizational commitment and eventually contribute to enhance performance. Questionnaires were used as a quantitative research tool to collect the data from 500 employees in SMEs in the Nakhon Pathom Province, Thailand. Structural Equation Modelling (SEM) was used for analysing the statistics. The results found that the learning organisation is most appropriate, which has direct and indirect effects on supply chain performance. The mediating effect of organisational commitment on the relationship between learning organisation and supply chain performance was also found. The results of this study will be beneficial to entrepreneurs, the government, and educational agencies to be used as a guideline to form the policies and conduct further research.",60103781,Suan Sunandha Rajabhat University,Bangkok,Thailand,['1710'],23.8,0.2157349896480331,0.5087474120082816,1
990,990,Research on Cooperative Trajectory Planning and Tracking Problem for Multiple Carrier Aircraft on the Deck,"IEEEBased on the concepts of the reciprocal velocity obstacle (RVO) and Dubins methods, an improved Dubins-RVO method that can be applied to the scenario with noncircular obstacles is developed. Based on the Dubins-RVO method and one-sided Symplectic Pseudospectral method, a multiaircraft collaborative trajectory planning method was proposed. The kinematic constraint and terminal boundary conditions can be strictly satisfied in the proposed compound trajectory planning method. In addition, a symplectic pseudospectral receding horizon control (RHC) controller is designed to solve the trajectory tracking problem where the constraints on the state and control variables are considered. The proposed compound trajectory planning method is first applied to a two-aircraft problem. The obtained results demonstrate that compared to the RVO and Dubins-RVO methods, the proposed method can effectively avoid the &#x201C;dead-lock&#x201D; phenomenon and generate feasible trajectory efficiently satisfying all constraints. In addition, simulation experiment for four aircrafts is conducted. Smooth trajectories are obtained. Despite the presence of disturbances in the environment, the trajectories can be tracked with high precision using the symplectic pseudospectral RHC controller.",60082826,Beijing Aeronautical Manufacturing Technology Research Institute,Beijing,China,"['1710', '1706', '1705']",19.0,0.3075,0.5591666666666667,1
991,991,Enabling Workforce Optimization in Constrained Attribute Based Access Control Systems,"IEEEEffective utilization of human capital is one of the key requirements for any successful business endeavor, with reorganization necessary if there are nonproductive employees or employees that are retiring. However, while reorganizing tasks for newer employees, it should be ensured that the employees have the requisite capabilities of handling the assigned tasks. Furthermore, security constraints forbid any arbitrary assignment of tasks to employees and also enforce major dependencies on other employees who have access to the same tasks. Since Attribute Based Access Control (ABAC) is poised to emerge as the de facto model for specifying access control policies in commercial information systems, we consider organizational policies and constraints to be modeled with ABAC. In this work, we define the Employee Replacement Problem (ERP) which answers the question of whether a given set of employees can be replaced by a smaller set of employees, while ensuring that the desired security constraints are not violated. We prove that the problem is NP-hard and use CNF-SAT to obtain a solution. An extensive experimental evaluation is carried out on diverse data sets to validate the efficiency of the proposed solution.",60004750,Indian Institute of Technology Kharagpur,Kharagpur,India,"['1701', '1710', '1709', '1706']",26.571428571428573,0.057291666666666664,0.4902777777777778,1
992,992,A Type of Novel Nonlinear Distributions for Improving Significantly the Stiffness of Carbon Nanotube-Reinforced Composite Beams,"So far, the carbon nanotube (CNT) distributions have been still limited in the linear forms, which may lead to the limitations in maximizing the strength and potential of carbon nanotube reinforced composite (CNTRC) structures. This study, hence proposes a type of novel CNTs distribution for improving the stiffness of CNTRC beams. The distributions are in the nonlinear forms and ensure the same total CNT volume fraction along the thickness of structures. For demonstrating, the effectiveness of the proposed CNT distributions, the static, free vibration and buckling analyses of functionally graded carbon nanotube (FG-CNT) reinforced composite beams using the new CNT distributions are conducted and one-dimensional NURSB basis functions based on the third-order shear deformation theory (TSDT) are utilized to describe the exact geometry and to approximate the unknown solution in finite element model of the beam. The numerical investigations of the geometric and material parameters reveal that the new nonlinear CNT distributions can help increase the normalized frequency, buckling load and the nondimensional central deflection to the maxima of 8%, 16% and 16% respectively, in some conditions of geometric parameters.",60107345,Institute for Computational Science and Technology,Ho Chi Minh City,Viet Nam,['1701'],36.0,0.06794990723562153,0.5304962894248607,1
993,993,Secure Communications Over Cell-Free Massive MIMO Networks With Hardware Impairments,"IEEEThis paper investigates the effect of hardware impairments on the physical layer security for a cell-free massive multiple-input multiple-output (MIMO) network in the presence of pilot spoofing attack. By employing a classical additive hardware distortion model, the joint hardware impairment effects brought by both access points (APs) and user equipments have been taken into account, whereas the eavesdropper is assumed to be equipped with perfect hardware. Thereby, we derive a closed-form lower bound for the ergodic secrecy rate in the presence of imperfect channel state information. To obtain further insights, we investigate asymptotic secrecy performance under different hardware scaling factors. It proves that the hardware-quality scaling effect vanishes as the number of APs increases in the considered secure cell-free massive MIMO system with active attack. Furthermore, by using continuous approximation and path-following algorithms, the optimal power allocation scheme is obtained to maximize the achievable secrecy rate. Numerical results validate the derived results and the efficiency of the proposed power allocation scheme.",60069734,Logistical Engineering University China,Chongqing,China,"['1710', '1706', '1705']",23.0,0.15666666666666668,0.5442857142857143,1
994,994,RAS: A Data-Driven Rigidity-Aware Skinning Model For 3D Facial Animation," Our model builds upon a linear blend skinning (LBS) scheme, where the bone set and skinning weights are shared for diverse identities and learned from the data via a sparse and localized skinning decomposition algorithm. Our model characterizes the animated face into the active expression and the passive deformation: The former is represented by an LBS-based multi-linear model learned from the FaceWareHouse data set, and the latter is represented by a spatially varying as-rigid-as-possible deformation applied to the LBS-based multi-linear model, whose rigidity parameters are learned from the data by a novel rigidity estimation algorithm. Our RAS model is not only generic and expressive for faithfully modelling medium-scale facial deformation, but also compact and lightweight for generating vivid facial animation in real time. We validate the efficiency and effectiveness of our RAS model for real-time 3D facial animation and expression editing.",60098464,Microsoft Research Asia,Beijing,China,['1704'],35.5,0.09015151515151515,0.33181818181818185,0
995,995,Asymptotic Stability Analysis of Discrete-Time Switched Cascade Nonlinear Systems with Delays,"CCBYThis paper addresses the stability issue of a class of delayed switched cascade nonlinear systems consisting of separate subsystems and coupling terms between them. Some global and local asymptotic stability sufficient conditions are proposed, drawing stability conclusion of the overall cascade system from those of separate systems. These results essentially rely on the following observation: For a general delayed switched nonlinear system being asymptotically stable, the trajectories of the perturbed system asymptotically approach zero if so does the perturbation. This observation is one of the main results in the present paper.",60028761,Southwest University for Nationalities,Chengdu,China,['1706'],22.75,0.027083333333333334,0.15416666666666667,1
996,996,Evolutionary Collaborative Human-UAV Search for Escaped Criminals,"The use of unmanned aerial vehicles (UAVs) for target searching in complex environments has increased considerably in recent years. The numerous studies on UAV search methods have been reported, but few have been conducted on collaborative human-UAV search which is common in many applications. In this paper, we present a problem of collaborative human-UAV search for escaped criminals, the aim of which is to minimize the expected time of capture rather than detection. We show that our problem is much more complex than the problem of pure UAV search. The difficulty of our problem is further increased by the fact that criminals will attempt to avoid detection and capture. To solve the problem, we propose a hybrid evolutionary algorithm (EA) that uses three evolutionary operators, namely, comprehensive learning, variable mutation, and local search, to efficiently explore the solution space. The experimental results demonstrate that the proposed method outperforms some well-known EAs and other popular UAV search methods on test instances. An application of our method to a real-world operation took 311 min to capture a criminal who had escaped for over three days, validating its practicability and performance advantage. This paper provides a good basis for promoting the application of EAs to a wider class of man-machine collaboration scheduling problems.",60069734,Logistical Engineering University China,Chongqing,China,"['1712', '1703']",23.333333333333332,0.049404761904761896,0.4097222222222222,1
997,997,Some measures to detect the influencer on social network based on information propagation,"Determining the influencer for a brand plays an important role in the influence marketing. The influencer makes a brand approaching goal customers easily and quickly. There are many current methods to measure the influence of a user. In this paper, a model for representing a social network is presented. It includes two main objects: users and tags. This model can represent relationship between these objects clearly. Besides that, some influence measures are proposed. They represent the ability of the influence on other people by relationships between users and the concern to user's tags, as well as the speed of the user's tag propagation on the social network. Based on them, the problem about determining the influencer of a specific brand on a social network is solved. Our method is tested in practice and gets some positive results.",60078566,Vietnam National University Ho Chi Minh City,Ho Chi Minh City,Viet Nam,"['1712', '1709', '1707', '1705']",13.7,0.1525432900432901,0.3711038961038961,1
998,998,Color temperature tuning: Allowing accurate post-capture white-balance editing,"The in-camera imaging pipeline consists of several routines that render the sensor's scene-referred raw-RGB image to the final display-referred standard RGB (sRGB) image. One of the crucial routines applied in the pipeline is white balance (WB). WB is performed to normalize the color cast caused by the scene's illumination, which is often described using correlated color temperature. WB is applied early in the in-camera pipeline and is followed by a number of nonlinear color manipulations. Because of these nonlinear steps, it is challenging to modify an image's WB with a different color temperature in the sRGB image. As a result, if an sRGB image is processed with the wrong color temperature, the image will have a strong color cast that cannot be easily corrected. To address this problem, we propose an imaging framework that renders a small number of ""tiny versions"" of the original image (e.g., 0.1% of the full-size image), each with different WB color temperatures. Rendering these tiny images requires minimal overhead from the camera pipeline. These tiny images are sufficient to allow color mapping functions to be computed that can map the full-sized sRGB image to appear as if it was rendered with any of the tiny images' color temperature. Moreover, by blending the color mapping functions, we can map the output sRGB image to appear as if it was rendered through the camera pipeline with any color temperature. These mapping functions can be stored as a JPEG comment with less than 6 KB overhead. We demonstrate that this capture framework can significantly outperform existing solutions targeting post-capture WB editing.",60033420,York University,Toronto,Canada,['1707'],21.916666666666668,0.05714285714285714,0.5551587301587301,1
999,999,Developing a visual method to characterize displays,"The goal is to develop a display characterization model to include the personal vision characteristics. A two-step model for visually characterizing displays was developed. It was based on the concept of half-toning technique for obtaining gamma factor for each colour channel, and unique hue concept for achieving 3x3 matrix coefficients, respectively. The variation can be presented by the optimized RGB primaries for each observer. The typical difference between the individual and the measured ground truth is 2.2 in terms of CIEDE2000 units.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],16.4,0.04404761904761905,0.37142857142857144,1
1000,1000,Estimating concentrations of pigments using encoder-decoder type of neural network.,"In this paper, we propose a method to estimate the concentration of pigments mixed in a painting, using the encoderdecoder model of neural networks. Encoder-decoder model is trained to output value which is same as input and its middle output extracts a certain feature as compressed information of the input. In this instance, the input and the output are spectral data of a painting. We trained the model to have pigments concentration as compressed information as a middle output. We used the dataset which was obtained from 19 pigments. The dataset has scattering coefficient and absorption coefficient of each pigment. We applied Kubelka-Munk theory to the coefficients to obtain many patterns of spectral data. It's shown that the accuracy of estimation is very high, and the speed of execution is very fast compared with a conventional method using simple for-loop optimization. We concluded our method is more effective and practical.",60002787,Chiba University,Chiba,Japan,['1707'],16.666666666666664,0.1782857142857143,0.4118928571428571,1
1001,1001,Vividness as a Colour Appearance Attribute,"It is desirable to communicate colour with intuitive terms which are understood not only by experts. Studies have showed that chroma, saturation and colourfulness are more difficult to understand for ""ordinary people"" than other colour terms. Vividness has recently it been proposed as a formal colour scale, and it is believed to be more intuitive than other colour science terms. In this work we investigate how people interpret vividness of colour samples and test current models by collecting visual data in a psychophysical experiment. 31 people were asked to judge the vividness of 53 NCS patches and 53 colour matches on display on a scale from 0 to 100. The majority of the variations in the vividness data is predicted by chroma, while the results indicate that lightness does not contribute in prediction of the observers' interpretation of vividness. Current models did not outperform chroma as a single predictor for the vividness data obtained in this experiment.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],22.428571428571427,-0.005952380952380952,0.4595238095238096,1
1002,1002,Appearance perception of textiles: A tactile and visual texture study,"Texture analysis and characterization based on human perception has been continuously sought after by psychology and computer vision researchers. However, the fundamental question of how humans truly perceive texture still remains. In the present study, using a series of textile samples, the most important perceptual attributes people use to interpret and evaluate the texture properties of textiles were accumulated through the verbal description of texture by a group of participants. Smooth, soft, homogeneous, geometric variation, random, repeating, regular, color variation, strong, and complicated were ten of the most frequently used words by participants to describe texture. Since the participants were allowed to freely interact with the textiles, the accumulated texture properties are most likely a combination of visual and tactile information. Each individual texture attribute was rated by another group of participants via rank ordering. Analyzing the correlations between various texture attributes showed strong positive and negative correlations between some of the attributes. Principal component analysis on the rank ordering data indicated that there is a clear separation of perceptual texture attributes in terms of homogeneity and regularity on one hand, and non-homogeneity and randomness on the other hand.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],23.625,0.04111305361305361,0.4998991393222162,1
1003,1003,Skin balancing: Skin color-based calibration for portrait images to enhance the affective quality,"Because our sensitivity to human skin color leads to a precise chromatic adjustment, skin color has been considered a calibration target to enhance the quality of images that contain human faces. In this paper, we investigated the perceived quality of portrait images depending on how the target skin color is defined: measured, memory, digital, or CCT skin color variations. A user study was conducted; 24 participants assessed the quality of white-balanced portraits on five criteria: reality, naturalness, appropriateness, preference, and emotional enhancement. The results showed that the calibration using measured skin color best served the aspects of reality and naturalness. With regard to appropriateness and preference, digital skin color obtained the highest score. Also, the memory skin color was appropriate to calibrate portraits with emotional enhancement. In addition, the other two CCT target colors enhanced the affective quality of portrait images, but the effect was quite marginal. In the foregoing, labelled Skin Balance, this study proposes a set of alternative targets for skin color, a simple but efficient way of reproducing portrait images with affective enhancement.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,['1707'],22.0,0.16136363636363635,0.3483766233766234,1
1004,1004,Impact of shape on apparent translucency differences,"Translucency is one of the major appearance attributes. Apparent translucency is impacted by various factors including object shape and geometry. Despite general proposals that object shape and geometry have a significant effect on apparent translucency, no quantification has been made so far. Quantifying and modeling the impact of geometry, as well as comprehensive understanding of the translucency perception process, are a point of not only academic, but also industrial interest with 3D printing as an example among many. We hypothesize that a presence of thin areas in the object facilitates material translucency estimation and changes in material properties have larger impact on apparent translucency of the objects with thin areas. Computergenerated images of objects with various geometry and thickness have been used for a psychophysical experiment in order to quantify apparent translucency difference between objects while varying material absorption and scattering properties. Finally, absorption and scattering difference thresholds where the human visual system starts perceiving translucency difference need to be identified and its consistency needs to be analyzed across different shapes and geometries.",60027424,Fraunhofer Institute for Computer Graphics Research IGD,Darmstadt,Germany,['1707'],24.714285714285715,0.024375,0.53375,1
1005,1005,Improvement of blood pressure estimation from face video using RGB camera,"In this paper, we investigated the correlation between blood pressure (BP) and image-based pulse transit time (iPTT) acquired from only face using RGB camera. In general, the value of iPTT can be calculated from a transition time at peaks of hemoglobin amount which is extracted from RGB values of the camera. The transition time of peaks is obtained by time of the peak at the face and the palm. In the previous research, it is known that there is a correlation between BP and iPTT. Therefore, blood pressure can be estimated by acquiring iPTT from video taken using RGB camera. However, it is necessary to take video of face and palm simultaneously in this conventional iPTT measurement method. It is difficult to take the video of face and palm simultaneously. In order to solve this problem, we investigated whether iPTT can be acquired from a single part of body. At first, we took a video of face and palm using a high-speed camera and investigated whether the pulse wave flow can be observed. As a result, we were able to observe the propagation of the pulse wave in the regions of face and palm. Hence, iPTT acquisition from the single part of body is expected to be possible in these two parts. Next, we set a region of interest (ROI) on the chin and the forehead for the face, and the center of the palm and thenar for the palm. Then, pulse waves were extracted from each region, and iPTT was calculated from each part. We found that iPTT acquired from face is long and stable, but iPTT acquired from palm is short and unstable. Moreover, we examined the correlation between blood pressure and iPTT acquired from face. Consequently, a correlation was found between blood pressure and iPTT acquired from only face.",60002787,Chiba University,Chiba,Japan,['1707'],18.875,-0.023669467787114845,0.5065126050420168,1
1006,1006,Temporary tritanopia: Effects of cataract surgery on color,"This pilot study made a wide variety of visual measurements before, during, and after bilateral cataract surgery. This article describes the changes in color discrimination and color appearance resulting from cataract implants. It used the F-M 100 Hue Test, color matching of real scenes, and color-balance titration measurements. The pre-surgery data indicated that the previously normal color observers had severe tritanopic anomalies. Lens replacement restored normal color vision.",113660628,McCann Imaging,Arlington,United States,['1707'],13.6,0.08,0.4,1
1007,1007,Polarized multispectral imaging for the diagnosis of skin cancer,"The effective and non-invasive diagnosis of skin cancer is a hot topic in biophotonics since the current gold standard, a biopsy, is slow and costly. Non-invasive optical techniques such as polarization and multispectral imaging have arisen as powerful tools to overcome these constraints. The combination of these techniques provides a comprehensive characterization of skin chromophores including polarization, color and spectral features. Hence, in this work we propose a polarized multispectral imaging device that works from 414 nm to 995 nm and at 0°, 45° and 90° polarization configurations. Preliminary results performed over 20 nevi and 20 melanoma found statistically significant descriptors (p<0.05) that discriminated between these two lesion etiologies. A further analysis of more lesions is expected to contribute in reducing the false positives during the diagnosis process and, as a consequence, the number of necessary biopsies.",60030315,Hospital Clinic Barcelona,Barcelona,Spain,['1707'],22.833333333333332,0.0942307692307692,0.6019230769230769,1
1008,1008,Future directions in image quality,"With the advancements made in the field of image processing and computer vision, the last few decades have seen an increase in studies focused on image quality assessment. While this has resulted in the introduction of different new metrics which some show high correlation with the perceptual judgement of the human observers there still exists a huge room for improvement. In this short paper which is prepared as a complement to the workshop on Future Directions in Image Quality at CIC 27 in Paris, France we aim to introduce future directions in the field and challenges facing ahead.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],32.66666666666667,0.049636363636363645,0.3311212121212121,1
1009,1009,Illuminant estimation through reverse calibration of an auto white-balanced image that contains displays,"This study proposes an illuminant estimation method that reproduces the original illuminant of a scene using a mobile display as a target. The original lighting environment of an auto white-balancing (AWB) photograph is obtained through reverse calibration, using the white point of a display in the photograph. This reproduces the photograph before AWB processed, and we can obtain the illuminant information using Gray World computation. The study consists of two sessions. In Session 1, we measured the display's white points under varying illuminants to prove that display colors show limited changes under any light conditions. Then, in Session 2, we generated the estimations and assessed the performance of display-based illuminant estimation by comparing the result with the optically measured values in the real situation. Overall, the proposed method is a satisfactory way to estimate the less chromatic illuminants under 6300 K that we experience as indoor light in our daily lives.",60032144,Korea Advanced Institute of Science &amp; Technology,Yusong,South Korea,['1707'],21.571428571428573,0.13744588744588745,0.30995670995670993,1
1010,1010,Degree of chromatic adaptation under adapting conditions with different luminance and chromaticities,"Adapting chromaticities are not considered in characterizing the degree of chromatic adaptation in various chromatic adaptation transforms (CATs). Though several recent studies have clearly suggested that the effect of adapting chromaticities on degree of chromatic adaptation should not be ignored, these studies were only carried out under a single adapting luminance level. This study was carefully designed to systematically vary the adapting luminance and chromaticities to investigate whether the adapting luminance and chromaticities jointly affect the degree of chromatic adaptation. Human observers adjusted the color of a stimulus produced by a self-luminous display to make it appear the whitest under each of the 17 different adapting conditions. It was found the adapting chromaticities and luminance jointly affected the degree of chromatic adaptation. At a same adapting luminance level, the degree of chromatic adaptation was found lower under a lower adapting CCT (i.e., 2700 and 3500 K). A higher adapting luminance can significantly increase the degree of chromatic adaptation, especially when the adapting CCT was low (i.e., 2700 and 3500 K).",60008928,Hong Kong Polytechnic University,Kowloon,Hong Kong,['1707'],24.285714285714285,0.039540816326530615,0.4891156462585034,1
1011,1011,Modelling incomplete chromatic adaptation on a display under different ambient illuminations,"The purposes of this study was to investigate the chromatic adaptation and adaptive whites on a display under various ambient lighting conditions with different chromaticity and illuminance. An image including black text and white background was rendered by means of the CAT02 chromatic adaptation transform, into 42 different white stimuli varying at 6 CCTs and 7 Duv levels. Twenty observers assessed the neutral white evaluations of each color stimulus via psychophysical experiments. The optimization based on the neutral white stimulus under each ambient lighting condition suggested a lower degree of chromatic adaptation under the conditions with a lower CCT and a lower illuminance level. The results were used to model the adaptive display white and the incomplete adaptation factor (D) for CAT02 under different ambient illumiantions.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],25.2,-0.016666666666666666,0.2733333333333333,1
1012,1012,Removing gloss using Deep Neural Network for 3D Reconstruction,"3D reconstruction is used for inspection of industrial products. The demand for measuring 3D shapes is increased. There are many methods for 3D reconstruction using RGB images. However, it is difficult to reconstruct 3D shape using RGB images with gloss. In this paper, we use the deep neural network to remove the gloss from the image group captured by the RGB camera, and reconstruct the 3D shape with high accuracy than conventional method. In order to do the evaluation experiment, we use CG of simple shape and create images which changed geometry such as illumination direction. We removed gloss on these images and corrected defect parts after gloss removal for accurately estimating 3D shape. Finally, we compared 3D estimation using proposed method and conventional method by photo metric stereo. As a result, we show that the proposed method can estimate 3D shape more accurately than the conventional method.",60002787,Chiba University,Chiba,Japan,['1707'],16.444444444444443,0.07934065934065937,0.5488644688644688,1
1013,1013,Change of color appearance due to extremely high light level: Corresponding colors under 100 and 3000 cd/m2,"Great efforts have been made to develop color appearance models to predict color appearance of stimuli under various viewing conditions. CIECAM02, the most widely used color appearance model, and many other color appearance models were all developed based on corresponding color datasets, including LUTCHI data. Though the effect of adapting light level on color appearance, which is known as ""Hunt Effect"", is well known, most of the corresponding color datasets were collected within a limited range of light levels (i.e., below 700 cd/m2), which was much lower than that under daylight. A recent study investigating color preference of an artwork under various light levels from 20 to 15000 lx suggested that the existing color appearance models may not accurately characterize the color appearance of stimuli under extremely high light levels, based on the assumption that the same preference judgements were due to the same color appearance. This article reports a psychophysical study, which was designed to directly collect corresponding colors under two light levels- 100 and 3000 cd/m2 (i.e., ~ 314 and 9420 lx). Human observers completed haploscopic color matching for four color stimuli (i.e., red, green, blue, and yellow) under the two light levels at 2700 or 6500 K. Though the Hunt Effect was supported by the results, CIECAM02 was found to have large errors under the extremely high light levels, especially when the CCT was low.",60008928,Hong Kong Polytechnic University,Kowloon,Hong Kong,['1707'],32.57142857142857,0.15331932773109247,0.43484593837535007,1
1014,1014,No-reference image quality metric for tone-mapped images,"Tone-mapping operators transform high dynamic range (HDR) images into displayable low dynamic range (LDR) images. Image quality evaluation of these LDR images is not possible by comparison with their corresponding high dynamic range images. Hence, a no-reference image quality metric for tone-mapped LDR images is proposed based on the fitting to the present psychophysical results including different visual image quality attributes. Ten images, including HDR natural scenes, were tonemapped using six TMOs. They were used in the assessment and visual attributes were determined to predict the quality of these images. The visual attributes (brightness and Naturalness) were modeled using parameters derived from CAM16-UCS. Results showed that the quality prediction of the model had a reasonable degree of accuracy.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],16.857142857142858,0.07,0.31124999999999997,1
1015,1015,Real-world environment affects the color appearance of virtual stimuli produced by augmented reality,"Color appearance models have been extensively studied for characterizing and predicting the perceived color appearance of physical color stimuli under different viewing conditions. These stimuli are either surface colors reflecting illumination or selfluminous emitting radiations. With the rapid development of augmented reality (AR) and mixed reality (MR), it is critically important to understand how the color appearance of the objects that are produced by AR and MR are perceived, especially when these objects are overlaid on the real world. In this study, nine lighting conditions, with different correlated color temperature (CCT) levels and light levels, were created in a real-world environment. Under each lighting condition, human observers adjusted the color appearance of a virtual stimulus, which was overlaid on a real-world luminous environment, until it appeared the whitest. It was found that the CCT and light level of the real-world environment significantly affected the color appearance of the white stimulus, especially when the light level was high. Moreover, a lower degree of chromatic adaptation was found for viewing the virtual stimulus that was overlaid on the real world.",60008928,Hong Kong Polytechnic University,Kowloon,Hong Kong,['1707'],25.428571428571427,0.14911764705882355,0.5377170868347338,1
1016,1016,Perceptual estimation of diffuse white level in HDR images,"Diffuse white is an important concept in all color appearance models. However, there is a lack of research directly about the perceived diffuse white in HDR images. Three experiments were conducted to explore the perceptual estimation of diffuse white in real HDR images when presented on displays. The first experiment showed that the perceptual estimation of diffuse white relied more on the image content than the clipped peak luminance levels. Experiment II used images with different neutral density filters rather than clipping. The normalized luminance levels of the perceptual estimation were similar, depending on image content but not on image absolute luminance levels. Moreover, in both experiments, no significant difference can be found between expert and naive observers. The variance across images agreed with each other between experiment I and II. However, both results demonstrated that the absolute luminance level of observers' estimation is higher than the calibrated diffuse white level. Experiment III focused on exploring the impact of measurement methodologies on the absolute luminance level of the estimated diffuse white. Results of experiment III verified that the absolute luminance level of the perceptual estimation can be manipulated by the measurement methodology but the variance across image content is stable.",60103907,Nippon Hoso Kyokai,Tokyo,Japan,['1707'],18.181818181818183,0.08988095238095237,0.4706349206349207,1
1017,1017,A testing paradigm for quantifying ICC profilers,"To reproduce colors in one system which differs from another system in terms of the color gamut, it is necessary to use a color gamut mapping process. This color gamut mapping is a method to translate a specific color from a medium (screen, digital camera, scanner, digital file, etc) into another system having a difference in gamut volume. There are different rendering intent options defined by the International Color Consortium [5] to use the different reproduction goals of the user [19]. Any rendering intent used to reproduce colors, includes profile engine decisions to do it, i.e. looking for color accuracy, vivid colors or pleasing reproduction of images. Using the same decisions on different profile engines, the final visual output can look different (more than one Just Noticeable Difference[16]) depending on the profile engine used and the color algorithms that they implement. Profile performance substantially depends on the profiler engine used to create them. Different profilers provide the user with varying levels of liberty to design a profile for their color management needs and preference. The motivation of this study is to rank the performance of various market leading profiler engines on the basis of different metrics designed specifically to report the performance of particular aspects of these profiles. The study helped us take valuable decisions regarding profile performance without any visual assessment to decide on the best profiler engine.",101094834,HP Inc.,Barcelona,Spain,['1707'],22.9,0.04722222222222222,0.434920634920635,1
1018,1018,Illuminance impacts opacity perception of textile materials,"Opacity is an important appearance attribute in the textile industry. Obscuring power and the way textile samples block light can define product quality and customer satisfaction in the lingerie, shirting, and curtain industries. While the question whether opacity implies the complete absence of light transmission remains open, various factors can impact cues used for opacity assessment. We propose that perceived opacity has poor consistency across various conditions and it can be dramatically impacted by the presence of a high-illuminance light source. We have conducted psychophysical experiments asking human subjects to classify textile samples into opaque and non-opaque categories under different illumination conditions. We have observed interesting behavioral patterns and cues used for opacity assessment. Finally, we found obvious indications that the high-illuminance light source has a significant impact on opacity perception of some textile samples, and to model the impact based on material properties remains a promising direction for future work.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],21.571428571428573,0.14539473684210527,0.5526315789473684,1
1019,1019,Effects of black luminance level on image quality,"The image quality is affected by the black luminance level of the image. This research aimed to investigate how low luminance levels are required to maintain image quality. The psychophysical experiment was carried out in a dark room using OLED display. Total of 6 different black luminance levels (0.003, 0.05, 0.1, 0.2, 0.3, and 1 cd/m2) were used in the experiment. Total of 20 participants was invited to evaluate the image quality. For the experiment, twelve test images are used and these test images categorized into three groups as dark, medium bright and bright image group by image histogram distribution. Each image is rendered by adjusting six different black luminance levels. Result found that the black level is higher than 0.1 cd/m2, the preference for the image is decreased. The best performance is achieved when the black level is 0.003 cd/m2, but there is no big difference from 0.1 cd/m2. The final result shows that a change in black level between about 0.003 cd/m2 and 0.1 cd/m2 does not significantly affect image quality.",60103153,Ulsan National Institute of Science and Technology,Ulsan,South Korea,['1707'],17.3,0.036309523809523826,0.5464285714285715,1
1020,1020,Benchmark of 2D quality metrics for the assessment of 360-deg images,"Omnidirectional or 360-degree images are becoming very popular in many applications and several challenges are raised because of both the nature and the representation of the data. Quality assessment is one of them from two different points of view: objectively or subjectively. In this paper, we propose to study the performance of different metrics belonging to various categories including simple mathematical metrics, humand perception based metrics and spherically optimized metrics. The performance of these metrics is measured using different tools such as PLCC, SROCC, KROCC and RMSE based on the only publically available database from Nanjing university. The results show that the metric that are considered as optimized for 360 degrees images are not providing the best correlation with the human judgement of the quality.",60032653,Universite de Poitiers,Poitiers,France,['1707'],25.0,0.195625,0.46294642857142854,1
1021,1021,Detecting wetness on skin using RGB camera,"In this study, we propose a method to detect wetness on the surface of human skin and skin phantoms using an RGB camera. Recent research on affect analysis has addressed the non-contact multi-modal analysis of affect aimed at such applications as automated questionnaires. New modalities are needed to develop a more accurate system for analyzing affects than the current system. Thus we focus on emotional sweating, which is among the most reliable modalities in contact methods for affect analysis. However, sweat detection on the human skin has not been achieved by other researchers, and thus it is unclear whether their feature values are useful. The proposed method is based on feature values of color and glossiness obtained from images. In tests of this method, the error rate was approximately 6.5% on a skin phantom and at least approximately 12.7% on human skin. This research will help to develop non-contact affect analysis.",60002787,Chiba University,Chiba,Japan,['1707'],18.875,0.03821022727272728,0.3851799242424242,1
1022,1022,Color processing and management in Ghostscript,"Ghostscript has a long history in the open source community and was developed at the same time that page description languages were evolving to the complex specification of PDF today. Color is a key component in this specification and its description and proper implementation is as complex as any other part of the specification. In this document, the color processing and management that takes place in Ghostscript is reviewed with a focus on how its design achieves computational efficiency while providing flexibility for the developer and user.",122111436,Artifex Software,Novato,United States,['1707'],29.0,-0.07500000000000001,0.4,1
1023,1023,Estimation of layered ink layout from arbitrary skin color and translucency in inkjet 3d printer,"In this paper, we propose a layout estimation method for multi-layered ink by using PSF measurement and machine learning. This estimation can bring various capabilities of color reproduction for the newfangled 3D printer that can apply multi-layered inkjet color. Especially, the control of translucency is useful for the reproduction of skin color that is overpainted flesh color on bloody-red layer. Conventional method of this layer design and color selection depended on the experience of professional designer. However, it is difficult to optimize the color selection and layer design for reproducing complex colors with many layers. Therefore, in this research, we developed an efficiency estimation of color layout for human skin with arbitrary translucency by using machine learning. Our proposed method employs PSF measurement for quantifying the color translucency of overlapped layers. The machine learning was performed by using the correspondence between these measured PSFs and multi-layered printings with 5-layer neural network. The result was evaluated in the CG simulation with the combination of 14 colors and 10 layers. The result shows that our proposed method can derive an appropriate combination which reproduce the appearance close to the target color and translucency.",60082079,Tokyo Metropolitan College of Technology,Tokyo,Japan,['1707'],19.1,0.03809523809523809,0.4464285714285714,1
1024,1024,Joint design of plane-dependent FM screens sets using DBS algorithm,"Color Halftoning is a technique for generating a halftone image by using a limited number of colorants to simulate a continuous-tone image as perceived by a human viewer. This paper describes an algorithm to jointly design three screens for Cyan, Magenta and Yellow colorants using the Direct Binary Search algorithm. The results show that high-quality color halftone images can be obtained using the screens sets, and the computational complexity will be greatly reduced.",60009254,Purdue University,West Lafayette,United States,['1707'],24.333333333333332,0.16571428571428573,0.2785714285714286,1
1025,1025,A psychovisual study of print smoothness via metameric samples,"The smoothness of a print is one of its main image quality attributes. Here smoothness can refer to the level of unexpected changes or discontinuities in color transitions (at a macro scale) or the level of local variation (at a micro scale), sometimes also described as grain. This paper starts with presenting an approach to building a first-ever set of metameric printed samples that match in color but vary in grain, followed by a psychovisual study of smoothness perception based on a large number of evaluations by both experts and non-experts. This data shows high levels of intra- and inter-observer correlation and can therefore serve as a robust ground truth for understanding and modelling the print smoothness phenomenon. Then, a previously published predictive smoothness model is revisited, that estimates smoothness from a digital halftone before it is printed, and it is shown to result in high degrees of correlation between observer assigned smoothness judgments and computationally predicted scores. The paper also reports the results of tuning the smoothness metrics parameters to further enhance is alignment with the psychovisual ground truth.",101094834,HP Inc.,Barcelona,Spain,['1707'],30.0,0.07047619047619048,0.3898412698412698,1
1026,1026,Evaluating Colour Constancy on the new MIST dataset of Multi-Illuminant Scenes,"A new image test set of synthetically generated, full-spectrum images with pixelwise ground truth has been developed to aid in the evaluation of illumination estimation methods for colour constancy. The performance of 9 illumination methods is reported for this dataset along and compared to the optimal single-illuminant estimate. None of the methods specifically designed to handle multi-illuminant scenes is found to perform any better than the optimal single-illuminant case based on completely uniform illumination.",60018491,Simon Fraser University,Burnaby,Canada,['1707'],24.666666666666668,0.20909090909090908,0.4136363636363636,1
1027,1027,Least-squares optimal contrast limited histogram equalisation,"Contrast Limited Histogram Equalisation moves the input image histogram gently towards one which has a more uniform distribution. Viewed as a tone mapping operation, CLHE generates a tone curve with bounded max and min slopes. It is this boundedness which ensures that the processed images have more detail but few artefacts. Outside of limiting contrast, recent improvements to histogram equalisation include constraining the tone curve to make good whites and blacks and constraining the tone curve to be smooth. This paper makes three contributions. First, we show that the CLHE formalism is not least-squares optimal but optimality can be achieved by reformulating the problem in a quadratic programming framework. Second, we incorporate the additional constraints of tone curve smoothness and good whites and blacks in our quadratic programming CLHE framework. Third, experiments demonstrate the utility of our method.",60000112,University of East Anglia,Norwich,United Kingdom,['1707'],17.25,0.22912087912087914,0.33663003663003666,1
1028,1028,Coupled retinex,"Retinex is a colour vision model introduced by Land more than 40 years ago. Since then, it has also been widely and successfully used for image enhancement. However, Retinex often introduces colour and halo artefacts. Artefacts are a necessary consequence of the per channel color processing and the lack of any strong control for controlling the locality of the processing (halos are very local errors). In this paper we relate an input to the corresponding output processed retinex image by using a single shading term which is both spatially varying and smooth and a global colour shift. This coupling dramatically reduces common Retinex artefacts. Coupled Retinex is strongly preferred in preference tests.",60032942,Universitat Pompeu Fabra Barcelona,Barcelona,Spain,['1707'],16.0,0.18593073593073592,0.5028138528138528,1
1029,1029,Exposure invariance in spectral reconstruction from RGB images,"In the spectral reconstruction (SR) problem, reflectance and/or radiance spectra are recovered from RGB images. Most of the prior art only attempts to solve this problem for fixed exposure conditions, and this limits the usefulness of these approaches (they can work inside the lab but not in the real world). In this paper, we seek methods that work well even when exposure is unknown or varies across an image, namely 'exposure invariance'. We begin by re-examining three main approaches - regression, sparse coding and Deep Neural Networks (DNN) - from a varying exposure viewpoint. All three of these approaches are predominantly implemented assuming a fixed capturing condition. However, the leading sparse coding approach (which is almost the best approach overall) is shown to be exposure-invariant, and this teaches that exposure invariance need not come at the cost of poorer overall performance. This result in turn encouraged us to revisit the regression approach. Remarkably, we show that a very simple root-polynomial regression model - which by construction is exposure-invariant - provides competitive performance without any of the complexity inherent in sparse coding or DNNs.",60000112,University of East Anglia,Norwich,United Kingdom,['1707'],22.875,0.19404761904761905,0.3605442176870749,1
1030,1030,Proposed modification to the CAM16 colour appearance model to predict the simultaneous colour contrast effect,"Experiments were carried out to investigate the simultaneous colour contrast effect on a self-luminous display using colour matching method. The goals of this study were to accumulate a new visual dataset and to extend CAM16 to predict the simultaneous colour contrast effect. Five coloured targets together with a neutral grey were studied. A total of 132 test/background combinations were displayed on a calibrated display. Twenty normal colour vision observers performed colour matching in the experiment. In total, 2,640 matches were accumulated. The data were used to accurately model the lightness and hue contrast results. The model was also successfully tested using two independent datasets.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],13.0,0.15404040404040406,0.4903198653198653,1
1031,1031,Conceptualization of color temperature scenario applied to quality lighting design.,"Quality lighting is characterized by four major factors, one of them being the color temperature. When designed for elderly, this quality lighting can allow them to evolve within their environment safely, independently and above all comfort without having to focus on the effects of aging. This article aims to show the benefits of designing color temperature scenarios, made possible for example by dynamic LED lighting, thus contributing to the production of comfortable lighting and thus quality.",60122689,Laboratoire Plasma et Conversion d’Energie,Toulouse,France,['1707'],25.333333333333332,0.07708333333333334,0.4486111111111111,1
1032,1032,On an euler-lagrange equation for color to grayscale conversion,"In this paper we give a new method to find a grayscale im- age from a color image. The idea is that the structure tensors of the grayscale image and the color image should be as equal as possible. This is measured by the energy of the tensor differences. We deduce an Euler-Lagrange equation and a second variational inequality. The second variational inequality is remarkably sim- ple in its form. Our equation does not involve several steps, such as finding a gradient first and then integrating it. We show that if a color image is at least two times continuous differentiable, the resulting grayscale image is not necessarily two times continuous differentiable.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],16.0,0.07603305785123965,0.4261707988980716,1
1033,1033,Measurement of CIELAB spatio-chromatic contrast sensitivity in different spatial and chromatie directions,"This paper presents data on CIELAB chromatic contrast sensitivity collected in a psychophysical experiment. To complement previously published data in the low-frequency range, we selected five spatial frequencies in the range from 2.4 to 19.1 cycles per degree (cpd). A Gabor stimulus was modulated along six chromatic directions in the a∗-b∗ plane. We also investigated the impact on contrast sensitivity from spatial orientations - both vertically and diagonally oriented stimuli were used. The analysis of the collected data showed lowest contrast sensitivity in the chromatic direction of around 120° from the positive a∗-axis. The contrast sensitivity in the diagonal spatial orientation is slightly lower when compared to the vertical orientation.",60031912,Digimarc Corporation,Beaverton,United States,['1707'],18.333333333333332,-0.03535353535353535,0.2929292929292929,1
1034,1034,Assessing colour differences under a wide range of luminance levels using surface and display colours,"Two experimental data sets were accumulated for evaluating colour differences under a wide range of luminance levels using the printed colours in a spectrum tuneable viewing cabinet and selfluminous colours on a display respectively. For the surface mode experiment, pairs of samples were assessed at 9 phases ranged from 0.25 to 1128 cd/m2. For the luminous mode experiment, it was conducted in 6 phases ranged from 0.25 to 279 cd/m2. There were 140 and 42 pairs of samples judged by 20 observers using a sixcategory scales for each phase. The results were used to establish the just noticeable difference (JND) at each luminance level and showed a great agreement between two modes of colours. These were used to test the performance of 5 uniform colour spaces and colour difference equations. Also, the spaces or equations were extended to improve the fit to the present data sets.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],20.857142857142858,0.20000000000000004,0.3416666666666666,1
1035,1035,Time course of chromatic adaptation under dynamic lighting,"Chromatic adaptation is an extensively studied concept. However, less is known about the time course of chromatic adaptation under gradually-changing lighting. Two experiments were carried out to quantify the time course of chromatic adaptation under dynamic lighting. In the first experiment, a step change in lighting chromaticity was used. The time course of adaptation was well described by the Rinner and Gegenfurtner slow adaptation exponential model [Vision Research, 40(14), 2000], and the adaptation state after saturation differed between observers. In the second experiment, chromatic adaptation was measured in response to two different speeds of lighting chromaticity transitions. An adjusted exponential model was able to fit the observed time course of adaptation for both lighting transition speeds.",60032882,Technische Universiteit Eindhoven,Eindhoven,Netherlands,['1707'],16.57142857142857,0.07592592592592592,0.32499999999999996,1
1036,1036,Line spread function of specular reflection and gloss unevenness analysis,"In this paper, we examined the physical meaning of the widely used gloss evaluation. Gloss is one of the important qualities for materials. A visual test of the sharpness of a specular reflection image, i.e. gloss, on the surface of materials is often performed to estimate the gloss of materials. If the specular reflection image is sharp, we estimate that it has high gloss. This means that gloss can be estimated by measuring the sharpness of the specular reflection image. In this case, a line light source such as a fluorescent lamp is often used. Here we call it the line light source observation method. We developed a measurement apparatus based on the line light source observation method. As a result of experimental verification, it is confirmed that the Line Spread Function of Specular Reflection (SR-LSF) can be derived from the line light source observation images. However, the reflected image of line light source observation method is considered to be strictly different from SR-LSF. On the other hand, it is clarified that the line source observation method is an approximate SR-LSF measurement method. We also introduce the reconstruct method of gloss unevenness image by following visual observation conditions and image processing in human brain.",60002787,Chiba University,Chiba,Japan,['1707'],15.692307692307692,0.11476190476190477,0.49085034013605433,1
1037,1037,Beyond raw-RGB and sRGB: Advocating access to a colorimetric image state,"Most modern cameras allow captured images to be saved in two color spaces: (1) raw-RGB and (2) standard RGB (sRGB). The raw-RGB image represents a scene-referred sensor image whose RGB values are specific to the color sensitivities of the sensor's color filter array. The sRGB image represents a displayreferred image that has been rendered through the camera's image signal processor (ISP). The rendering process involves several camera-specific photo-finishing manipulations intended to make the sRGB image visually pleasing. For applications that want to use a camera for purposes beyond photography, both the raw-RGB and sRGB color spaces are undesirable. For example, because the raw-RGB color space is dependent on the camera's sensor, it is challenging to develop applications that work across multiple cameras. Similarly, the camera-specific photo-finishing operations used to render sRGB images also hinder applications intended to run on different cameras. Interestingly, the ISP camera pipeline includes a colorimetric conversion stage where the raw-RGB images are converted to a device-independent color space. However, this image state is not accessible. In this paper, we advocate for the ability to access the colorimetric image state and recommend that cameras output a third image format that is based on this device-independent colorimetric space. To this end, we perform experiments to demonstrate that image pixel values in a colorimetric space are more similar across different makes and models than sRGB and raw-RGB.",60033420,York University,Toronto,Canada,['1707'],20.727272727272727,0.07426470588235294,0.37058823529411766,1
1038,1038,Estimating OLED display device lifetime from pixel and screen brightness and its application,"In this paper we discuss a model to estimate the power consumption and lifetime (LT) of an OLED display based on its pixel value and the brightness setting of the screen (scbr). This model is used to illustrate the effect of OLED aging on display color characteristics. Model parameters are based on power consumption measurement of a given display for a number of pixel and scbr combinations. OLED LT is often given for the most stressful display operating situation, i.e. white image at maximum scbr, but having the ability to predict the LT for other configurations can be meaningful to estimate the impact and quality of new image processing algorithms. After explaining our model we present a use case to illustrate how we use it to evaluate the impact of an image processing algorithm for brightness adaptation.",60009507,University of Montreal,Montreal,Canada,['1707'],22.833333333333332,0.16856060606060605,0.30492424242424243,1
1039,1039,An evaluation of colonr-to-greyscale image conversion by linear anisotropic diffusion and manual colour grading,"In the paper ""Colour-to-Greyscale Image Conversion by Linear Anisotropic Diffusion of Perceptual Colour Metrics"", Farup et al. presented an algorithm to convert colour images to greyscale. The algorithm produces greyscale reproductions that preserve detail derived from local colour differences in the original colour image. Such detail is extracted by using linear anisotropic diffusion to build a greyscale reproduction from a gradient of the original image that is in turn calculated using Riemannised colour metrics. The purpose of the current paper is to re-evaluate one of the psychometric experiments for these Wo methods (CIELAB L∗ and anisotropic ΔE99) by using a flipping method to compare their resulting images instead of the side by side method used in the original evaluation. In addition to testing the two selected algorithms, a third greyscale reproduction was manually created (colour graded) using a colour correction software commonly used to process motion pictures. Results of the psychometric experiment found that when comparing images using the flipping method, there was a statistically significant difference between the anisotropic ΔE99 and CIELAB L∗ conversions that favored the anisotropic method. The comparison between ΔE99 conversion and the manually colour graded image also showed a statistically significant difference between them, in this case favoring the colour graded version.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],25.875,0.2159090909090909,0.5727272727272728,1
1040,1040,"Measuring, modeling, and reproducing material appearance from specular profile","A method is proposed for measuring, modeling, and reproducing material appearance from the specular profile representing reflectance distribution around a specular highlight. Our method is aimed at opaque materials with a highly glossy surface like plastic, ceramic, and metals. Hence, the material surface is assumed to be not a perfect mirror, but a surface with some roughness. We do not use a goniospectrophometer nor an image-based measurement setup. Instead, we make use of a gloss meter with a function to measure the specular profile, containing for glossy materials appearance such as roughness, sharpness, and intensity. The surface reflection is represented as a linear sum of diffuse and specular reflection components, the latter described by the Cook-Torrance model. The specular function represents the glossy surface appearance by a small number of control parameters. Mitsuba rendering system is utilized to perform the rendering algorithms. Finally, the feasibility of the proposed method is examined using different materials.",60021994,Nagano University,Ueda,Japan,['1707'],17.11111111111111,-0.08428571428571428,0.5771428571428572,1
1041,1041,Chromaticity coordinates for graphic arts based on CIE 2006 LMS with even spacing of Munsell colours,"We construct redness-greenness (r,g) coordinates to fit the spectral locus into a triangle in the normalised CIE 2006 LMS plane. The reflection spectra for the Munsell patches for blackbody illuminants from 5000 to 6500 K appear as near circles in this space, suggesting that equal steps in (r,g) space may correspond to equal perceived colour contrasts within the gamut of reflective colours. We fit a matrix to convert from XYZ to LMS for reflective colours.",120851496,Filmlight Ltd,London,United Kingdom,['1707'],25.0,0.18,0.34,1
1042,1042,Relative spectral difference occurrence matrix: A metrological spectral-spatial feature for hyperspectral texture analysis,"We develop a spectral-spatial feature, Relative Spectral Difference Occurrence Matrix (RSDOM) for hyperspectral texture recognition. Inspired by Julesz's conjecture, the proposed feature is based on spectral difference approach and respects the metrological constraints. It simultaneously considers the distribution of spectra and their spatial arrangement in the hyperspectral image. The feature is generic and adapted for any number of spectral bands and range. We validate our proposition by applying a classification scheme on the HyTexiLa database. An accuracy comparable to local binary pattern approach is obtained, but at a much reduced cost due to the extremely small feature size.",60032653,Universite de Poitiers,Poitiers,France,['1707'],16.333333333333336,-0.029166666666666664,0.1625,1
1043,1043,Color vision differences following retinal detachment and subsequent cataract surgery,"In September 2017, the first author suffered a rhegmatogenous retinal detachment. This experience included a series of remarkable, sometimes unsettling visual phenomena, which included visible differences in the color vision between her two eyes during the recovery from retinal detachment, as a cataract developed, and following cataract surgery. Her right eye is now equipped with a new lens, replacing one that had yellowed from years of exposure to ultraviolet radiation, which provides a cooler view of the world than before retinal detachment, with slight distortions, and occasionally with sparkles early in the morning. In this review, the color vision changes that were experienced are quantified and detailed. While this does not represent a typical study with a hypothesis and testing of various participants, we hope that it inspires others to ask interesting questions that lead to increased consideration of the relationships between perception and visual health and that it raises awareness of the warning signs of retinal detachment.",60027165,University of Rochester,Rochester,United States,['1707'],31.6,0.14639674051438756,0.40677998472116117,1
1044,1044,Development of the stool color card for early detection of - Biliary atresia using multispectral image,The stool color card for early detection of biliary atresia have been developed using multispectral images of stools of newborns. Color and its spectra were measured and analyzed spectrally first in the world and used to design the stool color card. Representative texture was selected by medical specialists from captured multispectral images and spectral information of the images was replaced and edited according to the result of spectral and chromaticity analysis. The stool color card was placed within the Maternal and Child Health Handbook that was distributed to all pregnant women by their respective local government according to the Maternal and Child Health Law in Japan.,60104703,National Center for Child Health and Development,Tokyo,Japan,['1707'],26.5,0.11190476190476191,0.21904761904761907,1
1045,1045,Color Space Transformation using Neural Networks,"We investigated how well a multilayer neural network could implement the mapping between two trichromatic color spaces, specifically from camera R,G,B to tristimulus X,Y,Z. For training the network, a set of 800,000 synthetic reflectance spectra was generated. For testing the network, a set of 8,714 real reflectance spectra was collated from instrumental measurements on textiles, paints and natural materials. Various network architectures were tested, with both linear and sigmoidal activations. Results show that over 85% of all test samples had color errors of less than 1.0 ΔE2000 units, much more accurate than could be achieved by regression.",60022148,UCL,London,United Kingdom,['1707'],19.4,0.17222222222222225,0.4000000000000001,1
1046,1046,Colour image enhancement using perceptual saturation and vividness,A perceptual study was conducted to enhance colour image quality in terms of naturalness and preference using perceptual scales of saturation and vividness. Saturation scale has been extensively used for this purpose while vividness has been little used. We used perceptual scales of a recently developed colour appearance model based on Jzazbz uniform colour space. A two-fold aim of the study was (i) to test performance of recently developed perceptual scales of saturation and vividness compared with previously used hypothetical models and (ii) to compare performance and chose one of saturation and vividness scales for colour image enhancement in future. Test images were first transformed to Jzazbz colour space and their saturation and vividness were then decreased or increased to obtain 6 different variants of the image. Categorical judgment method was used to judge preference and naturalness of different variants of the test images and results are reported.,60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],24.666666666666668,-0.030416666666666668,0.39583333333333337,1
1047,1047,Physical noise propagation in color image construction: A geometrical interpretation,"To avoid false colors, classical color sensors cut infrared wavelengths for which silicon is sensitive (with the use of an infrared cutoff filter called IR-cut). However, in low light situation, noise can alter images. To increase the amount of photons received by the sensor, in other words, the sensor's sensitivity, it has been proposed to remove the IR-cut for low light applications. In this paper, we analyze if this methodology is beneficial from a signal to noise ratio point of view when the wanted result is a color image. For this aim we recall the formalism behind physical raw image acquisition and color reconstruction. A comparative study is carried out between one classical color sensor and one specific color sensor designed for low light conditions. Simulated results have been computed for both sensors under same exposure settings and show that raw signal to noise ratio is better for the low light sensor. However, its reconstructed color image appears more noisy. Our formalism illustrates geometrically the reasons of this degradation in the case of the low light sensor. It is due on one hand to the higher correlation between spectral channels and on the other hand to the near infrared part of the signal in the raw data which is not intrinsically useful for color.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,['1707'],21.4,0.06492042440318303,0.4138783630162941,1
1048,1048,Analyzing color harmony of food images,"Color of food images play a key role in human perception of food quality and calories, as well as in food choice. In this paper we investigate the use of computational methods for color harmony analysis of food images. To this end we propose a computational pipeline that includes color segmentation, color palette extraction and color harmony prediction. Such a pipeline makes it possible to analyze the emotions elicited by pairs and multiple combinations of food dishes.",60021199,Consiglio Nazionale delle Ricerche,Rome,Italy,['1707'],19.25,0.0,0.52,1
1049,1049,Printing with light: Daylight-fluorescent inks for large-gamut multi-color printing,"With printing technologies continuously reaching ever higher degrees of performance an/qualify, the need for novelty andimpact and also keeps increasing Specialty inks have always played an important role here, albeit not without challenges. Often the use of such materials involved dedicated solutions that deal with these inks outside of the constraints of normal pipelines and workflows, which constrains their application and results in Hmited use. This is so since specialty inks, such as fluorescents, behave differently to traditional dye or pigment-based ones. So much so that most applications use specialty inks as spot colors, explicitly determining (by means of a separate layer in the input) where they are to be used for given content. For example, for materials such as fluorescents or quantum dots, the possibility of presenting more light at a given wLlength than is incident at that wavelength, breaks some of the basic assumptions of current processes from how they are measured to how they can be used in building color separations all the way to how color management deals with them. In this paper we describe first experiments of using fluorescent inks that are activated by visible-instead ofthe more customary UV-radiation, showing performance of spectrophotometer measurement with a dedicated model to handle the specific properties of these inks, as well as results ofthe impact such inks can have on extending color gamuts that go significantly beyond current printing gamuts and therefore also pose new challenges.",60107879,HP Inc.,Bengaluru,India,['1707'],39.666666666666664,0.17435064935064934,0.47918470418470416,1
1050,1050,Quantitative assessment of color tracking and gray tracking in color displays medical,"The goal of this study is to develop quantitative metrics for evaluating color tracking and gray tracking in a color medical display. Color tracking is the chromaticity consistency of the red, green, or blue shades. Gray tracking is the chromaticity consistency of the gray shades. Color tracking and gray tracking are the most important colorimetric responses of a color medical display because they directly indicate the color calibration quality and can therefore be used to compare color performance between displays. Two metrics, primary purity and gray purity, are defined to measure the color shift of the primary shades and gray shades of a color display, respectively. The area under the curves of primary purity and gray purity can then represent the quality of color tracking (C-AUC) and gray tracking (G-AUC), respectively. Fifteen displays including medical, professional-grade, consumer-grade, mobile, and special displays were tested to compare their C-AUC and G-AUC. The OLED displays have the greatest C-AUC values. The medical and professional-grade displays have the greatest combinations of C-AUC and G-AUC values. Most consumer-grade displays have lower C-AUC and G-AUC values, but some show better gray tracking than color tracking. The special displays exhibit particularly poor color and gray tracking. Using C-AUC and G-AUC together can quantitatively predict and compare color performance of different displays.",60101765,"Food and Drug Administration, Center for Devices and Radiological Health",Rockville,United States,['1707'],17.833333333333332,0.231055900621118,0.4062111801242235,1
1051,1051,Angular color prediction model for anisotropic halftone prints on a metallic substrate,"Under specular reflection, non-isotropic halftones such as line halftones printed on an ink-receiving plastic layer superposed with a metallic layer change their colors upon in-plane rotation of the print. This color change is due to the orientation-dependent optical dot gain of the halftone. A strong dot gain occurs when the incident light is perpendicular to the halftone line structure. A color prediction model is proposed which predicts under specular reflection the color of cyan, magenta and yellow line halftones as a function of the azimuthal rotation angle, the incident angle and the line frequency. The model is calibrated by measuring 17 reflectances at the (25° V 25°) measurement geometry, with the incident light parallel to the halftone lines. The model has been tested for several azimuthal rotation and incident viewing angles, each time for 125 different cyan, magenta and yellow ink surface coverages. The obtained prediction accuracies are between ΔE94 = 3:5 and ΔE94 = 7.",60107281,RISE Research Institutes of Sweden AB,Gothenburg,Sweden,['1707'],22.285714285714285,0.11083333333333334,0.3608333333333334,1
1052,1052,Subjective Judgments of Refrigerator Lighting by Altering Chromaticity and Placement across Age Groups,"This study investigates an optimal chromaticity and placement of refrigerator lighting to meet users' preference. In the experiment, eighteen lighting stimuli were provided by combining six chromaticities and three placements. A total of 177 women aged 20 to 69 participated and assessed the lighting stimuli using ten affective scales. Based on the assessments, we derived four aspects to describe the characteristics of lighting styles: performance, aesthetics, visual comfort, and overall satisfaction. Specifically, cool white lighting placed in front appealed the well-functioning, performance support aspect. Further, when the shelves were lit in magenta-white, the refrigerator interior was evaluated to be the most attractive. When visual comfort matters more, shelf lighting in cyan-white would be optimal. An age effect was also discovered. Younger participants in their 20s and 30s preferred cool white when lit indirectly. Participants over 40, however, found magenta-white more attractive, especially when they viewed it directly. By expanding this study to diverse product categories, it could produce additional empirical findings for designers, so that they may choose and place lighting properties more efficiently and successfully.",60094206,"LG Electronics, Korea",Seoul,South Korea,['1707'],16.0,0.2340909090909091,0.4272727272727272,1
1053,1053,Perceived glossiness: Beyond surface properties,"Gloss is widely accepted as a surface- and illuminationbased property, both by definition and by means of metrology. However, mechanisms of gloss perception are yet to be fully understood. Potential cues generating gloss perception can be a product of phenomena other than surface reflection and can vary from person to person. While human observers are less likely to be capable of inverting optics, they might also fail predicting the origin of the cues. Therefore, we hypothesize that color and translucency could also impact perceived glossiness. In order to validate our hypothesis, we conducted series of psychophysical experiments asking observers to rank objects by their glossiness. The objects had the identical surface geometry and shape but different color and translucency. The experiments have demonstrated that people do not perceive objects with identical surface equally glossy. Human subjects are usually able to rank objects of identical surface by their glossiness. However, the strategy used for ranking varies across the groups of people.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],16.0,-0.1279761904761905,0.5011904761904761,1
1054,1054,New metrics for evaluating whiteness of fluorescent samples,"A magnitude estimation experiment was carried out to scale the extent of whiteness from a set of near white textile samples including fluorescent white agent. Each was assessed under 4 different CCTs, each having a high and a low level of UV energy. The results were used to test various existing whiteness formulae. Finally, by fitting to the present data, two new metrics were developed. One is based on CIECAM02, and the other is based on the present CIE whiteness formula by transforming the data to D65 chromaticity from the other white sources via CAT02 chromatic adaption transform with a proper incomplete adaptation factor (D). It was also tested using an independent set of data. Both formulae gave accurate prediction to the data. The former metric is proposed because it is based on a colour appearance model.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],17.125,0.060334928229665075,0.27383572567783093,1
1055,1055,Tone mapping operators evaluation based on high quality reference images,"High Dynamic Range (HDR) imaging applications have been commonly placed recently. Several tone mapping operators (TMOs) have been developed which project the HDR radiance range to that of a display. Currently, there is no agreement on a technique for evaluation of tone mapping operators. The goal of this study is to establish a method based on reference images to evaluate the TMOs. Two psychophysical experiments were carried out for the evaluation of tone mapping operators. In the first experiment, a set of high quality images were generated to possess right extents of image features including contrast, colourfulness and sharpness. These images were further used in the second experiment as reference images to evaluate different TMOs. It was found Reinhard's photographic reproduction based on local TMO gave an overall better performance. CIELAB(2:1) and S- CIELAB metrics were also used to judge colour image quality of the same TMOs. It was found that both metrics agreed well with the visual results.",60117981,State Key Laboratory of Modern Optical Instrumentation,Hangzhou,China,['1707'],15.9,0.06798319327731092,0.2965126050420168,1
1056,1056,Smartphone-based measurement of the melanopic daylight efficacy ratio,"Recently, the CIE published a new standard in which the so called 'melanopic daylight efficacy ratio' (abbreviated to melanopic DER) is introduced. This number is helpful in estimating the impact that a light source may have on our circadian rhythm. Although the melanopic DER can be directly calculated from the spectral power distribution, in case the latter is unknown a spectrophotometer or similar instrument is required, which is usually unavailable to the general public. Here we demonstrate how the melanopic DER can be accurately estimated from a smartphone image of two selected color samples. In addition, using the smartphone's camera parameters we provide a method to estimate the illuminance. Combined these measurements allow an evaluation of the absolute melanopic stimulation.",120943392,Signify Research,Eindhoven,Netherlands,['1707'],20.0,0.07202797202797204,0.39650349650349653,1
1057,1057,Evaluation and modification of von Kries chromatic adaptation transform,"Over the years, various chromatic adaptation transforms have been derived to fit the visual perception. However, some research demonstrated that CAT02, the most widely used chromatic adaptation transform, overestimates the degree of adaptation, especially for colored illumination. In this study, a memory color matching experiment was conducted in a real scene with the background adapting field varying in field of view, luminance and chromaticity. It showed that a larger field of view results in more complete adaptation. The results were used to test several existing chromatic adaptation models and to develop three new types of models. All of them improved the performance to some extent, especially for the illuminations with low CCT.",60025063,KU Leuven,3000 Leuven,Belgium,['1707'],18.666666666666668,0.12402597402597403,0.44675324675324674,1
1058,1058,Appearance reconstruction of fluorescent objects based on reference geometric factors,"An approach is proposed for the reliable appearance reconstruction of fluorescent objects under arbitrary conditions of material and illuminant based on reference geometric factors. First, a large set of spectral images is acquired from a variety of scenes of fluorescent objects paired with a mutual illumination effect under different conditions. The target fluorescent object is constructed using a cube and a flat plate supporting it, and is subsequently illuminated using a directional light source. We produce many target objects of the same size with different fluorescent materials and observe them under different illumination conditions. The observed spectral images are subsequently decomposed into five components, combining the spectral functions and geometric factors. The reference geometric factors are independent of the material, illuminant, and illumination direction change; instead, they are only dependent on object geometries. A reliable estimation method of reference geometric factors is presented using the whole spectral images observed under various conditions. Further, we propose an algorithm for reconstructing a realistic appearance including mutual illumination effect under arbitrary conditions of material, illuminant, and illumination direction. Finally, the reliability of the proposed approach is examined experimentally.",60021994,Nagano University,Ueda,Japan,['1707'],20.555555555555557,0.08436147186147186,0.44637445887445887,1
1059,1059,Deep learning for dental hyperspectral image analysis,"The aim of this work is automatic and efficient detection of medically-relevant features from oral and dental hyperspectral images by applying up-to-date deep learning convolutional neural network techniques. This will help dentists to identify and classify unhealthy areas automatically and to prevent the progression of diseases. Hyperspectral imaging approach allows one to do so without exposing the patient to ionizing X-ray radiation. Spectral imaging provides information in the visible and near-infrared wavelength ranges. The dataset used in this paper contains 116 hyperspectral images from 18 patients taken from different viewing angles. Image annotation (ground truth) includes 38 classes in six different sub-groups assessed by dental experts. Mask region-based convolutional neural network (Mask R-CNN) is used as a deep learning model, for instance segmentation of areas. Preliminary results show high potential and accuracy for classification and segmentation of different classes.",60103673,Itä-Suomen yliopisto,Kuopio,Finland,['1707'],17.375,-0.030000000000000002,0.605,1
1060,1060,Spectral image recovery from spectral filter array cameras using LMMSE,"A hyperspectral camera can record a cube of data with both spatial 2D and spectral 1D dimensions. Spectral Filter Arrays (SFAs) overlaid on a single sensor allows a snapshot version of a hyperspectral camera. But acquired image is subsampled both spatially and spectrally, and a recovery method should be applied. In this paper we present a linear model of spectral and spatial recovery based on Linear Minimum Mean Square Error (LMMSE) approach. The method learns a stable linear solution for which redundancy is controlled using spatial neighborhood. We evaluate results in simulation using gaussian shaped filter's sensitivities on SFA mosaics of upto 9 filters with sensitivities both in visible and Near-Infrared (NIR) wavelength. We show by experiment that by using big neighborhood sizes in our model we can accurately recover the spectra from the RAWimages taken by such a camera. We also present results on recovered spectra of Macbeth color chart from a Bayer SFA having 3 filters.",60104653,Universite Grenoble Alpes,Saint Martin d'Heres,France,['1707'],19.75,0.0022959183673469546,0.3050170068027211,1
1061,1061,Deep learning approaches for whiteboard image quality enhancement,"Different whiteboard image degradations highly reduce the legibility of pen-stroke content as well as the overall quality of the images. Consequently, different researchers addressed the problem through different image enhancement techniques. Most of the state-of-the-art approaches applied common image processing techniques such as background foreground segmentation, text extraction, contrast and color enhancements and white balancing. However, such types of conventional enhancement methods are incapable of recovering severely degraded pen-stroke contents and produce artifacts in the presence of complex pen-stroke illustrations. In order to surmount such problems, the authors have proposed a deep learning based solution. They have contributed a new whiteboard image data set and adopted two deep convolutional neural network architectures for whiteboard image quality enhancement applications. Their different evaluations of the trained models demonstrated their superior performances over the conventional methods.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1707'],19.0,0.03213943950786056,0.4583595352016405,1
1062,1062,The impact of matching primary peak wavelength on color matching accuracy and observer variability,"Over time, much work has been carried out to ascertain the accuracy of the CIE standard color-matching functions, but no definitive answer has been given. Recent work indicates an undeniable discrepancy between visual and computed metamers calculated using the existing CIE (the International Commission on Illumination) standard observer CMFs, especially when matching with narrowband sources. With a spectrally tunable solid-state light source, a series of pilot matching experiments have been done using primaries with different peak wavelengths. The results indicate which regions in wavelength space are most sensitive to generating matching inaccuracies for a given CMF set and which primary combinations have the most stable matching performance.",60025063,KU Leuven,3000 Leuven,Belgium,['1707'],26.75,0.16153846153846155,0.3961538461538462,1
1063,1063,Analysis of relationship between wrinkle distribution and age based on the components of surface reflection by removing luminance unevenness on the face,"In this paper, we perform multi-resolution analysis by using Wavelet transform for the components of surface reflection on faces in order to acquire features of wrinkles and fine asperities on the face. Also, by applying principal component analysis to the acquired trend of the wrinkles and the fine asperities, we analyze the relationship between the distribution of wrinkles and asperities, and actual age statistically. In the previous researches, components of facial surface reflection were directly used for multiresolution analysis, and it is considered that the acquired relationship was dependent on the luminance unevenness of lighting on the face. In this research, therefore, we propose to remove the luminance unevenness of the lighting on the face is transformed into uniform distribution by signal processing, and it contributes to the appropriate analysis to the component of surface reflection on the face.",60002787,Chiba University,Chiba,Japan,['1707'],34.75,0.18095238095238095,0.3095238095238096,1
1064,1064,Case-based reasoning for the analysis of methylation data in oncology,"Researchers seek to identify biological markers which accurately differentiate cancer subtypes and their severity from normal controls. One such biomarker, DNA methylation, has recently become more prevalent in genetic research studies in oncology. This paper roposes to apply these findings in a study of the diagnostic accuracy of DNA methylation signatures for classifying metastasis samples. Very high classification performance measures were obtained from differentially methylated positions and regions, as well as from selected gene signatures. Perfect accuracy was achieved with the top 5 feature-selected genes using three similar cases and the K-nearest neighbor classifier. This work contributes to the path toward the identification of biological signatures for oncology samples using case-based reasoning.",60014235,State University of New York at Oswego,Oswego,United States,['1700'],18.666666666666668,0.30644444444444446,0.5705925925925927,1
1065,1065,Achieving automotive suppliers’ mass customization through modularity: Vital antecedents and the valuable role and responsibility of information sharing,"Purpose: Previous literature tends to combine postponement and modularity or view them as parallel factors to achieve mass customization (MC) while ignoring the sequence of a firm to design and implement operations and supply chain strategy. Based on a customer-oriented strategy and theories of organizational information processing theory, three-dimensional (3D) concurrent engineering and resource dependency, the purpose of this paper is to propose a sequential model reflecting the sequence of practices as well as an overview picture for a firm to achieve MC. Design/methodology/approach: The model links three company antecedents – postponement orientation, operational alignment and information sharing, to three company supply chain practices – product and process modularity and supplier segmentation. These practices, in turn, lead to the company’s MC capabilities. The proposed model is tested with a data set collected from automotive suppliers in China and in the USA. Structural equation modeling is used to analyze the data and test the model. Findings: The results suggest that, for suppliers to achieve MC, postponement orientation and operational alignment are vital antecedents. The results also reveal the important responsibility and role of information sharing practices in coordinating suppliers’ modularity practices. Originality/value: This research provides three findings that are of value to both academicians and practitioners of supply chain management. First, this study originally proposed and empirically tested that a postponement orientation is an antecedent of product and process modularity and supplier segmentation to achieve MC in the automotive sector, contrary to the traditional view of parallel relationships for both. Second, it developed and verified measures of operational alignment and supplier segmentation for future research use. Third, the vital role of information sharing to coordinate internal and external supply chain practices to achieve MC is empirically supported.",60031760,Central Washington University,Ellensburg,United States,"['1712', '1706']",23.833333333333332,0.05043859649122807,0.2802631578947368,1
1066,1066,ProCAKE: A process-oriented case-Based reasoning framework,"This paper presents ProCAKE - the process-oriented casebased knowledge engine of the CAKE framework, which has evolved from several research projects at the University of Trier over the years. ProCAKE constitutes a domain-independent framework that can be used to implement diverse structural or process-oriented case-based reasoning applications for integrated process and knowledge management. This paper gives an overview of the main components and demonstrates their application by examples.",60011891,Universitat Trier,Trier,Germany,['1700'],22.666666666666668,0.08333333333333333,0.16666666666666666,1
1067,1067,Seen the villains: Detecting social engineering attacks using case-based reasoning and deep learning,"Social engineering attacks are frequent, well-known and easy-toapply attacks in the cyber domain. Historical evidence of such attacks has shown that the vast majority of malicious attempts against both physical and virtual IT systems were based or been initiated using social engineering methods. By identifying the importance of tackling efficiently cybersecurity threats and using the recent developments in machine learning, case-based reasoning and cybersecurity we propose and demonstrate a two-stage approach that detects social engineering attacks and is based on natural language processing, case-based reasoning and deep learning. Our approach can be applied in offline texts or real time environments and can identify whether a human, chatbot or offline conversation is a potential social engineering attack or not. Initially, the conversation text is parsed and checked for grammatical errors using natural language processing techniques and case-based reasoning and then deep learning is used to identify and isolate possible attacks. Our proposed method is being evaluated using both real and semi-synthetic conversation points with high accuracy results. Comparison benchmarks are also presented for comparisons in both datasets.",60075096,German Research Center for Artificial Intelligence (DFKI),Kaiserslautern,Germany,['1700'],25.142857142857142,0.0473015873015873,0.3475963718820862,1
1068,1068,Service switching in case-based decisions following bad experiences: Online reviews data of Japanese hairdressing salons,"This paper examines consumer service switching from the perspective of case-based decision theory (CBDT), developed by Gilboa and Schmeidler. In contrast with the consumption of physical goods, it is difficult for consumers to evaluate their utility from service provi- sion in advance because of intangibility. CBDT is a decision criterion that reflects consumers' past experiences, and enables us to examine their reasoning for service switching. Our paper empirically examines consumer choice behavior based on past experiences, using data from Japanese hairdressing salons, which consist of salon introductions and individual reviews of those salons. We focus on bad service experiences because CBDT suggests that after experiencing bad service, consumers will choose services that are less similar for their next salon appointment. Our paper examines whether CBDT accurately predicts the switching process for the service consumption. The results indicate that prior experiences have no significant effect on service choices.",60025272,University of Tokyo,Tokyo,Japan,['1700'],21.0,-0.13463541666666662,0.3594494047619048,1
1069,1069,A novel interface for the explanation of group recommendations using augmented reality,"This paper describes our novel approach that applies Augmented Reality (AR) for the explanation of recommendations in the movie domain. Our goal is to use augmented reality in order to explain the recommendation of a movie either to a single user or a group of friends that are creating a joint plan. The presented system reuses our past results in group recommendation and AR to include explanation capabilities in a mobile scenario where users can receive situated recommendations (in a bus stop or in front of a movie marquee), and to join friends in a plan through facial recognition.",60027282,Universidad Complutense de Madrid,Madrid,Spain,['1700'],33.0,-0.10714285714285714,0.15476190476190477,1
1070,1070,Human activity recognition with deep metric learners,"Establishing a strong foundation for similarity-based return is a top priority in Case-Based Reasoning (CBR) systems. Deep Metric Learners (DMLs) are a group of neural network architectures which learn to optimise case representations for similarity-based return by training upon multiple cases simultaneously to incorporate relationship knowledge. This is particularly important in the Human Activity Recognition (HAR) domain, where understanding similarity between cases supports aspects such as personalisation and open-ended HAR. In this paper, we perform a short review of three DMLs and compare their performance across three HAR datasets. Our findings support research which indicates DMLs are valuable to improve similarity-based return and indicate that considering more cases simultaneously offers better performance.",60011885,Robert Gordon University,Aberdeen,United Kingdom,['1700'],22.4,0.22121212121212122,0.4121212121212121,1
1071,1071,Optimized energy aware resource allocation algorithm using software defined network technology," All rights reserved.The number of data centers (DCs) used for storing and processing data has evolved rapidly in recent years. However, the operations held by DCs may relate to a number of disadvantages, primarily presuming in excessive energy and power consumption due to the poor management standards applied. This may lead to a situation in which many devices within the DC operate at full capacity without any tasks assigned for actual execution. A Software Defined Network (SDN) is a network architecture where the control plane is an independent entity from the data plane, yielding to a higher controllability and flexibility over the network. Through the utilization of SDN architecture, a highly functional energy aware network may be established. In this paper, we propose a heuristic algorithm that monitors the current status of an SDN network (in addition to all ingoing and outgoing traffic), in order to dynamically and efficiently allocate network resources by ensuring that only the necessary network devices are active and by turning the idle ones off. The results show that the proposed algorithm reduces energy consumption of the network compared to existing solutions.",60070814,University of Wollongong in Dubai,Dubai,United Arab Emirates,['1705'],26.714285714285715,0.06260416666666667,0.5181250000000001,0
1072,1072,Multimedia mathematical communication in a diverse group of students," All rights reserved.The article tackles the problem of improving mathematical communication in a group of students with different visual impairment levels, under the guidance of a group leader or a teacher. Visually impaired persons face a problem while learning mathematics. The said problem results from the specific nature in which mathematical content (formulas, function graphs, geometrical figures and projections of solids) is recorded and presented. The effectiveness of learning mathematics is boosted when students work in a group moderated by a leader. This requires them to share documents, with the leader being able to keep track of the individual work of each participant, and with the group discussing specific solutions. In order for a visually impaired student to be able to participate in and contribute to the work of the group, either remotely or locally, all participants must use universal IT tools that support visually impaired students without complicating the work of others. This paper presents interactive multimedia solutions developed under two research projects carried out by the author. The said solutions support communication in mathematics. Results of qualitative surveys on new solutions are presented, confirming their usefulness and the measurable impact they exert on the efficiency of the group's work concerning mathematical problems.",60085241,"Naukowej i Akademickiej Sieci Komputerowej, Warszawa",Warsaw,Poland,['1705'],22.77777777777778,0.07272727272727272,0.19144385026737967,0
1073,1073,Representing temporal dependencies in human activity recognition,"Smart Homes offer the opportunity to perform continuous, long-term behavioural and vitals monitoring of residents, which may be employed to aid diagnosis and management of chronic conditions without placing additional strain on health services. A profile of the resident's behaviour can be produced from sensor data, and then compared over time. Activity Recognition is a primary challenge for profile generation, however many of the approaches adopted fail to take full advantage of the inherent temporal dependencies that exist in the activities taking place. Long Short Term Memory (LSTM) is a form of recurrent neural network that uses previously learned examples to inform classification decisions. In this paper we present a variety of approaches to human activity recognition using LSTMs and consider the temporal dependencies that exist in binary ambient sensor data in order to produce case-based representations. These LSTM approaches are compared to the performance of a selection of baseline classification algorithms on several real world datasets. In general, it was found that accuracy in LSTMs improved as additional temporal information was presented to the classifier.",60011885,Robert Gordon University,Aberdeen,United Kingdom,['1700'],25.142857142857142,0.07673992673992674,0.32765567765567766,1
1074,1074,Interactive assistance for scientific workflow modeling by case-based reasoning,Developing scientific workflows is a demanding task that can be supported in various ways. The range of approaches covers knowledge- intensive planning approaches to statistical approaches. Some of the key challenges are knowledge engineering and elicitation of the target problem to provide specific assistance. The presented research addresses these challenges with a case-based approach. The goal is to provide an interactive and self-improving assistant that collaborates with the developer not only to learn from newly created workflows but also to improve the underlying domain model.,60011891,Universitat Trier,Trier,Germany,['1700'],17.0,0.02727272727272727,0.615909090909091,1
1075,1075,Autonomous navigation control of UAV using wireless smart meter devices," All rights reserved.In preparation for the upcoming home delivery services that rely on Unmanned Aerial Vehicles (UAVs), we developed a new multi-hop radio network that is laid over a smart meter network transferring electric energy information only. In this network, a UAV follows, for navigation purposes, the topology of a virtual network overlaid on the physical smart meter network. We established a service management control method which does not rely on image analysis or map information processing, i.e. processes that consume precious power resources of the UAV. Instead, navigation is based on the routing technology. The current distance between the UAV and a node of the smart meter network is measured by means of the radio transmission loss value, therefore determining the position of the UAV. A two-layer network model has been proposed. One layer consists of a network of nodes in a residential area with scattered buildings - a location that is safer to navigate - while the other is an access network of nodes in a densely populated area. Then, we proposed methods to determine the direction of movement towards the next hop node on the data-link layer and the end node on the network layer, which is the target destination. We implemented a software-based test system and verified the effectiveness of the proposed methods.",60011944,Shibaura Institute of Technology,Tokyo,Japan,['1705'],21.8,0.11402007083825265,0.5091794569067297,0
1076,1076,Cyber-security for mobile service robots - Challenges for cyber-physical system safety," All rights reserved.A review of the known and an indication of the new threats for cyber-physical robotic systems, caused by cybernetic attacks, serves, in this paper, as a basis for the analysis of the known methods relied upon to detect and mitigate consequences of such attacks. A particular emphasis is placed on threats specific for cyber-physical systems, as they are a feature distinguishing these systems from their traditional Information and Communication Technologies (ICT) counterparts. Based on the review of literature and own analyses, unresolved issues regarding the cyber-security of robot systems are presented and discussed.",60003675,Politechnika Warszawska,Warsaw,Poland,['1705'],32.0,0.1147186147186147,0.4804112554112554,0
1077,1077,A CBR-ANN hybrid for dynamic environments,"This paper proposes a Case-based Reasoning (CBR) and Artificial Neural Network (ANN) hybrid solution for dynamic problems. In this solution, a CBR system chooses between several expert neural networks for a given case/problem. These neural networks are Recurrent Neural Networks, which are trained using Deep Q-Learning (DQN). The system was tested on the game Mega Man 2 for the NES, and is compared to how a single recurrent neural network performed. The results collected outperforms the basic ANN that it was compared against, and provides a good base for future research on the model.",60095417,Alexandra Instituttet AS,Aarhus,Denmark,['1700'],18.8,-0.11714285714285715,0.4030952380952382,1
1078,1078,Cl-MWSNs: Cross layer model-based QoS centric routing protocol for mission-critical cooperative communication in mobile WSNs," All rights reserved.The paper presents a robust QoS centric routing protocol for mission-critical communication over mobile Wireless Sensor Networks (CL-mWSN) that exploits dynamic network states from the different layers of the IEEE 802.15.4 protocol stack to make the routing decision. The CL-mWSN protocol exploits three key layers: application layer, network layer and MAC layer. It exhibits proactive network and node table management, service differentiation, fair resource scheduling and congestion detection, avoidance at the network layer, as well as dynamic link quality estimation and packet injection rate estimation at the MAC layer to assess its candidature as the best forwarding node for QoS-centric mission-critical communication. Simulation reveals that the proposed routing model exhibits higher throughput, minimum loss and deadline miss ratio that augments QoS provision in mobile WSNs.",60114322,Nitte Meenakshi Institute of Technology,Bengaluru,India,['1705'],32.0,0.24375,0.4666666666666666,0
1079,1079,Ontology-based transfer learning in the airport and warehouse logistics domains,"This work is a position paper for the examination of ontologybased transfer learning in the context of business processes. We continue our preliminary work on transfering process-oriented knowledge from a well-known source domain to a less specified target domain. We outline our ideas on workflows from two specific contexts: passenger and baggage logistics at the airport on one hand and warehouse management logistics on the other hand. In the first step we automatically transform BPMN files from these two domains in two separate ontologies. In the next step we intend to use ontology mapping as a means for the transfer. We plan to examine the concepts of generalization and abstraction to ease the transfer. We claim that the mentioned domains are feasible candidates for transfer learning, as we find several analogies between the airport handling and warehouse management workflows. Additionally we discuss possible utilization resp. benefits of the transfer learning within this two particular domains and draft the next steps for the future research.",60007762,Goethe-Universität Frankfurt am Main,Frankfurt am Main,Germany,['1700'],18.22222222222222,0.012500000000000002,0.23583333333333334,1
1080,1080,Dynamic difficulty adjustment in video games,"Dynamic difficulty adjustment (DDA) in video games context allows a game to be automatically adjusted and customized based on the player's performance. Our goal is to build a DDA architecture able to learn from behavioral data and return appropriate feedback to maximize the player's performance and enjoyment. For our experiments, we use Tetris Analytics video game, which is like a traditional Tetris from the player's point of view. However, it allows us to extract data from the games such as the movements made by the player, the state of the board, next piece, etc. With this data, we predict the player's profile and personalize the game.",60027282,Universidad Complutense de Madrid,Madrid,Spain,['1700'],21.2,-0.02222222222222223,0.41574074074074074,1
1081,1081,Design and prototype development of automated greenhouse with arduino and (IoT) application,"A greenhouse is a steel-frame structure, covered by the anti-UV plastic sheet to protect the crops and environmentally controlled to maximize the crop's condition and productivity. Exposure to the extreme temperature during the hot season in Malaysia will affect the growth of the crops that influence the quality, yield, and profit per season. This paper highlight to fabricate a small scale of greenhouse with air ventilation design for seed germination, plant propagation or cloning. It also focusing on controlling and monitoring system, and testing the system operation to reduce the greenhouse temperature. Three farmers were interviewed to determine the greenhouse problem and the possible ways to solve the problem. The 3D design is generated by Autodesk Inventor 2018 to visualize all the details regarding the greenhouse, and the Arduino software with Tinkercad simulation is used to simulate the coding and the system. The environment of the greenhouse can be monitored by the smartphone app include the temperature and humidity inside the greenhouse, the level of soil moisture and the level of water in the hydroponic tank. The system automatically executes the cooling, watering, lighting and warning notification features. The design and the system were tested, and the result was recorded to determine the temperature pattern. The result was then compared with the greenhouse at one of the farmers around Kuala Nerus, Terengganu that apply the greenhouse to maximise their productivity. The automated greenhouse with air ventilation design is 3°C lowered and 7°C can be reduced once all the cooling features operated simultaneously.",60103919,Universiti Sultan Zainal Abidin,Kuala Terengganu,Malaysia,['1700'],22.90909090909091,-0.03125,0.8125,1
1082,1082,An experimental analysis of the applications of datamining methods on bigdata,"Data mining is a procedure of separating covered up, obscure, however possibly valuable data from gigantic data. Huge Data impactsly affects logical disclosures and worth creation. Data mining (DM) with Big Data has been broadly utilized in the lifecycle of electronic items that range from the structure and generation stages to the administration organize. A far reaching examination of DM with Big Data and a survey of its application in the phases of its lifecycle won't just profit scientists to create solid research. As of late huge data have turned into a trendy expression, which constrained the analysts to extend the current data mining methods to adapt to the advanced idea of data and to grow new scientific procedures. In this paper, we build up an exact assessment technique dependent on the standard of Design of Experiment. We apply this technique to assess data mining instruments and AI calculations towards structure huge data examination for media transmission checking data. Two contextual investigations are directed to give bits of knowledge of relations between the necessities of data examination and the decision of an instrument or calculation with regards to data investigation work processes.",122490329,CSE,Rajahmundry,India,['1700'],24.0,0.16660353535353536,0.49261363636363636,1
1083,1083,Numerical investigation of finite element torsional rigidity revolution in formula car,"EIMARace formula student has become more popular inter institutions that open to the public, private, college, polytechnics and technical higher institution that served education through motorsport. One of the failure manner whenever do a material selection is torsional rigidity endurance. A torsional rigidity has grown to be more specific complex index study, having highly degrees of effect in influences on system operating; therefore, this paper mainly emphasizes the study on finite element calculation based on torsional rigidity. However, in torsional rigidity test can be conduct on most material to determine the torsional and mechanical properties behavior becomes highly concern due to i.e. crack propagation, rapid deformation, failure of properties. The study was conduct by using physics simulation software ANSYS version 15 and 3D CAD design software Solidworks version 2013. From the numerical study found that the torsional rigidity test has in a range of safety factor that could endurance incoming force acting at various region on mild steel AISI1030 hot rolled steel thus ensure the modulus of elastic in shear by mean of twisting test that comply with ASTM-E-143.",60000906,Universiti Sains Malaysia,Gelugor,Malaysia,['1700'],25.571428571428573,0.0931439393939394,0.4269318181818182,1
1084,1084,R Infrastructure and energy conservation in big data computing: A survey," All rights reserved.Progress in life, physical sciences and technology depends on efficient data-mining and modern computing technologies. The rapid growth of data-intensive domains requires a continuous development of new solutions for network infrastructure, servers and storage in order to address Big Data-related problems. Development of software frameworks, include smart calculation, communication management, data decomposition and allocation algorithms is clearly one of the major technological challenges we are faced with. Reduction in energy consumption is another challenge arising in connection with the development of efficient HPC infrastructures. This paper addresses the vital problem of energy-efficient high performance distributed and parallel computing. An overview of recent technologies for Big Data processing is presented. The attention is focused on the most popular middleware and software platforms. Various energy-saving approaches are presented and discussed as well.",60003675,Politechnika Warszawska,Warsaw,Poland,['1705'],16.625,0.13820995670995673,0.38090620490620497,0
1085,1085,Fuzzified control of deaerator system in power plant & comparative analysis with pid control scheme,". All rights reserved.Deaerator modeling is one of the utmost common difficulties in the process manufacturing. The input and output temperature are measured manually. The mathematical model of the deaerator is recognized in the laboratory circumstances using MATLAB simulations and the obtained model is used for implementing controllers like PI, PID, and Fuzzy in the simulation environment. The boiler deaerator temperature controller scheme is a non-linear, time-varying, delay control process. It can’t be accomplished satisfying the effect using traditional control algorithm to control deaerator water temperature. This paper suggests a fuzzy control algorithm, which can regulate the online control constraints to familiarize the variations of the deaerator water temperature. In this manu script we have carried out a simulation work for fuzzy control procedure and the PID control procedure in MATLAB Simulink. The simulation result shows that the system works well and has very good static and dynamic recital, strong sturdiness and self-adaptive capability.",60103989,"Sri Krishna College of Engineering and Technology, Coimbatore",Coimbatore,India,['1700'],17.11111111111111,0.24925925925925924,0.5922222222222223,1
1086,1086,Autonomous explainable agents,"Current trends in Artificial Intelligence are leading to the development of autonomous agents to perform critical operations in the real world. Events in real-world can endanger a wide range of discrepancies and the user should trust the agent to handle them. To achieve this the agent should be able to smartly adapt its behavior to handle the discrepancies and explain it to the human user. This thesis proposes a three-phase approach to address the above-mentioned problem. In the first phase, the agent uses case-based explanations and behavior adaptation in response to a discrepancy. This phase will not only help the agent build its knowledge about the discrepancy, but also forms a basis for its adapted behavior. In the second phase, the agent transforms the knowledge attained from the first phase to explain its behavior to the human operator. This knowledge includes both the causal understanding of the discrepancy and the reasoning behind its adapted behavior. In the final phase, the agent uses the feedback from the human counterpart to adapt its causal knowledge as well as its reasoning behind the behavior adaptation. Finally, this approach will be evaluated through the performance of the agent an underwater mine clearance domain, which is a surveillance mission to create a safe passage for ships.",60018306,Wright State University,Dayton,United States,['1700'],21.1,0.04071428571428572,0.5367261904761904,1
1087,1087,On preventing and detecting cyber attacks in industrial control system networks," All rights reserved.This paper outlines the problem of cybersecurity in OT (operations/operational technology) networks. It provides descriptions of the most common components of these systems, summarizes the threats and compares them with those present in the IT domain. A considerable section of the paper summarizes research conducted over the past decade, focusing on how common the problem is and in which countries it prevails. The article presents techniques most commonly used in the protection of these systems, with many examples from the nuclear industry given.",60113625,"Narodowe Centrum Badań Jądrowych, Otwock",Otwock,Poland,['1705'],21.5,0.05000000000000001,0.41111111111111115,0
1088,1088,Exploiting relationship among cases to make the best use of users feedback,"Recommender systems (RSs) are built with the aim to reduce the cognitive load on the user. An efficient RS should ensure that a user spends minimal time in the process. Conversational Case-Based Recommender systems (CCBR-RSs) depend on the feedback provided by the user to learn about the preferences of the user. In our work, we exploit the relationship among the cases/products in addition to the feedback (preference-based feedback (PBF)) provided by the user in several ways to develop an efficient CCBR-RS.",60025757,Indian Institute of Technology Madras,Chennai,India,['1700'],20.25,-0.05,0.3,1
1089,1089,Finite different method and differential quadrature method for solving burgers equation," All rights reserved.Finite Difference Method, FDM and Difference Quadrature Method, DQM are the main method used. In order to solve this method in terms of accuracy, the different number nodes and different initial condition are used [1]. The solutions of these methods are compared in terms of accuracy of the numerical solution by using the graph. C++ are used to find numerical solution for those method and the exact solution solve by using maple. For results and tabulate, compare the solution in terms of the accuracy of the numerical solution with the exact solution with the collected result. To find the best method to solve this equation, those method compare by using sum of square error, SSE. The lesser the number of node will affect the increasing the errors of the solution. Generally, in terms of accuracy of numerical solutions, FDM and DQM showed DQM is better than FDM.",60004351,Universiti Teknologi MARA,Shah Alam,Malaysia,['1701'],18.75,0.22166666666666668,0.3833333333333333,0
1090,1090,Improving medical coding with case-based reasoning - Evaluation for cancer registries,"Providing a comparable and consistent description of any entity is a difficult task. Vocabulary, semantics and objectives need to be very clearly defined and followed. The same can be said about cancer registries. They are an essential element in the fight against cancer. Among the main tasks of these registries is the data collection and coding process of cancer cases. To ensure comparable and consistent data, complex international standards and numerous best coding practices have been defined. Unfortunately this complexity can easily overwhelm operators, which are the people in charge of data collection and coding. While coding experts can help operators in their job, this represents a great burden on their precious time. To assist operators in their task and reduce the burden on coding experts, a coding assistant relying on arguments was designed and implemented. This system provides answers and a partial explanation, using arguments in favor and against answers. In this paper, a first evaluation of this system is presented, testing the system on real topography questions asked by operators.",60072560,Luxembourg Institute of Health,Luxembourg,Luxembourg,['1700'],15.636363636363637,0.14333333333333334,0.4707407407407408,1
1091,1091,"Recent trends in XAI: A broad overview on current approaches, methodologies and interactions","The definition of an explainable artificial intelligence heavily depends on the use-case, whether one is focusing on the technical knowledge-management component [30, 33, 37, 43] or rather the more social interaction including speech acts and conversations [27, 31, 33]. Since the uprising debate of the unknown outcome on the development of AI in general using Deep Learning [4, 34, 35, 44] and recent legal restrictions (for example the GDPR [19]), the need on developing an explainable AI is rapidly increasing, especially since the last two years. Additionally, the goal to increase the users trust towards AI has still to be achieved. Thus, this contribution aims to provide an overview on the current topics especially since 2018 with a focus on case-based explanations up until today.",60075096,German Research Center for Artificial Intelligence (DFKI),Kaiserslautern,Germany,['1700'],31.25,-0.008333333333333331,0.4702380952380953,1
1092,1092,An IDSS to identify and implement actions to protect drinking water sources in land use planning: Exploration and use of knowledge and past experiences,"Protecting source water is an important step in maintaining high drinking water quality. This involves the implementation of various actions, on the territorial level, aimed at reducing the impact of anthropogenic activities on water sources. Acting on the territory involves many organizations with different goals and responsibilities resulting in knowledge fragmentation within a decision-making process. In this research summary, we describe a doctoral research project aimed at designing a knowledge-based decision support system (KB-DSS) using case-based reasoning (CBR), in the province of Quebec (Canada). The system is meant to recommend source water protection actions based on past experiences. It is divided into two phases: 1) knowledge acquisition and structuring; 2) technical design, implementation and testing of the KB-DSS. The knowledge gathering methodology consists of a mixed method approach using online surveys, interviews and focus groups. The structuring process uses concept maps and coding analysis in Nvivo to create a graph-based edition process.",60032619,Université Laval,Quebec,Canada,['1700'],19.0,0.09000000000000001,0.41555555555555557,1
1093,1093,Demonstrating the myCBR rest API,"Case-based reasoning (CBR) tools are important to reduce the effort of developing CBR systems. myCBR has been a tool for researchers and practitioners over the last ten years providing CBR system building blocks and functionality through the myCBR-SDK and means to develop CBR models in the myCBR-workbench. In this paper we present the myCBR Rest API which exposes the functionality of both myCBR-SDK and myCBR-workbench though a RESTful API. It includes the myCBR-SDK functionality to enable researchers the fast development and experimentation of CBR applications from not only Java, but from the programming language of the developers choice. Most of the myCBR-workbench functionality has also been exposed in the same fashion enabling users to programmatically create, modify and delete CBR models and case-bases, so that the Rest API also allows myCBR to act as a service, and be accessed by the client software through HTTP.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1700'],29.0,0.1375,0.4114583333333333,1
1094,1094,Activity profiling and phenotypes of physical activity and sleep,"Physical inactivity and obesity contribute significantly to several health problems and have been a topic of research amongst the public health research community. Objective measurements of physical behaviour using body-worn sensors have radically uplifted the method of collecting physical behaviour data from a large population and opened the possibility of analysing these objective recordings using machine learning methods to gain useful insights such as identifying different physical activities and the duration of time spent in each activity, among others. We aim to address the theme of physical activity from both the public health and computer science perspective by first determining the best strategy to increase the accuracy of human activity classification from body-worn sensor data collected in cohort studies using the same data collection protocol as HUNT4 and strategically using objectively measured physical activity data to identify clusters of different physical behaviour phenotypes such that intra-cluster similarity is maximized. Identifying physical behaviour phenotypes can allow us in the future to design tailored interventions for users to self-manage their daily physical activity routines. Additionally, we consider the compositional nature of the physical behaviour data we have and plan to employ suitable methodologies which allow us to model the compositional co-dependency between physical behaviours and sleep.",60013141,Norges Teknisk-Naturvitenskapelige Universitet,Trondheim,Norway,['1700'],40.8,0.07142857142857144,0.20860215053763448,1
1095,1095,Employing multi-modal sensors for personalised smart home health monitoring,"As the prevalence of IoT sensor equipment in smart homes continues to rise, long term monitoring for personalised and more representative health tracking has become more accessible. The estimation of physiological health factors such as gait and heart rate can be captured using a range of diverse sensor equipment, while behavioural changes are now being monitored using simple binary sensors through activity classification and profiling. Combining both physiological and behavioural monitoring in fixed layout properties has already allowed us to effectively consider fall risk. However, expanding application of the system to new layouts and conditions requires consideration of differing retrofit home layouts and sensor configurations. A wider selection of sensors in varying configurations could potentially allow for the identification of other health conditions such as heart disease and stroke.",60011885,Robert Gordon University,Aberdeen,United Kingdom,['1700'],25.8,0.1731268731268731,0.5080419580419581,1
1096,1096,Hypothyroid disease diagnosis with causal explanation using case-based reasoning and domain-specific ontology,"Explainability of intelligent systems in health-care domain is still in its initial state. Recently, more efforts are made to leverage machine learning in solving causal inference problems of disease diagnosis, prediction and treatments. This research work presents an ontology based causal inference model for hypothyroid disease diagnosis using case-based reasoning. The effectiveness of the proposed method is demonstrated with an example from hypothyroid disease domain. Here, the domain knowledge is mapped into an expert defined ontology and causal inference is performed based on this domain-specific ontology. The goal is to incorporate this causal inference model in traditional case-based reasoning cycle enabling explanation for each solved problem. Finally, a mechanism is defined to deduce explanation for a solution to a problem case from the combined causal statements of similar cases. The initial result shows that case-based reasoning can retrieve relevant cases with 95% accuracy.",60006739,Mälardalens högskola,Vasteras,Sweden,['1700'],17.875,0.21250000000000002,0.55625,1
1097,1097,Optimization of drop-and-pull transport network based on shared freight station and hub-and-spoke network," All rights reserved.The current drop-and-pull (D-P) transport process has many defects, including but not limited to the insufficient information sharing, the private ownership of vehicles and infrastructure, and the mismatch between vehicles and goods. Moreover, the hardware and software of existing freight stations fall short of the demand for D-P transport. To solve these problems, this paper optimizes the design of the D-P transport network based on shared freight station and the hub-and-spoke (H-S) network. The freight stations were taken as the hubs, and the routes between supply/demand point and freight station are treated as spokes. On this basis, an optimization model was established to minimize the total cost of freight stations and maximize the force from freight stations on supply/demand points in the H-S D-P network. In addition, all the supply/demand points in the region are covered by the selected freight stations. The LINGO software was introduced to solve the established model. Taking a region in southern China for example, the proposed shared freight station design was compared with the traditional freight station design. The results show that the single-hub H-S D-P network obtained by the traditional design could meet the demand when the D-P demand was relatively small; however, only the multi-hub H-S D-P network obtained by the shared freight station design could fulfil a large D-P demand in an efficient manner. The research findings show that the shared freight station is the future of D-P transport.",60017060,Central South University,Changsha,China,['1706'],24.0,0.038461538461538464,0.45549450549450554,0
1098,1098,Case-base maintenance beyond case deletion,"Case-base maintenance strategies judiciously choose the most valuable cases to retain and the least valuable cases to delete in order to maintain a compact, competent case base. This research summary presents three case-base maintenance strategies which involve more than merely deleting cases: (1) Flexible feature deletion deletes components of cases instead of whole cases. (2) Adaptation-guided feature deletion prioritizes components for deletion according to their recoverability via adaptation knowledge. (3) Expansion-contraction compression, in addition to deleting cases, also adds cases in unexplored regions of the prob- lem space. Evaluation of the strategies compared to standard case-base maintenance shows improved retention of competence and solution quality for suitable data sets compressed to the same sizes.",60021121,Indiana University Bloomington,Bloomington,United States,['1700'],22.8,-0.0090909090909091,0.5310606060606061,1
1099,1099,Constructing prototypes for classification using epigenetic and genetic analysis,"Researchers seek to identify biological markers which accurately differentiate cancer subtypes and their severity from normal controls. One such biomarker, DNA methylation, has recently become more prevalent in genetic research studies in oncology. This project seeks to apply the innovative and adaptive machine learning methodology in case-based reasoning (CBR) to examine DNA methylation levels in breast cancer. Instead of relying on a generalized knowledge-base, CBR uses highly specific information extracted from similar cases which can also greatly expedite the process of finding a solution. Further, this can locate targeted biomarkers by reusing homogenous factors, or revising to locate novel biomarkers in highly heterogeneous samples. While locating these biomarkers, this project proposes to use CBR to classify samples, predict prognoses and determine survival factors.",60014235,State University of New York at Oswego,Oswego,United States,['1700'],20.5,0.2281818181818182,0.5316666666666667,1
1100,1100,Visiting structural differences of explanations,"During the very recent two years, the rising interest in explanations is undeniable with much more research focusing XAI and conferences using this topic as their main theme. We present our current research in this area and provide further steps we are taking to structure the vast different facets of an explanation (attributes, goals, types, targets, ...). The reason behind this structural effort is to enable an XAI component to effectively find the most appropriate explanation for a given user. We suggest that this explanation can change during the course of a conversation and depends heavily on the user's current emotional state.",60075096,German Research Center for Artificial Intelligence (DFKI),Kaiserslautern,Germany,['1700'],25.5,0.11111111111111112,0.513888888888889,1
1101,1101,Feature Recognition Method for Hand-Written Signature Image,"In recent years, the online payment by using credit card on Internet is still one of the major payment approaches. Although it is convenient and quick in use, there are lots of increasing demands in security solution. In this paper, we propose a feature recognition method to quickly verify whether user’s handwritten signature image is matched the record stored in the feature-based electronic handwritten-signature database (FEHS-DB) or not. The FEHS-DB is pre-established via records learning process. After the signing the signature by the user, the signature image is outputted as a same-size image. Then, the image will be taken its center point, and use the concentric circles in order to capture the intersection. Finally, these features are compared with the learned record in the FEHS-DB. The specific features retrieved by our scheme from the signature image could easily identify the signature is true or not. In addition, we show that the recognition speed is very fast than the traditional schemes.",60031941,China Medical University Hospital Taichung,Taichung,Taiwan,"['1706', '1705', '1710']",17.77777777777778,0.15204545454545457,0.5443939393939394,1
1102,1102,A fuzzy-based approach for mobilepeerdroid system considering of peer communication cost,"In this work, we present a distributed event-based awareness approach for P2P groupware systems. The awareness of collaboration will be achieved by using primitive operations and services that are integrated into the P2P middleware.We propose an abstract model for achieving these requirements and we discuss how this model can support awareness of collaboration in mobile teams. In this paper, we present a fuzzy-based system for improving peer coordination quality according to four parameters. We consider Peer Communication Cost (PCC) as a new parameter This model will be implemented in MobilePeerDroid system to give more realistic view of the collaborative activity and better decisions for the groupwork, while encouraging peers to increase their reliability in order to support awareness of collaboration in MobilePeerDroid Mobile System. We evaluated the performance of proposed system by computer simulations. From the simulations results, we conclude that when AA, SCT, GS values are increased, the peer coordination quality is increased, but when PCC is increased, the peer coordination quality is decreased.",60009108,Fukuoka Institute of Technology,Fukuoka,Japan,"['1706', '1705', '1710']",27.5,0.12900432900432898,0.3554112554112554,1
1104,1104,Global Fairness Model Estimation Implementation in Logical Layer by Using Optical Network Survivability Techniques,"Optical communication network plays an predominant role in the life of the user(s) system by providing high demand i.e. digital signal levels, fair queuing and channel reuse for high capacity links. In optical communications, Optical Component and Parameter (OCP) are becoming more accurate in order to provide the significance of the optical devices. Optical networks are enhanced in order to afford the optical technologies connectivities to provide high end communication in terms of sustainability and survivability. In survivability concept, two layers plays a significant/vital role between source to destination i.e. end to end connectivities is much reliable in terms of node connectivities, flow connectivities hence local to global fair queuing is achieved with the lower bound to upper bound and vice versa. Further the path propagation determines the range of path propagation determines the range of packets and its estimation is measured by using the concept of node mobility and scalability. It achieves the global range of optical packet transmission reception and design issues in network architecture analysis.",60114353,NMAM Institute of Technology,Udupi,India,"['1706', '1705', '1710']",21.0,0.2286666666666667,0.4068888888888889,1
1105,1105,Clinical Trial on Computer-Aided Design in Pre-operative Alveolar Bone Grafting in Cleft Lip - Cleft Palate Patient,"Cleft lip and cleft palate are facial anomalies. One of the treatment for the patients is alveolar bone grafting. In Thailand, spiral CT scan has been extensively utilized in the diagnosis in order to examine the lesions on facial bone. However, spiral CT scans are expensive, relatively large and immobile. In this study, we evaluated the application of moveable CT scan. The important pre-operative information such as the shape of the alveolar cleft, the volume of the alveolar cleft, teeth, and tip of dental roots around alveolar cleft are required for treatment planning. Normally, plastic surgeons measured and evaluated these quantities in the operating room. Differently, the cleft lip and cleft palate patients underwent mobile CT for the pre-operative period. And with computer-aided design software, plastic surgeons worked collaboratively with engineers to process output and perform measurement pre-operatively. Our study shows that the pre-operative information from computer-aided design can increase understanding for alveolar cleft anatomy. The most important advantage of mobile CT and computer-aided design software is avoidance of dental root injury during alveolar bone graft operation.",60000881,Chiang Mai University,Chiang Mai,Thailand,"['1706', '1705', '1710']",16.090909090909093,0.10584415584415585,0.5192640692640693,1
1106,1106,Hyper Elliptic Curve Based Homomorphic Encryption Scheme for Cloud Data Security,"Another rising pattern in the field in PC innovation is Cloud computing. Generally, the information was kept up and controlled in one possess servers. Cloud computing is a stretchy, savvy, and affirmed conveyance stage for giving business or shopper IT benefits in overabundance of the Internet. Today, Cloud provider gives conveyance of registering as an administration. Contingent upon the administration, the colossal data is shared over the system and this tremendous measure of information is put away in the cloud service provider. Henceforth, security is a noteworthy worry for the information in the cloud. Different encryption calculations were combined for securing the information in the cloud. Yet at the same time, the information is not secure in the cloud because of different assaults on the information. Thus, another method called Homomorphic encryption is presented which is a smart thought that enables particular operations to be performed on the scrambled information. In this paper, we propose hybrid homomorphic encryption calculation for giving improved security and secrecy of the information that is put away in the cloud. The Encryption procedure is conveyed by utilizing Hyper Elliptic Curve Cryptography (HECC) calculation, which creates a key, this resultant key is sent to the cloud provider where Homomorphic multiplicative operations are combined to the scrambled key. Hence, the encoded key is put away in the cloud which can be gotten to whenever. Since the cloud supplier has the scrambled key no other individual can have the capacity to know which operation has been performed. Consequently security and confirmation is upgraded. For the best Performance and most incredible security of cloud computing, this paper proposed homomorphic hybrid encryption strategy. Both are ideal, a mix of HECC and Homomorphic encryption to hybrid calculation. Here first we are creating key from HECC cryptosystem then these private and public keys taken after by Homomorphic with the end goal of encryption/decoding, for a safe scrambled correspondence of clients in cloud.",60114485,Chikkanna Government Arts College,Tiruppur,India,"['1706', '1705', '1710']",18.823529411764707,0.18756868131868132,0.6365842490842493,1
1107,1107,A Cloud Fog Based Framework for Efficient Resource Allocation Using Firefly Algorithm,"Information Technology (IT) is progressing day by day. With the effective and efficient use of IT new techniques are emerging introducing new Platforms for the development of computing based System. One of the emerging technologies of present era is cloud computing. However, Cloud computing is a new technique, yet it has broader scope in every aspect of Technology. Cloud computing as an Internet based technique allows Consumption of resources efficiently in cost effective way. Fog is also an internet based solution for sharing resources but has less storage and increased Security than Cloud. Load balancing is very important factor effecting any Cloud or Fog environment. Resource sharing in a way that there is maximum utilization of resources is very difficult yet worthy challenge. Different Algorithms work for Load balancing. This paper uses FireFly Algorithm for Load balancing along with Cost reduction.",60089631,COMSATS University Islamabad,Islamabad,Pakistan,"['1706', '1705', '1710']",14.1,0.14961432506887049,0.6027548209366391,1
1108,1108,Cyclic redundancy check based data authentication in opportunistic networks,"Opportunistic Networks (OppNets) work with dynamic topology, neither having focused management nor any protection system. Security is a challenging and open research issue in OppNets. A source node always has the concerns about its data. The success of any network depends on percentage of guaranteed and authenticated delivery that it can provide from source node to destination node. OppNets nodes like handheld devices, vehicular nodes, sensors, RFID, etc., have limited calculation resources and small buffering capacity. Hence the aim of the proposed technique is to logically use the energy and storage of the OppNet nodes. In this paper, we present a novel message authentication technique for opportunistic networks. The proposed technique is based on cyclic redundancy check (CRC) encryption with timestamps. The idea is simple but powerful with high accuracy results and efficiently utilizing the resources of the network nodes. The analysis of the proposed protocol shows that it can resist malicious attacks, which may alter or modify the data packets during the transmission.",60114078,"University of Delhi, Miranda House",New Delhi,India,"['1706', '1705', '1710']",16.4,0.10805194805194805,0.39606060606060606,1
1109,1109,Efficient Energy Management Assisted by Fog Computing,"Now a day, every field is consuming services of Cloud Computing (CC) because everyone is not able to deploy his own data centers. Due to the large number of requests on central place concept of Fog for the distributed processing of requests. Fog is placed between user and cloud to reduce the Response Time (RT). Smart Grid (SG) is also integrated cloud architecture for efficient management of energy. In this paper Fog Based architecture for SG is presented. Due to this there is no chance of a peak time generation at any time. A three-tier architecture is used for request processing. In SG environment there is need of low latency and high RT for providing uninterpretable services to the end user. For this purpose, Fog layer is used between cloud and SM (Smart Meter) and it acts as intermediate layer. A model is presented in this paper for efficient distribution of load among all available Virtual Machines (VMs). A load balancing technique is implemented for load distribution. Two regions are taken into account for experimental results and each region is divided into six group/cluster of building. Three Fogs are placed in each region for better RT and it produce optimal results as shown in simulations and discussion section.",60121546,University of Gujrat,Gujrat,Pakistan,"['1706', '1705', '1710']",16.0,0.1463736263736264,0.49840659340659343,1
1110,1110,Proposal of a Regional Culture Inheritance System by AR Technology,"In this research, we implement a regional culture inheritance system by digital archiving of regional cultural assets. This system realizes inheritance of regional culture and dissemination of information on cultural activities. This system is a smartphone application utilizing Web-GIS and AR (Augmented Reality) technology. By utilizing Web-GIS technology, this system provides users with multi-dimensional information visualization and location information reference. Also, by utilizing AR technology, this system provides users with browsing of regional culture contents superimposed on real space.",60009108,Fukuoka Institute of Technology,Fukuoka,Japan,"['1706', '1705', '1710']",15.8,0.1,0.125,1
1111,1111,Performance Analysis of MIMO Systems Over AWGN and Rician Channels Using QOSTBC4 as Space Time Block Coding Technique with Zero Forcing Receiver,"MIMO is the technology in which multiple antennas (MIMO) are utilized as a part of wireless communication to accomplish high data rates and increasing the demand of clients in various fields. The main motive is to use spatial diversity in proper way by placing n number of antennas at the transmitting and receiving ends. This technology has different types of space time coding. In this paper analysis has done for QOSTBC4 through the comparison of AWGN and Rician channels. The number of reception antennas increases and no. of transmitting antennas is 4. This paper shows the analysis of QOSTBC4 through the comparison of different channels, such as AWGN and Rayleigh channel between the BER vs SNR for the improvement of spatial diversity.",60094571,Lovely Professional University,Phagwara,India,"['1706', '1705', '1710']",17.428571428571427,0.04083333333333333,0.39666666666666667,1
1112,1112,A model for data enrichment over IOT streams at edges of internet,"In this paper some issues related to the efficiency of processing IoT data are addressed through semantic data enrichment and edge computing. The aim is to cope with big data streams at various levels, from the lowest level of data capturing to the highest level of Cloud platforms and applications. The objective is thus to extract full knowledge contained in the data in real time but also to solve bottlenecks of processing observed in IoT Cloud systems, in which IoT devices are directly connected to Cloud servers. An architecture comprising various levels is introduced, where each level is in charge of specific functionalities in the overall processing chain. In particular, there is a focus on the layer of semantic data enrichment in order to enable further processing and reasoning in upper layers of the architecture. Some preliminary evaluation results are presented to highlight the issues and findings of this study using a case study of pothole detection in roads based on a data stream collected by cars.",60012937,Universiteit Antwerpen,Antwerpen,Belgium,"['1706', '1705', '1710']",27.833333333333332,0.06282051282051282,0.29294871794871796,1
